==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=16, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=132, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=132, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=264, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=264, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 14.880 | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.704 | Acc: 1.488,0.893,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.640 | Acc: 1.791,1.048,1.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.584 | Acc: 1.755,1.242,1.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.530 | Acc: 1.562,1.254,1.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.474 | Acc: 1.477,1.253,1.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 14.422 | Acc: 1.530,1.259,1.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 14.387 | Acc: 1.524,1.291,1.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 14.362 | Acc: 1.543,1.339,1.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 14.338 | Acc: 1.532,1.342,1.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 14.314 | Acc: 1.485,1.325,1.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 14.294 | Acc: 1.478,1.312,1.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 14.270 | Acc: 1.501,1.310,1.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 14.257 | Acc: 1.494,1.311,1.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 14.243 | Acc: 1.540,1.309,1.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 14.236 | Acc: 1.521,1.282,1.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 14.230 | Acc: 1.536,1.270,1.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 14.230 | Acc: 1.498,1.260,1.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 14.231 | Acc: 1.463,1.249,1.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 14.223 | Acc: 1.464,1.253,1.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.988 | Acc: 0.781,0.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.959 | Acc: 1.488,1.228,1.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.955 | Acc: 1.505,1.010,1.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.961 | Acc: 1.601,1.076,1.191,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 14.211 | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.182 | Acc: 2.083,1.079,1.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.166 | Acc: 2.058,1.220,1.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.138 | Acc: 1.985,1.204,1.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.132 | Acc: 1.842,1.370,1.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.136 | Acc: 1.795,1.377,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 14.126 | Acc: 1.795,1.388,1.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 14.108 | Acc: 1.834,1.396,1.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 14.095 | Acc: 1.849,1.344,1.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 14.086 | Acc: 1.865,1.347,1.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 14.073 | Acc: 1.885,1.380,1.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 14.065 | Acc: 1.916,1.407,1.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 14.060 | Acc: 1.926,1.397,1.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 14.055 | Acc: 1.898,1.395,1.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 14.050 | Acc: 1.877,1.404,1.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 14.042 | Acc: 1.879,1.396,1.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 14.036 | Acc: 1.874,1.392,1.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 14.033 | Acc: 1.860,1.372,1.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 14.026 | Acc: 1.857,1.350,1.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 14.019 | Acc: 1.839,1.362,1.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.722 | Acc: 1.562,0.781,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.156 | Acc: 2.121,1.339,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.187 | Acc: 1.848,1.315,1.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.138 | Acc: 1.767,1.409,1.242,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 13.901 | Acc: 0.781,0.781,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.930 | Acc: 1.525,0.967,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.927 | Acc: 1.677,1.029,1.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.930 | Acc: 1.819,1.037,1.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.907 | Acc: 1.842,1.138,1.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.903 | Acc: 1.818,1.091,1.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.893 | Acc: 1.750,1.085,1.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.889 | Acc: 1.773,1.031,1.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.897 | Acc: 1.776,1.034,1.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.894 | Acc: 1.865,1.122,1.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.894 | Acc: 1.889,1.081,1.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.890 | Acc: 1.895,1.078,1.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.891 | Acc: 1.926,1.125,1.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.888 | Acc: 1.913,1.134,1.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.882 | Acc: 1.913,1.143,1.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.877 | Acc: 1.962,1.168,1.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.871 | Acc: 1.969,1.163,1.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.867 | Acc: 1.945,1.189,1.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.863 | Acc: 1.987,1.231,1.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.859 | Acc: 1.979,1.222,1.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.917 | Acc: 2.344,0.781,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.728 | Acc: 2.307,1.897,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.844 | Acc: 2.172,1.658,1.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.740 | Acc: 2.177,1.755,1.934,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 13.931 | Acc: 2.344,1.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.773 | Acc: 2.641,1.935,1.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.768 | Acc: 2.725,1.982,1.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.759 | Acc: 2.600,1.908,1.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.755 | Acc: 2.498,1.861,1.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.758 | Acc: 2.491,1.833,1.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.754 | Acc: 2.454,1.782,1.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.753 | Acc: 2.421,1.790,1.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.754 | Acc: 2.392,1.800,2.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.754 | Acc: 2.339,1.735,1.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.750 | Acc: 2.309,1.765,1.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.744 | Acc: 2.291,1.760,1.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.738 | Acc: 2.269,1.763,1.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.735 | Acc: 2.248,1.748,2.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.732 | Acc: 2.252,1.752,2.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.730 | Acc: 2.256,1.770,2.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.729 | Acc: 2.244,1.769,2.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.728 | Acc: 2.241,1.746,2.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.723 | Acc: 2.236,1.772,2.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.721 | Acc: 2.237,1.755,2.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.894 | Acc: 3.125,3.125,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.718 | Acc: 2.530,2.158,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.736 | Acc: 2.248,2.229,1.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.722 | Acc: 2.075,2.228,2.088,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 13.678 | Acc: 3.125,0.000,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.639 | Acc: 2.604,1.451,1.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.619 | Acc: 2.725,1.810,1.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.622 | Acc: 2.613,1.985,2.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.628 | Acc: 2.566,2.064,1.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.628 | Acc: 2.437,2.119,1.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.631 | Acc: 2.402,2.027,1.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.626 | Acc: 2.355,1.978,1.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.621 | Acc: 2.373,1.931,1.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.618 | Acc: 2.314,1.912,1.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.617 | Acc: 2.282,1.873,1.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.616 | Acc: 2.224,1.852,1.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.613 | Acc: 2.227,1.832,1.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.613 | Acc: 2.212,1.811,1.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.608 | Acc: 2.213,1.829,1.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.606 | Acc: 2.196,1.838,1.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.603 | Acc: 2.176,1.876,1.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.601 | Acc: 2.183,1.821,1.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.602 | Acc: 2.177,1.818,1.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.600 | Acc: 2.176,1.833,1.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.593 | Acc: 2.344,0.781,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.611 | Acc: 2.195,1.302,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.611 | Acc: 2.306,1.372,2.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.603 | Acc: 2.485,1.306,2.280,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 13.473 | Acc: 2.344,0.781,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.548 | Acc: 2.567,1.749,1.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.555 | Acc: 2.496,1.925,1.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.555 | Acc: 2.549,1.793,1.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.544 | Acc: 2.431,1.804,1.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.529 | Acc: 2.444,1.849,2.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.524 | Acc: 2.454,1.872,1.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.526 | Acc: 2.366,1.856,1.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.524 | Acc: 2.363,1.834,1.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.520 | Acc: 2.326,1.817,1.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.513 | Acc: 2.293,1.850,1.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.510 | Acc: 2.255,1.831,1.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.505 | Acc: 2.253,1.828,1.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.501 | Acc: 2.272,1.814,1.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.499 | Acc: 2.291,1.807,1.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.494 | Acc: 2.318,1.801,1.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.488 | Acc: 2.283,1.825,1.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.483 | Acc: 2.305,1.821,1.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.477 | Acc: 2.307,1.842,1.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.475 | Acc: 2.292,1.852,1.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.396 | Acc: 3.906,1.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.445 | Acc: 2.195,2.232,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.452 | Acc: 2.191,2.191,2.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.451 | Acc: 2.190,2.216,2.293,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 13.347 | Acc: 2.344,3.906,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.403 | Acc: 2.195,2.009,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.402 | Acc: 2.191,2.115,1.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.405 | Acc: 2.088,2.024,2.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.400 | Acc: 2.209,1.987,2.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.391 | Acc: 2.297,1.957,2.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.385 | Acc: 2.324,1.956,2.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.386 | Acc: 2.316,1.961,1.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.379 | Acc: 2.373,1.975,2.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.374 | Acc: 2.318,1.951,2.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.366 | Acc: 2.371,2.068,2.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.363 | Acc: 2.379,2.075,2.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.357 | Acc: 2.383,2.097,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.354 | Acc: 2.350,2.092,2.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.353 | Acc: 2.369,2.052,2.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.347 | Acc: 2.380,2.017,2.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.342 | Acc: 2.380,2.008,2.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.338 | Acc: 2.339,2.028,2.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.334 | Acc: 2.326,2.028,2.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.331 | Acc: 2.338,2.003,2.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.184 | Acc: 4.688,5.469,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.251 | Acc: 2.455,2.344,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.261 | Acc: 2.591,2.325,2.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.259 | Acc: 2.433,2.152,2.305,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 13.248 | Acc: 0.781,1.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.230 | Acc: 1.674,2.046,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.208 | Acc: 2.382,2.268,1.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.211 | Acc: 2.549,2.344,1.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.220 | Acc: 2.527,2.363,1.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.218 | Acc: 2.591,2.336,1.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.218 | Acc: 2.563,2.331,1.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.217 | Acc: 2.532,2.311,1.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.216 | Acc: 2.523,2.261,1.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.213 | Acc: 2.581,2.339,2.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.210 | Acc: 2.542,2.305,2.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.207 | Acc: 2.531,2.305,2.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.206 | Acc: 2.522,2.263,2.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.205 | Acc: 2.490,2.221,2.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.200 | Acc: 2.461,2.219,2.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.199 | Acc: 2.427,2.204,2.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.200 | Acc: 2.451,2.207,2.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.197 | Acc: 2.442,2.193,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.194 | Acc: 2.456,2.199,2.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.189 | Acc: 2.454,2.182,2.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.041 | Acc: 5.469,3.125,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.125 | Acc: 2.641,2.604,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.128 | Acc: 2.687,2.553,2.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.128 | Acc: 2.677,2.267,2.344,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 13.212 | Acc: 0.781,0.000,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.181 | Acc: 2.232,1.786,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.159 | Acc: 2.591,2.439,2.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.150 | Acc: 2.561,2.228,1.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.134 | Acc: 2.575,2.218,1.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.130 | Acc: 2.614,2.197,2.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.128 | Acc: 2.563,2.279,2.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.122 | Acc: 2.538,2.294,2.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.119 | Acc: 2.577,2.329,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.111 | Acc: 2.585,2.404,2.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.108 | Acc: 2.542,2.402,2.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.103 | Acc: 2.552,2.397,2.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.100 | Acc: 2.577,2.412,2.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.096 | Acc: 2.622,2.422,2.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.093 | Acc: 2.597,2.369,2.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.092 | Acc: 2.598,2.346,2.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.091 | Acc: 2.592,2.341,2.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.088 | Acc: 2.614,2.328,2.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.086 | Acc: 2.614,2.303,2.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.082 | Acc: 2.604,2.297,2.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.934 | Acc: 3.906,2.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.027 | Acc: 2.530,2.641,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.031 | Acc: 2.630,2.458,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.030 | Acc: 2.587,2.318,2.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 12.954 | Acc: 2.344,3.906,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.014 | Acc: 2.307,2.195,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.014 | Acc: 2.515,2.306,2.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.033 | Acc: 2.421,2.177,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.038 | Acc: 2.537,2.209,2.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.034 | Acc: 2.607,2.243,2.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.030 | Acc: 2.608,2.311,2.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.028 | Acc: 2.604,2.261,2.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.029 | Acc: 2.591,2.247,2.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.026 | Acc: 2.585,2.219,2.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.021 | Acc: 2.577,2.223,2.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.019 | Acc: 2.644,2.252,2.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.018 | Acc: 2.668,2.256,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.017 | Acc: 2.631,2.203,2.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.020 | Acc: 2.625,2.196,2.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.018 | Acc: 2.629,2.198,2.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.019 | Acc: 2.633,2.205,2.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.019 | Acc: 2.646,2.238,2.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.017 | Acc: 2.636,2.238,2.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.014 | Acc: 2.629,2.237,2.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.865 | Acc: 5.469,0.781,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.969 | Acc: 2.865,2.158,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.976 | Acc: 2.934,2.401,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.976 | Acc: 2.856,2.126,2.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 12.880 | Acc: 2.344,1.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.977 | Acc: 2.604,2.232,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.993 | Acc: 2.477,2.191,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.996 | Acc: 2.369,2.152,2.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.980 | Acc: 2.556,2.315,2.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.975 | Acc: 2.584,2.321,2.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.971 | Acc: 2.563,2.299,2.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.967 | Acc: 2.632,2.311,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.962 | Acc: 2.645,2.358,2.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.959 | Acc: 2.693,2.352,2.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.957 | Acc: 2.694,2.387,2.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.955 | Acc: 2.637,2.358,2.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.954 | Acc: 2.626,2.402,2.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.951 | Acc: 2.628,2.404,2.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.948 | Acc: 2.647,2.380,2.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.948 | Acc: 2.676,2.393,2.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.946 | Acc: 2.680,2.392,2.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.943 | Acc: 2.701,2.412,2.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.941 | Acc: 2.709,2.394,2.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.940 | Acc: 2.701,2.385,2.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.738 | Acc: 4.688,2.344,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.887 | Acc: 2.790,2.381,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.895 | Acc: 2.782,2.439,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.889 | Acc: 2.638,2.216,2.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 12.869 | Acc: 2.344,0.781,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.884 | Acc: 2.827,2.567,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.896 | Acc: 2.839,2.439,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.907 | Acc: 2.549,2.305,2.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.908 | Acc: 2.585,2.334,2.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.940 | Acc: 2.498,2.375,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.976 | Acc: 2.441,2.350,2.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.003 | Acc: 2.360,2.316,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.020 | Acc: 2.373,2.300,2.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.033 | Acc: 2.404,2.296,2.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.042 | Acc: 2.464,2.313,2.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.045 | Acc: 2.496,2.344,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.053 | Acc: 2.538,2.334,2.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.059 | Acc: 2.547,2.317,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.058 | Acc: 2.600,2.338,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.056 | Acc: 2.598,2.375,2.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.056 | Acc: 2.629,2.390,2.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.053 | Acc: 2.658,2.438,2.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.051 | Acc: 2.675,2.424,2.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.050 | Acc: 2.670,2.418,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.788 | Acc: 3.906,1.562,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.029 | Acc: 2.865,2.827,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.042 | Acc: 3.106,2.572,2.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.047 | Acc: 3.010,2.510,2.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 13.069 | Acc: 1.562,1.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.986 | Acc: 2.902,2.567,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.978 | Acc: 3.068,2.496,2.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.973 | Acc: 2.818,2.395,2.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.962 | Acc: 2.778,2.459,2.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.965 | Acc: 2.692,2.460,2.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.965 | Acc: 2.686,2.421,2.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.966 | Acc: 2.721,2.493,2.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.966 | Acc: 2.703,2.514,2.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.967 | Acc: 2.663,2.568,2.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.968 | Acc: 2.620,2.561,2.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.968 | Acc: 2.637,2.524,2.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.962 | Acc: 2.697,2.541,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.961 | Acc: 2.673,2.523,2.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.958 | Acc: 2.708,2.516,2.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.956 | Acc: 2.705,2.515,2.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.956 | Acc: 2.740,2.529,2.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.953 | Acc: 2.754,2.538,2.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.952 | Acc: 2.755,2.552,2.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.951 | Acc: 2.756,2.559,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.843 | Acc: 3.906,0.781,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.005 | Acc: 2.641,2.493,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.006 | Acc: 2.572,2.420,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.001 | Acc: 2.369,2.293,2.344,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 12.927 | Acc: 3.125,2.344,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.926 | Acc: 2.604,2.269,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.932 | Acc: 2.687,2.649,2.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.927 | Acc: 2.728,2.613,2.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.927 | Acc: 2.894,2.546,2.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.916 | Acc: 2.792,2.421,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.902 | Acc: 2.905,2.525,2.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.902 | Acc: 2.887,2.493,2.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.898 | Acc: 2.887,2.533,2.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.894 | Acc: 2.875,2.538,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.891 | Acc: 2.865,2.550,2.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.888 | Acc: 2.839,2.528,2.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.882 | Acc: 2.872,2.577,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.879 | Acc: 2.850,2.547,2.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.877 | Acc: 2.841,2.577,2.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.874 | Acc: 2.863,2.614,2.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.871 | Acc: 2.884,2.646,2.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.869 | Acc: 2.878,2.637,2.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.868 | Acc: 2.863,2.612,2.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.868 | Acc: 2.840,2.610,2.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.850 | Acc: 4.688,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.903 | Acc: 2.976,3.088,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.920 | Acc: 3.144,2.725,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.916 | Acc: 2.830,2.651,2.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 12.753 | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.814 | Acc: 2.567,2.567,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.828 | Acc: 2.725,2.553,2.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.821 | Acc: 2.754,2.459,2.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.822 | Acc: 2.797,2.517,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.823 | Acc: 2.808,2.475,2.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.822 | Acc: 2.847,2.531,2.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.820 | Acc: 2.820,2.588,2.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.818 | Acc: 2.824,2.591,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.818 | Acc: 2.806,2.590,2.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.820 | Acc: 2.853,2.596,2.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.822 | Acc: 2.825,2.641,2.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.818 | Acc: 2.807,2.658,2.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.812 | Acc: 2.856,2.679,2.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.808 | Acc: 2.858,2.652,2.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.805 | Acc: 2.868,2.671,2.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.806 | Acc: 2.867,2.667,2.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.805 | Acc: 2.859,2.651,2.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.805 | Acc: 2.876,2.651,2.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.806 | Acc: 2.854,2.649,2.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.701 | Acc: 5.469,0.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.824 | Acc: 3.348,2.567,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.832 | Acc: 3.373,2.630,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.827 | Acc: 3.215,2.587,2.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 12.657 | Acc: 0.781,2.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.739 | Acc: 2.679,2.902,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.739 | Acc: 2.725,2.954,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.747 | Acc: 2.894,2.882,2.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.752 | Acc: 3.067,2.980,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.754 | Acc: 3.048,2.924,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.752 | Acc: 3.073,2.905,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.754 | Acc: 3.025,2.881,2.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.753 | Acc: 2.965,2.916,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.758 | Acc: 2.926,2.875,2.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.756 | Acc: 2.892,2.876,2.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.751 | Acc: 2.913,2.927,2.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.749 | Acc: 2.908,2.882,2.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.744 | Acc: 2.948,2.898,2.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.743 | Acc: 2.908,2.866,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.743 | Acc: 2.899,2.839,2.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.742 | Acc: 2.884,2.840,2.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.744 | Acc: 2.848,2.795,2.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.744 | Acc: 2.844,2.785,2.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.740 | Acc: 2.858,2.783,2.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.743 | Acc: 5.469,0.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.049 | Acc: 2.493,2.455,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.051 | Acc: 2.401,2.534,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.046 | Acc: 2.293,2.433,2.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 12.810 | Acc: 7.031,6.250,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.710 | Acc: 3.460,3.609,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.687 | Acc: 2.877,3.030,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.696 | Acc: 2.959,2.792,2.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.709 | Acc: 3.038,2.903,2.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.710 | Acc: 3.110,2.970,2.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.708 | Acc: 3.093,3.015,2.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.710 | Acc: 3.047,3.009,2.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.711 | Acc: 3.047,2.970,2.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.712 | Acc: 3.004,2.935,2.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.706 | Acc: 3.036,2.966,2.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.703 | Acc: 3.026,2.973,2.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.706 | Acc: 2.995,2.989,2.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.707 | Acc: 2.957,3.002,2.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.705 | Acc: 2.936,2.986,2.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.704 | Acc: 2.912,2.961,2.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.702 | Acc: 2.901,2.950,2.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.705 | Acc: 2.862,2.933,2.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.704 | Acc: 2.852,2.928,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.703 | Acc: 2.887,2.920,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.634 | Acc: 4.688,0.781,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.773 | Acc: 2.790,1.897,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.781 | Acc: 2.725,1.963,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.777 | Acc: 2.715,1.985,2.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 12.789 | Acc: 2.344,0.000,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.736 | Acc: 2.790,2.604,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.708 | Acc: 2.896,2.611,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.693 | Acc: 2.946,2.728,2.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.698 | Acc: 2.971,2.836,2.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.691 | Acc: 2.986,2.831,2.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.686 | Acc: 3.080,2.828,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.683 | Acc: 3.059,2.865,2.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.680 | Acc: 3.018,2.902,2.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.680 | Acc: 2.944,2.879,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.679 | Acc: 2.888,2.888,2.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.682 | Acc: 2.906,2.835,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.688 | Acc: 2.911,2.807,2.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.703 | Acc: 2.939,2.832,2.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.727 | Acc: 2.933,2.878,2.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.745 | Acc: 2.884,2.881,2.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.760 | Acc: 2.894,2.889,2.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.774 | Acc: 2.898,2.894,2.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.786 | Acc: 2.909,2.887,2.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.795 | Acc: 2.906,2.875,2.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 26.716 | Acc: 3.125,0.781,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 26.495 | Acc: 3.125,1.265,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 26.457 | Acc: 3.087,1.105,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 26.471 | Acc: 2.920,1.076,2.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 12.813 | Acc: 1.562,1.562,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.947 | Acc: 2.493,2.567,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.939 | Acc: 2.725,2.649,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.938 | Acc: 2.894,2.626,2.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.951 | Acc: 2.961,2.797,2.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.958 | Acc: 2.970,2.823,2.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.969 | Acc: 2.964,2.873,2.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.969 | Acc: 3.036,2.920,2.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.971 | Acc: 2.950,2.897,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.960 | Acc: 2.978,2.926,2.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.953 | Acc: 2.997,2.931,2.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.954 | Acc: 3.026,2.991,2.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.960 | Acc: 2.960,2.956,2.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.956 | Acc: 2.984,2.993,2.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.957 | Acc: 2.964,3.003,2.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.951 | Acc: 2.943,3.006,2.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.947 | Acc: 2.945,2.964,2.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.945 | Acc: 2.953,2.951,2.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.943 | Acc: 2.928,2.941,2.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.943 | Acc: 2.899,2.934,2.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.898 | Acc: 1.562,0.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.197 | Acc: 2.083,2.753,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.199 | Acc: 1.905,2.687,1.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.192 | Acc: 1.780,2.523,2.100,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 13.110 | Acc: 2.344,2.344,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.883 | Acc: 3.237,2.865,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.911 | Acc: 3.430,2.915,2.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.900 | Acc: 3.125,2.997,2.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.901 | Acc: 3.125,3.009,2.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.902 | Acc: 3.040,2.939,2.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.896 | Acc: 3.093,2.970,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.890 | Acc: 3.036,2.986,2.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.889 | Acc: 3.062,2.999,2.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.889 | Acc: 3.017,2.939,2.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.890 | Acc: 2.977,2.919,2.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.889 | Acc: 3.012,2.888,2.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.882 | Acc: 3.021,2.882,2.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.877 | Acc: 2.993,2.906,2.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.875 | Acc: 3.039,2.916,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.871 | Acc: 3.042,2.897,2.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.871 | Acc: 3.025,2.855,2.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.867 | Acc: 3.015,2.816,2.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.865 | Acc: 3.015,2.852,2.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.863 | Acc: 2.996,2.856,2.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.659 | Acc: 4.688,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.882 | Acc: 3.013,3.088,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.869 | Acc: 3.030,2.992,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.859 | Acc: 2.959,3.048,2.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 12.863 | Acc: 3.906,0.781,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.789 | Acc: 3.609,3.199,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.776 | Acc: 3.182,3.277,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.777 | Acc: 3.151,3.330,2.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.781 | Acc: 3.193,3.414,2.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.782 | Acc: 3.140,3.380,2.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.792 | Acc: 3.144,3.377,2.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.790 | Acc: 3.186,3.302,2.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.784 | Acc: 3.159,3.241,2.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.785 | Acc: 3.190,3.198,2.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.789 | Acc: 3.117,3.187,2.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.789 | Acc: 3.100,3.174,2.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.790 | Acc: 3.106,3.167,2.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.787 | Acc: 3.095,3.149,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.785 | Acc: 3.083,3.136,2.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.783 | Acc: 3.055,3.117,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.778 | Acc: 3.042,3.118,2.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.777 | Acc: 3.033,3.063,2.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.775 | Acc: 3.021,3.036,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.772 | Acc: 3.022,3.018,2.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.694 | Acc: 3.906,3.125,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.834 | Acc: 2.902,3.237,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.842 | Acc: 3.030,2.896,3.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.838 | Acc: 2.907,2.779,3.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 12.657 | Acc: 0.781,2.344,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.716 | Acc: 2.976,2.865,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.723 | Acc: 2.801,3.068,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.727 | Acc: 3.023,2.984,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.721 | Acc: 3.144,2.980,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.720 | Acc: 3.071,2.963,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.712 | Acc: 3.112,2.918,2.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.709 | Acc: 3.142,2.992,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.711 | Acc: 3.052,3.018,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.701 | Acc: 3.056,3.112,2.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.695 | Acc: 3.074,3.164,2.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.692 | Acc: 3.072,3.146,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.688 | Acc: 3.099,3.154,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.684 | Acc: 3.098,3.116,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.685 | Acc: 3.064,3.092,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.685 | Acc: 3.052,3.045,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.681 | Acc: 3.084,3.054,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.676 | Acc: 3.072,3.059,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.675 | Acc: 3.032,3.034,2.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.675 | Acc: 3.031,3.022,2.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.361 | Acc: 1.562,2.344,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.518 | Acc: 2.232,3.348,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.530 | Acc: 2.096,3.316,3.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.525 | Acc: 1.857,3.279,3.343,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 12.576 | Acc: 3.906,3.906,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.639 | Acc: 2.902,3.013,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.670 | Acc: 3.087,3.258,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.665 | Acc: 3.048,3.061,2.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.662 | Acc: 3.096,3.038,2.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.663 | Acc: 3.094,3.024,2.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.662 | Acc: 3.190,3.190,2.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.654 | Acc: 3.291,3.286,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.653 | Acc: 3.309,3.203,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.657 | Acc: 3.336,3.233,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.657 | Acc: 3.300,3.261,2.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.653 | Acc: 3.288,3.252,2.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.653 | Acc: 3.274,3.222,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.651 | Acc: 3.275,3.179,2.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.651 | Acc: 3.250,3.150,2.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.649 | Acc: 3.250,3.164,2.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.647 | Acc: 3.288,3.193,2.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.645 | Acc: 3.356,3.224,2.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.641 | Acc: 3.404,3.214,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.638 | Acc: 3.445,3.221,2.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.516 | Acc: 6.250,1.562,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.678 | Acc: 4.688,3.199,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.690 | Acc: 4.497,3.106,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.686 | Acc: 4.572,3.266,3.227,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 12.694 | Acc: 3.906,3.906,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.542 | Acc: 4.427,2.753,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.549 | Acc: 4.802,2.706,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.554 | Acc: 4.880,2.971,2.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.560 | Acc: 4.958,3.164,2.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.565 | Acc: 5.043,3.187,2.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.564 | Acc: 4.965,3.325,2.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.574 | Acc: 4.920,3.236,2.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.574 | Acc: 5.037,3.159,2.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.580 | Acc: 5.080,3.082,2.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.578 | Acc: 5.251,3.059,2.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.580 | Acc: 5.377,3.047,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.578 | Acc: 5.485,3.060,2.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.575 | Acc: 5.574,3.044,2.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.572 | Acc: 5.694,3.025,2.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.572 | Acc: 5.746,3.016,2.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.567 | Acc: 5.805,3.025,2.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.569 | Acc: 5.822,3.004,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.575 | Acc: 5.860,2.993,2.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.574 | Acc: 5.895,2.998,2.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.574 | Acc: 9.375,1.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.742 | Acc: 5.729,2.753,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.765 | Acc: 5.373,2.954,1.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.760 | Acc: 5.648,2.946,1.332,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 12.400 | Acc: 9.375,1.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.595 | Acc: 7.254,2.827,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.630 | Acc: 6.841,2.725,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.590 | Acc: 7.159,3.023,2.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.579 | Acc: 6.935,3.106,2.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.572 | Acc: 6.861,3.009,2.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.578 | Acc: 6.980,2.996,2.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.585 | Acc: 7.053,3.075,2.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.596 | Acc: 6.997,3.115,2.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.604 | Acc: 6.884,3.082,2.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.609 | Acc: 6.887,3.067,2.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.611 | Acc: 6.862,3.030,2.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.615 | Acc: 6.902,3.028,2.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.615 | Acc: 6.903,3.005,2.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.612 | Acc: 6.945,3.017,2.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.608 | Acc: 6.943,3.029,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.609 | Acc: 7.002,3.018,2.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.607 | Acc: 7.008,3.022,2.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.603 | Acc: 7.062,3.034,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.603 | Acc: 7.074,3.004,2.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.076 | Acc: 6.250,1.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.315 | Acc: 5.990,2.641,1.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.349 | Acc: 6.155,2.420,1.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.330 | Acc: 6.288,2.369,1.319,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 12.703 | Acc: 11.719,3.906,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.635 | Acc: 7.850,2.121,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.563 | Acc: 7.908,2.611,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.562 | Acc: 7.953,2.856,2.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.551 | Acc: 7.996,2.903,2.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.552 | Acc: 7.782,2.877,2.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.553 | Acc: 7.780,2.912,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.562 | Acc: 7.713,2.975,2.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.567 | Acc: 7.735,2.941,2.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.568 | Acc: 7.778,2.926,2.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.569 | Acc: 7.789,2.915,2.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.566 | Acc: 7.862,2.952,2.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.561 | Acc: 7.890,2.976,2.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.556 | Acc: 7.935,2.984,2.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.554 | Acc: 7.918,2.975,2.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.555 | Acc: 7.914,2.967,2.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.555 | Acc: 7.956,2.947,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.554 | Acc: 7.939,2.946,2.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.554 | Acc: 7.970,2.965,2.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.552 | Acc: 8.036,2.961,2.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.551 | Acc: 7.031,3.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.707 | Acc: 5.990,2.790,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.717 | Acc: 6.364,2.763,2.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.703 | Acc: 6.391,2.779,2.203,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 12.484 | Acc: 8.594,3.125,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.476 | Acc: 8.929,3.088,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.440 | Acc: 9.680,3.068,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.440 | Acc: 9.541,3.048,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.467 | Acc: 9.394,3.029,2.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.457 | Acc: 9.390,3.164,2.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.454 | Acc: 9.291,3.209,2.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.447 | Acc: 9.375,3.258,2.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.438 | Acc: 9.409,3.261,2.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.434 | Acc: 9.405,3.259,2.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.432 | Acc: 9.352,3.300,2.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.427 | Acc: 9.407,3.302,2.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.419 | Acc: 9.485,3.235,2.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.411 | Acc: 9.471,3.224,2.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.407 | Acc: 9.450,3.214,2.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.401 | Acc: 9.489,3.208,2.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.395 | Acc: 9.519,3.198,2.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.389 | Acc: 9.556,3.189,2.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.383 | Acc: 9.576,3.175,2.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.379 | Acc: 9.613,3.137,2.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.152 | Acc: 9.375,1.562,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.338 | Acc: 9.635,3.720,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.345 | Acc: 9.585,3.354,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.332 | Acc: 9.657,3.227,2.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 12.194 | Acc: 12.500,3.125,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.246 | Acc: 10.826,3.274,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.305 | Acc: 9.966,2.896,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.290 | Acc: 9.913,2.882,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.277 | Acc: 9.915,3.106,2.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.280 | Acc: 9.971,3.071,2.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.291 | Acc: 9.982,3.015,2.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.293 | Acc: 10.073,3.075,2.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.287 | Acc: 10.156,3.076,2.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.286 | Acc: 10.407,3.116,2.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.286 | Acc: 10.448,3.106,2.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.283 | Acc: 10.503,3.114,2.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.287 | Acc: 10.432,3.131,2.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.285 | Acc: 10.438,3.161,2.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.284 | Acc: 10.457,3.158,2.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.287 | Acc: 10.426,3.128,2.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.290 | Acc: 10.509,3.135,2.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.293 | Acc: 10.537,3.114,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.293 | Acc: 10.574,3.110,2.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.293 | Acc: 10.640,3.109,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.596 | Acc: 10.156,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.577 | Acc: 9.263,2.827,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.572 | Acc: 9.585,2.591,2.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.556 | Acc: 9.439,2.561,2.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 12.133 | Acc: 16.406,1.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.320 | Acc: 11.793,3.199,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.302 | Acc: 11.395,3.144,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.284 | Acc: 11.168,2.997,2.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.280 | Acc: 11.227,3.009,2.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.269 | Acc: 11.239,3.055,2.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.274 | Acc: 11.183,2.886,2.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.254 | Acc: 11.237,2.909,2.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.251 | Acc: 11.229,2.931,2.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.249 | Acc: 11.244,2.918,2.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.250 | Acc: 11.221,2.923,2.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.251 | Acc: 11.330,2.916,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.251 | Acc: 11.304,2.895,2.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.244 | Acc: 11.363,2.909,2.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.243 | Acc: 11.368,2.922,2.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.237 | Acc: 11.384,2.910,2.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.231 | Acc: 11.373,2.913,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.229 | Acc: 11.460,2.949,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.224 | Acc: 11.509,2.926,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.221 | Acc: 11.571,2.924,2.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.436 | Acc: 14.062,0.781,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.487 | Acc: 9.970,3.013,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.504 | Acc: 9.794,2.668,2.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.497 | Acc: 9.695,2.677,2.305,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 11.739 | Acc: 16.406,1.562,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.109 | Acc: 13.244,3.385,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.118 | Acc: 13.224,3.678,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.113 | Acc: 12.769,3.407,2.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.116 | Acc: 12.674,3.221,2.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.107 | Acc: 12.717,3.249,2.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.108 | Acc: 12.636,3.293,2.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.121 | Acc: 12.506,3.291,2.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.120 | Acc: 12.582,3.246,2.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.122 | Acc: 12.517,3.190,2.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.126 | Acc: 12.395,3.133,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.126 | Acc: 12.313,3.167,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.127 | Acc: 12.257,3.080,2.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.118 | Acc: 12.329,3.092,2.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.114 | Acc: 12.328,3.086,2.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.109 | Acc: 12.435,3.024,2.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.112 | Acc: 12.478,2.991,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.114 | Acc: 12.473,2.978,2.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.120 | Acc: 12.481,2.978,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.123 | Acc: 12.486,2.979,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.766 | Acc: 12.500,0.000,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.523 | Acc: 10.565,1.749,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.455 | Acc: 11.490,1.791,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.494 | Acc: 11.501,1.883,2.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 12.063 | Acc: 16.406,2.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.130 | Acc: 14.286,3.311,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.126 | Acc: 14.215,3.068,2.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.136 | Acc: 13.998,3.215,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.150 | Acc: 13.677,3.183,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.183 | Acc: 13.451,3.102,2.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.194 | Acc: 13.275,3.028,2.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.188 | Acc: 13.375,3.025,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.189 | Acc: 13.451,3.013,2.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.186 | Acc: 13.424,2.991,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.185 | Acc: 13.359,2.977,2.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.185 | Acc: 13.257,2.895,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.184 | Acc: 13.194,2.879,2.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.179 | Acc: 13.224,2.933,2.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.176 | Acc: 13.231,2.925,2.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.177 | Acc: 13.219,2.917,2.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.177 | Acc: 13.228,2.916,2.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.176 | Acc: 13.203,2.949,2.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.174 | Acc: 13.229,2.935,2.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.172 | Acc: 13.269,2.918,2.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.763 | Acc: 7.812,1.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.833 | Acc: 7.664,2.530,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.860 | Acc: 7.927,2.553,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.840 | Acc: 7.825,2.421,2.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 12.110 | Acc: 10.938,3.906,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.089 | Acc: 13.951,3.088,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.057 | Acc: 14.082,2.896,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.069 | Acc: 13.845,2.792,2.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.067 | Acc: 13.918,2.739,2.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.065 | Acc: 13.846,2.761,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.066 | Acc: 13.811,2.751,2.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.062 | Acc: 13.913,2.665,2.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.056 | Acc: 14.024,2.703,2.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.059 | Acc: 13.959,2.728,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.055 | Acc: 13.965,2.740,2.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.053 | Acc: 13.981,2.796,2.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.054 | Acc: 13.907,2.814,2.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.049 | Acc: 13.940,2.841,2.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.051 | Acc: 13.987,2.794,2.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.049 | Acc: 14.011,2.756,2.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.051 | Acc: 13.975,2.757,2.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.049 | Acc: 14.024,2.731,2.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.045 | Acc: 14.026,2.731,2.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.044 | Acc: 14.001,2.723,2.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.976 | Acc: 13.281,2.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.967 | Acc: 11.979,2.493,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.974 | Acc: 11.909,2.306,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.961 | Acc: 11.898,2.331,2.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 11.568 | Acc: 21.094,3.125,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.930 | Acc: 14.062,2.455,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.971 | Acc: 13.929,2.477,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.971 | Acc: 14.255,2.626,2.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.972 | Acc: 14.390,2.749,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.982 | Acc: 14.318,2.638,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.994 | Acc: 14.256,2.699,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.994 | Acc: 14.434,2.643,2.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.007 | Acc: 14.441,2.654,2.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.003 | Acc: 14.572,2.676,2.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.002 | Acc: 14.603,2.705,2.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.999 | Acc: 14.681,2.708,2.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.995 | Acc: 14.604,2.720,2.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.992 | Acc: 14.649,2.733,2.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.992 | Acc: 14.638,2.772,2.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.985 | Acc: 14.667,2.814,2.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.980 | Acc: 14.785,2.826,2.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.976 | Acc: 14.841,2.820,2.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.970 | Acc: 14.868,2.818,2.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.969 | Acc: 14.918,2.830,2.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.942 | Acc: 10.938,3.125,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.138 | Acc: 10.603,3.385,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.150 | Acc: 10.575,3.373,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.137 | Acc: 10.925,3.291,2.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 11.804 | Acc: 15.625,3.906,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.929 | Acc: 14.546,2.827,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.889 | Acc: 15.168,2.858,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.887 | Acc: 15.241,2.792,2.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.875 | Acc: 15.442,2.951,2.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.868 | Acc: 15.555,2.924,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.870 | Acc: 15.728,2.880,2.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.875 | Acc: 15.525,2.848,2.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.883 | Acc: 15.431,2.868,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.884 | Acc: 15.383,2.991,2.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.885 | Acc: 15.388,2.942,2.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.885 | Acc: 15.279,2.934,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.884 | Acc: 15.349,2.921,2.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.881 | Acc: 15.442,2.912,2.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.878 | Acc: 15.517,2.950,2.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.875 | Acc: 15.563,2.974,2.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.874 | Acc: 15.571,2.945,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.878 | Acc: 15.510,2.919,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.877 | Acc: 15.590,2.902,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.875 | Acc: 15.561,2.871,2.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.714 | Acc: 8.594,1.562,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.971 | Acc: 7.589,1.935,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.948 | Acc: 7.717,1.982,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.929 | Acc: 7.633,1.908,2.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 11.746 | Acc: 16.406,2.344,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.782 | Acc: 15.811,2.902,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.795 | Acc: 15.968,2.992,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.802 | Acc: 16.522,3.061,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.825 | Acc: 16.300,3.173,3.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.841 | Acc: 16.445,3.218,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.866 | Acc: 16.303,3.196,2.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.874 | Acc: 16.284,3.197,2.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.886 | Acc: 16.329,3.309,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.893 | Acc: 16.285,3.362,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.904 | Acc: 16.329,3.432,2.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.917 | Acc: 16.339,3.390,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.921 | Acc: 16.280,3.401,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.924 | Acc: 16.272,3.418,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.921 | Acc: 16.201,3.556,2.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.903 | Acc: 16.077,3.893,2.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.873 | Acc: 16.134,4.335,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.845 | Acc: 16.113,4.754,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.815 | Acc: 16.140,5.164,2.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.794 | Acc: 16.031,5.483,2.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.723 | Acc: 14.062,8.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.862 | Acc: 11.682,9.710,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.853 | Acc: 11.909,9.566,2.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.848 | Acc: 11.655,9.798,2.369,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 11.329 | Acc: 17.188,15.625,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.242 | Acc: 16.369,13.058,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.232 | Acc: 15.930,13.396,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.242 | Acc: 16.355,13.870,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.228 | Acc: 16.696,14.130,2.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.221 | Acc: 16.507,14.271,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.237 | Acc: 16.019,14.269,2.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.231 | Acc: 16.068,14.439,2.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.218 | Acc: 16.071,14.664,2.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.204 | Acc: 16.048,14.969,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.184 | Acc: 16.181,15.333,2.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.171 | Acc: 16.198,15.508,2.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.168 | Acc: 16.105,15.456,2.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.149 | Acc: 16.152,15.712,2.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.136 | Acc: 16.134,15.961,2.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.126 | Acc: 16.069,16.066,2.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.117 | Acc: 16.085,16.209,2.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.105 | Acc: 16.136,16.365,2.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.093 | Acc: 16.099,16.527,2.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.083 | Acc: 16.097,16.646,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.944 | Acc: 2.344,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.984 | Acc: 3.981,7.143,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.986 | Acc: 4.230,7.107,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.999 | Acc: 4.316,7.236,2.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 10.869 | Acc: 13.281,18.750,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.896 | Acc: 14.844,19.345,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.913 | Acc: 15.301,19.207,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.936 | Acc: 15.113,19.057,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.915 | Acc: 15.152,19.271,2.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.884 | Acc: 15.439,19.694,2.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.848 | Acc: 15.845,20.132,2.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.843 | Acc: 15.691,20.157,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.829 | Acc: 15.800,20.293,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.811 | Acc: 16.048,20.584,2.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.807 | Acc: 16.049,20.468,2.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.805 | Acc: 16.081,20.553,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.798 | Acc: 16.186,20.562,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.789 | Acc: 16.236,20.699,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.777 | Acc: 16.228,20.788,2.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.773 | Acc: 16.206,20.847,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.772 | Acc: 16.204,20.870,2.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.765 | Acc: 16.207,20.961,2.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.761 | Acc: 16.211,21.042,2.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.754 | Acc: 16.244,21.112,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.487 | Acc: 3.906,9.375,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.573 | Acc: 4.874,8.222,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.581 | Acc: 4.707,8.270,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.580 | Acc: 4.777,8.402,3.138,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 10.482 | Acc: 20.312,30.469,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.647 | Acc: 16.927,23.400,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.566 | Acc: 17.397,24.181,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.610 | Acc: 17.021,23.348,2.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.611 | Acc: 17.168,23.196,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.599 | Acc: 16.901,23.113,2.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.580 | Acc: 16.910,23.263,2.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.565 | Acc: 16.933,23.510,2.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.543 | Acc: 16.979,23.471,2.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.527 | Acc: 17.028,23.554,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.522 | Acc: 17.013,23.620,2.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.518 | Acc: 17.025,23.664,2.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.508 | Acc: 17.029,23.817,2.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.503 | Acc: 17.110,23.854,2.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.501 | Acc: 17.112,23.804,2.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.494 | Acc: 17.162,23.912,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.495 | Acc: 17.134,23.888,2.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.494 | Acc: 17.048,23.919,2.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.491 | Acc: 17.062,23.944,2.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.487 | Acc: 17.060,24.030,2.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.375 | Acc: 6.250,17.969,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.535 | Acc: 8.929,16.704,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.552 | Acc: 8.784,16.425,2.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.549 | Acc: 8.709,15.830,2.395,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 10.767 | Acc: 18.750,28.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.392 | Acc: 17.076,26.786,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.336 | Acc: 17.816,26.658,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.359 | Acc: 17.687,25.820,2.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.341 | Acc: 17.882,26.051,2.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.330 | Acc: 17.984,26.199,2.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.325 | Acc: 17.943,26.362,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.336 | Acc: 17.924,26.152,2.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.319 | Acc: 17.935,26.271,2.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.311 | Acc: 17.951,26.502,2.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.316 | Acc: 17.965,26.504,2.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.301 | Acc: 18.078,26.718,2.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.299 | Acc: 18.034,26.611,2.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.304 | Acc: 17.939,26.589,2.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.302 | Acc: 17.883,26.571,2.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.301 | Acc: 17.818,26.581,2.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.296 | Acc: 17.820,26.650,2.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.286 | Acc: 17.852,26.803,2.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.283 | Acc: 17.780,26.814,2.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.276 | Acc: 17.784,26.909,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.932 | Acc: 9.375,23.438,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.152 | Acc: 11.347,19.308,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.204 | Acc: 11.147,19.855,2.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.221 | Acc: 11.040,19.762,2.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 10.326 | Acc: 13.281,22.656,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.118 | Acc: 17.374,29.167,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.112 | Acc: 17.321,29.478,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.123 | Acc: 17.546,28.957,2.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.100 | Acc: 18.162,29.263,2.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.097 | Acc: 18.394,29.479,2.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.087 | Acc: 18.453,29.423,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.101 | Acc: 18.301,29.350,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.093 | Acc: 18.347,29.367,2.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.087 | Acc: 18.344,29.476,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.092 | Acc: 18.287,29.474,2.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.095 | Acc: 18.283,29.373,2.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.097 | Acc: 18.254,29.328,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.096 | Acc: 18.145,29.358,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.089 | Acc: 18.158,29.493,2.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.087 | Acc: 18.223,29.563,2.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.088 | Acc: 18.273,29.571,2.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.083 | Acc: 18.326,29.584,2.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.082 | Acc: 18.278,29.610,2.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.083 | Acc: 18.289,29.700,2.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.091 | Acc: 12.500,21.094,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.527 | Acc: 10.751,21.726,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.556 | Acc: 10.938,22.142,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.595 | Acc: 10.809,21.414,2.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 10.069 | Acc: 14.844,30.469,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.931 | Acc: 19.048,31.473,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.947 | Acc: 19.531,31.612,2.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.939 | Acc: 19.557,31.916,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.958 | Acc: 19.271,31.838,2.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.962 | Acc: 19.206,31.869,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.969 | Acc: 18.995,31.909,2.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.984 | Acc: 18.678,31.727,2.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.988 | Acc: 18.624,31.575,2.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.975 | Acc: 18.703,31.548,2.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.968 | Acc: 18.715,31.643,2.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.965 | Acc: 18.711,31.611,2.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.963 | Acc: 18.685,31.590,2.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.955 | Acc: 18.678,31.633,2.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.955 | Acc: 18.603,31.628,2.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.954 | Acc: 18.597,31.624,2.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.955 | Acc: 18.619,31.552,2.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.952 | Acc: 18.585,31.621,2.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.952 | Acc: 18.553,31.640,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.951 | Acc: 18.568,31.711,2.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.155 | Acc: 18.750,32.812,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.687 | Acc: 11.905,25.149,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.710 | Acc: 11.909,24.790,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.711 | Acc: 11.719,24.808,2.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 10.184 | Acc: 20.312,26.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.855 | Acc: 18.043,32.664,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.820 | Acc: 18.731,33.194,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.799 | Acc: 18.942,33.158,2.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.802 | Acc: 19.416,33.150,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.805 | Acc: 19.353,33.021,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.798 | Acc: 19.312,33.368,2.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.796 | Acc: 19.210,33.378,2.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.789 | Acc: 19.323,33.434,2.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.792 | Acc: 19.302,33.503,2.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.802 | Acc: 19.360,33.543,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.812 | Acc: 19.457,33.573,2.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.825 | Acc: 19.437,33.493,2.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.834 | Acc: 19.468,33.450,2.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.839 | Acc: 19.526,33.421,2.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.846 | Acc: 19.555,33.428,2.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.852 | Acc: 19.444,33.445,2.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.853 | Acc: 19.408,33.397,2.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.854 | Acc: 19.393,33.440,2.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.855 | Acc: 19.330,33.475,2.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.756 | Acc: 8.594,25.000,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.994 | Acc: 11.533,25.707,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.953 | Acc: 11.623,25.171,2.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.966 | Acc: 11.616,24.193,2.139,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 9.630 | Acc: 17.969,35.156,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.858 | Acc: 19.382,35.156,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.853 | Acc: 19.322,35.080,2.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.853 | Acc: 19.301,34.631,2.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.819 | Acc: 19.792,34.963,2.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.813 | Acc: 19.756,34.592,2.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.794 | Acc: 20.177,34.859,2.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.780 | Acc: 20.202,34.990,2.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.780 | Acc: 20.298,35.049,2.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.772 | Acc: 20.274,35.087,2.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.759 | Acc: 20.351,35.207,2.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.766 | Acc: 20.270,35.015,2.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.772 | Acc: 20.193,34.855,2.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.772 | Acc: 20.348,34.791,2.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.770 | Acc: 20.407,34.850,2.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.764 | Acc: 20.416,34.930,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.764 | Acc: 20.390,34.937,2.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.761 | Acc: 20.450,34.929,2.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.757 | Acc: 20.455,34.981,2.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.752 | Acc: 20.468,35.087,2.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.744 | Acc: 20.312,33.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.934 | Acc: 14.025,26.525,1.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.940 | Acc: 14.043,26.658,1.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.964 | Acc: 14.011,26.921,1.358,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 9.283 | Acc: 25.781,43.750,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.672 | Acc: 20.387,35.379,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.696 | Acc: 20.370,35.785,2.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.714 | Acc: 20.018,36.168,2.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.698 | Acc: 20.187,36.362,2.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.691 | Acc: 20.529,36.402,2.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.692 | Acc: 20.422,36.596,2.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.704 | Acc: 20.412,36.386,2.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.709 | Acc: 20.531,36.335,2.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.701 | Acc: 20.679,36.460,2.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.688 | Acc: 20.728,36.517,2.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.689 | Acc: 20.655,36.538,2.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.681 | Acc: 20.831,36.566,2.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.681 | Acc: 20.920,36.545,2.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.676 | Acc: 21.016,36.527,2.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.681 | Acc: 20.974,36.470,2.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.674 | Acc: 21.094,36.490,2.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.665 | Acc: 21.085,36.577,2.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.661 | Acc: 21.126,36.572,2.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.661 | Acc: 21.137,36.547,2.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.105 | Acc: 11.719,30.469,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.621 | Acc: 9.598,23.438,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.657 | Acc: 9.394,23.304,1.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.669 | Acc: 9.401,23.181,1.268,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 9.521 | Acc: 25.781,32.812,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.548 | Acc: 22.731,37.240,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.582 | Acc: 21.799,36.966,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.586 | Acc: 22.208,36.706,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.586 | Acc: 22.106,36.738,2.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.592 | Acc: 21.875,36.634,2.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.648 | Acc: 21.907,36.874,2.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.730 | Acc: 21.809,36.591,2.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.764 | Acc: 21.982,36.534,2.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.788 | Acc: 21.996,36.369,2.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.798 | Acc: 22.089,36.451,2.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.817 | Acc: 22.112,36.394,2.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.816 | Acc: 22.212,36.579,2.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.822 | Acc: 22.186,36.539,2.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.828 | Acc: 22.186,36.583,2.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.831 | Acc: 22.228,36.545,2.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.828 | Acc: 22.279,36.522,2.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.826 | Acc: 22.349,36.579,2.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.812 | Acc: 22.529,36.769,2.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.809 | Acc: 22.611,36.752,2.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.979 | Acc: 14.062,29.688,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.034 | Acc: 14.100,27.009,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.094 | Acc: 13.910,26.372,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.130 | Acc: 13.589,26.447,2.331,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 9.484 | Acc: 27.344,42.969,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.649 | Acc: 23.289,38.095,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.621 | Acc: 23.971,38.224,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.631 | Acc: 24.180,37.999,2.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.626 | Acc: 24.228,38.349,2.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.629 | Acc: 24.149,38.227,2.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.628 | Acc: 24.225,38.372,2.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.624 | Acc: 24.379,38.420,2.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.630 | Acc: 24.277,38.369,2.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.620 | Acc: 24.370,38.432,2.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.622 | Acc: 24.433,38.390,2.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.607 | Acc: 24.449,38.557,2.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.597 | Acc: 24.543,38.654,2.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.590 | Acc: 24.590,38.658,2.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.585 | Acc: 24.694,38.709,2.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.580 | Acc: 24.759,38.844,2.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.578 | Acc: 24.808,38.824,2.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.575 | Acc: 24.762,38.772,2.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.573 | Acc: 24.773,38.751,2.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.573 | Acc: 24.756,38.759,2.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.002 | Acc: 18.750,40.625,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.045 | Acc: 19.978,34.115,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.061 | Acc: 20.103,34.413,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.098 | Acc: 20.172,34.503,2.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 9.343 | Acc: 30.469,40.625,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.346 | Acc: 26.749,41.443,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.387 | Acc: 26.658,40.511,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.342 | Acc: 27.113,41.803,2.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.375 | Acc: 26.775,41.088,2.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.384 | Acc: 26.485,41.019,2.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.402 | Acc: 26.362,40.819,2.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.397 | Acc: 26.363,40.847,2.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.403 | Acc: 26.271,40.800,2.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.415 | Acc: 26.096,40.599,2.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.410 | Acc: 26.217,40.466,2.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.408 | Acc: 26.273,40.484,2.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.409 | Acc: 26.196,40.285,2.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.406 | Acc: 26.158,40.224,2.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.395 | Acc: 26.265,40.255,2.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.392 | Acc: 26.352,40.350,2.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.397 | Acc: 26.239,40.202,2.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.391 | Acc: 26.349,40.245,2.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.387 | Acc: 26.443,40.294,2.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.380 | Acc: 26.562,40.344,2.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.502 | Acc: 15.625,24.219,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.112 | Acc: 15.030,28.311,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.116 | Acc: 14.024,28.277,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.175 | Acc: 13.691,28.023,2.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 9.754 | Acc: 17.969,35.156,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.267 | Acc: 27.046,42.076,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.219 | Acc: 27.515,42.283,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.221 | Acc: 27.754,42.059,2.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.213 | Acc: 27.836,42.110,2.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.229 | Acc: 27.986,41.623,2.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.239 | Acc: 27.886,41.445,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.227 | Acc: 27.981,41.412,2.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.228 | Acc: 27.979,41.450,2.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.232 | Acc: 27.888,41.436,2.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.238 | Acc: 27.907,41.398,2.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.240 | Acc: 27.902,41.343,2.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.245 | Acc: 27.717,41.358,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.248 | Acc: 27.739,41.385,2.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.254 | Acc: 27.697,41.362,2.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.257 | Acc: 27.715,41.256,2.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.247 | Acc: 27.762,41.326,2.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.243 | Acc: 27.797,41.321,2.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.236 | Acc: 27.807,41.354,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.233 | Acc: 27.803,41.369,2.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.834 | Acc: 26.562,42.969,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.136 | Acc: 19.345,35.565,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.155 | Acc: 19.398,34.737,2.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.169 | Acc: 19.045,34.388,2.677,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 9.637 | Acc: 26.562,37.500,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.225 | Acc: 28.237,41.592,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.208 | Acc: 27.420,41.711,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.185 | Acc: 27.510,41.855,2.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.173 | Acc: 27.884,41.840,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.168 | Acc: 27.761,41.878,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.143 | Acc: 28.067,42.362,2.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.142 | Acc: 28.286,42.254,2.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.145 | Acc: 28.309,42.163,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.132 | Acc: 28.630,42.459,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.133 | Acc: 28.665,42.467,2.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.138 | Acc: 28.514,42.325,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.133 | Acc: 28.605,42.418,2.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.130 | Acc: 28.595,42.541,2.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.130 | Acc: 28.628,42.566,2.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.124 | Acc: 28.654,42.572,2.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.124 | Acc: 28.639,42.594,2.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.129 | Acc: 28.652,42.524,2.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.129 | Acc: 28.642,42.540,2.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.131 | Acc: 28.623,42.514,2.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.179 | Acc: 14.844,27.344,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.087 | Acc: 15.551,27.381,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.140 | Acc: 15.682,26.448,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.183 | Acc: 14.985,26.627,3.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 9.083 | Acc: 32.031,39.062,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.041 | Acc: 30.097,44.085,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.025 | Acc: 30.297,44.398,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.968 | Acc: 30.289,45.133,2.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.001 | Acc: 29.716,44.348,2.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.996 | Acc: 29.796,44.446,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.000 | Acc: 29.720,44.273,2.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.991 | Acc: 29.915,44.337,2.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.990 | Acc: 29.877,44.332,2.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.987 | Acc: 29.938,44.151,2.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.991 | Acc: 30.014,43.968,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.999 | Acc: 29.885,43.775,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.011 | Acc: 29.668,43.675,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.010 | Acc: 29.598,43.624,2.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.012 | Acc: 29.532,43.561,2.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.016 | Acc: 29.560,43.535,2.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.018 | Acc: 29.629,43.526,2.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.025 | Acc: 29.587,43.491,2.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.032 | Acc: 29.530,43.482,2.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.033 | Acc: 29.575,43.475,2.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.045 | Acc: 26.562,32.031,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.221 | Acc: 20.759,32.031,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.223 | Acc: 20.522,32.641,3.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.242 | Acc: 20.274,32.825,3.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 9.114 | Acc: 29.688,46.875,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.036 | Acc: 30.655,45.871,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.989 | Acc: 30.907,45.617,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.966 | Acc: 30.699,45.428,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.018 | Acc: 30.372,44.637,2.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.996 | Acc: 30.523,44.810,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.005 | Acc: 30.520,44.796,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.021 | Acc: 30.280,44.564,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.021 | Acc: 30.265,44.653,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.032 | Acc: 30.266,44.626,2.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.037 | Acc: 30.325,44.555,2.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.041 | Acc: 30.158,44.443,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.043 | Acc: 30.080,44.402,2.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.051 | Acc: 30.065,44.136,2.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.049 | Acc: 30.118,44.039,2.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.050 | Acc: 30.121,44.015,2.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.041 | Acc: 30.345,44.193,2.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.034 | Acc: 30.334,44.206,2.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.034 | Acc: 30.343,44.168,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.035 | Acc: 30.352,44.170,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.422 | Acc: 27.344,30.469,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.671 | Acc: 18.192,31.994,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.697 | Acc: 18.255,32.050,2.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.733 | Acc: 17.905,31.442,2.024,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 9.357 | Acc: 29.688,35.156,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.893 | Acc: 30.952,44.531,3.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.925 | Acc: 31.421,45.008,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.948 | Acc: 31.135,44.890,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.980 | Acc: 30.855,44.560,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.991 | Acc: 30.554,44.493,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.994 | Acc: 30.585,44.396,2.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.003 | Acc: 30.541,44.210,2.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.999 | Acc: 30.585,44.298,2.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.000 | Acc: 30.685,44.363,2.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.996 | Acc: 30.799,44.255,2.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.008 | Acc: 30.699,44.082,2.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.004 | Acc: 30.751,44.110,2.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.997 | Acc: 30.789,44.190,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.991 | Acc: 30.819,44.125,2.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.990 | Acc: 30.788,44.041,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.985 | Acc: 30.856,44.135,2.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.980 | Acc: 30.957,44.282,2.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.980 | Acc: 30.949,44.287,2.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.981 | Acc: 30.850,44.289,2.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.977 | Acc: 23.438,42.969,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.375 | Acc: 19.308,33.705,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.355 | Acc: 18.998,33.803,2.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.364 | Acc: 18.801,33.709,2.203,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 8.748 | Acc: 29.688,40.625,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.976 | Acc: 29.836,44.457,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.951 | Acc: 30.164,45.370,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.922 | Acc: 30.815,45.517,2.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.919 | Acc: 30.797,45.245,2.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.908 | Acc: 30.956,45.452,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.895 | Acc: 31.263,45.616,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.879 | Acc: 31.538,45.529,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.889 | Acc: 31.473,45.327,2.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.879 | Acc: 31.513,45.425,2.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.887 | Acc: 31.363,45.281,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.882 | Acc: 31.360,45.281,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.881 | Acc: 31.347,45.270,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.883 | Acc: 31.352,45.187,2.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.878 | Acc: 31.378,45.260,2.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.886 | Acc: 31.250,45.159,2.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.889 | Acc: 31.296,45.108,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.886 | Acc: 31.353,45.193,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.886 | Acc: 31.326,45.172,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.888 | Acc: 31.279,45.189,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.243 | Acc: 26.562,38.281,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.714 | Acc: 17.857,31.287,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.770 | Acc: 17.797,30.069,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.771 | Acc: 17.623,30.059,3.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 8.713 | Acc: 26.562,53.906,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.829 | Acc: 30.952,46.949,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.856 | Acc: 30.774,46.303,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.817 | Acc: 31.442,46.632,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.814 | Acc: 31.887,46.267,2.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.814 | Acc: 31.614,46.264,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.827 | Acc: 31.624,45.965,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.819 | Acc: 31.455,46.038,2.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.828 | Acc: 31.444,45.783,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.830 | Acc: 31.457,45.748,2.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.824 | Acc: 31.549,45.759,2.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.822 | Acc: 31.678,45.715,2.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.831 | Acc: 31.736,45.721,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.840 | Acc: 31.675,45.651,2.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.840 | Acc: 31.789,45.707,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.846 | Acc: 31.792,45.634,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.844 | Acc: 31.885,45.707,2.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.841 | Acc: 31.924,45.784,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.842 | Acc: 31.960,45.732,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.838 | Acc: 31.970,45.813,2.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.675 | Acc: 25.000,44.531,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.730 | Acc: 23.772,38.542,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.797 | Acc: 22.752,37.405,2.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.819 | Acc: 22.336,37.628,2.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 8.889 | Acc: 32.031,46.094,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.697 | Acc: 33.147,47.991,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.698 | Acc: 32.927,48.495,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.735 | Acc: 32.774,47.554,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.739 | Acc: 32.735,47.222,2.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.728 | Acc: 32.704,47.130,2.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.734 | Acc: 32.871,47.011,2.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.736 | Acc: 32.818,46.864,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.740 | Acc: 32.953,46.642,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.743 | Acc: 32.817,46.612,2.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.741 | Acc: 32.805,46.653,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.743 | Acc: 32.770,46.635,3.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.752 | Acc: 32.647,46.447,2.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.757 | Acc: 32.663,46.357,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.758 | Acc: 32.662,46.394,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.758 | Acc: 32.675,46.364,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.759 | Acc: 32.671,46.330,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.764 | Acc: 32.615,46.243,2.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.758 | Acc: 32.642,46.340,2.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.753 | Acc: 32.716,46.424,2.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.379 | Acc: 17.969,34.375,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.384 | Acc: 19.234,32.887,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.450 | Acc: 18.693,32.050,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.497 | Acc: 18.443,31.878,2.677,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 8.506 | Acc: 41.406,51.562,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.685 | Acc: 33.482,48.065,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.704 | Acc: 32.946,47.999,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.698 | Acc: 33.350,47.900,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.669 | Acc: 33.574,47.994,2.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.689 | Acc: 33.555,47.602,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.696 | Acc: 33.445,47.450,2.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.693 | Acc: 33.605,47.473,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.691 | Acc: 33.608,47.351,2.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.688 | Acc: 33.658,47.341,2.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.691 | Acc: 33.625,47.361,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.692 | Acc: 33.594,47.236,2.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.708 | Acc: 33.490,47.037,2.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.710 | Acc: 33.387,46.977,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.706 | Acc: 33.407,46.986,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.701 | Acc: 33.438,47.018,2.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.694 | Acc: 33.501,47.109,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.691 | Acc: 33.523,47.129,2.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.690 | Acc: 33.522,47.150,2.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.697 | Acc: 33.471,47.051,2.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.242 | Acc: 13.281,28.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.971 | Acc: 15.588,29.464,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.969 | Acc: 15.187,29.916,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.946 | Acc: 15.087,30.085,2.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 8.459 | Acc: 33.594,53.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.636 | Acc: 34.263,47.768,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.615 | Acc: 33.289,47.561,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.608 | Acc: 33.389,47.618,3.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.584 | Acc: 33.825,47.917,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.587 | Acc: 33.826,48.058,3.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.598 | Acc: 33.846,48.140,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.598 | Acc: 33.716,48.288,3.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.612 | Acc: 33.754,48.127,3.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.616 | Acc: 33.745,47.971,3.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.614 | Acc: 33.808,47.963,3.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.619 | Acc: 33.869,47.865,3.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.624 | Acc: 33.707,47.763,3.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.626 | Acc: 33.699,47.827,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.631 | Acc: 33.685,47.695,3.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.634 | Acc: 33.627,47.594,3.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.635 | Acc: 33.606,47.576,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.634 | Acc: 33.676,47.553,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.627 | Acc: 33.700,47.604,3.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.627 | Acc: 33.745,47.605,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.287 | Acc: 25.000,46.094,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.494 | Acc: 25.335,39.137,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.503 | Acc: 25.514,39.005,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.517 | Acc: 25.346,38.717,3.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 8.582 | Acc: 32.812,46.094,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.436 | Acc: 36.161,50.632,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.478 | Acc: 35.328,50.152,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.482 | Acc: 35.207,49.705,3.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.504 | Acc: 34.635,49.026,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.535 | Acc: 34.429,48.747,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.533 | Acc: 34.595,48.773,2.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.522 | Acc: 34.635,48.897,2.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.527 | Acc: 34.574,48.651,3.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.536 | Acc: 34.440,48.597,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.539 | Acc: 34.426,48.581,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.543 | Acc: 34.350,48.621,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.552 | Acc: 34.307,48.438,2.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.555 | Acc: 34.318,48.372,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.558 | Acc: 34.294,48.307,2.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.559 | Acc: 34.308,48.230,2.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.570 | Acc: 34.270,48.085,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.575 | Acc: 34.244,47.924,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.582 | Acc: 34.198,47.849,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.581 | Acc: 34.231,47.935,2.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.656 | Acc: 27.344,40.625,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.843 | Acc: 21.726,37.872,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.890 | Acc: 21.799,36.585,3.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.921 | Acc: 21.350,36.219,3.548,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 8.161 | Acc: 36.719,53.125,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.446 | Acc: 36.719,49.219,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.463 | Acc: 35.918,49.143,3.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.460 | Acc: 35.579,49.565,3.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.473 | Acc: 35.272,49.064,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.513 | Acc: 35.141,48.731,3.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.519 | Acc: 35.079,48.554,3.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.491 | Acc: 35.406,48.947,3.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.506 | Acc: 35.263,48.816,3.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.514 | Acc: 35.139,48.688,3.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.526 | Acc: 35.121,48.624,3.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.530 | Acc: 34.987,48.639,3.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.533 | Acc: 34.874,48.528,3.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.542 | Acc: 34.746,48.426,3.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.544 | Acc: 34.745,48.471,3.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.539 | Acc: 34.819,48.500,3.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.547 | Acc: 34.684,48.416,3.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.539 | Acc: 34.817,48.550,3.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.538 | Acc: 34.834,48.604,3.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.538 | Acc: 34.783,48.571,3.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.382 | Acc: 25.000,46.875,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.930 | Acc: 21.466,38.988,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.997 | Acc: 20.884,38.262,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.008 | Acc: 20.581,37.884,2.894,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 8.744 | Acc: 34.375,45.312,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.491 | Acc: 33.780,48.400,3.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.462 | Acc: 34.604,49.848,3.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.472 | Acc: 34.721,49.539,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.486 | Acc: 34.857,49.306,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.480 | Acc: 34.955,49.250,3.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.485 | Acc: 34.911,49.270,3.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.473 | Acc: 35.023,49.413,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.480 | Acc: 34.826,49.204,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.489 | Acc: 34.785,49.124,3.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.483 | Acc: 34.884,49.188,2.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.481 | Acc: 34.888,49.205,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.492 | Acc: 34.806,48.985,2.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.495 | Acc: 34.809,48.961,2.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.498 | Acc: 34.859,48.893,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.500 | Acc: 34.821,48.892,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.506 | Acc: 34.762,48.793,2.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.506 | Acc: 34.778,48.749,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.506 | Acc: 34.760,48.686,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.511 | Acc: 34.740,48.643,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.125 | Acc: 21.875,39.844,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.099 | Acc: 18.750,37.946,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.173 | Acc: 19.131,36.585,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.209 | Acc: 18.865,36.206,3.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 8.993 | Acc: 28.125,41.406,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.519 | Acc: 33.668,48.363,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.484 | Acc: 35.137,48.533,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.475 | Acc: 35.143,48.911,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.446 | Acc: 35.600,49.450,3.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.437 | Acc: 35.582,49.528,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.448 | Acc: 35.376,49.438,3.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.477 | Acc: 35.234,49.468,2.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.524 | Acc: 35.219,49.301,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.542 | Acc: 35.273,49.378,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.562 | Acc: 35.312,49.324,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.585 | Acc: 35.170,49.166,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.607 | Acc: 35.020,49.128,2.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.626 | Acc: 35.099,49.036,2.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.635 | Acc: 35.240,48.988,2.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.653 | Acc: 35.221,48.881,2.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.661 | Acc: 35.217,48.934,2.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.666 | Acc: 35.216,48.850,2.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.668 | Acc: 35.230,48.901,2.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.676 | Acc: 35.199,48.823,2.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.892 | Acc: 26.562,40.625,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.206 | Acc: 24.033,37.277,1.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.252 | Acc: 24.676,36.757,1.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.236 | Acc: 24.616,37.193,1.767,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 8.330 | Acc: 39.062,53.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.726 | Acc: 34.077,48.996,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.695 | Acc: 35.347,49.428,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.665 | Acc: 36.078,49.936,2.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.681 | Acc: 35.523,49.653,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.694 | Acc: 35.435,49.691,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.716 | Acc: 35.143,49.180,2.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.702 | Acc: 34.957,49.097,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.699 | Acc: 34.865,49.044,2.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.697 | Acc: 34.880,48.899,2.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.686 | Acc: 35.063,48.916,2.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.686 | Acc: 35.071,48.833,2.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.681 | Acc: 35.095,48.927,2.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.673 | Acc: 35.228,48.988,2.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.660 | Acc: 35.265,49.099,2.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.656 | Acc: 35.265,49.032,2.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.651 | Acc: 35.278,49.104,2.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.649 | Acc: 35.179,49.109,2.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.650 | Acc: 35.117,49.143,2.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.652 | Acc: 35.074,49.069,2.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.368 | Acc: 22.656,38.281,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.492 | Acc: 19.903,35.231,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.489 | Acc: 19.722,34.889,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.513 | Acc: 19.442,34.862,2.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 8.330 | Acc: 37.500,53.906,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.486 | Acc: 36.272,50.632,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.502 | Acc: 36.147,50.553,2.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.529 | Acc: 35.950,49.846,2.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.530 | Acc: 35.899,50.000,2.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.522 | Acc: 35.729,50.023,2.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.516 | Acc: 35.957,50.213,2.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.510 | Acc: 35.888,50.211,2.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.510 | Acc: 35.899,50.121,2.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.521 | Acc: 35.946,49.948,2.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.526 | Acc: 35.996,49.732,2.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.528 | Acc: 36.086,49.795,2.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.538 | Acc: 35.986,49.708,2.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.542 | Acc: 35.902,49.668,2.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.549 | Acc: 35.854,49.550,2.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.546 | Acc: 35.862,49.605,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.550 | Acc: 35.847,49.603,2.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.554 | Acc: 35.791,49.505,2.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.560 | Acc: 35.723,49.429,2.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.563 | Acc: 35.749,49.418,2.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.428 | Acc: 22.656,35.938,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.728 | Acc: 21.057,33.408,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.754 | Acc: 20.312,32.508,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.742 | Acc: 20.505,32.441,2.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 8.402 | Acc: 35.156,50.000,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.378 | Acc: 38.021,52.046,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.383 | Acc: 37.614,51.905,3.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.428 | Acc: 36.770,50.999,3.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.453 | Acc: 36.478,50.453,3.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.457 | Acc: 36.363,50.526,3.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.479 | Acc: 36.267,50.433,3.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.500 | Acc: 36.076,50.222,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.497 | Acc: 35.942,50.175,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.493 | Acc: 35.881,50.142,2.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.485 | Acc: 35.988,50.175,2.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.493 | Acc: 36.019,49.947,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.499 | Acc: 35.915,49.932,2.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.494 | Acc: 35.991,49.940,2.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.497 | Acc: 35.932,49.925,2.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.496 | Acc: 35.867,50.070,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.505 | Acc: 35.789,49.973,2.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.505 | Acc: 35.837,50.005,2.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.506 | Acc: 35.780,50.048,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.506 | Acc: 35.712,49.988,2.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.152 | Acc: 30.469,43.750,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.674 | Acc: 22.917,36.868,1.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.773 | Acc: 22.980,35.556,2.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.809 | Acc: 22.643,35.835,1.998,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 8.474 | Acc: 31.250,44.531,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.428 | Acc: 35.565,49.144,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.426 | Acc: 35.461,50.229,3.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.384 | Acc: 36.322,51.140,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.414 | Acc: 35.986,50.685,3.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.442 | Acc: 36.046,50.441,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.425 | Acc: 36.583,50.549,3.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.440 | Acc: 36.580,50.421,3.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.444 | Acc: 36.607,50.398,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.444 | Acc: 36.481,50.371,3.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.439 | Acc: 36.524,50.311,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.434 | Acc: 36.450,50.336,3.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.429 | Acc: 36.560,50.282,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.430 | Acc: 36.500,50.269,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.432 | Acc: 36.530,50.225,2.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.426 | Acc: 36.573,50.228,2.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.426 | Acc: 36.529,50.243,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.425 | Acc: 36.535,50.250,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.432 | Acc: 36.442,50.151,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.428 | Acc: 36.438,50.242,2.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.574 | Acc: 25.000,45.312,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.992 | Acc: 22.731,40.811,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.021 | Acc: 22.294,39.672,2.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.008 | Acc: 22.490,39.293,2.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 8.265 | Acc: 37.500,54.688,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.324 | Acc: 35.491,52.604,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.329 | Acc: 36.395,51.810,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.341 | Acc: 36.373,51.627,2.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.332 | Acc: 36.863,51.466,2.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.327 | Acc: 36.819,51.663,2.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.325 | Acc: 36.719,51.653,2.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.327 | Acc: 36.752,51.540,2.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.346 | Acc: 36.811,51.519,2.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.343 | Acc: 36.827,51.554,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.345 | Acc: 36.738,51.543,2.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.356 | Acc: 36.652,51.389,2.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.358 | Acc: 36.563,51.306,2.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.358 | Acc: 36.686,51.341,2.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.355 | Acc: 36.669,51.390,2.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.350 | Acc: 36.714,51.407,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.348 | Acc: 36.763,51.356,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.347 | Acc: 36.822,51.340,2.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.355 | Acc: 36.691,51.190,2.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.359 | Acc: 36.647,51.124,2.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.375 | Acc: 34.375,38.281,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.777 | Acc: 25.632,38.653,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.796 | Acc: 25.438,38.034,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.800 | Acc: 25.243,37.756,2.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 9.280 | Acc: 26.562,49.219,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.240 | Acc: 37.351,53.237,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.270 | Acc: 36.528,52.706,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.277 | Acc: 36.847,52.369,3.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.278 | Acc: 36.979,52.267,2.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.295 | Acc: 36.966,51.779,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.292 | Acc: 37.209,51.885,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.306 | Acc: 36.990,51.812,2.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.316 | Acc: 36.874,51.616,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.326 | Acc: 36.732,51.424,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.321 | Acc: 36.785,51.562,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.320 | Acc: 36.867,51.672,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.327 | Acc: 36.660,51.562,2.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.330 | Acc: 36.596,51.548,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.334 | Acc: 36.535,51.496,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.335 | Acc: 36.612,51.461,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.334 | Acc: 36.636,51.421,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.335 | Acc: 36.572,51.425,2.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.343 | Acc: 36.470,51.283,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.340 | Acc: 36.481,51.333,2.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.150 | Acc: 27.344,39.844,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.232 | Acc: 21.987,36.644,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.338 | Acc: 21.913,35.918,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.386 | Acc: 21.414,35.233,2.894,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 8.301 | Acc: 35.938,50.000,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.238 | Acc: 38.579,51.525,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.244 | Acc: 37.252,51.410,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.260 | Acc: 37.244,51.473,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.270 | Acc: 37.114,51.485,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.295 | Acc: 36.719,51.385,3.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.307 | Acc: 36.564,51.408,3.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.303 | Acc: 36.625,51.579,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.291 | Acc: 36.913,51.664,3.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.293 | Acc: 37.086,51.752,3.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.296 | Acc: 36.987,51.644,3.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.296 | Acc: 36.888,51.534,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.292 | Acc: 36.978,51.579,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.290 | Acc: 36.916,51.560,3.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.300 | Acc: 36.827,51.476,3.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.303 | Acc: 36.760,51.420,3.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.297 | Acc: 36.838,51.485,3.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.296 | Acc: 36.836,51.466,3.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.299 | Acc: 36.836,51.448,3.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.300 | Acc: 36.840,51.423,3.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.377 | Acc: 31.250,41.406,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.886 | Acc: 26.116,37.277,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.870 | Acc: 26.029,36.700,3.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.844 | Acc: 26.319,36.949,3.458,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 8.753 | Acc: 30.469,46.875,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.228 | Acc: 37.574,51.935,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.261 | Acc: 37.138,51.543,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.258 | Acc: 36.936,51.742,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.269 | Acc: 36.979,51.601,2.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.268 | Acc: 37.121,51.617,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.279 | Acc: 36.874,51.595,2.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.282 | Acc: 37.107,51.701,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.290 | Acc: 36.976,51.592,2.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.291 | Acc: 36.866,51.485,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.286 | Acc: 36.843,51.504,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.277 | Acc: 36.959,51.644,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.268 | Acc: 37.130,51.783,2.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.270 | Acc: 37.102,51.778,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.267 | Acc: 37.091,51.746,2.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.269 | Acc: 37.074,51.718,2.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.273 | Acc: 37.055,51.709,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.276 | Acc: 37.094,51.668,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.280 | Acc: 37.065,51.612,2.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.284 | Acc: 36.998,51.546,2.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.199 | Acc: 28.125,37.500,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.888 | Acc: 26.265,37.165,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.989 | Acc: 25.629,35.899,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.987 | Acc: 25.448,36.002,2.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 8.208 | Acc: 41.406,56.250,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.201 | Acc: 37.128,53.423,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.280 | Acc: 37.005,51.791,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.314 | Acc: 36.885,51.575,2.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.334 | Acc: 36.709,51.591,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.334 | Acc: 36.564,51.624,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.319 | Acc: 36.635,51.711,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.318 | Acc: 36.525,51.779,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.316 | Acc: 36.641,51.713,2.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.327 | Acc: 36.464,51.532,2.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.322 | Acc: 36.482,51.562,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.319 | Acc: 36.528,51.573,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.313 | Acc: 36.686,51.644,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.310 | Acc: 36.701,51.625,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.314 | Acc: 36.713,51.526,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.319 | Acc: 36.771,51.529,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.322 | Acc: 36.787,51.541,3.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.324 | Acc: 36.794,51.501,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.319 | Acc: 36.892,51.560,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.318 | Acc: 36.903,51.591,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.490 | Acc: 16.406,43.750,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.726 | Acc: 14.249,36.644,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.834 | Acc: 14.158,36.052,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.881 | Acc: 13.665,35.758,3.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 8.178 | Acc: 35.156,50.781,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.255 | Acc: 37.612,52.121,3.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.223 | Acc: 38.167,52.744,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.218 | Acc: 38.204,53.099,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.267 | Acc: 37.568,52.353,2.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.281 | Acc: 37.724,52.266,2.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.286 | Acc: 37.958,52.331,2.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.297 | Acc: 37.844,52.205,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.302 | Acc: 37.820,52.232,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.306 | Acc: 37.690,52.042,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.310 | Acc: 37.589,51.986,3.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.316 | Acc: 37.518,51.881,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.315 | Acc: 37.591,51.919,3.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.324 | Acc: 37.425,51.811,3.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.330 | Acc: 37.253,51.738,3.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.333 | Acc: 37.165,51.744,3.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.333 | Acc: 37.171,51.743,3.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.337 | Acc: 37.122,51.695,3.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.334 | Acc: 37.121,51.764,3.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.341 | Acc: 37.090,51.686,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.833 | Acc: 25.000,39.844,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.364 | Acc: 19.866,37.165,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.333 | Acc: 20.122,36.414,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.384 | Acc: 19.685,36.219,2.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 8.246 | Acc: 35.938,50.000,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.258 | Acc: 36.012,51.860,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.215 | Acc: 37.424,52.363,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.209 | Acc: 37.641,52.651,3.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.217 | Acc: 37.770,52.662,2.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.235 | Acc: 37.724,52.537,2.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.242 | Acc: 37.752,52.583,3.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.257 | Acc: 37.827,52.172,3.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.260 | Acc: 37.845,52.261,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.268 | Acc: 37.785,52.206,3.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.276 | Acc: 37.683,52.177,3.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.280 | Acc: 37.603,52.107,3.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.274 | Acc: 37.604,52.217,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.272 | Acc: 37.671,52.257,3.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.274 | Acc: 37.572,52.277,3.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.280 | Acc: 37.435,52.180,3.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.290 | Acc: 37.393,52.083,3.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.288 | Acc: 37.342,52.133,3.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.278 | Acc: 37.498,52.227,3.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.279 | Acc: 37.625,52.264,3.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.658 | Acc: 28.125,41.406,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.497 | Acc: 26.302,41.481,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.613 | Acc: 25.629,40.511,3.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.621 | Acc: 25.576,40.830,3.458,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 8.011 | Acc: 40.625,64.844,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.206 | Acc: 39.286,54.278,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.205 | Acc: 38.510,54.230,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.243 | Acc: 38.217,52.856,3.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.249 | Acc: 37.924,52.826,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.238 | Acc: 38.142,52.994,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.245 | Acc: 38.036,52.770,3.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.247 | Acc: 37.855,52.754,3.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.241 | Acc: 37.917,52.683,3.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.241 | Acc: 37.888,52.633,3.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.247 | Acc: 37.776,52.651,3.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.259 | Acc: 37.634,52.453,3.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.259 | Acc: 37.555,52.350,3.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.252 | Acc: 37.635,52.434,3.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.262 | Acc: 37.558,52.313,3.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.267 | Acc: 37.516,52.250,3.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.269 | Acc: 37.607,52.205,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.269 | Acc: 37.654,52.220,3.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.274 | Acc: 37.615,52.160,3.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.273 | Acc: 37.682,52.184,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.657 | Acc: 25.000,39.062,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.664 | Acc: 22.693,39.472,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.672 | Acc: 22.999,38.643,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.695 | Acc: 23.117,38.243,2.882,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 8.086 | Acc: 39.844,53.125,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.251 | Acc: 37.872,52.902,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.196 | Acc: 38.319,53.601,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.215 | Acc: 38.230,53.189,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.214 | Acc: 38.484,52.913,2.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.228 | Acc: 38.335,52.777,3.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.231 | Acc: 38.449,52.951,3.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.242 | Acc: 38.242,52.876,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.243 | Acc: 38.170,52.829,3.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.243 | Acc: 38.173,52.844,3.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.241 | Acc: 38.157,52.907,3.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.247 | Acc: 38.122,52.665,3.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.247 | Acc: 37.993,52.606,3.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.255 | Acc: 37.886,52.550,3.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.252 | Acc: 37.992,52.650,3.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.256 | Acc: 37.972,52.499,3.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.259 | Acc: 37.943,52.419,3.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.261 | Acc: 37.933,52.422,3.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.261 | Acc: 37.941,52.355,3.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.266 | Acc: 37.914,52.284,3.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.364 | Acc: 33.594,50.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.857 | Acc: 26.153,41.443,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.895 | Acc: 25.686,41.273,2.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.922 | Acc: 25.615,40.651,2.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 8.334 | Acc: 32.812,52.344,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.249 | Acc: 38.876,54.539,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.230 | Acc: 38.129,54.135,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.245 | Acc: 38.294,53.650,2.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.249 | Acc: 38.503,53.472,2.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.281 | Acc: 38.366,52.761,2.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.277 | Acc: 38.081,52.841,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.268 | Acc: 38.375,52.870,2.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.270 | Acc: 38.291,52.878,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.273 | Acc: 38.264,52.892,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.279 | Acc: 38.211,52.857,2.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.287 | Acc: 38.143,52.825,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.289 | Acc: 38.022,52.814,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.289 | Acc: 38.123,52.808,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.291 | Acc: 38.101,52.783,2.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.291 | Acc: 38.048,52.756,2.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.295 | Acc: 38.023,52.670,2.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.293 | Acc: 38.064,52.756,2.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.298 | Acc: 37.974,52.673,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.299 | Acc: 37.974,52.662,2.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.429 | Acc: 30.469,42.969,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.489 | Acc: 27.641,41.406,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.530 | Acc: 27.077,40.835,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.553 | Acc: 26.473,40.318,2.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 8.190 | Acc: 40.625,51.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.141 | Acc: 39.769,54.353,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.194 | Acc: 39.005,53.754,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.236 | Acc: 38.589,53.035,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.229 | Acc: 38.561,53.376,2.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.231 | Acc: 38.482,53.287,2.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.248 | Acc: 38.191,53.002,2.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.259 | Acc: 38.126,52.754,2.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.253 | Acc: 38.155,52.800,2.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.250 | Acc: 38.100,52.939,2.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.245 | Acc: 38.250,52.919,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.248 | Acc: 38.380,52.892,2.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.249 | Acc: 38.366,52.768,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.261 | Acc: 38.156,52.625,2.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.264 | Acc: 38.114,52.658,2.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.261 | Acc: 38.196,52.749,2.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.265 | Acc: 38.169,52.687,2.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.264 | Acc: 38.139,52.610,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.267 | Acc: 38.112,52.560,2.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.269 | Acc: 38.097,52.596,2.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.443 | Acc: 30.469,51.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.514 | Acc: 22.433,43.378,3.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.587 | Acc: 22.694,43.121,3.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.615 | Acc: 22.118,43.455,3.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 8.310 | Acc: 40.625,53.906,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.136 | Acc: 39.174,53.423,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.148 | Acc: 39.139,53.620,3.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.152 | Acc: 39.075,53.829,3.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.151 | Acc: 39.236,54.147,3.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.165 | Acc: 38.869,53.937,3.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.173 | Acc: 38.991,53.654,3.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.195 | Acc: 38.536,53.441,3.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.201 | Acc: 38.339,53.460,3.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.207 | Acc: 38.398,53.466,3.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.208 | Acc: 38.305,53.370,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.203 | Acc: 38.430,53.323,3.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.210 | Acc: 38.447,53.258,3.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.215 | Acc: 38.323,53.349,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.228 | Acc: 38.187,53.258,3.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.226 | Acc: 38.146,53.218,3.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.225 | Acc: 38.179,53.159,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.222 | Acc: 38.213,53.187,3.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.222 | Acc: 38.167,53.157,3.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.228 | Acc: 38.107,53.090,3.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.904 | Acc: 25.000,53.125,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.100 | Acc: 26.897,45.796,3.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.155 | Acc: 27.020,45.351,3.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.149 | Acc: 27.075,45.543,3.509,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 8.020 | Acc: 32.031,53.125,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.125 | Acc: 39.025,54.762,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.146 | Acc: 39.082,54.002,3.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.149 | Acc: 39.152,53.868,3.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.157 | Acc: 38.927,53.598,3.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.151 | Acc: 38.962,53.837,3.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.157 | Acc: 38.837,53.700,3.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.161 | Acc: 38.819,53.657,3.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.179 | Acc: 38.684,53.494,3.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.190 | Acc: 38.480,53.509,3.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.207 | Acc: 38.340,53.475,3.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.205 | Acc: 38.324,53.592,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.206 | Acc: 38.372,53.715,3.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.208 | Acc: 38.395,53.718,3.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.211 | Acc: 38.306,53.681,3.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.210 | Acc: 38.344,53.712,3.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.228 | Acc: 38.186,53.488,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.227 | Acc: 38.245,53.437,3.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.232 | Acc: 38.236,53.387,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.238 | Acc: 38.193,53.310,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.488 | Acc: 21.875,37.500,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.372 | Acc: 21.949,36.012,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.524 | Acc: 21.856,34.394,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.540 | Acc: 21.542,34.490,2.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 8.509 | Acc: 29.688,48.438,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.239 | Acc: 37.202,53.088,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.217 | Acc: 37.710,53.735,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.191 | Acc: 38.166,54.022,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.199 | Acc: 37.992,53.791,2.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.189 | Acc: 37.894,53.937,2.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.182 | Acc: 38.223,53.951,2.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.196 | Acc: 38.265,54.061,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.209 | Acc: 38.373,53.863,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.222 | Acc: 38.277,53.669,2.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.227 | Acc: 38.227,53.603,2.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.233 | Acc: 38.292,53.567,2.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.240 | Acc: 38.213,53.491,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.244 | Acc: 38.209,53.394,2.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.252 | Acc: 38.170,53.211,2.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.255 | Acc: 38.138,53.190,2.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.255 | Acc: 38.164,53.205,2.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.254 | Acc: 38.169,53.253,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.260 | Acc: 38.143,53.177,2.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.263 | Acc: 38.158,53.146,2.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.341 | Acc: 28.906,43.750,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.545 | Acc: 25.930,43.341,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.609 | Acc: 25.629,42.645,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.629 | Acc: 25.282,42.636,2.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 8.265 | Acc: 41.406,53.906,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.257 | Acc: 37.835,52.753,3.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.223 | Acc: 37.976,53.182,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.188 | Acc: 38.371,53.458,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.199 | Acc: 38.243,53.607,3.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.208 | Acc: 38.142,53.682,3.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.200 | Acc: 38.326,53.751,3.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.215 | Acc: 38.165,53.541,2.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.234 | Acc: 38.121,53.372,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.234 | Acc: 38.087,53.259,2.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.232 | Acc: 38.075,53.284,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.223 | Acc: 38.034,53.380,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.226 | Acc: 37.967,53.206,3.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.212 | Acc: 38.045,53.352,3.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.210 | Acc: 38.062,53.395,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.215 | Acc: 38.110,53.330,3.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.221 | Acc: 38.004,53.346,3.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.218 | Acc: 38.032,53.446,3.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.223 | Acc: 37.933,53.365,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.222 | Acc: 38.060,53.396,3.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.030 | Acc: 26.562,39.062,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.138 | Acc: 21.503,37.016,3.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.241 | Acc: 21.684,36.204,3.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.260 | Acc: 21.286,36.437,3.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 7.906 | Acc: 41.406,59.375,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.045 | Acc: 40.402,55.469,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.140 | Acc: 38.986,54.402,3.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.168 | Acc: 38.358,54.252,3.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.166 | Acc: 38.474,54.041,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.170 | Acc: 38.312,53.782,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.171 | Acc: 38.288,53.758,2.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.180 | Acc: 38.265,53.707,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.178 | Acc: 38.538,53.635,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.185 | Acc: 38.454,53.535,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.188 | Acc: 38.429,53.588,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.190 | Acc: 38.405,53.535,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.191 | Acc: 38.284,53.485,2.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.182 | Acc: 38.440,53.652,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.187 | Acc: 38.401,53.556,2.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.182 | Acc: 38.491,53.597,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.180 | Acc: 38.488,53.629,2.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.189 | Acc: 38.414,53.567,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.190 | Acc: 38.392,53.519,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.196 | Acc: 38.328,53.465,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.380 | Acc: 28.906,42.188,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.479 | Acc: 24.777,42.001,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.524 | Acc: 24.714,41.063,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.509 | Acc: 25.154,41.176,2.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 8.219 | Acc: 42.188,54.688,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.165 | Acc: 38.207,53.646,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.197 | Acc: 37.843,53.735,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.147 | Acc: 38.512,54.162,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.152 | Acc: 38.484,53.877,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.146 | Acc: 38.598,53.721,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.137 | Acc: 38.740,53.868,2.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.124 | Acc: 38.852,54.012,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.124 | Acc: 38.766,54.149,2.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.128 | Acc: 38.739,54.157,2.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.131 | Acc: 38.810,54.050,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.135 | Acc: 38.773,53.949,2.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.132 | Acc: 38.926,53.981,2.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.132 | Acc: 39.003,54.038,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.134 | Acc: 38.929,53.998,2.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.138 | Acc: 38.831,53.948,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.146 | Acc: 38.778,53.855,2.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.148 | Acc: 38.804,53.844,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.151 | Acc: 38.740,53.856,2.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.149 | Acc: 38.718,53.808,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.395 | Acc: 25.781,39.062,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.505 | Acc: 21.466,34.338,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.568 | Acc: 21.361,33.422,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.563 | Acc: 21.299,33.619,2.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 8.078 | Acc: 39.062,52.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.080 | Acc: 38.728,54.836,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.075 | Acc: 39.101,54.954,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.088 | Acc: 39.460,54.854,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.098 | Acc: 39.284,54.649,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.095 | Acc: 39.055,54.672,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.115 | Acc: 38.772,54.229,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.109 | Acc: 38.913,54.167,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.107 | Acc: 39.038,54.294,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.103 | Acc: 39.291,54.221,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.101 | Acc: 39.066,54.244,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.114 | Acc: 38.946,54.012,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.110 | Acc: 38.923,54.039,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.102 | Acc: 39.068,54.104,2.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.103 | Acc: 38.960,54.120,2.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.110 | Acc: 38.928,54.007,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.109 | Acc: 38.904,53.987,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.117 | Acc: 38.902,53.925,2.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.116 | Acc: 38.898,53.941,2.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.116 | Acc: 38.864,53.886,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.991 | Acc: 32.812,48.438,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.312 | Acc: 28.125,44.903,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.379 | Acc: 27.058,43.807,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.401 | Acc: 26.883,43.507,2.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 7.605 | Acc: 46.094,61.719,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.022 | Acc: 40.737,56.213,3.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.008 | Acc: 40.434,56.117,3.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.016 | Acc: 40.407,55.751,3.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.028 | Acc: 40.201,55.314,2.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.043 | Acc: 39.813,55.020,2.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.067 | Acc: 39.540,54.952,2.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.067 | Acc: 39.561,54.931,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.064 | Acc: 39.553,54.988,2.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.063 | Acc: 39.421,54.946,2.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.060 | Acc: 39.416,55.014,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.069 | Acc: 39.091,54.815,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.071 | Acc: 39.150,54.743,2.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.067 | Acc: 39.239,54.753,2.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.073 | Acc: 39.149,54.690,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.080 | Acc: 38.977,54.527,2.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.085 | Acc: 38.912,54.398,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.084 | Acc: 38.953,54.431,2.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.087 | Acc: 38.943,54.400,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.084 | Acc: 38.972,54.349,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.841 | Acc: 32.812,46.875,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.540 | Acc: 27.195,41.146,3.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.557 | Acc: 26.715,40.187,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.545 | Acc: 26.870,40.138,3.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 8.030 | Acc: 42.969,51.562,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.009 | Acc: 39.100,54.948,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.970 | Acc: 39.634,55.316,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.998 | Acc: 39.562,54.700,2.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.024 | Acc: 39.400,54.697,2.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.026 | Acc: 39.302,54.626,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.021 | Acc: 39.308,54.823,2.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.034 | Acc: 39.279,54.510,2.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.036 | Acc: 39.092,54.556,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.045 | Acc: 38.985,54.441,2.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.055 | Acc: 38.864,54.202,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.053 | Acc: 38.875,54.136,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.053 | Acc: 38.878,54.068,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.065 | Acc: 38.763,53.894,2.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.073 | Acc: 38.634,53.728,2.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.079 | Acc: 38.655,53.722,2.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.075 | Acc: 38.758,53.687,2.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.074 | Acc: 38.717,53.750,2.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.072 | Acc: 38.727,53.807,2.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.073 | Acc: 38.782,53.826,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.993 | Acc: 33.594,46.875,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.179 | Acc: 28.199,43.341,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.211 | Acc: 26.791,42.816,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.220 | Acc: 26.921,42.597,2.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 8.141 | Acc: 39.844,54.688,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.973 | Acc: 40.030,55.394,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.962 | Acc: 39.863,55.259,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.991 | Acc: 39.191,54.572,2.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.993 | Acc: 39.323,54.678,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.034 | Acc: 39.132,54.494,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.046 | Acc: 39.172,54.423,2.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.053 | Acc: 39.207,54.593,2.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.043 | Acc: 39.339,54.823,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.040 | Acc: 39.214,54.804,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.048 | Acc: 39.214,54.726,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.050 | Acc: 39.084,54.624,2.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.058 | Acc: 38.968,54.548,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.056 | Acc: 38.964,54.592,2.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.049 | Acc: 39.076,54.671,2.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.052 | Acc: 39.047,54.615,2.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.056 | Acc: 39.138,54.507,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.059 | Acc: 39.044,54.507,2.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.055 | Acc: 38.967,54.499,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.055 | Acc: 38.933,54.544,2.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.555 | Acc: 28.125,46.094,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.186 | Acc: 22.098,35.156,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.195 | Acc: 22.771,34.642,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.202 | Acc: 22.503,34.413,2.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 8.037 | Acc: 38.281,53.906,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.162 | Acc: 36.086,52.865,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.094 | Acc: 37.614,54.249,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.089 | Acc: 37.641,54.188,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.058 | Acc: 37.973,54.601,2.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.025 | Acc: 38.111,55.097,2.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.025 | Acc: 38.236,55.030,2.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.025 | Acc: 38.287,54.632,2.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.028 | Acc: 38.456,54.469,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.026 | Acc: 38.519,54.588,2.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.018 | Acc: 38.647,54.765,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.023 | Acc: 38.624,54.804,2.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.027 | Acc: 38.618,54.830,2.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.022 | Acc: 38.691,54.924,2.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.022 | Acc: 38.812,54.857,2.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.022 | Acc: 38.831,54.864,2.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.020 | Acc: 38.809,54.853,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.026 | Acc: 38.788,54.814,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.029 | Acc: 38.807,54.778,2.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.028 | Acc: 38.855,54.763,2.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.392 | Acc: 25.781,31.250,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.400 | Acc: 22.917,32.701,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.472 | Acc: 22.694,32.031,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.442 | Acc: 22.912,31.993,3.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 7.820 | Acc: 46.094,55.469,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.034 | Acc: 38.988,54.688,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.005 | Acc: 39.482,55.412,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.001 | Acc: 39.421,55.072,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.999 | Acc: 39.082,54.967,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.006 | Acc: 39.016,54.842,2.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.001 | Acc: 38.933,54.707,2.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.992 | Acc: 39.046,54.915,2.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.990 | Acc: 39.053,54.780,2.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.989 | Acc: 39.032,54.817,2.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.998 | Acc: 38.888,54.684,2.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.010 | Acc: 38.812,54.702,2.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.013 | Acc: 38.816,54.626,2.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.008 | Acc: 38.940,54.667,2.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.012 | Acc: 38.896,54.701,2.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.020 | Acc: 38.894,54.607,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.023 | Acc: 38.912,54.617,2.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.026 | Acc: 38.925,54.561,2.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.028 | Acc: 38.918,54.480,2.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.028 | Acc: 38.921,54.489,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.203 | Acc: 28.906,42.188,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.532 | Acc: 22.359,43.601,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.530 | Acc: 22.447,43.712,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.537 | Acc: 22.682,43.648,2.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 8.061 | Acc: 39.844,52.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.942 | Acc: 39.435,56.064,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.944 | Acc: 39.806,56.059,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.991 | Acc: 39.344,55.533,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.004 | Acc: 39.188,55.459,2.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.008 | Acc: 39.109,55.175,2.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.005 | Acc: 38.998,55.081,2.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.011 | Acc: 38.902,55.092,2.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.009 | Acc: 39.004,55.032,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.008 | Acc: 39.114,55.080,2.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.994 | Acc: 39.338,55.228,2.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.995 | Acc: 39.370,55.168,2.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.004 | Acc: 39.215,54.963,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.011 | Acc: 39.167,54.921,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.014 | Acc: 39.135,54.832,2.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.019 | Acc: 39.026,54.742,2.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.022 | Acc: 39.033,54.666,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.024 | Acc: 39.035,54.694,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.018 | Acc: 39.123,54.800,2.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.012 | Acc: 39.130,54.862,2.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.093 | Acc: 34.375,53.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.572 | Acc: 24.926,42.783,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.563 | Acc: 25.191,41.845,2.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.550 | Acc: 25.512,41.957,2.177,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 7.718 | Acc: 44.531,66.406,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.983 | Acc: 40.588,54.911,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.918 | Acc: 40.777,55.907,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.984 | Acc: 39.818,55.302,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.967 | Acc: 40.046,55.575,3.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.945 | Acc: 40.478,55.809,3.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.948 | Acc: 40.380,55.533,3.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.952 | Acc: 40.254,55.369,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.960 | Acc: 40.101,55.459,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.967 | Acc: 39.904,55.395,3.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.964 | Acc: 40.093,55.519,2.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.966 | Acc: 40.134,55.391,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.973 | Acc: 39.928,55.274,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.975 | Acc: 39.904,55.187,2.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.989 | Acc: 39.727,55.010,2.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.990 | Acc: 39.589,54.986,2.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.989 | Acc: 39.566,55.016,2.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.997 | Acc: 39.434,54.949,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.000 | Acc: 39.357,54.895,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.003 | Acc: 39.321,54.901,2.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.822 | Acc: 32.812,43.750,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.298 | Acc: 25.967,43.787,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.332 | Acc: 26.181,43.636,2.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.348 | Acc: 25.973,43.366,2.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 7.730 | Acc: 42.969,55.469,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.907 | Acc: 39.844,55.171,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.888 | Acc: 40.206,55.716,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.912 | Acc: 39.946,55.482,2.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.889 | Acc: 39.921,56.086,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.891 | Acc: 39.898,55.956,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.904 | Acc: 39.837,55.876,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.933 | Acc: 39.666,55.424,2.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.938 | Acc: 39.737,55.411,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.957 | Acc: 39.628,55.292,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.951 | Acc: 39.626,55.216,2.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.954 | Acc: 39.628,55.154,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.953 | Acc: 39.610,55.112,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.951 | Acc: 39.616,55.184,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.958 | Acc: 39.627,55.205,2.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.964 | Acc: 39.569,55.240,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.970 | Acc: 39.486,55.179,2.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.978 | Acc: 39.370,55.017,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.983 | Acc: 39.374,54.971,2.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.987 | Acc: 39.302,54.932,2.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.102 | Acc: 36.719,49.219,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.438 | Acc: 28.088,43.304,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.439 | Acc: 28.773,42.378,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.451 | Acc: 28.304,42.239,3.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 8.052 | Acc: 37.500,51.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.902 | Acc: 40.662,56.622,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.851 | Acc: 41.216,57.355,3.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.888 | Acc: 40.561,56.327,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.901 | Acc: 40.567,56.067,3.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.928 | Acc: 40.246,55.856,3.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.925 | Acc: 40.244,56.018,3.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.950 | Acc: 39.927,55.657,3.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.957 | Acc: 39.684,55.537,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.969 | Acc: 39.460,55.305,3.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.977 | Acc: 39.373,55.162,3.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.977 | Acc: 39.275,55.129,3.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.972 | Acc: 39.325,55.180,3.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.978 | Acc: 39.320,55.134,2.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.981 | Acc: 39.240,55.052,3.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.981 | Acc: 39.317,55.217,2.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.984 | Acc: 39.250,55.169,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.989 | Acc: 39.166,55.088,2.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.984 | Acc: 39.257,55.159,2.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.986 | Acc: 39.282,55.104,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.081 | Acc: 30.469,46.875,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.916 | Acc: 29.278,46.912,4.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.991 | Acc: 28.735,45.389,3.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.000 | Acc: 28.932,45.056,3.573,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 7.999 | Acc: 37.500,55.469,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.928 | Acc: 40.662,54.241,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.921 | Acc: 40.015,54.935,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.932 | Acc: 39.869,55.059,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.931 | Acc: 40.152,55.343,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.926 | Acc: 39.743,55.724,3.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.945 | Acc: 39.637,55.624,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.950 | Acc: 39.500,55.546,3.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.958 | Acc: 39.261,55.178,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.955 | Acc: 39.416,55.287,3.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.954 | Acc: 39.552,55.247,3.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.956 | Acc: 39.511,55.218,3.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.957 | Acc: 39.432,55.320,3.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.959 | Acc: 39.302,55.340,3.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.962 | Acc: 39.285,55.266,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.969 | Acc: 39.291,55.137,3.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.973 | Acc: 39.243,55.038,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.970 | Acc: 39.395,55.116,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.965 | Acc: 39.539,55.125,3.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.970 | Acc: 39.446,55.098,3.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.013 | Acc: 32.031,49.219,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.267 | Acc: 28.162,44.457,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.366 | Acc: 27.382,42.969,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.370 | Acc: 27.357,42.866,2.946,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 7.465 | Acc: 43.750,64.062,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.800 | Acc: 41.815,58.110,3.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.895 | Acc: 39.615,56.517,3.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.914 | Acc: 39.549,56.160,3.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.911 | Acc: 39.477,56.115,3.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.937 | Acc: 39.256,55.732,3.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.944 | Acc: 39.166,55.598,3.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.945 | Acc: 39.356,55.751,3.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.934 | Acc: 39.621,55.920,3.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.925 | Acc: 39.732,55.926,3.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.925 | Acc: 39.715,55.854,3.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.930 | Acc: 39.738,55.702,3.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.928 | Acc: 39.857,55.725,3.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.928 | Acc: 39.898,55.696,3.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.937 | Acc: 39.783,55.574,3.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.944 | Acc: 39.753,55.567,3.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.941 | Acc: 39.734,55.569,3.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.943 | Acc: 39.642,55.581,3.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.947 | Acc: 39.638,55.557,3.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.950 | Acc: 39.688,55.491,3.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.726 | Acc: 15.625,30.469,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.854 | Acc: 14.249,30.729,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.942 | Acc: 14.253,29.707,1.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.906 | Acc: 14.306,29.675,1.908,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 8.256 | Acc: 33.594,56.250,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.911 | Acc: 39.918,56.213,3.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.934 | Acc: 39.482,55.526,3.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.923 | Acc: 39.882,55.879,3.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.902 | Acc: 40.027,56.067,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.887 | Acc: 39.906,56.335,3.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.895 | Acc: 39.585,56.166,3.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.889 | Acc: 39.683,56.256,3.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.894 | Acc: 39.596,56.172,3.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.905 | Acc: 39.611,56.069,3.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.912 | Acc: 39.607,56.114,3.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.921 | Acc: 39.519,55.978,3.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.930 | Acc: 39.422,55.929,3.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.930 | Acc: 39.470,55.987,3.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.934 | Acc: 39.491,55.866,3.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.939 | Acc: 39.530,55.840,3.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.946 | Acc: 39.527,55.702,3.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.958 | Acc: 39.411,55.526,3.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.969 | Acc: 39.404,55.443,3.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.001 | Acc: 39.421,55.454,3.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.295 | Acc: 23.438,46.094,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.336 | Acc: 23.698,41.778,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.407 | Acc: 23.438,40.625,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.394 | Acc: 23.143,40.727,1.063,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 8.533 | Acc: 44.531,50.000,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.444 | Acc: 42.076,56.324,1.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.470 | Acc: 41.197,56.079,1.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.504 | Acc: 40.574,56.122,1.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.521 | Acc: 40.721,56.038,1.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.511 | Acc: 40.579,56.188,1.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.508 | Acc: 40.483,56.153,1.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.506 | Acc: 40.503,56.178,1.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.502 | Acc: 40.431,56.148,1.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.506 | Acc: 40.288,56.146,1.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.520 | Acc: 40.120,55.850,1.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.525 | Acc: 40.045,55.794,1.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.527 | Acc: 40.029,55.845,1.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.523 | Acc: 40.074,56.026,1.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.518 | Acc: 40.108,56.025,1.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.523 | Acc: 40.028,55.957,1.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.523 | Acc: 40.043,55.887,1.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.526 | Acc: 40.041,55.867,1.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.525 | Acc: 39.930,55.847,1.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.525 | Acc: 39.944,55.813,1.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.914 | Acc: 28.125,49.219,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.977 | Acc: 26.414,41.815,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.975 | Acc: 27.153,41.825,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.008 | Acc: 27.113,41.163,1.063,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 8.431 | Acc: 41.406,57.812,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.445 | Acc: 40.625,57.143,1.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.408 | Acc: 41.749,57.641,1.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.418 | Acc: 41.342,57.505,1.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.420 | Acc: 41.493,57.552,1.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.434 | Acc: 41.043,57.279,1.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.443 | Acc: 40.651,56.973,1.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.442 | Acc: 40.769,56.976,1.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.444 | Acc: 40.911,56.895,1.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.440 | Acc: 40.992,56.941,1.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.440 | Acc: 40.901,56.907,1.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.449 | Acc: 40.784,56.741,1.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.450 | Acc: 40.690,56.733,1.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.458 | Acc: 40.640,56.537,1.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.461 | Acc: 40.567,56.478,1.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.462 | Acc: 40.532,56.445,1.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.463 | Acc: 40.491,56.469,1.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.465 | Acc: 40.371,56.470,1.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.464 | Acc: 40.352,56.486,1.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.467 | Acc: 40.336,56.424,1.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.976 | Acc: 25.000,35.938,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.089 | Acc: 21.429,33.482,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.192 | Acc: 21.532,32.470,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.190 | Acc: 21.311,32.313,1.063,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 8.297 | Acc: 43.750,53.906,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.421 | Acc: 40.067,56.324,1.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.439 | Acc: 39.844,56.745,1.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.418 | Acc: 40.394,56.814,1.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.423 | Acc: 40.287,56.655,1.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.429 | Acc: 39.952,56.397,1.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.427 | Acc: 39.805,56.747,1.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.438 | Acc: 39.655,56.710,1.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.438 | Acc: 39.727,56.565,1.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.433 | Acc: 39.801,56.556,1.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.437 | Acc: 39.883,56.479,1.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.430 | Acc: 40.010,56.540,1.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.427 | Acc: 40.119,56.464,1.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.426 | Acc: 40.227,56.442,1.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.432 | Acc: 40.177,56.339,1.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.434 | Acc: 40.140,56.367,1.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.438 | Acc: 40.097,56.260,1.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.442 | Acc: 40.022,56.255,1.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.445 | Acc: 40.036,56.267,1.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.446 | Acc: 40.022,56.289,1.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.640 | Acc: 30.469,42.969,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.969 | Acc: 27.307,41.964,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.016 | Acc: 26.677,41.178,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.024 | Acc: 26.140,40.753,1.063,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 8.711 | Acc: 39.844,50.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.383 | Acc: 41.964,56.659,1.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.374 | Acc: 41.120,56.745,1.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.405 | Acc: 40.279,56.429,1.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.417 | Acc: 40.066,56.192,1.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.420 | Acc: 40.169,56.095,1.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.425 | Acc: 40.225,55.953,1.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.430 | Acc: 40.265,55.956,1.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.425 | Acc: 40.353,55.959,1.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.422 | Acc: 40.336,56.108,1.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.425 | Acc: 40.252,55.958,1.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.429 | Acc: 40.173,56.006,1.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.428 | Acc: 40.220,55.932,1.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.430 | Acc: 40.305,55.969,1.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.436 | Acc: 40.208,55.900,1.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.433 | Acc: 40.288,55.928,1.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.431 | Acc: 40.316,56.029,1.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.434 | Acc: 40.247,55.961,1.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.432 | Acc: 40.292,56.070,1.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.435 | Acc: 40.274,55.983,1.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.887 | Acc: 18.750,55.469,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.178 | Acc: 24.033,43.564,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.183 | Acc: 24.009,43.540,0.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.186 | Acc: 24.014,43.430,0.871,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 8.873 | Acc: 35.156,50.781,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.460 | Acc: 40.216,56.548,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.419 | Acc: 39.806,56.879,1.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.411 | Acc: 39.805,56.737,1.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.408 | Acc: 39.824,56.549,1.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.393 | Acc: 40.153,56.536,1.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.398 | Acc: 40.225,56.418,1.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.395 | Acc: 40.065,56.289,1.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.402 | Acc: 40.048,56.303,1.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.396 | Acc: 40.159,56.513,1.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.405 | Acc: 40.038,56.507,1.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.402 | Acc: 40.003,56.430,1.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.410 | Acc: 39.892,56.419,1.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.411 | Acc: 39.946,56.352,1.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.412 | Acc: 40.008,56.397,1.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.412 | Acc: 40.012,56.390,1.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.411 | Acc: 40.099,56.386,1.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.412 | Acc: 40.116,56.298,1.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.416 | Acc: 40.151,56.272,1.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.419 | Acc: 40.084,56.246,1.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.422 | Acc: 21.094,45.312,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.602 | Acc: 21.094,39.695,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.612 | Acc: 20.770,39.672,1.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.623 | Acc: 20.722,39.434,1.050,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 8.126 | Acc: 42.969,54.688,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.358 | Acc: 40.513,58.445,1.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.367 | Acc: 39.901,57.450,1.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.388 | Acc: 39.383,57.070,2.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.387 | Acc: 39.853,56.829,1.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.379 | Acc: 40.107,56.962,1.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.399 | Acc: 40.044,56.534,1.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.395 | Acc: 40.065,56.754,1.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.394 | Acc: 40.014,56.813,1.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.403 | Acc: 39.960,56.608,1.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.398 | Acc: 40.197,56.674,1.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.397 | Acc: 40.293,56.611,1.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.400 | Acc: 40.252,56.678,1.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.404 | Acc: 40.146,56.693,1.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.404 | Acc: 40.072,56.556,1.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.403 | Acc: 40.005,56.554,1.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.404 | Acc: 40.043,56.540,1.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.409 | Acc: 40.002,56.440,1.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.413 | Acc: 39.974,56.421,1.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.419 | Acc: 39.913,56.314,1.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.633 | Acc: 20.312,43.750,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.844 | Acc: 19.159,38.244,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.838 | Acc: 18.655,38.110,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.819 | Acc: 18.468,38.153,1.063,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 8.401 | Acc: 38.281,53.906,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.336 | Acc: 40.699,56.659,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.331 | Acc: 40.320,56.974,1.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.360 | Acc: 40.356,57.108,1.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.385 | Acc: 40.143,56.867,1.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.398 | Acc: 40.037,56.668,1.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.389 | Acc: 40.160,56.779,1.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.382 | Acc: 40.204,56.876,1.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.389 | Acc: 40.145,56.643,1.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.399 | Acc: 39.991,56.617,1.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.407 | Acc: 39.859,56.569,1.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.411 | Acc: 39.847,56.558,1.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.408 | Acc: 40.025,56.613,1.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.404 | Acc: 39.990,56.636,1.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.404 | Acc: 40.102,56.606,1.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.406 | Acc: 40.010,56.486,1.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.411 | Acc: 40.080,56.379,1.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.413 | Acc: 40.073,56.314,1.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.419 | Acc: 39.978,56.220,1.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.421 | Acc: 40.002,56.184,1.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.525 | Acc: 32.812,53.125,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.619 | Acc: 26.711,46.987,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.607 | Acc: 26.734,46.456,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.634 | Acc: 26.409,46.196,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 8.627 | Acc: 34.375,49.219,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.354 | Acc: 40.662,56.213,1.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.416 | Acc: 40.225,55.907,1.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.401 | Acc: 40.433,56.301,1.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.375 | Acc: 40.721,56.771,1.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.385 | Acc: 40.555,56.753,1.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.398 | Acc: 40.715,56.741,1.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.406 | Acc: 40.675,56.677,1.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.400 | Acc: 40.707,56.745,1.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.399 | Acc: 40.638,56.772,1.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.403 | Acc: 40.644,56.755,1.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.404 | Acc: 40.445,56.646,1.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.412 | Acc: 40.359,56.558,1.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.419 | Acc: 40.224,56.409,1.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.416 | Acc: 40.194,56.489,1.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.415 | Acc: 40.225,56.471,1.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.420 | Acc: 40.233,56.467,1.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.419 | Acc: 40.185,56.447,1.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.417 | Acc: 40.220,56.438,1.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.412 | Acc: 40.289,56.549,1.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.924 | Acc: 31.250,61.719,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.475 | Acc: 28.162,47.321,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.494 | Acc: 27.801,46.856,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.516 | Acc: 27.613,46.811,0.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 8.666 | Acc: 34.375,49.219,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.316 | Acc: 40.662,56.808,1.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.322 | Acc: 41.406,57.298,1.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.355 | Acc: 40.996,56.916,1.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.367 | Acc: 40.683,56.636,1.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.377 | Acc: 40.571,56.521,1.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.380 | Acc: 40.509,56.553,1.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.371 | Acc: 40.653,56.826,1.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.383 | Acc: 40.378,56.658,1.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.383 | Acc: 40.362,56.651,1.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.387 | Acc: 40.407,56.538,1.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.392 | Acc: 40.279,56.377,1.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.386 | Acc: 40.327,56.506,1.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.394 | Acc: 40.176,56.430,1.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.394 | Acc: 40.144,56.431,1.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.394 | Acc: 40.282,56.465,1.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.394 | Acc: 40.289,56.496,1.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.399 | Acc: 40.247,56.415,1.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.401 | Acc: 40.205,56.328,1.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.407 | Acc: 40.205,56.258,1.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.634 | Acc: 32.031,46.094,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.909 | Acc: 24.814,45.796,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.969 | Acc: 24.619,45.065,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.988 | Acc: 24.372,44.544,1.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 8.097 | Acc: 41.406,62.500,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.256 | Acc: 41.778,59.226,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.321 | Acc: 40.854,57.450,2.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.329 | Acc: 41.073,57.313,2.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.349 | Acc: 40.943,57.301,1.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.375 | Acc: 40.408,56.791,1.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.378 | Acc: 40.309,56.437,1.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.386 | Acc: 40.359,56.394,1.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.393 | Acc: 40.310,56.357,1.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.383 | Acc: 40.530,56.569,1.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.389 | Acc: 40.384,56.518,1.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.384 | Acc: 40.424,56.536,1.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.392 | Acc: 40.265,56.409,1.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.394 | Acc: 40.290,56.319,1.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.394 | Acc: 40.316,56.370,1.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.395 | Acc: 40.321,56.359,1.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.397 | Acc: 40.233,56.330,1.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.394 | Acc: 40.332,56.367,1.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.395 | Acc: 40.309,56.389,1.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.404 | Acc: 40.272,56.283,1.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.654 | Acc: 32.812,45.312,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.881 | Acc: 27.418,41.183,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.909 | Acc: 27.458,41.845,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.907 | Acc: 27.485,41.253,0.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 8.269 | Acc: 40.625,58.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.314 | Acc: 41.146,58.408,1.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.343 | Acc: 40.454,57.812,1.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.357 | Acc: 40.459,57.505,1.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.343 | Acc: 40.403,57.610,1.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.337 | Acc: 40.679,57.650,1.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.349 | Acc: 40.767,57.483,1.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.356 | Acc: 40.741,57.303,1.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.366 | Acc: 40.669,57.162,1.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.370 | Acc: 40.590,57.040,1.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.372 | Acc: 40.676,57.152,1.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.373 | Acc: 40.629,57.144,1.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.379 | Acc: 40.515,57.057,1.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.379 | Acc: 40.526,57.031,1.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.385 | Acc: 40.533,56.920,1.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.377 | Acc: 40.609,57.016,1.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.383 | Acc: 40.567,56.914,1.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.388 | Acc: 40.405,56.901,1.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.388 | Acc: 40.413,56.990,1.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.392 | Acc: 40.367,56.943,1.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.911 | Acc: 28.906,46.875,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.797 | Acc: 27.307,43.490,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.908 | Acc: 27.420,42.607,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.911 | Acc: 27.613,42.623,1.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 8.766 | Acc: 39.062,48.438,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.522 | Acc: 39.881,55.990,1.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.507 | Acc: 39.634,56.421,1.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.448 | Acc: 40.074,56.852,1.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.430 | Acc: 40.278,56.665,1.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.425 | Acc: 40.037,56.675,1.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.413 | Acc: 40.167,56.657,1.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.400 | Acc: 40.237,56.560,1.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.397 | Acc: 40.043,56.561,1.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.390 | Acc: 40.172,56.647,1.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.392 | Acc: 40.229,56.681,1.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.388 | Acc: 40.247,56.780,1.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.392 | Acc: 40.184,56.597,1.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.396 | Acc: 40.185,56.486,1.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.397 | Acc: 40.177,56.522,1.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.398 | Acc: 40.119,56.497,1.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.397 | Acc: 40.172,56.498,1.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.397 | Acc: 40.178,56.573,1.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.401 | Acc: 40.184,56.510,1.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.404 | Acc: 40.073,56.396,1.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.482 | Acc: 23.438,38.281,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.751 | Acc: 23.363,38.504,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.714 | Acc: 22.809,38.643,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.721 | Acc: 23.092,38.601,1.063,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 8.118 | Acc: 43.750,55.469,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.255 | Acc: 41.778,59.040,1.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.280 | Acc: 40.949,58.403,2.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.311 | Acc: 40.907,57.889,2.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.286 | Acc: 41.281,58.189,2.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.306 | Acc: 40.934,57.812,2.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.319 | Acc: 41.038,57.612,1.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.327 | Acc: 40.736,57.580,1.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.342 | Acc: 40.620,57.361,1.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.345 | Acc: 40.642,57.420,1.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.349 | Acc: 40.656,57.389,1.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.350 | Acc: 40.632,57.342,1.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.354 | Acc: 40.492,57.248,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.366 | Acc: 40.398,57.040,1.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.369 | Acc: 40.400,57.056,1.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.373 | Acc: 40.327,56.972,1.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.381 | Acc: 40.253,56.739,1.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.388 | Acc: 40.146,56.623,1.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.388 | Acc: 40.164,56.553,1.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.389 | Acc: 40.153,56.490,1.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.339 | Acc: 31.250,38.281,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.298 | Acc: 26.004,38.951,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.409 | Acc: 26.391,38.472,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.467 | Acc: 25.832,37.628,0.999,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 8.233 | Acc: 46.094,58.594,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.327 | Acc: 41.518,56.994,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.335 | Acc: 41.311,57.470,1.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.327 | Acc: 41.381,57.185,1.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.337 | Acc: 40.799,57.176,1.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.350 | Acc: 40.695,56.962,1.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.353 | Acc: 40.612,56.999,1.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.349 | Acc: 40.619,57.103,1.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.353 | Acc: 40.703,56.915,1.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.360 | Acc: 40.595,56.643,1.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.371 | Acc: 40.396,56.662,1.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.386 | Acc: 40.325,56.558,1.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.384 | Acc: 40.304,56.697,1.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.383 | Acc: 40.371,56.672,1.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.385 | Acc: 40.380,56.670,1.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.389 | Acc: 40.345,56.585,1.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.390 | Acc: 40.386,56.605,1.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.389 | Acc: 40.378,56.603,1.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.387 | Acc: 40.430,56.609,1.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.387 | Acc: 40.432,56.590,1.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.665 | Acc: 24.219,50.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.144 | Acc: 24.368,42.374,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.176 | Acc: 24.066,41.978,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.163 | Acc: 23.476,42.213,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 8.530 | Acc: 42.188,53.125,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.320 | Acc: 41.629,57.664,1.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.292 | Acc: 41.959,58.155,1.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.272 | Acc: 42.021,58.222,2.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.298 | Acc: 41.696,57.841,1.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.310 | Acc: 41.422,57.480,1.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.319 | Acc: 41.458,57.490,1.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.329 | Acc: 41.279,57.596,1.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.332 | Acc: 41.139,57.458,1.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.344 | Acc: 40.931,57.346,1.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.353 | Acc: 40.796,57.194,1.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.350 | Acc: 40.869,57.289,1.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.353 | Acc: 40.845,57.154,1.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.354 | Acc: 40.873,57.154,1.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.356 | Acc: 40.733,57.165,1.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.364 | Acc: 40.672,57.078,1.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.364 | Acc: 40.674,57.077,1.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.369 | Acc: 40.636,57.036,1.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.375 | Acc: 40.582,56.858,1.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.373 | Acc: 40.609,56.921,1.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.491 | Acc: 32.031,53.906,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.628 | Acc: 29.092,47.098,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.685 | Acc: 28.296,46.608,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.733 | Acc: 28.304,45.581,0.909,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 8.203 | Acc: 48.438,60.156,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.317 | Acc: 42.262,56.808,2.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.324 | Acc: 41.025,56.822,2.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.317 | Acc: 41.176,56.993,2.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.322 | Acc: 41.175,57.012,2.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.314 | Acc: 41.337,56.915,1.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.331 | Acc: 41.129,56.799,1.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.352 | Acc: 40.874,56.516,1.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.357 | Acc: 40.882,56.546,1.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.359 | Acc: 40.970,56.630,1.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.364 | Acc: 40.901,56.604,1.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.374 | Acc: 40.841,56.540,1.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.369 | Acc: 40.855,56.701,1.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.370 | Acc: 40.736,56.615,1.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.373 | Acc: 40.720,56.561,1.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.377 | Acc: 40.695,56.471,1.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.384 | Acc: 40.613,56.403,1.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.384 | Acc: 40.581,56.445,1.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.384 | Acc: 40.530,56.456,1.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.382 | Acc: 40.557,56.502,1.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.189 | Acc: 24.219,39.844,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.154 | Acc: 19.978,34.896,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.239 | Acc: 19.512,34.165,0.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.284 | Acc: 19.403,33.658,1.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 8.225 | Acc: 40.625,58.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.204 | Acc: 43.118,58.780,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.249 | Acc: 42.168,58.479,1.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.275 | Acc: 41.265,58.107,1.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.278 | Acc: 41.184,58.102,1.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.300 | Acc: 41.035,57.727,1.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.324 | Acc: 40.722,57.193,1.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.327 | Acc: 40.830,57.264,1.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.329 | Acc: 40.630,57.274,1.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.348 | Acc: 40.470,57.083,1.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.347 | Acc: 40.473,57.121,1.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.351 | Acc: 40.498,57.176,1.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.352 | Acc: 40.628,57.213,1.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.353 | Acc: 40.652,57.184,1.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.356 | Acc: 40.617,57.142,1.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.357 | Acc: 40.669,57.062,1.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.362 | Acc: 40.625,57.056,1.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.368 | Acc: 40.602,56.942,1.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.368 | Acc: 40.649,56.934,1.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.366 | Acc: 40.697,56.939,1.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.833 | Acc: 11.719,21.094,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.979 | Acc: 11.421,23.735,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.016 | Acc: 10.823,23.190,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.065 | Acc: 10.387,23.220,0.948,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 8.334 | Acc: 43.750,57.812,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.296 | Acc: 42.969,58.110,1.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.308 | Acc: 41.463,57.851,1.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.326 | Acc: 41.393,57.326,1.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.311 | Acc: 41.416,57.562,1.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.325 | Acc: 41.368,57.457,1.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.343 | Acc: 41.012,57.296,1.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.340 | Acc: 41.162,57.430,1.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.343 | Acc: 41.003,57.347,1.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.344 | Acc: 40.979,57.394,1.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.348 | Acc: 41.111,57.280,1.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.350 | Acc: 41.067,57.243,1.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.358 | Acc: 40.975,57.119,1.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.358 | Acc: 40.942,57.040,1.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.361 | Acc: 40.856,56.978,1.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.356 | Acc: 40.931,57.088,1.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.361 | Acc: 40.844,56.905,1.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.362 | Acc: 40.854,56.912,1.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.365 | Acc: 40.818,56.856,1.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.359 | Acc: 40.857,56.955,1.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.799 | Acc: 32.812,46.094,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.903 | Acc: 26.897,42.820,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.883 | Acc: 27.344,42.149,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.875 | Acc: 27.267,42.123,0.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 8.645 | Acc: 34.375,46.875,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.355 | Acc: 40.327,56.436,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.360 | Acc: 40.816,56.250,1.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.350 | Acc: 41.214,56.660,1.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.320 | Acc: 41.860,57.243,1.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.347 | Acc: 41.437,56.938,1.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.350 | Acc: 41.238,57.076,1.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.371 | Acc: 40.908,56.677,1.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.383 | Acc: 40.785,56.488,1.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.378 | Acc: 40.875,56.621,1.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.364 | Acc: 41.107,56.810,1.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.361 | Acc: 41.077,56.943,1.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.364 | Acc: 40.978,56.879,1.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.369 | Acc: 40.897,56.798,1.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.375 | Acc: 40.764,56.714,1.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.373 | Acc: 40.773,56.746,1.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.369 | Acc: 40.735,56.800,1.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.365 | Acc: 40.847,56.843,1.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.370 | Acc: 40.776,56.761,1.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.372 | Acc: 40.773,56.732,1.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.367 | Acc: 32.812,46.875,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.604 | Acc: 29.539,43.638,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.634 | Acc: 29.002,43.026,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.654 | Acc: 28.599,43.148,0.935,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 8.401 | Acc: 43.750,53.906,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.272 | Acc: 41.369,59.077,2.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.312 | Acc: 41.559,58.479,1.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.325 | Acc: 41.329,58.069,1.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.313 | Acc: 41.406,58.063,2.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.316 | Acc: 41.313,57.983,2.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.328 | Acc: 40.980,57.729,2.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.324 | Acc: 41.146,57.519,2.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.336 | Acc: 40.916,57.381,1.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.334 | Acc: 40.975,57.420,1.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.338 | Acc: 40.878,57.459,1.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.343 | Acc: 40.788,57.427,1.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.348 | Acc: 40.774,57.381,1.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.353 | Acc: 40.766,57.346,1.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.354 | Acc: 40.783,57.368,1.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.357 | Acc: 40.794,57.234,1.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.361 | Acc: 40.735,57.112,1.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.365 | Acc: 40.707,57.068,1.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.366 | Acc: 40.709,57.046,1.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.370 | Acc: 40.656,56.968,1.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.646 | Acc: 33.594,43.750,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.993 | Acc: 26.562,42.188,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.022 | Acc: 26.220,41.216,1.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.072 | Acc: 25.832,40.599,1.076,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 7.837 | Acc: 46.094,63.281,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.234 | Acc: 41.518,59.189,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.269 | Acc: 41.940,58.308,1.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.271 | Acc: 41.611,58.581,1.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.287 | Acc: 41.676,58.150,1.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.297 | Acc: 41.499,58.161,1.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.298 | Acc: 41.503,58.200,1.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.311 | Acc: 41.129,57.951,1.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.309 | Acc: 41.096,57.900,1.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.320 | Acc: 41.039,57.795,1.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.336 | Acc: 40.780,57.482,1.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.346 | Acc: 40.618,57.311,1.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.355 | Acc: 40.531,57.203,1.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.353 | Acc: 40.565,57.235,1.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.354 | Acc: 40.533,57.190,1.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.353 | Acc: 40.617,57.177,1.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.356 | Acc: 40.637,57.060,1.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.361 | Acc: 40.522,56.990,1.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.363 | Acc: 40.517,56.981,1.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.367 | Acc: 40.508,56.953,1.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.505 | Acc: 32.031,47.656,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.874 | Acc: 26.935,42.597,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.924 | Acc: 26.715,42.168,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.904 | Acc: 26.998,42.380,0.909,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 8.128 | Acc: 46.875,61.719,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.251 | Acc: 42.113,57.924,1.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.230 | Acc: 41.978,58.765,1.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.243 | Acc: 41.624,58.491,1.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.247 | Acc: 41.647,58.536,1.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.249 | Acc: 41.994,58.540,1.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.257 | Acc: 41.832,58.620,1.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.278 | Acc: 41.595,58.311,1.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.283 | Acc: 41.576,58.244,1.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.296 | Acc: 41.346,58.153,1.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.297 | Acc: 41.391,57.945,1.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.302 | Acc: 41.233,57.858,1.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.315 | Acc: 41.150,57.595,1.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.322 | Acc: 40.975,57.456,1.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.330 | Acc: 40.911,57.395,1.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.332 | Acc: 40.859,57.369,1.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.339 | Acc: 40.783,57.248,1.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.340 | Acc: 40.850,57.253,1.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.342 | Acc: 40.811,57.176,1.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.346 | Acc: 40.840,57.175,1.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.714 | Acc: 25.000,35.156,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.721 | Acc: 22.470,38.653,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.777 | Acc: 22.409,38.281,1.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.778 | Acc: 21.965,38.294,1.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 8.402 | Acc: 36.719,63.281,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.289 | Acc: 40.476,58.594,1.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.261 | Acc: 41.730,58.060,1.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.300 | Acc: 41.009,57.223,1.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.314 | Acc: 40.828,57.658,1.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.318 | Acc: 40.733,57.604,1.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.328 | Acc: 40.709,57.561,1.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.324 | Acc: 40.919,57.596,1.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.338 | Acc: 40.756,57.400,1.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.340 | Acc: 40.789,57.338,1.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.345 | Acc: 40.734,57.307,1.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.340 | Acc: 40.798,57.360,1.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.340 | Acc: 40.865,57.333,1.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.336 | Acc: 41.005,57.337,1.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.335 | Acc: 41.025,57.340,1.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.335 | Acc: 41.066,57.428,1.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.346 | Acc: 40.944,57.372,1.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.343 | Acc: 41.019,57.471,1.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.349 | Acc: 41.017,57.416,1.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.357 | Acc: 40.920,57.355,1.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.402 | Acc: 21.875,40.625,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.740 | Acc: 21.317,37.872,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.780 | Acc: 21.170,36.604,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.781 | Acc: 21.004,36.552,1.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 8.688 | Acc: 32.812,50.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.290 | Acc: 41.332,58.594,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.336 | Acc: 41.311,58.365,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.359 | Acc: 41.150,57.812,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.361 | Acc: 41.040,57.880,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.367 | Acc: 40.842,57.735,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.363 | Acc: 41.090,57.729,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.374 | Acc: 40.847,57.508,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.379 | Acc: 40.741,57.327,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.383 | Acc: 40.599,57.217,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.377 | Acc: 40.796,57.284,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.381 | Acc: 40.770,57.183,0.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.374 | Acc: 40.839,57.336,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.374 | Acc: 40.858,57.375,0.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.373 | Acc: 40.889,57.376,0.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.368 | Acc: 40.952,57.467,0.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.375 | Acc: 40.883,57.294,0.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.380 | Acc: 40.893,57.235,0.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.384 | Acc: 40.865,57.101,0.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.387 | Acc: 40.838,57.068,0.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.540 | Acc: 34.375,46.875,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.421 | Acc: 31.176,45.126,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.461 | Acc: 30.621,44.569,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.478 | Acc: 30.405,44.339,0.909,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 8.193 | Acc: 40.625,63.281,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.374 | Acc: 40.365,58.482,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.333 | Acc: 40.758,58.937,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.356 | Acc: 41.073,58.850,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.362 | Acc: 41.001,58.709,0.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.349 | Acc: 41.329,58.702,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.338 | Acc: 41.471,58.613,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.352 | Acc: 41.035,58.150,0.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.361 | Acc: 40.834,57.958,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.363 | Acc: 40.923,57.851,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.365 | Acc: 40.909,57.766,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.367 | Acc: 41.049,57.742,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.371 | Acc: 40.933,57.764,0.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.367 | Acc: 41.005,57.747,0.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.358 | Acc: 41.095,57.865,0.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.363 | Acc: 41.048,57.714,0.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.370 | Acc: 40.927,57.535,0.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.370 | Acc: 40.946,57.430,0.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.374 | Acc: 40.915,57.321,0.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.375 | Acc: 40.861,57.290,0.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.494 | Acc: 37.500,49.219,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.611 | Acc: 28.385,44.345,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.678 | Acc: 28.487,43.540,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.689 | Acc: 28.650,43.020,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 8.718 | Acc: 45.312,51.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.428 | Acc: 40.885,55.915,0.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.364 | Acc: 41.197,57.489,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.368 | Acc: 40.856,57.480,1.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.369 | Acc: 40.779,57.716,1.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.367 | Acc: 40.726,57.812,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.346 | Acc: 41.064,57.884,1.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.359 | Acc: 41.013,57.696,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.360 | Acc: 41.193,57.652,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.367 | Acc: 41.057,57.571,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.352 | Acc: 41.301,57.785,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.360 | Acc: 41.010,57.668,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.358 | Acc: 40.988,57.774,0.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.363 | Acc: 40.954,57.663,0.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.366 | Acc: 40.984,57.587,0.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.360 | Acc: 40.996,57.696,0.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.367 | Acc: 40.915,57.540,0.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.370 | Acc: 40.854,57.547,0.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.368 | Acc: 40.969,57.652,0.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.366 | Acc: 41.031,57.657,0.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.526 | Acc: 30.469,44.531,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.575 | Acc: 28.646,44.568,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.605 | Acc: 28.487,44.627,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.613 | Acc: 28.202,44.390,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 8.419 | Acc: 36.719,58.594,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.283 | Acc: 41.592,60.193,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.284 | Acc: 42.035,59.204,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.296 | Acc: 41.368,58.901,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.308 | Acc: 41.368,58.729,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.314 | Acc: 41.406,58.609,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.332 | Acc: 41.342,58.361,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.350 | Acc: 41.074,58.029,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.334 | Acc: 41.198,58.206,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.336 | Acc: 41.156,57.959,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.339 | Acc: 41.255,57.879,0.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.344 | Acc: 41.311,57.745,0.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.347 | Acc: 41.254,57.780,0.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.351 | Acc: 41.077,57.690,0.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.355 | Acc: 41.023,57.660,0.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.367 | Acc: 40.809,57.480,0.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.372 | Acc: 40.788,57.482,0.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.373 | Acc: 40.817,57.363,0.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.377 | Acc: 40.727,57.256,0.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.379 | Acc: 40.752,57.171,0.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.040 | Acc: 28.906,45.312,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.280 | Acc: 25.670,40.811,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.356 | Acc: 25.286,39.882,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.382 | Acc: 25.295,39.447,0.948,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 8.224 | Acc: 37.500,57.031,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.410 | Acc: 40.179,56.734,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.364 | Acc: 40.835,57.489,0.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.355 | Acc: 40.548,57.723,0.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.377 | Acc: 40.278,57.620,0.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.382 | Acc: 40.246,57.727,0.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.374 | Acc: 40.360,57.890,0.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.365 | Acc: 40.470,57.973,0.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.365 | Acc: 40.533,57.837,0.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.364 | Acc: 40.642,57.774,0.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.355 | Acc: 40.734,57.778,0.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.354 | Acc: 40.717,57.756,0.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.347 | Acc: 40.826,57.864,0.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.348 | Acc: 40.817,57.983,0.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.350 | Acc: 40.706,57.915,0.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.349 | Acc: 40.840,57.901,0.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.356 | Acc: 40.851,57.747,0.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.359 | Acc: 40.779,57.714,0.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.353 | Acc: 40.924,57.769,0.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.358 | Acc: 40.828,57.648,0.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.690 | Acc: 28.906,49.219,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.972 | Acc: 27.381,42.746,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.040 | Acc: 26.448,41.883,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.050 | Acc: 26.614,41.944,0.986,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 8.160 | Acc: 43.750,58.594,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.276 | Acc: 41.853,59.003,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.278 | Acc: 41.292,58.365,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.280 | Acc: 41.496,58.440,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.290 | Acc: 41.194,58.574,0.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.321 | Acc: 41.035,57.789,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.326 | Acc: 41.148,57.787,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.338 | Acc: 41.307,57.691,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.341 | Acc: 41.464,57.745,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.341 | Acc: 41.342,57.787,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.344 | Acc: 41.383,57.614,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.341 | Acc: 41.371,57.682,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.339 | Acc: 41.270,57.780,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.344 | Acc: 41.152,57.639,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.349 | Acc: 41.036,57.682,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.352 | Acc: 41.038,57.657,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.354 | Acc: 41.058,57.630,0.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.356 | Acc: 41.072,57.538,0.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.360 | Acc: 40.997,57.471,0.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.364 | Acc: 40.869,57.351,0.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.955 | Acc: 30.469,49.219,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.892 | Acc: 25.744,45.424,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.963 | Acc: 24.733,44.798,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.954 | Acc: 24.680,44.416,0.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 8.739 | Acc: 39.844,52.344,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.249 | Acc: 41.629,59.226,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.276 | Acc: 41.559,58.994,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.278 | Acc: 41.048,59.132,0.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.288 | Acc: 41.291,58.787,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.302 | Acc: 41.089,58.741,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.304 | Acc: 41.213,58.755,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.303 | Acc: 41.445,58.854,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.315 | Acc: 41.246,58.540,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.324 | Acc: 41.195,58.421,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.322 | Acc: 41.181,58.353,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.318 | Acc: 41.275,58.318,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.325 | Acc: 41.231,58.214,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.328 | Acc: 41.245,58.121,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.341 | Acc: 41.164,57.982,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.341 | Acc: 41.235,57.973,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.345 | Acc: 41.209,57.907,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.351 | Acc: 41.163,57.725,0.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.353 | Acc: 41.190,57.728,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.358 | Acc: 41.162,57.689,0.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.600 | Acc: 23.438,48.438,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.568 | Acc: 21.280,42.522,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.655 | Acc: 21.456,41.235,0.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.671 | Acc: 21.465,40.202,0.871,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 8.337 | Acc: 44.531,57.031,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.344 | Acc: 41.518,58.371,1.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.292 | Acc: 41.616,58.460,1.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.308 | Acc: 40.945,58.222,1.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.279 | Acc: 41.184,58.497,1.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.301 | Acc: 40.718,58.021,1.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.298 | Acc: 40.567,58.122,1.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.301 | Acc: 40.509,57.896,1.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.302 | Acc: 40.547,57.779,1.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.297 | Acc: 40.543,57.718,1.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.297 | Acc: 40.493,57.801,1.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.300 | Acc: 40.487,57.805,1.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.304 | Acc: 40.473,57.735,1.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.311 | Acc: 40.433,57.732,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.321 | Acc: 40.405,57.682,1.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.323 | Acc: 40.539,57.698,1.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.330 | Acc: 40.513,57.674,1.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.336 | Acc: 40.570,57.625,1.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.341 | Acc: 40.517,57.600,1.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.344 | Acc: 40.504,57.612,1.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.999 | Acc: 28.125,47.656,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.000 | Acc: 24.442,43.006,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.073 | Acc: 25.057,42.073,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.100 | Acc: 24.974,41.457,0.935,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 8.005 | Acc: 46.875,63.281,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.295 | Acc: 41.890,57.701,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.312 | Acc: 40.473,58.155,0.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.344 | Acc: 40.049,57.723,0.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.345 | Acc: 40.172,57.755,0.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.337 | Acc: 40.424,57.843,0.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.325 | Acc: 40.457,58.013,0.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.337 | Acc: 40.509,57.851,0.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.346 | Acc: 40.601,57.910,0.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.351 | Acc: 40.578,57.666,0.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.353 | Acc: 40.695,57.540,0.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.351 | Acc: 40.657,57.622,0.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.360 | Acc: 40.544,57.530,0.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.354 | Acc: 40.700,57.597,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.353 | Acc: 40.745,57.509,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.349 | Acc: 40.726,57.493,1.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.341 | Acc: 40.742,57.537,1.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.337 | Acc: 40.804,57.487,1.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.330 | Acc: 40.837,57.501,1.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.328 | Acc: 40.756,57.454,1.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.530 | Acc: 28.906,49.219,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.774 | Acc: 24.442,46.801,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.804 | Acc: 24.676,45.160,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.827 | Acc: 24.718,44.941,0.935,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 8.047 | Acc: 40.625,67.188,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.317 | Acc: 40.179,57.180,1.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.366 | Acc: 40.377,57.050,1.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.360 | Acc: 40.804,57.428,1.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.351 | Acc: 41.165,57.745,1.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.339 | Acc: 41.081,57.774,1.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.324 | Acc: 41.342,57.955,1.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.312 | Acc: 41.318,57.962,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.315 | Acc: 41.329,57.968,1.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.310 | Acc: 41.385,58.071,1.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.319 | Acc: 41.266,58.038,1.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.316 | Acc: 41.297,58.092,1.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.301 | Acc: 41.393,58.156,1.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.298 | Acc: 41.343,57.968,1.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.294 | Acc: 41.276,57.879,1.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.283 | Acc: 41.295,57.950,1.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.286 | Acc: 41.175,57.861,1.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.286 | Acc: 41.136,57.748,1.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.283 | Acc: 41.112,57.691,1.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.282 | Acc: 41.082,57.523,1.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.341 | Acc: 33.594,48.438,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.809 | Acc: 29.055,43.006,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.827 | Acc: 28.182,42.302,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.862 | Acc: 27.766,41.790,1.063,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 8.416 | Acc: 35.156,53.906,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.080 | Acc: 42.597,58.333,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.157 | Acc: 41.597,58.155,2.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.190 | Acc: 40.920,57.889,2.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.174 | Acc: 41.088,57.976,2.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.173 | Acc: 41.012,57.882,2.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.172 | Acc: 41.090,57.961,1.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.181 | Acc: 41.007,57.768,2.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.188 | Acc: 40.630,57.478,2.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.200 | Acc: 40.496,57.299,2.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.195 | Acc: 40.539,57.494,1.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.188 | Acc: 40.607,57.660,1.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.183 | Acc: 40.738,57.757,2.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.185 | Acc: 40.769,57.786,1.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.184 | Acc: 40.811,57.768,2.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.188 | Acc: 40.716,57.724,2.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.193 | Acc: 40.722,57.674,2.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.197 | Acc: 40.758,57.613,2.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.196 | Acc: 40.731,57.525,2.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.197 | Acc: 40.736,57.583,2.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.242 | Acc: 25.000,42.188,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.504 | Acc: 22.991,38.988,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.556 | Acc: 22.809,38.148,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.599 | Acc: 22.234,37.884,1.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 8.064 | Acc: 42.188,59.375,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.185 | Acc: 40.365,57.552,2.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.170 | Acc: 40.091,57.717,2.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.162 | Acc: 40.164,57.620,2.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.145 | Acc: 40.847,57.899,2.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.143 | Acc: 41.112,57.975,2.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.141 | Acc: 41.142,57.909,2.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.149 | Acc: 40.996,57.652,2.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.151 | Acc: 40.824,57.555,2.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.165 | Acc: 40.798,57.528,2.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.176 | Acc: 40.788,57.303,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.172 | Acc: 40.738,57.318,2.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.175 | Acc: 40.735,57.297,2.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.177 | Acc: 40.724,57.175,2.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.181 | Acc: 40.617,57.123,2.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.181 | Acc: 40.721,57.130,1.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.178 | Acc: 40.727,57.194,2.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.178 | Acc: 40.744,57.215,2.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.176 | Acc: 40.772,57.245,2.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.180 | Acc: 40.736,57.150,2.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.783 | Acc: 28.125,43.750,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.071 | Acc: 26.637,40.141,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.097 | Acc: 26.582,40.434,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.106 | Acc: 26.691,40.356,0.845,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 8.370 | Acc: 38.281,50.000,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.130 | Acc: 40.402,56.957,2.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.090 | Acc: 40.968,57.812,2.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.105 | Acc: 40.856,57.838,2.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.092 | Acc: 41.001,58.063,2.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.114 | Acc: 41.004,57.805,2.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.112 | Acc: 41.116,57.890,2.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.117 | Acc: 41.002,57.873,2.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.126 | Acc: 40.848,57.788,2.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.123 | Acc: 40.871,57.739,2.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.114 | Acc: 41.049,57.785,2.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.110 | Acc: 41.138,57.823,2.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.111 | Acc: 41.199,57.693,2.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.119 | Acc: 41.158,57.639,2.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.121 | Acc: 41.256,57.551,2.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.117 | Acc: 41.251,57.579,2.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.118 | Acc: 41.209,57.625,2.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.123 | Acc: 41.115,57.544,2.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.125 | Acc: 41.079,57.505,2.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.131 | Acc: 41.054,57.419,2.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.093 | Acc: 30.469,42.188,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.083 | Acc: 25.223,42.485,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.087 | Acc: 25.152,41.883,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.054 | Acc: 25.512,42.136,0.948,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 7.996 | Acc: 41.406,61.719,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.037 | Acc: 42.448,59.673,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.067 | Acc: 41.921,58.651,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.095 | Acc: 41.406,58.017,2.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.091 | Acc: 41.271,57.919,2.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.094 | Acc: 40.927,57.758,2.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.081 | Acc: 40.786,57.884,2.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.065 | Acc: 40.952,58.006,2.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.063 | Acc: 41.052,57.890,2.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.064 | Acc: 41.061,57.886,2.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.077 | Acc: 41.072,57.708,2.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.081 | Acc: 41.010,57.523,2.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.088 | Acc: 40.946,57.462,2.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.088 | Acc: 40.966,57.432,2.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.091 | Acc: 40.831,57.340,2.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.090 | Acc: 40.827,57.395,2.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.088 | Acc: 40.854,57.357,2.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.094 | Acc: 40.772,57.320,2.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.099 | Acc: 40.694,57.233,2.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.100 | Acc: 40.695,57.138,2.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.482 | Acc: 33.594,42.969,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.356 | Acc: 29.650,48.177,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.427 | Acc: 28.716,46.875,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.430 | Acc: 28.496,47.080,0.948,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 7.994 | Acc: 39.844,62.500,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.041 | Acc: 39.621,58.110,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.038 | Acc: 40.358,58.136,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.044 | Acc: 40.740,58.043,2.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.044 | Acc: 40.702,57.996,2.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.053 | Acc: 40.733,57.836,2.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.046 | Acc: 41.051,57.767,2.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.046 | Acc: 41.029,57.812,2.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.057 | Acc: 40.872,57.570,2.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.062 | Acc: 40.824,57.575,2.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.065 | Acc: 40.722,57.490,2.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.062 | Acc: 40.812,57.487,2.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.060 | Acc: 40.914,57.573,2.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.061 | Acc: 40.814,57.438,2.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.058 | Acc: 40.909,57.493,2.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.064 | Acc: 40.939,57.472,2.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.066 | Acc: 40.968,57.501,2.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.067 | Acc: 40.905,57.448,2.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.068 | Acc: 40.863,57.442,2.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.067 | Acc: 40.877,57.417,2.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.673 | Acc: 27.344,53.906,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.800 | Acc: 25.930,47.061,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.847 | Acc: 25.915,45.732,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.859 | Acc: 25.781,45.274,1.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 7.918 | Acc: 40.625,56.250,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.964 | Acc: 41.034,59.040,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.986 | Acc: 40.720,58.403,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.993 | Acc: 40.702,58.184,2.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.979 | Acc: 40.644,58.275,2.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.989 | Acc: 40.664,58.091,2.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.993 | Acc: 40.935,57.819,2.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.001 | Acc: 40.913,57.835,2.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.013 | Acc: 40.785,57.628,2.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.022 | Acc: 40.655,57.558,2.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.019 | Acc: 40.660,57.684,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.022 | Acc: 40.657,57.629,2.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.018 | Acc: 40.654,57.650,2.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.020 | Acc: 40.694,57.594,2.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.024 | Acc: 40.619,57.432,2.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.023 | Acc: 40.578,57.465,2.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.025 | Acc: 40.554,57.421,2.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.027 | Acc: 40.607,57.382,2.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 39.173,55.332,2.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 37.160,52.471,2.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.339,1.339,1.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.200,1.200,1.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.101,1.101,1.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.080,1.080,1.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.058,1.058,1.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.030,1.030,1.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.838,0.838,0.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.045,1.045,1.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.049,1.049,1.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.871,0.871,0.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.878,0.878,0.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.954,0.954,0.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.954,0.954,0.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.818,0.818,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.089,1.089,1.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.080,1.080,1.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.060,1.060,1.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.083,1.083,1.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.073,1.073,1.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.056,1.056,1.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.632,0.632,0.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.724,0.724,0.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.845,0.845,0.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.858,0.858,0.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.874,0.874,0.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.878,0.878,0.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.887,0.887,0.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.924,0.924,0.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.890,0.890,0.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.901,0.901,0.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.928,0.928,0.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.937,0.937,0.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.143,1.143,1.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.101,1.101,1.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.038,1.038,1.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.143,1.143,1.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.818,0.818,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.076,1.076,1.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.080,1.080,1.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.129,1.129,1.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.091,1.091,1.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.066,1.066,1.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.181,1.181,1.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.204,1.204,1.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.148,1.148,1.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.098,1.098,1.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.091,1.091,1.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.070,1.070,1.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.065,1.065,1.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.857,0.857,0.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.868,0.868,0.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.905,0.905,0.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.943,0.943,0.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.942,0.942,0.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.302,1.302,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.947,0.947,0.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.954,0.954,0.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.954,0.954,0.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.982,0.982,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.960,0.960,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.963,0.963,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.707,0.707,0.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.730,0.730,0.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.733,0.733,0.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.797,0.797,0.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.891,0.891,0.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.931,0.931,0.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.927,0.927,0.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.946,0.946,0.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.928,0.928,0.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.910,0.910,0.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.919,0.919,0.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.898,0.898,0.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.937,0.937,0.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.940,0.940,0.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.958,0.958,0.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.122,1.122,1.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.707,0.707,0.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.838,0.838,0.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.832,0.832,0.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.907,0.907,0.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.920,0.920,0.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.960,0.960,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.926,0.926,0.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.926,0.926,0.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.954,0.954,0.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.916,0.916,0.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.931,0.931,0.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.932,0.932,0.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.943,0.943,0.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.958,0.958,0.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.882,0.882,0.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.904,0.904,0.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.914,0.914,0.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.963,0.963,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.101,1.101,1.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.045,1.045,1.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.041,1.041,1.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.744,0.744,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.768,0.768,0.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.772,0.772,0.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.874,0.874,0.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.872,0.872,0.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.927,0.927,0.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.917,0.917,0.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.949,0.949,0.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.866,0.866,0.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.852,0.852,0.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.870,0.870,0.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.912,0.912,0.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.928,0.928,0.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.925,0.925,0.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.940,0.940,0.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.963,0.963,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.982,0.982,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.916,0.916,0.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.928,0.928,0.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.943,0.943,0.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.920,0.920,0.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.904,0.904,0.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.931,0.931,0.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.982,0.982,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.937,0.937,0.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.947,0.947,0.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.946,0.946,0.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.670,0.670,0.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.819,0.819,0.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.845,0.845,0.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.858,0.858,0.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.913,0.913,0.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.923,0.923,0.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.914,0.914,0.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.101,1.101,1.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.051,1.051,1.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.038,1.038,1.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.041,1.041,1.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.140,1.140,1.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.128,1.128,1.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.075,1.075,1.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.078,1.078,1.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.064,1.064,1.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.058,1.058,1.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.045,1.045,1.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.038,1.038,1.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.075,1.075,1.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.969,0.969,0.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.376,1.376,1.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.884,0.884,0.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.810,0.810,0.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.928,0.928,0.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.062,1.062,1.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.046,1.046,1.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: nan | Acc: 3.906,3.906,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.960,0.960,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.051,1.051,1.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.947,0.947,0.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.949,0.949,0.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.949,0.949,0.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.744,0.744,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.762,0.762,0.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.935,0.935,0.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.907,0.907,0.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.905,0.905,0.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.969,0.969,0.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.089,1.089,1.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.907,0.907,0.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.943,0.943,0.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.903,0.903,0.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.903,0.903,0.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.925,0.925,0.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.940,0.940,0.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.955,0.955,0.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.376,1.376,1.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.200,1.200,1.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.065,1.065,1.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.064,1.064,1.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.066,1.066,1.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.073,1.073,1.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.800,0.800,0.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.794,0.794,0.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.887,0.887,0.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.874,0.874,0.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.903,0.903,0.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.960,0.960,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.595,0.595,0.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.743,0.743,0.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.768,0.768,0.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.829,0.829,0.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.851,0.851,0.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.910,0.910,0.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.859,0.859,0.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.886,0.886,0.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.919,0.919,0.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.911,0.911,0.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.931,0.931,0.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.960,0.960,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.105,1.105,1.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.838,0.838,0.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.730,0.730,0.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.762,0.762,0.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.797,0.797,0.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.878,0.878,0.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.881,0.881,0.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.898,0.898,0.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.910,0.910,0.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.901,0.901,0.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.891,0.891,0.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.929,0.929,0.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.927,0.927,0.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.960,0.960,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.076,1.076,1.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.091,1.091,1.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.080,1.080,1.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.068,1.068,1.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.062,1.062,1.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.061,1.061,1.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.064,1.064,1.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.060,1.060,1.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.078,1.078,1.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.054,1.054,1.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.049,1.049,1.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.933,0.933,0.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.917,0.917,0.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.982,0.982,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.124,1.124,1.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.089,1.089,1.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.080,1.080,1.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.041,1.041,1.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.051,1.051,1.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.041,1.041,1.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.920,0.920,0.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.917,0.917,0.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.875,0.875,0.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.917,0.917,0.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.963,0.963,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.916,0.916,0.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.049,1.049,1.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.076,1.076,1.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.080,1.080,1.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.038,1.038,1.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.915,0.915,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.913,0.913,0.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.904,0.904,0.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.925,0.925,0.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.228,1.228,1.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.124,1.124,1.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.127,1.127,1.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.942,0.942,0.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.877,0.877,0.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: nan | Acc: 3.125,3.125,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.089,1.089,1.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.119,1.119,1.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.064,1.064,1.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.070,1.070,1.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.818,0.818,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.982,0.982,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.982,0.982,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.105,1.105,1.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.167,1.167,1.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.122,1.122,1.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.058,1.058,1.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.045,1.045,1.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.857,0.857,0.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.832,0.832,0.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.849,0.849,0.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.851,0.851,0.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.927,0.927,0.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.954,0.954,0.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.969,0.969,0.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.838,0.838,0.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.075,1.075,1.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.038,1.038,1.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.061,1.061,1.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.060,1.060,1.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.054,1.054,1.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.041,1.041,1.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.931,0.931,0.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.963,0.963,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.181,1.181,1.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.109,1.109,1.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.819,0.819,0.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.105,1.105,1.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.076,1.076,1.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.090,1.090,1.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.061,1.061,1.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.670,0.670,0.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.667,0.667,0.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.768,0.768,0.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.887,0.887,0.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.928,0.928,0.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.943,0.943,0.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.162,1.162,1.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.265,1.265,1.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.124,1.124,1.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.165,1.165,1.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.128,1.128,1.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.059,1.059,1.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.058,1.058,1.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.068,1.068,1.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.045,1.045,1.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.707,0.707,0.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.838,0.838,0.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.845,0.845,0.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.916,0.916,0.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.064,1.064,1.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.062,1.062,1.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.818,0.818,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.051,1.051,1.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.884,0.884,0.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.071,1.071,1.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.098,1.098,1.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.049,1.049,1.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.077,1.077,1.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.105,1.105,1.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.076,1.076,1.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.075,1.075,1.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.092,1.092,1.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.082,1.082,1.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.073,1.073,1.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.054,1.054,1.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.877,0.877,0.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.887,0.887,0.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.969,0.969,0.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: nan | Acc: 3.125,3.125,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.071,1.071,1.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.091,1.091,1.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.059,1.059,1.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.070,1.070,1.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.061,1.061,1.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.061,1.061,1.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.178,1.178,1.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.215,1.215,1.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.137,1.137,1.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.117,1.117,1.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.103,1.103,1.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.096,1.096,1.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.046,1.046,1.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.839,0.839,0.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.913,0.913,0.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.960,0.960,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.907,0.907,0.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.920,0.920,0.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.949,0.949,0.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.414,1.414,1.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.181,1.181,1.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.109,1.109,1.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.265,1.265,1.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.157,1.157,1.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.162,1.162,1.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.077,1.077,1.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.066,1.066,1.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.049,1.049,1.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.030,1.030,1.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.030,1.030,1.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.200,1.200,1.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.140,1.140,1.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.128,1.128,1.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.129,1.129,1.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.078,1.078,1.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.065,1.065,1.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.190,1.190,1.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.200,1.200,1.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.217,1.217,1.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.157,1.157,1.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.122,1.122,1.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.078,1.078,1.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.069,1.069,1.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.046,1.046,1.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.832,0.832,0.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.887,0.887,0.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.843,0.843,0.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.885,0.885,0.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.943,0.943,0.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.946,0.946,0.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.960,0.960,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.942,0.942,0.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.414,1.414,1.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.239,1.239,1.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.090,1.090,1.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.046,1.046,1.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.525,1.525,1.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.296,1.296,1.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.217,1.217,1.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.225,1.225,1.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.160,1.160,1.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.091,1.091,1.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.058,1.058,1.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.049,1.049,1.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.954,0.954,0.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.963,0.963,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: nan | Acc: 3.125,3.125,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.955,0.955,0.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.890,0.890,0.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.910,0.910,0.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.903,0.903,0.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.924,0.924,0.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.929,0.929,0.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.969,0.969,0.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.744,0.744,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.051,1.051,1.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.045,1.045,1.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.030,1.030,1.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.041,1.041,1.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.955,0.955,0.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.943,0.943,0.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.912,0.912,0.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.958,0.958,0.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.929,0.929,0.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.931,0.931,0.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.927,0.927,0.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.924,0.924,0.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.933,0.933,0.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.919,0.919,0.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.937,0.937,0.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.949,0.949,0.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.101,1.101,1.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.087,1.087,1.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.088,1.088,1.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.069,1.069,1.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.068,1.068,1.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.060,1.060,1.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.071,1.071,1.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.083,1.083,1.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.123,1.123,1.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.097,1.097,1.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.084,1.084,1.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.064,1.064,1.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.744,0.744,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.800,0.800,0.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.884,0.884,0.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.839,0.839,0.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.890,0.890,0.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.885,0.885,0.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.917,0.917,0.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.958,0.958,0.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.178,1.178,1.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.167,1.167,1.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.937,0.937,0.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.952,0.952,0.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.105,1.105,1.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.061,1.061,1.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.137,1.137,1.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.078,1.078,1.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.069,1.069,1.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.049,1.049,1.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.744,0.744,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.838,0.838,0.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.794,0.794,0.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.829,0.829,0.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.843,0.843,0.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.878,0.878,0.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.800,0.800,0.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.794,0.794,0.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.829,0.829,0.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.923,0.923,0.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.917,0.917,0.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.913,0.913,0.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.878,0.878,0.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.881,0.881,0.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.912,0.912,0.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.889,0.889,0.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.906,0.906,0.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.923,0.923,0.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.921,0.921,0.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.952,0.952,0.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.076,1.076,1.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.937,0.937,0.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.915,0.915,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.920,0.920,0.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.915,0.915,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.061,1.061,1.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.060,1.060,1.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.186,1.186,1.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.106,1.106,1.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.065,1.065,1.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.069,1.069,1.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.068,1.068,1.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.092,1.092,1.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.069,1.069,1.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.030,1.030,1.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.943,0.943,0.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.942,0.942,0.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.924,0.924,0.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.933,0.933,0.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.924,0.924,0.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.928,0.928,0.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.926,0.926,0.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.937,0.937,0.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.954,0.954,0.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.957,0.957,0.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.943,0.943,0.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.877,0.877,0.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.913,0.913,0.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.891,0.891,0.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.870,0.870,0.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.927,0.927,0.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.937,0.937,0.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.952,0.952,0.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.949,0.949,0.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.926,0.926,0.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.882,0.882,0.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.910,0.910,0.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.887,0.887,0.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.922,0.922,0.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.941,0.941,0.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.929,0.929,0.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.923,0.923,0.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.921,0.921,0.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.931,0.931,0.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.600,1.600,1.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.239,1.239,1.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.089,1.089,1.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.090,1.090,1.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.098,1.098,1.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.045,1.045,1.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.143,1.143,1.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.083,1.083,1.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.030,1.030,1.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.228,1.228,1.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.105,1.105,1.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.046,1.046,1.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.064,1.064,1.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.038,1.038,1.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.023,1.023,1.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.061,1.061,1.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.058,1.058,1.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.818,0.818,0.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.871,0.871,0.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.801,0.801,0.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.890,0.890,0.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.910,0.910,0.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.898,0.898,0.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.890,0.890,0.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.925,0.925,0.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.302,1.302,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.916,0.916,0.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.039,1.039,1.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.670,0.670,0.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.877,0.877,0.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.871,0.871,0.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.916,0.916,0.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.092,1.092,1.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.069,1.069,1.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.302,1.302,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.105,1.105,1.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.954,0.954,0.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.963,0.963,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.051,1.051,1.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.190,1.190,1.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.258,1.258,1.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.165,1.165,1.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.080,1.080,1.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.083,1.083,1.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.078,1.078,1.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.069,1.069,1.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.077,1.077,1.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.066,1.066,1.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.030,1.030,1.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.059,1.059,1.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.058,1.058,1.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.051,1.051,1.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.058,1.058,1.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.030,1.030,1.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.128,1.128,1.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.122,1.122,1.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.117,1.117,1.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.072,1.072,1.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.070,1.070,1.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.084,1.084,1.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.068,1.068,1.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.982,0.982,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.960,0.960,0.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.969,0.969,0.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.913,0.913,0.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.744,0.744,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.838,0.838,0.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.858,0.858,0.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.928,0.928,0.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.964,0.964,0.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.051,1.051,1.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.033,1.033,1.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.744,0.744,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.934,0.934,0.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.948,0.948,0.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.265,1.265,1.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.162,1.162,1.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.153,1.153,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.128,1.128,1.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.097,1.097,1.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.092,1.092,1.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.088,1.088,1.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.078,1.078,1.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.031,1.031,1.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.046,1.046,1.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.707,0.707,0.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.955,0.955,0.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.920,0.920,0.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.962,0.962,0.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.190,1.190,1.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.982,0.982,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.916,0.916,0.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.969,0.969,0.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.857,0.857,0.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.956,0.956,0.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.990,0.990,0.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.228,1.228,1.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.988,0.988,0.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.038,1.038,1.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.050,1.050,1.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.858,0.858,0.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.810,0.810,0.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.797,0.797,0.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.768,0.768,0.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.820,0.820,0.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.869,0.869,0.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.859,0.859,0.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.875,0.875,0.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.873,0.873,0.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.895,0.895,0.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.931,0.931,0.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.920,0.920,0.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.955,0.955,0.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.045,1.045,1.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.041,1.041,1.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.076,1.076,1.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.080,1.080,1.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.021,1.021,1.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.190,1.190,1.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.970,0.970,0.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.976,0.976,0.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.982,0.982,0.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.896,0.896,0.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.858,0.858,0.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.897,0.897,0.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.890,0.890,0.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.878,0.878,0.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.870,0.870,0.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.927,0.927,0.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.915,0.915,0.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.913,0.913,0.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.937,0.937,0.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.958,0.958,0.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.376,1.376,1.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.334,1.334,1.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.140,1.140,1.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.090,1.090,1.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.052,1.052,1.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.011,1.011,1.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.967,0.967,0.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.877,0.877,0.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.974,0.974,0.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.980,0.980,0.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.987,0.987,0.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.994,0.994,0.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.992,0.992,0.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.989,0.989,0.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.277,1.277,1.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.191,1.191,1.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.254,1.254,1.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.176,1.176,1.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.149,1.149,1.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.136,1.136,1.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.116,1.116,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.100,1.100,1.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.064,1.064,1.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.041,1.041,1.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.071,1.071,1.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.046,1.046,1.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.909,0.909,0.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.014,1.014,1.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.958,0.958,0.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.952,0.952,0.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.959,0.959,0.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.000,1.000,1.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: nan | Acc: 2.344,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.228,1.228,1.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.143,1.143,1.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.230,1.230,1.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.167,1.167,1.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.122,1.122,1.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.111,1.111,1.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.026,1.026,1.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.190,1.190,1.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.968,0.968,0.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.981,0.981,0.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.985,0.985,0.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.950,0.950,0.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.007,1.007,1.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.002,1.002,1.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.973,0.973,0.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.984,0.984,0.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.963,0.963,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 0.978,0.978,0.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.955,0.955,0.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.944,0.944,0.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.936,0.936,0.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.975,0.975,0.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.001,1.001,1.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.020,1.020,1.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.893,0.893,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 0.920,0.920,0.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 0.930,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.942,0.942,0.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 0.951,0.951,0.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 0.963,0.963,0.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 0.979,0.979,0.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 0.983,0.983,0.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 0.966,0.966,0.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 0.955,0.955,0.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.965,0.965,0.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 0.971,0.971,0.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.004,1.004,1.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.190,1.190,1.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.999,0.999,0.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.051,1.051,1.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.085,1.085,1.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.053,1.053,1.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.065,1.065,1.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.071,1.071,1.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.054,1.054,1.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.038,1.038,1.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.034,1.034,1.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.228,1.228,1.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.972,0.972,0.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.114,1.114,1.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.085,1.085,1.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.047,1.047,1.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.032,1.032,1.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 0.995,0.995,0.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.029,1.029,1.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 0.986,0.986,0.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: nan | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.079,1.079,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.162,1.162,1.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.037,1.037,1.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 1.071,1.071,1.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.027,1.027,1.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 0.997,0.997,0.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.024,1.024,1.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.057,1.057,1.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.048,1.048,1.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.015,1.015,1.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.017,1.017,1.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.019,1.019,1.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.003,1.003,1.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: nan | Acc: 0.000,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 0.744,0.744,0.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 0.953,0.953,0.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.063,1.063,1.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: nan | Acc: 0.993,0.993,0.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: nan | Acc: 1.036,1.036,1.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: nan | Acc: 1.043,1.043,1.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: nan | Acc: 1.070,1.070,1.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: nan | Acc: 1.018,1.018,1.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: nan | Acc: 1.028,1.028,1.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: nan | Acc: 1.010,1.010,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: nan | Acc: 0.998,0.998,0.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: nan | Acc: 1.008,1.008,1.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: nan | Acc: 1.009,1.009,1.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 0.856,0.856,0.856,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 0.991,0.991,0.991,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 60 | Loss: nan | Acc: 0.961,0.961,0.961,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 80 | Loss: nan | Acc: 0.945,0.945,0.945,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 100 | Loss: nan | Acc: 1.044,1.044,1.044,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 120 | Loss: nan | Acc: 1.046,1.046,1.046,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 140 | Loss: nan | Acc: 1.086,1.086,1.086,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 160 | Loss: nan | Acc: 1.077,1.077,1.077,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 180 | Loss: nan | Acc: 1.096,1.096,1.096,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.066 0.934
Batch: 200 | Loss: nan | Acc: 1.088,1.088,1.088,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.159 0.841
Batch: 220 | Loss: nan | Acc: 1.117,1.117,1.117,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.235 0.765
Batch: 240 | Loss: nan | Acc: 1.092,1.092,1.092,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.299 0.701
Batch: 260 | Loss: nan | Acc: 1.060,1.060,1.060,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.352 0.648
Batch: 280 | Loss: nan | Acc: 1.040,1.040,1.040,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.399 0.601
Batch: 300 | Loss: nan | Acc: 1.025,1.025,1.025,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.439 0.561
Batch: 320 | Loss: nan | Acc: 1.022,1.022,1.022,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.473 0.526
Batch: 340 | Loss: nan | Acc: 1.013,1.013,1.013,% | Adaptive Acc: 0.000% | clf_exit: 0.003 0.501 0.496
Batch: 360 | Loss: nan | Acc: 1.006,1.006,1.006,% | Adaptive Acc: 0.000% | clf_exit: 0.003 0.529 0.468
Batch: 380 | Loss: nan | Acc: 1.005,1.005,1.005,% | Adaptive Acc: 0.000% | clf_exit: 0.003 0.554 0.444
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.000% | clf_exit: 0.000 0.524 0.475
model is save as models/resnet56_dense_cifar100_adaptive0_circles10_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475
Batch: 0 | Loss: nan | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 1.562% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: nan | Acc: 1.042,1.042,1.042,% | Adaptive Acc: 0.595% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: nan | Acc: 1.067,1.067,1.067,% | Adaptive Acc: 0.381% | clf_exit: 0.000 0.292 0.707
Batch: 60 | Loss: nan | Acc: 1.012,1.012,1.012,% | Adaptive Acc: 0.256% | clf_exit: 0.000 0.524 0.475







Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 14.221 |  Acc: 1.456,1.242,1.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 13.958 |  Acc: 1.560,1.030,1.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 14.017 |  Acc: 1.832,1.362,1.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 15.123 |  Acc: 1.840,1.390,1.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 13.858 |  Acc: 1.976,1.218,1.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 15.718 |  Acc: 2.240,1.680,1.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 13.720 |  Acc: 2.228,1.748,2.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 13.712 |  Acc: 2.210,2.120,1.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 13.598 |  Acc: 2.164,1.836,1.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 13.593 |  Acc: 2.560,1.250,2.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 13.473 |  Acc: 2.284,1.850,1.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 13.445 |  Acc: 2.210,2.060,2.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 13.328 |  Acc: 2.348,2.008,2.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 13.254 |  Acc: 2.460,2.110,2.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 13.186 |  Acc: 2.488,2.194,2.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 13.125 |  Acc: 2.640,2.310,2.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 13.082 |  Acc: 2.590,2.300,2.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 13.029 |  Acc: 2.620,2.440,2.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 13.014 |  Acc: 2.650,2.238,2.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 12.974 |  Acc: 2.820,2.190,2.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 12.940 |  Acc: 2.688,2.386,2.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 12.886 |  Acc: 2.670,2.250,2.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 13.049 |  Acc: 2.664,2.432,2.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 13.043 |  Acc: 2.970,2.630,2.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 12.950 |  Acc: 2.760,2.558,2.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 12.998 |  Acc: 2.390,2.430,2.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 12.867 |  Acc: 2.850,2.614,2.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 12.912 |  Acc: 2.820,2.780,2.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 12.804 |  Acc: 2.860,2.648,2.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 12.826 |  Acc: 3.150,2.660,2.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 12.741 |  Acc: 2.860,2.772,2.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 13.057 |  Acc: 2.290,2.510,2.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 12.703 |  Acc: 2.898,2.926,2.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 12.775 |  Acc: 2.720,2.010,2.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 12.800 |  Acc: 2.898,2.870,2.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 26.472 |  Acc: 3.020,1.060,2.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 12.945 |  Acc: 2.882,2.912,2.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 13.184 |  Acc: 1.790,2.640,2.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 12.863 |  Acc: 2.990,2.848,2.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 12.846 |  Acc: 3.010,3.190,2.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 12.769 |  Acc: 3.034,3.016,2.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 12.836 |  Acc: 2.960,2.950,3.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 12.677 |  Acc: 3.040,3.008,2.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 13.527 |  Acc: 1.870,3.260,3.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 12.637 |  Acc: 3.500,3.228,2.662,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 12.684 |  Acc: 4.490,3.290,3.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 12.575 |  Acc: 5.904,3.004,2.536,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 12.743 |  Acc: 5.760,2.980,1.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 12.604 |  Acc: 7.096,3.004,2.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 13.328 |  Acc: 6.400,2.470,1.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 12.551 |  Acc: 8.024,2.938,2.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 12.698 |  Acc: 6.370,2.760,2.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 12.378 |  Acc: 9.634,3.124,2.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 12.319 |  Acc: 9.570,3.200,2.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 12.293 |  Acc: 10.680,3.100,2.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 12.542 |  Acc: 9.190,2.550,2.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 12.221 |  Acc: 11.540,2.934,2.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 12.477 |  Acc: 9.910,2.810,2.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 12.124 |  Acc: 12.500,2.988,2.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 18.485 |  Acc: 11.340,1.920,2.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 12.170 |  Acc: 13.266,2.918,2.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 12.813 |  Acc: 7.860,2.530,2.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 12.041 |  Acc: 14.058,2.728,2.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 12.926 |  Acc: 11.850,2.450,2.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 11.968 |  Acc: 14.894,2.824,2.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 12.121 |  Acc: 10.860,3.200,2.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 11.873 |  Acc: 15.590,2.866,2.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 12.932 |  Acc: 7.590,2.010,2.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 11.781 |  Acc: 16.030,5.694,2.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 11.835 |  Acc: 11.470,9.900,2.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 11.082 |  Acc: 16.042,16.672,2.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 12.980 |  Acc: 4.280,7.150,2.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 10.753 |  Acc: 16.262,21.168,2.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 13.565 |  Acc: 4.850,8.310,3.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 10.485 |  Acc: 17.080,24.074,2.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 11.534 |  Acc: 8.870,16.050,2.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 10.270 |  Acc: 17.838,26.982,2.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 11.209 |  Acc: 10.980,19.960,2.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 10.081 |  Acc: 18.322,29.722,2.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 11.610 |  Acc: 10.940,21.190,2.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 9.950 |  Acc: 18.588,31.724,2.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 10.704 |  Acc: 11.750,24.870,2.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 9.854 |  Acc: 19.300,33.480,2.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 10.955 |  Acc: 11.640,24.340,2.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 9.752 |  Acc: 20.476,35.062,2.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 10.979 |  Acc: 13.900,26.550,1.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 9.665 |  Acc: 21.114,36.498,2.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 11.676 |  Acc: 9.410,23.350,1.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 9.802 |  Acc: 22.616,36.788,2.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 11.147 |  Acc: 13.580,26.320,2.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 9.572 |  Acc: 24.780,38.740,2.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 10.099 |  Acc: 19.890,34.740,2.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 9.378 |  Acc: 26.598,40.318,2.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 11.185 |  Acc: 13.520,27.860,2.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 9.232 |  Acc: 27.794,41.382,2.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 10.171 |  Acc: 19.100,34.490,2.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 9.127 |  Acc: 28.646,42.580,2.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 11.215 |  Acc: 14.770,26.430,3.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 9.032 |  Acc: 29.592,43.528,2.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 10.248 |  Acc: 20.110,32.760,3.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 9.040 |  Acc: 30.292,44.094,2.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 10.735 |  Acc: 17.790,31.860,1.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 8.985 |  Acc: 30.818,44.276,2.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 10.359 |  Acc: 18.870,33.670,2.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 8.887 |  Acc: 31.294,45.162,2.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 10.776 |  Acc: 17.570,30.250,2.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 8.836 |  Acc: 31.958,45.796,2.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 9.819 |  Acc: 22.290,37.700,2.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 8.752 |  Acc: 32.726,46.468,2.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 10.491 |  Acc: 18.530,31.920,2.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 8.695 |  Acc: 33.434,47.058,2.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 10.938 |  Acc: 14.990,29.990,2.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 8.626 |  Acc: 33.762,47.624,3.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 9.515 |  Acc: 25.510,38.910,3.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 8.582 |  Acc: 34.238,47.900,2.942,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 9.912 |  Acc: 21.170,36.430,3.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 8.540 |  Acc: 34.758,48.528,3.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 10.010 |  Acc: 20.510,37.980,2.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 8.512 |  Acc: 34.744,48.586,2.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 10.205 |  Acc: 18.780,36.230,2.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 8.682 |  Acc: 35.168,48.792,2.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 10.235 |  Acc: 24.400,37.410,1.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 8.653 |  Acc: 35.034,49.030,2.746,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 10.501 |  Acc: 19.380,35.020,2.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 8.564 |  Acc: 35.748,49.402,2.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 10.718 |  Acc: 20.620,32.790,2.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 8.508 |  Acc: 35.680,49.942,2.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 10.812 |  Acc: 22.730,36.130,1.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 8.429 |  Acc: 36.430,50.236,2.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 10.025 |  Acc: 22.630,39.270,2.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 8.362 |  Acc: 36.594,51.102,2.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 9.789 |  Acc: 25.550,37.950,2.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 8.338 |  Acc: 36.516,51.342,2.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 10.361 |  Acc: 21.630,35.350,2.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 8.303 |  Acc: 36.826,51.372,3.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 9.823 |  Acc: 26.610,36.960,3.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 8.285 |  Acc: 37.022,51.542,2.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 9.986 |  Acc: 25.300,35.730,2.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 8.322 |  Acc: 36.914,51.562,3.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 10.876 |  Acc: 14.110,35.740,3.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 8.343 |  Acc: 37.096,51.656,3.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 10.358 |  Acc: 19.970,36.410,2.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 8.281 |  Acc: 37.598,52.240,3.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 9.616 |  Acc: 25.660,41.310,3.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 8.275 |  Acc: 37.708,52.166,3.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 9.687 |  Acc: 23.270,38.260,2.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 8.271 |  Acc: 37.898,52.236,3.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 9.912 |  Acc: 25.860,40.830,2.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 8.299 |  Acc: 37.954,52.624,2.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 9.532 |  Acc: 26.470,40.420,2.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 8.271 |  Acc: 38.052,52.550,2.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 9.595 |  Acc: 22.030,43.750,3.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 8.225 |  Acc: 38.112,53.110,3.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 9.128 |  Acc: 27.130,45.860,3.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 8.235 |  Acc: 38.248,53.330,3.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 10.518 |  Acc: 21.700,34.720,2.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 8.260 |  Acc: 38.158,53.188,2.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 9.612 |  Acc: 25.480,42.730,2.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 8.225 |  Acc: 38.052,53.350,3.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 10.214 |  Acc: 21.580,36.880,3.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 8.197 |  Acc: 38.318,53.430,2.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 9.478 |  Acc: 25.740,41.550,2.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 8.150 |  Acc: 38.692,53.734,2.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 10.549 |  Acc: 21.410,33.750,2.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 8.118 |  Acc: 38.852,53.856,2.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 9.418 |  Acc: 26.610,43.270,2.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 8.082 |  Acc: 38.976,54.354,2.914,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 9.533 |  Acc: 27.070,40.580,2.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 8.074 |  Acc: 38.776,53.798,2.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 9.208 |  Acc: 26.990,42.870,2.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 8.056 |  Acc: 38.938,54.520,2.886,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 10.164 |  Acc: 22.570,34.600,2.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 8.030 |  Acc: 38.876,54.750,2.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 10.414 |  Acc: 22.980,31.950,3.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 8.030 |  Acc: 38.890,54.478,2.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 9.494 |  Acc: 23.060,43.830,2.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 8.015 |  Acc: 39.088,54.772,2.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 9.527 |  Acc: 25.480,41.830,2.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 8.003 |  Acc: 39.270,54.840,2.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 9.333 |  Acc: 26.120,43.290,2.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 7.988 |  Acc: 39.348,54.926,2.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 9.415 |  Acc: 28.480,42.580,3.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 7.987 |  Acc: 39.276,55.090,2.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 8.961 |  Acc: 29.040,45.280,3.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 7.969 |  Acc: 39.430,55.140,2.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 9.373 |  Acc: 27.260,42.880,2.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 7.953 |  Acc: 39.650,55.452,3.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 12.934 |  Acc: 14.340,29.930,1.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 8.018 |  Acc: 39.438,55.436,3.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 10.400 |  Acc: 23.000,40.820,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 8.522 |  Acc: 40.002,55.854,1.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 10.006 |  Acc: 26.950,41.290,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 8.470 |  Acc: 40.332,56.412,1.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 11.187 |  Acc: 21.110,32.340,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 8.447 |  Acc: 39.998,56.248,1.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 9.986 |  Acc: 26.450,40.960,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 8.432 |  Acc: 40.260,56.056,1.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 10.155 |  Acc: 24.040,43.660,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 8.421 |  Acc: 40.052,56.154,1.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 10.622 |  Acc: 20.460,39.590,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 8.424 |  Acc: 39.908,56.248,1.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 10.836 |  Acc: 18.370,37.880,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 8.417 |  Acc: 40.082,56.176,1.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 9.617 |  Acc: 26.690,46.490,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 8.416 |  Acc: 40.272,56.512,1.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 9.519 |  Acc: 27.330,46.930,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 8.412 |  Acc: 40.116,56.152,1.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 9.982 |  Acc: 24.200,44.580,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 8.407 |  Acc: 40.242,56.254,1.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 9.924 |  Acc: 27.710,40.940,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 8.395 |  Acc: 40.304,56.888,1.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 9.917 |  Acc: 27.780,42.730,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 8.403 |  Acc: 40.058,56.346,1.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 10.695 |  Acc: 23.310,38.310,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 8.394 |  Acc: 40.126,56.438,1.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 10.464 |  Acc: 25.910,37.830,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 8.389 |  Acc: 40.434,56.586,1.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 10.156 |  Acc: 23.570,42.190,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 8.375 |  Acc: 40.552,56.862,1.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 9.708 |  Acc: 28.450,45.710,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 8.380 |  Acc: 40.558,56.526,1.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 11.258 |  Acc: 19.620,33.910,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 8.364 |  Acc: 40.738,56.936,1.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 14.012 |  Acc: 10.420,23.620,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 8.360 |  Acc: 40.870,56.930,1.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 9.867 |  Acc: 27.610,42.180,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 8.372 |  Acc: 40.784,56.696,1.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 9.652 |  Acc: 28.480,43.100,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 8.372 |  Acc: 40.658,56.966,1.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 10.039 |  Acc: 25.920,40.870,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 8.366 |  Acc: 40.528,56.962,1.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 9.916 |  Acc: 27.180,42.590,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 8.349 |  Acc: 40.818,57.112,1.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 10.730 |  Acc: 22.130,38.630,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 8.361 |  Acc: 40.882,57.364,1.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 10.739 |  Acc: 21.340,36.640,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 8.387 |  Acc: 40.838,57.032,0.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 9.468 |  Acc: 30.410,44.680,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 8.375 |  Acc: 40.886,57.304,0.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 9.661 |  Acc: 28.560,43.590,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 8.368 |  Acc: 40.990,57.612,0.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 9.584 |  Acc: 28.370,44.590,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 8.378 |  Acc: 40.750,57.136,0.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 10.367 |  Acc: 25.600,39.470,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 8.358 |  Acc: 40.874,57.612,0.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 10.069 |  Acc: 26.390,41.840,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 8.364 |  Acc: 40.922,57.342,0.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 9.925 |  Acc: 24.440,44.250,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 8.357 |  Acc: 41.182,57.682,0.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 10.667 |  Acc: 21.260,40.440,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 8.348 |  Acc: 40.518,57.552,1.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 10.050 |  Acc: 24.900,41.950,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 8.325 |  Acc: 40.784,57.442,1.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 9.795 |  Acc: 24.950,45.220,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 8.282 |  Acc: 41.108,57.476,1.662,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 9.850 |  Acc: 27.730,41.810,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 8.193 |  Acc: 40.728,57.584,2.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 10.599 |  Acc: 22.370,37.970,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 8.177 |  Acc: 40.778,57.186,2.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 10.099 |  Acc: 26.610,40.590,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 8.137 |  Acc: 40.990,57.326,2.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 10.053 |  Acc: 25.380,42.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 8.099 |  Acc: 40.744,57.122,2.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 9.406 |  Acc: 28.630,47.340,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 8.065 |  Acc: 40.932,57.438,2.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 9.829 |  Acc: 25.900,45.430,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: nan |  Acc: 36.268,51.202,2.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='resnet56_dense', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit: 0.003 0.565 0.433
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.000% | clf_exit: 0.000 0.627 0.373

circles: 0
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 1
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 2
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 3
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 4
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 5
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 6
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 7
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 8
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 9
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
circles: 10
Testing: Epoch=299 | Loss: nan |  Acc: 1.000,1.000,1.000,% | Adaptive Acc:0.200% | clf_exit: 0.000 0.627 0.373
