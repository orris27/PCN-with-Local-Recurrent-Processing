==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
******************************
IMPORTANT: attention 2 is default to yes!!!!!!
******************************
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=16, out_features=16, bias=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (BN1d): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=48, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (attention_1): ScanLayer(
        (conv): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=48, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention_2): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=16, out_features=4, bias=True)
          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=4, out_features=16, bias=True)
          (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=96, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=96, out_features=100, bias=True)
      (attention): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=32, out_features=8, bias=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=8, out_features=32, bias=True)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 14.942 | Acc: 2.344,0.000,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.575 | Acc: 1.376,1.153,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.333 | Acc: 1.296,1.200,1.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.195 | Acc: 1.165,1.358,1.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.093 | Acc: 1.196,1.534,1.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.017 | Acc: 1.346,1.679,2.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.954 | Acc: 1.608,1.776,2.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.902 | Acc: 1.695,1.834,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.847 | Acc: 1.825,1.975,2.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.795 | Acc: 1.878,2.011,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.747 | Acc: 1.959,2.087,3.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.703 | Acc: 2.061,2.135,3.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.663 | Acc: 2.140,2.198,3.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.619 | Acc: 2.212,2.356,3.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.578 | Acc: 2.263,2.410,4.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.544 | Acc: 2.372,2.479,4.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.508 | Acc: 2.468,2.577,4.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.472 | Acc: 2.552,2.623,4.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.434 | Acc: 2.658,2.740,5.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.397 | Acc: 2.778,2.848,5.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.647 | Acc: 3.125,5.469,7.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.720 | Acc: 3.981,3.869,8.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.744 | Acc: 4.021,4.154,8.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.753 | Acc: 3.893,3.970,8.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 12.546 | Acc: 6.250,6.250,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.721 | Acc: 4.092,4.539,9.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.695 | Acc: 4.192,4.802,9.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.675 | Acc: 4.431,4.969,9.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.649 | Acc: 4.514,5.179,10.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.614 | Acc: 4.541,5.430,10.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.592 | Acc: 4.487,5.488,10.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.552 | Acc: 4.538,5.729,10.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.527 | Acc: 4.561,5.818,11.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.504 | Acc: 4.584,6.017,11.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.486 | Acc: 4.586,6.153,11.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.469 | Acc: 4.560,6.197,11.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.442 | Acc: 4.587,6.338,11.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.427 | Acc: 4.598,6.507,11.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.408 | Acc: 4.593,6.631,11.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.391 | Acc: 4.597,6.689,12.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.372 | Acc: 4.639,6.759,12.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.350 | Acc: 4.749,6.903,12.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.333 | Acc: 4.763,6.947,12.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.313 | Acc: 4.813,7.025,12.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.972 | Acc: 6.250,8.594,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.934 | Acc: 5.357,7.999,14.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.928 | Acc: 5.431,8.441,14.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.940 | Acc: 5.392,8.594,14.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 11.822 | Acc: 3.125,8.594,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.933 | Acc: 4.799,9.301,14.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.886 | Acc: 5.450,9.375,14.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.852 | Acc: 5.674,9.413,15.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.834 | Acc: 5.739,9.520,15.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.817 | Acc: 5.956,9.406,15.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.791 | Acc: 6.179,9.446,15.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.776 | Acc: 6.189,9.536,16.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.744 | Acc: 6.289,9.753,16.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.738 | Acc: 6.285,9.686,16.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.730 | Acc: 6.273,9.663,16.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.715 | Acc: 6.303,9.707,16.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.708 | Acc: 6.325,9.758,16.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.700 | Acc: 6.328,9.839,16.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.681 | Acc: 6.320,9.889,16.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.666 | Acc: 6.411,9.933,16.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.653 | Acc: 6.513,10.061,16.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.630 | Acc: 6.591,10.193,16.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.611 | Acc: 6.720,10.319,16.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.598 | Acc: 6.756,10.328,16.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.274 | Acc: 10.156,12.500,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.340 | Acc: 7.403,10.938,17.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.336 | Acc: 7.565,10.690,17.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.364 | Acc: 7.390,10.656,17.277,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 11.900 | Acc: 2.344,7.812,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.163 | Acc: 8.445,12.612,19.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.187 | Acc: 7.965,12.367,19.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.169 | Acc: 7.889,12.756,20.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.144 | Acc: 7.851,12.992,20.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.152 | Acc: 7.959,12.887,20.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.137 | Acc: 8.026,12.881,20.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.131 | Acc: 8.051,12.960,20.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.110 | Acc: 8.181,13.087,20.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.091 | Acc: 8.382,13.070,20.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.085 | Acc: 8.361,13.204,20.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.073 | Acc: 8.343,13.129,20.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.060 | Acc: 8.406,13.223,20.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.046 | Acc: 8.432,13.284,20.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.041 | Acc: 8.455,13.265,20.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.030 | Acc: 8.495,13.276,20.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.016 | Acc: 8.616,13.362,20.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.999 | Acc: 8.646,13.531,20.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.988 | Acc: 8.646,13.565,20.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.975 | Acc: 8.663,13.656,20.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.751 | Acc: 10.156,18.750,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.766 | Acc: 9.412,14.658,21.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.735 | Acc: 9.489,14.729,21.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.764 | Acc: 9.260,14.524,21.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 10.281 | Acc: 13.281,10.156,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.646 | Acc: 10.268,14.955,22.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.584 | Acc: 10.080,15.149,22.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.552 | Acc: 10.310,15.318,22.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.571 | Acc: 10.002,15.403,22.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.563 | Acc: 10.017,15.424,22.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.550 | Acc: 10.066,15.567,22.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.538 | Acc: 10.173,15.680,22.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.542 | Acc: 10.137,15.664,22.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.532 | Acc: 10.092,15.625,23.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.512 | Acc: 10.137,15.780,23.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.499 | Acc: 10.241,15.883,23.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.490 | Acc: 10.244,15.832,23.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.471 | Acc: 10.339,15.996,23.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.462 | Acc: 10.398,16.061,23.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.453 | Acc: 10.488,16.097,23.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.445 | Acc: 10.541,16.143,23.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.433 | Acc: 10.605,16.255,23.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.426 | Acc: 10.684,16.343,23.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.413 | Acc: 10.755,16.373,23.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.231 | Acc: 10.938,19.531,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.352 | Acc: 10.119,16.629,23.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.300 | Acc: 10.309,16.825,23.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.318 | Acc: 10.297,17.162,23.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 10.370 | Acc: 9.375,14.062,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.076 | Acc: 12.574,17.894,26.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.096 | Acc: 12.748,17.702,25.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.065 | Acc: 12.846,17.969,25.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.034 | Acc: 12.934,18.056,25.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.033 | Acc: 12.778,18.340,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.013 | Acc: 12.823,18.485,25.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.021 | Acc: 12.921,18.617,25.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.016 | Acc: 12.840,18.634,26.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.004 | Acc: 12.949,18.694,26.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.983 | Acc: 12.966,18.769,26.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.964 | Acc: 13.009,18.948,26.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.937 | Acc: 13.129,19.110,26.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.920 | Acc: 13.215,19.232,26.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.909 | Acc: 13.220,19.273,26.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.898 | Acc: 13.248,19.285,26.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.890 | Acc: 13.289,19.295,26.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.886 | Acc: 13.309,19.268,26.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.872 | Acc: 13.370,19.395,26.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.866 | Acc: 13.357,19.386,26.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.083 | Acc: 15.625,22.656,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.005 | Acc: 13.876,17.225,26.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.965 | Acc: 13.891,16.883,26.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.006 | Acc: 14.062,16.957,26.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 9.098 | Acc: 14.062,22.656,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.463 | Acc: 15.067,20.536,28.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.515 | Acc: 14.482,20.770,29.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.530 | Acc: 14.780,20.671,29.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.479 | Acc: 15.500,21.393,29.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.489 | Acc: 15.377,21.272,29.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.476 | Acc: 15.476,21.384,29.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.464 | Acc: 15.553,21.504,29.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.446 | Acc: 15.664,21.661,29.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.427 | Acc: 15.724,21.763,29.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.418 | Acc: 15.831,21.817,29.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.411 | Acc: 15.911,21.889,29.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.402 | Acc: 15.995,21.878,29.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.398 | Acc: 15.972,21.962,29.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.388 | Acc: 16.087,22.017,29.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.381 | Acc: 16.227,22.070,29.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.372 | Acc: 16.207,22.084,29.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.360 | Acc: 16.285,22.134,29.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.343 | Acc: 16.318,22.171,29.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.332 | Acc: 16.367,22.234,29.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.334 | Acc: 23.438,24.219,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.369 | Acc: 16.741,22.582,30.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.344 | Acc: 16.616,22.790,30.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.364 | Acc: 16.701,22.823,29.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 9.697 | Acc: 14.062,22.656,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.953 | Acc: 18.676,24.479,32.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.976 | Acc: 18.369,24.714,31.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.958 | Acc: 18.289,24.475,32.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.936 | Acc: 18.297,24.682,32.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.956 | Acc: 18.263,24.466,32.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.974 | Acc: 18.117,24.296,32.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.975 | Acc: 18.207,24.385,32.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.952 | Acc: 18.425,24.549,32.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.949 | Acc: 18.469,24.577,32.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.945 | Acc: 18.556,24.553,32.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.933 | Acc: 18.640,24.632,32.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.925 | Acc: 18.624,24.569,32.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.921 | Acc: 18.600,24.572,32.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.923 | Acc: 18.572,24.605,32.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.915 | Acc: 18.540,24.663,32.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.912 | Acc: 18.662,24.706,32.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.902 | Acc: 18.681,24.748,32.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.894 | Acc: 18.798,24.890,32.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.883 | Acc: 18.850,24.936,32.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.976 | Acc: 17.188,28.906,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.052 | Acc: 17.225,23.475,32.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.031 | Acc: 17.740,23.285,32.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.043 | Acc: 17.392,23.028,32.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 8.864 | Acc: 24.219,25.781,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.623 | Acc: 20.536,26.042,35.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.633 | Acc: 20.084,25.991,35.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.604 | Acc: 19.608,26.037,35.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.595 | Acc: 19.859,26.061,34.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.629 | Acc: 19.794,25.951,34.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.592 | Acc: 19.977,26.117,34.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.579 | Acc: 20.135,26.274,34.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.587 | Acc: 20.065,26.262,34.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.585 | Acc: 20.161,26.278,34.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.571 | Acc: 20.351,26.481,35.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.561 | Acc: 20.383,26.548,35.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.560 | Acc: 20.371,26.598,35.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.550 | Acc: 20.537,26.751,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.540 | Acc: 20.510,26.757,35.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.534 | Acc: 20.564,26.806,35.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.523 | Acc: 20.634,26.845,35.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.513 | Acc: 20.775,26.936,35.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.509 | Acc: 20.845,26.976,35.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.502 | Acc: 20.973,27.143,35.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.348 | Acc: 14.062,23.438,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.340 | Acc: 16.853,22.619,30.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.262 | Acc: 16.997,22.485,30.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.271 | Acc: 16.522,22.682,29.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 8.759 | Acc: 20.312,28.125,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.382 | Acc: 21.615,28.497,37.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.306 | Acc: 22.008,28.487,36.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.308 | Acc: 22.362,28.817,37.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.274 | Acc: 22.068,28.723,37.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.270 | Acc: 22.045,28.991,37.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.259 | Acc: 22.275,28.939,37.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.245 | Acc: 22.335,28.801,37.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.240 | Acc: 22.336,28.863,37.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.239 | Acc: 22.177,28.850,37.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.238 | Acc: 22.240,28.863,37.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.232 | Acc: 22.204,28.828,37.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.231 | Acc: 22.371,28.845,37.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.231 | Acc: 22.399,28.840,37.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.227 | Acc: 22.476,28.851,37.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.225 | Acc: 22.501,28.911,37.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.209 | Acc: 22.622,29.018,37.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.203 | Acc: 22.615,28.977,37.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.195 | Acc: 22.645,29.012,37.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.195 | Acc: 22.671,29.013,37.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.982 | Acc: 16.406,26.562,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.282 | Acc: 16.629,22.879,33.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.360 | Acc: 16.425,23.037,32.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.378 | Acc: 16.445,23.028,32.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 8.642 | Acc: 23.438,23.438,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.032 | Acc: 23.735,30.618,39.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.996 | Acc: 23.704,29.897,39.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.953 | Acc: 23.783,30.174,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.928 | Acc: 23.900,30.257,40.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.915 | Acc: 24.203,30.159,40.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.923 | Acc: 24.109,30.062,40.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.934 | Acc: 23.958,30.197,40.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.933 | Acc: 23.971,30.221,40.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.937 | Acc: 24.033,30.309,40.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.929 | Acc: 23.919,30.410,40.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.918 | Acc: 24.081,30.493,40.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.910 | Acc: 24.173,30.602,40.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.913 | Acc: 24.189,30.574,40.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.909 | Acc: 24.227,30.666,40.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.906 | Acc: 24.203,30.765,40.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.902 | Acc: 24.160,30.768,40.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.898 | Acc: 24.187,30.769,40.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.899 | Acc: 24.117,30.763,40.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.902 | Acc: 24.116,30.739,40.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.552 | Acc: 26.562,28.906,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.686 | Acc: 20.312,27.009,36.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.642 | Acc: 20.427,26.810,37.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.621 | Acc: 20.300,27.024,37.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 7.217 | Acc: 29.688,28.906,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.652 | Acc: 25.930,31.845,42.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.670 | Acc: 25.762,32.165,41.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.702 | Acc: 25.077,31.801,41.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.698 | Acc: 25.077,31.944,42.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.699 | Acc: 25.101,31.830,41.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.685 | Acc: 25.207,31.921,42.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.659 | Acc: 25.399,32.103,42.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.677 | Acc: 25.136,31.973,42.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.674 | Acc: 25.224,32.031,42.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.675 | Acc: 25.241,32.090,41.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.695 | Acc: 25.103,31.961,41.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.697 | Acc: 25.214,32.005,41.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.684 | Acc: 25.287,32.094,41.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.683 | Acc: 25.231,32.070,41.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.673 | Acc: 25.317,32.164,41.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.669 | Acc: 25.309,32.211,41.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.675 | Acc: 25.222,32.237,41.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.675 | Acc: 25.292,32.241,41.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.670 | Acc: 25.295,32.222,41.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.767 | Acc: 23.438,27.344,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.966 | Acc: 20.796,24.628,33.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.969 | Acc: 20.427,25.057,33.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.949 | Acc: 20.236,25.115,33.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 7.415 | Acc: 26.562,31.250,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.444 | Acc: 27.121,34.673,44.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.409 | Acc: 27.039,34.794,44.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.461 | Acc: 26.255,34.746,44.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.454 | Acc: 26.524,34.703,44.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.429 | Acc: 26.493,34.677,44.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.435 | Acc: 26.530,34.459,44.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.445 | Acc: 26.385,34.364,44.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.459 | Acc: 26.271,33.992,44.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.485 | Acc: 26.131,33.879,43.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.503 | Acc: 25.976,33.664,43.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.509 | Acc: 26.025,33.618,43.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.496 | Acc: 26.180,33.665,43.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.500 | Acc: 26.212,33.639,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.485 | Acc: 26.321,33.794,43.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.478 | Acc: 26.402,33.921,43.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.480 | Acc: 26.314,33.835,43.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.480 | Acc: 26.219,33.734,43.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.477 | Acc: 26.270,33.843,43.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.472 | Acc: 26.280,33.883,43.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.995 | Acc: 24.219,34.375,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.955 | Acc: 24.702,31.250,41.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.022 | Acc: 24.085,30.107,40.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.029 | Acc: 23.937,29.931,40.279,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 7.173 | Acc: 28.906,35.156,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.361 | Acc: 25.558,34.189,44.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.372 | Acc: 26.562,34.718,45.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.339 | Acc: 26.960,34.759,45.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.345 | Acc: 26.842,34.568,44.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.344 | Acc: 26.795,34.537,45.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.321 | Acc: 26.982,34.666,44.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.316 | Acc: 26.978,34.691,45.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.319 | Acc: 26.868,34.875,45.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.317 | Acc: 26.843,34.936,45.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.331 | Acc: 26.761,34.927,45.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.319 | Acc: 26.912,35.040,45.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.305 | Acc: 27.036,35.192,45.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.292 | Acc: 27.149,35.315,45.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.290 | Acc: 27.177,35.315,45.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.287 | Acc: 27.159,35.317,45.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.284 | Acc: 27.159,35.395,45.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.281 | Acc: 27.218,35.429,45.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.279 | Acc: 27.259,35.392,45.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.276 | Acc: 27.268,35.392,45.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.952 | Acc: 17.969,35.938,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.161 | Acc: 21.131,29.762,38.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.188 | Acc: 21.799,29.802,38.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.221 | Acc: 21.657,29.380,38.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 8.385 | Acc: 21.094,23.438,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.356 | Acc: 27.902,34.784,46.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.316 | Acc: 27.572,35.290,46.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.304 | Acc: 27.600,35.579,45.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.269 | Acc: 27.459,35.561,45.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.242 | Acc: 27.584,35.357,45.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.250 | Acc: 27.376,35.376,45.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.230 | Acc: 27.200,35.627,45.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.204 | Acc: 27.451,35.675,46.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.184 | Acc: 27.512,35.912,46.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.175 | Acc: 27.721,36.062,46.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.172 | Acc: 27.708,36.029,46.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.173 | Acc: 27.691,35.954,46.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.175 | Acc: 27.580,35.940,46.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.173 | Acc: 27.600,35.960,46.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.161 | Acc: 27.764,36.054,46.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.153 | Acc: 27.762,36.110,46.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.153 | Acc: 27.845,36.148,46.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.139 | Acc: 27.945,36.295,46.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.132 | Acc: 27.979,36.407,46.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.773 | Acc: 29.688,35.938,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.739 | Acc: 25.967,30.804,41.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.799 | Acc: 25.896,30.488,41.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.778 | Acc: 26.089,30.494,42.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 6.756 | Acc: 25.781,35.938,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.922 | Acc: 28.646,37.872,47.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.895 | Acc: 29.116,38.434,48.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.937 | Acc: 29.047,37.795,47.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.967 | Acc: 28.848,37.529,47.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.971 | Acc: 28.759,37.856,48.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.984 | Acc: 28.764,37.461,48.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.985 | Acc: 28.834,37.572,48.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.980 | Acc: 28.901,37.655,48.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.982 | Acc: 28.889,37.547,48.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.978 | Acc: 28.976,37.655,48.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.984 | Acc: 28.913,37.691,48.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.988 | Acc: 28.968,37.617,48.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.989 | Acc: 28.930,37.632,48.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.992 | Acc: 28.934,37.558,48.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.986 | Acc: 28.909,37.612,48.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.979 | Acc: 28.904,37.748,48.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.982 | Acc: 28.902,37.780,48.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.980 | Acc: 28.943,37.853,48.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.978 | Acc: 28.972,37.861,48.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.916 | Acc: 28.125,31.250,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.938 | Acc: 22.842,32.812,43.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.996 | Acc: 22.332,32.374,41.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.983 | Acc: 22.310,32.364,41.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 6.847 | Acc: 21.875,39.062,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.778 | Acc: 30.022,40.960,49.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.848 | Acc: 29.402,39.729,49.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.864 | Acc: 29.150,39.716,49.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.830 | Acc: 29.311,39.757,49.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.856 | Acc: 29.092,39.325,49.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.846 | Acc: 29.087,39.463,49.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.845 | Acc: 29.261,39.533,49.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.842 | Acc: 29.154,39.485,49.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.842 | Acc: 29.118,39.460,49.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.843 | Acc: 29.225,39.556,49.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.843 | Acc: 29.140,39.427,49.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.829 | Acc: 29.204,39.568,49.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.825 | Acc: 29.316,39.532,49.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.832 | Acc: 29.226,39.385,49.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.833 | Acc: 29.194,39.379,49.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.833 | Acc: 29.154,39.325,49.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.836 | Acc: 29.106,39.305,49.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.841 | Acc: 29.064,39.218,49.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.841 | Acc: 29.083,39.261,49.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.991 | Acc: 25.000,36.719,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.837 | Acc: 22.656,34.152,43.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.944 | Acc: 22.752,33.117,41.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.938 | Acc: 22.477,33.453,42.303,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 7.329 | Acc: 32.812,41.406,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.671 | Acc: 29.836,40.699,50.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.621 | Acc: 30.030,41.368,51.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.627 | Acc: 30.097,41.112,51.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.625 | Acc: 30.266,41.049,51.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.632 | Acc: 30.082,41.166,51.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.640 | Acc: 30.010,41.045,51.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.655 | Acc: 30.086,40.957,50.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.670 | Acc: 29.974,40.848,50.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.674 | Acc: 30.050,40.828,50.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.673 | Acc: 30.127,40.792,50.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.678 | Acc: 29.977,40.777,50.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.681 | Acc: 29.950,40.751,50.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.692 | Acc: 29.840,40.544,50.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.702 | Acc: 29.885,40.539,50.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.702 | Acc: 29.895,40.534,50.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.700 | Acc: 29.999,40.557,50.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.703 | Acc: 29.965,40.556,50.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.708 | Acc: 29.923,40.590,50.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.708 | Acc: 29.934,40.664,50.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.914 | Acc: 28.906,41.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.657 | Acc: 23.363,34.301,45.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.699 | Acc: 23.285,33.956,44.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.700 | Acc: 23.130,33.978,44.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 6.250 | Acc: 38.281,44.531,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.610 | Acc: 30.357,40.513,51.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.567 | Acc: 29.954,41.197,51.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.532 | Acc: 30.315,41.445,52.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.570 | Acc: 29.842,40.963,51.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.548 | Acc: 29.935,41.074,51.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.555 | Acc: 30.217,41.206,51.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.561 | Acc: 30.341,41.307,51.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.569 | Acc: 30.498,41.392,51.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.565 | Acc: 30.590,41.557,51.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.577 | Acc: 30.636,41.472,51.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.571 | Acc: 30.614,41.512,51.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.567 | Acc: 30.592,41.630,51.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.565 | Acc: 30.657,41.592,51.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.575 | Acc: 30.524,41.456,51.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.582 | Acc: 30.469,41.474,51.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.584 | Acc: 30.469,41.435,51.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.574 | Acc: 30.560,41.603,51.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.573 | Acc: 30.529,41.582,51.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.585 | Acc: 30.473,41.513,51.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.338 | Acc: 27.344,39.062,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.632 | Acc: 22.693,35.714,45.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.639 | Acc: 22.580,35.175,45.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.654 | Acc: 22.131,35.336,45.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 5.982 | Acc: 28.906,41.406,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.456 | Acc: 31.064,42.411,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.398 | Acc: 31.669,43.483,54.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.424 | Acc: 31.609,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.428 | Acc: 31.549,43.104,53.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.436 | Acc: 31.606,43.015,53.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.434 | Acc: 31.541,42.794,53.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.440 | Acc: 31.533,42.852,53.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.445 | Acc: 31.439,42.702,52.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.448 | Acc: 31.496,42.671,52.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.451 | Acc: 31.355,42.557,52.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.457 | Acc: 31.377,42.587,52.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.457 | Acc: 31.367,42.518,52.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.456 | Acc: 31.313,42.451,52.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.462 | Acc: 31.278,42.446,52.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.464 | Acc: 31.279,42.444,52.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.473 | Acc: 31.136,42.360,52.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.475 | Acc: 31.069,42.449,52.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.480 | Acc: 31.023,42.404,52.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.478 | Acc: 31.088,42.440,52.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.357 | Acc: 28.125,36.719,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.636 | Acc: 22.954,36.347,45.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.672 | Acc: 23.438,35.785,45.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.621 | Acc: 23.502,35.848,45.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 5.932 | Acc: 38.281,53.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.326 | Acc: 32.329,44.122,54.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.285 | Acc: 32.184,44.474,54.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.348 | Acc: 31.788,43.584,54.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.359 | Acc: 31.655,43.721,54.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.387 | Acc: 31.088,43.448,54.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.390 | Acc: 31.411,43.472,53.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.376 | Acc: 31.577,43.545,53.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.373 | Acc: 31.609,43.488,53.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.375 | Acc: 31.720,43.513,53.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.377 | Acc: 31.674,43.532,53.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.378 | Acc: 31.600,43.492,53.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.379 | Acc: 31.542,43.413,53.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.369 | Acc: 31.612,43.478,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.368 | Acc: 31.639,43.539,53.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.365 | Acc: 31.606,43.628,53.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.374 | Acc: 31.598,43.567,53.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.374 | Acc: 31.582,43.578,53.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.369 | Acc: 31.607,43.642,53.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.363 | Acc: 31.625,43.695,53.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.238 | Acc: 31.250,40.625,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.440 | Acc: 25.967,37.760,47.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.516 | Acc: 25.648,37.157,47.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.532 | Acc: 25.576,36.732,46.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 6.576 | Acc: 22.656,41.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.281 | Acc: 33.185,45.164,54.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.278 | Acc: 32.603,45.084,54.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.257 | Acc: 32.326,44.762,54.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.269 | Acc: 32.282,44.425,54.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.248 | Acc: 32.495,44.709,54.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.258 | Acc: 32.432,44.764,54.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.263 | Acc: 32.286,44.592,54.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.246 | Acc: 32.342,44.556,54.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.244 | Acc: 32.377,44.700,54.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.258 | Acc: 32.206,44.407,54.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.270 | Acc: 32.311,44.436,54.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.280 | Acc: 32.216,44.291,54.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.276 | Acc: 32.271,44.409,54.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.283 | Acc: 32.151,44.351,54.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.283 | Acc: 32.153,44.376,54.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.283 | Acc: 32.133,44.373,54.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.285 | Acc: 32.125,44.382,54.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.285 | Acc: 32.081,44.432,54.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.286 | Acc: 32.066,44.404,54.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.899 | Acc: 29.688,41.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.924 | Acc: 28.013,39.881,49.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.018 | Acc: 27.915,38.929,48.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.991 | Acc: 28.535,39.114,48.489,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 6.637 | Acc: 28.125,42.188,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.047 | Acc: 33.668,46.094,56.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.094 | Acc: 33.041,45.979,56.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.098 | Acc: 32.953,45.978,56.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.154 | Acc: 32.851,45.187,55.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.147 | Acc: 33.068,45.312,55.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.153 | Acc: 33.071,45.241,55.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.169 | Acc: 32.740,45.019,55.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.178 | Acc: 32.594,44.949,55.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.203 | Acc: 32.450,44.786,54.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.192 | Acc: 32.389,44.959,55.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.190 | Acc: 32.367,44.955,55.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.197 | Acc: 32.446,44.911,54.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.191 | Acc: 32.438,44.953,54.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.193 | Acc: 32.437,44.887,54.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.185 | Acc: 32.517,44.972,55.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.183 | Acc: 32.562,45.033,55.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.181 | Acc: 32.538,45.005,55.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.191 | Acc: 32.486,44.966,54.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.188 | Acc: 32.507,44.968,55.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.385 | Acc: 22.656,42.969,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.783 | Acc: 22.954,37.165,47.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.919 | Acc: 22.447,36.833,46.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.937 | Acc: 22.439,37.026,46.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 6.192 | Acc: 30.469,40.625,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.963 | Acc: 33.966,46.726,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.975 | Acc: 33.937,47.180,58.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.023 | Acc: 33.145,46.350,57.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.016 | Acc: 32.967,46.229,57.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.049 | Acc: 32.983,46.256,56.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.067 | Acc: 32.980,46.081,56.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.053 | Acc: 33.023,46.149,57.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.049 | Acc: 33.021,46.293,56.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.052 | Acc: 33.097,46.335,56.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.063 | Acc: 32.995,46.179,56.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.065 | Acc: 32.968,46.253,56.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.070 | Acc: 32.913,46.191,56.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.069 | Acc: 32.875,46.112,56.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.081 | Acc: 32.896,46.097,56.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.089 | Acc: 32.846,46.018,56.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.086 | Acc: 32.876,46.079,56.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.093 | Acc: 32.856,46.014,56.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.088 | Acc: 32.947,46.094,56.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.092 | Acc: 32.905,46.014,56.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.985 | Acc: 23.438,37.500,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.349 | Acc: 20.238,33.929,45.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.356 | Acc: 19.588,33.746,44.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.345 | Acc: 19.237,33.530,44.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 5.700 | Acc: 39.844,50.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.979 | Acc: 33.296,45.536,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.978 | Acc: 34.165,46.056,56.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.991 | Acc: 33.927,46.004,56.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.981 | Acc: 34.356,46.460,57.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.977 | Acc: 34.197,46.651,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.973 | Acc: 33.755,46.965,57.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.970 | Acc: 33.671,46.958,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.956 | Acc: 33.691,46.967,57.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.972 | Acc: 33.602,46.905,57.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.972 | Acc: 33.555,46.999,57.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.975 | Acc: 33.534,47.031,57.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.979 | Acc: 33.506,47.118,57.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.988 | Acc: 33.405,47.037,57.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.990 | Acc: 33.366,46.900,56.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.996 | Acc: 33.451,46.867,56.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.996 | Acc: 33.355,46.834,56.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.002 | Acc: 33.337,46.788,56.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.012 | Acc: 33.202,46.702,56.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.020 | Acc: 33.126,46.559,56.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.572 | Acc: 31.250,41.406,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.017 | Acc: 26.414,39.993,51.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.005 | Acc: 27.115,40.454,51.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.017 | Acc: 26.767,39.946,50.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 5.612 | Acc: 37.500,49.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.757 | Acc: 35.491,49.368,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.884 | Acc: 34.261,49.085,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.881 | Acc: 34.349,48.527,58.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.878 | Acc: 34.163,48.061,58.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.888 | Acc: 34.282,48.066,58.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.871 | Acc: 34.336,48.063,57.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.881 | Acc: 34.209,47.878,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.885 | Acc: 34.181,47.899,58.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.894 | Acc: 34.069,47.691,57.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.914 | Acc: 33.920,47.458,57.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.919 | Acc: 33.725,47.462,57.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.929 | Acc: 33.779,47.442,57.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.925 | Acc: 33.731,47.474,57.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.927 | Acc: 33.736,47.495,57.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.924 | Acc: 33.804,47.555,57.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.928 | Acc: 33.757,47.447,57.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.930 | Acc: 33.747,47.546,57.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.931 | Acc: 33.702,47.505,57.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.937 | Acc: 33.629,47.505,57.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.342 | Acc: 29.688,42.969,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.211 | Acc: 27.939,37.760,47.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.290 | Acc: 27.954,37.176,46.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.273 | Acc: 27.843,37.513,46.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 6.320 | Acc: 30.469,42.969,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.892 | Acc: 33.147,48.586,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.867 | Acc: 33.498,48.342,58.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.791 | Acc: 33.901,49.257,59.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.778 | Acc: 34.481,49.392,59.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.803 | Acc: 34.205,49.211,59.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.809 | Acc: 34.323,49.264,59.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.807 | Acc: 34.336,49.391,59.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.803 | Acc: 34.331,49.350,59.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.795 | Acc: 34.492,49.305,59.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.811 | Acc: 34.445,48.978,59.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.813 | Acc: 34.485,49.000,59.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.826 | Acc: 34.401,48.784,58.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.830 | Acc: 34.345,48.758,58.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.829 | Acc: 34.369,48.702,58.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.840 | Acc: 34.295,48.528,58.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.841 | Acc: 34.251,48.518,58.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.849 | Acc: 34.194,48.492,58.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.849 | Acc: 34.182,48.531,58.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.850 | Acc: 34.190,48.450,58.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.264 | Acc: 28.125,38.281,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.216 | Acc: 26.190,40.588,49.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.264 | Acc: 26.543,40.187,49.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.199 | Acc: 26.703,40.561,49.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 5.838 | Acc: 38.281,46.094,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.652 | Acc: 34.673,49.405,60.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.630 | Acc: 34.947,50.133,61.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.675 | Acc: 34.734,49.910,60.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.674 | Acc: 34.857,49.672,60.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.717 | Acc: 34.630,48.979,59.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.762 | Acc: 34.323,48.618,59.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.778 | Acc: 34.092,48.532,59.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.789 | Acc: 34.084,48.462,59.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.782 | Acc: 34.094,48.675,59.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.789 | Acc: 34.037,48.651,59.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.798 | Acc: 33.972,48.455,59.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.801 | Acc: 34.041,48.447,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.799 | Acc: 34.133,48.438,58.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.800 | Acc: 34.242,48.432,58.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.799 | Acc: 34.282,48.508,58.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.794 | Acc: 34.292,48.562,58.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.792 | Acc: 34.428,48.648,59.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.795 | Acc: 34.433,48.639,59.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.796 | Acc: 34.465,48.626,58.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.543 | Acc: 17.969,39.844,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.829 | Acc: 19.792,39.249,50.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.989 | Acc: 19.493,38.700,49.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.014 | Acc: 19.249,38.345,49.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 5.935 | Acc: 29.688,46.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.596 | Acc: 34.933,49.888,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.690 | Acc: 34.337,49.771,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.714 | Acc: 33.824,49.091,59.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.687 | Acc: 34.163,49.412,60.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.722 | Acc: 34.066,48.971,59.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.734 | Acc: 33.975,48.915,59.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.739 | Acc: 34.081,48.958,59.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.724 | Acc: 34.161,49.180,59.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.729 | Acc: 34.241,49.201,59.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.733 | Acc: 34.274,49.238,59.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.730 | Acc: 34.315,49.261,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.736 | Acc: 34.365,49.154,59.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.738 | Acc: 34.417,49.174,59.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.749 | Acc: 34.406,49.108,59.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.754 | Acc: 34.479,49.118,59.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.757 | Acc: 34.426,49.087,59.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.745 | Acc: 34.533,49.191,59.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.745 | Acc: 34.531,49.115,59.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.747 | Acc: 34.564,49.135,59.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.900 | Acc: 27.344,38.281,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.986 | Acc: 22.247,37.277,49.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.063 | Acc: 22.351,36.928,49.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.099 | Acc: 22.195,36.475,48.655,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 5.501 | Acc: 36.719,52.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.603 | Acc: 34.301,50.335,62.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.618 | Acc: 34.184,49.790,61.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.631 | Acc: 34.490,49.808,61.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.622 | Acc: 34.742,50.183,61.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.639 | Acc: 34.754,50.085,60.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.644 | Acc: 34.717,50.071,60.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.646 | Acc: 34.602,50.061,60.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.667 | Acc: 34.627,49.985,60.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.677 | Acc: 34.643,49.978,60.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.690 | Acc: 34.635,49.833,60.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.679 | Acc: 34.718,49.936,60.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.680 | Acc: 34.839,50.042,60.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.684 | Acc: 34.791,50.039,60.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.676 | Acc: 34.917,50.078,60.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.677 | Acc: 34.956,50.031,60.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.677 | Acc: 34.910,50.037,60.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.673 | Acc: 34.987,50.096,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.691 | Acc: 34.901,49.935,59.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.690 | Acc: 34.865,49.924,59.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.619 | Acc: 32.812,37.500,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.519 | Acc: 26.674,37.612,46.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.655 | Acc: 26.601,36.643,46.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.700 | Acc: 26.396,36.552,45.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 4.954 | Acc: 36.719,55.469,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.545 | Acc: 34.673,50.112,61.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.553 | Acc: 35.290,50.534,61.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.565 | Acc: 35.297,49.629,61.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.608 | Acc: 34.915,49.363,60.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.586 | Acc: 35.133,49.714,60.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.588 | Acc: 35.059,49.716,60.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.602 | Acc: 35.195,49.884,60.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.607 | Acc: 35.219,50.087,60.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.602 | Acc: 35.389,50.164,60.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.606 | Acc: 35.358,50.027,60.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.609 | Acc: 35.347,50.035,60.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.621 | Acc: 35.263,50.010,60.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.622 | Acc: 35.399,50.042,60.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.623 | Acc: 35.398,50.022,60.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.632 | Acc: 35.356,50.016,60.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.633 | Acc: 35.283,50.085,60.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.636 | Acc: 35.262,50.137,60.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.634 | Acc: 35.325,50.240,60.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.634 | Acc: 35.357,50.271,60.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.679 | Acc: 32.812,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.561 | Acc: 29.613,43.713,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.564 | Acc: 28.792,43.407,55.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.591 | Acc: 29.162,43.494,54.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 5.688 | Acc: 34.375,43.750,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.647 | Acc: 34.561,49.814,60.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.592 | Acc: 35.099,50.114,60.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.567 | Acc: 35.246,50.730,60.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.574 | Acc: 35.311,50.868,60.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.568 | Acc: 35.272,50.890,60.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.566 | Acc: 35.498,50.768,61.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.566 | Acc: 35.450,50.770,61.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.576 | Acc: 35.389,50.718,61.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.590 | Acc: 35.376,50.552,61.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.591 | Acc: 35.483,50.735,61.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.573 | Acc: 35.623,50.827,61.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.580 | Acc: 35.558,50.804,61.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.579 | Acc: 35.527,50.799,61.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.584 | Acc: 35.412,50.751,61.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.579 | Acc: 35.553,50.789,61.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.578 | Acc: 35.480,50.681,61.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.572 | Acc: 35.550,50.708,61.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.567 | Acc: 35.585,50.777,61.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.583 | Acc: 35.433,50.724,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.744 | Acc: 32.031,42.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.061 | Acc: 27.455,41.518,51.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.123 | Acc: 27.287,41.044,51.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.111 | Acc: 27.421,40.715,51.076,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 5.441 | Acc: 35.156,52.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.324 | Acc: 38.021,53.385,64.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.386 | Acc: 36.814,51.791,63.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.393 | Acc: 36.642,51.883,63.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.389 | Acc: 36.815,52.286,62.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.400 | Acc: 36.696,52.065,62.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.410 | Acc: 36.583,52.014,62.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.428 | Acc: 36.475,51.806,62.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.435 | Acc: 36.306,51.917,62.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.428 | Acc: 36.231,51.891,62.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.433 | Acc: 36.202,51.803,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.442 | Acc: 36.146,51.796,62.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.452 | Acc: 36.113,51.754,62.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.460 | Acc: 36.090,51.682,62.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.461 | Acc: 36.015,51.704,62.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.474 | Acc: 35.935,51.586,61.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.480 | Acc: 35.940,51.511,61.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.486 | Acc: 35.841,51.439,61.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.496 | Acc: 35.702,51.298,61.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.503 | Acc: 35.665,51.220,61.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.387 | Acc: 28.906,39.062,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.993 | Acc: 29.836,40.885,50.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.111 | Acc: 29.154,39.825,50.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.090 | Acc: 29.086,40.561,50.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 4.796 | Acc: 42.188,56.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.392 | Acc: 37.909,52.939,62.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.481 | Acc: 35.995,51.277,61.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.413 | Acc: 36.668,51.806,62.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.441 | Acc: 36.786,51.755,62.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.442 | Acc: 36.417,51.825,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.455 | Acc: 36.370,51.737,62.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.461 | Acc: 36.386,51.973,62.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.477 | Acc: 36.297,51.829,62.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.467 | Acc: 36.369,51.834,62.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.471 | Acc: 36.427,51.730,62.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.481 | Acc: 36.280,51.651,62.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.465 | Acc: 36.395,51.854,62.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.468 | Acc: 36.315,51.841,62.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.472 | Acc: 36.196,51.827,62.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.469 | Acc: 36.233,51.822,62.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.465 | Acc: 36.303,51.891,62.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.459 | Acc: 36.352,52.005,62.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.471 | Acc: 36.240,51.924,62.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.481 | Acc: 36.151,51.845,62.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.502 | Acc: 29.688,45.312,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.045 | Acc: 26.116,42.374,53.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.075 | Acc: 26.105,42.245,52.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.107 | Acc: 25.999,41.919,52.100,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.480 | Acc: 31.250,51.562,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.349 | Acc: 36.124,52.865,64.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.374 | Acc: 35.709,52.096,63.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.360 | Acc: 36.283,52.613,63.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.353 | Acc: 36.217,52.344,63.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.354 | Acc: 36.216,52.290,63.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.361 | Acc: 36.280,52.247,62.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.373 | Acc: 36.431,52.233,62.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.374 | Acc: 36.617,52.378,62.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.376 | Acc: 36.559,52.521,62.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.394 | Acc: 36.493,52.390,62.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.408 | Acc: 36.365,52.255,62.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.426 | Acc: 36.181,52.178,62.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.439 | Acc: 36.084,52.053,62.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.450 | Acc: 35.988,51.955,62.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.443 | Acc: 36.070,52.053,62.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.442 | Acc: 36.137,52.071,62.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.444 | Acc: 36.107,52.089,62.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.444 | Acc: 36.163,52.112,62.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.446 | Acc: 36.110,52.092,62.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.230 | Acc: 30.469,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.722 | Acc: 28.051,44.680,54.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.801 | Acc: 27.496,44.131,53.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.779 | Acc: 27.510,44.595,54.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 5.297 | Acc: 28.906,53.125,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.216 | Acc: 36.719,53.943,65.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.244 | Acc: 37.119,54.078,65.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.297 | Acc: 37.129,53.765,64.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.274 | Acc: 37.201,53.655,64.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.287 | Acc: 36.928,53.458,64.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.277 | Acc: 36.835,53.577,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.302 | Acc: 36.641,53.286,63.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.306 | Acc: 36.505,53.450,63.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.318 | Acc: 36.542,53.336,63.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.335 | Acc: 36.478,53.230,63.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.333 | Acc: 36.627,53.224,63.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.336 | Acc: 36.524,53.170,63.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.340 | Acc: 36.560,53.104,63.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.347 | Acc: 36.521,53.061,63.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.357 | Acc: 36.462,52.930,63.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.372 | Acc: 36.397,52.775,63.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.370 | Acc: 36.423,52.793,63.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.365 | Acc: 36.442,52.809,63.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.378 | Acc: 36.393,52.672,63.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.552 | Acc: 31.250,50.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.645 | Acc: 28.906,44.606,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.609 | Acc: 28.392,44.722,54.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.601 | Acc: 28.151,44.647,54.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 5.594 | Acc: 32.812,43.750,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.191 | Acc: 36.830,55.022,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.286 | Acc: 36.166,53.849,64.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.266 | Acc: 36.475,53.445,64.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.245 | Acc: 36.535,53.405,64.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.267 | Acc: 36.580,53.403,64.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.281 | Acc: 36.454,53.209,64.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.310 | Acc: 36.392,53.114,63.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.298 | Acc: 36.530,53.164,63.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.291 | Acc: 36.589,53.233,63.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.305 | Acc: 36.575,53.106,63.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.309 | Acc: 36.500,53.107,63.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.306 | Acc: 36.540,53.170,63.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.315 | Acc: 36.410,53.218,63.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.324 | Acc: 36.418,53.169,63.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.320 | Acc: 36.483,53.208,63.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.331 | Acc: 36.402,53.140,63.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.339 | Acc: 36.361,52.999,63.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.338 | Acc: 36.327,53.019,63.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.346 | Acc: 36.315,53.002,63.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.831 | Acc: 32.812,44.531,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.726 | Acc: 26.972,44.345,52.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.764 | Acc: 27.210,43.921,52.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.808 | Acc: 27.152,43.942,52.152,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 5.025 | Acc: 38.281,53.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.230 | Acc: 37.946,54.129,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.204 | Acc: 37.652,54.649,65.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.225 | Acc: 37.474,54.060,64.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.264 | Acc: 37.114,53.723,64.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.267 | Acc: 36.997,53.620,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.266 | Acc: 36.990,53.616,64.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.274 | Acc: 36.951,53.585,64.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.289 | Acc: 36.864,53.324,64.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.305 | Acc: 36.701,53.172,63.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.305 | Acc: 36.769,53.094,63.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.302 | Acc: 36.800,53.192,63.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.298 | Acc: 36.732,53.287,63.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.304 | Acc: 36.560,53.275,63.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.313 | Acc: 36.546,53.189,63.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.317 | Acc: 36.516,53.122,63.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.323 | Acc: 36.427,52.955,63.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.319 | Acc: 36.526,52.962,63.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.320 | Acc: 36.511,52.922,63.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.316 | Acc: 36.626,52.971,63.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.759 | Acc: 26.562,48.438,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.864 | Acc: 24.591,43.080,53.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.946 | Acc: 24.905,42.664,53.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.975 | Acc: 24.731,42.111,53.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 5.142 | Acc: 40.625,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.237 | Acc: 37.463,54.167,64.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.230 | Acc: 37.614,53.544,64.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.233 | Acc: 37.103,53.381,64.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.226 | Acc: 37.625,53.627,64.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.263 | Acc: 37.198,52.978,64.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.276 | Acc: 37.184,53.067,63.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.279 | Acc: 37.195,53.197,64.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.275 | Acc: 37.165,53.358,63.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.278 | Acc: 37.094,53.259,63.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.289 | Acc: 36.968,53.032,63.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.279 | Acc: 37.002,53.174,63.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.283 | Acc: 37.085,53.206,63.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.296 | Acc: 36.988,53.089,63.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.295 | Acc: 37.019,53.003,63.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.298 | Acc: 37.007,52.928,63.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.302 | Acc: 37.089,52.962,63.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.303 | Acc: 37.179,52.969,63.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.300 | Acc: 37.208,53.075,63.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.300 | Acc: 37.178,53.125,63.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.547 | Acc: 32.031,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.426 | Acc: 30.432,45.908,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.490 | Acc: 30.069,45.122,55.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.538 | Acc: 30.008,45.159,55.366,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 5.126 | Acc: 43.750,56.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.164 | Acc: 37.723,55.618,64.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.170 | Acc: 37.633,54.935,64.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.177 | Acc: 37.628,54.534,64.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.185 | Acc: 37.539,54.591,65.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.186 | Acc: 37.639,54.448,64.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.196 | Acc: 37.448,54.223,64.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.192 | Acc: 37.661,54.366,64.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.200 | Acc: 37.563,54.227,64.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.217 | Acc: 37.362,54.049,64.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.226 | Acc: 37.461,53.972,64.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.230 | Acc: 37.263,53.899,64.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.241 | Acc: 37.241,53.851,64.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.239 | Acc: 37.281,53.837,64.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.244 | Acc: 37.155,53.845,64.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.250 | Acc: 37.116,53.831,64.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.256 | Acc: 37.042,53.743,64.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.258 | Acc: 37.085,53.712,64.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.262 | Acc: 37.067,53.720,64.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.264 | Acc: 37.039,53.746,64.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.462 | Acc: 29.688,48.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.597 | Acc: 26.823,44.978,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.608 | Acc: 27.420,45.255,55.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.633 | Acc: 27.894,45.261,54.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 5.054 | Acc: 39.062,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.089 | Acc: 37.277,55.506,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.117 | Acc: 37.462,55.088,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.133 | Acc: 37.001,54.803,65.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.148 | Acc: 37.076,54.678,65.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.130 | Acc: 37.183,54.711,65.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.153 | Acc: 37.164,54.739,65.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.164 | Acc: 37.240,54.726,65.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.168 | Acc: 37.228,54.789,65.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.189 | Acc: 37.025,54.653,64.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.197 | Acc: 37.104,54.497,64.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.200 | Acc: 37.118,54.422,64.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.192 | Acc: 37.231,54.428,64.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.186 | Acc: 37.314,54.523,64.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.199 | Acc: 37.228,54.457,64.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.199 | Acc: 37.266,54.436,64.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.218 | Acc: 37.198,54.315,64.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.220 | Acc: 37.220,54.277,64.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.229 | Acc: 37.197,54.201,64.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.229 | Acc: 37.262,54.150,64.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.096 | Acc: 34.375,50.000,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.256 | Acc: 30.283,45.796,56.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.302 | Acc: 30.221,44.093,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.307 | Acc: 30.469,44.442,55.853,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 5.276 | Acc: 39.062,56.250,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.116 | Acc: 36.235,54.501,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.230 | Acc: 35.537,54.040,65.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.206 | Acc: 35.873,53.778,65.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.182 | Acc: 36.015,54.022,65.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.185 | Acc: 36.402,54.278,65.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.189 | Acc: 36.725,54.126,64.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.229 | Acc: 36.514,53.640,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.223 | Acc: 36.709,53.863,64.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.204 | Acc: 36.956,54.040,64.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.191 | Acc: 37.123,54.225,64.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.184 | Acc: 37.306,54.136,64.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.186 | Acc: 37.276,54.234,64.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.173 | Acc: 37.404,54.322,64.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.169 | Acc: 37.478,54.351,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.179 | Acc: 37.396,54.277,64.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.183 | Acc: 37.356,54.230,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.183 | Acc: 37.358,54.268,64.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.182 | Acc: 37.359,54.302,64.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.184 | Acc: 37.320,54.314,64.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.215 | Acc: 34.375,48.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.586 | Acc: 29.576,45.982,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.604 | Acc: 28.906,45.694,54.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.617 | Acc: 28.612,45.799,54.495,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 4.685 | Acc: 44.531,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.014 | Acc: 38.579,55.618,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.971 | Acc: 38.643,56.155,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.999 | Acc: 38.294,55.891,67.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.037 | Acc: 38.059,55.584,66.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.089 | Acc: 37.871,55.113,66.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.096 | Acc: 37.732,54.926,65.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.093 | Acc: 37.855,54.970,65.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.105 | Acc: 37.777,54.886,65.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.101 | Acc: 37.910,54.921,65.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.106 | Acc: 37.834,54.878,65.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.117 | Acc: 37.765,54.829,65.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.127 | Acc: 37.785,54.804,65.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.141 | Acc: 37.772,54.804,65.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.153 | Acc: 37.658,54.682,65.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.157 | Acc: 37.570,54.628,65.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.169 | Acc: 37.554,54.534,65.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.165 | Acc: 37.550,54.525,65.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.169 | Acc: 37.567,54.562,65.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.170 | Acc: 37.529,54.560,65.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.866 | Acc: 39.062,50.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.947 | Acc: 33.185,48.624,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.976 | Acc: 33.937,48.476,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.989 | Acc: 34.093,48.143,57.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 5.339 | Acc: 38.281,53.125,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.897 | Acc: 38.356,56.287,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.966 | Acc: 38.338,55.412,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.992 | Acc: 38.627,55.943,67.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.029 | Acc: 38.137,55.575,66.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.059 | Acc: 37.848,55.252,66.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.049 | Acc: 38.055,55.430,66.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.074 | Acc: 37.855,55.070,66.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.071 | Acc: 37.932,55.153,66.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.069 | Acc: 37.975,55.279,66.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.063 | Acc: 38.079,55.391,65.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.067 | Acc: 38.108,55.486,65.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.075 | Acc: 38.080,55.466,65.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.093 | Acc: 37.955,55.346,65.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.105 | Acc: 37.845,55.277,65.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.105 | Acc: 37.804,55.217,65.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.111 | Acc: 37.768,55.177,65.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.115 | Acc: 37.786,55.109,65.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.119 | Acc: 37.829,54.988,65.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.122 | Acc: 37.760,54.944,65.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.563 | Acc: 32.031,46.875,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.536 | Acc: 28.757,46.577,56.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.669 | Acc: 28.335,44.931,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.665 | Acc: 28.484,45.005,54.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 5.104 | Acc: 39.844,48.438,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.994 | Acc: 38.207,55.208,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.018 | Acc: 37.767,55.335,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.082 | Acc: 37.705,54.995,67.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.067 | Acc: 38.117,55.083,66.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.075 | Acc: 37.918,55.105,66.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.079 | Acc: 37.939,55.075,66.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.094 | Acc: 37.827,55.042,66.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.083 | Acc: 38.005,55.265,66.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.080 | Acc: 38.009,55.339,66.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.077 | Acc: 37.994,55.360,66.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.080 | Acc: 38.016,55.250,66.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.095 | Acc: 37.840,55.235,65.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.096 | Acc: 37.862,55.262,65.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.091 | Acc: 37.928,55.330,65.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.095 | Acc: 37.980,55.300,65.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.095 | Acc: 38.079,55.298,65.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.093 | Acc: 38.128,55.283,65.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.097 | Acc: 38.110,55.220,65.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.106 | Acc: 38.078,55.186,65.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.074 | Acc: 31.250,46.094,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.437 | Acc: 28.906,44.903,54.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.487 | Acc: 29.078,44.836,54.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.513 | Acc: 29.547,44.570,54.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 4.746 | Acc: 41.406,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.905 | Acc: 39.509,57.626,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.918 | Acc: 38.929,57.393,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.911 | Acc: 38.691,57.121,68.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.935 | Acc: 38.744,56.588,67.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.951 | Acc: 38.722,56.351,67.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.972 | Acc: 38.559,56.030,67.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.985 | Acc: 38.774,56.062,67.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.988 | Acc: 38.568,56.022,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.002 | Acc: 38.747,56.008,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.019 | Acc: 38.616,55.881,66.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.020 | Acc: 38.698,55.872,66.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.024 | Acc: 38.709,55.861,66.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.031 | Acc: 38.584,55.813,66.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.036 | Acc: 38.468,55.819,66.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.043 | Acc: 38.401,55.728,66.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.051 | Acc: 38.335,55.600,66.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.055 | Acc: 38.316,55.547,66.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.062 | Acc: 38.214,55.560,66.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.065 | Acc: 38.160,55.532,65.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.059 | Acc: 26.562,43.750,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.168 | Acc: 26.600,42.522,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.216 | Acc: 26.277,41.616,51.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.239 | Acc: 26.294,41.560,50.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 5.198 | Acc: 36.719,50.781,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.955 | Acc: 39.249,56.622,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.029 | Acc: 37.957,55.583,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.039 | Acc: 37.999,55.686,66.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.033 | Acc: 37.915,55.700,66.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.016 | Acc: 38.227,55.871,66.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.016 | Acc: 38.146,55.914,66.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.025 | Acc: 38.065,55.895,66.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.028 | Acc: 38.315,55.789,66.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.037 | Acc: 38.277,55.594,66.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.038 | Acc: 38.149,55.585,66.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.041 | Acc: 38.186,55.667,66.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.034 | Acc: 38.226,55.741,66.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.036 | Acc: 38.212,55.690,66.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.043 | Acc: 38.142,55.691,65.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.040 | Acc: 38.180,55.767,66.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.042 | Acc: 38.155,55.785,66.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.048 | Acc: 38.103,55.723,65.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.053 | Acc: 38.091,55.635,65.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.053 | Acc: 38.105,55.633,65.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.364 | Acc: 27.344,42.969,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.862 | Acc: 26.674,41.741,54.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.937 | Acc: 25.495,41.178,53.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.947 | Acc: 25.845,41.304,53.343,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 5.123 | Acc: 45.312,60.156,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.976 | Acc: 37.612,56.287,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.960 | Acc: 38.072,56.021,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.969 | Acc: 37.820,56.224,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.016 | Acc: 37.857,56.134,67.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.043 | Acc: 37.485,55.856,67.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.060 | Acc: 37.209,55.811,66.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.045 | Acc: 37.622,55.956,66.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.050 | Acc: 37.670,56.007,66.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.047 | Acc: 37.919,56.000,66.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.046 | Acc: 37.943,56.048,66.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.048 | Acc: 38.002,55.967,66.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.041 | Acc: 38.006,56.117,66.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.041 | Acc: 38.021,56.040,66.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.047 | Acc: 37.964,55.936,66.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.041 | Acc: 37.933,56.040,66.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.038 | Acc: 37.941,56.050,66.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.035 | Acc: 37.990,56.076,66.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.044 | Acc: 37.890,55.951,66.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.045 | Acc: 37.883,55.942,66.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.386 | Acc: 25.000,46.094,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.714 | Acc: 27.232,47.098,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.844 | Acc: 26.220,45.789,55.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.890 | Acc: 26.345,45.530,55.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 5.166 | Acc: 38.281,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.967 | Acc: 36.496,56.324,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.914 | Acc: 37.862,56.879,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.954 | Acc: 37.795,56.506,67.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.940 | Acc: 38.214,56.568,67.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.957 | Acc: 37.980,56.412,67.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.941 | Acc: 38.171,56.612,67.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.946 | Acc: 38.154,56.560,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.949 | Acc: 38.267,56.434,67.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.947 | Acc: 38.428,56.483,67.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.949 | Acc: 38.499,56.510,66.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.954 | Acc: 38.507,56.441,66.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.956 | Acc: 38.544,56.344,66.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.954 | Acc: 38.545,56.313,66.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.962 | Acc: 38.565,56.247,66.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.959 | Acc: 38.619,56.284,66.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.955 | Acc: 38.615,56.328,66.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.965 | Acc: 38.588,56.280,66.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.974 | Acc: 38.532,56.213,66.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.979 | Acc: 38.542,56.213,66.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.802 | Acc: 31.250,45.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.964 | Acc: 24.516,39.769,49.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.942 | Acc: 25.095,39.329,49.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.920 | Acc: 25.628,39.793,49.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 4.861 | Acc: 39.062,53.906,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.728 | Acc: 39.249,58.668,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.840 | Acc: 38.891,58.213,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.863 | Acc: 38.717,57.736,69.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.866 | Acc: 38.956,57.542,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.865 | Acc: 39.140,57.727,68.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.871 | Acc: 39.411,57.961,68.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.886 | Acc: 39.223,57.923,68.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.898 | Acc: 39.140,57.749,67.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.933 | Acc: 38.868,57.225,67.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.936 | Acc: 38.837,57.183,67.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.934 | Acc: 38.857,57.162,67.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.936 | Acc: 38.839,57.064,67.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.938 | Acc: 38.832,57.031,67.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.942 | Acc: 38.868,57.012,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.954 | Acc: 38.790,56.881,67.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.958 | Acc: 38.829,56.827,67.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.960 | Acc: 38.758,56.818,67.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.962 | Acc: 38.727,56.774,67.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.966 | Acc: 38.685,56.750,67.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.391 | Acc: 32.031,53.906,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.214 | Acc: 30.952,49.144,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.175 | Acc: 31.040,49.123,57.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.208 | Acc: 31.071,48.796,57.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 4.842 | Acc: 35.156,57.812,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.820 | Acc: 39.472,57.403,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.814 | Acc: 39.139,57.088,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.846 | Acc: 39.216,57.351,68.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.876 | Acc: 39.207,56.983,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.879 | Acc: 38.939,56.737,68.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.892 | Acc: 38.727,56.631,68.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.917 | Acc: 38.863,56.416,67.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.912 | Acc: 38.699,56.580,67.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.921 | Acc: 38.972,56.479,67.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.931 | Acc: 38.981,56.514,67.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.941 | Acc: 38.822,56.543,67.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.945 | Acc: 38.755,56.457,67.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.953 | Acc: 38.646,56.427,67.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.958 | Acc: 38.604,56.445,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.951 | Acc: 38.665,56.481,67.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.953 | Acc: 38.622,56.437,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.956 | Acc: 38.604,56.390,67.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.953 | Acc: 38.684,56.391,67.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.958 | Acc: 38.675,56.355,66.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.805 | Acc: 28.125,49.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.927 | Acc: 26.376,46.019,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.941 | Acc: 25.781,45.084,55.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.936 | Acc: 26.358,45.633,55.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.768 | Acc: 39.844,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.983 | Acc: 38.095,55.841,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.981 | Acc: 38.091,55.297,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.968 | Acc: 38.166,55.546,68.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.954 | Acc: 38.397,55.797,68.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.946 | Acc: 38.637,55.809,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.929 | Acc: 38.727,56.224,68.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.928 | Acc: 38.403,56.411,68.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.912 | Acc: 38.616,56.677,68.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.899 | Acc: 38.752,56.802,68.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.914 | Acc: 38.794,56.670,67.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.927 | Acc: 38.780,56.649,67.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.927 | Acc: 38.793,56.652,67.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.943 | Acc: 38.745,56.564,67.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.943 | Acc: 38.798,56.522,67.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.956 | Acc: 38.699,56.439,67.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.950 | Acc: 38.724,56.513,67.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.946 | Acc: 38.762,56.587,67.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.946 | Acc: 38.762,56.648,67.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.945 | Acc: 38.659,56.800,67.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.272 | Acc: 28.125,49.219,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.523 | Acc: 23.810,45.164,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.478 | Acc: 23.838,44.703,52.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.483 | Acc: 24.027,44.339,52.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 4.769 | Acc: 39.844,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.794 | Acc: 39.955,59.821,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.839 | Acc: 39.329,58.822,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.821 | Acc: 39.139,58.747,68.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.826 | Acc: 39.352,58.555,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.848 | Acc: 39.333,58.037,68.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.871 | Acc: 38.979,57.696,68.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.868 | Acc: 39.051,57.691,68.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.879 | Acc: 38.975,57.521,68.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.889 | Acc: 38.769,57.325,67.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.893 | Acc: 38.771,57.284,67.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.898 | Acc: 38.730,57.144,67.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.902 | Acc: 38.790,57.086,67.735,% | Adaptive Acc: 0.000% | clf_exit: 
