==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=16, out_features=16, bias=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (BN1d): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=48, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=48, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=96, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=96, out_features=100, bias=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 14.874 | Acc: 0.000,1.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.600 | Acc: 1.339,1.265,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.388 | Acc: 1.467,1.239,1.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.250 | Acc: 1.562,1.447,1.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.165 | Acc: 1.669,1.669,1.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.119 | Acc: 1.640,1.725,1.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 14.079 | Acc: 1.834,1.788,1.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 14.040 | Acc: 1.878,1.823,1.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 14.016 | Acc: 1.859,1.810,1.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 14.002 | Acc: 1.830,1.830,1.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.979 | Acc: 1.877,1.854,1.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.962 | Acc: 1.895,1.824,1.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.950 | Acc: 1.948,1.896,1.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.935 | Acc: 1.979,1.901,1.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.921 | Acc: 2.016,1.929,1.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.906 | Acc: 2.053,1.952,1.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.898 | Acc: 2.093,1.962,1.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.888 | Acc: 2.101,1.957,1.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.880 | Acc: 2.084,1.941,1.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.869 | Acc: 2.087,1.936,1.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.951 | Acc: 1.562,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.960 | Acc: 2.567,2.269,1.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.505 | Acc: 2.382,2.115,1.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.427 | Acc: 2.280,1.985,1.486,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 13.853 | Acc: 2.344,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.629 | Acc: 3.013,1.562,1.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.644 | Acc: 2.992,1.601,1.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.649 | Acc: 2.715,1.601,1.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.627 | Acc: 2.836,1.649,1.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.631 | Acc: 2.854,1.787,1.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.620 | Acc: 2.970,1.821,1.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.609 | Acc: 3.014,1.923,1.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.600 | Acc: 3.047,1.965,1.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.590 | Acc: 3.082,2.003,1.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.588 | Acc: 3.043,1.986,1.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.581 | Acc: 3.033,2.004,1.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.575 | Acc: 3.054,1.990,1.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.569 | Acc: 3.086,1.985,1.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.568 | Acc: 3.117,1.996,1.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.564 | Acc: 3.159,2.030,1.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.558 | Acc: 3.144,2.030,1.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.548 | Acc: 3.171,2.039,1.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.543 | Acc: 3.179,2.043,1.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.537 | Acc: 3.223,2.036,1.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.384 | Acc: 5.469,2.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.450 | Acc: 4.167,1.823,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.454 | Acc: 4.116,1.810,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.435 | Acc: 4.073,1.947,2.177,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 13.537 | Acc: 1.562,2.344,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.401 | Acc: 3.720,2.827,1.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.390 | Acc: 3.678,2.591,1.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.400 | Acc: 3.765,2.600,1.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.394 | Acc: 3.887,2.652,1.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.379 | Acc: 4.007,2.893,1.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.372 | Acc: 4.126,2.944,1.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.366 | Acc: 4.156,3.053,1.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.359 | Acc: 4.212,3.067,1.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.350 | Acc: 4.282,3.160,1.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.343 | Acc: 4.353,3.218,1.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.335 | Acc: 4.426,3.213,1.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.326 | Acc: 4.496,3.313,1.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.323 | Acc: 4.466,3.344,1.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.315 | Acc: 4.479,3.406,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.305 | Acc: 4.511,3.481,1.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.295 | Acc: 4.556,3.544,1.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.284 | Acc: 4.637,3.620,1.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.275 | Acc: 4.655,3.627,1.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.269 | Acc: 4.741,3.666,1.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.147 | Acc: 7.812,4.688,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.183 | Acc: 5.915,3.906,1.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.205 | Acc: 5.526,3.563,1.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.203 | Acc: 5.610,3.714,2.024,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 13.257 | Acc: 5.469,5.469,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.086 | Acc: 6.696,4.167,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.086 | Acc: 6.707,4.497,2.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.087 | Acc: 6.698,4.598,2.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.080 | Acc: 6.645,4.842,2.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.055 | Acc: 6.668,4.865,2.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.034 | Acc: 6.838,4.771,2.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.029 | Acc: 6.765,4.820,2.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.013 | Acc: 6.755,4.872,2.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.009 | Acc: 6.733,4.886,2.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.003 | Acc: 6.786,4.909,2.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.997 | Acc: 6.876,4.903,2.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.985 | Acc: 6.960,4.995,2.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.978 | Acc: 6.992,5.002,2.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.972 | Acc: 7.048,5.043,2.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.961 | Acc: 7.122,5.111,2.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.952 | Acc: 7.160,5.167,2.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.949 | Acc: 7.123,5.226,2.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.942 | Acc: 7.165,5.293,2.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.932 | Acc: 7.214,5.354,2.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.867 | Acc: 13.281,4.688,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.947 | Acc: 8.036,5.134,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.983 | Acc: 7.793,5.697,2.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.974 | Acc: 7.723,5.622,2.152,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 12.534 | Acc: 7.031,4.688,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.678 | Acc: 8.333,6.324,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.687 | Acc: 8.403,6.517,2.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.669 | Acc: 8.683,6.660,2.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.670 | Acc: 8.642,6.645,2.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.669 | Acc: 8.625,6.668,2.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.678 | Acc: 8.497,6.605,1.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.667 | Acc: 8.516,6.654,1.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.654 | Acc: 8.487,6.740,1.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.644 | Acc: 8.503,6.880,1.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.637 | Acc: 8.473,6.954,1.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.628 | Acc: 8.562,7.017,1.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.612 | Acc: 8.662,7.180,2.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.605 | Acc: 8.648,7.127,2.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.596 | Acc: 8.697,7.181,1.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.591 | Acc: 8.775,7.280,1.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.578 | Acc: 8.891,7.335,1.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.567 | Acc: 8.951,7.414,1.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.554 | Acc: 9.022,7.518,1.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.541 | Acc: 9.100,7.603,1.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.563 | Acc: 7.031,7.031,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.488 | Acc: 8.743,7.999,2.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.516 | Acc: 8.670,7.508,2.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.529 | Acc: 8.530,7.633,2.152,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 12.397 | Acc: 11.719,14.062,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.278 | Acc: 11.458,8.519,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.256 | Acc: 10.842,8.975,2.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.228 | Acc: 10.925,8.978,2.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.236 | Acc: 10.822,8.883,2.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.235 | Acc: 10.628,8.864,2.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.235 | Acc: 10.666,8.981,2.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.232 | Acc: 10.727,9.087,2.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.220 | Acc: 10.734,9.239,2.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.213 | Acc: 10.748,9.241,2.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.201 | Acc: 10.879,9.324,2.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.193 | Acc: 10.962,9.396,2.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.186 | Acc: 11.054,9.407,2.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.170 | Acc: 11.096,9.531,2.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.160 | Acc: 11.129,9.628,2.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.153 | Acc: 11.150,9.692,2.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.143 | Acc: 11.215,9.740,2.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.129 | Acc: 11.263,9.840,2.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.119 | Acc: 11.297,9.955,2.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.112 | Acc: 11.300,9.957,2.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.387 | Acc: 10.938,11.719,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.401 | Acc: 9.375,9.226,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.403 | Acc: 9.413,9.261,2.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.399 | Acc: 9.439,9.375,1.998,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 12.031 | Acc: 10.938,6.250,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.903 | Acc: 11.979,11.272,1.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.902 | Acc: 11.681,10.880,1.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.879 | Acc: 12.013,11.066,1.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.874 | Acc: 12.056,11.015,2.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.877 | Acc: 12.051,11.030,2.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.861 | Acc: 12.222,11.247,2.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.870 | Acc: 12.240,11.314,2.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.876 | Acc: 12.253,11.331,2.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.882 | Acc: 12.310,11.335,1.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.886 | Acc: 12.372,11.396,1.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.879 | Acc: 12.514,11.591,1.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.876 | Acc: 12.494,11.628,1.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.867 | Acc: 12.608,11.809,1.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.863 | Acc: 12.608,11.769,1.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.857 | Acc: 12.700,11.789,1.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.851 | Acc: 12.785,11.784,1.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.849 | Acc: 12.825,11.817,1.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.843 | Acc: 12.898,11.864,1.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.840 | Acc: 12.922,11.893,1.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.172 | Acc: 13.281,10.938,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.033 | Acc: 12.277,10.826,1.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.048 | Acc: 12.671,10.461,1.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.045 | Acc: 12.551,10.220,1.755,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 11.456 | Acc: 16.406,19.531,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.660 | Acc: 15.848,14.397,1.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.620 | Acc: 15.644,14.882,1.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.641 | Acc: 14.818,13.998,2.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.621 | Acc: 14.940,13.956,2.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.611 | Acc: 14.983,14.047,2.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.600 | Acc: 14.992,14.082,2.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.598 | Acc: 14.894,13.968,2.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.600 | Acc: 14.829,13.961,2.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.602 | Acc: 14.753,13.950,2.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.600 | Acc: 14.758,13.907,2.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.594 | Acc: 14.759,13.921,2.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.592 | Acc: 14.682,13.956,2.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.591 | Acc: 14.712,13.916,2.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.589 | Acc: 14.688,13.835,2.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.581 | Acc: 14.761,13.920,1.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.579 | Acc: 14.776,13.938,1.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.572 | Acc: 14.803,13.941,2.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.566 | Acc: 14.848,13.965,2.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.561 | Acc: 14.924,13.983,2.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.150 | Acc: 13.281,12.500,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.749 | Acc: 13.058,13.132,1.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.751 | Acc: 13.053,12.652,1.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.754 | Acc: 13.089,12.846,1.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 10.827 | Acc: 17.969,19.531,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.285 | Acc: 16.815,16.481,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.321 | Acc: 16.711,16.197,1.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.346 | Acc: 16.586,16.009,1.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.338 | Acc: 16.782,16.098,1.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.343 | Acc: 16.677,16.043,1.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.331 | Acc: 16.490,15.786,2.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.336 | Acc: 16.439,15.669,2.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.340 | Acc: 16.421,15.547,2.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.340 | Acc: 16.441,15.500,2.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.334 | Acc: 16.523,15.532,2.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.322 | Acc: 16.498,15.590,2.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.323 | Acc: 16.494,15.631,2.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.304 | Acc: 16.679,15.876,2.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.298 | Acc: 16.579,15.886,2.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.294 | Acc: 16.604,15.882,2.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.292 | Acc: 16.645,15.932,2.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.289 | Acc: 16.741,15.934,2.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.283 | Acc: 16.798,15.952,2.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.274 | Acc: 16.843,16.021,2.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.402 | Acc: 14.844,14.062,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.447 | Acc: 14.844,13.914,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.434 | Acc: 14.615,14.977,2.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.443 | Acc: 14.677,15.113,1.960,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 10.743 | Acc: 17.969,21.875,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.071 | Acc: 18.750,18.713,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.060 | Acc: 18.807,17.969,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.074 | Acc: 18.865,17.905,2.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.070 | Acc: 18.663,18.113,2.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.059 | Acc: 18.719,17.976,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.046 | Acc: 18.892,18.020,2.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.049 | Acc: 18.684,17.725,2.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.050 | Acc: 18.682,17.634,2.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.062 | Acc: 18.590,17.645,2.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.052 | Acc: 18.696,17.685,2.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.055 | Acc: 18.573,17.566,2.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.045 | Acc: 18.630,17.687,2.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.037 | Acc: 18.606,17.639,2.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.033 | Acc: 18.661,17.618,2.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.023 | Acc: 18.695,17.670,2.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.018 | Acc: 18.653,17.626,2.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.010 | Acc: 18.757,17.712,2.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.005 | Acc: 18.856,17.737,2.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.002 | Acc: 18.855,17.735,2.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.654 | Acc: 19.531,11.719,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.479 | Acc: 17.374,12.574,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.455 | Acc: 17.683,12.881,2.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.463 | Acc: 17.444,13.025,2.241,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 11.096 | Acc: 17.188,17.188,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.817 | Acc: 19.903,18.527,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.807 | Acc: 20.427,19.169,2.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.832 | Acc: 20.402,19.057,2.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.814 | Acc: 20.525,19.059,2.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.811 | Acc: 20.637,19.121,2.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.809 | Acc: 20.829,19.157,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.802 | Acc: 20.734,19.265,2.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.799 | Acc: 20.526,19.172,2.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.793 | Acc: 20.429,19.203,2.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.792 | Acc: 20.351,19.209,2.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.798 | Acc: 20.362,19.146,2.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.796 | Acc: 20.322,19.197,2.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.787 | Acc: 20.417,19.211,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.783 | Acc: 20.426,19.209,2.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.780 | Acc: 20.416,19.230,2.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.771 | Acc: 20.488,19.371,2.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.768 | Acc: 20.455,19.334,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.763 | Acc: 20.592,19.408,2.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.762 | Acc: 20.690,19.455,2.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.112 | Acc: 25.781,17.969,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.995 | Acc: 19.792,16.332,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.015 | Acc: 20.027,16.864,2.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.030 | Acc: 19.762,16.675,2.369,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 10.606 | Acc: 22.656,25.000,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.571 | Acc: 22.507,21.503,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.563 | Acc: 22.732,21.627,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.586 | Acc: 22.656,21.542,2.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.591 | Acc: 22.261,21.393,2.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.581 | Acc: 22.231,21.326,2.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.585 | Acc: 22.120,21.100,2.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.572 | Acc: 22.213,21.382,2.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.570 | Acc: 22.258,21.341,2.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.564 | Acc: 22.311,21.439,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.565 | Acc: 22.322,21.420,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.559 | Acc: 22.338,21.486,2.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.551 | Acc: 22.387,21.509,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.547 | Acc: 22.504,21.609,2.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.549 | Acc: 22.451,21.583,2.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.545 | Acc: 22.516,21.628,2.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.542 | Acc: 22.537,21.600,2.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.540 | Acc: 22.629,21.589,2.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.534 | Acc: 22.650,21.561,2.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.526 | Acc: 22.714,21.627,2.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.994 | Acc: 15.625,14.844,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.133 | Acc: 13.839,12.351,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.183 | Acc: 13.720,12.348,2.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.183 | Acc: 13.717,12.334,2.344,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 10.370 | Acc: 23.438,25.000,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.378 | Acc: 24.777,24.107,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.376 | Acc: 24.219,23.228,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.351 | Acc: 24.488,23.297,2.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.395 | Acc: 23.949,22.647,2.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.398 | Acc: 23.809,22.401,2.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.396 | Acc: 23.786,22.618,2.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.407 | Acc: 23.665,22.440,2.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.408 | Acc: 23.520,22.312,2.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.399 | Acc: 23.649,22.471,2.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.400 | Acc: 23.721,22.563,2.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.401 | Acc: 23.646,22.458,2.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.391 | Acc: 23.749,22.504,2.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.381 | Acc: 23.845,22.543,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.374 | Acc: 23.902,22.628,2.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.365 | Acc: 23.936,22.700,2.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.357 | Acc: 23.975,22.795,2.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.345 | Acc: 24.077,22.899,2.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.340 | Acc: 24.106,22.979,2.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.341 | Acc: 24.044,22.956,2.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.311 | Acc: 19.531,17.969,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.183 | Acc: 18.415,17.225,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.233 | Acc: 18.407,17.226,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.260 | Acc: 18.276,17.264,2.331,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 10.327 | Acc: 21.094,21.875,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.164 | Acc: 24.591,24.591,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.197 | Acc: 24.886,24.333,2.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.169 | Acc: 25.282,24.488,2.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.179 | Acc: 25.260,24.392,2.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.156 | Acc: 25.309,24.606,2.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.151 | Acc: 25.413,24.580,2.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.151 | Acc: 25.493,24.612,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.156 | Acc: 25.277,24.573,2.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.149 | Acc: 25.302,24.504,2.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.163 | Acc: 25.222,24.320,2.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.165 | Acc: 25.201,24.403,2.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.164 | Acc: 25.292,24.429,2.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.158 | Acc: 25.413,24.482,2.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.151 | Acc: 25.500,24.583,2.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.146 | Acc: 25.480,24.618,2.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.147 | Acc: 25.460,24.596,2.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.146 | Acc: 25.419,24.567,2.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.144 | Acc: 25.424,24.580,2.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.137 | Acc: 25.416,24.660,2.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.835 | Acc: 17.969,22.656,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.931 | Acc: 20.945,18.304,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.932 | Acc: 20.617,18.769,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.919 | Acc: 19.992,18.455,2.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 9.842 | Acc: 25.000,28.125,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.089 | Acc: 26.265,25.744,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.032 | Acc: 26.486,25.934,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.031 | Acc: 26.562,26.153,2.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.035 | Acc: 26.601,25.839,2.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.026 | Acc: 26.632,25.727,2.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.015 | Acc: 26.692,25.755,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.008 | Acc: 26.745,25.665,2.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.019 | Acc: 26.543,25.514,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.014 | Acc: 26.502,25.565,2.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.000 | Acc: 26.656,25.653,2.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.995 | Acc: 26.852,25.799,2.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.991 | Acc: 26.903,25.869,2.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.986 | Acc: 26.814,25.940,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.984 | Acc: 26.807,25.931,2.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.985 | Acc: 26.783,25.914,2.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.985 | Acc: 26.782,25.913,2.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.984 | Acc: 26.794,25.896,2.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.978 | Acc: 26.822,26.026,2.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.968 | Acc: 26.940,26.183,2.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.993 | Acc: 21.875,15.625,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.104 | Acc: 19.940,17.522,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.060 | Acc: 20.198,18.350,2.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.089 | Acc: 20.069,18.340,2.164,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 9.569 | Acc: 32.031,32.812,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.824 | Acc: 28.348,28.162,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.883 | Acc: 27.553,27.096,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.872 | Acc: 27.382,27.126,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.840 | Acc: 27.662,27.556,2.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.840 | Acc: 27.537,27.614,2.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.848 | Acc: 27.570,27.660,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.861 | Acc: 27.383,27.582,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.855 | Acc: 27.679,27.518,2.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.865 | Acc: 27.663,27.365,2.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.863 | Acc: 27.670,27.359,2.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.864 | Acc: 27.570,27.287,2.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.854 | Acc: 27.652,27.496,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.838 | Acc: 27.778,27.637,2.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.837 | Acc: 27.802,27.644,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.835 | Acc: 27.808,27.671,2.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.827 | Acc: 27.843,27.663,2.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.822 | Acc: 27.875,27.674,2.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.825 | Acc: 27.909,27.686,2.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.825 | Acc: 27.893,27.719,2.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.895 | Acc: 29.688,27.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.745 | Acc: 22.693,19.271,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.761 | Acc: 22.599,19.036,2.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.772 | Acc: 22.323,19.185,2.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 9.584 | Acc: 28.906,33.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.702 | Acc: 28.795,29.278,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.722 | Acc: 28.449,29.402,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.716 | Acc: 28.215,28.932,2.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.737 | Acc: 28.125,28.848,2.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.756 | Acc: 28.001,28.566,2.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.757 | Acc: 27.822,28.538,2.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.755 | Acc: 28.097,28.579,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.750 | Acc: 28.062,28.474,2.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.754 | Acc: 28.151,28.449,2.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.746 | Acc: 28.133,28.525,2.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.748 | Acc: 28.150,28.577,2.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.750 | Acc: 28.093,28.572,2.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.742 | Acc: 28.248,28.775,2.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.734 | Acc: 28.308,28.834,2.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.730 | Acc: 28.387,28.862,2.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.725 | Acc: 28.444,28.826,2.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.718 | Acc: 28.480,28.893,2.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.710 | Acc: 28.597,28.904,2.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.711 | Acc: 28.609,28.912,2.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.756 | Acc: 21.875,24.219,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.004 | Acc: 18.899,21.429,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.984 | Acc: 18.712,21.646,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.969 | Acc: 18.558,21.644,2.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 10.209 | Acc: 25.781,23.438,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.648 | Acc: 28.869,29.092,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.616 | Acc: 29.078,29.897,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.580 | Acc: 29.226,30.097,2.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.583 | Acc: 29.321,29.890,2.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.587 | Acc: 29.533,30.097,2.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.591 | Acc: 29.545,29.997,2.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.582 | Acc: 29.593,29.992,2.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.579 | Acc: 29.474,30.061,2.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.588 | Acc: 29.463,29.938,2.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.588 | Acc: 29.555,29.995,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.594 | Acc: 29.617,29.995,2.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.589 | Acc: 29.632,30.057,2.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.586 | Acc: 29.622,30.119,2.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.581 | Acc: 29.685,30.241,2.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.571 | Acc: 29.825,30.303,2.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.571 | Acc: 29.824,30.325,2.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.574 | Acc: 29.756,30.302,2.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.576 | Acc: 29.761,30.332,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.580 | Acc: 29.733,30.323,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.840 | Acc: 28.125,28.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.156 | Acc: 25.521,25.446,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.100 | Acc: 25.781,25.629,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.077 | Acc: 25.820,25.602,3.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 9.404 | Acc: 32.812,35.156,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.525 | Acc: 29.353,29.576,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.495 | Acc: 30.736,31.059,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.499 | Acc: 30.469,31.135,2.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.502 | Acc: 30.411,31.086,2.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.497 | Acc: 30.492,31.296,2.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.486 | Acc: 30.346,31.347,2.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.473 | Acc: 30.441,31.449,2.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.472 | Acc: 30.430,31.570,2.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.470 | Acc: 30.473,31.600,2.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.471 | Acc: 30.375,31.592,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.479 | Acc: 30.299,31.533,2.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.489 | Acc: 30.038,31.380,2.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.493 | Acc: 30.026,31.364,2.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.491 | Acc: 30.029,31.417,2.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.488 | Acc: 30.079,31.414,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.485 | Acc: 30.070,31.428,2.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.478 | Acc: 30.143,31.530,2.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.473 | Acc: 30.198,31.542,2.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.474 | Acc: 30.272,31.570,2.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.299 | Acc: 29.688,24.219,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.155 | Acc: 24.107,26.637,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.224 | Acc: 24.085,26.239,2.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.221 | Acc: 24.219,26.409,2.100,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 9.491 | Acc: 33.594,28.906,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.402 | Acc: 32.143,33.371,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.369 | Acc: 31.955,33.594,2.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.377 | Acc: 31.685,32.864,2.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.364 | Acc: 31.645,32.957,2.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.347 | Acc: 31.722,33.130,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.345 | Acc: 31.721,33.110,2.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.342 | Acc: 31.599,33.167,2.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.345 | Acc: 31.570,33.123,2.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.346 | Acc: 31.449,33.248,2.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.345 | Acc: 31.421,33.178,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.348 | Acc: 31.402,33.141,2.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.335 | Acc: 31.451,33.315,2.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.335 | Acc: 31.463,33.300,2.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.333 | Acc: 31.420,33.346,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.338 | Acc: 31.426,33.386,2.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.344 | Acc: 31.304,33.331,2.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.341 | Acc: 31.232,33.291,2.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.340 | Acc: 31.220,33.291,2.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.344 | Acc: 31.135,33.249,2.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.129 | Acc: 28.125,25.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.982 | Acc: 26.562,27.046,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.014 | Acc: 26.334,26.620,2.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.009 | Acc: 26.178,26.742,2.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 8.765 | Acc: 35.156,39.062,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.199 | Acc: 30.952,34.449,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.231 | Acc: 31.555,34.661,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.245 | Acc: 31.288,34.503,2.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.237 | Acc: 31.356,34.433,2.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.260 | Acc: 31.381,34.282,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.261 | Acc: 31.411,34.304,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.262 | Acc: 31.510,34.187,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.270 | Acc: 31.541,34.254,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.273 | Acc: 31.522,34.142,2.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.283 | Acc: 31.433,34.091,2.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.287 | Acc: 31.437,34.092,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.280 | Acc: 31.509,34.125,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.271 | Acc: 31.498,34.201,2.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.269 | Acc: 31.472,34.203,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.261 | Acc: 31.543,34.269,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.256 | Acc: 31.559,34.331,2.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.259 | Acc: 31.527,34.279,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.261 | Acc: 31.562,34.291,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.263 | Acc: 31.527,34.305,2.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.631 | Acc: 28.125,35.156,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.901 | Acc: 26.004,31.250,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.939 | Acc: 25.915,29.745,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.955 | Acc: 25.615,29.316,2.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 9.012 | Acc: 32.812,39.062,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.082 | Acc: 32.254,36.458,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.180 | Acc: 32.107,35.804,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.176 | Acc: 31.685,35.400,2.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.175 | Acc: 31.588,35.069,2.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.152 | Acc: 31.761,35.295,2.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.154 | Acc: 31.921,35.408,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.138 | Acc: 32.480,35.777,2.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.150 | Acc: 32.313,35.646,2.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.142 | Acc: 32.441,35.881,2.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.145 | Acc: 32.447,35.930,2.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.148 | Acc: 32.533,36.026,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.161 | Acc: 32.346,35.928,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.162 | Acc: 32.334,35.920,2.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.155 | Acc: 32.384,35.982,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.163 | Acc: 32.301,35.896,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.159 | Acc: 32.306,35.891,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.171 | Acc: 32.260,35.825,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.179 | Acc: 32.161,35.743,2.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.179 | Acc: 32.138,35.763,2.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.833 | Acc: 35.938,32.812,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.907 | Acc: 27.344,28.981,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.927 | Acc: 26.524,28.220,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.919 | Acc: 26.588,28.509,2.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 9.247 | Acc: 30.469,32.812,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.175 | Acc: 31.436,34.449,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.100 | Acc: 32.222,35.728,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.100 | Acc: 32.480,36.027,2.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.106 | Acc: 32.639,36.227,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.112 | Acc: 32.565,36.208,2.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.099 | Acc: 32.780,36.460,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.097 | Acc: 32.812,36.658,2.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.095 | Acc: 32.822,36.680,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.097 | Acc: 32.812,36.693,2.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.093 | Acc: 32.754,36.664,2.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.101 | Acc: 32.752,36.613,2.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.101 | Acc: 32.728,36.602,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.105 | Acc: 32.633,36.524,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.109 | Acc: 32.568,36.477,2.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.112 | Acc: 32.569,36.464,2.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.112 | Acc: 32.469,36.410,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.114 | Acc: 32.462,36.348,2.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.118 | Acc: 32.427,36.295,2.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.118 | Acc: 32.380,36.341,2.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.297 | Acc: 31.250,35.938,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.622 | Acc: 24.256,29.427,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.653 | Acc: 23.666,28.392,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.674 | Acc: 23.297,27.843,2.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 8.909 | Acc: 34.375,39.844,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.997 | Acc: 33.594,38.021,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.014 | Acc: 32.679,38.072,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.016 | Acc: 33.158,38.038,2.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.002 | Acc: 33.497,38.146,2.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.008 | Acc: 33.663,37.879,2.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.012 | Acc: 33.484,37.758,2.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.011 | Acc: 33.522,37.683,2.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.999 | Acc: 33.579,37.801,2.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.000 | Acc: 33.365,37.681,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.011 | Acc: 33.302,37.690,2.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.007 | Acc: 33.368,37.762,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.002 | Acc: 33.390,37.750,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.005 | Acc: 33.414,37.754,2.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.007 | Acc: 33.407,37.675,2.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.004 | Acc: 33.448,37.801,2.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.003 | Acc: 33.455,37.685,2.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.002 | Acc: 33.463,37.663,2.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.003 | Acc: 33.410,37.608,2.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.010 | Acc: 33.337,37.580,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.343 | Acc: 29.688,28.906,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.346 | Acc: 23.735,28.832,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.358 | Acc: 23.914,29.268,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.380 | Acc: 23.975,29.214,2.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 8.849 | Acc: 36.719,41.406,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.921 | Acc: 34.449,38.318,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.879 | Acc: 34.032,38.567,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.912 | Acc: 33.965,38.909,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.944 | Acc: 33.845,38.571,2.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.960 | Acc: 33.702,38.320,2.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.948 | Acc: 33.891,38.656,2.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.949 | Acc: 33.793,38.569,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.955 | Acc: 33.696,38.572,2.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.953 | Acc: 33.792,38.441,2.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.937 | Acc: 33.909,38.561,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.939 | Acc: 33.845,38.677,2.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.935 | Acc: 33.937,38.826,2.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.936 | Acc: 33.995,38.715,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.939 | Acc: 34.002,38.651,2.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.947 | Acc: 33.962,38.567,2.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.941 | Acc: 33.988,38.583,2.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.935 | Acc: 34.029,38.675,2.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.931 | Acc: 34.066,38.684,2.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.926 | Acc: 34.092,38.724,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.725 | Acc: 29.688,31.250,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.894 | Acc: 26.153,31.362,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.912 | Acc: 26.258,31.155,2.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.930 | Acc: 26.050,30.751,2.024,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 8.757 | Acc: 39.844,36.719,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.883 | Acc: 34.338,38.728,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.809 | Acc: 34.832,39.596,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.828 | Acc: 34.337,39.613,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.828 | Acc: 34.655,39.911,2.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.832 | Acc: 34.615,39.712,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.840 | Acc: 34.298,39.508,2.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.849 | Acc: 34.347,39.328,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.843 | Acc: 34.375,39.320,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.834 | Acc: 34.345,39.442,2.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.840 | Acc: 34.282,39.350,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.840 | Acc: 34.315,39.398,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.841 | Acc: 34.346,39.422,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.839 | Acc: 34.321,39.458,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.837 | Acc: 34.372,39.541,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.841 | Acc: 34.359,39.501,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.837 | Acc: 34.341,39.513,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.840 | Acc: 34.341,39.479,2.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.843 | Acc: 34.306,39.472,2.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.847 | Acc: 34.344,39.446,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.391 | Acc: 30.469,36.719,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.281 | Acc: 29.613,36.421,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.289 | Acc: 29.325,36.490,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.342 | Acc: 28.599,35.669,3.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 8.689 | Acc: 30.469,39.062,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.762 | Acc: 35.193,41.369,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.820 | Acc: 34.299,40.511,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.826 | Acc: 34.042,40.561,2.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.847 | Acc: 34.018,40.500,2.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.834 | Acc: 34.220,40.625,2.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.810 | Acc: 34.601,40.780,2.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.811 | Acc: 34.469,40.509,2.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.807 | Acc: 34.535,40.615,2.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.806 | Acc: 34.474,40.457,2.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.798 | Acc: 34.616,40.617,2.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.786 | Acc: 34.831,40.731,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.781 | Acc: 34.839,40.755,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.789 | Acc: 34.743,40.604,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.788 | Acc: 34.739,40.533,2.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.785 | Acc: 34.679,40.516,2.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.790 | Acc: 34.618,40.323,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.784 | Acc: 34.712,40.398,2.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.786 | Acc: 34.628,40.344,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.790 | Acc: 34.553,40.209,2.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.005 | Acc: 22.656,34.375,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.176 | Acc: 22.954,29.948,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.204 | Acc: 23.018,29.516,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.222 | Acc: 22.797,29.124,2.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 8.821 | Acc: 34.375,36.719,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.706 | Acc: 35.268,41.927,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.734 | Acc: 35.499,41.902,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.741 | Acc: 35.387,41.829,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.721 | Acc: 35.610,41.946,2.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.719 | Acc: 35.613,41.793,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.724 | Acc: 35.460,41.419,2.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.735 | Acc: 35.262,41.113,2.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.722 | Acc: 35.331,41.411,2.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.732 | Acc: 35.286,41.281,2.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.729 | Acc: 35.269,41.251,2.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.733 | Acc: 35.319,41.244,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.729 | Acc: 35.383,41.270,2.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.724 | Acc: 35.324,41.155,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.730 | Acc: 35.215,41.056,2.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.725 | Acc: 35.229,41.079,2.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.721 | Acc: 35.178,41.058,2.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.719 | Acc: 35.168,41.074,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.719 | Acc: 35.174,41.069,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.722 | Acc: 35.210,41.084,2.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.423 | Acc: 32.812,33.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.564 | Acc: 26.637,36.756,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.537 | Acc: 26.448,35.880,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.543 | Acc: 26.217,35.092,2.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 8.910 | Acc: 32.031,42.188,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.616 | Acc: 36.012,42.150,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.634 | Acc: 35.271,41.806,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.635 | Acc: 35.464,42.316,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.677 | Acc: 35.127,41.561,2.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.688 | Acc: 35.032,41.476,2.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.686 | Acc: 34.859,41.284,2.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.687 | Acc: 35.040,41.284,2.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.678 | Acc: 35.345,41.562,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.684 | Acc: 35.424,41.523,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.676 | Acc: 35.642,41.709,2.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.671 | Acc: 35.612,41.767,2.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.670 | Acc: 35.561,41.740,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.676 | Acc: 35.518,41.667,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.678 | Acc: 35.437,41.584,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.676 | Acc: 35.434,41.653,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.677 | Acc: 35.351,41.564,2.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.671 | Acc: 35.413,41.695,2.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.672 | Acc: 35.444,41.714,2.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.694 | Acc: 35.355,41.654,2.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.703 | Acc: 29.688,34.375,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.502 | Acc: 26.153,34.226,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.432 | Acc: 25.800,34.051,1.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.423 | Acc: 25.730,33.760,1.242,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 8.815 | Acc: 36.719,44.531,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.084 | Acc: 36.421,42.485,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.063 | Acc: 36.261,42.207,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.073 | Acc: 36.258,41.829,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.035 | Acc: 36.362,41.937,2.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.044 | Acc: 35.914,41.886,2.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.042 | Acc: 35.750,41.690,2.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.050 | Acc: 35.372,41.633,2.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.037 | Acc: 35.569,41.717,2.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.054 | Acc: 35.268,41.488,2.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.052 | Acc: 35.351,41.472,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.036 | Acc: 35.382,41.636,2.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.026 | Acc: 35.406,41.769,2.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.019 | Acc: 35.360,41.762,2.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.014 | Acc: 35.429,41.707,2.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.010 | Acc: 35.509,41.725,2.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.011 | Acc: 35.565,41.788,2.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.005 | Acc: 35.628,41.848,2.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.001 | Acc: 35.615,41.817,2.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.005 | Acc: 35.511,41.740,2.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.561 | Acc: 32.812,35.156,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.730 | Acc: 29.688,36.272,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.739 | Acc: 29.402,36.204,2.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.750 | Acc: 29.009,36.002,2.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 8.878 | Acc: 30.469,40.625,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.965 | Acc: 34.412,41.555,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.926 | Acc: 35.156,41.330,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.954 | Acc: 35.476,41.726,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.932 | Acc: 35.494,41.763,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.911 | Acc: 35.914,41.832,2.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.893 | Acc: 36.047,42.200,2.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.894 | Acc: 36.120,42.304,2.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.889 | Acc: 36.107,42.265,2.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.888 | Acc: 36.196,42.209,2.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.914 | Acc: 35.879,41.943,2.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.903 | Acc: 35.983,42.067,2.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.906 | Acc: 35.895,42.045,2.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.907 | Acc: 35.719,41.933,2.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.894 | Acc: 35.899,42.074,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.890 | Acc: 35.886,42.068,2.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.885 | Acc: 35.964,42.188,2.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.880 | Acc: 36.029,42.242,2.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.877 | Acc: 36.085,42.369,2.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.876 | Acc: 36.042,42.345,2.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.748 | Acc: 30.469,34.375,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.045 | Acc: 26.860,33.445,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.038 | Acc: 26.315,34.013,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.033 | Acc: 25.653,33.594,2.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 8.776 | Acc: 46.875,50.781,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.754 | Acc: 38.095,43.415,3.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.795 | Acc: 37.557,43.712,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.738 | Acc: 38.268,44.442,2.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.731 | Acc: 37.944,44.203,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.750 | Acc: 37.260,43.835,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.758 | Acc: 37.184,43.769,2.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.761 | Acc: 36.924,43.545,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.759 | Acc: 36.777,43.517,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.753 | Acc: 36.866,43.599,2.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.759 | Acc: 36.750,43.536,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.762 | Acc: 36.733,43.481,2.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.763 | Acc: 36.754,43.500,2.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.766 | Acc: 36.782,43.463,2.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.773 | Acc: 36.741,43.427,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.771 | Acc: 36.765,43.503,2.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.769 | Acc: 36.741,43.519,2.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.762 | Acc: 36.842,43.642,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.770 | Acc: 36.756,43.473,2.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.764 | Acc: 36.768,43.533,2.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.256 | Acc: 34.375,35.156,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.545 | Acc: 30.320,35.603,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.579 | Acc: 29.802,35.785,2.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.608 | Acc: 29.726,35.707,2.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 8.431 | Acc: 41.406,44.531,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.688 | Acc: 37.426,43.304,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.647 | Acc: 37.481,43.902,2.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.654 | Acc: 36.796,44.121,2.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.679 | Acc: 36.863,43.866,2.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.683 | Acc: 36.757,43.820,2.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.691 | Acc: 36.738,43.970,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.698 | Acc: 36.830,44.049,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.684 | Acc: 36.893,44.158,2.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.677 | Acc: 36.982,44.238,2.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.683 | Acc: 36.983,44.189,2.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.677 | Acc: 37.058,44.379,2.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.665 | Acc: 37.121,44.424,2.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.672 | Acc: 37.039,44.355,2.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.677 | Acc: 36.908,44.273,2.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.678 | Acc: 36.874,44.285,2.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.682 | Acc: 36.853,44.229,2.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.681 | Acc: 36.863,44.270,2.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.681 | Acc: 36.894,44.181,2.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.686 | Acc: 36.811,44.070,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.859 | Acc: 33.594,38.281,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.290 | Acc: 25.298,32.999,3.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.298 | Acc: 25.229,32.146,3.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.268 | Acc: 25.295,32.275,3.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 8.720 | Acc: 35.156,42.188,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.643 | Acc: 36.719,45.536,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.644 | Acc: 36.795,45.122,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.626 | Acc: 37.295,45.172,2.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.639 | Acc: 37.249,44.869,2.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.632 | Acc: 37.430,44.864,2.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.636 | Acc: 37.390,44.777,2.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.648 | Acc: 37.168,44.542,2.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.656 | Acc: 37.010,44.371,2.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.657 | Acc: 36.935,44.238,2.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.643 | Acc: 37.205,44.360,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.646 | Acc: 37.196,44.351,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.642 | Acc: 37.130,44.359,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.640 | Acc: 37.084,44.403,2.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.641 | Acc: 37.116,44.370,2.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.632 | Acc: 37.285,44.568,2.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.633 | Acc: 37.266,44.507,2.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.636 | Acc: 37.152,44.472,2.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.636 | Acc: 37.119,44.488,2.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.635 | Acc: 37.125,44.439,2.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.536 | Acc: 35.938,39.062,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.893 | Acc: 28.460,31.920,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.911 | Acc: 28.525,31.955,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.952 | Acc: 27.971,31.673,2.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 8.852 | Acc: 35.938,40.625,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.617 | Acc: 36.868,44.494,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.613 | Acc: 36.700,44.303,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.574 | Acc: 36.680,44.787,2.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.570 | Acc: 37.037,45.052,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.542 | Acc: 37.353,45.382,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.545 | Acc: 37.519,45.241,2.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.530 | Acc: 37.899,45.545,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.540 | Acc: 37.869,45.458,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.546 | Acc: 37.876,45.416,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.557 | Acc: 37.733,45.250,2.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.566 | Acc: 37.574,45.026,2.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.564 | Acc: 37.597,45.115,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.564 | Acc: 37.602,45.160,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.569 | Acc: 37.592,45.118,2.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.567 | Acc: 37.516,45.105,2.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.571 | Acc: 37.444,45.050,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.575 | Acc: 37.445,45.070,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.578 | Acc: 37.318,45.042,2.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.579 | Acc: 37.252,44.948,2.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.974 | Acc: 28.125,32.031,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.231 | Acc: 26.190,34.115,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.217 | Acc: 26.867,34.546,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.226 | Acc: 27.088,34.106,2.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 8.267 | Acc: 38.281,48.438,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.451 | Acc: 37.314,45.945,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.473 | Acc: 37.348,46.532,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.496 | Acc: 37.769,46.183,2.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.516 | Acc: 37.481,45.843,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.514 | Acc: 37.794,45.854,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.506 | Acc: 37.958,46.029,2.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.513 | Acc: 37.921,46.016,3.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.522 | Acc: 37.893,45.987,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.522 | Acc: 37.880,45.912,2.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.536 | Acc: 37.667,45.717,2.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.534 | Acc: 37.620,45.765,2.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.531 | Acc: 37.526,45.630,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.530 | Acc: 37.524,45.606,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.529 | Acc: 37.430,45.546,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.524 | Acc: 37.445,45.536,2.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.521 | Acc: 37.561,45.602,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.518 | Acc: 37.640,45.654,2.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.514 | Acc: 37.710,45.663,2.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.517 | Acc: 37.709,45.624,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.921 | Acc: 30.469,39.844,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.145 | Acc: 25.223,35.863,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.133 | Acc: 25.572,35.918,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.095 | Acc: 25.871,36.142,3.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 8.753 | Acc: 34.375,52.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.552 | Acc: 36.979,46.652,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.485 | Acc: 37.252,46.132,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.483 | Acc: 37.436,45.966,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.483 | Acc: 37.539,45.882,2.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.463 | Acc: 37.894,46.264,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.448 | Acc: 37.913,46.404,2.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.438 | Acc: 38.026,46.504,2.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.459 | Acc: 37.922,46.234,2.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.459 | Acc: 37.945,46.241,2.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.460 | Acc: 37.908,46.171,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.454 | Acc: 38.034,46.242,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.458 | Acc: 38.041,46.246,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.453 | Acc: 38.141,46.315,2.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.452 | Acc: 38.223,46.341,2.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.457 | Acc: 38.151,46.283,2.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.457 | Acc: 38.067,46.323,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.457 | Acc: 37.988,46.330,2.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.460 | Acc: 37.909,46.267,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.460 | Acc: 37.910,46.309,2.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.105 | Acc: 31.250,46.094,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.594 | Acc: 27.976,39.062,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.605 | Acc: 27.992,38.091,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.587 | Acc: 27.766,38.179,2.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 8.428 | Acc: 36.719,45.312,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.416 | Acc: 37.314,47.917,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.404 | Acc: 37.386,46.932,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.426 | Acc: 37.538,46.606,2.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.395 | Acc: 38.021,46.827,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.410 | Acc: 37.918,46.728,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.418 | Acc: 37.874,46.643,2.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.421 | Acc: 37.799,46.592,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.422 | Acc: 37.636,46.632,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.429 | Acc: 37.500,46.525,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.416 | Acc: 37.718,46.615,2.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.418 | Acc: 37.737,46.758,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.424 | Acc: 37.753,46.700,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.441 | Acc: 37.581,46.468,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.442 | Acc: 37.575,46.489,2.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.439 | Acc: 37.640,46.613,2.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.438 | Acc: 37.592,46.576,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.439 | Acc: 37.615,46.547,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.430 | Acc: 37.690,46.613,2.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.429 | Acc: 37.734,46.649,2.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.694 | Acc: 28.125,33.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.667 | Acc: 26.042,37.388,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.651 | Acc: 26.334,37.805,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.640 | Acc: 26.140,37.615,2.984,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 7.967 | Acc: 45.312,52.344,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.461 | Acc: 37.165,46.094,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.446 | Acc: 37.519,46.646,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.417 | Acc: 37.948,47.118,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.385 | Acc: 38.079,47.348,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.368 | Acc: 38.328,47.432,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.363 | Acc: 38.243,47.463,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.379 | Acc: 38.037,47.241,2.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.386 | Acc: 37.908,47.030,2.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.390 | Acc: 37.906,46.905,2.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.383 | Acc: 37.904,47.007,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.386 | Acc: 37.800,46.942,2.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.392 | Acc: 37.766,46.904,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.393 | Acc: 37.805,46.863,2.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.391 | Acc: 37.889,46.947,2.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.392 | Acc: 37.933,46.901,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.388 | Acc: 37.965,46.912,2.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.389 | Acc: 37.915,46.820,2.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.386 | Acc: 37.987,46.860,2.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.387 | Acc: 38.039,46.898,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.621 | Acc: 27.344,35.156,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.691 | Acc: 28.088,37.500,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.742 | Acc: 27.630,37.633,3.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.783 | Acc: 27.113,37.308,3.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 8.589 | Acc: 36.719,46.094,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.324 | Acc: 40.327,48.475,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.285 | Acc: 40.111,48.628,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.292 | Acc: 39.716,48.553,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.308 | Acc: 39.583,48.225,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.342 | Acc: 39.179,47.896,2.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.334 | Acc: 39.075,47.798,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.334 | Acc: 38.863,47.784,2.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.335 | Acc: 38.771,47.651,2.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.338 | Acc: 38.907,47.751,2.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.325 | Acc: 38.969,47.886,2.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.321 | Acc: 38.967,47.921,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.333 | Acc: 38.699,47.702,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.334 | Acc: 38.622,47.668,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.344 | Acc: 38.632,47.620,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.344 | Acc: 38.564,47.659,2.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.349 | Acc: 38.495,47.527,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.351 | Acc: 38.471,47.487,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.355 | Acc: 38.368,47.410,2.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.351 | Acc: 38.382,47.494,2.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.929 | Acc: 39.062,41.406,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.396 | Acc: 31.696,35.677,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.396 | Acc: 31.536,36.109,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.416 | Acc: 30.994,35.899,3.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 8.504 | Acc: 36.719,47.656,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.367 | Acc: 38.356,48.214,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.326 | Acc: 38.434,47.351,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.316 | Acc: 39.037,48.105,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.330 | Acc: 38.445,47.676,2.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.312 | Acc: 38.560,47.912,2.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.304 | Acc: 38.598,48.044,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.294 | Acc: 38.719,48.111,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.281 | Acc: 38.844,48.166,2.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.295 | Acc: 38.747,48.066,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.291 | Acc: 38.755,48.068,2.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.297 | Acc: 38.624,48.056,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.298 | Acc: 38.609,48.084,2.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.290 | Acc: 38.721,48.192,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.290 | Acc: 38.648,48.243,2.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.294 | Acc: 38.621,48.152,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.295 | Acc: 38.649,48.150,2.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.296 | Acc: 38.673,48.069,2.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.303 | Acc: 38.645,47.992,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.305 | Acc: 38.607,47.954,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.831 | Acc: 37.500,40.625,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.067 | Acc: 34.152,39.695,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.057 | Acc: 33.784,39.386,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.081 | Acc: 33.312,39.178,2.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 8.015 | Acc: 40.625,43.750,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.277 | Acc: 38.058,47.582,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.290 | Acc: 37.843,47.542,3.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.280 | Acc: 37.974,47.439,3.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.278 | Acc: 38.117,47.753,3.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.270 | Acc: 38.057,48.028,3.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.265 | Acc: 38.236,48.102,3.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.255 | Acc: 38.259,48.127,3.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.258 | Acc: 38.441,48.350,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.265 | Acc: 38.406,48.226,3.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.267 | Acc: 38.394,48.216,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.268 | Acc: 38.564,48.264,3.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.274 | Acc: 38.511,48.220,3.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.283 | Acc: 38.551,48.108,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.283 | Acc: 38.595,48.123,3.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.282 | Acc: 38.580,48.235,3.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.282 | Acc: 38.559,48.279,3.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.287 | Acc: 38.448,48.130,3.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.287 | Acc: 38.511,48.197,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.286 | Acc: 38.531,48.226,3.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.583 | Acc: 31.250,37.500,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.590 | Acc: 29.204,36.756,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.696 | Acc: 27.934,35.499,2.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.707 | Acc: 28.279,35.515,2.228,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 8.984 | Acc: 35.156,42.188,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.234 | Acc: 39.100,49.554,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.235 | Acc: 39.062,49.733,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.228 | Acc: 39.037,49.462,2.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.232 | Acc: 38.947,49.363,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.252 | Acc: 39.008,49.180,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.231 | Acc: 39.095,49.277,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.239 | Acc: 39.195,49.113,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.247 | Acc: 39.160,49.030,2.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.247 | Acc: 39.153,48.865,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.243 | Acc: 39.187,48.892,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.249 | Acc: 38.995,48.894,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.247 | Acc: 38.926,48.865,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.256 | Acc: 38.850,48.749,3.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.264 | Acc: 38.784,48.549,2.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.268 | Acc: 38.780,48.471,2.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.269 | Acc: 38.841,48.452,2.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.270 | Acc: 38.813,48.396,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.268 | Acc: 38.848,48.401,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.263 | Acc: 38.864,48.425,2.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.935 | Acc: 25.781,33.594,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.121 | Acc: 25.112,35.119,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.168 | Acc: 24.714,34.508,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.194 | Acc: 24.334,33.991,2.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 8.235 | Acc: 38.281,44.531,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.150 | Acc: 38.356,49.368,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.160 | Acc: 38.662,49.447,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.134 | Acc: 39.395,50.179,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.200 | Acc: 39.053,49.306,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.204 | Acc: 39.070,49.404,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.207 | Acc: 39.153,49.251,2.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.196 | Acc: 39.334,49.346,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.192 | Acc: 39.218,49.238,2.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.187 | Acc: 39.209,49.279,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.189 | Acc: 39.327,49.335,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.194 | Acc: 39.264,49.396,2.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.195 | Acc: 39.244,49.361,2.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.202 | Acc: 39.080,49.231,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.219 | Acc: 38.985,49.069,2.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.234 | Acc: 38.785,48.920,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.224 | Acc: 38.870,49.002,2.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.229 | Acc: 38.813,48.946,2.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.233 | Acc: 38.731,48.840,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.230 | Acc: 38.749,48.928,2.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.321 | Acc: 39.062,39.062,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.317 | Acc: 29.576,38.356,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.392 | Acc: 29.821,37.652,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.376 | Acc: 29.828,38.243,2.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 8.536 | Acc: 32.031,42.969,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.051 | Acc: 39.658,48.921,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.130 | Acc: 39.253,49.333,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.146 | Acc: 38.922,49.232,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.144 | Acc: 39.082,49.585,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.141 | Acc: 39.333,49.776,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.148 | Acc: 39.514,49.806,2.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.148 | Acc: 39.522,49.878,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.149 | Acc: 39.320,49.791,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.161 | Acc: 39.313,49.663,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.170 | Acc: 39.307,49.475,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.172 | Acc: 39.176,49.427,2.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.173 | Acc: 39.205,49.498,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.175 | Acc: 39.257,49.428,2.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.175 | Acc: 39.240,49.430,2.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.176 | Acc: 39.273,49.509,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.183 | Acc: 39.189,49.362,2.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.175 | Acc: 39.221,49.413,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.180 | Acc: 39.164,49.318,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.188 | Acc: 39.128,49.202,2.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.564 | Acc: 27.344,30.469,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.339 | Acc: 24.888,33.147,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.340 | Acc: 24.962,33.537,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.280 | Acc: 25.077,33.581,2.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 8.241 | Acc: 39.062,50.000,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.148 | Acc: 39.546,50.112,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.135 | Acc: 38.986,49.943,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.117 | Acc: 39.139,50.448,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.144 | Acc: 38.821,49.932,2.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.149 | Acc: 39.101,49.714,2.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.163 | Acc: 38.933,49.522,2.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.147 | Acc: 39.135,49.557,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.154 | Acc: 39.101,49.573,2.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.159 | Acc: 39.054,49.448,3.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.161 | Acc: 39.012,49.464,3.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.160 | Acc: 38.964,49.477,3.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.170 | Acc: 38.855,49.400,3.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.180 | Acc: 38.724,49.350,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.177 | Acc: 38.740,49.374,3.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.179 | Acc: 38.704,49.317,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.179 | Acc: 38.724,49.343,2.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.176 | Acc: 38.808,49.340,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.172 | Acc: 38.842,49.381,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.173 | Acc: 38.866,49.395,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.393 | Acc: 37.500,41.406,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.643 | Acc: 27.641,36.198,3.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.717 | Acc: 27.210,35.652,3.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.714 | Acc: 27.344,35.592,3.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 8.085 | Acc: 41.406,47.656,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.105 | Acc: 39.732,50.781,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.143 | Acc: 39.196,49.943,3.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.136 | Acc: 39.370,49.731,3.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.114 | Acc: 39.892,50.251,3.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.134 | Acc: 39.627,49.745,3.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.145 | Acc: 39.566,49.916,3.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.155 | Acc: 39.284,49.839,3.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.150 | Acc: 39.446,49.971,3.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.153 | Acc: 39.239,49.892,3.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.135 | Acc: 39.509,50.070,3.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.125 | Acc: 39.589,50.085,3.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.123 | Acc: 39.445,50.052,3.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.128 | Acc: 39.482,50.006,3.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.125 | Acc: 39.566,49.975,3.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.128 | Acc: 39.587,49.927,3.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.124 | Acc: 39.617,49.959,3.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.126 | Acc: 39.587,49.924,3.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.124 | Acc: 39.584,49.991,3.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.125 | Acc: 39.608,50.043,3.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.849 | Acc: 35.938,41.406,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.030 | Acc: 33.296,41.183,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.094 | Acc: 32.774,40.415,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.155 | Acc: 32.172,39.895,2.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 8.115 | Acc: 31.250,46.875,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.125 | Acc: 40.067,51.339,3.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.096 | Acc: 40.015,51.067,3.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.107 | Acc: 39.421,51.217,3.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.095 | Acc: 39.583,51.128,3.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.113 | Acc: 39.380,50.704,3.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.126 | Acc: 39.205,50.439,3.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.115 | Acc: 39.389,50.493,3.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.114 | Acc: 39.567,50.519,3.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.112 | Acc: 39.602,50.527,3.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.119 | Acc: 39.463,50.249,3.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.116 | Acc: 39.554,50.325,3.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.113 | Acc: 39.584,50.357,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.117 | Acc: 39.610,50.248,3.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.118 | Acc: 39.702,50.289,3.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.117 | Acc: 39.634,50.291,3.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.117 | Acc: 39.608,50.299,3.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.115 | Acc: 39.670,50.266,3.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.118 | Acc: 39.623,50.260,3.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.120 | Acc: 39.672,50.258,3.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.453 | Acc: 30.469,39.844,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.337 | Acc: 29.018,39.174,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.377 | Acc: 29.040,39.043,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.376 | Acc: 29.470,39.344,3.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 8.233 | Acc: 42.188,57.031,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.976 | Acc: 41.220,51.600,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.913 | Acc: 42.283,52.172,3.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.969 | Acc: 41.509,51.665,3.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.003 | Acc: 40.856,51.215,3.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.001 | Acc: 40.965,51.346,3.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.031 | Acc: 40.774,51.065,3.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.039 | Acc: 40.714,50.892,3.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.039 | Acc: 40.756,50.946,3.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.040 | Acc: 40.733,50.915,3.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.049 | Acc: 40.633,50.840,3.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.064 | Acc: 40.370,50.739,3.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.069 | Acc: 40.369,50.723,3.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.072 | Acc: 40.380,50.739,3.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.073 | Acc: 40.230,50.678,3.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.070 | Acc: 40.246,50.716,3.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.071 | Acc: 40.228,50.686,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.076 | Acc: 40.233,50.609,3.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.080 | Acc: 40.129,50.522,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.084 | Acc: 40.102,50.441,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.970 | Acc: 30.469,39.062,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.066 | Acc: 25.967,36.012,3.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.080 | Acc: 25.781,35.995,3.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.111 | Acc: 25.410,35.681,3.727,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 8.288 | Acc: 35.938,46.875,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.042 | Acc: 40.030,50.781,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.013 | Acc: 40.625,51.162,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.001 | Acc: 40.369,51.025,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.993 | Acc: 40.538,51.485,3.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.992 | Acc: 40.432,51.524,3.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.993 | Acc: 40.360,51.466,3.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.994 | Acc: 40.293,51.463,3.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.004 | Acc: 40.334,51.499,3.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.022 | Acc: 40.167,51.377,3.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.028 | Acc: 40.077,51.131,3.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.028 | Acc: 40.070,51.142,3.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.030 | Acc: 39.986,51.011,3.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.032 | Acc: 39.996,51.033,3.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.035 | Acc: 40.088,50.990,3.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.037 | Acc: 40.070,50.960,3.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.041 | Acc: 39.953,50.901,3.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.048 | Acc: 39.938,50.839,3.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.055 | Acc: 39.917,50.716,3.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.059 | Acc: 39.827,50.683,3.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.637 | Acc: 25.000,41.406,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.986 | Acc: 24.107,37.537,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.044 | Acc: 23.666,36.452,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.063 | Acc: 23.258,36.283,2.293,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 7.447 | Acc: 45.312,58.594,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.887 | Acc: 41.815,53.237,3.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.921 | Acc: 41.120,52.725,3.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.933 | Acc: 41.457,52.446,3.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.950 | Acc: 40.914,52.122,3.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.957 | Acc: 40.842,52.003,3.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.979 | Acc: 40.606,51.950,3.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.003 | Acc: 40.337,51.723,3.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.013 | Acc: 40.285,51.465,3.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.023 | Acc: 40.180,51.247,3.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.036 | Acc: 40.019,51.158,3.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.041 | Acc: 39.992,51.071,3.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.045 | Acc: 39.889,50.998,3.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.046 | Acc: 39.949,50.955,3.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.044 | Acc: 40.005,51.048,3.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.040 | Acc: 40.132,51.041,3.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.051 | Acc: 39.997,50.981,3.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.050 | Acc: 39.967,50.994,3.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.048 | Acc: 39.909,51.011,3.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.050 | Acc: 39.893,50.984,3.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.732 | Acc: 24.219,44.531,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.647 | Acc: 24.702,39.955,3.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.643 | Acc: 24.447,40.396,3.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.677 | Acc: 24.705,40.164,3.624,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 8.134 | Acc: 35.938,53.125,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.123 | Acc: 37.500,50.298,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.081 | Acc: 38.415,51.239,3.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.043 | Acc: 39.011,51.627,3.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.023 | Acc: 39.757,51.736,3.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.026 | Acc: 39.759,51.926,3.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.026 | Acc: 39.876,51.872,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.029 | Acc: 39.988,51.790,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.031 | Acc: 40.048,51.684,3.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.029 | Acc: 39.991,51.597,3.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.030 | Acc: 40.058,51.481,3.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.028 | Acc: 40.077,51.591,3.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.023 | Acc: 40.029,51.614,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.027 | Acc: 40.056,51.595,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.025 | Acc: 40.047,51.590,3.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.033 | Acc: 39.984,51.461,3.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.034 | Acc: 39.941,51.443,3.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.034 | Acc: 39.901,51.432,3.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.034 | Acc: 39.872,51.370,3.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.027 | Acc: 40.004,51.501,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.511 | Acc: 29.688,50.000,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.971 | Acc: 31.362,42.150,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.947 | Acc: 31.764,42.226,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.986 | Acc: 31.224,41.995,2.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 7.707 | Acc: 45.312,53.906,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.889 | Acc: 41.629,52.679,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.943 | Acc: 41.482,52.191,3.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.951 | Acc: 41.381,52.357,3.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.967 | Acc: 40.972,52.151,2.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.986 | Acc: 40.540,51.764,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.009 | Acc: 40.263,51.466,2.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.987 | Acc: 40.470,51.734,3.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.990 | Acc: 40.348,51.635,3.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.987 | Acc: 40.474,51.562,3.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.988 | Acc: 40.450,51.609,3.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.993 | Acc: 40.399,51.502,3.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.995 | Acc: 40.411,51.540,3.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.996 | Acc: 40.439,51.527,3.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.004 | Acc: 40.339,51.493,3.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.006 | Acc: 40.236,51.368,3.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.006 | Acc: 40.267,51.302,3.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.006 | Acc: 40.258,51.388,3.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.011 | Acc: 40.173,51.350,3.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.014 | Acc: 40.217,51.333,3.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.846 | Acc: 28.906,46.094,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.283 | Acc: 28.757,42.448,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.313 | Acc: 28.125,42.454,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.374 | Acc: 27.574,41.893,3.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 8.229 | Acc: 42.969,50.000,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.907 | Acc: 41.890,54.018,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.931 | Acc: 40.606,53.201,3.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.920 | Acc: 40.881,53.112,3.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.931 | Acc: 40.741,52.913,3.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.934 | Acc: 40.733,52.978,3.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.946 | Acc: 40.696,52.751,3.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.950 | Acc: 40.841,52.532,3.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.958 | Acc: 40.805,52.402,3.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.958 | Acc: 40.923,52.309,3.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.962 | Acc: 41.045,52.227,3.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.965 | Acc: 40.986,52.100,3.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.969 | Acc: 40.923,52.062,3.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.974 | Acc: 40.781,51.907,3.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.974 | Acc: 40.745,51.882,3.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.986 | Acc: 40.563,51.760,3.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.993 | Acc: 40.503,51.711,3.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.995 | Acc: 40.426,51.684,3.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.997 | Acc: 40.361,51.656,3.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.997 | Acc: 40.344,51.690,3.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.770 | Acc: 39.062,46.875,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.933 | Acc: 35.342,45.238,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.928 | Acc: 35.480,44.436,1.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.945 | Acc: 34.734,44.390,1.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 7.704 | Acc: 45.312,60.156,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.770 | Acc: 42.560,55.060,3.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.855 | Acc: 41.330,53.925,3.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.914 | Acc: 41.176,53.266,3.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.909 | Acc: 41.011,52.874,3.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.912 | Acc: 40.594,52.707,3.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.903 | Acc: 40.845,52.692,3.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.908 | Acc: 40.852,52.610,3.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.909 | Acc: 40.843,52.776,3.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.927 | Acc: 40.694,52.642,3.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.937 | Acc: 40.574,52.449,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.947 | Acc: 40.629,52.344,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.943 | Acc: 40.606,52.318,3.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.943 | Acc: 40.601,52.305,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.939 | Acc: 40.728,52.394,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.944 | Acc: 40.651,52.318,3.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.947 | Acc: 40.584,52.288,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.951 | Acc: 40.471,52.181,3.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.959 | Acc: 40.396,52.056,3.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.963 | Acc: 40.426,52.014,3.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.801 | Acc: 35.938,39.844,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.112 | Acc: 30.357,42.225,3.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.131 | Acc: 29.364,41.254,3.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.127 | Acc: 29.098,41.406,3.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 7.932 | Acc: 40.625,53.125,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.866 | Acc: 41.406,53.646,4.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.858 | Acc: 41.349,53.125,3.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.899 | Acc: 41.329,52.997,3.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.928 | Acc: 40.828,52.894,3.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.929 | Acc: 40.787,52.444,3.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.923 | Acc: 40.941,52.893,3.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.924 | Acc: 40.858,52.859,3.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.929 | Acc: 40.644,52.679,3.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.934 | Acc: 40.556,52.568,3.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.926 | Acc: 40.602,52.678,3.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.926 | Acc: 40.593,52.577,3.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.922 | Acc: 40.703,52.571,3.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.930 | Acc: 40.553,52.365,3.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.934 | Acc: 40.519,52.344,3.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.938 | Acc: 40.487,52.281,3.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.934 | Acc: 40.533,52.329,3.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.936 | Acc: 40.497,52.316,3.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.937 | Acc: 40.489,52.257,3.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.931 | Acc: 40.557,52.350,3.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.182 | Acc: 32.031,44.531,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.270 | Acc: 28.943,39.472,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.313 | Acc: 29.287,38.472,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.345 | Acc: 28.727,38.614,3.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 7.620 | Acc: 45.312,52.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.946 | Acc: 40.848,52.195,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.901 | Acc: 40.549,52.439,3.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.906 | Acc: 41.048,52.613,3.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.910 | Acc: 40.885,52.710,3.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.908 | Acc: 40.555,52.738,3.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.922 | Acc: 40.251,52.518,3.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.915 | Acc: 40.326,52.654,3.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.916 | Acc: 40.266,52.615,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.924 | Acc: 40.224,52.555,3.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.924 | Acc: 40.306,52.523,3.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.927 | Acc: 40.261,52.443,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.931 | Acc: 40.304,52.422,3.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.926 | Acc: 40.383,52.511,3.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.922 | Acc: 40.486,52.552,3.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.927 | Acc: 40.394,52.453,3.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.924 | Acc: 40.460,52.534,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.927 | Acc: 40.483,52.465,3.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.929 | Acc: 40.428,52.391,3.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.928 | Acc: 40.397,52.411,3.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.948 | Acc: 30.469,46.875,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.441 | Acc: 28.869,40.067,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.435 | Acc: 27.934,39.977,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.443 | Acc: 27.446,39.921,2.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 7.856 | Acc: 39.844,51.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.760 | Acc: 42.299,55.171,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.839 | Acc: 40.892,53.563,3.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.850 | Acc: 40.958,53.753,3.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.864 | Acc: 40.934,53.627,3.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.871 | Acc: 40.656,53.489,3.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.880 | Acc: 40.709,53.403,3.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.881 | Acc: 40.969,53.369,3.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.885 | Acc: 40.872,53.377,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.881 | Acc: 40.720,53.414,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.890 | Acc: 40.606,53.300,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.883 | Acc: 40.657,53.316,3.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.889 | Acc: 40.602,53.222,3.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.895 | Acc: 40.532,53.152,3.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.899 | Acc: 40.508,53.119,3.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.903 | Acc: 40.454,53.037,3.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.901 | Acc: 40.515,53.120,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.902 | Acc: 40.536,53.063,2.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.895 | Acc: 40.668,53.051,2.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.903 | Acc: 40.629,52.955,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.688 | Acc: 32.812,43.750,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.031 | Acc: 26.339,40.402,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.948 | Acc: 26.372,40.396,2.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.925 | Acc: 25.897,40.343,2.293,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 7.905 | Acc: 34.375,53.906,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.851 | Acc: 40.885,53.013,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.858 | Acc: 40.968,53.316,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.851 | Acc: 41.163,53.304,3.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.848 | Acc: 41.146,53.617,3.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.850 | Acc: 41.159,53.806,3.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.879 | Acc: 40.793,53.667,2.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.893 | Acc: 40.836,53.330,3.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.898 | Acc: 40.732,53.460,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.890 | Acc: 40.660,53.501,3.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.888 | Acc: 40.773,53.560,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.893 | Acc: 40.752,53.415,3.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.906 | Acc: 40.619,53.332,3.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.900 | Acc: 40.625,53.260,2.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.902 | Acc: 40.581,53.250,2.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.905 | Acc: 40.560,53.195,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.911 | Acc: 40.525,53.113,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.910 | Acc: 40.565,53.070,2.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.917 | Acc: 40.515,52.880,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.918 | Acc: 40.510,52.932,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.707 | Acc: 30.469,41.406,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.749 | Acc: 34.412,45.052,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.767 | Acc: 34.013,44.989,3.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.782 | Acc: 33.786,44.672,3.458,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 7.812 | Acc: 46.875,57.812,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.794 | Acc: 42.783,53.869,3.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.831 | Acc: 41.711,53.220,3.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.832 | Acc: 41.790,53.560,3.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.825 | Acc: 41.406,53.733,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.829 | Acc: 41.313,53.489,3.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.836 | Acc: 41.161,53.558,3.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.854 | Acc: 41.046,53.363,3.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.860 | Acc: 41.149,53.271,3.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.861 | Acc: 41.143,53.190,3.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.867 | Acc: 41.099,53.164,3.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.861 | Acc: 41.085,53.171,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.859 | Acc: 41.150,53.216,3.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.860 | Acc: 41.122,53.149,3.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.864 | Acc: 41.020,53.114,3.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.865 | Acc: 40.975,53.099,3.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.866 | Acc: 40.907,53.154,3.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.868 | Acc: 40.875,53.072,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.871 | Acc: 40.794,53.010,3.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.869 | Acc: 40.810,53.041,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.096 | Acc: 30.469,44.531,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.932 | Acc: 31.436,41.927,3.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.997 | Acc: 30.507,41.139,3.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.015 | Acc: 30.059,41.240,3.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 8.246 | Acc: 39.844,56.250,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.853 | Acc: 40.513,53.162,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.868 | Acc: 40.187,52.934,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.845 | Acc: 40.638,52.920,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.805 | Acc: 41.155,53.578,3.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.820 | Acc: 41.136,53.651,3.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.826 | Acc: 41.296,53.454,3.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.821 | Acc: 41.401,53.563,3.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.823 | Acc: 41.314,53.562,3.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.831 | Acc: 41.177,53.380,3.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.845 | Acc: 41.076,53.327,3.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.849 | Acc: 41.131,53.369,3.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.850 | Acc: 41.144,53.339,3.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.850 | Acc: 41.128,53.433,3.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.852 | Acc: 41.178,53.464,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.855 | Acc: 41.121,53.465,3.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.850 | Acc: 41.190,53.485,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.854 | Acc: 41.124,53.407,3.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.859 | Acc: 41.060,53.352,3.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.862 | Acc: 41.006,53.379,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.174 | Acc: 28.906,39.062,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.380 | Acc: 23.400,36.905,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.379 | Acc: 24.009,37.043,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.401 | Acc: 23.706,37.116,2.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 7.496 | Acc: 40.625,58.594,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.734 | Acc: 43.080,54.539,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.760 | Acc: 41.502,53.830,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.820 | Acc: 40.625,53.112,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.823 | Acc: 40.673,53.299,2.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.844 | Acc: 40.733,53.318,2.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.848 | Acc: 40.573,53.112,2.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.847 | Acc: 40.542,53.158,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.839 | Acc: 40.678,53.440,3.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.838 | Acc: 40.590,53.457,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.832 | Acc: 40.734,53.553,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.825 | Acc: 40.752,53.705,2.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.820 | Acc: 40.764,53.631,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.814 | Acc: 40.870,53.736,3.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.822 | Acc: 40.822,53.753,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.818 | Acc: 40.781,53.810,3.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.823 | Acc: 40.795,53.797,3.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.823 | Acc: 40.774,53.721,3.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.822 | Acc: 40.785,53.701,3.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.824 | Acc: 40.830,53.750,2.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.430 | Acc: 30.469,41.406,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.545 | Acc: 25.149,41.778,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.550 | Acc: 24.829,40.701,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.601 | Acc: 24.411,39.933,2.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 7.453 | Acc: 44.531,61.719,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.812 | Acc: 40.811,54.278,3.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.868 | Acc: 41.063,53.582,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.857 | Acc: 41.150,53.957,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.867 | Acc: 40.982,53.733,3.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.864 | Acc: 40.795,53.318,3.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.848 | Acc: 41.077,53.700,3.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.870 | Acc: 40.675,53.485,3.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.862 | Acc: 40.780,53.528,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.867 | Acc: 40.694,53.410,3.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.872 | Acc: 40.777,53.358,3.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.867 | Acc: 40.759,53.507,3.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.866 | Acc: 40.816,53.498,3.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.859 | Acc: 40.861,53.583,3.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.860 | Acc: 40.872,53.573,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.862 | Acc: 40.936,53.616,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.864 | Acc: 40.963,53.602,3.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.858 | Acc: 40.978,53.618,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.861 | Acc: 40.984,53.558,3.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.860 | Acc: 40.988,53.519,3.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 237.012 | Acc: 28.906,42.188,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 235.243 | Acc: 29.353,41.034,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 234.580 | Acc: 29.592,40.206,1.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 233.589 | Acc: 29.278,39.562,1.255,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 7.595 | Acc: 39.844,46.875,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.807 | Acc: 41.369,53.646,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.851 | Acc: 40.930,53.373,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.834 | Acc: 40.894,53.471,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.813 | Acc: 41.165,53.501,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.801 | Acc: 41.476,53.566,3.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.789 | Acc: 41.555,53.796,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.805 | Acc: 41.439,53.662,3.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.825 | Acc: 41.198,53.567,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.817 | Acc: 41.376,53.703,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.826 | Acc: 41.321,53.619,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.835 | Acc: 41.113,53.567,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.838 | Acc: 40.969,53.433,3.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.846 | Acc: 40.864,53.245,3.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.841 | Acc: 40.945,53.361,3.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.844 | Acc: 40.934,53.382,3.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.863 | Acc: 40.771,53.210,3.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.864 | Acc: 40.730,53.251,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.861 | Acc: 40.857,53.354,3.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.863 | Acc: 40.840,53.320,3.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.832 | Acc: 36.719,45.312,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.017 | Acc: 32.850,44.420,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.008 | Acc: 32.279,43.998,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.050 | Acc: 32.185,43.904,3.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 7.966 | Acc: 42.188,52.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.941 | Acc: 40.960,53.237,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.936 | Acc: 40.796,53.525,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.928 | Acc: 40.843,53.727,3.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.914 | Acc: 41.184,53.858,3.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.913 | Acc: 41.321,53.914,3.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.893 | Acc: 41.355,54.010,3.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.896 | Acc: 41.445,54.178,3.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.909 | Acc: 41.421,54.241,3.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.910 | Acc: 41.385,54.221,3.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.918 | Acc: 41.212,54.155,3.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.920 | Acc: 41.208,54.090,3.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.920 | Acc: 41.293,54.072,3.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.916 | Acc: 41.319,54.083,3.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.912 | Acc: 41.356,54.123,3.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.912 | Acc: 41.401,54.116,3.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.910 | Acc: 41.438,54.147,3.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.910 | Acc: 41.422,54.122,3.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.913 | Acc: 41.307,54.038,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.914 | Acc: 41.287,53.996,3.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.426 | Acc: 39.844,49.219,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.929 | Acc: 32.961,44.010,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.010 | Acc: 32.679,42.854,3.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.009 | Acc: 32.339,43.148,3.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 7.970 | Acc: 39.844,57.031,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.916 | Acc: 41.890,54.836,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.865 | Acc: 42.378,54.840,3.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.867 | Acc: 41.906,54.816,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.871 | Acc: 41.609,54.620,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.864 | Acc: 41.569,54.463,3.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.851 | Acc: 41.832,54.462,3.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.853 | Acc: 41.733,54.488,3.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.856 | Acc: 41.848,54.489,3.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.864 | Acc: 41.769,54.299,3.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.863 | Acc: 41.647,54.361,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.872 | Acc: 41.537,54.193,3.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.868 | Acc: 41.546,54.273,3.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.868 | Acc: 41.646,54.346,3.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.877 | Acc: 41.626,54.304,3.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.882 | Acc: 41.598,54.236,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.879 | Acc: 41.752,54.247,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.875 | Acc: 41.759,54.339,3.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.880 | Acc: 41.668,54.278,3.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.895 | Acc: 41.583,54.238,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.067 | Acc: 32.812,44.531,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.237 | Acc: 30.469,42.894,1.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.246 | Acc: 30.678,43.026,1.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.282 | Acc: 30.277,42.918,1.614,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 7.729 | Acc: 44.531,58.594,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.844 | Acc: 41.369,55.246,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.942 | Acc: 40.644,54.268,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.918 | Acc: 40.753,54.495,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.908 | Acc: 41.078,54.774,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.926 | Acc: 41.197,54.455,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.916 | Acc: 41.154,54.384,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.913 | Acc: 41.096,54.471,3.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.892 | Acc: 41.329,54.658,3.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.893 | Acc: 41.298,54.601,3.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.897 | Acc: 41.305,54.668,3.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.891 | Acc: 41.488,54.634,3.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.896 | Acc: 41.393,54.477,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.891 | Acc: 41.481,54.559,3.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.899 | Acc: 41.484,54.532,3.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.904 | Acc: 41.453,54.488,3.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.904 | Acc: 41.474,54.527,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.906 | Acc: 41.491,54.495,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.908 | Acc: 41.443,54.447,3.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.909 | Acc: 41.408,54.390,3.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.246 | Acc: 30.469,36.719,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.062 | Acc: 26.637,34.487,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.074 | Acc: 25.877,34.432,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.070 | Acc: 25.653,34.580,2.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 7.701 | Acc: 46.875,55.469,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.952 | Acc: 41.071,54.278,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.888 | Acc: 42.149,55.240,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.884 | Acc: 41.816,54.969,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.904 | Acc: 41.368,54.417,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.885 | Acc: 41.770,54.610,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.885 | Acc: 41.665,54.629,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.881 | Acc: 41.628,54.699,3.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.886 | Acc: 41.532,54.668,3.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.888 | Acc: 41.419,54.614,3.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.883 | Acc: 41.500,54.563,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.883 | Acc: 41.396,54.560,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.879 | Acc: 41.422,54.597,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.873 | Acc: 41.505,54.643,3.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.870 | Acc: 41.612,54.701,3.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.876 | Acc: 41.541,54.651,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.880 | Acc: 41.423,54.559,3.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.881 | Acc: 41.420,54.575,3.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.881 | Acc: 41.389,54.577,3.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.883 | Acc: 41.429,54.573,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.719 | Acc: 38.281,53.125,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.756 | Acc: 35.268,46.168,3.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.754 | Acc: 35.309,45.713,3.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.805 | Acc: 34.593,45.453,3.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 7.861 | Acc: 43.750,61.719,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.817 | Acc: 41.406,55.804,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.861 | Acc: 41.482,55.221,3.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.857 | Acc: 41.381,54.982,3.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.856 | Acc: 41.348,54.678,3.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.860 | Acc: 41.097,54.510,3.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.854 | Acc: 41.271,54.733,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.854 | Acc: 41.185,54.815,3.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.851 | Acc: 41.227,54.925,3.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.856 | Acc: 41.177,54.830,3.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.858 | Acc: 41.204,54.676,3.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.854 | Acc: 41.283,54.737,3.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.852 | Acc: 41.322,54.704,3.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.861 | Acc: 41.272,54.679,3.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.864 | Acc: 41.395,54.632,3.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.863 | Acc: 41.471,54.630,3.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.858 | Acc: 41.625,54.688,3.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.853 | Acc: 41.672,54.761,3.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.861 | Acc: 41.525,54.601,3.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.863 | Acc: 41.474,54.605,3.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.627 | Acc: 35.156,48.438,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.918 | Acc: 32.478,44.680,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.897 | Acc: 32.774,45.046,3.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.955 | Acc: 31.570,44.365,3.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 8.038 | Acc: 38.281,51.562,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.835 | Acc: 41.778,55.432,3.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.769 | Acc: 41.883,56.345,3.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.760 | Acc: 42.520,56.096,3.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.782 | Acc: 41.725,55.864,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.805 | Acc: 41.623,55.685,3.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.818 | Acc: 41.497,55.223,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.822 | Acc: 41.362,55.164,3.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.825 | Acc: 41.513,55.197,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.824 | Acc: 41.557,55.253,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.828 | Acc: 41.507,55.239,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.830 | Acc: 41.625,55.264,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.847 | Acc: 41.387,55.115,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.856 | Acc: 41.328,54.930,3.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.856 | Acc: 41.362,55.007,3.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.852 | Acc: 41.344,55.040,3.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.854 | Acc: 41.353,55.099,3.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.855 | Acc: 41.253,55.033,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.857 | Acc: 41.229,54.958,3.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.857 | Acc: 41.291,54.927,3.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.891 | Acc: 34.375,43.750,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.136 | Acc: 31.287,41.815,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.153 | Acc: 31.269,41.921,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.193 | Acc: 31.071,41.739,2.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 7.818 | Acc: 37.500,56.250,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.811 | Acc: 42.039,54.501,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.818 | Acc: 42.283,54.726,3.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.823 | Acc: 41.611,54.841,3.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.805 | Acc: 42.024,55.006,3.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.795 | Acc: 42.280,55.461,3.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.804 | Acc: 42.129,55.598,3.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.811 | Acc: 41.938,55.397,3.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.804 | Acc: 41.921,55.362,3.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.804 | Acc: 41.885,55.525,2.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.822 | Acc: 41.772,55.340,2.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.831 | Acc: 41.816,55.306,2.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.837 | Acc: 41.727,55.313,2.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.833 | Acc: 41.879,55.388,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.846 | Acc: 41.773,55.174,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.852 | Acc: 41.707,55.186,2.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.855 | Acc: 41.618,55.094,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.863 | Acc: 41.528,55.022,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.860 | Acc: 41.582,55.019,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.863 | Acc: 41.605,54.979,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.348 | Acc: 33.594,46.094,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.655 | Acc: 27.567,38.951,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.710 | Acc: 27.191,38.491,2.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.762 | Acc: 26.883,38.461,2.011,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 8.322 | Acc: 36.719,48.438,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.831 | Acc: 42.671,55.729,3.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.840 | Acc: 42.340,55.907,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.859 | Acc: 42.239,55.866,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.819 | Acc: 42.284,56.211,2.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.843 | Acc: 42.288,55.925,2.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.844 | Acc: 42.000,55.662,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.847 | Acc: 41.894,55.513,2.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.841 | Acc: 41.891,55.561,2.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.847 | Acc: 41.907,55.460,2.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.854 | Acc: 41.857,55.352,2.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.862 | Acc: 41.696,55.239,3.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.857 | Acc: 41.821,55.472,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.856 | Acc: 41.822,55.499,3.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.867 | Acc: 41.759,55.330,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.874 | Acc: 41.692,55.266,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.878 | Acc: 41.674,55.240,2.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.878 | Acc: 41.738,55.233,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.888 | Acc: 41.701,55.170,2.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.896 | Acc: 41.622,55.100,2.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.673 | Acc: 39.844,50.781,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.788 | Acc: 36.421,45.126,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.812 | Acc: 35.938,45.389,1.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.848 | Acc: 35.476,45.325,1.652,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 7.583 | Acc: 45.312,56.250,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.957 | Acc: 41.704,55.246,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.905 | Acc: 40.892,55.469,2.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.901 | Acc: 41.201,55.020,2.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.911 | Acc: 41.416,54.958,2.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.896 | Acc: 41.468,55.384,2.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.893 | Acc: 41.581,55.301,2.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.892 | Acc: 41.622,55.192,2.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.896 | Acc: 41.663,55.017,2.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.899 | Acc: 41.566,55.028,2.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.901 | Acc: 41.593,55.119,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.899 | Acc: 41.498,55.154,2.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.901 | Acc: 41.341,55.060,2.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.907 | Acc: 41.260,55.029,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.901 | Acc: 41.492,55.038,2.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.900 | Acc: 41.554,55.002,2.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.895 | Acc: 41.533,55.060,2.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.893 | Acc: 41.585,55.150,2.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.891 | Acc: 41.536,55.231,2.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.886 | Acc: 41.576,55.278,2.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.836 | Acc: 34.375,50.000,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.875 | Acc: 33.371,46.875,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.882 | Acc: 33.117,45.522,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.926 | Acc: 33.158,45.312,2.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 7.332 | Acc: 42.969,60.156,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.834 | Acc: 41.778,55.841,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.815 | Acc: 42.569,55.831,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.831 | Acc: 41.701,55.853,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.828 | Acc: 41.590,55.498,2.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.827 | Acc: 41.863,55.639,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.827 | Acc: 41.852,55.559,2.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.818 | Acc: 42.049,55.602,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.816 | Acc: 41.921,55.546,2.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.816 | Acc: 41.967,55.421,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.815 | Acc: 41.981,55.500,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.815 | Acc: 42.060,55.525,2.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.826 | Acc: 41.983,55.349,2.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.839 | Acc: 41.828,55.229,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.841 | Acc: 41.859,55.246,2.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.845 | Acc: 41.827,55.209,2.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.844 | Acc: 41.878,55.315,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.845 | Acc: 41.871,55.398,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.853 | Acc: 41.835,55.345,2.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.856 | Acc: 41.827,55.368,2.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.257 | Acc: 29.688,45.312,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.224 | Acc: 31.808,41.146,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.213 | Acc: 31.574,41.197,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.261 | Acc: 30.802,40.958,2.254,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 7.991 | Acc: 42.969,51.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.752 | Acc: 44.159,56.436,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.822 | Acc: 42.931,55.697,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.824 | Acc: 42.789,55.879,2.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.800 | Acc: 42.940,56.520,2.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.794 | Acc: 42.830,56.358,2.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.814 | Acc: 42.769,56.140,2.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.823 | Acc: 42.631,56.039,2.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.825 | Acc: 42.716,55.959,2.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.828 | Acc: 42.731,55.883,2.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.829 | Acc: 42.751,55.807,2.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.833 | Acc: 42.640,55.808,2.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.850 | Acc: 42.463,55.595,2.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.856 | Acc: 42.469,55.642,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.858 | Acc: 42.574,55.661,2.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.866 | Acc: 42.387,55.575,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.872 | Acc: 42.248,55.561,2.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.880 | Acc: 42.149,55.526,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.886 | Acc: 41.993,55.519,2.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.887 | Acc: 41.995,55.506,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.537 | Acc: 31.250,39.062,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.376 | Acc: 31.994,41.332,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.402 | Acc: 31.764,41.197,2.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.403 | Acc: 31.865,41.701,2.075,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 8.229 | Acc: 41.406,51.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.967 | Acc: 39.918,54.241,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.889 | Acc: 41.273,55.450,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.871 | Acc: 41.637,55.866,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.894 | Acc: 41.580,55.826,3.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.904 | Acc: 41.522,55.593,3.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.912 | Acc: 41.710,55.507,2.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.920 | Acc: 41.645,55.375,2.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.913 | Acc: 41.625,55.590,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.908 | Acc: 41.739,55.581,3.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.911 | Acc: 41.779,55.581,3.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.918 | Acc: 41.742,55.600,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.931 | Acc: 41.578,55.365,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.930 | Acc: 41.619,55.394,2.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.926 | Acc: 41.701,55.363,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.928 | Acc: 41.715,55.355,2.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.931 | Acc: 41.686,55.342,2.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.927 | Acc: 41.732,55.336,2.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.929 | Acc: 41.701,55.345,2.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.930 | Acc: 41.679,55.299,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.887 | Acc: 44.531,44.531,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.663 | Acc: 36.049,46.503,3.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.707 | Acc: 35.880,45.846,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.711 | Acc: 35.579,45.633,3.138,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 8.020 | Acc: 40.625,54.688,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.848 | Acc: 43.080,56.510,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.829 | Acc: 42.226,56.441,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.841 | Acc: 42.444,56.301,3.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.830 | Acc: 42.448,56.279,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.833 | Acc: 42.311,56.482,2.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.839 | Acc: 42.426,56.295,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.847 | Acc: 42.215,56.062,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.864 | Acc: 41.969,55.847,2.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.864 | Acc: 41.976,55.728,2.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.866 | Acc: 42.009,55.741,2.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.862 | Acc: 42.085,55.879,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.877 | Acc: 41.944,55.712,2.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.871 | Acc: 41.951,55.699,3.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.868 | Acc: 41.929,55.744,3.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.871 | Acc: 41.892,55.757,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.866 | Acc: 41.983,55.778,3.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.861 | Acc: 41.949,55.822,3.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.863 | Acc: 41.885,55.735,3.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.858 | Acc: 41.917,55.848,3.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.179 | Acc: 28.906,41.406,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.418 | Acc: 29.501,42.560,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.459 | Acc: 29.821,42.092,2.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.500 | Acc: 29.803,41.893,2.357,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 7.548 | Acc: 43.750,58.594,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.752 | Acc: 42.522,56.771,3.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.745 | Acc: 42.835,56.574,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.748 | Acc: 42.751,56.737,3.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.736 | Acc: 42.766,56.694,3.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.743 | Acc: 42.721,56.559,3.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.751 | Acc: 42.536,56.366,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.741 | Acc: 42.670,56.483,3.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.748 | Acc: 42.610,56.677,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.746 | Acc: 42.593,56.617,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.758 | Acc: 42.378,56.386,2.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.773 | Acc: 42.343,56.331,2.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.775 | Acc: 42.366,56.273,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.784 | Acc: 42.229,56.172,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.793 | Acc: 42.112,56.078,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.803 | Acc: 42.110,55.972,2.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.805 | Acc: 42.066,55.931,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.809 | Acc: 42.064,55.867,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.806 | Acc: 42.151,55.941,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.821 | Acc: 41.978,55.793,2.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.282 | Acc: 33.594,39.844,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.202 | Acc: 32.738,40.737,3.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.204 | Acc: 33.270,40.053,3.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.265 | Acc: 32.672,39.985,3.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 7.930 | Acc: 39.062,54.688,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.878 | Acc: 42.671,55.543,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.842 | Acc: 42.454,56.136,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.846 | Acc: 42.380,55.891,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.840 | Acc: 41.995,55.970,2.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.814 | Acc: 42.288,56.691,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.805 | Acc: 42.504,56.650,2.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.809 | Acc: 42.520,56.560,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.799 | Acc: 42.527,56.599,2.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.790 | Acc: 42.472,56.725,2.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.784 | Acc: 42.537,56.713,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.784 | Acc: 42.456,56.756,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.783 | Acc: 42.551,56.765,2.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.795 | Acc: 42.280,56.660,2.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.792 | Acc: 42.310,56.661,2.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.793 | Acc: 42.278,56.673,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.794 | Acc: 42.282,56.588,2.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.793 | Acc: 42.279,56.598,2.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.791 | Acc: 42.261,56.598,2.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.795 | Acc: 42.241,56.474,2.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.168 | Acc: 32.031,42.969,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.392 | Acc: 26.562,43.080,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.396 | Acc: 26.486,42.340,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.357 | Acc: 26.691,42.508,2.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 7.709 | Acc: 43.750,54.688,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.639 | Acc: 44.420,59.040,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.614 | Acc: 44.970,58.956,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.667 | Acc: 43.596,57.851,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.679 | Acc: 43.412,57.697,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.708 | Acc: 43.201,57.449,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.716 | Acc: 42.898,57.251,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.722 | Acc: 42.730,57.137,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.740 | Acc: 42.542,56.968,2.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.744 | Acc: 42.503,56.906,2.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.748 | Acc: 42.405,56.876,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.754 | Acc: 42.371,56.939,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.758 | Acc: 42.376,56.966,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.762 | Acc: 42.310,56.846,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.761 | Acc: 42.368,56.845,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.764 | Acc: 42.325,56.772,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.769 | Acc: 42.270,56.737,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.769 | Acc: 42.284,56.713,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.769 | Acc: 42.302,56.627,2.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.776 | Acc: 42.153,56.599,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.814 | Acc: 39.062,47.656,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.899 | Acc: 33.036,46.503,4.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.887 | Acc: 32.489,46.322,3.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.950 | Acc: 31.814,45.658,3.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 7.209 | Acc: 46.875,66.406,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.615 | Acc: 44.010,58.110,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.650 | Acc: 43.178,57.832,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.639 | Acc: 43.148,57.992,2.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.639 | Acc: 42.901,58.218,2.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.634 | Acc: 43.062,58.300,3.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.662 | Acc: 42.898,58.129,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.688 | Acc: 42.664,57.785,2.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.700 | Acc: 42.551,57.555,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.713 | Acc: 42.313,57.320,2.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.721 | Acc: 42.238,57.167,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.726 | Acc: 42.325,57.127,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.736 | Acc: 42.252,56.986,2.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.741 | Acc: 42.214,56.935,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.746 | Acc: 42.087,56.837,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.750 | Acc: 42.021,56.795,2.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.753 | Acc: 42.095,56.783,2.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.751 | Acc: 42.110,56.738,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.749 | Acc: 42.177,56.808,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.757 | Acc: 42.171,56.748,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.454 | Acc: 39.844,48.438,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.787 | Acc: 34.189,45.201,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.807 | Acc: 33.155,44.493,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.840 | Acc: 32.928,44.288,2.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 7.909 | Acc: 43.750,58.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.794 | Acc: 42.411,56.734,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.794 | Acc: 41.825,56.250,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.767 | Acc: 41.931,56.391,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.734 | Acc: 42.390,56.655,3.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.742 | Acc: 42.288,56.629,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.718 | Acc: 42.620,56.870,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.722 | Acc: 42.642,56.594,3.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.725 | Acc: 42.697,56.599,2.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.716 | Acc: 42.727,56.772,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.718 | Acc: 42.646,56.681,3.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.722 | Acc: 42.668,56.766,3.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.728 | Acc: 42.577,56.684,3.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.722 | Acc: 42.666,56.771,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.728 | Acc: 42.518,56.703,3.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.731 | Acc: 42.496,56.735,3.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.741 | Acc: 42.438,56.673,3.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.736 | Acc: 42.451,56.688,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.738 | Acc: 42.430,56.659,3.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.743 | Acc: 42.349,56.578,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.992 | Acc: 39.844,41.406,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.880 | Acc: 33.594,46.205,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.863 | Acc: 33.727,46.380,3.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.875 | Acc: 33.581,46.376,3.266,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 7.633 | Acc: 47.656,63.281,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.632 | Acc: 42.225,58.780,3.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.634 | Acc: 42.664,58.136,3.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.638 | Acc: 42.559,58.056,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.682 | Acc: 42.313,57.591,3.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.674 | Acc: 42.721,57.565,3.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.680 | Acc: 42.523,57.580,3.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.667 | Acc: 42.631,57.663,3.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.675 | Acc: 42.464,57.584,3.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.671 | Acc: 42.395,57.528,3.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.678 | Acc: 42.351,57.533,2.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.688 | Acc: 42.336,57.378,3.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.692 | Acc: 42.372,57.362,3.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.692 | Acc: 42.409,57.399,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.698 | Acc: 42.346,57.254,3.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.703 | Acc: 42.297,57.153,2.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.709 | Acc: 42.299,56.997,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.713 | Acc: 42.277,56.946,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.715 | Acc: 42.281,56.921,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.713 | Acc: 42.319,56.996,2.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.124 | Acc: 35.938,46.094,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.981 | Acc: 30.878,46.243,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.014 | Acc: 31.117,45.008,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.049 | Acc: 30.443,44.634,2.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 7.690 | Acc: 50.000,60.156,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.618 | Acc: 43.787,59.040,3.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.627 | Acc: 43.140,58.098,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.651 | Acc: 42.879,57.531,2.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.652 | Acc: 42.757,57.591,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.680 | Acc: 42.698,57.302,3.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.669 | Acc: 42.594,57.457,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.660 | Acc: 42.620,57.619,3.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.658 | Acc: 42.571,57.589,3.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.662 | Acc: 42.416,57.623,3.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.673 | Acc: 42.327,57.525,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.670 | Acc: 42.301,57.622,3.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.670 | Acc: 42.346,57.628,2.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.671 | Acc: 42.313,57.492,2.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.676 | Acc: 42.282,57.334,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.675 | Acc: 42.351,57.322,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.682 | Acc: 42.331,57.236,2.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.691 | Acc: 42.259,57.164,2.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.694 | Acc: 42.237,57.079,2.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.694 | Acc: 42.229,57.060,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.824 | Acc: 31.250,39.062,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.513 | Acc: 26.414,42.746,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.617 | Acc: 25.495,41.616,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.686 | Acc: 25.166,41.624,2.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 7.496 | Acc: 47.656,62.500,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.522 | Acc: 43.638,59.859,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.570 | Acc: 43.769,59.089,2.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.597 | Acc: 43.058,58.722,2.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.619 | Acc: 43.036,58.497,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.628 | Acc: 42.984,58.153,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.630 | Acc: 43.001,58.064,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.637 | Acc: 42.902,57.995,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.649 | Acc: 42.644,57.846,2.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.657 | Acc: 42.585,57.618,2.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.658 | Acc: 42.565,57.498,2.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.652 | Acc: 42.644,57.682,2.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.660 | Acc: 42.434,57.540,2.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.661 | Acc: 42.433,57.456,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.667 | Acc: 42.343,57.426,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.669 | Acc: 42.333,57.436,2.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.666 | Acc: 42.360,57.474,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.668 | Acc: 42.394,57.455,2.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.669 | Acc: 42.441,57.386,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.671 | Acc: 42.434,57.417,2.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.835 | Acc: 24.219,46.875,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.141 | Acc: 22.359,40.365,3.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.103 | Acc: 23.190,41.387,3.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.169 | Acc: 22.567,40.574,3.624,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 7.736 | Acc: 43.750,57.812,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.664 | Acc: 43.080,58.185,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.632 | Acc: 43.102,57.965,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.595 | Acc: 43.135,58.274,2.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.608 | Acc: 43.162,57.803,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.650 | Acc: 42.450,57.588,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.621 | Acc: 42.930,57.987,2.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.620 | Acc: 43.068,58.056,2.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.616 | Acc: 43.080,58.002,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.618 | Acc: 42.982,57.981,2.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.639 | Acc: 42.747,57.641,2.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.648 | Acc: 42.640,57.410,2.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.647 | Acc: 42.671,57.462,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.648 | Acc: 42.577,57.447,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.658 | Acc: 42.491,57.315,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.662 | Acc: 42.413,57.309,2.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.661 | Acc: 42.416,57.323,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.661 | Acc: 42.456,57.311,2.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.655 | Acc: 42.490,57.410,2.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.658 | Acc: 42.458,57.376,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.647 | Acc: 35.938,49.219,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.493 | Acc: 33.891,47.991,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.503 | Acc: 33.708,48.438,2.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.520 | Acc: 33.056,48.028,2.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 7.389 | Acc: 45.312,65.625,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.618 | Acc: 42.708,57.924,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.595 | Acc: 42.873,57.527,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.594 | Acc: 42.764,57.428,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.588 | Acc: 42.766,57.726,3.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.592 | Acc: 42.907,57.720,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.591 | Acc: 42.949,58.000,3.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.610 | Acc: 42.764,57.940,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.622 | Acc: 42.687,57.856,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.634 | Acc: 42.528,57.739,2.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.639 | Acc: 42.491,57.556,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.649 | Acc: 42.389,57.455,2.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.642 | Acc: 42.531,57.654,2.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.644 | Acc: 42.514,57.633,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.646 | Acc: 42.585,57.618,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.650 | Acc: 42.548,57.571,2.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.649 | Acc: 42.553,57.589,2.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.658 | Acc: 42.485,57.560,2.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.666 | Acc: 42.423,57.510,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.664 | Acc: 42.448,57.486,2.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.992 | Acc: 30.469,45.312,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.858 | Acc: 31.436,45.833,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.909 | Acc: 31.250,44.665,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.960 | Acc: 31.276,44.762,2.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 7.820 | Acc: 46.094,53.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.591 | Acc: 43.118,58.780,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.617 | Acc: 42.607,57.812,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.627 | Acc: 42.380,57.428,2.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.630 | Acc: 42.448,57.610,2.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.631 | Acc: 42.551,57.426,2.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.629 | Acc: 42.556,57.354,2.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.635 | Acc: 42.559,57.430,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.620 | Acc: 42.828,57.536,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.640 | Acc: 42.550,57.299,2.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.640 | Acc: 42.456,57.463,2.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.652 | Acc: 42.361,57.286,3.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.656 | Acc: 42.385,57.401,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.652 | Acc: 42.352,57.450,3.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.639 | Acc: 42.527,57.512,3.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.637 | Acc: 42.457,57.537,2.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.637 | Acc: 42.477,57.564,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.634 | Acc: 42.529,57.599,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.631 | Acc: 42.534,57.646,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.636 | Acc: 42.511,57.536,2.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.255 | Acc: 21.875,38.281,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.170 | Acc: 25.074,39.025,1.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.146 | Acc: 25.095,38.586,2.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.214 | Acc: 24.308,38.256,2.126,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 7.629 | Acc: 38.281,58.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.658 | Acc: 41.741,57.626,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.649 | Acc: 42.492,57.774,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.609 | Acc: 42.687,57.928,2.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.614 | Acc: 42.438,58.111,2.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.628 | Acc: 42.381,57.797,2.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.614 | Acc: 42.749,58.013,2.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.617 | Acc: 42.647,57.774,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.621 | Acc: 42.663,57.745,2.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.609 | Acc: 42.831,57.920,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.615 | Acc: 42.739,57.844,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.617 | Acc: 42.583,57.809,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.626 | Acc: 42.599,57.728,2.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.621 | Acc: 42.639,57.768,2.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.620 | Acc: 42.674,57.821,2.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.621 | Acc: 42.707,57.838,2.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.616 | Acc: 42.713,57.868,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.617 | Acc: 42.685,57.796,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.615 | Acc: 42.690,57.858,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.618 | Acc: 42.684,57.823,2.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.384 | Acc: 38.281,43.750,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.201 | Acc: 28.534,46.801,3.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.237 | Acc: 28.068,45.979,3.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.238 | Acc: 27.485,45.863,3.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 7.465 | Acc: 49.219,62.500,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.590 | Acc: 43.601,57.850,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.561 | Acc: 43.826,57.889,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.576 | Acc: 43.225,58.107,2.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.563 | Acc: 43.297,58.449,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.549 | Acc: 43.232,58.687,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.559 | Acc: 43.279,58.736,3.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.554 | Acc: 43.395,58.621,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.557 | Acc: 43.352,58.754,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.567 | Acc: 43.146,58.555,2.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.588 | Acc: 43.109,58.186,2.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.594 | Acc: 43.001,58.212,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.600 | Acc: 42.940,58.250,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.599 | Acc: 42.912,58.175,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.600 | Acc: 42.838,58.210,2.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.600 | Acc: 42.759,58.129,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.605 | Acc: 42.808,58.078,2.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.605 | Acc: 42.831,58.076,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.611 | Acc: 42.752,58.014,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.611 | Acc: 42.735,58.026,2.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.652 | Acc: 32.031,48.438,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.658 | Acc: 32.143,48.103,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.619 | Acc: 32.832,47.599,3.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.673 | Acc: 32.480,47.170,3.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 7.068 | Acc: 44.531,60.156,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.507 | Acc: 43.787,60.193,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.544 | Acc: 43.312,58.803,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.520 | Acc: 43.840,59.516,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.527 | Acc: 43.721,59.221,2.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.518 | Acc: 43.812,59.197,2.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.534 | Acc: 43.421,58.917,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.556 | Acc: 43.113,58.505,2.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.560 | Acc: 42.911,58.545,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.562 | Acc: 42.943,58.374,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.574 | Acc: 42.887,58.232,2.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.581 | Acc: 42.796,58.120,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.581 | Acc: 42.888,58.062,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.591 | Acc: 42.912,57.947,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.593 | Acc: 42.802,57.868,2.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.597 | Acc: 42.730,57.823,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.596 | Acc: 42.728,57.854,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.600 | Acc: 42.614,57.849,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.593 | Acc: 42.707,57.932,2.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.594 | Acc: 42.673,57.868,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.256 | Acc: 32.812,46.875,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.110 | Acc: 32.068,44.754,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.125 | Acc: 31.784,44.512,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.172 | Acc: 31.288,44.326,2.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 7.318 | Acc: 46.875,60.938,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.682 | Acc: 41.890,57.292,3.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.606 | Acc: 42.435,58.175,3.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.566 | Acc: 42.546,58.504,3.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.569 | Acc: 42.689,58.738,3.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.571 | Acc: 42.969,58.609,3.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.541 | Acc: 43.104,58.955,3.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.551 | Acc: 42.852,58.865,3.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.567 | Acc: 42.896,58.623,3.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.573 | Acc: 42.693,58.546,3.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.573 | Acc: 42.634,58.497,3.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.580 | Acc: 42.668,58.392,3.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.575 | Acc: 42.609,58.380,3.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.578 | Acc: 42.622,58.348,3.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.582 | Acc: 42.635,58.307,3.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.584 | Acc: 42.694,58.342,3.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.583 | Acc: 42.815,58.265,3.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.588 | Acc: 42.769,58.193,3.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.588 | Acc: 42.770,58.250,3.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.590 | Acc: 42.723,58.202,3.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.554 | Acc: 39.062,50.000,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.702 | Acc: 33.668,47.917,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.711 | Acc: 32.908,47.123,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.717 | Acc: 32.710,46.875,3.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 7.360 | Acc: 35.938,60.938,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.468 | Acc: 43.490,58.705,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.515 | Acc: 43.312,58.708,3.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.507 | Acc: 42.982,58.427,3.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.515 | Acc: 43.162,58.652,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.508 | Acc: 43.077,58.702,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.519 | Acc: 43.027,58.523,3.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.523 | Acc: 42.941,58.555,3.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.531 | Acc: 42.760,58.453,3.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.545 | Acc: 42.675,58.425,2.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.543 | Acc: 42.662,58.442,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.542 | Acc: 42.781,58.396,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.546 | Acc: 42.816,58.321,3.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.550 | Acc: 42.924,58.294,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.557 | Acc: 42.905,58.338,3.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.561 | Acc: 42.987,58.311,3.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.567 | Acc: 42.876,58.265,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.570 | Acc: 42.726,58.213,3.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.574 | Acc: 42.711,58.144,3.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.579 | Acc: 42.698,58.083,2.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.801 | Acc: 28.906,43.750,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.120 | Acc: 27.902,44.792,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.157 | Acc: 28.011,45.084,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.198 | Acc: 27.421,44.467,2.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 7.029 | Acc: 48.438,69.531,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.519 | Acc: 43.452,58.073,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.548 | Acc: 43.312,58.594,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.558 | Acc: 43.007,58.030,3.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.550 | Acc: 43.403,58.304,3.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.566 | Acc: 42.791,58.354,3.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.565 | Acc: 42.885,58.335,3.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.567 | Acc: 42.886,58.428,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.577 | Acc: 42.639,58.230,3.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.571 | Acc: 42.718,58.270,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.572 | Acc: 42.774,58.403,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.577 | Acc: 42.700,58.350,3.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.575 | Acc: 42.696,58.296,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.577 | Acc: 42.616,58.223,3.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.575 | Acc: 42.677,58.266,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.571 | Acc: 42.696,58.332,3.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.571 | Acc: 42.730,58.319,3.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.581 | Acc: 42.657,58.179,3.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.583 | Acc: 42.646,58.044,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.584 | Acc: 42.624,58.050,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.574 | Acc: 46.094,51.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.989 | Acc: 33.073,46.057,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.006 | Acc: 32.069,45.351,2.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.972 | Acc: 31.903,45.082,2.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 7.463 | Acc: 45.312,57.812,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.533 | Acc: 41.927,57.143,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.524 | Acc: 42.569,58.136,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.543 | Acc: 42.444,58.376,3.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.514 | Acc: 43.065,58.690,2.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.524 | Acc: 42.876,58.222,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.538 | Acc: 42.756,58.226,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.546 | Acc: 42.880,58.134,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.542 | Acc: 42.896,58.273,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.544 | Acc: 42.813,58.205,2.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.542 | Acc: 42.802,58.057,2.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.538 | Acc: 42.852,58.251,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.545 | Acc: 42.807,58.244,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.546 | Acc: 42.747,58.259,2.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.551 | Acc: 42.721,58.179,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.547 | Acc: 42.836,58.228,2.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.548 | Acc: 42.774,58.231,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.551 | Acc: 42.818,58.294,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.553 | Acc: 42.813,58.245,3.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.556 | Acc: 42.774,58.225,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.618 | Acc: 37.500,53.125,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.962 | Acc: 34.003,45.424,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.983 | Acc: 33.117,45.141,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.041 | Acc: 32.620,44.544,2.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 7.505 | Acc: 46.094,58.594,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.458 | Acc: 42.969,59.561,3.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.464 | Acc: 43.445,59.889,3.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.470 | Acc: 43.379,60.028,3.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.496 | Acc: 43.142,59.346,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.507 | Acc: 42.683,59.166,3.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.504 | Acc: 42.627,59.485,3.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.516 | Acc: 42.647,59.159,3.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.523 | Acc: 42.469,58.972,3.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.527 | Acc: 42.265,58.853,3.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.530 | Acc: 42.347,58.644,3.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.529 | Acc: 42.364,58.753,3.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.533 | Acc: 42.444,58.753,3.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.541 | Acc: 42.445,58.528,3.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.539 | Acc: 42.538,58.572,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.547 | Acc: 42.452,58.378,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.553 | Acc: 42.380,58.321,3.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.554 | Acc: 42.481,58.314,3.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.554 | Acc: 42.473,58.319,3.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.549 | Acc: 42.495,58.329,3.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.194 | Acc: 32.031,47.656,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.980 | Acc: 31.696,45.982,3.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.999 | Acc: 31.040,45.941,3.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.993 | Acc: 30.289,46.247,3.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 7.852 | Acc: 39.062,48.438,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.419 | Acc: 44.494,60.268,3.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.432 | Acc: 44.055,59.737,3.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.453 | Acc: 43.660,59.221,3.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.465 | Acc: 43.441,59.327,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.475 | Acc: 43.371,59.274,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.494 | Acc: 43.066,59.039,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.484 | Acc: 43.218,59.109,3.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.494 | Acc: 43.207,59.021,3.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.497 | Acc: 43.215,58.961,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.511 | Acc: 43.233,58.831,3.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.517 | Acc: 43.124,58.834,3.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.523 | Acc: 43.154,58.775,3.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.541 | Acc: 43.047,58.561,3.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.544 | Acc: 42.944,58.441,3.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.552 | Acc: 42.816,58.373,3.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.551 | Acc: 42.837,58.363,3.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.556 | Acc: 42.763,58.275,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.554 | Acc: 42.791,58.332,3.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.561 | Acc: 42.723,58.143,3.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.888 | Acc: 29.688,48.438,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.943 | Acc: 24.665,40.960,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.004 | Acc: 24.905,40.282,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.026 | Acc: 24.680,40.151,2.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 7.260 | Acc: 47.656,65.625,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.643 | Acc: 41.815,58.222,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.615 | Acc: 41.749,58.556,3.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.591 | Acc: 41.931,58.530,3.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.569 | Acc: 42.188,58.719,3.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.555 | Acc: 42.520,58.485,3.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.558 | Acc: 42.271,58.387,3.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.541 | Acc: 42.681,58.422,3.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.545 | Acc: 42.639,58.526,3.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.552 | Acc: 42.602,58.425,3.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.547 | Acc: 42.483,58.570,3.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.549 | Acc: 42.492,58.484,3.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.552 | Acc: 42.473,58.409,3.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.549 | Acc: 42.529,58.480,3.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.549 | Acc: 42.524,58.480,3.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.550 | Acc: 42.494,58.521,3.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.553 | Acc: 42.499,58.477,3.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.555 | Acc: 42.495,58.429,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.553 | Acc: 42.477,58.414,3.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.552 | Acc: 42.532,58.374,3.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.136 | Acc: 34.375,47.656,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.038 | Acc: 32.180,47.731,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.075 | Acc: 32.565,46.151,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.107 | Acc: 32.044,46.247,2.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 7.525 | Acc: 42.188,56.250,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.447 | Acc: 43.006,59.524,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.446 | Acc: 43.674,60.309,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.466 | Acc: 43.852,59.503,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.470 | Acc: 43.364,59.346,3.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.468 | Acc: 43.201,59.375,3.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.481 | Acc: 42.904,59.091,3.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.496 | Acc: 42.858,58.871,3.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.484 | Acc: 43.022,59.016,3.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.490 | Acc: 42.986,58.848,3.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.503 | Acc: 42.809,58.749,3.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.511 | Acc: 42.852,58.643,3.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.517 | Acc: 42.956,58.594,3.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.523 | Acc: 43.011,58.540,3.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.529 | Acc: 42.883,58.449,3.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.526 | Acc: 42.896,58.539,3.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.527 | Acc: 42.893,58.455,3.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.522 | Acc: 42.989,58.523,3.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.527 | Acc: 42.986,58.537,3.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.535 | Acc: 42.932,58.438,3.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.082 | Acc: 28.906,46.094,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.167 | Acc: 28.832,43.415,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.156 | Acc: 28.487,42.912,2.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.174 | Acc: 28.471,42.828,2.293,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 7.516 | Acc: 44.531,65.625,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.448 | Acc: 42.597,59.226,3.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.422 | Acc: 43.559,59.870,3.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.451 | Acc: 42.905,59.183,3.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.466 | Acc: 43.162,59.356,3.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.478 | Acc: 43.209,59.274,3.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.486 | Acc: 43.175,59.110,3.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.502 | Acc: 43.107,58.932,3.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.503 | Acc: 43.158,58.764,3.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.513 | Acc: 43.210,58.650,3.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.509 | Acc: 43.171,58.726,3.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.517 | Acc: 43.117,58.654,3.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.519 | Acc: 43.160,58.652,3.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.513 | Acc: 43.184,58.687,3.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.515 | Acc: 43.074,58.669,3.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.517 | Acc: 43.018,58.640,3.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.517 | Acc: 43.066,58.616,3.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.523 | Acc: 43.072,58.534,3.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.527 | Acc: 43.040,58.518,3.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.528 | Acc: 43.028,58.602,3.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.712 | Acc: 44.531,51.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.130 | Acc: 33.110,46.540,0.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.102 | Acc: 32.622,46.723,1.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.107 | Acc: 31.967,46.747,1.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 7.242 | Acc: 41.406,60.938,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.528 | Acc: 42.634,57.924,3.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.488 | Acc: 43.121,59.032,3.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.482 | Acc: 43.097,58.978,3.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.472 | Acc: 43.248,59.172,3.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.476 | Acc: 43.417,58.988,3.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.477 | Acc: 43.434,58.962,3.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.496 | Acc: 42.996,58.605,3.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.498 | Acc: 43.240,58.560,3.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.495 | Acc: 43.275,58.667,3.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.501 | Acc: 43.109,58.640,3.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.503 | Acc: 43.114,58.601,3.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.492 | Acc: 43.277,58.659,3.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.493 | Acc: 43.277,58.713,3.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.497 | Acc: 43.258,58.758,3.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.506 | Acc: 43.176,58.739,3.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.509 | Acc: 43.112,58.808,3.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.512 | Acc: 43.097,58.873,3.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.518 | Acc: 43.105,58.827,3.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.524 | Acc: 43.065,58.764,3.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.297 | Acc: 34.375,56.250,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.600 | Acc: 32.961,51.860,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.580 | Acc: 32.374,50.915,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.606 | Acc: 31.724,49.974,2.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 7.618 | Acc: 42.969,53.906,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.580 | Acc: 42.820,58.259,3.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.556 | Acc: 43.083,58.289,3.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.521 | Acc: 43.353,58.799,3.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.520 | Acc: 43.065,58.951,3.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.506 | Acc: 43.247,59.174,3.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.499 | Acc: 43.511,59.201,3.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.503 | Acc: 43.418,59.120,3.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.507 | Acc: 43.478,59.045,3.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.512 | Acc: 43.362,58.874,3.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.520 | Acc: 43.221,58.796,3.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.524 | Acc: 43.174,58.788,3.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.522 | Acc: 43.241,58.840,3.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.534 | Acc: 43.080,58.591,3.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.546 | Acc: 42.910,58.541,3.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.552 | Acc: 42.901,58.448,3.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.564 | Acc: 42.742,58.350,3.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.563 | Acc: 42.792,58.385,3.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.557 | Acc: 42.962,58.572,3.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.554 | Acc: 43.026,58.625,3.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.639 | Acc: 37.500,52.344,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.925 | Acc: 35.193,51.451,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.908 | Acc: 34.451,50.781,2.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.955 | Acc: 33.607,49.949,2.190,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 7.492 | Acc: 40.625,52.344,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.476 | Acc: 42.671,59.449,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.511 | Acc: 43.255,60.194,3.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.495 | Acc: 43.635,59.798,3.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.505 | Acc: 43.615,59.597,3.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.506 | Acc: 43.487,59.429,3.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.503 | Acc: 43.640,59.330,3.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.502 | Acc: 43.506,59.281,3.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.514 | Acc: 43.697,59.205,3.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.517 | Acc: 43.513,59.125,3.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.531 | Acc: 43.373,59.134,3.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.553 | Acc: 43.047,58.887,3.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.569 | Acc: 42.878,58.668,3.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.565 | Acc: 42.951,58.746,3.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.568 | Acc: 42.983,58.677,3.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.568 | Acc: 42.969,58.638,3.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.568 | Acc: 43.051,58.655,3.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.571 | Acc: 43.021,58.541,3.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.569 | Acc: 43.014,58.483,3.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.574 | Acc: 43.036,58.440,3.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.690 | Acc: 35.156,47.656,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.139 | Acc: 28.423,45.685,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.112 | Acc: 28.430,45.484,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.136 | Acc: 27.907,45.056,3.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 7.697 | Acc: 40.625,57.031,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.521 | Acc: 44.048,59.226,3.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.481 | Acc: 44.169,60.042,3.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.428 | Acc: 44.864,60.438,3.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.454 | Acc: 44.502,59.963,3.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.463 | Acc: 44.191,59.754,3.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.472 | Acc: 44.002,59.472,3.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.490 | Acc: 43.689,59.275,3.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.509 | Acc: 43.614,59.278,3.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.515 | Acc: 43.603,59.151,3.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.523 | Acc: 43.563,59.130,3.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.531 | Acc: 43.527,59.021,3.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.542 | Acc: 43.436,59.090,3.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.552 | Acc: 43.220,59.010,3.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.558 | Acc: 43.288,59.005,3.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.567 | Acc: 43.361,58.877,3.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.573 | Acc: 43.288,58.798,3.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.577 | Acc: 43.193,58.814,3.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.578 | Acc: 43.244,58.799,3.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.585 | Acc: 43.065,58.680,3.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.381 | Acc: 38.281,53.906,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.427 | Acc: 34.859,49.963,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.429 | Acc: 34.604,50.095,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.444 | Acc: 33.927,50.154,2.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 8.011 | Acc: 37.500,53.125,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.582 | Acc: 43.676,60.156,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.561 | Acc: 43.331,60.042,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.546 | Acc: 43.417,59.721,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.558 | Acc: 43.364,59.230,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.547 | Acc: 43.394,59.305,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.546 | Acc: 43.421,59.310,3.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.549 | Acc: 43.329,59.270,3.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.561 | Acc: 43.139,59.171,3.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.554 | Acc: 43.193,59.233,3.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.556 | Acc: 43.116,59.146,3.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.559 | Acc: 43.043,59.131,3.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.561 | Acc: 43.017,59.106,3.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.563 | Acc: 42.978,59.079,3.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.567 | Acc: 42.933,59.027,3.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.570 | Acc: 42.958,58.960,3.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.573 | Acc: 42.915,58.915,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.575 | Acc: 42.955,58.928,3.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.577 | Acc: 42.887,58.864,3.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.578 | Acc: 42.903,58.836,3.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.407 | Acc: 41.406,53.906,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.947 | Acc: 30.618,48.400,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.029 | Acc: 29.897,47.180,2.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.051 | Acc: 29.444,46.606,2.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 7.287 | Acc: 42.188,63.281,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.424 | Acc: 44.085,60.603,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.408 | Acc: 44.779,60.633,3.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.435 | Acc: 44.403,60.143,3.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.466 | Acc: 44.300,59.925,3.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.457 | Acc: 44.315,60.234,3.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.477 | Acc: 44.157,59.821,3.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.482 | Acc: 44.160,59.730,3.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.493 | Acc: 44.080,59.603,3.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.511 | Acc: 43.780,59.457,3.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.517 | Acc: 43.672,59.293,3.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.526 | Acc: 43.612,59.188,3.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.519 | Acc: 43.637,59.180,3.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.523 | Acc: 43.732,59.127,3.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.522 | Acc: 43.764,59.217,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.524 | Acc: 43.724,59.201,3.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.526 | Acc: 43.626,59.146,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.537 | Acc: 43.491,59.084,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.537 | Acc: 43.516,59.141,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.545 | Acc: 43.397,59.024,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.156 | Acc: 28.125,50.000,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.760 | Acc: 25.037,43.787,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.753 | Acc: 25.362,43.083,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.772 | Acc: 24.936,42.892,3.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 6.828 | Acc: 48.438,69.531,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.491 | Acc: 42.746,59.859,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.540 | Acc: 42.492,59.261,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.545 | Acc: 42.828,59.209,3.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.549 | Acc: 43.046,59.510,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.534 | Acc: 42.953,59.483,3.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.532 | Acc: 43.072,59.504,3.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.527 | Acc: 43.129,59.569,3.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.520 | Acc: 43.051,59.482,3.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.511 | Acc: 43.051,59.414,3.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.513 | Acc: 43.132,59.429,3.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.509 | Acc: 43.223,59.446,3.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.515 | Acc: 43.212,59.346,3.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.511 | Acc: 43.313,59.348,3.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.509 | Acc: 43.364,59.292,3.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.521 | Acc: 43.275,59.123,3.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.523 | Acc: 43.178,59.029,3.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.527 | Acc: 43.159,58.979,3.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.528 | Acc: 43.161,58.985,3.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.525 | Acc: 43.203,58.992,3.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.175 | Acc: 37.500,46.875,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.189 | Acc: 30.655,48.363,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.259 | Acc: 29.516,47.637,2.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.308 | Acc: 28.663,46.913,2.280,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 7.565 | Acc: 44.531,57.031,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.461 | Acc: 43.713,58.966,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.464 | Acc: 43.483,58.956,3.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.460 | Acc: 43.660,59.439,3.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.476 | Acc: 43.769,59.317,3.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.501 | Acc: 43.472,58.965,3.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.491 | Acc: 43.453,59.104,3.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.505 | Acc: 43.296,59.059,3.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.511 | Acc: 43.134,59.128,3.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.506 | Acc: 43.396,59.297,3.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.502 | Acc: 43.455,59.383,3.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.497 | Acc: 43.503,59.400,3.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.498 | Acc: 43.533,59.378,3.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.504 | Acc: 43.427,59.321,3.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.504 | Acc: 43.441,59.253,3.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.508 | Acc: 43.389,59.199,3.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.519 | Acc: 43.202,59.056,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.518 | Acc: 43.189,59.082,3.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.519 | Acc: 43.144,59.020,3.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.517 | Acc: 43.118,59.033,3.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.454 | Acc: 30.469,44.531,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.438 | Acc: 27.827,45.089,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.447 | Acc: 27.915,44.112,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.477 | Acc: 27.715,43.993,2.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 7.333 | Acc: 45.312,57.031,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.486 | Acc: 44.234,58.780,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.445 | Acc: 43.845,59.585,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.450 | Acc: 43.737,60.003,2.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.446 | Acc: 44.020,60.166,2.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.448 | Acc: 43.820,60.311,3.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.466 | Acc: 43.834,59.937,3.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.472 | Acc: 43.733,59.741,3.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.479 | Acc: 43.643,59.763,3.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.498 | Acc: 43.426,59.638,2.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.510 | Acc: 43.412,59.453,2.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.521 | Acc: 43.358,59.318,2.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.522 | Acc: 43.348,59.268,2.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.523 | Acc: 43.379,59.306,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.523 | Acc: 43.297,59.325,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.518 | Acc: 43.311,59.320,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.521 | Acc: 43.185,59.370,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.522 | Acc: 43.180,59.462,3.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.523 | Acc: 43.244,59.459,3.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.522 | Acc: 43.262,59.447,3.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.676 | Acc: 28.906,49.219,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.717 | Acc: 28.013,43.676,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.733 | Acc: 28.011,43.655,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.761 | Acc: 27.702,43.494,2.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 7.713 | Acc: 35.938,55.469,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.464 | Acc: 44.457,60.863,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.491 | Acc: 43.197,60.480,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.468 | Acc: 43.788,60.387,3.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.438 | Acc: 43.981,60.966,3.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.455 | Acc: 43.595,60.466,3.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.435 | Acc: 43.614,60.311,3.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.427 | Acc: 43.805,60.322,3.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.416 | Acc: 43.876,60.219,4.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.397 | Acc: 43.785,60.117,4.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.404 | Acc: 43.688,59.791,4.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.398 | Acc: 43.577,59.792,4.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.386 | Acc: 43.614,59.809,4.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.376 | Acc: 43.523,59.800,4.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.365 | Acc: 43.533,59.723,5.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.355 | Acc: 43.628,59.731,5.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.351 | Acc: 43.667,59.704,5.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.349 | Acc: 43.647,59.700,5.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.344 | Acc: 43.531,59.665,5.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.343 | Acc: 43.524,59.560,5.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.623 | Acc: 39.844,53.906,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.782 | Acc: 32.738,48.363,4.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.797 | Acc: 32.679,47.599,4.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.810 | Acc: 32.172,47.810,3.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 6.906 | Acc: 45.312,66.406,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.062 | Acc: 43.564,61.979,7.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.093 | Acc: 43.979,61.623,7.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.132 | Acc: 43.519,60.733,7.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.149 | Acc: 43.490,60.475,7.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.176 | Acc: 43.093,60.009,8.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.161 | Acc: 43.233,59.827,8.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.156 | Acc: 43.113,60.051,8.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.149 | Acc: 43.240,60.069,8.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.144 | Acc: 43.383,60.061,8.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.150 | Acc: 43.455,59.849,8.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.150 | Acc: 43.481,59.750,8.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.145 | Acc: 43.526,59.770,8.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.146 | Acc: 43.391,59.692,8.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.145 | Acc: 43.330,59.595,8.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.142 | Acc: 43.350,59.564,8.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.146 | Acc: 43.300,59.536,8.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.149 | Acc: 43.257,59.437,8.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.152 | Acc: 43.129,59.327,8.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.154 | Acc: 43.100,59.297,8.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.880 | Acc: 28.906,51.562,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.246 | Acc: 23.810,44.196,7.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.240 | Acc: 23.933,42.835,7.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.302 | Acc: 23.040,42.956,7.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 7.213 | Acc: 42.969,53.906,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.019 | Acc: 42.560,59.673,10.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.004 | Acc: 42.931,59.718,10.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.015 | Acc: 43.225,59.874,10.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.047 | Acc: 43.181,59.163,10.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.030 | Acc: 43.433,59.390,10.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.008 | Acc: 43.840,59.601,10.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.007 | Acc: 43.706,59.536,10.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.002 | Acc: 43.692,59.472,10.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.010 | Acc: 43.724,59.483,10.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.016 | Acc: 43.699,59.286,10.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.014 | Acc: 43.686,59.354,10.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.018 | Acc: 43.727,59.291,10.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.029 | Acc: 43.699,59.189,10.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.036 | Acc: 43.564,59.072,10.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.049 | Acc: 43.431,58.827,10.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.052 | Acc: 43.341,58.796,10.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.048 | Acc: 43.381,58.862,10.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.056 | Acc: 43.352,58.786,10.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.057 | Acc: 43.381,58.754,10.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.380 | Acc: 26.562,35.156,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.650 | Acc: 23.289,32.887,5.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.715 | Acc: 22.809,32.717,4.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.767 | Acc: 22.605,32.646,4.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 7.631 | Acc: 37.500,48.438,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.052 | Acc: 43.378,58.705,11.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.013 | Acc: 43.197,59.280,11.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.967 | Acc: 43.443,59.209,11.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.978 | Acc: 43.239,59.172,11.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.975 | Acc: 43.069,59.174,11.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.964 | Acc: 43.130,59.414,11.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.970 | Acc: 43.124,59.419,11.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.969 | Acc: 43.114,59.443,11.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.973 | Acc: 43.150,59.397,11.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.979 | Acc: 43.221,59.282,11.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.978 | Acc: 43.184,59.202,11.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.980 | Acc: 43.092,59.193,11.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.990 | Acc: 42.966,59.022,11.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.994 | Acc: 42.983,58.919,11.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.000 | Acc: 42.961,58.840,11.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.997 | Acc: 42.961,58.813,11.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.991 | Acc: 42.937,58.821,11.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.985 | Acc: 42.928,58.910,11.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.989 | Acc: 42.852,58.885,11.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.669 | Acc: 28.906,43.750,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.520 | Acc: 28.051,40.997,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.548 | Acc: 28.563,41.120,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.653 | Acc: 27.523,40.663,2.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 6.771 | Acc: 44.531,54.688,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.975 | Acc: 42.634,58.036,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.927 | Acc: 43.197,59.089,12.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.906 | Acc: 43.468,59.209,12.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.945 | Acc: 42.805,58.941,12.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.974 | Acc: 42.582,58.470,12.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.982 | Acc: 42.691,58.193,12.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.990 | Acc: 42.658,58.117,12.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.971 | Acc: 42.726,58.191,12.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.968 | Acc: 42.822,58.227,12.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.971 | Acc: 42.825,58.042,12.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.966 | Acc: 42.919,58.007,12.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.965 | Acc: 42.936,58.026,12.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.960 | Acc: 43.026,58.118,12.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.966 | Acc: 42.983,58.040,12.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.969 | Acc: 42.979,58.062,12.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.979 | Acc: 42.857,57.878,12.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.976 | Acc: 42.875,57.835,12.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.978 | Acc: 42.835,57.819,12.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.980 | Acc: 42.821,57.833,12.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.198 | Acc: 34.375,46.094,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.132 | Acc: 30.208,44.866,4.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.205 | Acc: 29.916,44.188,4.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.226 | Acc: 30.008,44.057,4.790,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 6.725 | Acc: 43.750,60.938,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.024 | Acc: 43.713,58.296,12.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.961 | Acc: 43.426,58.136,13.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.950 | Acc: 43.199,58.683,13.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.972 | Acc: 42.892,58.063,12.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.952 | Acc: 42.915,58.362,12.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.957 | Acc: 42.775,58.335,12.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.944 | Acc: 42.730,58.372,12.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.947 | Acc: 42.765,58.400,12.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.942 | Acc: 42.796,58.305,12.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.946 | Acc: 42.650,58.053,12.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.952 | Acc: 42.481,57.911,12.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.962 | Acc: 42.424,57.757,12.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.964 | Acc: 42.490,57.812,12.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.954 | Acc: 42.666,57.876,12.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.961 | Acc: 42.546,57.781,12.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.956 | Acc: 42.587,57.725,12.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.951 | Acc: 42.692,57.769,12.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.951 | Acc: 42.716,57.776,13.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.962 | Acc: 42.628,57.661,13.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.189 | Acc: 26.562,42.969,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.067 | Acc: 20.610,36.830,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.982 | Acc: 20.598,36.300,9.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.956 | Acc: 20.466,36.399,9.285,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 6.971 | Acc: 35.938,59.375,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.878 | Acc: 42.597,56.845,13.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.916 | Acc: 43.140,57.698,13.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.927 | Acc: 42.943,58.081,13.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.939 | Acc: 42.930,57.841,13.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.951 | Acc: 43.007,57.542,13.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.931 | Acc: 42.853,57.632,13.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.922 | Acc: 42.780,57.569,13.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.914 | Acc: 42.935,57.691,13.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.910 | Acc: 43.137,57.648,13.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.923 | Acc: 43.066,57.630,13.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.919 | Acc: 43.078,57.703,13.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.924 | Acc: 43.021,57.624,13.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.926 | Acc: 43.047,57.594,13.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.934 | Acc: 42.955,57.407,13.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.936 | Acc: 42.888,57.374,13.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.945 | Acc: 42.706,57.204,13.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.945 | Acc: 42.627,57.212,13.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.945 | Acc: 42.629,57.291,13.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.939 | Acc: 42.649,57.345,13.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.064 | Acc: 34.375,52.344,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.501 | Acc: 31.027,48.251,7.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.486 | Acc: 31.136,47.351,7.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.495 | Acc: 30.622,47.336,7.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 7.102 | Acc: 35.938,51.562,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.869 | Acc: 43.229,59.189,13.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.919 | Acc: 42.854,58.537,13.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.932 | Acc: 42.495,58.030,13.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.917 | Acc: 42.737,58.044,13.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.910 | Acc: 42.837,57.735,13.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.880 | Acc: 43.020,57.845,13.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.886 | Acc: 42.913,57.907,13.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.902 | Acc: 42.823,57.749,13.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.910 | Acc: 42.667,57.718,13.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.914 | Acc: 42.650,57.575,13.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.905 | Acc: 42.732,57.724,13.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.901 | Acc: 42.823,57.748,13.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.905 | Acc: 42.669,57.681,13.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.905 | Acc: 42.638,57.551,13.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.908 | Acc: 42.629,57.439,13.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.914 | Acc: 42.630,57.440,13.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.914 | Acc: 42.666,57.384,13.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.919 | Acc: 42.581,57.276,13.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.919 | Acc: 42.509,57.283,13.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.993 | Acc: 34.375,53.906,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.973 | Acc: 33.408,47.619,13.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.969 | Acc: 33.498,48.571,13.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.991 | Acc: 33.453,48.130,13.627,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 6.418 | Acc: 45.312,64.062,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.980 | Acc: 42.076,56.920,13.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.950 | Acc: 43.064,57.279,13.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.927 | Acc: 43.186,57.518,13.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.900 | Acc: 43.451,57.504,13.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.889 | Acc: 43.317,57.093,14.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.905 | Acc: 43.195,57.154,14.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.899 | Acc: 42.897,57.314,14.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.891 | Acc: 42.974,57.259,14.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.894 | Acc: 42.869,57.307,14.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.903 | Acc: 42.693,57.105,14.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.890 | Acc: 42.788,57.279,14.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.897 | Acc: 42.641,57.271,14.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.891 | Acc: 42.744,57.396,14.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.902 | Acc: 42.585,57.306,14.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.914 | Acc: 42.528,57.109,14.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.919 | Acc: 42.465,57.022,14.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.918 | Acc: 42.352,57.022,14.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.915 | Acc: 42.300,57.023,14.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.914 | Acc: 42.362,56.990,14.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.096 | Acc: 28.906,45.312,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.241 | Acc: 24.330,41.667,7.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.337 | Acc: 24.028,40.377,7.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.408 | Acc: 23.783,40.330,7.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 7.104 | Acc: 41.406,53.125,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.984 | Acc: 41.146,55.394,13.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.997 | Acc: 41.368,56.002,13.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.933 | Acc: 41.752,56.788,14.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.930 | Acc: 42.178,56.713,14.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.943 | Acc: 42.195,56.412,14.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.946 | Acc: 42.342,56.282,14.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.951 | Acc: 42.154,56.305,14.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.953 | Acc: 42.163,56.400,14.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.956 | Acc: 42.291,56.436,14.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.946 | Acc: 42.269,56.448,14.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.946 | Acc: 42.276,56.349,14.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.941 | Acc: 42.291,56.386,14.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.943 | Acc: 42.247,56.382,14.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.937 | Acc: 42.240,56.389,14.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.936 | Acc: 42.304,56.294,14.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.931 | Acc: 42.351,56.357,14.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.941 | Acc: 42.286,56.257,14.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.948 | Acc: 42.222,56.172,14.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.955 | Acc: 42.224,56.188,14.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.082 | Acc: 28.125,44.531,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.595 | Acc: 27.121,41.853,5.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.721 | Acc: 26.734,40.263,5.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.748 | Acc: 26.524,39.703,5.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 6.855 | Acc: 43.750,58.594,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.972 | Acc: 41.815,56.510,14.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.905 | Acc: 42.035,56.784,14.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.913 | Acc: 42.098,56.647,14.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.903 | Acc: 41.840,57.215,14.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.913 | Acc: 41.785,56.962,14.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.913 | Acc: 41.652,56.928,14.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.923 | Acc: 41.777,56.715,14.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.921 | Acc: 41.848,56.711,14.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.899 | Acc: 42.080,56.915,14.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.893 | Acc: 42.044,56.872,15.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.892 | Acc: 41.954,56.847,15.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.892 | Acc: 41.993,56.850,15.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.903 | Acc: 41.912,56.732,15.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.907 | Acc: 41.873,56.717,15.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.905 | Acc: 41.907,56.702,15.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.917 | Acc: 41.908,56.552,15.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.915 | Acc: 41.974,56.536,15.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.916 | Acc: 42.049,56.616,15.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.920 | Acc: 42.050,56.560,15.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.310 | Acc: 34.375,47.656,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.911 | Acc: 27.307,41.815,10.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.810 | Acc: 27.687,41.997,10.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.808 | Acc: 27.344,42.303,10.720,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 6.803 | Acc: 47.656,58.594,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.057 | Acc: 40.067,54.353,15.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.067 | Acc: 40.015,54.383,15.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.050 | Acc: 40.330,54.585,15.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.998 | Acc: 41.030,55.247,15.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.968 | Acc: 41.337,55.337,15.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.976 | Acc: 41.077,55.198,15.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.950 | Acc: 41.129,55.341,15.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.922 | Acc: 41.445,55.721,15.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.913 | Acc: 41.562,55.883,15.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.922 | Acc: 41.585,55.780,15.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.916 | Acc: 41.590,55.822,15.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.909 | Acc: 41.776,55.874,15.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.909 | Acc: 41.673,55.933,15.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.901 | Acc: 41.823,56.119,15.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.901 | Acc: 41.837,56.102,15.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.910 | Acc: 41.757,55.926,15.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.911 | Acc: 41.681,55.888,15.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.919 | Acc: 41.651,55.845,15.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.929 | Acc: 41.593,55.703,15.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.011 | Acc: 37.500,43.750,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.426 | Acc: 33.631,46.354,8.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.447 | Acc: 33.098,45.465,8.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.489 | Acc: 32.223,45.133,8.222,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 6.631 | Acc: 41.406,59.375,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.924 | Acc: 41.741,56.399,15.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.936 | Acc: 42.283,56.136,16.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.893 | Acc: 42.354,56.250,16.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.863 | Acc: 42.361,56.327,16.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.885 | Acc: 42.110,56.273,16.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.916 | Acc: 42.000,56.089,16.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.918 | Acc: 41.977,56.184,16.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.915 | Acc: 41.877,55.978,16.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.908 | Acc: 42.028,55.866,16.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.919 | Acc: 41.869,55.694,16.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.918 | Acc: 41.827,55.681,16.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.926 | Acc: 41.789,55.666,16.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.930 | Acc: 41.679,55.687,16.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.932 | Acc: 41.579,55.580,16.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.928 | Acc: 41.653,55.772,16.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.925 | Acc: 41.708,55.882,16.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.930 | Acc: 41.725,55.815,16.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.935 | Acc: 41.791,55.780,15.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.933 | Acc: 41.796,55.752,15.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.832 | Acc: 35.938,48.438,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.111 | Acc: 33.110,44.754,12.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.069 | Acc: 32.812,45.046,12.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.123 | Acc: 32.275,44.032,12.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 7.042 | Acc: 35.156,56.250,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.972 | Acc: 40.476,56.064,14.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.854 | Acc: 42.454,56.612,15.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.902 | Acc: 42.072,56.148,15.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.916 | Acc: 41.696,55.787,15.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.913 | Acc: 41.677,56.057,15.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.912 | Acc: 41.697,56.056,15.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.928 | Acc: 41.451,55.851,14.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.944 | Acc: 41.484,55.663,14.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.939 | Acc: 41.441,55.741,14.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.943 | Acc: 41.363,55.605,14.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.946 | Acc: 41.357,55.610,14.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.946 | Acc: 41.445,55.475,14.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.967 | Acc: 41.364,55.181,14.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.979 | Acc: 41.328,55.054,15.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.989 | Acc: 41.313,55.056,15.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.994 | Acc: 41.314,55.009,15.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.998 | Acc: 41.276,54.995,15.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.998 | Acc: 41.177,54.921,15.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.991 | Acc: 41.131,54.911,15.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.304 | Acc: 28.125,46.875,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.790 | Acc: 28.460,42.560,7.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.824 | Acc: 28.163,41.044,7.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.849 | Acc: 27.959,41.009,7.902,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 6.702 | Acc: 39.062,53.906,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.916 | Acc: 42.225,55.283,17.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.882 | Acc: 42.226,55.316,16.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.886 | Acc: 42.162,55.558,16.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.902 | Acc: 41.937,55.478,16.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.879 | Acc: 42.203,55.933,16.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.871 | Acc: 42.123,55.895,16.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.906 | Acc: 42.115,55.696,16.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.916 | Acc: 42.056,55.454,16.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.923 | Acc: 41.916,55.413,16.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.917 | Acc: 41.865,55.445,16.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.938 | Acc: 41.654,55.165,16.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.959 | Acc: 41.588,54.979,16.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.964 | Acc: 41.574,54.864,16.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.981 | Acc: 41.484,54.751,16.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.982 | Acc: 41.432,54.750,16.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.980 | Acc: 41.443,54.804,16.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.984 | Acc: 41.450,54.804,16.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.978 | Acc: 41.501,54.880,16.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.981 | Acc: 41.472,54.806,16.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.139 | Acc: 25.000,33.594,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.305 | Acc: 21.540,30.022,5.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.208 | Acc: 22.123,30.069,5.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.188 | Acc: 21.849,30.187,5.725,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 6.698 | Acc: 46.094,60.156,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.039 | Acc: 41.332,53.013,16.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.981 | Acc: 41.178,53.620,16.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.008 | Acc: 41.214,53.740,16.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.985 | Acc: 41.001,54.128,16.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.976 | Acc: 41.368,54.486,16.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.963 | Acc: 41.542,54.597,16.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.970 | Acc: 41.384,54.582,16.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.963 | Acc: 41.557,54.726,16.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.988 | Acc: 41.523,54.688,16.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.010 | Acc: 41.336,54.559,16.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.998 | Acc: 41.526,54.666,16.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.992 | Acc: 41.633,54.662,16.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.004 | Acc: 41.583,54.589,16.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.006 | Acc: 41.620,54.560,16.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.005 | Acc: 41.572,54.449,16.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.998 | Acc: 41.630,54.507,16.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.010 | Acc: 41.590,54.474,16.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.010 | Acc: 41.575,54.478,16.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.013 | Acc: 41.496,54.429,16.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.305 | Acc: 41.406,45.312,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.562 | Acc: 31.696,42.857,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.571 | Acc: 30.736,42.530,12.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.558 | Acc: 30.033,42.559,11.911,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 6.683 | Acc: 44.531,61.719,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.954 | Acc: 40.923,55.543,15.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.919 | Acc: 41.463,56.079,16.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.933 | Acc: 41.445,55.238,17.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.932 | Acc: 41.474,55.507,16.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.899 | Acc: 41.723,55.585,17.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.898 | Acc: 41.813,55.585,17.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.895 | Acc: 41.766,55.596,17.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.893 | Acc: 41.634,55.590,17.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.897 | Acc: 41.536,55.387,17.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.920 | Acc: 41.367,55.177,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.933 | Acc: 41.424,54.903,17.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.940 | Acc: 41.413,54.937,16.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.940 | Acc: 41.439,54.861,16.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.939 | Acc: 41.398,54.835,16.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.944 | Acc: 41.357,54.763,16.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.954 | Acc: 41.326,54.692,16.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.956 | Acc: 41.370,54.786,16.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.967 | Acc: 41.339,54.670,16.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.982 | Acc: 41.234,54.599,16.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.356 | Acc: 26.562,42.188,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.336 | Acc: 27.307,38.318,11.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.378 | Acc: 26.963,37.519,11.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.390 | Acc: 26.870,37.398,10.643,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 7.486 | Acc: 39.844,52.344,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.156 | Acc: 40.885,52.009,17.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.044 | Acc: 41.082,53.087,16.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.983 | Acc: 41.406,54.022,17.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.018 | Acc: 40.953,53.781,17.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.032 | Acc: 40.741,53.419,17.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.087 | Acc: 40.722,53.196,17.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.115 | Acc: 40.553,52.931,16.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.113 | Acc: 40.504,52.926,16.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.110 | Acc: 40.491,53.008,16.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.108 | Acc: 40.664,53.020,16.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.106 | Acc: 40.572,52.927,16.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.102 | Acc: 40.563,52.888,16.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.102 | Acc: 40.511,52.817,16.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.107 | Acc: 40.408,52.744,16.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.088 | Acc: 40.612,52.881,16.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.082 | Acc: 40.722,52.955,16.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.081 | Acc: 40.694,52.960,16.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.085 | Acc: 40.670,52.915,16.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.118 | Acc: 40.479,52.664,16.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.216 | Acc: 25.000,39.062,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.178 | Acc: 27.902,39.397,10.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.176 | Acc: 27.534,38.891,10.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.186 | Acc: 27.152,38.768,10.220,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 7.821 | Acc: 35.938,42.969,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.348 | Acc: 37.500,49.628,15.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.287 | Acc: 38.605,50.438,15.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.240 | Acc: 39.229,51.780,15.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.203 | Acc: 39.323,51.804,15.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.192 | Acc: 39.472,51.709,16.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.182 | Acc: 39.779,51.911,16.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.167 | Acc: 39.855,52.045,16.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.152 | Acc: 39.980,52.135,16.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.142 | Acc: 40.167,52.137,16.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.160 | Acc: 40.104,51.963,16.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.170 | Acc: 40.052,51.920,16.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.159 | Acc: 40.067,52.065,16.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.142 | Acc: 40.104,52.101,16.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.132 | Acc: 40.113,52.174,16.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.117 | Acc: 40.236,52.287,17.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.110 | Acc: 40.238,52.285,17.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.112 | Acc: 40.158,52.323,17.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.107 | Acc: 40.209,52.415,17.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.110 | Acc: 40.229,52.370,17.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.604 | Acc: 33.594,39.062,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.857 | Acc: 29.650,41.741,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.857 | Acc: 29.287,41.025,8.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.880 | Acc: 28.945,41.060,8.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 7.217 | Acc: 43.750,52.344,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.953 | Acc: 42.374,54.241,19.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.041 | Acc: 40.930,54.021,18.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.043 | Acc: 40.958,53.599,18.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.035 | Acc: 40.924,53.559,18.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.007 | Acc: 40.857,53.728,18.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.997 | Acc: 40.941,53.861,18.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.012 | Acc: 40.775,53.640,18.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.015 | Acc: 40.848,53.508,18.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.027 | Acc: 40.754,53.539,18.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.053 | Acc: 40.473,53.187,18.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.055 | Acc: 40.452,53.104,18.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.046 | Acc: 40.447,53.164,18.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.055 | Acc: 40.374,53.011,18.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.085 | Acc: 40.175,52.716,18.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.103 | Acc: 40.036,52.388,18.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.128 | Acc: 39.885,51.991,18.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.142 | Acc: 39.720,51.842,18.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.156 | Acc: 39.705,51.647,18.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.157 | Acc: 39.715,51.558,18.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.273 | Acc: 27.344,39.844,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.243 | Acc: 22.954,34.189,12.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.185 | Acc: 22.142,33.670,11.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.145 | Acc: 21.977,33.517,12.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 6.937 | Acc: 42.188,56.250,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.132 | Acc: 40.513,50.967,18.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.196 | Acc: 39.253,49.466,17.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.125 | Acc: 39.460,50.154,18.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.052 | Acc: 40.336,51.264,18.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.004 | Acc: 40.702,51.965,19.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.992 | Acc: 40.651,52.040,19.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.995 | Acc: 40.459,52.178,19.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.966 | Acc: 40.615,52.557,19.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.942 | Acc: 40.815,52.698,20.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.927 | Acc: 40.932,52.900,20.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.929 | Acc: 40.749,52.733,20.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.926 | Acc: 40.803,52.775,20.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.904 | Acc: 40.897,52.924,20.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.886 | Acc: 40.922,53.103,20.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.861 | Acc: 41.012,53.250,20.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.847 | Acc: 41.163,53.351,21.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.846 | Acc: 41.163,53.306,21.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.842 | Acc: 41.092,53.227,21.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.839 | Acc: 41.008,53.281,21.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.983 | Acc: 28.125,41.406,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.440 | Acc: 24.516,36.458,13.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.486 | Acc: 24.314,36.090,13.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.501 | Acc: 24.027,35.976,13.435,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 6.464 | Acc: 42.188,59.375,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.660 | Acc: 40.848,54.911,23.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.596 | Acc: 41.768,55.583,24.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.591 | Acc: 41.983,55.674,24.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.591 | Acc: 41.715,55.720,24.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.581 | Acc: 41.894,55.716,24.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.622 | Acc: 41.955,55.256,24.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.664 | Acc: 41.816,54.654,24.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.675 | Acc: 41.794,54.518,24.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.662 | Acc: 41.829,54.614,24.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.657 | Acc: 41.826,54.629,24.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.644 | Acc: 41.838,54.709,24.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.632 | Acc: 41.854,54.814,24.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.635 | Acc: 41.942,54.777,24.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.626 | Acc: 41.957,54.749,24.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.631 | Acc: 41.788,54.695,24.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.646 | Acc: 41.599,54.534,24.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.643 | Acc: 41.555,54.550,24.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.633 | Acc: 41.556,54.555,24.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.624 | Acc: 41.687,54.646,24.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.872 | Acc: 35.938,47.656,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.097 | Acc: 30.766,45.164,18.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.095 | Acc: 31.269,43.960,17.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.135 | Acc: 30.930,43.519,17.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 5.967 | Acc: 47.656,61.719,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.298 | Acc: 42.597,56.436,28.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.264 | Acc: 43.540,57.107,28.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.269 | Acc: 43.545,57.275,28.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.241 | Acc: 43.875,57.533,28.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.240 | Acc: 43.936,57.534,28.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.251 | Acc: 43.640,57.393,29.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.269 | Acc: 43.429,57.303,28.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.279 | Acc: 43.274,57.400,28.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.287 | Acc: 43.163,57.320,28.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.297 | Acc: 42.945,57.284,28.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.297 | Acc: 42.958,57.318,28.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.313 | Acc: 42.716,57.067,28.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.317 | Acc: 42.580,56.882,28.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.319 | Acc: 42.546,56.817,28.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.318 | Acc: 42.600,56.787,28.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.306 | Acc: 42.669,56.798,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.311 | Acc: 42.655,56.754,28.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.306 | Acc: 42.692,56.802,28.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.299 | Acc: 42.745,56.853,28.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.163 | Acc: 36.719,56.250,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.717 | Acc: 32.924,49.442,18.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.699 | Acc: 33.117,49.219,18.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.712 | Acc: 32.787,49.449,18.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 6.786 | Acc: 32.031,53.906,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.093 | Acc: 42.262,58.668,30.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.114 | Acc: 42.664,58.803,30.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.184 | Acc: 42.405,58.120,30.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.198 | Acc: 42.409,58.025,30.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.240 | Acc: 42.157,57.495,30.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.232 | Acc: 42.200,57.399,30.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.201 | Acc: 42.453,57.591,30.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.196 | Acc: 42.464,57.550,30.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.177 | Acc: 42.580,57.623,30.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.162 | Acc: 42.794,57.793,31.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.156 | Acc: 42.902,57.834,31.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.154 | Acc: 42.914,57.900,31.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.156 | Acc: 42.888,57.836,31.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.146 | Acc: 42.883,57.821,31.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.145 | Acc: 42.896,57.729,31.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.157 | Acc: 42.806,57.637,31.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.162 | Acc: 42.701,57.519,31.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.152 | Acc: 42.819,57.609,31.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.150 | Acc: 42.805,57.614,31.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.217 | Acc: 30.469,45.312,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.119 | Acc: 31.659,47.470,14.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.141 | Acc: 31.536,46.627,14.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.165 | Acc: 31.404,46.555,14.908,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 5.645 | Acc: 44.531,60.938,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.885 | Acc: 44.754,59.598,33.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.969 | Acc: 44.055,58.441,33.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.980 | Acc: 43.660,58.363,33.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.995 | Acc: 43.451,58.391,33.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.014 | Acc: 43.139,58.400,33.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.996 | Acc: 43.137,58.368,33.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.001 | Acc: 43.318,58.245,33.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.993 | Acc: 43.595,58.443,33.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.987 | Acc: 43.530,58.369,33.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.998 | Acc: 43.346,58.279,33.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.999 | Acc: 43.283,58.329,33.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.004 | Acc: 43.296,58.377,34.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.999 | Acc: 43.376,58.324,34.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.993 | Acc: 43.436,58.357,34.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.992 | Acc: 43.361,58.384,34.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.996 | Acc: 43.339,58.462,34.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.002 | Acc: 43.306,58.486,34.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.004 | Acc: 43.315,58.434,34.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.011 | Acc: 43.321,58.419,34.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.286 | Acc: 28.125,46.094,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.594 | Acc: 24.963,39.993,24.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.648 | Acc: 25.762,39.425,25.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.709 | Acc: 25.218,39.203,25.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 6.433 | Acc: 36.719,60.156,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.949 | Acc: 42.299,59.412,36.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.996 | Acc: 42.435,58.441,35.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.927 | Acc: 43.584,58.607,36.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.964 | Acc: 43.210,58.169,35.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.969 | Acc: 43.054,57.975,35.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.948 | Acc: 43.085,58.142,35.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.964 | Acc: 42.891,57.912,35.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.967 | Acc: 42.891,57.948,35.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.955 | Acc: 43.111,58.136,35.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.949 | Acc: 43.268,58.283,35.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.956 | Acc: 43.181,58.233,35.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.951 | Acc: 43.257,58.308,35.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.950 | Acc: 43.241,58.354,35.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.951 | Acc: 43.166,58.274,35.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.955 | Acc: 43.132,58.275,35.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.950 | Acc: 43.151,58.263,36.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.959 | Acc: 43.026,58.197,36.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.968 | Acc: 43.034,58.118,36.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.968 | Acc: 43.041,58.104,36.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.639 | Acc: 39.844,57.031,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.618 | Acc: 36.830,51.897,33.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.660 | Acc: 37.290,50.705,33.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.709 | Acc: 36.322,50.333,33.145,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 5.503 | Acc: 48.438,63.281,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.709 | Acc: 44.457,59.896,38.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.760 | Acc: 43.731,59.794,38.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.798 | Acc: 43.916,59.516,38.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.836 | Acc: 43.827,58.980,38.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.873 | Acc: 43.502,58.516,38.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.877 | Acc: 43.285,58.523,37.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.878 | Acc: 43.251,58.455,37.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.866 | Acc: 43.279,58.453,37.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.862 | Acc: 43.180,58.568,37.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.864 | Acc: 43.116,58.462,37.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.877 | Acc: 43.057,58.261,37.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.885 | Acc: 42.978,58.163,37.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.876 | Acc: 43.059,58.366,37.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.879 | Acc: 43.124,58.374,37.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.872 | Acc: 43.132,58.409,37.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.875 | Acc: 43.073,58.448,37.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.876 | Acc: 43.044,58.353,37.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.877 | Acc: 43.092,58.312,37.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.875 | Acc: 43.071,58.374,37.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.974 | Acc: 31.250,48.438,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.292 | Acc: 32.143,46.987,19.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.415 | Acc: 31.212,46.075,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.489 | Acc: 30.558,45.927,18.353,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 5.541 | Acc: 48.438,61.719,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.723 | Acc: 43.824,58.780,39.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.715 | Acc: 44.150,59.546,40.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.751 | Acc: 43.212,58.940,39.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.757 | Acc: 43.499,58.845,39.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.765 | Acc: 43.487,58.950,39.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.752 | Acc: 43.782,59.291,39.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.755 | Acc: 43.789,59.076,39.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.766 | Acc: 43.600,58.846,39.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.773 | Acc: 43.517,58.922,39.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.773 | Acc: 43.493,58.905,39.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.773 | Acc: 43.510,58.958,39.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.780 | Acc: 43.377,58.772,39.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.778 | Acc: 43.328,58.815,39.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.791 | Acc: 43.177,58.724,39.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.788 | Acc: 43.091,58.786,39.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.802 | Acc: 43.000,58.689,39.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.799 | Acc: 43.040,58.667,39.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.799 | Acc: 43.001,58.646,39.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.802 | Acc: 42.975,58.590,39.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.115 | Acc: 41.406,53.125,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.330 | Acc: 35.640,47.879,31.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.351 | Acc: 35.766,47.504,31.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.369 | Acc: 35.246,47.579,30.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 5.508 | Acc: 44.531,64.062,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.816 | Acc: 42.857,58.929,40.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.764 | Acc: 43.655,59.165,40.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.787 | Acc: 43.776,58.619,40.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.765 | Acc: 43.509,58.787,39.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.766 | Acc: 43.069,58.656,39.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.749 | Acc: 43.098,58.871,40.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.754 | Acc: 43.262,58.838,40.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.743 | Acc: 43.260,58.793,40.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.728 | Acc: 43.422,58.969,40.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.738 | Acc: 43.377,58.846,40.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.750 | Acc: 43.174,58.710,40.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.744 | Acc: 43.176,58.730,40.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.755 | Acc: 43.199,58.690,40.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.756 | Acc: 43.211,58.566,40.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.750 | Acc: 43.254,58.570,40.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.745 | Acc: 43.331,58.623,40.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.751 | Acc: 43.363,58.605,40.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.751 | Acc: 43.330,58.605,40.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.751 | Acc: 43.297,58.612,40.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.240 | Acc: 36.719,50.000,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.287 | Acc: 33.073,47.359,33.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.365 | Acc: 32.565,46.246,31.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.402 | Acc: 32.377,46.734,31.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 5.511 | Acc: 46.875,72.656,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.558 | Acc: 43.638,60.528,43.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.555 | Acc: 43.826,61.509,43.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.583 | Acc: 43.622,60.681,43.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.613 | Acc: 43.277,59.983,43.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.591 | Acc: 43.502,60.118,43.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.594 | Acc: 43.569,60.040,43.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.613 | Acc: 43.351,59.730,43.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.612 | Acc: 43.386,59.749,43.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.606 | Acc: 43.310,59.768,43.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.610 | Acc: 43.291,59.756,43.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.610 | Acc: 43.474,59.767,42.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.610 | Acc: 43.465,59.673,43.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.615 | Acc: 43.484,59.522,43.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.617 | Acc: 43.419,59.447,43.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.622 | Acc: 43.272,59.383,43.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.627 | Acc: 43.346,59.377,43.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.632 | Acc: 43.301,59.322,42.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.646 | Acc: 43.172,59.174,42.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.641 | Acc: 43.233,59.186,43.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.201 | Acc: 39.844,52.344,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.522 | Acc: 34.487,50.744,40.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.533 | Acc: 34.280,50.686,39.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.572 | Acc: 34.080,50.141,39.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 6.388 | Acc: 36.719,53.906,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.553 | Acc: 42.597,59.598,45.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.574 | Acc: 41.978,59.375,45.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.571 | Acc: 42.841,59.452,44.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.600 | Acc: 42.670,59.221,44.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.615 | Acc: 42.791,59.004,44.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.622 | Acc: 42.736,58.884,44.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.608 | Acc: 42.980,58.998,44.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.626 | Acc: 42.809,58.909,44.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.622 | Acc: 42.977,59.060,44.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.615 | Acc: 43.089,59.037,44.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.605 | Acc: 43.195,59.099,44.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.614 | Acc: 43.157,59.086,44.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.612 | Acc: 43.106,59.013,44.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.613 | Acc: 42.983,58.925,44.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.609 | Acc: 43.096,58.960,44.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.617 | Acc: 43.076,58.869,44.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.616 | Acc: 43.088,58.937,44.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.621 | Acc: 43.107,58.936,44.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.625 | Acc: 43.018,58.899,44.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.201 | Acc: 35.938,48.438,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.121 | Acc: 32.366,48.438,39.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.158 | Acc: 32.088,47.542,37.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.192 | Acc: 31.660,46.990,37.679,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 5.468 | Acc: 42.188,56.250,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.477 | Acc: 42.894,59.710,45.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.510 | Acc: 43.007,59.108,45.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.528 | Acc: 43.033,59.132,45.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.566 | Acc: 42.930,58.517,45.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.575 | Acc: 43.015,58.532,45.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.576 | Acc: 43.072,58.723,45.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.578 | Acc: 43.168,58.693,45.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.588 | Acc: 43.105,58.579,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.591 | Acc: 42.999,58.676,44.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.592 | Acc: 43.031,58.710,44.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.580 | Acc: 43.202,58.753,45.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.578 | Acc: 43.202,58.902,45.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.572 | Acc: 43.346,58.917,45.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.564 | Acc: 43.447,59.011,45.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.571 | Acc: 43.361,58.970,45.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.562 | Acc: 43.397,59.051,45.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.564 | Acc: 43.390,59.027,45.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.578 | Acc: 43.254,58.914,45.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.582 | Acc: 43.112,58.854,45.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.841 | Acc: 19.531,38.281,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.320 | Acc: 20.647,34.152,31.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.300 | Acc: 20.217,33.518,31.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.236 | Acc: 20.786,33.952,31.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 5.576 | Acc: 46.094,58.594,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.509 | Acc: 43.266,58.743,47.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.449 | Acc: 43.902,59.680,47.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.448 | Acc: 43.891,59.759,47.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.447 | Acc: 43.856,59.944,47.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.477 | Acc: 43.363,59.545,46.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.488 | Acc: 43.408,59.562,46.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.475 | Acc: 43.423,59.491,46.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.485 | Acc: 43.391,59.254,46.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.501 | Acc: 43.292,59.155,46.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.496 | Acc: 43.218,59.204,46.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.492 | Acc: 43.230,59.244,46.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.478 | Acc: 43.316,59.271,46.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.472 | Acc: 43.319,59.345,46.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.478 | Acc: 43.191,59.389,46.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.478 | Acc: 43.171,59.315,46.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.482 | Acc: 43.207,59.312,46.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.483 | Acc: 43.209,59.290,46.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.484 | Acc: 43.207,59.265,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.490 | Acc: 43.139,59.143,46.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.026 | Acc: 29.688,49.219,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.548 | Acc: 24.033,40.699,32.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.473 | Acc: 24.371,40.606,32.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.472 | Acc: 23.899,40.894,32.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 5.688 | Acc: 42.969,57.031,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.384 | Acc: 44.680,59.077,48.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.423 | Acc: 43.197,59.204,48.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.395 | Acc: 43.686,59.759,48.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.424 | Acc: 43.943,59.549,47.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.420 | Acc: 43.711,59.537,47.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.418 | Acc: 43.756,59.833,47.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.430 | Acc: 43.490,59.591,47.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.421 | Acc: 43.663,59.584,47.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.435 | Acc: 43.608,59.500,47.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.449 | Acc: 43.509,59.433,47.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.453 | Acc: 43.407,59.311,47.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.449 | Acc: 43.468,59.245,47.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.444 | Acc: 43.400,59.306,47.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.447 | Acc: 43.341,59.205,47.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.457 | Acc: 43.210,59.061,47.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.462 | Acc: 43.198,59.022,47.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.467 | Acc: 43.019,58.924,47.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.477 | Acc: 42.919,58.914,47.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.471 | Acc: 42.932,58.981,47.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.922 | Acc: 33.594,47.656,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.068 | Acc: 31.845,47.061,40.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.027 | Acc: 32.241,46.399,40.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.041 | Acc: 31.481,46.734,40.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 5.299 | Acc: 41.406,65.625,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.466 | Acc: 42.448,60.379,48.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.426 | Acc: 42.778,59.889,48.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.378 | Acc: 42.828,60.092,49.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.388 | Acc: 42.612,59.722,49.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.388 | Acc: 42.543,59.963,49.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.376 | Acc: 42.833,60.034,49.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.383 | Acc: 42.930,60.018,49.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.382 | Acc: 42.949,59.904,49.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.399 | Acc: 42.921,59.785,49.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.400 | Acc: 42.802,59.744,48.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.404 | Acc: 42.866,59.704,48.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.412 | Acc: 42.875,59.595,48.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.406 | Acc: 43.029,59.662,49.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.410 | Acc: 43.041,59.589,49.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.416 | Acc: 43.018,59.520,48.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.411 | Acc: 42.959,59.528,49.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.412 | Acc: 42.930,59.446,49.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.403 | Acc: 42.917,59.451,49.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.403 | Acc: 42.940,59.424,49.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.777 | Acc: 29.688,49.219,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.637 | Acc: 27.046,46.838,30.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.668 | Acc: 27.229,45.770,29.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.677 | Acc: 26.729,45.940,28.945,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.833 | Acc: 40.625,58.594,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.174 | Acc: 44.568,60.082,52.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.193 | Acc: 43.197,60.861,52.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.227 | Acc: 43.340,60.272,51.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.252 | Acc: 43.046,60.185,51.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.284 | Acc: 42.899,59.986,51.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.289 | Acc: 43.085,60.021,51.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.294 | Acc: 42.952,60.023,51.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.301 | Acc: 42.964,59.952,50.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.315 | Acc: 42.930,59.923,50.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.325 | Acc: 42.918,59.748,50.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.322 | Acc: 43.001,59.647,50.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.336 | Acc: 42.761,59.540,50.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.338 | Acc: 42.870,59.492,50.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.329 | Acc: 42.960,59.592,50.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.324 | Acc: 43.008,59.575,50.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.326 | Acc: 43.005,59.545,50.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.322 | Acc: 43.035,59.453,51.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.312 | Acc: 43.129,59.492,51.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.307 | Acc: 43.145,59.572,51.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.458 | Acc: 35.156,50.000,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.928 | Acc: 30.915,48.958,43.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.997 | Acc: 30.412,48.418,43.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.096 | Acc: 29.598,47.925,42.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 5.720 | Acc: 36.719,58.594,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.214 | Acc: 42.597,59.524,52.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.107 | Acc: 43.902,60.423,53.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.124 | Acc: 43.750,60.195,53.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.163 | Acc: 43.586,59.983,53.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.160 | Acc: 43.557,59.831,53.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.155 | Acc: 43.563,59.963,53.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.169 | Acc: 43.429,59.791,53.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.192 | Acc: 43.211,59.603,52.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.198 | Acc: 43.176,59.513,52.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.216 | Acc: 43.004,59.356,52.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.234 | Acc: 43.018,59.216,52.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.230 | Acc: 43.082,59.297,52.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.237 | Acc: 42.954,59.139,52.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.226 | Acc: 43.097,59.208,52.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.221 | Acc: 43.182,59.222,52.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.224 | Acc: 43.166,59.236,53.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.215 | Acc: 43.269,59.283,53.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.214 | Acc: 43.205,59.317,53.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.204 | Acc: 43.211,59.416,53.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.753 | Acc: 28.906,55.469,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.542 | Acc: 25.335,45.238,46.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.551 | Acc: 25.305,44.950,46.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.587 | Acc: 25.090,44.762,46.094,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 5.249 | Acc: 40.625,57.812,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.003 | Acc: 43.378,61.756,55.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.970 | Acc: 43.826,62.024,56.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.995 | Acc: 44.442,61.936,56.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.031 | Acc: 43.953,61.400,55.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.009 | Acc: 43.912,61.347,55.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.008 | Acc: 43.763,61.331,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.010 | Acc: 43.900,61.287,56.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.030 | Acc: 43.619,60.860,56.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.032 | Acc: 43.573,60.916,56.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.043 | Acc: 43.486,60.751,56.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.065 | Acc: 43.358,60.513,55.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.075 | Acc: 43.293,60.341,55.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.078 | Acc: 43.175,60.300,55.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.068 | Acc: 43.269,60.251,56.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.062 | Acc: 43.278,60.260,56.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.064 | Acc: 43.288,60.122,56.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.068 | Acc: 43.244,60.046,56.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.069 | Acc: 43.239,60.029,56.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.063 | Acc: 43.235,60.046,56.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.368 | Acc: 32.812,52.344,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.729 | Acc: 29.874,46.763,46.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.765 | Acc: 30.050,46.684,46.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.794 | Acc: 29.329,46.798,46.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 5.139 | Acc: 39.844,62.500,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.842 | Acc: 43.862,61.979,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.825 | Acc: 44.112,62.405,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.897 | Acc: 43.430,61.437,58.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.938 | Acc: 42.998,60.918,58.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.949 | Acc: 43.154,60.713,57.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.940 | Acc: 43.182,60.692,57.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.954 | Acc: 43.273,60.550,57.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.952 | Acc: 43.323,60.617,57.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.955 | Acc: 43.474,60.644,57.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.958 | Acc: 43.486,60.642,57.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.959 | Acc: 43.485,60.602,57.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.966 | Acc: 43.504,60.552,57.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.968 | Acc: 43.508,60.426,57.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.976 | Acc: 43.461,60.398,57.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.974 | Acc: 43.415,60.429,57.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.975 | Acc: 43.460,60.439,57.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.978 | Acc: 43.404,60.321,57.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.977 | Acc: 43.324,60.308,57.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.981 | Acc: 43.311,60.203,57.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.760 | Acc: 36.719,52.344,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.133 | Acc: 29.278,46.019,45.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.233 | Acc: 28.868,44.646,44.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.236 | Acc: 28.099,44.416,45.120,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 4.814 | Acc: 40.625,63.281,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.898 | Acc: 43.080,61.235,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.956 | Acc: 42.912,60.633,58.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.949 | Acc: 43.174,60.643,58.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.961 | Acc: 42.998,60.494,58.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.957 | Acc: 43.162,60.466,58.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.929 | Acc: 43.666,60.647,58.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.959 | Acc: 43.440,60.478,58.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.950 | Acc: 43.352,60.491,58.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.941 | Acc: 43.526,60.545,58.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.929 | Acc: 43.552,60.677,58.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.931 | Acc: 43.379,60.609,58.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.933 | Acc: 43.520,60.532,58.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.924 | Acc: 43.585,60.521,58.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.941 | Acc: 43.361,60.393,58.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.957 | Acc: 43.200,60.335,58.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.965 | Acc: 43.105,60.293,58.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.967 | Acc: 43.049,60.223,58.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.963 | Acc: 43.060,60.277,58.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.961 | Acc: 43.133,60.298,58.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.615 | Acc: 32.031,46.094,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.840 | Acc: 31.176,46.205,47.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.911 | Acc: 30.564,45.122,46.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.934 | Acc: 30.482,44.928,46.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 5.444 | Acc: 39.062,60.938,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.925 | Acc: 42.597,60.491,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.862 | Acc: 43.007,60.804,59.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.815 | Acc: 43.430,61.078,59.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.807 | Acc: 43.885,61.101,59.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.822 | Acc: 44.098,60.968,59.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.842 | Acc: 43.685,60.925,59.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.867 | Acc: 43.517,60.860,59.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.871 | Acc: 43.566,60.840,59.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.879 | Acc: 43.603,60.808,59.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.886 | Acc: 43.326,60.700,59.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.889 | Acc: 43.266,60.538,59.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.886 | Acc: 43.296,60.574,59.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.894 | Acc: 43.229,60.545,58.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.887 | Acc: 43.314,60.598,59.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.905 | Acc: 43.187,60.460,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.901 | Acc: 43.183,60.514,58.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.910 | Acc: 43.049,60.523,58.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.919 | Acc: 43.019,60.457,58.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.924 | Acc: 42.995,60.408,58.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.577 | Acc: 36.719,49.219,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.788 | Acc: 30.878,46.540,49.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.816 | Acc: 30.431,46.475,48.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.825 | Acc: 29.393,46.555,48.822,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 4.879 | Acc: 44.531,60.938,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.854 | Acc: 44.829,61.868,59.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 45.332,63.777,62.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.523 | Acc: 45.569,64.575,62.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.467 | Acc: 46.113,65.220,63.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.424 | Acc: 46.156,65.385,63.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.416 | Acc: 46.223,65.580,64.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.382 | Acc: 46.432,65.819,64.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.366 | Acc: 46.380,65.945,64.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.350 | Acc: 46.392,66.083,64.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.329 | Acc: 46.517,66.332,65.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.320 | Acc: 46.649,66.424,65.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.308 | Acc: 46.872,66.523,65.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.294 | Acc: 46.914,66.664,65.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.274 | Acc: 47.070,66.868,65.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.260 | Acc: 47.186,67.034,65.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.254 | Acc: 47.281,67.107,65.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.248 | Acc: 47.370,67.220,66.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.245 | Acc: 47.373,67.255,66.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.240 | Acc: 47.408,67.315,66.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.372 | Acc: 49.219,69.531,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.583 | Acc: 45.238,63.616,64.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.585 | Acc: 45.236,62.786,63.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.634 | Acc: 44.698,62.449,63.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.955 | Acc: 46.094,71.875,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.966 | Acc: 49.740,70.089,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.999 | Acc: 49.352,69.569,68.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.038 | Acc: 49.155,69.314,68.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.029 | Acc: 49.084,69.261,68.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.055 | Acc: 48.832,68.998,68.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.059 | Acc: 48.502,69.015,68.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.059 | Acc: 48.787,68.961,67.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.060 | Acc: 48.777,68.944,67.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.070 | Acc: 48.567,68.914,67.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.073 | Acc: 48.472,68.886,67.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.064 | Acc: 48.568,68.966,68.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.040 | Acc: 48.856,69.207,68.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.042 | Acc: 48.839,69.259,68.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.042 | Acc: 48.729,69.351,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.032 | Acc: 48.778,69.386,68.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.041 | Acc: 48.676,69.341,68.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.042 | Acc: 48.591,69.288,68.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.040 | Acc: 48.580,69.306,68.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.039 | Acc: 48.532,69.326,68.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.291 | Acc: 54.688,66.406,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.518 | Acc: 45.685,63.653,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 45.617,62.881,64.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.581 | Acc: 44.915,62.615,63.858,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 4.069 | Acc: 46.875,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.946 | Acc: 49.516,68.936,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.944 | Acc: 49.676,69.436,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.952 | Acc: 49.462,69.557,68.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.972 | Acc: 49.363,69.821,69.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.968 | Acc: 49.598,69.988,69.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.942 | Acc: 49.651,70.254,69.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.948 | Acc: 49.590,70.107,69.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.966 | Acc: 49.165,69.924,69.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.968 | Acc: 49.210,69.963,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.971 | Acc: 49.145,69.858,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.972 | Acc: 49.028,69.934,69.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.963 | Acc: 49.027,70.034,69.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.968 | Acc: 49.048,69.917,68.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.977 | Acc: 49.013,69.820,68.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.975 | Acc: 49.024,69.871,69.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.977 | Acc: 48.990,69.862,68.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.974 | Acc: 49.038,69.818,68.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.971 | Acc: 49.065,69.839,68.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.976 | Acc: 49.065,69.783,68.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.286 | Acc: 52.344,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 45.089,64.286,64.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 44.970,63.186,64.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 44.506,62.820,64.075,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 4.037 | Acc: 53.125,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.067 | Acc: 47.582,68.155,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.012 | Acc: 47.599,69.322,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.002 | Acc: 48.066,69.659,69.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.989 | Acc: 48.515,69.570,69.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.950 | Acc: 48.639,70.065,69.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.964 | Acc: 48.618,69.964,69.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.949 | Acc: 48.775,70.119,69.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.950 | Acc: 48.675,70.196,69.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.943 | Acc: 48.826,70.161,69.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.935 | Acc: 48.776,70.270,69.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.933 | Acc: 48.911,70.305,69.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.941 | Acc: 48.937,70.209,69.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.935 | Acc: 48.928,70.175,69.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.939 | Acc: 48.955,70.137,69.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.933 | Acc: 48.993,70.113,69.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.919 | Acc: 49.112,70.286,69.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.922 | Acc: 49.134,70.198,69.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.921 | Acc: 49.180,70.196,69.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.921 | Acc: 49.157,70.220,69.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 51.562,67.188,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.537 | Acc: 44.717,64.583,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.548 | Acc: 44.817,63.758,65.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.587 | Acc: 44.467,63.204,64.524,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 3.898 | Acc: 49.219,67.188,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.875 | Acc: 49.144,71.094,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.913 | Acc: 48.952,70.770,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.906 | Acc: 49.488,70.633,69.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.906 | Acc: 49.662,70.843,69.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.896 | Acc: 49.660,70.769,69.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.895 | Acc: 49.464,70.506,69.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.892 | Acc: 49.429,70.484,69.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.888 | Acc: 49.437,70.541,69.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.901 | Acc: 49.404,70.468,69.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.897 | Acc: 49.436,70.530,69.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.893 | Acc: 49.357,70.546,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.890 | Acc: 49.371,70.526,69.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.885 | Acc: 49.398,70.558,69.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.890 | Acc: 49.338,70.499,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.894 | Acc: 49.304,70.523,69.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.892 | Acc: 49.323,70.493,69.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.891 | Acc: 49.363,70.491,69.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.886 | Acc: 49.437,70.540,69.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.887 | Acc: 49.354,70.575,69.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.275 | Acc: 53.125,68.750,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 46.243,63.653,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.427,62.881,64.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 45.031,62.692,63.781,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.829 | Acc: 53.125,74.219,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.923 | Acc: 49.107,70.126,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.879 | Acc: 49.104,70.770,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.855 | Acc: 49.424,71.017,70.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.865 | Acc: 49.373,70.833,69.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.894 | Acc: 49.219,70.730,69.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.877 | Acc: 49.309,70.939,69.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.876 | Acc: 49.479,70.817,69.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.881 | Acc: 49.505,70.783,69.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.871 | Acc: 49.637,70.839,70.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.862 | Acc: 49.662,70.868,70.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.854 | Acc: 49.643,70.868,70.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.850 | Acc: 49.731,70.922,70.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.855 | Acc: 49.647,70.896,70.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.865 | Acc: 49.569,70.852,70.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.865 | Acc: 49.538,70.780,70.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.865 | Acc: 49.499,70.775,70.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.868 | Acc: 49.416,70.727,70.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.869 | Acc: 49.381,70.706,70.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.868 | Acc: 49.375,70.725,70.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.225 | Acc: 53.906,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.500 | Acc: 46.652,64.360,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 46.132,63.415,64.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.557 | Acc: 45.594,62.987,64.127,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 4.164 | Acc: 53.906,66.406,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.816 | Acc: 49.814,71.429,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.818 | Acc: 49.676,70.713,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.842 | Acc: 49.334,70.671,70.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.818 | Acc: 49.450,71.161,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.831 | Acc: 49.141,71.032,70.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.834 | Acc: 49.245,71.055,70.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.844 | Acc: 49.086,71.110,70.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.829 | Acc: 49.393,71.273,70.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.807 | Acc: 49.521,71.426,70.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.815 | Acc: 49.390,71.366,70.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.823 | Acc: 49.307,71.235,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.836 | Acc: 49.238,71.155,70.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.833 | Acc: 49.315,71.133,70.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.834 | Acc: 49.260,71.110,70.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.832 | Acc: 49.349,71.237,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.834 | Acc: 49.413,71.225,70.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.836 | Acc: 49.446,71.181,70.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.839 | Acc: 49.316,71.204,70.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.832 | Acc: 49.416,71.284,70.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.325 | Acc: 47.656,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 45.685,64.918,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.579 | Acc: 45.427,63.319,64.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.624 | Acc: 44.903,62.935,64.088,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.487 | Acc: 53.125,73.438,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.839 | Acc: 49.963,70.275,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.834 | Acc: 49.009,70.446,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.805 | Acc: 49.590,71.004,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.790 | Acc: 49.431,71.296,71.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.795 | Acc: 49.389,71.504,71.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.806 | Acc: 49.212,71.436,70.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.807 | Acc: 49.418,71.354,70.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.808 | Acc: 49.534,71.463,71.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.795 | Acc: 49.771,71.577,71.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.798 | Acc: 49.650,71.494,71.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.797 | Acc: 49.646,71.511,71.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.795 | Acc: 49.708,71.522,71.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.799 | Acc: 49.710,71.435,71.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.802 | Acc: 49.697,71.447,71.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.797 | Acc: 49.751,71.509,71.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.802 | Acc: 49.652,71.444,71.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.800 | Acc: 49.718,71.465,71.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.801 | Acc: 49.727,71.453,70.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.810 | Acc: 49.643,71.358,70.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.456 | Acc: 45.312,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.588 | Acc: 46.205,64.360,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 45.465,63.224,64.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 44.839,62.923,63.870,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 3.943 | Acc: 36.719,72.656,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.854 | Acc: 48.475,71.466,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.755 | Acc: 49.962,72.085,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.771 | Acc: 49.936,71.388,71.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.794 | Acc: 49.923,71.142,70.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.774 | Acc: 50.039,71.388,71.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.786 | Acc: 49.755,71.275,71.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.795 | Acc: 49.623,71.243,71.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.794 | Acc: 49.592,71.283,70.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.781 | Acc: 49.840,71.478,71.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.787 | Acc: 49.782,71.428,71.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.792 | Acc: 49.724,71.440,71.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.790 | Acc: 49.724,71.450,71.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.789 | Acc: 49.823,71.426,71.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.792 | Acc: 49.803,71.469,71.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.786 | Acc: 49.730,71.538,71.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.785 | Acc: 49.732,71.551,71.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.781 | Acc: 49.743,71.582,71.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.781 | Acc: 49.792,71.570,71.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.787 | Acc: 49.750,71.549,71.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.319 | Acc: 53.125,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.539 | Acc: 45.610,64.286,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.548 | Acc: 45.389,63.072,64.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 44.941,62.859,64.242,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 4.017 | Acc: 49.219,72.656,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.795 | Acc: 50.037,71.168,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.736 | Acc: 50.686,72.027,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.755 | Acc: 49.936,72.003,71.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.731 | Acc: 50.550,72.010,71.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.725 | Acc: 50.480,72.084,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.735 | Acc: 50.303,71.959,71.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.748 | Acc: 50.255,71.919,71.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.755 | Acc: 50.184,71.802,71.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.746 | Acc: 50.268,71.892,71.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.749 | Acc: 50.222,71.786,71.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.756 | Acc: 50.095,71.737,71.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.759 | Acc: 50.055,71.752,71.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.759 | Acc: 50.015,71.713,71.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.764 | Acc: 49.878,71.683,71.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.762 | Acc: 49.896,71.688,71.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.764 | Acc: 49.781,71.746,71.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.768 | Acc: 49.741,71.680,71.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.763 | Acc: 49.814,71.713,71.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.770 | Acc: 49.729,71.645,71.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.212 | Acc: 53.906,69.531,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.521 | Acc: 46.429,64.993,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 45.865,63.319,65.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.584 | Acc: 45.479,62.948,64.511,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 3.577 | Acc: 46.875,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.734 | Acc: 49.442,72.507,73.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.713 | Acc: 50.267,72.542,73.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.758 | Acc: 50.295,72.080,72.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.761 | Acc: 50.338,71.914,72.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.757 | Acc: 50.317,71.921,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.736 | Acc: 50.413,72.043,72.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.747 | Acc: 50.449,72.014,72.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.755 | Acc: 50.204,71.841,71.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.752 | Acc: 50.095,71.789,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.750 | Acc: 49.930,71.801,71.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.757 | Acc: 49.894,71.652,71.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.756 | Acc: 49.880,71.612,71.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.762 | Acc: 49.740,71.567,71.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.754 | Acc: 49.839,71.633,71.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.749 | Acc: 49.798,71.758,71.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.749 | Acc: 49.805,71.817,71.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.758 | Acc: 49.725,71.687,71.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.758 | Acc: 49.781,71.661,71.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.761 | Acc: 49.756,71.584,71.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.278 | Acc: 51.562,64.844,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.501 | Acc: 46.280,64.955,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.510 | Acc: 46.151,64.310,65.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.553 | Acc: 45.812,63.589,64.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 3.726 | Acc: 50.000,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.656 | Acc: 49.740,73.065,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.627 | Acc: 50.229,73.152,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.656 | Acc: 49.910,73.297,73.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.658 | Acc: 49.971,73.013,72.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.674 | Acc: 50.039,72.896,72.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.697 | Acc: 50.019,72.598,72.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.686 | Acc: 50.249,72.584,72.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.691 | Acc: 50.267,72.482,72.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.698 | Acc: 50.294,72.363,72.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.704 | Acc: 50.233,72.322,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.702 | Acc: 50.240,72.296,72.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.708 | Acc: 50.178,72.232,72.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.729 | Acc: 50.003,72.055,72.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.729 | Acc: 49.964,72.089,72.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.723 | Acc: 49.979,72.132,72.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.731 | Acc: 49.873,71.980,72.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.731 | Acc: 49.908,71.996,72.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.732 | Acc: 49.948,72.007,72.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.731 | Acc: 49.963,71.992,72.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.299 | Acc: 54.688,67.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.528 | Acc: 46.057,64.435,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 45.617,63.262,64.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 45.082,62.615,64.229,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 3.543 | Acc: 50.000,77.344,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.522 | Acc: 51.339,73.735,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.609 | Acc: 50.114,72.847,73.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.625 | Acc: 50.307,72.682,73.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.668 | Acc: 49.942,72.560,72.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.680 | Acc: 49.892,72.331,72.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.684 | Acc: 50.000,72.417,72.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.673 | Acc: 50.105,72.368,72.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.677 | Acc: 50.102,72.331,72.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.692 | Acc: 49.901,72.203,72.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.704 | Acc: 49.949,71.972,72.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.710 | Acc: 49.855,71.960,72.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.701 | Acc: 49.987,72.079,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.713 | Acc: 50.012,71.983,72.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.709 | Acc: 50.086,72.039,72.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.713 | Acc: 50.008,71.979,72.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.714 | Acc: 49.981,71.941,72.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.715 | Acc: 49.952,71.967,72.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.718 | Acc: 49.903,71.912,72.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.718 | Acc: 49.934,71.838,72.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.311 | Acc: 55.469,68.750,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 46.280,64.993,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 45.732,63.967,64.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 45.569,63.525,64.460,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 3.543 | Acc: 53.125,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.601 | Acc: 52.195,72.433,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.623 | Acc: 51.220,72.942,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.625 | Acc: 50.640,72.951,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.623 | Acc: 50.511,73.032,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.641 | Acc: 50.433,72.741,73.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.661 | Acc: 50.194,72.618,73.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.681 | Acc: 50.127,72.435,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.688 | Acc: 50.073,72.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.704 | Acc: 49.996,72.233,72.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.705 | Acc: 49.922,72.291,72.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.701 | Acc: 49.979,72.253,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.703 | Acc: 49.951,72.238,72.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.709 | Acc: 49.907,72.237,72.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.710 | Acc: 49.903,72.273,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.721 | Acc: 49.836,72.103,72.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.718 | Acc: 49.976,72.099,72.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.716 | Acc: 49.984,72.079,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.715 | Acc: 49.890,72.107,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.710 | Acc: 49.902,72.181,72.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.488 | Acc: 51.562,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.448 | Acc: 46.615,64.621,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.491 | Acc: 46.113,63.929,65.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.533 | Acc: 45.697,63.691,64.857,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 2.794 | Acc: 63.281,78.906,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.572 | Acc: 51.190,73.326,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.611 | Acc: 50.819,73.133,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.621 | Acc: 50.538,73.245,73.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.597 | Acc: 50.858,73.621,73.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.597 | Acc: 50.804,73.561,73.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.607 | Acc: 50.529,73.483,73.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.627 | Acc: 50.194,73.188,73.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.639 | Acc: 50.175,72.967,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.654 | Acc: 50.121,72.695,72.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.659 | Acc: 50.086,72.645,72.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.672 | Acc: 50.088,72.448,72.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.676 | Acc: 50.113,72.361,72.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.681 | Acc: 50.063,72.327,72.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.679 | Acc: 50.120,72.428,72.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.683 | Acc: 50.008,72.425,72.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.680 | Acc: 50.027,72.440,72.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.684 | Acc: 49.929,72.411,72.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.685 | Acc: 49.957,72.405,72.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.688 | Acc: 49.949,72.359,72.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.525 | Acc: 47.656,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.624 | Acc: 44.531,63.356,64.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.647 | Acc: 44.512,62.367,64.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.686 | Acc: 44.211,62.436,64.062,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 3.294 | Acc: 45.312,79.688,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.596 | Acc: 49.851,74.033,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.578 | Acc: 50.610,73.628,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.609 | Acc: 50.909,73.438,73.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.633 | Acc: 51.003,72.946,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.626 | Acc: 50.944,73.159,73.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.634 | Acc: 50.762,73.128,73.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.636 | Acc: 50.754,72.911,73.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.633 | Acc: 50.883,72.860,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.644 | Acc: 50.652,72.747,72.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.636 | Acc: 50.544,72.746,72.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.633 | Acc: 50.587,72.787,72.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.643 | Acc: 50.558,72.643,72.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.653 | Acc: 50.521,72.554,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.656 | Acc: 50.487,72.520,72.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.663 | Acc: 50.540,72.493,72.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.669 | Acc: 50.521,72.442,72.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.676 | Acc: 50.515,72.372,72.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.678 | Acc: 50.478,72.336,72.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.679 | Acc: 50.455,72.353,72.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.391 | Acc: 50.781,67.969,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 46.577,63.914,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.558 | Acc: 45.922,63.224,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 45.364,63.051,64.908,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 4.042 | Acc: 41.406,70.312,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.628 | Acc: 49.554,73.586,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.608 | Acc: 50.705,72.885,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.603 | Acc: 50.704,72.784,73.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.607 | Acc: 50.685,72.743,73.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.613 | Acc: 50.565,72.571,73.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.626 | Acc: 50.465,72.488,72.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.645 | Acc: 50.266,72.424,72.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.638 | Acc: 50.296,72.404,72.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.637 | Acc: 50.337,72.320,72.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.644 | Acc: 50.222,72.236,72.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.641 | Acc: 50.262,72.285,72.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.639 | Acc: 50.263,72.339,72.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.646 | Acc: 50.195,72.276,72.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.661 | Acc: 50.072,72.189,72.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.660 | Acc: 50.234,72.181,72.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.664 | Acc: 50.124,72.169,72.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.660 | Acc: 50.154,72.209,72.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.661 | Acc: 50.167,72.252,72.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.664 | Acc: 50.111,72.254,72.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 53.125,67.188,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 45.945,65.179,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.550 | Acc: 45.160,63.929,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 44.762,63.448,65.049,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 3.710 | Acc: 50.000,75.000,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.737 | Acc: 49.182,71.205,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.715 | Acc: 48.571,71.513,72.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.675 | Acc: 48.937,72.439,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.668 | Acc: 49.093,72.454,73.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.659 | Acc: 49.343,72.587,72.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.643 | Acc: 49.574,72.682,73.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.634 | Acc: 49.928,72.800,73.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.639 | Acc: 49.913,72.627,72.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.629 | Acc: 50.078,72.635,73.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.630 | Acc: 50.008,72.683,72.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.641 | Acc: 50.018,72.550,72.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.645 | Acc: 50.133,72.523,72.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.645 | Acc: 50.224,72.501,72.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.649 | Acc: 50.297,72.539,72.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.652 | Acc: 50.348,72.563,72.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.653 | Acc: 50.307,72.554,72.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.653 | Acc: 50.286,72.555,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.655 | Acc: 50.264,72.498,72.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.655 | Acc: 50.246,72.558,72.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.506 | Acc: 50.000,66.406,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.525 | Acc: 45.982,65.625,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.564 | Acc: 45.579,64.101,65.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.612 | Acc: 45.082,63.461,64.908,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 3.141 | Acc: 55.469,75.000,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.498 | Acc: 51.376,73.177,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.553 | Acc: 50.972,73.418,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.587 | Acc: 50.384,73.271,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.582 | Acc: 50.289,73.418,74.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.593 | Acc: 50.193,73.306,73.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.597 | Acc: 50.155,73.173,73.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.595 | Acc: 50.211,73.354,73.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.604 | Acc: 50.247,73.166,73.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.622 | Acc: 49.948,73.058,73.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.628 | Acc: 49.868,72.979,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.631 | Acc: 49.943,72.872,73.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.629 | Acc: 50.071,72.890,73.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.627 | Acc: 50.120,72.968,73.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.630 | Acc: 50.081,72.890,73.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.628 | Acc: 50.200,72.882,73.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.632 | Acc: 50.183,72.800,73.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.638 | Acc: 50.124,72.757,73.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.645 | Acc: 50.091,72.728,72.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.642 | Acc: 50.158,72.824,73.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.329 | Acc: 50.781,65.625,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 46.131,63.951,65.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.541,63.415,65.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 45.018,63.089,64.434,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 3.735 | Acc: 49.219,74.219,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.591 | Acc: 50.967,72.507,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.565 | Acc: 51.200,73.171,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.621 | Acc: 50.551,72.976,73.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.622 | Acc: 50.125,72.936,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.638 | Acc: 49.884,72.881,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.628 | Acc: 50.090,73.050,73.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.633 | Acc: 50.249,72.972,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.632 | Acc: 50.233,73.001,73.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.639 | Acc: 50.086,72.941,73.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.639 | Acc: 50.152,72.858,73.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.640 | Acc: 50.194,72.798,73.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.635 | Acc: 50.259,72.854,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.634 | Acc: 50.269,72.764,73.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.636 | Acc: 50.250,72.787,73.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.633 | Acc: 50.226,72.812,73.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.628 | Acc: 50.195,72.846,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.627 | Acc: 50.183,72.840,73.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.626 | Acc: 50.234,72.814,73.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.627 | Acc: 50.166,72.802,73.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.493 | Acc: 49.219,64.844,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 45.685,64.286,65.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 45.446,63.034,64.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 45.069,63.102,64.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 3.288 | Acc: 53.125,76.562,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.579 | Acc: 49.888,74.293,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.615 | Acc: 50.610,73.247,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.563 | Acc: 50.999,73.450,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.564 | Acc: 50.878,73.341,73.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.590 | Acc: 50.727,73.105,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.603 | Acc: 50.691,73.044,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.597 | Acc: 50.637,72.872,73.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.606 | Acc: 50.592,72.845,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.607 | Acc: 50.475,72.825,73.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.606 | Acc: 50.330,72.874,73.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.611 | Acc: 50.286,72.791,73.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.617 | Acc: 50.250,72.789,73.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.610 | Acc: 50.356,72.926,73.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.615 | Acc: 50.348,72.795,73.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.623 | Acc: 50.298,72.654,73.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.624 | Acc: 50.287,72.676,73.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.621 | Acc: 50.346,72.672,73.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.624 | Acc: 50.318,72.665,73.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.627 | Acc: 50.250,72.675,73.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.439 | Acc: 51.562,65.625,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.441 | Acc: 46.838,65.253,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.483 | Acc: 46.437,64.463,66.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 45.940,64.191,65.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 3.925 | Acc: 46.875,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.588 | Acc: 49.628,72.731,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.612 | Acc: 50.400,72.752,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.579 | Acc: 50.615,73.463,73.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.572 | Acc: 50.395,73.476,73.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.578 | Acc: 50.255,73.283,73.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.567 | Acc: 50.400,73.379,74.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.584 | Acc: 50.344,73.238,73.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.596 | Acc: 50.199,73.195,73.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.594 | Acc: 50.255,73.286,73.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.586 | Acc: 50.416,73.329,73.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.589 | Acc: 50.308,73.261,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.585 | Acc: 50.331,73.347,73.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.587 | Acc: 50.293,73.345,73.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.595 | Acc: 50.309,73.290,73.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.606 | Acc: 50.218,73.191,73.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.614 | Acc: 50.163,73.143,73.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.611 | Acc: 50.181,73.142,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.612 | Acc: 50.216,73.065,73.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.606 | Acc: 50.217,73.064,73.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.346 | Acc: 51.562,66.406,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.561 | Acc: 45.796,64.286,65.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 45.351,63.110,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.612 | Acc: 44.941,62.795,64.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 3.240 | Acc: 50.000,76.562,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.625 | Acc: 49.479,72.917,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.588 | Acc: 49.981,73.018,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.569 | Acc: 50.218,73.079,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.570 | Acc: 50.646,73.360,74.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.565 | Acc: 50.688,73.461,74.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.554 | Acc: 50.717,73.663,74.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.572 | Acc: 50.521,73.521,74.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.580 | Acc: 50.383,73.505,74.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.573 | Acc: 50.501,73.554,74.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.578 | Acc: 50.595,73.496,74.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.577 | Acc: 50.661,73.314,73.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.576 | Acc: 50.681,73.272,73.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.579 | Acc: 50.605,73.315,73.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.588 | Acc: 50.609,73.204,73.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.584 | Acc: 50.677,73.206,73.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.576 | Acc: 50.754,73.328,73.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.577 | Acc: 50.717,73.307,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.577 | Acc: 50.643,73.280,73.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.583 | Acc: 50.591,73.185,73.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.340 | Acc: 52.344,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 46.243,64.732,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 45.655,63.720,65.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 45.095,62.987,65.254,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 3.530 | Acc: 46.094,75.000,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.591 | Acc: 50.000,73.921,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.588 | Acc: 50.591,73.438,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.571 | Acc: 51.025,73.476,74.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.558 | Acc: 51.312,73.659,74.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.549 | Acc: 51.261,73.747,74.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.559 | Acc: 51.091,73.612,74.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.572 | Acc: 50.803,73.338,74.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.579 | Acc: 50.728,73.268,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.579 | Acc: 50.734,73.321,74.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.571 | Acc: 50.937,73.430,74.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.571 | Acc: 51.000,73.427,74.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.578 | Acc: 50.875,73.282,74.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.579 | Acc: 50.796,73.231,73.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.588 | Acc: 50.726,73.201,73.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.579 | Acc: 50.807,73.331,74.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.579 | Acc: 50.830,73.372,74.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.579 | Acc: 50.788,73.467,74.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.584 | Acc: 50.703,73.394,74.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.582 | Acc: 50.668,73.433,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.504 | Acc: 52.344,67.188,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.640 | Acc: 45.759,64.472,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.675 | Acc: 45.370,63.167,64.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.709 | Acc: 44.608,62.807,64.062,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 3.517 | Acc: 46.875,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.554 | Acc: 50.149,75.521,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.574 | Acc: 50.991,74.143,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.572 | Acc: 51.101,74.078,74.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.559 | Acc: 51.022,73.785,74.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.553 | Acc: 51.044,73.855,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.542 | Acc: 50.704,73.954,74.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.543 | Acc: 50.837,73.737,74.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.555 | Acc: 50.679,73.636,74.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.550 | Acc: 50.622,73.701,74.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.544 | Acc: 50.781,73.655,74.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.543 | Acc: 50.810,73.685,74.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.546 | Acc: 50.652,73.687,74.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.557 | Acc: 50.551,73.554,74.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.561 | Acc: 50.450,73.474,74.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.569 | Acc: 50.343,73.432,74.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.570 | Acc: 50.385,73.379,74.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.571 | Acc: 50.440,73.355,74.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.576 | Acc: 50.392,73.318,74.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.574 | Acc: 50.390,73.310,74.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 50.000,67.188,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.539 | Acc: 45.945,64.509,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 45.941,63.357,64.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.646 | Acc: 45.300,62.833,64.639,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 3.791 | Acc: 46.094,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.487 | Acc: 50.856,74.330,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.515 | Acc: 51.239,73.609,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.552 | Acc: 51.050,73.399,74.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.552 | Acc: 51.051,73.264,74.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.552 | Acc: 51.191,73.120,74.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.551 | Acc: 51.027,73.076,73.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.547 | Acc: 51.064,73.177,73.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.550 | Acc: 50.903,73.253,74.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.546 | Acc: 50.893,73.347,74.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.548 | Acc: 50.738,73.340,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.557 | Acc: 50.580,73.215,73.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.563 | Acc: 50.532,73.240,74.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.561 | Acc: 50.533,73.291,73.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.562 | Acc: 50.478,73.315,74.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.561 | Acc: 50.501,73.264,73.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.566 | Acc: 50.504,73.309,73.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.569 | Acc: 50.463,73.275,74.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.563 | Acc: 50.511,73.327,74.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.565 | Acc: 50.459,73.333,74.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.335 | Acc: 54.688,68.750,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.549 | Acc: 46.503,64.435,66.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 45.846,63.243,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 45.505,62.807,64.767,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 3.418 | Acc: 43.750,76.562,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.493 | Acc: 50.149,74.851,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.485 | Acc: 50.191,74.676,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.470 | Acc: 50.615,74.552,75.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.477 | Acc: 50.424,74.460,75.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.503 | Acc: 50.209,73.925,75.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.495 | Acc: 50.329,74.006,75.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.507 | Acc: 50.310,73.670,75.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.522 | Acc: 50.364,73.690,74.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.531 | Acc: 50.470,73.645,74.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.534 | Acc: 50.529,73.678,74.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.534 | Acc: 50.576,73.692,74.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.536 | Acc: 50.506,73.626,74.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.538 | Acc: 50.560,73.692,74.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.531 | Acc: 50.703,73.665,74.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.533 | Acc: 50.766,73.583,74.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.535 | Acc: 50.750,73.644,74.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.541 | Acc: 50.696,73.547,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.543 | Acc: 50.649,73.570,74.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.549 | Acc: 50.607,73.503,74.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.249 | Acc: 53.906,67.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 46.540,64.397,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 45.884,62.995,64.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.632 | Acc: 45.453,62.602,64.370,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 3.087 | Acc: 58.594,77.344,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.601 | Acc: 49.033,73.438,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.570 | Acc: 49.809,73.495,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.569 | Acc: 49.974,73.450,74.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.564 | Acc: 49.875,73.418,74.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.558 | Acc: 49.845,73.646,74.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.568 | Acc: 49.832,73.528,74.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.562 | Acc: 49.723,73.576,74.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.554 | Acc: 49.898,73.714,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.553 | Acc: 49.896,73.571,74.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.546 | Acc: 50.035,73.678,74.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.530 | Acc: 50.198,73.837,74.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.535 | Acc: 50.123,73.745,74.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.537 | Acc: 50.168,73.668,74.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.542 | Acc: 50.114,73.588,74.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.552 | Acc: 50.135,73.461,74.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.556 | Acc: 50.124,73.367,74.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.559 | Acc: 50.119,73.355,74.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.555 | Acc: 50.184,73.409,74.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.552 | Acc: 50.164,73.468,74.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 52.344,67.188,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.622 | Acc: 46.243,63.914,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.670 | Acc: 45.312,62.729,64.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.702 | Acc: 45.095,62.551,64.434,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 3.670 | Acc: 52.344,76.562,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.374 | Acc: 51.525,74.628,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.437 | Acc: 50.762,74.200,75.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.418 | Acc: 50.986,74.539,75.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.457 | Acc: 50.704,74.334,75.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.465 | Acc: 50.859,74.296,75.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.461 | Acc: 50.956,74.341,75.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.480 | Acc: 50.803,74.346,75.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.472 | Acc: 51.004,74.495,75.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.488 | Acc: 50.885,74.296,75.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.489 | Acc: 50.657,74.265,75.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.513 | Acc: 50.502,73.957,74.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.520 | Acc: 50.428,73.849,74.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.525 | Acc: 50.386,73.898,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.516 | Acc: 50.637,74.030,74.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.525 | Acc: 50.431,73.918,74.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.522 | Acc: 50.460,73.917,74.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.527 | Acc: 50.408,73.887,74.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.530 | Acc: 50.372,73.844,74.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.528 | Acc: 50.433,73.794,74.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.434 | Acc: 51.562,67.969,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.491 | Acc: 46.391,64.546,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 46.075,63.186,65.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 45.722,62.718,65.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 3.805 | Acc: 48.438,73.438,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.421 | Acc: 50.558,75.707,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.473 | Acc: 50.152,74.562,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.431 | Acc: 50.615,75.090,75.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.449 | Acc: 50.463,75.000,75.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.476 | Acc: 50.317,74.613,75.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.472 | Acc: 50.471,74.400,75.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.483 | Acc: 50.576,74.324,75.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.487 | Acc: 50.461,74.112,75.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.490 | Acc: 50.354,74.020,75.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.484 | Acc: 50.443,74.102,75.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.492 | Acc: 50.382,73.985,75.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.496 | Acc: 50.451,73.914,75.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.505 | Acc: 50.485,73.791,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.507 | Acc: 50.498,73.779,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.506 | Acc: 50.615,73.770,75.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.505 | Acc: 50.628,73.822,75.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.518 | Acc: 50.518,73.685,75.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.519 | Acc: 50.541,73.745,75.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.527 | Acc: 50.451,73.692,75.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.622 | Acc: 54.688,64.062,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.650 | Acc: 46.168,64.286,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.694 | Acc: 45.884,63.053,64.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.720 | Acc: 45.453,62.641,63.922,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 3.389 | Acc: 49.219,78.125,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.445 | Acc: 51.042,75.298,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.436 | Acc: 51.200,75.095,75.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.467 | Acc: 50.666,74.577,75.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.465 | Acc: 50.907,74.238,75.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.464 | Acc: 50.843,74.373,75.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.481 | Acc: 50.723,74.387,75.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.481 | Acc: 50.587,74.490,75.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.493 | Acc: 50.432,74.340,75.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.490 | Acc: 50.445,74.366,75.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.502 | Acc: 50.319,74.215,74.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.511 | Acc: 50.339,74.088,74.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.513 | Acc: 50.434,74.073,74.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.515 | Acc: 50.470,74.012,74.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.518 | Acc: 50.481,73.941,74.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.513 | Acc: 50.514,74.037,74.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.517 | Acc: 50.496,74.000,74.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.519 | Acc: 50.536,73.948,74.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.521 | Acc: 50.496,73.851,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.517 | Acc: 50.453,73.899,74.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.333 | Acc: 55.469,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 46.168,64.211,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.600 | Acc: 45.655,62.862,65.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.635 | Acc: 45.005,62.513,64.562,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 3.713 | Acc: 53.906,71.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.369 | Acc: 51.525,75.186,76.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.449 | Acc: 50.819,74.162,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.483 | Acc: 50.307,74.308,75.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.497 | Acc: 50.367,74.055,75.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.492 | Acc: 50.201,73.917,75.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.507 | Acc: 50.271,73.760,75.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.499 | Acc: 50.404,73.859,75.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.493 | Acc: 50.461,73.981,75.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.494 | Acc: 50.483,74.033,75.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.492 | Acc: 50.443,74.118,75.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.497 | Acc: 50.392,74.084,75.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.494 | Acc: 50.438,74.121,75.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.504 | Acc: 50.332,74.051,75.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.506 | Acc: 50.370,74.038,75.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.508 | Acc: 50.275,73.990,75.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.515 | Acc: 50.253,73.868,75.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.511 | Acc: 50.307,73.893,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.510 | Acc: 50.227,73.831,75.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.512 | Acc: 50.295,73.813,75.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.718 | Acc: 50.000,62.500,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.707 | Acc: 45.796,62.946,64.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.715 | Acc: 45.427,62.348,64.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.758 | Acc: 44.915,61.949,64.319,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 3.643 | Acc: 50.000,75.781,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.537 | Acc: 49.405,73.958,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.517 | Acc: 50.229,73.914,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.444 | Acc: 50.692,74.641,76.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.457 | Acc: 50.685,74.527,75.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.464 | Acc: 50.766,74.497,75.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.465 | Acc: 50.943,74.348,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.472 | Acc: 50.759,74.324,75.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.481 | Acc: 50.500,74.248,75.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.486 | Acc: 50.583,74.150,75.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.487 | Acc: 50.498,74.157,75.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.498 | Acc: 50.357,74.106,75.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.492 | Acc: 50.444,74.138,75.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.498 | Acc: 50.407,74.084,75.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.498 | Acc: 50.506,74.030,75.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.498 | Acc: 50.532,74.019,75.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.502 | Acc: 50.548,74.012,75.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.502 | Acc: 50.605,73.955,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.501 | Acc: 50.658,73.976,75.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.499 | Acc: 50.673,73.967,75.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.593 | Acc: 47.656,64.062,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.656 | Acc: 45.424,63.504,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.675 | Acc: 45.141,62.995,64.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.710 | Acc: 44.941,62.564,64.588,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 3.634 | Acc: 44.531,72.656,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.500 | Acc: 49.144,73.772,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.548 | Acc: 49.219,73.495,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.517 | Acc: 50.000,74.142,75.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.487 | Acc: 50.251,74.286,75.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.481 | Acc: 50.217,74.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.472 | Acc: 50.291,74.509,75.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.489 | Acc: 50.150,74.252,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.492 | Acc: 50.087,74.165,75.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.485 | Acc: 50.263,74.262,75.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.498 | Acc: 50.163,74.079,75.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.490 | Acc: 50.201,74.229,75.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.486 | Acc: 50.230,74.245,75.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.486 | Acc: 50.317,74.174,75.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.493 | Acc: 50.359,74.119,75.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.499 | Acc: 50.298,74.133,75.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.502 | Acc: 50.331,74.090,75.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.500 | Acc: 50.449,74.116,75.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.502 | Acc: 50.400,74.069,75.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.502 | Acc: 50.361,74.114,75.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.472 | Acc: 54.688,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.545 | Acc: 46.615,64.881,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 46.894,63.853,65.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.609 | Acc: 46.247,63.230,65.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 3.389 | Acc: 55.469,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.508 | Acc: 49.814,72.991,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.456 | Acc: 50.362,73.838,75.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.435 | Acc: 50.961,74.091,75.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.441 | Acc: 50.965,74.074,75.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.460 | Acc: 50.588,73.963,75.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.462 | Acc: 50.588,73.986,75.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.461 | Acc: 50.504,74.152,75.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.452 | Acc: 50.451,74.267,75.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.463 | Acc: 50.440,74.145,75.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.466 | Acc: 50.501,74.075,75.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.468 | Acc: 50.672,73.982,75.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.481 | Acc: 50.541,73.820,75.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.490 | Acc: 50.395,73.794,75.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.490 | Acc: 50.478,73.849,75.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.486 | Acc: 50.470,73.855,75.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.483 | Acc: 50.467,73.878,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.481 | Acc: 50.575,73.882,75.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.476 | Acc: 50.612,73.953,75.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.476 | Acc: 50.558,73.938,75.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.757 | Acc: 50.781,63.281,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.079 | Acc: 42.150,61.682,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.073 | Acc: 41.749,61.185,63.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.103 | Acc: 41.803,61.142,63.204,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 3.445 | Acc: 53.125,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.416 | Acc: 50.744,74.814,76.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.460 | Acc: 50.362,73.819,76.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.455 | Acc: 50.512,73.911,76.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.450 | Acc: 50.550,74.007,75.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.440 | Acc: 50.735,74.041,76.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.448 | Acc: 50.659,74.051,75.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.434 | Acc: 50.765,74.230,76.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.425 | Acc: 50.830,74.374,76.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.425 | Acc: 50.941,74.331,76.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.434 | Acc: 50.906,74.262,76.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.429 | Acc: 50.901,74.321,76.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.430 | Acc: 50.882,74.326,76.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.432 | Acc: 50.901,74.297,76.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.442 | Acc: 50.829,74.238,76.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.453 | Acc: 50.638,74.180,75.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.461 | Acc: 50.652,74.102,75.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.460 | Acc: 50.710,74.125,75.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.466 | Acc: 50.671,74.119,75.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.470 | Acc: 50.584,74.094,75.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.638 | Acc: 50.000,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.630 | Acc: 47.210,63.690,65.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.662 | Acc: 46.570,63.243,65.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.709 | Acc: 45.671,62.654,64.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.685 | Acc: 57.812,81.250,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.445 | Acc: 50.818,73.996,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.453 | Acc: 50.000,74.200,75.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.444 | Acc: 50.307,74.219,75.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.470 | Acc: 50.125,74.113,75.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.476 | Acc: 50.054,74.033,75.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.493 | Acc: 50.039,74.135,75.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.496 | Acc: 50.139,74.008,75.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.483 | Acc: 50.238,74.122,75.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.483 | Acc: 50.401,74.029,75.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.480 | Acc: 50.470,74.063,75.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.489 | Acc: 50.276,74.091,75.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.486 | Acc: 50.383,74.096,75.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.477 | Acc: 50.404,74.171,75.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.472 | Acc: 50.361,74.216,75.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.466 | Acc: 50.558,74.310,75.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.468 | Acc: 50.552,74.323,75.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.467 | Acc: 50.538,74.267,75.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.458 | Acc: 50.634,74.370,75.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.455 | Acc: 50.689,74.428,75.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.524 | Acc: 51.562,68.750,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.670 | Acc: 45.610,63.765,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.707 | Acc: 44.931,62.386,65.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.741 | Acc: 44.903,62.141,64.639,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 2.993 | Acc: 60.938,79.688,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.386 | Acc: 51.190,75.298,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.415 | Acc: 50.781,74.924,76.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.428 | Acc: 50.589,74.898,76.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.434 | Acc: 50.405,74.392,75.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.451 | Acc: 50.309,74.358,75.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.452 | Acc: 50.504,74.245,75.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.460 | Acc: 50.754,74.080,75.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.462 | Acc: 50.733,74.015,75.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.460 | Acc: 50.872,74.029,75.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.464 | Acc: 50.766,73.974,75.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.457 | Acc: 50.841,74.081,75.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.451 | Acc: 50.872,74.167,75.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.446 | Acc: 50.874,74.324,75.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.446 | Acc: 50.834,74.363,75.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.447 | Acc: 50.836,74.369,75.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.450 | Acc: 50.820,74.319,75.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.447 | Acc: 50.788,74.315,75.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.447 | Acc: 50.805,74.323,75.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.450 | Acc: 50.779,74.200,75.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 50.000,67.188,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.615 | Acc: 46.391,64.323,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.684 | Acc: 45.389,62.767,64.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.725 | Acc: 45.056,62.065,63.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 3.052 | Acc: 53.906,78.125,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.416 | Acc: 50.149,73.400,76.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.439 | Acc: 49.447,73.095,75.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.389 | Acc: 50.077,74.103,76.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.414 | Acc: 49.807,74.122,76.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.411 | Acc: 49.892,74.219,76.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.407 | Acc: 50.232,74.367,76.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.404 | Acc: 50.471,74.535,76.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.394 | Acc: 50.776,74.728,76.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.406 | Acc: 50.609,74.676,76.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.414 | Acc: 50.735,74.689,76.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.413 | Acc: 50.757,74.745,76.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.418 | Acc: 50.716,74.689,76.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.418 | Acc: 50.668,74.620,76.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.424 | Acc: 50.631,74.566,76.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.425 | Acc: 50.722,74.556,76.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.434 | Acc: 50.713,74.472,76.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.440 | Acc: 50.648,74.379,75.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.440 | Acc: 50.701,74.394,75.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.444 | Acc: 50.730,74.332,75.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.243 | Acc: 52.344,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 46.280,64.509,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.563 | Acc: 46.227,63.072,65.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.614 | Acc: 45.710,62.346,64.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 3.974 | Acc: 46.875,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.440 | Acc: 50.484,74.256,76.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.405 | Acc: 50.724,75.000,76.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.399 | Acc: 50.320,74.872,76.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.413 | Acc: 50.135,74.614,76.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.414 | Acc: 50.387,74.466,76.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.411 | Acc: 50.536,74.567,76.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.421 | Acc: 50.565,74.418,76.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.436 | Acc: 50.801,74.199,76.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.432 | Acc: 50.850,74.262,76.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.433 | Acc: 50.805,74.227,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.441 | Acc: 50.799,74.183,76.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.445 | Acc: 50.788,74.134,76.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.448 | Acc: 50.700,74.096,76.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.449 | Acc: 50.784,74.133,76.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.449 | Acc: 50.802,74.180,76.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.452 | Acc: 50.730,74.168,76.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.452 | Acc: 50.703,74.210,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.447 | Acc: 50.716,74.260,76.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.452 | Acc: 50.679,74.184,76.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.455 | Acc: 50.781,69.531,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.607 | Acc: 46.577,63.876,66.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.641 | Acc: 46.380,62.824,64.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.696 | Acc: 45.594,62.282,64.588,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 3.682 | Acc: 46.875,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.406 | Acc: 51.860,74.219,76.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.336 | Acc: 51.886,75.362,77.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.345 | Acc: 51.562,75.525,77.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.359 | Acc: 51.321,75.367,76.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.394 | Acc: 50.696,75.093,76.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.407 | Acc: 50.691,74.877,76.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.420 | Acc: 50.598,74.684,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.420 | Acc: 50.650,74.651,76.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.420 | Acc: 50.630,74.646,76.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.427 | Acc: 50.556,74.537,76.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.423 | Acc: 50.696,74.417,76.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.423 | Acc: 50.681,74.536,76.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.426 | Acc: 50.733,74.605,76.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.418 | Acc: 50.773,74.725,76.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.425 | Acc: 50.732,74.600,76.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.429 | Acc: 50.706,74.596,76.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.426 | Acc: 50.777,74.535,76.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.430 | Acc: 50.714,74.450,76.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.432 | Acc: 50.650,74.366,76.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.732 | Acc: 48.438,64.062,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.712 | Acc: 45.312,64.062,64.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.730 | Acc: 45.198,62.862,64.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.761 | Acc: 44.698,62.282,63.858,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 3.637 | Acc: 46.094,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.403 | Acc: 50.372,75.335,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.395 | Acc: 50.210,75.343,77.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.386 | Acc: 50.897,75.487,77.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.417 | Acc: 50.637,75.010,76.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.420 | Acc: 50.688,75.000,76.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.413 | Acc: 50.652,74.877,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.416 | Acc: 50.604,74.950,76.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.410 | Acc: 50.597,74.908,76.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.409 | Acc: 50.600,74.927,76.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.419 | Acc: 50.622,74.701,76.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.422 | Acc: 50.548,74.671,76.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.431 | Acc: 50.535,74.595,76.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.431 | Acc: 50.527,74.596,76.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.434 | Acc: 50.528,74.572,76.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.435 | Acc: 50.613,74.530,76.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.437 | Acc: 50.550,74.421,76.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.437 | Acc: 50.550,74.457,76.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.434 | Acc: 50.595,74.517,76.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.424 | Acc: 50.691,74.594,76.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.696 | Acc: 50.000,61.719,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.854 | Acc: 44.048,61.756,64.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.877 | Acc: 44.112,61.223,63.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.896 | Acc: 43.660,61.066,63.140,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 3.455 | Acc: 53.906,81.250,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.348 | Acc: 50.707,75.298,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.353 | Acc: 50.915,75.724,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.321 | Acc: 51.114,76.178,77.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.317 | Acc: 51.061,76.061,77.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.344 | Acc: 50.673,75.789,77.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.360 | Acc: 50.374,75.336,77.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.380 | Acc: 50.432,74.956,76.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.378 | Acc: 50.495,74.893,76.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.385 | Acc: 50.630,74.918,76.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.397 | Acc: 50.536,74.837,76.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.390 | Acc: 50.679,74.908,76.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.403 | Acc: 50.525,74.799,76.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.407 | Acc: 50.593,74.740,76.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.407 | Acc: 50.578,74.825,76.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.413 | Acc: 50.535,74.720,76.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.412 | Acc: 50.587,74.774,76.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.416 | Acc: 50.566,74.663,76.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.415 | Acc: 50.597,74.639,76.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.418 | Acc: 50.572,74.627,76.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.302 | Acc: 54.688,66.406,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.718 | Acc: 46.503,62.835,64.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.747 | Acc: 45.293,61.795,64.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.797 | Acc: 44.915,61.296,63.794,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 3.390 | Acc: 52.344,77.344,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.339 | Acc: 50.484,75.298,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.361 | Acc: 49.924,75.553,76.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.341 | Acc: 50.269,75.666,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.356 | Acc: 50.318,75.280,76.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.350 | Acc: 50.781,75.364,76.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.344 | Acc: 50.962,75.452,76.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.355 | Acc: 51.092,75.404,76.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.368 | Acc: 51.155,75.301,76.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.374 | Acc: 50.911,75.237,76.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.374 | Acc: 50.968,75.210,76.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.371 | Acc: 51.032,75.240,76.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.376 | Acc: 50.982,75.227,76.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.378 | Acc: 51.018,75.224,76.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.397 | Acc: 50.879,75.003,76.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.386 | Acc: 50.966,75.047,76.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.384 | Acc: 50.959,75.034,76.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.391 | Acc: 50.827,74.977,76.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.393 | Acc: 50.885,74.970,76.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.405 | Acc: 50.816,74.785,76.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.486 | Acc: 50.781,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.646 | Acc: 45.685,64.881,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.698 | Acc: 45.255,63.319,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.747 | Acc: 44.813,62.577,64.114,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.863 | Acc: 52.344,78.125,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.210 | Acc: 51.860,76.711,78.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.289 | Acc: 51.658,75.762,77.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.311 | Acc: 51.767,75.525,77.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.321 | Acc: 51.505,75.569,77.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.326 | Acc: 51.114,75.580,77.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.337 | Acc: 51.317,75.355,77.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.352 | Acc: 51.092,75.255,77.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.357 | Acc: 50.912,75.238,77.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.366 | Acc: 50.950,75.043,77.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.364 | Acc: 50.941,75.004,77.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.373 | Acc: 50.820,74.951,77.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.386 | Acc: 50.794,74.880,77.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.379 | Acc: 50.865,74.925,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.383 | Acc: 50.801,74.861,76.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.387 | Acc: 50.740,74.826,76.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.385 | Acc: 50.820,74.781,76.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.392 | Acc: 50.790,74.787,76.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.395 | Acc: 50.792,74.758,76.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.404 | Acc: 50.695,74.686,76.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.438 | Acc: 45.312,65.625,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.742 | Acc: 43.899,63.393,65.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.791 | Acc: 43.559,62.176,64.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.841 | Acc: 43.327,61.885,63.717,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 3.518 | Acc: 46.875,75.781,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.315 | Acc: 51.079,76.116,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.303 | Acc: 51.410,76.258,78.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.335 | Acc: 51.025,75.871,77.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.349 | Acc: 50.916,75.521,77.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.345 | Acc: 51.083,75.402,77.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.357 | Acc: 50.956,75.220,77.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.353 | Acc: 50.931,75.211,77.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.349 | Acc: 50.907,75.257,77.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.355 | Acc: 50.911,75.168,77.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.365 | Acc: 50.843,75.058,77.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.369 | Acc: 50.799,74.929,77.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.369 | Acc: 50.781,74.925,77.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.375 | Acc: 50.736,74.877,77.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.371 | Acc: 50.837,74.889,77.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.376 | Acc: 50.698,74.881,76.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.383 | Acc: 50.662,74.706,76.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.385 | Acc: 50.715,74.638,76.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.387 | Acc: 50.736,74.665,76.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.384 | Acc: 50.769,74.678,76.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.738 | Acc: 49.219,64.844,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.728 | Acc: 45.833,63.281,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.744 | Acc: 45.503,62.462,64.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.790 | Acc: 45.133,61.821,63.704,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 3.441 | Acc: 50.000,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.303 | Acc: 52.158,75.967,78.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.365 | Acc: 51.239,75.152,78.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.352 | Acc: 51.230,74.936,78.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.348 | Acc: 51.138,75.193,78.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.345 | Acc: 51.292,75.379,78.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.342 | Acc: 51.479,75.149,77.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.339 | Acc: 51.330,75.233,77.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.350 | Acc: 51.233,75.053,77.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.352 | Acc: 51.213,75.004,77.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.358 | Acc: 51.170,74.942,77.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.360 | Acc: 51.099,75.018,77.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.362 | Acc: 50.914,74.948,77.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.367 | Acc: 50.889,74.850,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.370 | Acc: 50.909,74.839,77.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.375 | Acc: 50.875,74.709,77.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.377 | Acc: 50.830,74.713,77.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.382 | Acc: 50.816,74.663,77.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.384 | Acc: 50.840,74.710,77.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.387 | Acc: 50.804,74.715,77.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.414 | Acc: 52.344,67.188,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 46.615,63.579,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.657 | Acc: 46.227,63.110,64.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.702 | Acc: 45.556,62.269,64.767,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 3.513 | Acc: 53.906,75.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.199 | Acc: 52.344,76.823,79.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.295 | Acc: 51.562,75.896,78.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.317 | Acc: 51.409,75.884,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.335 | Acc: 51.003,75.743,77.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.359 | Acc: 50.890,75.511,77.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.375 | Acc: 50.420,75.226,77.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.369 | Acc: 50.659,75.166,77.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.368 | Acc: 50.563,75.136,77.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.388 | Acc: 50.440,74.970,77.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.385 | Acc: 50.606,74.883,77.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.391 | Acc: 50.615,74.710,77.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.390 | Acc: 50.655,74.715,76.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.387 | Acc: 50.751,74.853,77.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.381 | Acc: 50.628,75.033,77.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.376 | Acc: 50.670,75.049,77.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.377 | Acc: 50.684,75.022,77.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.380 | Acc: 50.731,74.975,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.383 | Acc: 50.762,74.965,77.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.384 | Acc: 50.824,74.961,77.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.595 | Acc: 49.219,65.625,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.816 | Acc: 44.680,63.653,64.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.819 | Acc: 44.303,62.710,64.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.864 | Acc: 43.929,62.001,64.088,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 3.135 | Acc: 53.906,74.219,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.353 | Acc: 50.781,73.772,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.402 | Acc: 50.495,73.742,75.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.390 | Acc: 50.333,74.206,76.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.380 | Acc: 50.521,74.614,76.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.390 | Acc: 50.394,74.489,76.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.378 | Acc: 50.581,74.561,76.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.365 | Acc: 50.626,74.623,76.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.366 | Acc: 50.607,74.636,76.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.372 | Acc: 50.552,74.698,76.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.363 | Acc: 50.579,74.852,76.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.373 | Acc: 50.520,74.714,76.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.381 | Acc: 50.464,74.770,76.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.384 | Acc: 50.443,74.710,76.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.388 | Acc: 50.487,74.694,76.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.394 | Acc: 50.439,74.608,76.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.397 | Acc: 50.402,74.504,76.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.393 | Acc: 50.479,74.537,76.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.391 | Acc: 50.584,74.578,76.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.393 | Acc: 50.521,74.518,76.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.644 | Acc: 46.094,64.844,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.845 | Acc: 44.382,62.909,64.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.848 | Acc: 44.627,62.195,63.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.908 | Acc: 43.993,61.629,62.871,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.928 | Acc: 57.031,78.906,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.277 | Acc: 52.418,76.079,78.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.284 | Acc: 51.353,76.181,78.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.287 | Acc: 51.819,76.191,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.279 | Acc: 51.948,75.868,77.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.293 | Acc: 51.717,75.735,77.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.292 | Acc: 51.801,75.678,77.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.313 | Acc: 51.635,75.355,77.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.315 | Acc: 51.485,75.412,77.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.323 | Acc: 51.463,75.298,77.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.329 | Acc: 51.430,75.307,77.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.347 | Acc: 51.209,75.106,77.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.349 | Acc: 51.063,75.078,77.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.348 | Acc: 51.060,75.090,77.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.354 | Acc: 51.076,74.967,77.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.357 | Acc: 50.999,74.912,77.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.365 | Acc: 50.947,74.861,77.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.368 | Acc: 50.887,74.814,77.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.370 | Acc: 50.820,74.775,77.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.370 | Acc: 50.830,74.791,77.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 50.000,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 46.726,64.472,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 46.570,63.548,64.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.670 | Acc: 45.889,62.820,64.203,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 3.702 | Acc: 47.656,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.415 | Acc: 49.591,74.368,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.416 | Acc: 49.676,74.581,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.416 | Acc: 49.705,74.718,77.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.387 | Acc: 50.000,74.990,77.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.371 | Acc: 50.665,75.186,77.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.372 | Acc: 50.620,75.032,77.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.369 | Acc: 50.853,75.133,77.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.371 | Acc: 50.645,75.053,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.366 | Acc: 50.634,75.142,77.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.372 | Acc: 50.579,75.043,77.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.363 | Acc: 50.728,75.124,77.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.359 | Acc: 50.840,75.097,77.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.364 | Acc: 50.838,75.072,77.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.355 | Acc: 50.948,75.167,77.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.360 | Acc: 50.999,75.104,77.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.358 | Acc: 50.981,75.156,77.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.367 | Acc: 50.891,75.064,77.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.367 | Acc: 50.985,75.061,77.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.370 | Acc: 50.978,75.008,77.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.703 | Acc: 51.562,63.281,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.781 | Acc: 46.057,62.723,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.844 | Acc: 45.332,61.509,63.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.861 | Acc: 44.813,61.347,62.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 3.302 | Acc: 46.094,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.375 | Acc: 52.158,75.186,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.398 | Acc: 51.010,75.286,76.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.370 | Acc: 50.794,75.115,77.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.343 | Acc: 50.984,75.588,77.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.351 | Acc: 50.696,75.534,77.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.356 | Acc: 50.426,75.600,77.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.351 | Acc: 50.388,75.560,77.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.352 | Acc: 50.485,75.446,77.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.351 | Acc: 50.665,75.470,77.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.352 | Acc: 50.618,75.393,77.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.358 | Acc: 50.573,75.368,77.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.357 | Acc: 50.574,75.383,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.360 | Acc: 50.596,75.323,77.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.351 | Acc: 50.737,75.384,77.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.349 | Acc: 50.776,75.335,77.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.351 | Acc: 50.835,75.270,77.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.354 | Acc: 50.884,75.229,77.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.358 | Acc: 50.842,75.184,77.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.359 | Acc: 50.841,75.158,77.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.718 | Acc: 50.000,64.062,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.840 | Acc: 45.424,62.426,64.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.866 | Acc: 44.207,61.490,63.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.910 | Acc: 44.249,61.181,63.409,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.892 | Acc: 59.375,80.469,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.306 | Acc: 51.488,75.446,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.263 | Acc: 52.115,76.162,78.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.281 | Acc: 51.870,75.756,78.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.296 | Acc: 51.678,75.810,78.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.294 | Acc: 51.524,75.928,78.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.312 | Acc: 51.072,75.684,78.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.322 | Acc: 50.947,75.571,77.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.326 | Acc: 51.019,75.480,77.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.323 | Acc: 50.988,75.548,77.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.328 | Acc: 50.902,75.466,77.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.327 | Acc: 51.004,75.460,77.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.339 | Acc: 50.943,75.324,77.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.343 | Acc: 50.910,75.275,77.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.348 | Acc: 50.904,75.197,77.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.352 | Acc: 50.895,75.187,77.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.357 | Acc: 50.971,75.173,77.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.357 | Acc: 51.033,75.170,77.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.360 | Acc: 51.013,75.108,77.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.363 | Acc: 51.058,75.031,77.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.631 | Acc: 50.781,63.281,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.677 | Acc: 45.982,63.430,64.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.690 | Acc: 46.037,63.072,64.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.742 | Acc: 45.748,62.474,63.730,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.894 | Acc: 57.031,82.812,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 50.670,75.298,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.248 | Acc: 50.819,76.410,78.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 50.307,76.114,78.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.283 | Acc: 50.666,75.984,78.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.288 | Acc: 50.758,76.122,78.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.296 | Acc: 50.581,75.988,78.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.304 | Acc: 50.554,75.748,78.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.301 | Acc: 50.723,75.893,78.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.305 | Acc: 50.768,75.811,78.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.308 | Acc: 50.828,75.789,78.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.313 | Acc: 50.901,75.711,77.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.309 | Acc: 51.002,75.781,77.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.316 | Acc: 51.051,75.599,77.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.322 | Acc: 51.073,75.559,77.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.328 | Acc: 51.108,75.475,77.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.337 | Acc: 50.988,75.285,77.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.334 | Acc: 51.063,75.318,77.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.339 | Acc: 51.045,75.197,77.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.343 | Acc: 51.007,75.172,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.665 | Acc: 51.562,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.741 | Acc: 45.759,63.504,64.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.767 | Acc: 45.332,62.748,63.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.808 | Acc: 44.826,62.538,63.371,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 3.528 | Acc: 51.562,76.562,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.384 | Acc: 51.414,74.368,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.336 | Acc: 51.220,74.848,78.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.344 | Acc: 51.460,75.179,77.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.320 | Acc: 51.630,75.299,78.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.325 | Acc: 51.307,75.224,78.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.331 | Acc: 51.207,75.129,78.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.316 | Acc: 51.369,75.338,78.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.306 | Acc: 51.558,75.519,78.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.308 | Acc: 51.739,75.401,78.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.326 | Acc: 51.590,75.148,77.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.335 | Acc: 51.456,75.057,77.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.340 | Acc: 51.280,75.000,77.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.338 | Acc: 51.266,75.000,77.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.335 | Acc: 51.312,75.070,77.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.332 | Acc: 51.370,75.101,77.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.337 | Acc: 51.385,75.032,77.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.337 | Acc: 51.404,75.034,77.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.333 | Acc: 51.381,75.078,77.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.338 | Acc: 51.341,75.043,77.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.620 | Acc: 50.000,64.062,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.705 | Acc: 46.317,63.244,64.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.737 | Acc: 45.198,62.538,63.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.788 | Acc: 44.621,61.988,63.794,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 2.940 | Acc: 57.812,78.125,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.209 | Acc: 51.525,77.604,79.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.293 | Acc: 50.152,76.524,78.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 50.768,76.050,78.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.309 | Acc: 50.820,75.588,77.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.300 | Acc: 51.052,75.619,78.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.278 | Acc: 51.246,75.749,78.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.284 | Acc: 51.324,75.704,78.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.282 | Acc: 51.218,75.752,78.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.293 | Acc: 51.014,75.540,78.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.301 | Acc: 50.913,75.501,78.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.305 | Acc: 50.870,75.530,78.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.317 | Acc: 50.788,75.421,78.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.316 | Acc: 50.766,75.503,78.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.315 | Acc: 50.784,75.467,78.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.317 | Acc: 50.784,75.436,77.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.315 | Acc: 50.796,75.426,78.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.321 | Acc: 50.797,75.357,77.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.328 | Acc: 50.825,75.296,77.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.338 | Acc: 50.730,75.162,77.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.476 | Acc: 49.219,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.895 | Acc: 44.866,60.938,63.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.927 | Acc: 44.741,60.347,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.979 | Acc: 43.788,59.939,62.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 3.677 | Acc: 48.438,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.312 | Acc: 49.926,75.074,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.271 | Acc: 51.200,75.934,78.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.269 | Acc: 51.140,75.679,78.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.310 | Acc: 50.550,75.376,78.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.295 | Acc: 50.781,75.565,78.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.281 | Acc: 50.988,75.600,78.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.292 | Acc: 50.986,75.576,78.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.299 | Acc: 50.878,75.519,78.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.307 | Acc: 50.937,75.501,78.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.312 | Acc: 50.944,75.428,78.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.313 | Acc: 50.997,75.357,78.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.311 | Acc: 51.015,75.486,78.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.319 | Acc: 50.877,75.416,78.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.317 | Acc: 50.862,75.523,78.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.327 | Acc: 50.760,75.363,78.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.332 | Acc: 50.696,75.302,77.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.337 | Acc: 50.580,75.231,77.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.340 | Acc: 50.591,75.214,77.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.340 | Acc: 50.681,75.277,77.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.744 | Acc: 50.781,66.406,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.806 | Acc: 46.540,63.095,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.807 | Acc: 45.732,62.348,62.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.848 | Acc: 45.351,62.116,62.679,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.964 | Acc: 53.125,78.125,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.284 | Acc: 50.037,75.409,78.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.345 | Acc: 50.152,75.248,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.374 | Acc: 49.577,74.590,77.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.335 | Acc: 50.145,75.260,77.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.323 | Acc: 50.480,75.364,78.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.318 | Acc: 50.801,75.355,78.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.326 | Acc: 50.726,75.211,78.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.316 | Acc: 50.772,75.306,78.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.321 | Acc: 50.699,75.194,78.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.320 | Acc: 50.758,75.276,78.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.322 | Acc: 50.714,75.286,78.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.319 | Acc: 50.726,75.240,78.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.318 | Acc: 50.748,75.219,78.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.331 | Acc: 50.703,75.139,77.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.326 | Acc: 50.831,75.195,78.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.323 | Acc: 50.944,75.200,77.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.327 | Acc: 50.985,75.149,77.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.333 | Acc: 50.905,75.039,77.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.335 | Acc: 50.855,75.033,77.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.468 | Acc: 50.000,63.281,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.800 | Acc: 45.722,62.500,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.814 | Acc: 45.027,61.376,63.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.867 | Acc: 44.429,61.078,63.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 3.539 | Acc: 50.781,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.361 | Acc: 49.926,75.446,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.312 | Acc: 51.162,75.152,77.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.279 | Acc: 51.242,75.653,78.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.278 | Acc: 51.370,75.666,78.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.278 | Acc: 51.122,75.704,78.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.275 | Acc: 51.233,75.575,78.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.272 | Acc: 51.197,75.637,78.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.278 | Acc: 51.160,75.539,78.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.279 | Acc: 51.066,75.488,78.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.295 | Acc: 50.921,75.358,78.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.306 | Acc: 50.806,75.315,78.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.320 | Acc: 50.577,75.152,77.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.331 | Acc: 50.479,75.009,77.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.335 | Acc: 50.442,75.017,77.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.327 | Acc: 50.514,75.034,77.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.332 | Acc: 50.589,74.961,77.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.328 | Acc: 50.685,75.000,77.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.329 | Acc: 50.647,75.030,77.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.326 | Acc: 50.650,75.125,77.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.767 | Acc: 48.438,63.281,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.900 | Acc: 44.829,62.351,63.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.916 | Acc: 44.379,61.681,63.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.956 | Acc: 44.416,61.424,62.820,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 3.273 | Acc: 55.469,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.235 | Acc: 50.818,75.372,78.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.239 | Acc: 51.048,75.572,78.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.223 | Acc: 51.153,76.127,79.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.254 | Acc: 50.916,75.907,78.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.245 | Acc: 50.959,76.067,78.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.244 | Acc: 51.040,76.027,78.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.249 | Acc: 51.125,75.986,78.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.254 | Acc: 51.179,75.990,78.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.271 | Acc: 51.027,75.820,78.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.276 | Acc: 51.069,75.669,78.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.279 | Acc: 50.983,75.753,78.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.286 | Acc: 50.927,75.700,78.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.290 | Acc: 50.862,75.775,78.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.298 | Acc: 50.742,75.737,78.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.306 | Acc: 50.659,75.670,78.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.306 | Acc: 50.699,75.647,78.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.312 | Acc: 50.605,75.570,77.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.320 | Acc: 50.545,75.489,77.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.323 | Acc: 50.537,75.449,77.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.838 | Acc: 44.531,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.869 | Acc: 44.606,62.202,64.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.897 | Acc: 44.912,61.166,63.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.936 | Acc: 44.506,61.245,63.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 3.537 | Acc: 51.562,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.234 | Acc: 51.190,75.298,79.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.253 | Acc: 50.991,75.610,79.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.248 | Acc: 51.025,75.704,78.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.233 | Acc: 51.244,76.109,79.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.241 | Acc: 50.928,76.153,79.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.226 | Acc: 51.227,76.311,79.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.226 | Acc: 51.269,76.191,79.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.232 | Acc: 51.334,76.140,79.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.252 | Acc: 51.157,75.738,78.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.248 | Acc: 51.143,75.840,78.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.254 | Acc: 51.039,75.767,78.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.265 | Acc: 50.956,75.600,78.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.274 | Acc: 51.018,75.551,78.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.283 | Acc: 51.012,75.531,78.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.287 | Acc: 50.971,75.514,78.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.289 | Acc: 50.954,75.409,78.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.288 | Acc: 51.001,75.399,78.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.299 | Acc: 50.907,75.368,78.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.306 | Acc: 50.828,75.299,78.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.574 | Acc: 51.562,64.844,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.673 | Acc: 46.615,64.472,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.696 | Acc: 46.684,62.824,64.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.745 | Acc: 45.991,62.423,64.319,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 3.146 | Acc: 46.875,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.202 | Acc: 50.967,76.414,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.166 | Acc: 51.677,77.115,80.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.185 | Acc: 52.139,76.895,79.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.216 | Acc: 51.524,76.514,79.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.242 | Acc: 51.416,76.137,79.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.255 | Acc: 51.711,75.956,79.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.261 | Acc: 51.707,75.765,79.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.248 | Acc: 51.849,75.835,79.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.251 | Acc: 51.761,75.855,79.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.261 | Acc: 51.535,75.770,79.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.254 | Acc: 51.608,75.781,79.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.252 | Acc: 51.666,75.820,79.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.253 | Acc: 51.709,75.757,78.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.261 | Acc: 51.551,75.706,78.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.271 | Acc: 51.376,75.600,78.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.279 | Acc: 51.326,75.462,78.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.290 | Acc: 51.164,75.369,78.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.292 | Acc: 51.043,75.374,78.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.297 | Acc: 51.048,75.344,78.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.605 | Acc: 54.688,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.704 | Acc: 46.429,62.240,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.740 | Acc: 45.903,61.662,63.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.806 | Acc: 44.941,61.463,63.730,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 3.020 | Acc: 52.344,82.812,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.190 | Acc: 52.158,77.232,79.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.193 | Acc: 51.467,76.715,79.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.240 | Acc: 51.255,75.973,78.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.248 | Acc: 51.321,75.907,78.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.247 | Acc: 51.230,75.928,79.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.268 | Acc: 51.330,75.575,78.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.275 | Acc: 51.341,75.576,78.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.273 | Acc: 51.368,75.553,78.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.278 | Acc: 51.178,75.634,78.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.278 | Acc: 51.209,75.715,78.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.279 | Acc: 51.188,75.707,78.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.283 | Acc: 51.067,75.707,78.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.286 | Acc: 51.060,75.635,78.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.289 | Acc: 51.043,75.678,78.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.296 | Acc: 50.942,75.626,78.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.294 | Acc: 50.905,75.640,78.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.294 | Acc: 50.857,75.557,78.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.297 | Acc: 50.863,75.532,78.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.296 | Acc: 50.878,75.523,78.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.668 | Acc: 46.094,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.881 | Acc: 45.275,63.281,63.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.943 | Acc: 44.760,61.681,62.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.000 | Acc: 44.275,61.219,62.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 3.137 | Acc: 53.125,79.688,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.087 | Acc: 52.902,77.902,80.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.146 | Acc: 52.439,76.982,80.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.183 | Acc: 51.614,76.703,79.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.223 | Acc: 50.849,76.717,79.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.211 | Acc: 50.913,76.864,79.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.224 | Acc: 51.007,76.472,79.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.233 | Acc: 50.981,76.380,79.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.237 | Acc: 51.097,76.364,79.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.241 | Acc: 51.036,76.342,79.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.234 | Acc: 51.139,76.314,79.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.239 | Acc: 51.223,76.304,79.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.246 | Acc: 51.186,76.268,79.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.254 | Acc: 51.116,76.161,79.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.257 | Acc: 51.145,76.101,78.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.261 | Acc: 51.176,75.999,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.267 | Acc: 51.185,75.930,78.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.269 | Acc: 51.113,75.907,78.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.275 | Acc: 51.123,75.807,78.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.281 | Acc: 51.130,75.730,78.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.719 | Acc: 52.344,64.844,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.690 | Acc: 45.796,63.318,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.741 | Acc: 45.198,61.814,63.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.799 | Acc: 44.608,61.732,63.486,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 3.713 | Acc: 46.875,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.197 | Acc: 50.446,76.674,79.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.194 | Acc: 50.991,76.258,79.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.222 | Acc: 50.999,76.358,79.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.214 | Acc: 51.244,76.437,79.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.217 | Acc: 51.539,76.338,79.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.235 | Acc: 51.395,76.188,79.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.248 | Acc: 51.402,76.025,79.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.251 | Acc: 51.349,75.898,79.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.260 | Acc: 51.243,75.751,78.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.266 | Acc: 51.248,75.684,78.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.268 | Acc: 51.227,75.541,78.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.281 | Acc: 51.070,75.434,78.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.281 | Acc: 51.051,75.443,78.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.288 | Acc: 50.968,75.417,78.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.291 | Acc: 50.955,75.446,78.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.292 | Acc: 50.964,75.470,78.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.297 | Acc: 50.845,75.431,78.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.299 | Acc: 50.812,75.403,78.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.301 | Acc: 50.843,75.422,78.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.576 | Acc: 50.781,64.062,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.778 | Acc: 44.717,62.202,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.827 | Acc: 44.646,61.395,64.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.883 | Acc: 44.403,61.437,63.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.734 | Acc: 49.219,83.594,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.224 | Acc: 50.967,76.042,78.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.244 | Acc: 51.162,76.181,79.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.240 | Acc: 50.999,76.178,79.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.246 | Acc: 50.752,76.080,79.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.265 | Acc: 50.596,75.851,79.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.268 | Acc: 50.581,75.936,79.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.263 | Acc: 50.626,75.864,79.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.260 | Acc: 50.738,75.873,79.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.265 | Acc: 50.760,75.898,79.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.266 | Acc: 50.641,75.824,79.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.268 | Acc: 50.728,75.806,79.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.273 | Acc: 50.616,75.755,79.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.276 | Acc: 50.724,75.617,78.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.281 | Acc: 50.745,75.559,78.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.280 | Acc: 50.812,75.587,78.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.288 | Acc: 50.754,75.516,78.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.287 | Acc: 50.777,75.541,78.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.290 | Acc: 50.725,75.541,78.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.290 | Acc: 50.740,75.574,78.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.737 | Acc: 50.781,66.406,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.770 | Acc: 45.387,63.132,64.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.775 | Acc: 45.617,62.233,63.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.842 | Acc: 44.851,61.847,62.948,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 3.082 | Acc: 57.812,82.031,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.210 | Acc: 52.009,76.823,79.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.280 | Acc: 51.200,75.724,78.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.273 | Acc: 51.268,75.845,78.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.257 | Acc: 51.119,76.051,78.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.262 | Acc: 51.230,75.828,78.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.261 | Acc: 51.027,75.852,78.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.255 | Acc: 51.036,75.992,78.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.261 | Acc: 50.985,76.024,78.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.252 | Acc: 51.209,76.161,79.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.249 | Acc: 51.259,76.178,79.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.256 | Acc: 51.181,76.152,78.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.262 | Acc: 51.099,76.079,78.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.259 | Acc: 51.128,76.030,78.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.269 | Acc: 51.065,75.862,78.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.267 | Acc: 51.041,75.955,78.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.266 | Acc: 51.029,75.879,78.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.267 | Acc: 51.052,75.914,78.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.270 | Acc: 51.073,75.892,78.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.272 | Acc: 51.066,75.804,78.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.714 | Acc: 44.531,64.062,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.086 | Acc: 44.122,60.714,63.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.111 | Acc: 43.636,60.194,62.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.160 | Acc: 43.507,60.054,62.615,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 3.360 | Acc: 50.000,76.562,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.198 | Acc: 50.298,76.786,80.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.215 | Acc: 50.743,76.143,80.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.210 | Acc: 50.794,75.961,80.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.206 | Acc: 51.032,76.321,80.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.213 | Acc: 51.269,76.354,80.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.214 | Acc: 51.427,76.382,80.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.217 | Acc: 51.568,76.280,80.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.225 | Acc: 51.451,76.271,79.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.229 | Acc: 51.368,76.213,79.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.232 | Acc: 51.403,76.267,79.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.240 | Acc: 51.301,76.220,79.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.234 | Acc: 51.313,76.306,79.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.244 | Acc: 51.233,76.119,79.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.247 | Acc: 51.184,76.051,79.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.250 | Acc: 51.176,75.981,79.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.253 | Acc: 51.134,75.969,79.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.265 | Acc: 51.065,75.839,79.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.268 | Acc: 51.063,75.788,79.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.266 | Acc: 51.095,75.802,79.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.712 | Acc: 50.781,64.062,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.910 | Acc: 45.312,62.314,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.918 | Acc: 44.855,61.357,62.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.979 | Acc: 43.942,61.053,62.052,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 3.100 | Acc: 54.688,82.031,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.109 | Acc: 51.860,78.237,80.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.173 | Acc: 51.315,77.134,80.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.207 | Acc: 51.358,76.934,80.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.209 | Acc: 51.543,76.852,80.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.208 | Acc: 51.702,76.586,79.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.194 | Acc: 51.892,76.653,79.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.199 | Acc: 51.607,76.546,80.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.206 | Acc: 51.524,76.514,79.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.218 | Acc: 51.398,76.299,79.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.227 | Acc: 51.283,76.236,79.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.235 | Acc: 51.347,76.131,79.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.245 | Acc: 51.229,76.070,79.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.247 | Acc: 51.230,76.003,79.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.247 | Acc: 51.170,76.009,79.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.249 | Acc: 51.176,75.958,79.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.254 | Acc: 51.219,75.956,79.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.266 | Acc: 51.127,75.827,79.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.265 | Acc: 51.216,75.846,79.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.264 | Acc: 51.232,75.820,79.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.612 | Acc: 48.438,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.753 | Acc: 45.833,61.682,65.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.799 | Acc: 45.846,61.185,63.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.864 | Acc: 45.492,60.950,63.525,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 3.270 | Acc: 50.781,78.906,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.304 | Acc: 50.893,75.037,79.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.254 | Acc: 51.067,75.495,80.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.263 | Acc: 50.666,75.628,79.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.235 | Acc: 50.704,76.138,79.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.264 | Acc: 50.410,75.851,79.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.273 | Acc: 50.194,75.613,79.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.274 | Acc: 50.133,75.626,79.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.265 | Acc: 50.223,75.733,79.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.262 | Acc: 50.328,75.734,79.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.268 | Acc: 50.439,75.715,79.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.273 | Acc: 50.488,75.703,79.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.267 | Acc: 50.509,75.713,79.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.257 | Acc: 50.641,75.904,79.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.266 | Acc: 50.623,75.848,79.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.268 | Acc: 50.589,75.901,79.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.269 | Acc: 50.582,75.881,79.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.263 | Acc: 50.726,75.907,79.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.262 | Acc: 50.757,75.913,79.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.266 | Acc: 50.785,75.867,79.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.673 | Acc: 51.562,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.817 | Acc: 46.057,62.760,64.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.834 | Acc: 45.312,61.623,63.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.890 | Acc: 44.864,61.091,63.204,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 3.473 | Acc: 46.875,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.246 | Acc: 50.744,75.781,79.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.257 | Acc: 50.705,75.514,79.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.228 | Acc: 51.178,75.973,79.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.234 | Acc: 51.514,75.965,79.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.219 | Acc: 51.477,76.222,79.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.216 | Acc: 51.543,76.207,79.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.224 | Acc: 51.452,76.180,79.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.232 | Acc: 51.412,76.087,79.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.244 | Acc: 51.157,75.993,79.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.238 | Acc: 51.209,76.061,79.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.231 | Acc: 51.361,76.188,79.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.238 | Acc: 51.157,76.109,79.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.246 | Acc: 51.105,76.024,79.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.249 | Acc: 51.070,76.056,79.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.242 | Acc: 51.119,76.155,79.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.246 | Acc: 51.051,76.093,79.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.252 | Acc: 51.045,76.070,79.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.254 | Acc: 50.976,76.032,79.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.255 | Acc: 50.953,76.009,79.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.778 | Acc: 46.094,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.794 | Acc: 45.089,62.686,63.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.822 | Acc: 44.474,61.719,63.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.899 | Acc: 44.198,61.258,62.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 3.569 | Acc: 43.750,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.230 | Acc: 49.628,77.195,80.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.201 | Acc: 50.629,76.753,80.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.200 | Acc: 51.063,76.537,80.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.188 | Acc: 51.331,76.871,80.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.190 | Acc: 50.843,76.748,80.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.232 | Acc: 50.523,76.330,79.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.234 | Acc: 50.687,76.291,79.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.231 | Acc: 50.587,76.441,79.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.230 | Acc: 50.622,76.291,79.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.231 | Acc: 50.711,76.290,79.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.235 | Acc: 50.658,76.258,79.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.239 | Acc: 50.655,76.280,79.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.246 | Acc: 50.706,76.218,79.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.252 | Acc: 50.701,76.193,79.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.246 | Acc: 50.794,76.199,79.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.247 | Acc: 50.849,76.205,79.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.254 | Acc: 50.825,76.068,79.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.254 | Acc: 50.833,76.019,79.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.258 | Acc: 50.771,75.931,79.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.872 | Acc: 53.125,65.625,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.861 | Acc: 45.424,62.500,63.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.847 | Acc: 45.960,61.833,63.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.918 | Acc: 45.095,61.552,63.153,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.747 | Acc: 50.781,79.688,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.176 | Acc: 51.079,77.269,80.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.259 | Acc: 49.848,76.448,80.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.247 | Acc: 50.141,76.217,80.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.263 | Acc: 50.299,75.868,79.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.234 | Acc: 50.835,76.029,80.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.229 | Acc: 51.085,76.078,80.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.248 | Acc: 51.025,75.887,79.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.243 | Acc: 51.121,75.985,79.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.249 | Acc: 51.062,75.911,79.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.264 | Acc: 50.902,75.781,79.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.264 | Acc: 50.841,75.774,79.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.263 | Acc: 50.895,75.836,79.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.266 | Acc: 50.814,75.748,79.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.266 | Acc: 50.698,75.731,79.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.265 | Acc: 50.862,75.740,79.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.271 | Acc: 50.864,75.613,79.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.276 | Acc: 50.848,75.557,79.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.271 | Acc: 50.863,75.636,79.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.271 | Acc: 50.839,75.632,79.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.630 | Acc: 47.656,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.631 | Acc: 46.391,64.397,66.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.683 | Acc: 45.541,62.881,64.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.732 | Acc: 45.402,62.538,64.191,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 3.686 | Acc: 50.000,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.251 | Acc: 50.595,76.153,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.188 | Acc: 51.486,76.410,79.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.166 | Acc: 51.524,76.345,80.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.173 | Acc: 51.350,76.476,80.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.198 | Acc: 50.897,76.245,80.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.199 | Acc: 50.904,76.201,80.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.204 | Acc: 50.682,76.175,80.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.219 | Acc: 50.563,75.990,80.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.216 | Acc: 50.786,76.105,80.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.217 | Acc: 50.976,76.088,80.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.224 | Acc: 51.071,76.018,80.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.229 | Acc: 51.015,75.927,79.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.236 | Acc: 51.003,75.802,79.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.233 | Acc: 50.909,75.909,79.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.231 | Acc: 50.966,75.968,79.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.234 | Acc: 51.010,75.901,79.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.236 | Acc: 50.958,75.882,79.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.238 | Acc: 50.995,75.883,79.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.237 | Acc: 50.990,75.876,79.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.469 | Acc: 47.656,67.188,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.838 | Acc: 44.717,62.798,64.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.834 | Acc: 44.970,61.909,63.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.890 | Acc: 44.659,61.475,62.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 3.272 | Acc: 49.219,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.271 | Acc: 51.339,75.260,79.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.255 | Acc: 51.620,75.553,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.245 | Acc: 51.165,75.551,79.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.210 | Acc: 51.572,75.965,80.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.215 | Acc: 51.354,76.176,80.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.203 | Acc: 51.375,76.253,80.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.202 | Acc: 51.485,76.280,80.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.221 | Acc: 51.169,76.155,79.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.216 | Acc: 51.325,76.269,79.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.221 | Acc: 51.318,76.178,79.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.221 | Acc: 51.403,76.202,79.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.220 | Acc: 51.374,76.154,79.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.221 | Acc: 51.317,76.152,79.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.225 | Acc: 51.354,76.084,79.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.222 | Acc: 51.412,76.088,79.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.230 | Acc: 51.402,75.978,79.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.232 | Acc: 51.324,75.939,79.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.240 | Acc: 51.301,75.900,79.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.242 | Acc: 51.300,75.882,79.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.913 | Acc: 46.094,62.500,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.877 | Acc: 44.420,62.351,64.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.922 | Acc: 44.150,60.671,63.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.970 | Acc: 43.942,60.297,62.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.948 | Acc: 53.906,80.469,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.156 | Acc: 52.716,77.046,80.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.132 | Acc: 52.744,77.153,81.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.092 | Acc: 52.485,77.830,81.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.112 | Acc: 52.218,77.595,81.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.086 | Acc: 52.351,77.924,81.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.080 | Acc: 52.137,77.899,81.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.067 | Acc: 52.161,78.059,81.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.060 | Acc: 52.237,78.062,82.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.059 | Acc: 52.279,78.043,82.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.057 | Acc: 52.359,78.113,82.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.061 | Acc: 52.319,78.174,82.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.056 | Acc: 52.331,78.229,82.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.048 | Acc: 52.386,78.320,82.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.050 | Acc: 52.227,78.397,82.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.045 | Acc: 52.266,78.488,82.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.050 | Acc: 52.271,78.383,82.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.048 | Acc: 52.291,78.416,82.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.047 | Acc: 52.244,78.402,82.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.042 | Acc: 52.196,78.441,82.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.355 | Acc: 54.688,67.969,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.464 | Acc: 47.470,65.067,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.491 | Acc: 47.256,64.234,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.553 | Acc: 46.491,63.947,65.894,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.521 | Acc: 48.438,82.812,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 51.228,79.501,84.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.972 | Acc: 51.296,79.249,84.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.969 | Acc: 51.627,79.188,83.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.957 | Acc: 51.813,79.292,83.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.963 | Acc: 52.081,79.254,83.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.975 | Acc: 52.021,79.236,83.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.966 | Acc: 52.178,79.183,83.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.950 | Acc: 52.436,79.353,83.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.965 | Acc: 52.106,79.230,83.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.961 | Acc: 52.247,79.186,83.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.969 | Acc: 52.167,79.087,83.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.972 | Acc: 52.165,79.101,83.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.971 | Acc: 52.113,79.098,83.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.974 | Acc: 52.169,79.115,83.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.968 | Acc: 52.214,79.187,83.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.972 | Acc: 52.244,79.137,83.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.974 | Acc: 52.220,79.094,83.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.971 | Acc: 52.246,79.088,83.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.969 | Acc: 52.268,79.181,83.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 56.250,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.448 | Acc: 47.656,65.588,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.485 | Acc: 47.104,64.253,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 46.709,63.909,66.355,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 3.113 | Acc: 50.781,75.000,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.926 | Acc: 51.004,79.167,84.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 52.515,79.497,84.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.899 | Acc: 52.741,80.033,84.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.921 | Acc: 52.344,79.726,84.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.933 | Acc: 52.336,79.657,84.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.947 | Acc: 52.189,79.416,83.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.920 | Acc: 52.521,79.671,84.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.919 | Acc: 52.475,79.712,84.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.924 | Acc: 52.486,79.722,84.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.925 | Acc: 52.554,79.645,84.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.925 | Acc: 52.605,79.680,84.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.927 | Acc: 52.538,79.649,84.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.930 | Acc: 52.559,79.589,84.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.938 | Acc: 52.472,79.512,84.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.943 | Acc: 52.458,79.441,84.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.942 | Acc: 52.368,79.449,84.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.944 | Acc: 52.399,79.413,84.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.945 | Acc: 52.419,79.434,84.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.950 | Acc: 52.336,79.409,84.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.372 | Acc: 56.250,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 47.842,65.476,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.510 | Acc: 47.332,64.101,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 46.824,63.845,65.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.694 | Acc: 59.375,82.031,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 52.567,79.129,83.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.969 | Acc: 52.649,78.544,83.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.939 | Acc: 52.882,78.932,83.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.952 | Acc: 52.517,78.810,83.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.919 | Acc: 52.986,79.169,84.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.902 | Acc: 52.725,79.390,84.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.901 | Acc: 52.682,79.350,84.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.901 | Acc: 52.844,79.319,84.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.913 | Acc: 52.698,79.226,84.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.915 | Acc: 52.639,79.186,84.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.915 | Acc: 52.627,79.246,84.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.922 | Acc: 52.483,79.198,84.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.922 | Acc: 52.640,79.200,84.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.921 | Acc: 52.691,79.276,84.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.928 | Acc: 52.642,79.187,84.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.931 | Acc: 52.585,79.133,84.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.932 | Acc: 52.658,79.092,84.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.930 | Acc: 52.645,79.153,84.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.930 | Acc: 52.694,79.126,84.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.428 | Acc: 55.469,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.462 | Acc: 47.768,65.737,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.487 | Acc: 47.351,64.520,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 46.734,64.050,66.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 2.906 | Acc: 57.031,80.469,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.957 | Acc: 51.339,79.688,84.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.946 | Acc: 51.696,79.707,84.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.956 | Acc: 52.254,79.380,84.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.948 | Acc: 52.305,79.668,84.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.930 | Acc: 52.367,79.773,84.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.947 | Acc: 52.344,79.552,84.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.938 | Acc: 52.394,79.577,84.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.933 | Acc: 52.509,79.746,84.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.936 | Acc: 52.499,79.675,84.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.930 | Acc: 52.604,79.653,84.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.928 | Acc: 52.648,79.642,84.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.935 | Acc: 52.451,79.610,84.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.931 | Acc: 52.496,79.708,84.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.930 | Acc: 52.441,79.743,84.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.922 | Acc: 52.570,79.765,84.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.916 | Acc: 52.594,79.829,84.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.923 | Acc: 52.545,79.724,84.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.928 | Acc: 52.456,79.703,84.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.930 | Acc: 52.432,79.659,84.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.416 | Acc: 54.688,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.493 | Acc: 47.693,65.476,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.510 | Acc: 47.180,64.310,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.570 | Acc: 46.811,63.998,66.035,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.347 | Acc: 50.781,86.719,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.926 | Acc: 52.381,80.394,85.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.956 | Acc: 52.153,79.592,85.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.932 | Acc: 52.523,79.483,85.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.916 | Acc: 52.720,79.851,84.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.919 | Acc: 52.560,79.718,84.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.922 | Acc: 52.712,79.675,84.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.926 | Acc: 52.693,79.671,84.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.926 | Acc: 52.800,79.649,84.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.921 | Acc: 52.862,79.778,84.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.918 | Acc: 52.876,79.804,84.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.913 | Acc: 53.012,79.811,84.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.911 | Acc: 52.943,79.772,84.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.901 | Acc: 53.065,79.819,84.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.905 | Acc: 52.903,79.815,84.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.910 | Acc: 52.881,79.828,84.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.916 | Acc: 52.894,79.717,84.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.916 | Acc: 52.912,79.706,84.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.919 | Acc: 52.809,79.664,84.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.921 | Acc: 52.756,79.685,84.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.340 | Acc: 57.031,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.468 | Acc: 47.545,65.327,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.503 | Acc: 47.085,64.043,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.562 | Acc: 46.683,63.768,65.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 3.315 | Acc: 49.219,75.000,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.998 | Acc: 52.716,78.534,83.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.938 | Acc: 52.896,79.116,84.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.910 | Acc: 52.997,79.675,84.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.899 | Acc: 53.086,79.794,84.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.903 | Acc: 52.939,79.680,84.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.905 | Acc: 52.789,79.707,84.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.914 | Acc: 52.554,79.582,84.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.907 | Acc: 52.557,79.537,84.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.902 | Acc: 52.585,79.618,84.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.905 | Acc: 52.511,79.583,84.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.900 | Acc: 52.605,79.673,84.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.894 | Acc: 52.710,79.772,84.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.893 | Acc: 52.712,79.765,84.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.895 | Acc: 52.627,79.749,84.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.893 | Acc: 52.702,79.745,84.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.897 | Acc: 52.728,79.646,84.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.903 | Acc: 52.598,79.598,84.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.903 | Acc: 52.539,79.627,84.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.906 | Acc: 52.479,79.581,84.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.459 | Acc: 54.688,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.527 | Acc: 47.619,64.658,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.540 | Acc: 46.989,63.586,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 46.644,63.576,66.035,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 3.076 | Acc: 51.562,80.469,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.853 | Acc: 53.013,80.729,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.850 | Acc: 53.468,81.040,86.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.871 | Acc: 53.125,80.610,85.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.877 | Acc: 53.067,80.324,85.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.894 | Acc: 52.901,80.152,85.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.883 | Acc: 52.686,80.185,85.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.890 | Acc: 52.721,80.092,85.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.901 | Acc: 52.528,79.950,85.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.905 | Acc: 52.560,79.856,85.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.893 | Acc: 52.775,79.913,85.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.896 | Acc: 52.634,79.924,85.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.893 | Acc: 52.652,79.927,84.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.892 | Acc: 52.661,79.966,84.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.898 | Acc: 52.625,79.896,84.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.896 | Acc: 52.647,79.911,84.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.900 | Acc: 52.563,79.863,84.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.899 | Acc: 52.630,79.907,84.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.902 | Acc: 52.621,79.889,84.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.904 | Acc: 52.549,79.849,84.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.440 | Acc: 54.688,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.492 | Acc: 47.954,65.439,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.513 | Acc: 47.389,64.310,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 46.939,63.986,66.060,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.689 | Acc: 57.812,80.469,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.943 | Acc: 52.195,79.836,83.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.913 | Acc: 53.296,79.840,84.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.928 | Acc: 52.702,79.611,83.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.921 | Acc: 52.344,79.601,84.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.930 | Acc: 52.406,79.432,84.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.930 | Acc: 52.357,79.487,84.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.915 | Acc: 52.316,79.610,84.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.913 | Acc: 52.470,79.590,84.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.916 | Acc: 52.417,79.567,84.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.908 | Acc: 52.534,79.668,84.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.905 | Acc: 52.471,79.765,84.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.896 | Acc: 52.516,79.817,84.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.890 | Acc: 52.568,79.954,84.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 52.602,79.960,84.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.899 | Acc: 52.551,79.856,84.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.904 | Acc: 52.482,79.763,84.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.904 | Acc: 52.557,79.770,84.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.906 | Acc: 52.536,79.713,84.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.905 | Acc: 52.571,79.683,84.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 56.250,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 47.805,65.030,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.516 | Acc: 47.447,64.101,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 46.888,63.858,65.881,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.949 | Acc: 56.250,78.906,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.876 | Acc: 54.278,80.357,85.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.850 | Acc: 54.268,80.354,85.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.860 | Acc: 53.919,80.738,85.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.842 | Acc: 53.897,80.874,85.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.860 | Acc: 53.527,80.461,85.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.874 | Acc: 53.196,80.282,85.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.880 | Acc: 53.020,80.158,85.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.875 | Acc: 53.149,80.158,85.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.877 | Acc: 53.194,80.175,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.884 | Acc: 53.067,80.084,85.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.878 | Acc: 53.129,80.140,85.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.883 | Acc: 53.106,80.080,85.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.889 | Acc: 53.080,79.954,85.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.895 | Acc: 53.022,79.832,84.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 53.013,79.856,84.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.897 | Acc: 52.925,79.855,84.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.896 | Acc: 52.884,79.859,85.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.894 | Acc: 52.924,79.811,85.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.891 | Acc: 52.910,79.876,85.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.434 | Acc: 54.688,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.485 | Acc: 48.214,65.141,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.518 | Acc: 47.599,64.082,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 46.875,63.998,66.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.873 | Acc: 55.469,75.781,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.973 | Acc: 50.818,79.018,85.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.936 | Acc: 51.543,79.211,85.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.883 | Acc: 52.216,79.790,85.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.922 | Acc: 51.861,79.581,85.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.918 | Acc: 52.065,79.649,85.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.896 | Acc: 52.202,79.868,85.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.907 | Acc: 52.067,79.815,85.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.908 | Acc: 52.067,79.707,85.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.903 | Acc: 52.102,79.722,85.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.891 | Acc: 52.231,79.886,85.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 52.262,79.850,85.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.898 | Acc: 52.334,79.846,84.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.892 | Acc: 52.446,79.897,84.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 52.394,79.882,85.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.892 | Acc: 52.375,79.942,85.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.895 | Acc: 52.349,79.907,85.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.891 | Acc: 52.408,79.956,85.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.890 | Acc: 52.491,79.960,85.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.889 | Acc: 52.534,79.983,85.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.486 | Acc: 52.344,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 46.912,65.476,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.515 | Acc: 46.646,64.329,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 46.209,64.127,65.958,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.904 | Acc: 57.031,82.031,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.820 | Acc: 54.836,80.320,85.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 53.373,79.364,85.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.899 | Acc: 52.741,79.905,85.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.900 | Acc: 52.768,79.890,85.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.875 | Acc: 53.032,80.097,85.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.883 | Acc: 53.035,79.888,85.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.887 | Acc: 52.687,79.898,85.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.884 | Acc: 52.771,80.071,85.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.876 | Acc: 52.814,80.059,85.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.875 | Acc: 52.830,80.204,85.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.879 | Acc: 52.718,80.221,85.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.881 | Acc: 52.768,80.203,85.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.888 | Acc: 52.706,80.080,85.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.892 | Acc: 52.677,79.974,85.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.897 | Acc: 52.624,79.877,84.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.891 | Acc: 52.748,79.936,85.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 52.658,79.985,85.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.891 | Acc: 52.601,79.934,84.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.887 | Acc: 52.672,79.981,84.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 53.906,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.522 | Acc: 47.247,65.737,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 46.856,64.291,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 46.670,64.101,66.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.880 | Acc: 54.688,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.899 | Acc: 53.981,79.613,85.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.907 | Acc: 53.182,79.345,85.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.883 | Acc: 53.381,79.713,85.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.901 | Acc: 53.038,79.851,85.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.897 | Acc: 53.086,79.742,85.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.902 | Acc: 52.673,79.765,84.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.908 | Acc: 52.405,79.566,84.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.911 | Acc: 52.261,79.605,84.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.902 | Acc: 52.357,79.744,84.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.890 | Acc: 52.573,79.948,85.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 52.612,79.871,85.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.903 | Acc: 52.564,79.759,84.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.899 | Acc: 52.541,79.780,84.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.899 | Acc: 52.544,79.799,84.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.898 | Acc: 52.614,79.841,84.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.892 | Acc: 52.687,79.904,85.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.896 | Acc: 52.671,79.839,85.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.896 | Acc: 52.655,79.807,85.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.895 | Acc: 52.696,79.782,85.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.459 | Acc: 56.250,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 47.470,65.104,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.548 | Acc: 47.085,63.853,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 46.580,63.704,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.722 | Acc: 51.562,85.938,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.816 | Acc: 53.981,80.692,85.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.831 | Acc: 53.639,80.793,85.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.838 | Acc: 53.407,80.315,86.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.852 | Acc: 53.221,80.372,86.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.858 | Acc: 53.055,80.252,85.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.860 | Acc: 52.796,80.294,85.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.871 | Acc: 52.948,80.109,85.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.886 | Acc: 52.824,80.017,85.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.882 | Acc: 52.819,80.011,85.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.881 | Acc: 52.935,79.967,85.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.879 | Acc: 52.938,80.002,85.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.875 | Acc: 52.930,79.999,85.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.869 | Acc: 52.996,79.993,85.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.874 | Acc: 53.028,80.035,85.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.872 | Acc: 52.915,80.147,85.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.867 | Acc: 52.974,80.123,85.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.871 | Acc: 52.859,80.047,85.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.872 | Acc: 52.831,80.060,85.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.873 | Acc: 52.803,80.079,85.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.432 | Acc: 53.906,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.521 | Acc: 47.061,65.513,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 46.742,64.139,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 46.465,64.127,66.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 3.169 | Acc: 47.656,72.656,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.850 | Acc: 54.092,80.320,85.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.875 | Acc: 53.163,80.088,85.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.891 | Acc: 52.818,80.008,85.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.881 | Acc: 52.894,80.228,85.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.877 | Acc: 53.311,80.190,85.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.864 | Acc: 53.338,80.249,85.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.868 | Acc: 53.086,80.170,85.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 53.275,80.250,85.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.857 | Acc: 53.319,80.262,85.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.862 | Acc: 53.242,80.259,85.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.860 | Acc: 53.220,80.264,85.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.865 | Acc: 52.989,80.284,85.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.868 | Acc: 52.951,80.283,85.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.871 | Acc: 52.950,80.241,85.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 53.024,80.261,85.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.872 | Acc: 52.925,80.155,85.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.874 | Acc: 52.829,80.123,85.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.877 | Acc: 52.761,80.073,85.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.876 | Acc: 52.803,80.096,85.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.493 | Acc: 53.906,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 47.842,65.067,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.565 | Acc: 47.332,63.796,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 46.709,63.755,66.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.991 | Acc: 48.438,73.438,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.847 | Acc: 52.902,79.427,85.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.804 | Acc: 53.125,80.297,85.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.830 | Acc: 52.805,80.085,85.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.835 | Acc: 52.903,79.938,85.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.853 | Acc: 52.870,79.842,85.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.859 | Acc: 52.957,79.707,85.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.861 | Acc: 52.914,79.832,85.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.865 | Acc: 52.902,79.872,85.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.864 | Acc: 52.728,79.977,85.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.866 | Acc: 52.760,79.928,85.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.863 | Acc: 52.637,79.988,85.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.869 | Acc: 52.571,79.911,85.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.864 | Acc: 52.550,80.005,85.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.859 | Acc: 52.663,79.996,85.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.859 | Acc: 52.689,79.965,85.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.865 | Acc: 52.602,79.848,85.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.864 | Acc: 52.669,79.852,85.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.862 | Acc: 52.699,79.915,85.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.862 | Acc: 52.795,79.923,85.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.430 | Acc: 54.688,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 47.433,65.662,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 46.989,64.310,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 46.542,64.191,66.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.701 | Acc: 60.938,82.031,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.832 | Acc: 54.353,80.208,85.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.847 | Acc: 53.487,80.354,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.859 | Acc: 53.048,80.033,85.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.848 | Acc: 53.009,80.305,85.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.842 | Acc: 52.963,80.438,85.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.859 | Acc: 52.776,80.198,85.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 52.571,80.236,85.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.865 | Acc: 52.659,80.221,85.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.862 | Acc: 52.655,80.184,85.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.864 | Acc: 52.639,80.166,85.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.871 | Acc: 52.446,80.129,85.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.865 | Acc: 52.610,80.248,85.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.866 | Acc: 52.703,80.268,85.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.870 | Acc: 52.511,80.177,85.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.873 | Acc: 52.528,80.152,85.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.875 | Acc: 52.614,80.177,85.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.871 | Acc: 52.708,80.196,85.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.874 | Acc: 52.642,80.161,85.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.879 | Acc: 52.623,80.063,85.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.517 | Acc: 54.688,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 47.619,65.365,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.553 | Acc: 47.332,64.120,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 46.773,63.973,65.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 3.180 | Acc: 43.750,75.781,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.904 | Acc: 52.493,79.874,85.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.887 | Acc: 52.458,79.821,85.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.866 | Acc: 52.357,79.790,85.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.880 | Acc: 52.296,79.601,85.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.871 | Acc: 52.290,79.796,85.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.863 | Acc: 52.389,79.978,85.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.854 | Acc: 52.582,79.992,85.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 52.557,79.920,85.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.856 | Acc: 52.478,80.024,85.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.864 | Acc: 52.530,79.983,85.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.852 | Acc: 52.750,80.186,85.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.859 | Acc: 52.681,80.193,85.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.861 | Acc: 52.646,80.148,85.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.864 | Acc: 52.700,80.113,85.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.865 | Acc: 52.692,80.116,85.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.865 | Acc: 52.636,80.130,85.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.863 | Acc: 52.642,80.111,85.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.866 | Acc: 52.629,80.038,85.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.869 | Acc: 52.567,80.075,85.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.424 | Acc: 53.906,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.513 | Acc: 47.731,65.476,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.536 | Acc: 47.466,64.024,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.597 | Acc: 46.901,63.730,66.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 3.213 | Acc: 50.000,73.438,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.831 | Acc: 53.385,80.990,85.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.843 | Acc: 52.782,81.021,85.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.871 | Acc: 52.228,80.558,85.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.887 | Acc: 51.997,80.295,85.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.897 | Acc: 51.926,80.082,85.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.884 | Acc: 52.221,80.062,85.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.885 | Acc: 52.255,79.965,85.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.898 | Acc: 52.353,79.896,85.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.898 | Acc: 52.396,79.791,85.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.895 | Acc: 52.379,79.730,85.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.897 | Acc: 52.301,79.737,85.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.888 | Acc: 52.551,79.733,85.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.888 | Acc: 52.565,79.762,85.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.883 | Acc: 52.519,79.788,85.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.881 | Acc: 52.611,79.885,85.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.880 | Acc: 52.653,79.882,85.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.875 | Acc: 52.713,80.006,85.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.873 | Acc: 52.805,79.980,85.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.875 | Acc: 52.750,79.966,85.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.507 | Acc: 54.688,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.544 | Acc: 47.619,65.030,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 47.180,64.062,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.612 | Acc: 46.696,63.998,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.658 | Acc: 61.719,77.344,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.849 | Acc: 52.679,80.469,86.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.838 | Acc: 52.858,80.583,86.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.816 | Acc: 52.997,80.648,86.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.843 | Acc: 52.652,80.334,86.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.838 | Acc: 52.754,80.314,85.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.860 | Acc: 52.641,80.056,85.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.858 | Acc: 52.698,79.976,85.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.853 | Acc: 52.737,80.047,85.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 52.642,79.942,85.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.852 | Acc: 52.620,79.901,85.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.859 | Acc: 52.496,79.864,85.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.854 | Acc: 52.538,79.931,85.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.864 | Acc: 52.383,79.822,85.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.857 | Acc: 52.438,79.952,85.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.859 | Acc: 52.429,79.931,85.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.861 | Acc: 52.405,79.965,85.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.867 | Acc: 52.325,79.885,85.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.866 | Acc: 52.389,79.889,85.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.866 | Acc: 52.450,79.901,85.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.458 | Acc: 53.906,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.522 | Acc: 47.135,65.327,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 46.913,64.177,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 46.529,63.883,66.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.912 | Acc: 45.312,79.688,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.877 | Acc: 52.604,79.650,84.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.847 | Acc: 53.277,79.916,85.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.882 | Acc: 52.497,79.828,85.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.882 | Acc: 52.392,79.842,85.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.885 | Acc: 52.398,79.804,85.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 52.531,80.043,85.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.872 | Acc: 52.371,80.092,85.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.867 | Acc: 52.373,80.202,85.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.857 | Acc: 52.521,80.287,85.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.857 | Acc: 52.651,80.309,85.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.854 | Acc: 52.665,80.341,85.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.860 | Acc: 52.522,80.284,85.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.858 | Acc: 52.604,80.253,85.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.859 | Acc: 52.572,80.196,85.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.857 | Acc: 52.570,80.318,85.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.852 | Acc: 52.677,80.262,85.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.853 | Acc: 52.616,80.196,85.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.854 | Acc: 52.597,80.146,85.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.856 | Acc: 52.653,80.079,85.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.520 | Acc: 54.688,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.534 | Acc: 47.619,65.030,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.558 | Acc: 47.218,64.043,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.613 | Acc: 46.773,63.922,66.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.569 | Acc: 56.250,79.688,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 53.348,80.283,85.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.831 | Acc: 53.525,80.030,85.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.811 | Acc: 53.778,80.494,86.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.814 | Acc: 53.607,80.266,86.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.827 | Acc: 53.326,79.997,85.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.838 | Acc: 53.209,80.004,85.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.840 | Acc: 53.086,80.025,85.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.839 | Acc: 53.154,80.066,85.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.847 | Acc: 53.069,80.080,85.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.846 | Acc: 53.051,80.150,85.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.845 | Acc: 53.065,80.197,85.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.850 | Acc: 53.080,80.161,85.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.853 | Acc: 53.035,80.220,85.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.858 | Acc: 52.947,80.166,85.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.855 | Acc: 52.930,80.248,85.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.850 | Acc: 52.955,80.276,85.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.861 | Acc: 52.845,80.196,85.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 52.889,80.255,85.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.857 | Acc: 52.819,80.208,85.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.504 | Acc: 56.250,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.540 | Acc: 47.619,65.141,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 47.332,63.929,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.617 | Acc: 47.093,63.781,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 3.027 | Acc: 46.875,82.031,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.932 | Acc: 51.525,78.720,85.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.851 | Acc: 52.801,79.916,85.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.864 | Acc: 52.882,79.944,85.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.861 | Acc: 52.807,79.890,86.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.870 | Acc: 52.785,79.804,86.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.871 | Acc: 52.589,79.862,86.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.874 | Acc: 52.687,79.804,85.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.871 | Acc: 52.562,79.852,85.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.872 | Acc: 52.667,79.761,85.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.870 | Acc: 52.484,79.901,85.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.871 | Acc: 52.549,79.928,85.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.866 | Acc: 52.571,79.966,85.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 52.472,79.960,85.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.862 | Acc: 52.511,80.021,85.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.864 | Acc: 52.538,79.957,85.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.872 | Acc: 52.458,79.928,85.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.874 | Acc: 52.454,79.930,85.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.871 | Acc: 52.508,79.928,85.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.868 | Acc: 52.569,79.942,85.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.508 | Acc: 56.250,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 47.545,65.141,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.557 | Acc: 47.180,63.929,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.616 | Acc: 46.811,63.909,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.810 | Acc: 46.875,78.125,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.760 | Acc: 52.790,81.064,86.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.754 | Acc: 53.163,80.907,86.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.786 | Acc: 53.535,80.943,86.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.814 | Acc: 53.212,80.382,86.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.816 | Acc: 53.256,80.492,86.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.843 | Acc: 53.073,80.172,86.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.850 | Acc: 52.870,80.197,85.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 52.727,80.032,85.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.865 | Acc: 52.624,80.016,85.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.866 | Acc: 52.585,80.049,85.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.853 | Acc: 52.648,80.080,85.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.844 | Acc: 52.717,80.200,86.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.837 | Acc: 52.829,80.352,86.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.834 | Acc: 52.858,80.388,86.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 52.868,80.334,86.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.839 | Acc: 52.869,80.325,86.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.845 | Acc: 52.797,80.221,86.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.844 | Acc: 52.805,80.291,86.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.851 | Acc: 52.717,80.258,85.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.523 | Acc: 55.469,64.844,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 47.396,65.216,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 47.066,63.910,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.630 | Acc: 46.644,63.768,65.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 2.822 | Acc: 57.812,81.250,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.821 | Acc: 53.497,81.845,85.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.827 | Acc: 53.163,81.212,86.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.857 | Acc: 52.882,80.494,86.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.852 | Acc: 53.260,80.613,86.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.855 | Acc: 53.311,80.654,86.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.854 | Acc: 53.319,80.514,85.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.860 | Acc: 53.042,80.458,85.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.863 | Acc: 52.892,80.546,85.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.854 | Acc: 52.944,80.607,85.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.849 | Acc: 52.853,80.593,85.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.853 | Acc: 52.807,80.493,85.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.848 | Acc: 52.930,80.543,85.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.851 | Acc: 52.853,80.463,85.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.850 | Acc: 52.925,80.421,85.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 52.907,80.404,85.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.850 | Acc: 52.974,80.420,85.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.853 | Acc: 52.917,80.368,85.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 52.893,80.289,85.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.852 | Acc: 52.908,80.319,85.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.461 | Acc: 54.688,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 47.247,65.476,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.549 | Acc: 47.161,63.986,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 46.644,63.781,65.612,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.661 | Acc: 52.344,75.781,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.894 | Acc: 51.786,79.018,85.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.863 | Acc: 52.077,79.668,86.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.844 | Acc: 52.369,80.110,86.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.875 | Acc: 52.151,79.803,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.868 | Acc: 52.251,79.950,86.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.852 | Acc: 52.292,80.198,86.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.856 | Acc: 52.255,80.275,86.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.853 | Acc: 52.334,80.435,86.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.851 | Acc: 52.439,80.365,86.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.852 | Acc: 52.371,80.243,86.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.844 | Acc: 52.605,80.285,86.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.842 | Acc: 52.629,80.310,86.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.842 | Acc: 52.607,80.355,86.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.845 | Acc: 52.605,80.282,85.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.848 | Acc: 52.624,80.264,85.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.849 | Acc: 52.611,80.267,85.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.853 | Acc: 52.568,80.203,85.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 52.567,80.168,85.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.851 | Acc: 52.674,80.188,85.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.518 | Acc: 55.469,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 47.693,65.216,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.559 | Acc: 47.180,64.043,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.617 | Acc: 46.837,63.806,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.937 | Acc: 49.219,82.812,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.915 | Acc: 51.376,79.315,85.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.836 | Acc: 52.630,79.783,86.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.809 | Acc: 52.882,80.187,86.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.809 | Acc: 53.241,80.179,86.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.847 | Acc: 52.460,79.896,86.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.838 | Acc: 52.847,79.972,86.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.840 | Acc: 52.510,80.014,86.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.843 | Acc: 52.475,80.090,86.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.837 | Acc: 52.534,80.257,86.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.833 | Acc: 52.612,80.251,86.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.840 | Acc: 52.566,80.221,86.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.840 | Acc: 52.548,80.128,86.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.840 | Acc: 52.619,80.098,86.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 52.494,80.060,86.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 52.448,79.978,86.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.847 | Acc: 52.480,80.082,86.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.846 | Acc: 52.474,80.180,86.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.845 | Acc: 52.549,80.155,86.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 52.621,80.143,86.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.446 | Acc: 56.250,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.544 | Acc: 47.247,65.253,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 46.856,64.043,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.630 | Acc: 46.568,63.845,65.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.624 | Acc: 51.562,82.031,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.819 | Acc: 54.055,80.469,85.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.843 | Acc: 53.678,80.164,86.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.836 | Acc: 53.740,80.353,86.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.864 | Acc: 53.019,80.006,86.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.856 | Acc: 53.086,80.198,86.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.862 | Acc: 52.770,80.114,86.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.846 | Acc: 52.820,80.170,86.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.864 | Acc: 52.713,79.930,85.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.858 | Acc: 52.547,79.985,86.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 52.491,80.049,86.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.843 | Acc: 52.521,80.129,86.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.838 | Acc: 52.496,80.093,86.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.845 | Acc: 52.511,80.086,86.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 52.661,80.196,86.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 52.588,80.261,86.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.840 | Acc: 52.536,80.182,85.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.841 | Acc: 52.568,80.198,86.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.836 | Acc: 52.603,80.259,86.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.834 | Acc: 52.711,80.309,86.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.532 | Acc: 54.688,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 47.247,65.290,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 46.875,64.215,66.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 46.376,63.947,65.984,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.836 | Acc: 53.125,80.469,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.827 | Acc: 52.418,80.171,86.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.855 | Acc: 51.296,79.897,86.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.847 | Acc: 52.049,79.969,86.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.831 | Acc: 52.469,80.189,86.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.836 | Acc: 52.669,80.190,86.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.843 | Acc: 52.512,80.010,86.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.845 | Acc: 52.338,80.230,86.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.844 | Acc: 52.334,80.275,86.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 52.184,80.201,86.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.855 | Acc: 52.262,80.162,86.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.858 | Acc: 52.368,80.144,86.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.855 | Acc: 52.509,80.174,86.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.844 | Acc: 52.538,80.238,86.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 52.486,80.174,86.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.848 | Acc: 52.546,80.209,86.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.848 | Acc: 52.531,80.281,86.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.851 | Acc: 52.538,80.263,86.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.848 | Acc: 52.564,80.285,86.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.850 | Acc: 52.573,80.286,86.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.486 | Acc: 54.688,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.545 | Acc: 47.470,65.439,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.579 | Acc: 47.066,64.310,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 46.760,64.050,65.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.637 | Acc: 52.344,79.688,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.841 | Acc: 52.976,80.060,86.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.854 | Acc: 52.534,79.859,86.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.848 | Acc: 52.459,80.341,86.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.839 | Acc: 52.710,80.478,86.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.843 | Acc: 52.483,80.639,86.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.840 | Acc: 52.505,80.533,86.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.840 | Acc: 52.432,80.524,86.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.857 | Acc: 52.344,80.182,86.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 52.378,80.279,86.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.853 | Acc: 52.495,80.239,86.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.846 | Acc: 52.697,80.370,86.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.848 | Acc: 52.658,80.336,86.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.841 | Acc: 52.691,80.403,86.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 52.697,80.416,86.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.840 | Acc: 52.681,80.404,86.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.839 | Acc: 52.709,80.401,86.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 52.697,80.327,86.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.845 | Acc: 52.677,80.319,86.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 52.631,80.327,86.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.527 | Acc: 56.250,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.551 | Acc: 47.879,65.327,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 47.218,64.215,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.635 | Acc: 46.913,63.896,65.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 3.254 | Acc: 47.656,76.562,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.898 | Acc: 52.716,79.427,85.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.838 | Acc: 53.506,79.688,85.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.830 | Acc: 52.574,80.059,86.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.800 | Acc: 52.595,80.488,86.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.791 | Acc: 53.009,80.446,86.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.804 | Acc: 52.931,80.275,86.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.814 | Acc: 52.837,80.197,86.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.814 | Acc: 52.921,80.250,86.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.822 | Acc: 52.831,80.227,86.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.820 | Acc: 52.810,80.329,86.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.827 | Acc: 52.817,80.288,86.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.833 | Acc: 52.694,80.216,86.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.834 | Acc: 52.661,80.229,86.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.836 | Acc: 52.686,80.358,86.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.834 | Acc: 52.780,80.393,86.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.835 | Acc: 52.804,80.347,86.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.833 | Acc: 52.809,80.400,86.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 52.787,80.285,86.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.839 | Acc: 52.842,80.299,86.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.511 | Acc: 55.469,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.551 | Acc: 47.507,65.365,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 46.856,64.101,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 46.568,63.806,65.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.533 | Acc: 55.469,83.594,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.799 | Acc: 52.344,80.952,85.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.819 | Acc: 52.439,80.869,85.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.836 | Acc: 52.254,80.533,85.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.817 | Acc: 52.440,80.671,86.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.821 | Acc: 52.568,80.399,86.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.815 | Acc: 52.725,80.553,86.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.819 | Acc: 52.726,80.519,86.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.823 | Acc: 52.713,80.532,86.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 52.698,80.434,86.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.832 | Acc: 52.554,80.465,86.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.837 | Acc: 52.471,80.423,86.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.834 | Acc: 52.486,80.443,86.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.837 | Acc: 52.556,80.442,86.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.830 | Acc: 52.747,80.466,86.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.831 | Acc: 52.746,80.541,86.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.831 | Acc: 52.753,80.498,86.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.833 | Acc: 52.731,80.439,86.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.833 | Acc: 52.722,80.432,86.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.830 | Acc: 52.776,80.483,86.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.513 | Acc: 56.250,65.625,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 47.507,65.588,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.564 | Acc: 47.332,64.272,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.615 | Acc: 47.016,63.986,66.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 3.133 | Acc: 50.781,77.344,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.835 | Acc: 53.311,79.688,85.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.833 | Acc: 52.611,79.764,85.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.806 | Acc: 52.741,80.251,86.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 52.816,80.392,86.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.818 | Acc: 52.816,80.314,86.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.812 | Acc: 52.712,80.404,86.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.803 | Acc: 52.842,80.602,86.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.818 | Acc: 52.766,80.406,86.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 52.767,80.559,86.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.808 | Acc: 52.775,80.613,86.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 52.726,80.550,86.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 52.798,80.459,86.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.817 | Acc: 52.673,80.394,86.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 52.780,80.380,86.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 52.653,80.365,86.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.815 | Acc: 52.738,80.398,86.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.816 | Acc: 52.731,80.395,86.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.820 | Acc: 52.662,80.352,86.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.820 | Acc: 52.633,80.397,86.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.525 | Acc: 54.688,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 47.470,65.290,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 47.428,64.158,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 46.952,63.832,65.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.886 | Acc: 51.562,78.125,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.823 | Acc: 53.199,80.432,86.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.782 | Acc: 53.449,80.640,86.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.797 | Acc: 52.984,80.802,86.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.833 | Acc: 52.450,80.170,86.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.819 | Acc: 52.754,80.237,86.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.826 | Acc: 52.660,80.346,86.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.843 | Acc: 52.538,80.208,86.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.836 | Acc: 52.596,80.289,86.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.826 | Acc: 52.754,80.309,86.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.825 | Acc: 52.620,80.372,86.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.824 | Acc: 52.694,80.341,86.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.826 | Acc: 52.636,80.300,86.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.828 | Acc: 52.505,80.289,86.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.833 | Acc: 52.483,80.205,86.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.836 | Acc: 52.416,80.222,86.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.833 | Acc: 52.487,80.245,86.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.833 | Acc: 52.403,80.244,86.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.830 | Acc: 52.526,80.216,86.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.832 | Acc: 52.541,80.161,86.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 53.125,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 47.284,65.067,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 47.104,64.005,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.639 | Acc: 46.644,63.755,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 3.090 | Acc: 51.562,82.031,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.757 | Acc: 53.943,81.436,87.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 54.135,80.869,87.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 53.266,80.533,86.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.786 | Acc: 53.279,80.575,86.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.808 | Acc: 53.287,80.562,86.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.814 | Acc: 53.364,80.443,86.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.817 | Acc: 53.031,80.491,86.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.819 | Acc: 52.984,80.551,86.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.816 | Acc: 53.000,80.616,86.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.819 | Acc: 52.993,80.496,86.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.827 | Acc: 52.938,80.324,86.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.822 | Acc: 52.843,80.326,86.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 52.856,80.316,86.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.825 | Acc: 52.864,80.321,86.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.827 | Acc: 52.845,80.352,86.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.826 | Acc: 52.709,80.359,86.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.827 | Acc: 52.756,80.327,86.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.829 | Acc: 52.779,80.311,86.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.824 | Acc: 52.817,80.344,86.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.510 | Acc: 53.906,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 47.545,65.402,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 47.123,64.177,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 46.632,63.819,65.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.574 | Acc: 53.906,85.938,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.787 | Acc: 53.646,81.324,87.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.795 | Acc: 53.296,81.345,86.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.809 | Acc: 52.856,80.891,86.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.822 | Acc: 52.903,80.816,85.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.806 | Acc: 53.133,80.654,86.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.816 | Acc: 53.177,80.436,86.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.817 | Acc: 53.119,80.447,86.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.830 | Acc: 53.043,80.241,86.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.836 | Acc: 53.069,80.197,86.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.837 | Acc: 53.078,80.282,86.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.837 | Acc: 53.012,80.243,86.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.836 | Acc: 53.031,80.232,86.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.838 | Acc: 52.918,80.250,86.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.829 | Acc: 52.967,80.333,86.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 52.912,80.388,86.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.829 | Acc: 52.904,80.337,86.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.828 | Acc: 52.868,80.322,86.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.831 | Acc: 52.816,80.263,86.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 52.819,80.327,86.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.527 | Acc: 56.250,66.406,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 47.768,66.034,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 47.351,64.520,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.624 | Acc: 46.862,64.088,65.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.346 | Acc: 57.031,87.500,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.727 | Acc: 54.241,81.659,86.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 53.659,81.707,87.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.773 | Acc: 53.266,81.084,86.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.774 | Acc: 53.173,81.096,86.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.793 | Acc: 53.055,80.925,86.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.783 | Acc: 53.261,81.076,86.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.791 | Acc: 53.247,80.990,86.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.797 | Acc: 53.164,80.949,86.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 53.000,80.995,86.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.812 | Acc: 52.795,80.733,86.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.808 | Acc: 52.924,80.716,86.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.816 | Acc: 52.869,80.709,86.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.820 | Acc: 52.742,80.633,86.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.820 | Acc: 52.752,80.622,86.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.820 | Acc: 52.702,80.588,86.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.819 | Acc: 52.658,80.617,86.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.823 | Acc: 52.635,80.547,86.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.821 | Acc: 52.651,80.547,86.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.824 | Acc: 52.660,80.504,86.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.531 | Acc: 55.469,65.625,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 47.433,65.216,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 47.123,64.120,65.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.651 | Acc: 46.683,63.742,64.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 3.082 | Acc: 47.656,79.688,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.822 | Acc: 53.199,80.878,86.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.837 | Acc: 52.725,80.583,86.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.829 | Acc: 52.433,80.558,86.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.822 | Acc: 52.459,80.662,86.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.810 | Acc: 52.498,80.763,86.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.817 | Acc: 52.557,80.675,86.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.814 | Acc: 52.466,80.818,86.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.818 | Acc: 52.523,80.794,86.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.805 | Acc: 52.706,80.775,86.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.805 | Acc: 52.697,80.752,86.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 52.676,80.646,86.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 52.541,80.572,86.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 52.655,80.565,86.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.812 | Acc: 52.733,80.638,86.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.812 | Acc: 52.780,80.653,86.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.811 | Acc: 52.908,80.622,86.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.811 | Acc: 52.992,80.604,86.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.812 | Acc: 52.939,80.603,86.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.810 | Acc: 52.922,80.551,86.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.543 | Acc: 55.469,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 47.247,65.551,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 47.027,64.272,66.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.626 | Acc: 46.644,63.858,65.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.615 | Acc: 63.281,83.594,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.780 | Acc: 53.981,81.287,86.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.770 | Acc: 53.601,81.059,86.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.777 | Acc: 53.330,80.904,87.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.786 | Acc: 52.990,80.970,86.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.786 | Acc: 52.978,80.995,86.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.784 | Acc: 53.035,80.824,86.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 53.241,80.646,86.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.788 | Acc: 53.339,80.551,86.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.784 | Acc: 53.246,80.572,86.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.783 | Acc: 53.269,80.609,86.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.791 | Acc: 53.224,80.564,86.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 53.209,80.634,86.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.793 | Acc: 53.104,80.660,86.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.795 | Acc: 53.019,80.661,86.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.791 | Acc: 53.065,80.715,86.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.795 | Acc: 53.015,80.632,86.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.795 | Acc: 52.992,80.595,86.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.797 | Acc: 52.880,80.596,86.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.799 | Acc: 52.803,80.584,86.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.498 | Acc: 53.125,65.625,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 47.284,65.439,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 47.161,64.291,65.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 46.747,63.973,65.484,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 3.219 | Acc: 46.094,78.906,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.825 | Acc: 52.716,80.432,86.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.740 | Acc: 53.506,81.631,87.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.744 | Acc: 53.240,81.199,87.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.766 | Acc: 53.337,81.308,87.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.791 | Acc: 53.287,81.041,86.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.797 | Acc: 53.106,80.753,86.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.800 | Acc: 52.937,80.751,86.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.803 | Acc: 52.844,80.755,86.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.803 | Acc: 52.849,80.685,86.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.798 | Acc: 52.915,80.686,86.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.805 | Acc: 52.807,80.653,86.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.807 | Acc: 52.713,80.641,86.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.808 | Acc: 52.724,80.582,86.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.809 | Acc: 52.697,80.574,86.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.812 | Acc: 52.616,80.632,86.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.804 | Acc: 52.765,80.707,86.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.801 | Acc: 52.774,80.714,86.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.798 | Acc: 52.794,80.713,86.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.804 | Acc: 52.692,80.641,86.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.510 | Acc: 55.469,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 47.433,65.365,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 47.237,64.177,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 46.811,63.819,65.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 3.113 | Acc: 47.656,75.000,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.823 | Acc: 51.079,79.836,87.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.807 | Acc: 51.677,80.316,87.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.797 | Acc: 52.177,80.302,87.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.804 | Acc: 52.739,80.314,87.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.806 | Acc: 52.916,80.260,87.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.807 | Acc: 52.822,80.236,86.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.811 | Acc: 52.815,80.286,86.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.817 | Acc: 52.727,80.294,86.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.816 | Acc: 52.732,80.253,86.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.809 | Acc: 52.861,80.430,86.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.810 | Acc: 52.782,80.472,86.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 52.616,80.478,86.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.804 | Acc: 52.733,80.547,86.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.804 | Acc: 52.705,80.549,86.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.802 | Acc: 52.775,80.474,86.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.799 | Acc: 52.874,80.520,86.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.796 | Acc: 52.981,80.515,86.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.795 | Acc: 53.036,80.564,86.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.795 | Acc: 53.049,80.557,86.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.528 | Acc: 53.125,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 47.247,65.551,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 47.123,64.558,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 46.619,64.152,65.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.704 | Acc: 45.312,82.031,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.801 | Acc: 52.455,79.725,86.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.798 | Acc: 52.763,80.393,86.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.780 | Acc: 52.754,80.392,86.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.771 | Acc: 52.778,80.642,87.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.756 | Acc: 53.094,80.763,87.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.772 | Acc: 52.983,80.585,87.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.769 | Acc: 53.125,80.585,86.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.772 | Acc: 53.106,80.634,86.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.774 | Acc: 53.220,80.659,86.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.782 | Acc: 53.195,80.585,86.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.785 | Acc: 53.118,80.642,86.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.793 | Acc: 53.060,80.608,86.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.788 | Acc: 53.122,80.660,86.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.783 | Acc: 53.156,80.761,86.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.780 | Acc: 53.128,80.811,87.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.785 | Acc: 53.050,80.809,87.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.782 | Acc: 53.056,80.840,87.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.785 | Acc: 53.041,80.787,87.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.784 | Acc: 53.031,80.809,87.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.508 | Acc: 57.031,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 48.065,65.588,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 47.580,64.310,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.647 | Acc: 47.080,63.742,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 3.132 | Acc: 47.656,75.781,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.895 | Acc: 51.674,79.985,86.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.843 | Acc: 51.696,80.602,86.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.814 | Acc: 51.883,80.635,87.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.816 | Acc: 52.016,80.334,87.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.804 | Acc: 52.143,80.507,87.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.792 | Acc: 52.382,80.591,87.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 52.549,80.641,87.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.788 | Acc: 52.426,80.663,87.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.785 | Acc: 52.663,80.866,87.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.786 | Acc: 52.849,80.803,87.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.792 | Acc: 52.779,80.748,87.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.803 | Acc: 52.648,80.560,86.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.797 | Acc: 52.724,80.645,87.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.805 | Acc: 52.600,80.633,86.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.800 | Acc: 52.705,80.635,86.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.797 | Acc: 52.687,80.671,86.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.792 | Acc: 52.770,80.764,86.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.792 | Acc: 52.753,80.770,86.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.791 | Acc: 52.803,80.885,86.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.542 | Acc: 56.250,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 47.768,65.625,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 47.466,64.234,65.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.639 | Acc: 46.952,63.870,65.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.509 | Acc: 58.594,85.156,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.682 | Acc: 54.353,82.292,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.738 | Acc: 54.078,82.088,87.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.744 | Acc: 54.060,81.814,87.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 53.617,81.530,87.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.775 | Acc: 53.380,81.343,87.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.775 | Acc: 53.274,81.282,87.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.782 | Acc: 53.236,81.244,86.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 53.067,80.988,86.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 53.034,80.926,86.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.796 | Acc: 53.047,80.904,86.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.799 | Acc: 53.005,80.896,86.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.795 | Acc: 53.080,80.955,86.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.790 | Acc: 53.086,81.040,86.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.792 | Acc: 53.053,80.939,86.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.792 | Acc: 53.037,80.874,86.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.798 | Acc: 52.935,80.829,86.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.796 | Acc: 52.910,80.792,86.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.796 | Acc: 52.831,80.796,86.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.796 | Acc: 52.819,80.807,86.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.548 | Acc: 54.688,67.188,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 47.693,65.290,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 47.142,64.062,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.638 | Acc: 46.798,63.832,65.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.831 | Acc: 60.156,80.469,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.780 | Acc: 52.976,81.324,87.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.823 | Acc: 52.706,80.202,86.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 52.472,80.443,86.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.791 | Acc: 52.546,80.710,87.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 52.653,80.801,86.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.792 | Acc: 52.802,80.830,86.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.789 | Acc: 52.920,80.851,86.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.796 | Acc: 52.965,80.774,86.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.796 | Acc: 53.000,80.775,86.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 53.086,80.745,86.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.789 | Acc: 53.040,80.762,87.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.783 | Acc: 53.047,80.835,87.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.784 | Acc: 53.101,80.870,86.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.784 | Acc: 53.058,80.883,86.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.790 | Acc: 52.993,80.762,86.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.785 | Acc: 53.067,80.817,86.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.784 | Acc: 53.104,80.835,86.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.780 | Acc: 53.160,80.869,86.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.787 | Acc: 53.043,80.817,86.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.535 | Acc: 55.469,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 47.693,65.662,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.585 | Acc: 47.428,64.139,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.642 | Acc: 47.016,63.883,65.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 3.113 | Acc: 55.469,78.125,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.813 | Acc: 53.683,80.841,86.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.818 | Acc: 53.316,80.697,86.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.839 | Acc: 52.664,80.277,86.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.830 | Acc: 52.720,80.334,86.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.829 | Acc: 52.576,80.469,86.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.825 | Acc: 52.757,80.462,86.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.818 | Acc: 52.798,80.557,86.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.818 | Acc: 52.727,80.532,86.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.823 | Acc: 52.637,80.490,86.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.820 | Acc: 52.740,80.496,86.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.810 | Acc: 52.931,80.691,86.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.806 | Acc: 52.921,80.712,86.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 52.853,80.624,86.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.803 | Acc: 52.889,80.669,86.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.802 | Acc: 52.938,80.648,86.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.799 | Acc: 52.967,80.642,86.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.801 | Acc: 52.969,80.609,86.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.799 | Acc: 52.922,80.618,86.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.796 | Acc: 52.984,80.588,86.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.548 | Acc: 56.250,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 47.656,65.774,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 47.409,64.348,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.632 | Acc: 46.965,64.152,65.740,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.628 | Acc: 53.125,85.938,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.750 | Acc: 53.571,81.734,87.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.794 | Acc: 52.858,80.983,87.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.789 | Acc: 52.984,81.007,87.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.776 | Acc: 53.231,81.057,87.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.783 | Acc: 53.280,81.049,87.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.775 | Acc: 53.177,81.237,87.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.770 | Acc: 53.180,81.167,87.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.776 | Acc: 52.960,81.134,87.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.774 | Acc: 53.034,81.047,87.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.774 | Acc: 53.024,80.986,87.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.779 | Acc: 53.100,81.017,87.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.777 | Acc: 53.109,80.984,87.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.777 | Acc: 53.182,80.945,87.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.779 | Acc: 53.195,80.966,87.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.773 | Acc: 53.291,81.048,87.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.777 | Acc: 53.317,80.965,86.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.780 | Acc: 53.281,80.909,86.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.785 | Acc: 53.181,80.889,86.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.791 | Acc: 53.049,80.828,86.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.460 | Acc: 57.031,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.544 | Acc: 47.545,65.439,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 47.313,64.139,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.627 | Acc: 46.798,63.998,65.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.809 | Acc: 58.594,78.906,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.805 | Acc: 53.162,80.320,86.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.796 | Acc: 52.839,80.888,86.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 52.459,80.827,86.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.798 | Acc: 52.575,80.883,86.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.798 | Acc: 52.560,80.995,87.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.803 | Acc: 52.712,80.901,87.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.792 | Acc: 52.909,80.818,87.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.790 | Acc: 52.941,80.833,87.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.800 | Acc: 52.888,80.633,87.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.808 | Acc: 52.903,80.616,86.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.800 | Acc: 52.920,80.670,86.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.797 | Acc: 52.960,80.744,87.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.784 | Acc: 53.116,80.831,87.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.782 | Acc: 53.161,80.897,87.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.786 | Acc: 53.159,80.832,87.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.787 | Acc: 53.088,80.797,87.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.783 | Acc: 53.091,80.831,87.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.778 | Acc: 53.060,80.895,87.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.777 | Acc: 53.051,80.955,87.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.500 | Acc: 56.250,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 47.321,65.625,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 47.066,64.386,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.637 | Acc: 46.734,64.127,65.548,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.557 | Acc: 53.906,84.375,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.770 | Acc: 53.237,81.473,87.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 53.201,81.193,87.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.795 | Acc: 53.176,80.879,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.796 | Acc: 53.009,80.816,87.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.803 | Acc: 52.963,80.801,86.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.787 | Acc: 53.086,80.863,86.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.804 | Acc: 52.704,80.790,86.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.805 | Acc: 52.698,80.707,86.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 52.754,80.633,86.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.808 | Acc: 52.748,80.620,86.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 52.726,80.649,86.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.799 | Acc: 52.794,80.751,86.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.793 | Acc: 52.865,80.810,87.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.792 | Acc: 52.911,80.877,87.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.795 | Acc: 52.907,80.780,86.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.797 | Acc: 52.901,80.722,86.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.800 | Acc: 52.960,80.686,86.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.801 | Acc: 52.969,80.709,86.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.799 | Acc: 53.070,80.705,86.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.518 | Acc: 55.469,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.551 | Acc: 47.582,65.885,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 47.370,64.463,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.638 | Acc: 46.990,64.114,65.817,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.502 | Acc: 50.000,83.594,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.702 | Acc: 55.320,81.436,87.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.715 | Acc: 55.050,81.269,87.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.746 | Acc: 54.265,80.891,87.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 53.231,80.652,87.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.768 | Acc: 53.411,80.863,87.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.766 | Acc: 53.480,80.772,87.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.783 | Acc: 53.275,80.657,87.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.787 | Acc: 53.188,80.726,87.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.790 | Acc: 53.116,80.762,87.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.786 | Acc: 53.207,80.725,87.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.791 | Acc: 53.129,80.575,87.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.785 | Acc: 53.086,80.624,87.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.788 | Acc: 52.945,80.678,87.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.789 | Acc: 52.900,80.655,87.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.783 | Acc: 52.956,80.731,87.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.784 | Acc: 52.967,80.744,87.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.782 | Acc: 52.955,80.817,87.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.785 | Acc: 52.898,80.761,87.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.784 | Acc: 52.856,80.801,87.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.510 | Acc: 55.469,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.533 | Acc: 47.545,65.885,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.557 | Acc: 47.389,64.520,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.615 | Acc: 46.939,64.178,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.393 | Acc: 55.469,82.031,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 54.315,82.106,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.708 | Acc: 53.887,81.822,87.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.732 | Acc: 53.740,81.737,87.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.747 | Acc: 53.549,81.568,87.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.782 | Acc: 53.272,81.242,86.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.782 | Acc: 53.357,81.198,86.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.789 | Acc: 53.169,81.056,86.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.799 | Acc: 53.106,80.818,86.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.793 | Acc: 53.185,80.939,86.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.794 | Acc: 53.284,80.842,86.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.803 | Acc: 53.252,80.709,86.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.810 | Acc: 53.161,80.628,86.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.803 | Acc: 53.242,80.738,86.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.807 | Acc: 53.245,80.652,86.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.804 | Acc: 53.252,80.637,86.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.800 | Acc: 53.174,80.676,86.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.806 | Acc: 53.061,80.572,86.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.803 | Acc: 53.043,80.618,86.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.799 | Acc: 53.074,80.649,86.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.488 | Acc: 56.250,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.538 | Acc: 47.582,65.513,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 47.199,64.463,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.627 | Acc: 46.939,64.127,65.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.903 | Acc: 52.344,77.344,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.791 | Acc: 53.162,80.394,87.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.792 | Acc: 53.525,80.202,87.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.762 | Acc: 53.804,80.686,87.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.784 | Acc: 53.347,80.498,87.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.777 | Acc: 53.574,80.732,87.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.793 | Acc: 53.190,80.566,87.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 53.036,80.668,87.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.788 | Acc: 52.979,80.673,87.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.791 | Acc: 53.004,80.706,87.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.787 | Acc: 53.094,80.655,87.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.793 | Acc: 52.938,80.600,87.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.800 | Acc: 52.798,80.488,87.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.800 | Acc: 52.820,80.550,87.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.789 | Acc: 53.017,80.677,87.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.792 | Acc: 53.050,80.666,87.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.787 | Acc: 53.050,80.715,87.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.784 | Acc: 53.084,80.744,87.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.785 | Acc: 53.088,80.754,87.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.779 | Acc: 53.164,80.828,87.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.550 | Acc: 55.469,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 47.954,65.737,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 47.523,64.310,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.640 | Acc: 46.965,63.986,65.625,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.777 | Acc: 50.781,78.906,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.767 | Acc: 53.534,81.064,87.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.792 | Acc: 53.068,80.526,86.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.766 | Acc: 53.765,80.571,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.772 | Acc: 53.241,80.633,86.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.782 | Acc: 53.071,80.291,86.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.772 | Acc: 53.080,80.424,86.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.762 | Acc: 53.186,80.502,86.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.762 | Acc: 53.135,80.556,86.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.765 | Acc: 52.991,80.585,87.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.774 | Acc: 52.966,80.512,86.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.777 | Acc: 52.867,80.515,86.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.775 | Acc: 52.911,80.582,86.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.777 | Acc: 52.954,80.577,86.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.776 | Acc: 52.986,80.616,86.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.784 | Acc: 52.868,80.510,86.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.787 | Acc: 52.838,80.464,86.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.790 | Acc: 52.820,80.421,86.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.788 | Acc: 52.898,80.458,86.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.788 | Acc: 52.924,80.477,86.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.530 | Acc: 57.031,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.549 | Acc: 47.805,65.327,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 47.485,64.177,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 47.029,63.960,65.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.700 | Acc: 59.375,83.594,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.808 | Acc: 53.832,80.878,85.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.795 | Acc: 53.277,81.002,86.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.786 | Acc: 53.291,80.968,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.801 | Acc: 53.077,80.758,86.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.800 | Acc: 53.024,80.724,86.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.806 | Acc: 52.841,80.714,86.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.805 | Acc: 52.848,80.663,86.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.797 | Acc: 52.810,80.726,86.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.802 | Acc: 52.754,80.680,86.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.799 | Acc: 52.670,80.772,86.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.794 | Acc: 52.711,80.833,86.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.790 | Acc: 52.791,80.838,86.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.780 | Acc: 52.999,80.909,87.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.779 | Acc: 52.997,80.969,87.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.783 | Acc: 52.946,80.923,87.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.782 | Acc: 53.003,80.914,87.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.781 | Acc: 53.049,80.916,86.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.781 | Acc: 53.056,80.895,86.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.781 | Acc: 53.061,80.930,86.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.522 | Acc: 53.906,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 47.470,65.699,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.558 | Acc: 47.275,64.520,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.619 | Acc: 46.849,64.191,65.612,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 3.432 | Acc: 41.406,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.846 | Acc: 52.716,79.688,85.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.815 | Acc: 52.439,79.916,86.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.795 | Acc: 52.664,80.123,86.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 52.421,80.372,86.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.782 | Acc: 52.661,80.639,87.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.758 | Acc: 52.751,80.959,87.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.775 | Acc: 52.671,80.679,87.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.780 | Acc: 52.494,80.663,87.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.778 | Acc: 52.633,80.762,87.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.782 | Acc: 52.662,80.659,87.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.776 | Acc: 52.644,80.773,87.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.778 | Acc: 52.684,80.848,87.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.782 | Acc: 52.652,80.774,87.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.783 | Acc: 52.666,80.797,87.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.780 | Acc: 52.671,80.855,87.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.786 | Acc: 52.650,80.768,87.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.784 | Acc: 52.664,80.838,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.782 | Acc: 52.686,80.884,87.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.779 | Acc: 52.834,80.877,87.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.483 | Acc: 57.812,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.570 | Acc: 47.656,65.625,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 47.370,64.386,66.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.653 | Acc: 46.939,63.998,65.625,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 3.153 | Acc: 48.438,75.781,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.875 | Acc: 51.749,79.539,86.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.808 | Acc: 52.725,80.431,87.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.790 | Acc: 53.202,80.712,86.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.788 | Acc: 53.144,80.498,86.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.795 | Acc: 52.924,80.678,87.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.774 | Acc: 53.215,80.934,87.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.772 | Acc: 53.336,80.834,87.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.771 | Acc: 53.232,80.862,87.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.775 | Acc: 53.181,80.874,87.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.775 | Acc: 53.304,80.920,87.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.773 | Acc: 53.323,80.928,87.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.776 | Acc: 53.209,80.919,87.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.783 | Acc: 53.128,80.840,87.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.788 | Acc: 53.125,80.797,87.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.790 | Acc: 53.164,80.726,87.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.790 | Acc: 53.137,80.715,87.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.788 | Acc: 53.139,80.739,86.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.790 | Acc: 53.071,80.748,86.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.795 | Acc: 52.940,80.707,86.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.518 | Acc: 56.250,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 47.619,65.513,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 47.218,64.291,66.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.623 | Acc: 46.849,64.101,65.689,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.567 | Acc: 53.906,79.688,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.796 | Acc: 51.600,80.097,86.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 52.477,80.850,87.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.787 | Acc: 52.357,80.456,87.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.778 | Acc: 52.546,80.584,87.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.795 | Acc: 52.351,80.476,87.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.801 | Acc: 52.486,80.488,87.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.775 | Acc: 52.682,80.995,87.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 52.747,81.148,87.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.772 | Acc: 52.749,81.090,87.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.765 | Acc: 52.787,81.223,87.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.765 | Acc: 52.708,81.197,87.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.765 | Acc: 52.791,81.260,87.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.766 | Acc: 52.811,81.220,87.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.773 | Acc: 52.689,81.119,87.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.775 | Acc: 52.723,81.097,87.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.775 | Acc: 52.689,81.148,87.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.775 | Acc: 52.752,81.129,87.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.778 | Acc: 52.772,81.122,87.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.778 | Acc: 52.752,81.068,87.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.536 | Acc: 55.469,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.548 | Acc: 47.731,65.513,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 47.275,64.196,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 46.862,63.883,65.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.823 | Acc: 60.938,79.688,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.832 | Acc: 51.711,80.952,86.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.808 | Acc: 52.153,81.098,86.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.793 | Acc: 52.228,81.071,86.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.788 | Acc: 52.508,81.105,86.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.789 | Acc: 52.429,81.095,86.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.793 | Acc: 52.518,80.953,86.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.793 | Acc: 52.615,80.979,86.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.792 | Acc: 52.548,80.973,86.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 52.624,81.090,87.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.788 | Acc: 52.670,81.005,87.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.786 | Acc: 52.623,81.041,87.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.785 | Acc: 52.736,81.068,87.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.791 | Acc: 52.769,81.028,87.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.792 | Acc: 52.830,81.008,87.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.791 | Acc: 52.829,80.946,87.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.789 | Acc: 52.799,80.904,87.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.783 | Acc: 52.843,80.902,87.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.782 | Acc: 52.826,80.934,87.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.780 | Acc: 52.889,80.965,87.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.571 | Acc: 55.469,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 47.545,65.365,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.576 | Acc: 47.256,64.177,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.631 | Acc: 46.926,63.870,65.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.799 | Acc: 53.125,80.469,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.774 | Acc: 53.311,80.990,87.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.755 | Acc: 53.506,80.983,87.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.788 | Acc: 53.202,80.763,87.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.791 | Acc: 53.337,80.691,87.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.791 | Acc: 53.241,80.701,87.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.790 | Acc: 52.976,80.643,87.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.794 | Acc: 52.887,80.602,86.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.794 | Acc: 53.057,80.522,86.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.807 | Acc: 52.892,80.369,86.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.815 | Acc: 52.717,80.313,86.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.806 | Acc: 52.676,80.511,87.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.809 | Acc: 52.723,80.469,86.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.801 | Acc: 52.790,80.532,87.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.799 | Acc: 52.769,80.544,87.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.794 | Acc: 52.842,80.640,87.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.796 | Acc: 52.813,80.590,87.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.794 | Acc: 52.825,80.609,87.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.796 | Acc: 52.813,80.566,87.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.795 | Acc: 52.943,80.561,87.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.488 | Acc: 55.469,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 47.619,65.699,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 47.351,64.367,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.621 | Acc: 46.977,64.062,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.655 | Acc: 51.562,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.855 | Acc: 51.488,79.985,86.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.818 | Acc: 52.515,80.335,86.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.818 | Acc: 52.574,80.187,86.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.814 | Acc: 52.469,80.372,87.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.815 | Acc: 52.560,80.500,87.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.819 | Acc: 52.705,80.501,86.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.810 | Acc: 52.870,80.491,86.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.804 | Acc: 52.853,80.653,87.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.802 | Acc: 52.719,80.641,86.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.795 | Acc: 52.701,80.756,86.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.780 | Acc: 52.927,80.960,87.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.779 | Acc: 52.973,80.945,87.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.775 | Acc: 53.095,80.957,87.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.775 | Acc: 53.119,80.908,87.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.771 | Acc: 53.133,80.923,87.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.773 | Acc: 53.115,80.885,87.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.776 | Acc: 53.095,80.874,87.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.775 | Acc: 53.138,80.847,87.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.779 | Acc: 53.049,80.865,87.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.531 | Acc: 54.688,67.188,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.569 | Acc: 47.098,65.662,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 47.123,64.272,66.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.650 | Acc: 46.785,64.011,65.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 3.022 | Acc: 47.656,75.000,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.854 | Acc: 51.451,80.729,85.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.823 | Acc: 51.677,80.659,87.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.824 | Acc: 51.665,80.610,86.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.821 | Acc: 51.630,80.768,87.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.796 | Acc: 52.143,81.026,87.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.786 | Acc: 52.279,81.050,87.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.778 | Acc: 52.432,81.045,87.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.781 | Acc: 52.353,80.993,86.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.776 | Acc: 52.633,80.926,86.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.784 | Acc: 52.488,80.842,86.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.775 | Acc: 52.602,80.932,86.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.782 | Acc: 52.548,80.877,86.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.788 | Acc: 52.455,80.780,87.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.782 | Acc: 52.655,80.847,87.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.781 | Acc: 52.629,80.887,87.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.777 | Acc: 52.745,80.992,87.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.777 | Acc: 52.690,81.025,87.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.782 | Acc: 52.720,80.954,87.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.783 | Acc: 52.750,80.891,87.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.530 | Acc: 55.469,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 47.396,65.737,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 47.313,64.463,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 46.824,64.139,65.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.698 | Acc: 59.375,82.031,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.787 | Acc: 52.009,80.804,87.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.800 | Acc: 52.820,80.316,86.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.790 | Acc: 53.061,80.597,87.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.800 | Acc: 52.614,80.604,87.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.778 | Acc: 53.125,80.856,87.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.767 | Acc: 53.196,81.140,87.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.773 | Acc: 53.169,81.051,87.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.767 | Acc: 53.130,81.090,87.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.769 | Acc: 53.103,81.030,87.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.776 | Acc: 53.039,80.846,87.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.773 | Acc: 53.076,80.843,87.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.778 | Acc: 53.057,80.897,87.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.781 | Acc: 53.062,80.909,87.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.784 | Acc: 53.025,80.994,87.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.785 | Acc: 53.008,81.016,87.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.779 | Acc: 53.081,81.085,87.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.779 | Acc: 53.180,81.058,87.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.779 | Acc: 53.162,81.057,87.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.778 | Acc: 53.109,81.031,87.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.524 | Acc: 56.250,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 47.433,65.625,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 47.351,64.348,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.645 | Acc: 46.849,63.909,65.727,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 3.191 | Acc: 51.562,71.094,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.858 | Acc: 53.534,79.985,86.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.777 | Acc: 54.135,80.831,87.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.816 | Acc: 53.304,81.007,87.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.803 | Acc: 53.029,81.211,87.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.804 | Acc: 52.947,81.072,87.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.800 | Acc: 52.899,80.998,87.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.793 | Acc: 53.064,80.840,87.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.793 | Acc: 53.004,80.804,87.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 52.987,80.754,87.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.788 | Acc: 53.109,80.764,87.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.794 | Acc: 53.114,80.670,87.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 53.050,80.702,87.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.788 | Acc: 53.107,80.786,87.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.792 | Acc: 53.069,80.727,87.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.796 | Acc: 53.052,80.692,87.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.795 | Acc: 53.067,80.717,87.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.794 | Acc: 53.102,80.762,87.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.792 | Acc: 53.151,80.793,87.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.788 | Acc: 53.217,80.768,87.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.530 | Acc: 56.250,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 47.396,65.625,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 47.027,64.082,65.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.652 | Acc: 46.657,63.870,65.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.274 | Acc: 56.250,86.719,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.746 | Acc: 53.051,80.618,87.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.762 | Acc: 53.925,80.869,87.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.787 | Acc: 53.599,80.827,86.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 53.356,80.941,86.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 53.403,81.204,87.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.763 | Acc: 53.280,81.237,87.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.774 | Acc: 52.898,81.145,87.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 53.004,81.192,87.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.779 | Acc: 52.745,81.133,87.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.780 | Acc: 52.697,81.141,87.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.774 | Acc: 52.800,81.059,87.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.769 | Acc: 52.908,81.124,87.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.772 | Acc: 52.889,81.026,87.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.777 | Acc: 52.825,80.950,87.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.771 | Acc: 52.902,80.990,87.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.774 | Acc: 52.882,80.963,87.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.774 | Acc: 52.878,80.991,87.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.774 | Acc: 52.891,80.962,87.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.779 | Acc: 52.803,80.936,87.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.571 | Acc: 56.250,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 47.991,65.365,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 47.466,64.310,65.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.638 | Acc: 47.029,63.934,65.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 3.040 | Acc: 53.906,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.750 | Acc: 52.009,81.399,87.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.751 | Acc: 53.030,81.288,87.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.781 | Acc: 52.920,81.301,87.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.778 | Acc: 52.836,81.356,87.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.783 | Acc: 52.792,81.173,87.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.785 | Acc: 52.854,81.024,87.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.787 | Acc: 52.998,80.945,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.792 | Acc: 52.810,81.056,87.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.801 | Acc: 52.633,80.844,87.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.795 | Acc: 52.744,80.943,87.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.791 | Acc: 52.846,80.981,87.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.789 | Acc: 52.862,80.923,87.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.787 | Acc: 52.909,80.954,87.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.787 | Acc: 52.950,80.914,86.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.789 | Acc: 52.878,80.897,86.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.792 | Acc: 52.865,80.851,86.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.789 | Acc: 52.884,80.934,86.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.790 | Acc: 52.902,80.936,86.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.787 | Acc: 52.965,80.934,86.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.565 | Acc: 56.250,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 47.582,65.699,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 47.313,64.253,65.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.652 | Acc: 46.913,63.922,65.394,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.598 | Acc: 58.594,85.156,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.762 | Acc: 52.790,80.766,87.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 52.572,80.907,87.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.805 | Acc: 52.318,80.584,87.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.793 | Acc: 52.730,80.729,87.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 52.506,80.925,87.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.776 | Acc: 52.738,81.147,87.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.777 | Acc: 52.671,81.045,87.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.759 | Acc: 52.863,81.129,87.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.760 | Acc: 52.957,81.146,87.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.762 | Acc: 52.997,81.122,87.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.769 | Acc: 52.885,81.116,87.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.772 | Acc: 52.908,81.062,87.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.779 | Acc: 52.859,80.987,87.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.780 | Acc: 52.858,80.925,87.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.775 | Acc: 52.912,80.952,87.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.777 | Acc: 52.947,80.909,87.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.777 | Acc: 52.981,80.941,87.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.775 | Acc: 52.982,80.945,87.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.777 | Acc: 53.047,80.938,87.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.510 | Acc: 55.469,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.545 | Acc: 47.656,65.737,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 47.199,64.425,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 46.824,64.088,65.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 3.114 | Acc: 48.438,83.594,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.786 | Acc: 54.241,80.915,86.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.816 | Acc: 53.258,80.335,86.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.829 | Acc: 52.754,80.020,86.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.816 | Acc: 52.556,80.228,86.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.801 | Acc: 52.924,80.476,86.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.796 | Acc: 53.093,80.656,86.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 53.147,80.685,86.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.783 | Acc: 53.275,80.891,86.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.784 | Acc: 53.211,80.818,86.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 53.086,80.791,86.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.791 | Acc: 53.054,80.723,86.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 52.918,80.754,86.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.790 | Acc: 52.951,80.732,86.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.789 | Acc: 52.928,80.750,86.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.792 | Acc: 52.936,80.650,86.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.789 | Acc: 52.989,80.651,86.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.788 | Acc: 52.990,80.675,86.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.788 | Acc: 52.974,80.657,86.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.786 | Acc: 52.967,80.682,86.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.555 | Acc: 55.469,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.554 | Acc: 47.545,65.848,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 47.294,64.425,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 46.862,64.114,65.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.585 | Acc: 57.812,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.713 | Acc: 53.943,81.362,87.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 53.468,81.079,87.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.782 | Acc: 53.279,80.904,87.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.772 | Acc: 53.511,80.864,87.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.774 | Acc: 53.550,80.840,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.766 | Acc: 53.493,81.018,87.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.774 | Acc: 53.319,80.906,87.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.769 | Acc: 53.290,80.881,87.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.778 | Acc: 53.103,80.758,87.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.777 | Acc: 53.071,80.791,87.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.780 | Acc: 53.005,80.766,87.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.786 | Acc: 52.827,80.679,87.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.783 | Acc: 52.912,80.615,87.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.784 | Acc: 52.903,80.680,87.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.780 | Acc: 52.946,80.728,87.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.781 | Acc: 52.962,80.732,87.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.780 | Acc: 52.978,80.764,87.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.778 | Acc: 52.978,80.765,87.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.781 | Acc: 52.934,80.674,87.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.539 | Acc: 54.688,67.188,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 47.582,65.551,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 47.428,64.501,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.631 | Acc: 46.952,64.114,65.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.614 | Acc: 60.938,79.688,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.863 | Acc: 52.679,80.841,87.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.818 | Acc: 53.639,80.621,87.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.804 | Acc: 53.663,80.379,86.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.817 | Acc: 53.569,79.948,86.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 53.643,80.337,86.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.783 | Acc: 53.609,80.495,86.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.780 | Acc: 53.607,80.496,86.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.780 | Acc: 53.275,80.609,86.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 53.293,80.603,87.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.780 | Acc: 53.152,80.632,87.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.781 | Acc: 53.040,80.684,86.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.781 | Acc: 53.067,80.741,86.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.785 | Acc: 52.987,80.738,86.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.787 | Acc: 53.055,80.769,86.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.783 | Acc: 53.060,80.796,86.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.784 | Acc: 52.942,80.758,86.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.785 | Acc: 52.930,80.725,86.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.787 | Acc: 52.932,80.670,86.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.788 | Acc: 52.869,80.709,86.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.540 | Acc: 54.688,66.406,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 47.433,65.662,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 47.161,64.310,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.645 | Acc: 46.696,64.037,65.625,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.572 | Acc: 57.031,78.125,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.827 | Acc: 53.348,80.580,85.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.774 | Acc: 53.201,81.288,86.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.776 | Acc: 53.689,81.288,86.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.770 | Acc: 53.318,80.874,87.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 53.233,80.871,87.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.752 | Acc: 53.428,80.966,87.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.757 | Acc: 53.413,81.012,87.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 53.256,80.915,87.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.778 | Acc: 53.224,80.870,87.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.786 | Acc: 53.133,80.784,87.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.793 | Acc: 53.118,80.730,87.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.792 | Acc: 52.999,80.796,87.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.790 | Acc: 52.960,80.714,87.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.781 | Acc: 53.078,80.805,87.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.780 | Acc: 53.029,80.858,87.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.779 | Acc: 53.013,80.907,87.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.777 | Acc: 52.983,81.009,87.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.777 | Acc: 52.939,81.038,87.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.778 | Acc: 52.895,81.041,87.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.548 | Acc: 56.250,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.549 | Acc: 47.582,65.551,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 47.142,64.177,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.630 | Acc: 46.798,63.832,65.727,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.587 | Acc: 54.688,82.031,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.746 | Acc: 54.204,80.878,86.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.759 | Acc: 53.506,80.888,86.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.766 | Acc: 53.586,80.802,86.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.767 | Acc: 53.598,80.922,86.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.767 | Acc: 53.535,80.995,86.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.768 | Acc: 53.480,81.108,86.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.773 | Acc: 53.147,80.962,86.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.780 | Acc: 53.140,80.969,86.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.783 | Acc: 53.272,80.870,86.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.778 | Acc: 53.164,80.935,86.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.778 | Acc: 53.008,80.942,86.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.775 | Acc: 53.005,80.952,86.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.780 | Acc: 52.924,80.876,86.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.778 | Acc: 52.944,80.919,86.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.781 | Acc: 52.930,80.876,86.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.779 | Acc: 52.904,80.900,86.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.779 | Acc: 52.827,80.941,86.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.778 | Acc: 52.863,80.938,86.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.779 | Acc: 52.904,81.008,86.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.525 | Acc: 55.469,65.625,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 47.619,65.625,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 47.332,64.329,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.631 | Acc: 46.965,63.998,66.035,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.632 | Acc: 50.781,84.375,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 54.464,81.696,87.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.780 | Acc: 53.735,81.364,87.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.803 | Acc: 53.240,80.584,87.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.800 | Acc: 53.395,80.546,87.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.793 | Acc: 53.195,80.546,87.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.792 | Acc: 53.022,80.701,87.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 53.380,80.696,87.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.777 | Acc: 53.440,80.702,87.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 53.384,80.672,87.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.779 | Acc: 53.339,80.729,87.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.781 | Acc: 53.220,80.794,87.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.781 | Acc: 53.089,80.799,87.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.785 | Acc: 52.999,80.750,87.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.779 | Acc: 53.014,80.791,87.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.775 | Acc: 53.115,80.830,87.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.770 | Acc: 53.164,80.943,87.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.772 | Acc: 53.102,80.936,87.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.775 | Acc: 53.060,80.919,87.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.777 | Acc: 53.113,80.844,87.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.562 | Acc: 56.250,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 47.582,65.439,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 47.294,64.272,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 46.875,63.909,65.984,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 3.060 | Acc: 53.125,81.250,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.812 | Acc: 52.604,81.287,86.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.776 | Acc: 52.287,81.117,87.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.762 | Acc: 52.856,81.301,87.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 52.720,81.385,87.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.768 | Acc: 52.669,81.095,87.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.765 | Acc: 52.957,81.050,87.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.755 | Acc: 53.064,81.150,87.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.769 | Acc: 52.950,81.080,87.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.769 | Acc: 52.909,81.069,87.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.777 | Acc: 53.001,80.990,87.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.774 | Acc: 52.906,80.950,87.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.772 | Acc: 53.021,81.023,87.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.773 | Acc: 52.933,81.011,87.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.770 | Acc: 53.033,81.058,87.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.766 | Acc: 53.076,81.105,87.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.771 | Acc: 52.967,81.075,87.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.775 | Acc: 52.926,81.080,87.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.773 | Acc: 52.937,81.120,87.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.777 | Acc: 52.891,81.068,87.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.531 | Acc: 56.250,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 47.284,65.885,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 47.008,64.577,66.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.646 | Acc: 46.644,64.101,65.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 3.011 | Acc: 52.344,80.469,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.778 | Acc: 51.600,81.064,86.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.805 | Acc: 51.601,80.869,86.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.792 | Acc: 52.382,80.802,86.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.776 | Acc: 52.614,80.883,87.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.780 | Acc: 52.614,80.964,87.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.763 | Acc: 52.918,81.011,87.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.753 | Acc: 53.136,80.918,87.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.757 | Acc: 53.130,80.847,87.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.751 | Acc: 53.289,80.874,87.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.745 | Acc: 53.397,80.896,87.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.753 | Acc: 53.330,80.808,87.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.752 | Acc: 53.349,80.842,87.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.753 | Acc: 53.299,80.906,87.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.758 | Acc: 53.192,80.927,87.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.758 | Acc: 53.182,80.926,87.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.763 | Acc: 53.096,80.929,87.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.770 | Acc: 52.990,80.858,87.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.772 | Acc: 52.932,80.834,87.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.774 | Acc: 52.885,80.803,87.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.550 | Acc: 54.688,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 47.545,65.737,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 47.313,64.234,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.650 | Acc: 46.837,63.909,65.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.678 | Acc: 50.781,85.156,92.969,% | Adaptive Acc: 85.938% | clf_exit: 0.352 0.438 0.211
Batch: 20 | Loss: 2.702 | Acc: 54.167,80.915,87.909,% | Adaptive Acc: 82.329% | clf_exit: 0.382 0.415 0.203
Batch: 40 | Loss: 2.716 | Acc: 54.021,80.964,88.053,% | Adaptive Acc: 82.793% | clf_exit: 0.373 0.420 0.208
Batch: 60 | Loss: 2.730 | Acc: 53.765,80.943,87.833,% | Adaptive Acc: 82.415% | clf_exit: 0.374 0.419 0.207
Batch: 80 | Loss: 2.744 | Acc: 53.559,80.777,87.587,% | Adaptive Acc: 82.002% | clf_exit: 0.380 0.416 0.204
Batch: 100 | Loss: 2.754 | Acc: 53.643,80.770,87.461,% | Adaptive Acc: 82.039% | clf_exit: 0.378 0.417 0.205
Batch: 120 | Loss: 2.758 | Acc: 53.345,80.882,87.435,% | Adaptive Acc: 81.734% | clf_exit: 0.377 0.418 0.204
Batch: 140 | Loss: 2.760 | Acc: 53.324,80.912,87.389,% | Adaptive Acc: 81.682% | clf_exit: 0.376 0.420 0.204
Batch: 160 | Loss: 2.769 | Acc: 53.275,80.949,87.345,% | Adaptive Acc: 81.730% | clf_exit: 0.375 0.422 0.203
Batch: 180 | Loss: 2.772 | Acc: 53.203,80.978,87.327,% | Adaptive Acc: 81.764% | clf_exit: 0.373 0.422 0.205
Batch: 200 | Loss: 2.778 | Acc: 53.133,80.822,87.247,% | Adaptive Acc: 81.716% | clf_exit: 0.371 0.422 0.206
Batch: 220 | Loss: 2.780 | Acc: 53.153,80.667,87.192,% | Adaptive Acc: 81.664% | clf_exit: 0.372 0.421 0.206
Batch: 240 | Loss: 2.783 | Acc: 53.021,80.702,87.211,% | Adaptive Acc: 81.590% | clf_exit: 0.372 0.420 0.208
Batch: 260 | Loss: 2.779 | Acc: 53.059,80.744,87.174,% | Adaptive Acc: 81.603% | clf_exit: 0.372 0.421 0.207
Batch: 280 | Loss: 2.775 | Acc: 53.106,80.788,87.158,% | Adaptive Acc: 81.589% | clf_exit: 0.372 0.421 0.207
Batch: 300 | Loss: 2.775 | Acc: 53.128,80.811,87.165,% | Adaptive Acc: 81.595% | clf_exit: 0.372 0.422 0.206
Batch: 320 | Loss: 2.773 | Acc: 53.123,80.895,87.218,% | Adaptive Acc: 81.622% | clf_exit: 0.372 0.423 0.205
Batch: 340 | Loss: 2.774 | Acc: 53.134,80.840,87.211,% | Adaptive Acc: 81.626% | clf_exit: 0.371 0.423 0.206
Batch: 360 | Loss: 2.775 | Acc: 53.144,80.828,87.175,% | Adaptive Acc: 81.603% | clf_exit: 0.372 0.422 0.206
Batch: 380 | Loss: 2.776 | Acc: 53.119,80.793,87.139,% | Adaptive Acc: 81.553% | clf_exit: 0.372 0.422 0.206
Batch: 0 | Loss: 4.510 | Acc: 56.250,66.406,67.188,% | Adaptive Acc: 63.281% | clf_exit: 0.516 0.328 0.156
Batch: 20 | Loss: 4.564 | Acc: 47.247,65.588,67.113,% | Adaptive Acc: 62.091% | clf_exit: 0.448 0.335 0.217
Batch: 40 | Loss: 4.581 | Acc: 46.932,64.386,66.216,% | Adaptive Acc: 61.966% | clf_exit: 0.443 0.333 0.224
Batch: 60 | Loss: 4.641 | Acc: 46.619,63.998,65.702,% | Adaptive Acc: 61.335% | clf_exit: 0.440 0.337 0.224
model is save as models/resnet56_2con3_att_cifar100_adaptive0_circles8_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 14.567 | Acc: 56.250,11.719,0.781,% | Adaptive Acc: 39.062% | clf_exit: 0.516 0.195 0.289
Batch: 20 | Loss: 14.746 | Acc: 47.247,8.519,3.571,% | Adaptive Acc: 34.933% | clf_exit: 0.448 0.214 0.339
Batch: 40 | Loss: 14.808 | Acc: 46.932,8.708,3.316,% | Adaptive Acc: 34.718% | clf_exit: 0.443 0.218 0.339
Batch: 60 | Loss: 14.910 | Acc: 46.619,8.696,3.266,% | Adaptive Acc: 34.413% | clf_exit: 0.440 0.220 0.341
Batch: 0 | Loss: 11.977 | Acc: 56.250,25.781,0.000,% | Adaptive Acc: 43.750% | clf_exit: 0.516 0.203 0.281
Batch: 20 | Loss: 12.210 | Acc: 47.247,22.173,3.125,% | Adaptive Acc: 37.463% | clf_exit: 0.448 0.203 0.349
Batch: 40 | Loss: 12.292 | Acc: 46.932,21.627,3.106,% | Adaptive Acc: 36.966% | clf_exit: 0.443 0.206 0.351
Batch: 60 | Loss: 12.380 | Acc: 46.619,20.530,3.099,% | Adaptive Acc: 36.616% | clf_exit: 0.440 0.210 0.350
Batch: 0 | Loss: 9.864 | Acc: 56.250,39.844,2.344,% | Adaptive Acc: 47.656% | clf_exit: 0.516 0.219 0.266
Batch: 20 | Loss: 10.059 | Acc: 47.247,33.891,5.060,% | Adaptive Acc: 40.365% | clf_exit: 0.448 0.224 0.329
Batch: 40 | Loss: 10.154 | Acc: 46.932,33.537,5.545,% | Adaptive Acc: 40.206% | clf_exit: 0.443 0.222 0.336
Batch: 60 | Loss: 10.224 | Acc: 46.619,32.518,5.571,% | Adaptive Acc: 39.869% | clf_exit: 0.440 0.219 0.342
Batch: 0 | Loss: 8.245 | Acc: 56.250,45.312,10.938,% | Adaptive Acc: 51.562% | clf_exit: 0.516 0.273 0.211
Batch: 20 | Loss: 8.466 | Acc: 47.247,40.848,14.844,% | Adaptive Acc: 44.643% | clf_exit: 0.448 0.226 0.327
Batch: 40 | Loss: 8.559 | Acc: 46.932,40.034,14.596,% | Adaptive Acc: 43.750% | clf_exit: 0.443 0.224 0.333
Batch: 60 | Loss: 8.627 | Acc: 46.619,39.255,14.511,% | Adaptive Acc: 43.327% | clf_exit: 0.440 0.222 0.338
Batch: 0 | Loss: 6.646 | Acc: 56.250,51.562,37.500,% | Adaptive Acc: 53.125% | clf_exit: 0.516 0.266 0.219
Batch: 20 | Loss: 6.908 | Acc: 47.247,45.685,36.607,% | Adaptive Acc: 49.740% | clf_exit: 0.448 0.230 0.323
Batch: 40 | Loss: 6.987 | Acc: 46.932,44.989,35.442,% | Adaptive Acc: 49.047% | clf_exit: 0.443 0.229 0.328
Batch: 60 | Loss: 7.060 | Acc: 46.619,44.314,35.169,% | Adaptive Acc: 48.668% | clf_exit: 0.440 0.226 0.335
Batch: 0 | Loss: 6.135 | Acc: 56.250,57.031,37.500,% | Adaptive Acc: 55.469% | clf_exit: 0.516 0.234 0.250
Batch: 20 | Loss: 6.440 | Acc: 47.247,52.679,39.881,% | Adaptive Acc: 51.823% | clf_exit: 0.448 0.232 0.320
Batch: 40 | Loss: 6.499 | Acc: 46.932,51.810,38.681,% | Adaptive Acc: 51.048% | clf_exit: 0.443 0.234 0.323
Batch: 60 | Loss: 6.564 | Acc: 46.619,51.332,38.576,% | Adaptive Acc: 50.832% | clf_exit: 0.440 0.237 0.323
Batch: 0 | Loss: 5.453 | Acc: 56.250,60.156,46.094,% | Adaptive Acc: 57.812% | clf_exit: 0.516 0.281 0.203
Batch: 20 | Loss: 5.627 | Acc: 47.247,60.231,49.777,% | Adaptive Acc: 55.506% | clf_exit: 0.448 0.262 0.290
Batch: 40 | Loss: 5.671 | Acc: 46.932,59.127,49.181,% | Adaptive Acc: 55.602% | clf_exit: 0.443 0.262 0.296
Batch: 60 | Loss: 5.728 | Acc: 46.619,58.901,48.809,% | Adaptive Acc: 55.328% | clf_exit: 0.440 0.266 0.295
Batch: 0 | Loss: 4.813 | Acc: 56.250,61.719,57.812,% | Adaptive Acc: 60.156% | clf_exit: 0.516 0.297 0.188
Batch: 20 | Loss: 4.957 | Acc: 47.247,63.988,61.421,% | Adaptive Acc: 59.487% | clf_exit: 0.448 0.305 0.248
Batch: 40 | Loss: 4.986 | Acc: 46.932,63.072,60.614,% | Adaptive Acc: 59.242% | clf_exit: 0.443 0.307 0.250
Batch: 60 | Loss: 5.038 | Acc: 46.619,62.910,60.182,% | Adaptive Acc: 58.901% | clf_exit: 0.440 0.313 0.248
Batch: 0 | Loss: 4.510 | Acc: 56.250,66.406,67.188,% | Adaptive Acc: 63.281% | clf_exit: 0.516 0.328 0.156
Batch: 20 | Loss: 4.564 | Acc: 47.247,65.588,67.113,% | Adaptive Acc: 62.091% | clf_exit: 0.448 0.335 0.217
Batch: 40 | Loss: 4.581 | Acc: 46.932,64.386,66.216,% | Adaptive Acc: 61.966% | clf_exit: 0.443 0.333 0.224
Batch: 60 | Loss: 4.641 | Acc: 46.619,63.998,65.702,% | Adaptive Acc: 61.335% | clf_exit: 0.440 0.337 0.224







Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.864 |  Acc: 2.116,1.946,1.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 16.560 |  Acc: 2.350,2.020,1.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 13.535 |  Acc: 3.218,2.054,1.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 13.431 |  Acc: 4.130,1.970,2.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 13.265 |  Acc: 4.768,3.700,1.944,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 13.196 |  Acc: 5.580,3.840,1.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 12.928 |  Acc: 7.248,5.380,2.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 12.976 |  Acc: 7.830,5.640,2.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 12.538 |  Acc: 9.094,7.604,2.006,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 12.516 |  Acc: 8.620,7.500,2.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 12.108 |  Acc: 11.262,9.964,2.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 12.380 |  Acc: 9.510,9.360,2.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 11.838 |  Acc: 12.936,11.920,1.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 12.007 |  Acc: 12.550,10.400,1.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 11.556 |  Acc: 14.948,14.042,2.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 11.728 |  Acc: 13.330,12.820,1.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 11.269 |  Acc: 16.892,16.052,2.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 11.419 |  Acc: 15.000,14.890,1.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 10.994 |  Acc: 18.950,17.774,2.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 11.436 |  Acc: 17.600,13.020,2.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 10.756 |  Acc: 20.748,19.492,2.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 11.007 |  Acc: 19.820,16.630,2.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 10.523 |  Acc: 22.732,21.634,2.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 12.179 |  Acc: 13.950,12.570,2.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 10.340 |  Acc: 24.066,22.952,2.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 11.255 |  Acc: 18.260,17.060,2.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 10.135 |  Acc: 25.402,24.654,2.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 10.887 |  Acc: 20.220,18.590,2.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 9.965 |  Acc: 26.944,26.240,2.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 11.068 |  Acc: 20.420,18.690,2.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 9.827 |  Acc: 27.876,27.714,2.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 10.725 |  Acc: 22.630,19.620,2.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 9.709 |  Acc: 28.648,28.874,2.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 10.935 |  Acc: 18.490,21.460,2.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 9.583 |  Acc: 29.646,30.268,2.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 10.070 |  Acc: 25.750,25.530,2.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 9.469 |  Acc: 30.292,31.676,2.614,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 10.208 |  Acc: 24.270,26.240,2.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 9.344 |  Acc: 31.128,33.236,2.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 9.990 |  Acc: 26.100,26.740,2.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 9.260 |  Acc: 31.574,34.320,2.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 9.971 |  Acc: 25.390,29.370,2.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 9.182 |  Acc: 32.126,35.762,2.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 9.906 |  Acc: 26.710,28.670,2.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 9.115 |  Acc: 32.346,36.334,2.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 10.692 |  Acc: 23.680,27.960,2.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 9.006 |  Acc: 33.408,37.648,2.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 10.385 |  Acc: 23.740,28.950,2.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 8.923 |  Acc: 34.086,38.750,2.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 9.919 |  Acc: 25.930,30.810,1.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 8.848 |  Acc: 34.366,39.444,2.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 9.332 |  Acc: 28.620,35.500,3.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 8.791 |  Acc: 34.566,40.224,2.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 10.206 |  Acc: 23.050,29.240,2.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 8.727 |  Acc: 35.170,41.054,2.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 9.520 |  Acc: 26.690,35.040,2.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 8.707 |  Acc: 35.330,41.610,2.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 18.447 |  Acc: 25.990,34.050,1.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 9.001 |  Acc: 35.552,41.720,2.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 9.726 |  Acc: 29.210,35.990,2.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 8.873 |  Acc: 36.062,42.372,2.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 10.023 |  Acc: 25.790,33.180,2.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 8.763 |  Acc: 36.784,43.506,2.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 9.600 |  Acc: 29.750,35.590,2.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 8.687 |  Acc: 36.844,44.030,2.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 10.271 |  Acc: 25.300,32.160,3.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 8.635 |  Acc: 37.136,44.408,2.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 9.931 |  Acc: 28.200,32.070,2.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 8.579 |  Acc: 37.254,44.956,2.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 10.222 |  Acc: 27.200,34.130,2.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 8.515 |  Acc: 37.728,45.654,2.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 10.081 |  Acc: 25.740,36.090,3.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 8.462 |  Acc: 37.872,46.288,2.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 9.574 |  Acc: 27.810,38.220,2.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 8.432 |  Acc: 37.700,46.610,2.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 9.630 |  Acc: 26.230,37.510,2.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 8.386 |  Acc: 38.070,46.910,2.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 9.721 |  Acc: 27.390,37.800,3.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 8.352 |  Acc: 38.346,47.506,2.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 9.407 |  Acc: 30.930,36.000,3.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 8.307 |  Acc: 38.622,47.954,2.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 9.066 |  Acc: 33.260,39.240,2.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 8.293 |  Acc: 38.434,48.182,2.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 9.688 |  Acc: 28.340,35.510,2.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 8.264 |  Acc: 38.888,48.434,2.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 10.188 |  Acc: 24.140,34.200,2.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 8.232 |  Acc: 38.728,48.948,2.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 9.358 |  Acc: 30.040,38.550,2.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 8.191 |  Acc: 39.146,49.168,2.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 10.242 |  Acc: 25.430,34.210,2.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 8.171 |  Acc: 38.908,49.410,3.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 9.695 |  Acc: 27.450,35.960,3.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 8.129 |  Acc: 39.562,50.050,3.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 9.144 |  Acc: 32.060,40.150,2.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 8.124 |  Acc: 39.640,50.190,3.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 9.347 |  Acc: 29.470,39.640,3.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 8.083 |  Acc: 40.104,50.456,3.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 10.120 |  Acc: 25.700,35.990,3.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 8.064 |  Acc: 39.804,50.652,3.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 10.064 |  Acc: 23.110,36.280,2.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 8.050 |  Acc: 39.926,50.920,3.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 9.646 |  Acc: 25.030,40.470,3.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 8.024 |  Acc: 39.982,51.450,3.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 8.985 |  Acc: 31.410,41.970,2.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 8.019 |  Acc: 40.128,51.260,3.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 9.376 |  Acc: 27.330,41.980,3.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 7.993 |  Acc: 40.368,51.710,3.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 8.945 |  Acc: 34.890,44.450,1.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 7.963 |  Acc: 40.448,51.982,3.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 9.108 |  Acc: 29.290,41.720,3.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 7.932 |  Acc: 40.572,52.352,3.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 9.318 |  Acc: 28.570,39.050,3.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 7.930 |  Acc: 40.348,52.394,3.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 9.424 |  Acc: 27.610,40.120,2.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 7.904 |  Acc: 40.628,52.986,2.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 9.905 |  Acc: 26.170,40.370,2.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 7.916 |  Acc: 40.548,52.972,2.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 8.758 |  Acc: 33.910,44.540,3.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 7.870 |  Acc: 40.816,53.010,3.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 8.991 |  Acc: 29.930,41.600,3.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 7.860 |  Acc: 41.030,53.408,3.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 10.384 |  Acc: 24.240,37.280,2.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 7.830 |  Acc: 40.856,53.710,2.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 9.561 |  Acc: 24.740,40.120,2.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 7.863 |  Acc: 41.004,53.514,3.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 232.765 |  Acc: 29.300,39.980,1.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 7.863 |  Acc: 40.872,53.408,3.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 9.011 |  Acc: 32.570,44.240,3.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 7.914 |  Acc: 41.318,53.992,3.138,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 8.987 |  Acc: 32.730,43.500,3.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 7.898 |  Acc: 41.506,54.198,3.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 9.260 |  Acc: 30.500,43.200,1.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 7.907 |  Acc: 41.420,54.422,3.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 10.046 |  Acc: 25.940,34.760,3.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 7.890 |  Acc: 41.362,54.528,3.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 8.791 |  Acc: 34.440,45.860,3.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 7.863 |  Acc: 41.444,54.618,3.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 8.921 |  Acc: 31.950,44.630,3.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 7.861 |  Acc: 41.272,54.890,3.006,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 9.169 |  Acc: 31.130,41.760,2.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 7.865 |  Acc: 41.622,54.954,2.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 9.734 |  Acc: 27.260,38.630,2.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 7.895 |  Acc: 41.624,55.116,2.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 8.851 |  Acc: 35.350,45.460,1.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 7.889 |  Acc: 41.548,55.220,2.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 8.925 |  Acc: 33.270,45.190,2.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 7.856 |  Acc: 41.830,55.328,2.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 9.236 |  Acc: 30.950,41.270,2.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 7.893 |  Acc: 41.928,55.446,2.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 9.404 |  Acc: 31.850,41.910,2.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 7.929 |  Acc: 41.674,55.298,2.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 8.690 |  Acc: 35.710,45.830,3.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 7.855 |  Acc: 41.928,55.894,2.994,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 9.497 |  Acc: 29.840,42.460,2.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 7.822 |  Acc: 41.958,55.768,2.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 9.244 |  Acc: 32.960,40.280,3.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 7.800 |  Acc: 42.204,56.414,2.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 9.380 |  Acc: 26.780,42.770,2.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 7.777 |  Acc: 42.162,56.616,2.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 8.954 |  Acc: 31.840,45.760,3.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 7.755 |  Acc: 42.152,56.752,2.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 8.848 |  Acc: 32.920,44.320,2.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 7.743 |  Acc: 42.388,56.586,2.986,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 8.846 |  Acc: 33.950,46.800,3.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 7.711 |  Acc: 42.324,57.040,2.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 9.033 |  Acc: 30.810,44.680,2.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 7.696 |  Acc: 42.216,57.072,2.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 9.671 |  Acc: 25.170,41.950,2.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 7.672 |  Acc: 42.464,57.438,2.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 10.132 |  Acc: 22.810,41.090,3.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 7.658 |  Acc: 42.464,57.394,2.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 8.536 |  Acc: 33.080,48.120,2.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 7.666 |  Acc: 42.416,57.456,2.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 8.947 |  Acc: 30.930,45.060,2.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 7.643 |  Acc: 42.438,57.452,2.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 10.245 |  Acc: 24.820,38.650,2.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 7.621 |  Acc: 42.616,57.778,2.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 9.220 |  Acc: 27.640,46.040,3.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 7.610 |  Acc: 42.744,58.036,2.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 8.666 |  Acc: 32.910,47.400,3.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 7.593 |  Acc: 42.684,57.886,2.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 9.166 |  Acc: 31.050,44.490,2.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 7.591 |  Acc: 42.724,58.240,3.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 8.718 |  Acc: 32.530,47.200,3.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 7.577 |  Acc: 42.676,58.114,3.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 9.181 |  Acc: 27.560,44.660,2.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 7.587 |  Acc: 42.522,57.998,3.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 8.974 |  Acc: 31.960,45.460,2.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 7.556 |  Acc: 42.772,58.194,2.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 9.081 |  Acc: 32.540,44.410,2.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 7.549 |  Acc: 42.526,58.302,3.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 8.993 |  Acc: 30.300,46.580,3.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 7.564 |  Acc: 42.658,58.142,3.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 9.999 |  Acc: 24.930,40.380,2.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 7.551 |  Acc: 42.480,58.384,3.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 9.147 |  Acc: 32.180,46.190,2.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 7.534 |  Acc: 42.926,58.426,3.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 10.214 |  Acc: 28.430,42.660,2.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 7.529 |  Acc: 43.008,58.646,3.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 10.103 |  Acc: 31.850,46.950,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 7.524 |  Acc: 43.076,58.752,3.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 8.625 |  Acc: 31.980,49.870,2.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 7.554 |  Acc: 43.046,58.618,3.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 8.966 |  Acc: 33.490,49.940,2.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 7.574 |  Acc: 43.022,58.402,3.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 9.135 |  Acc: 27.760,45.410,2.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 7.586 |  Acc: 43.054,58.734,3.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 8.443 |  Acc: 34.100,50.490,2.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 7.577 |  Acc: 42.888,58.850,3.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 9.078 |  Acc: 29.370,46.430,2.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 7.548 |  Acc: 43.382,58.950,3.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 9.798 |  Acc: 24.740,43.070,2.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 7.529 |  Acc: 43.182,58.910,3.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 9.309 |  Acc: 28.820,46.910,2.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 7.518 |  Acc: 43.064,59.002,3.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 9.474 |  Acc: 27.650,44.320,2.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 7.522 |  Acc: 43.266,59.444,3.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 9.762 |  Acc: 27.840,43.770,2.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 7.343 |  Acc: 43.480,59.536,5.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 11.859 |  Acc: 32.100,47.960,3.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 7.152 |  Acc: 43.150,59.282,8.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 9.330 |  Acc: 22.990,42.970,7.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 7.061 |  Acc: 43.352,58.730,10.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 11.782 |  Acc: 22.690,32.670,4.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 6.989 |  Acc: 42.878,58.838,11.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 10.664 |  Acc: 27.520,40.540,2.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 6.984 |  Acc: 42.812,57.796,12.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 9.204 |  Acc: 30.050,44.390,4.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 6.959 |  Acc: 42.688,57.680,13.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 10.948 |  Acc: 20.910,36.460,9.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 6.937 |  Acc: 42.698,57.346,13.512,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 8.503 |  Acc: 30.780,47.320,7.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 6.915 |  Acc: 42.558,57.306,13.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 8.010 |  Acc: 33.140,47.990,13.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 6.914 |  Acc: 42.346,56.972,14.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 9.415 |  Acc: 23.850,40.130,7.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 6.958 |  Acc: 42.172,56.164,14.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 9.787 |  Acc: 26.500,39.760,5.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 6.916 |  Acc: 42.058,56.578,15.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 8.810 |  Acc: 27.390,42.440,10.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 6.934 |  Acc: 41.592,55.640,15.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 8.497 |  Acc: 32.150,45.460,8.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 6.939 |  Acc: 41.788,55.696,15.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 8.129 |  Acc: 32.160,44.360,11.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 6.987 |  Acc: 41.158,54.878,15.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 8.849 |  Acc: 28.310,41.740,7.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 6.985 |  Acc: 41.510,54.786,16.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 11.165 |  Acc: 21.810,30.300,5.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 7.011 |  Acc: 41.506,54.438,16.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 8.580 |  Acc: 29.940,42.650,11.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 6.990 |  Acc: 41.206,54.514,16.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 9.349 |  Acc: 27.320,37.690,10.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 7.134 |  Acc: 40.382,52.510,16.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 9.185 |  Acc: 27.040,39.270,10.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 7.113 |  Acc: 40.232,52.386,17.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 8.869 |  Acc: 29.130,40.920,8.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 7.150 |  Acc: 39.788,51.624,18.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 10.143 |  Acc: 22.320,33.560,12.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 6.834 |  Acc: 41.050,53.300,21.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 9.476 |  Acc: 24.010,36.230,13.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 6.618 |  Acc: 41.676,54.640,24.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 8.143 |  Acc: 31.200,43.750,17.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 6.292 |  Acc: 42.764,56.914,29.060,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 7.715 |  Acc: 32.990,49.520,18.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 6.149 |  Acc: 42.822,57.636,31.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 8.168 |  Acc: 31.430,46.940,14.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 6.010 |  Acc: 43.304,58.426,34.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 8.650 |  Acc: 25.680,39.220,25.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 5.963 |  Acc: 43.076,58.130,36.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 6.711 |  Acc: 36.080,50.390,32.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 5.878 |  Acc: 43.054,58.354,37.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 8.478 |  Acc: 30.460,46.000,18.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 5.805 |  Acc: 42.982,58.552,39.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 7.361 |  Acc: 35.270,47.380,30.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 5.754 |  Acc: 43.278,58.618,40.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 7.413 |  Acc: 32.340,46.840,31.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 5.643 |  Acc: 43.208,59.124,43.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.550 |  Acc: 34.350,50.330,39.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 5.625 |  Acc: 42.972,58.874,44.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 7.172 |  Acc: 31.740,47.100,37.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 5.582 |  Acc: 43.066,58.894,45.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 10.176 |  Acc: 21.070,34.050,31.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 5.494 |  Acc: 43.102,59.086,46.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 8.443 |  Acc: 24.310,40.770,32.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 5.475 |  Acc: 42.882,58.960,47.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 7.019 |  Acc: 31.950,47.100,40.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 5.402 |  Acc: 42.936,59.416,49.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 8.649 |  Acc: 26.640,46.030,29.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 5.310 |  Acc: 43.112,59.554,51.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 7.080 |  Acc: 29.540,47.710,42.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 5.202 |  Acc: 43.230,59.424,53.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 7.604 |  Acc: 25.110,44.740,46.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 5.064 |  Acc: 43.210,60.026,56.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 6.762 |  Acc: 29.420,47.190,47.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.987 |  Acc: 43.220,60.152,57.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 7.211 |  Acc: 28.370,44.830,45.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.960 |  Acc: 43.158,60.356,58.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 6.954 |  Acc: 30.330,44.820,46.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.928 |  Acc: 43.036,60.420,58.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 6.774 |  Acc: 29.720,47.150,49.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 4.234 |  Acc: 47.456,67.352,66.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.615 |  Acc: 44.560,62.550,63.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 4.041 |  Acc: 48.516,69.322,68.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.560 |  Acc: 44.960,62.940,64.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.975 |  Acc: 49.078,69.782,68.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.577 |  Acc: 44.300,63.010,64.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.922 |  Acc: 49.146,70.200,69.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.577 |  Acc: 44.400,63.290,64.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.890 |  Acc: 49.382,70.548,69.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.585 |  Acc: 44.780,62.850,64.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.868 |  Acc: 49.316,70.720,70.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.534 |  Acc: 45.390,63.270,64.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.833 |  Acc: 49.444,71.286,70.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.607 |  Acc: 44.500,62.980,64.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.810 |  Acc: 49.674,71.356,70.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.611 |  Acc: 44.600,63.260,64.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.793 |  Acc: 49.672,71.490,71.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.574 |  Acc: 44.730,63.170,64.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.776 |  Acc: 49.710,71.598,71.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.568 |  Acc: 45.350,63.030,64.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.762 |  Acc: 49.780,71.600,71.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.543 |  Acc: 45.480,63.520,64.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.731 |  Acc: 49.942,71.984,72.038,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.590 |  Acc: 44.910,63.100,64.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.719 |  Acc: 49.922,71.812,72.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.571 |  Acc: 45.240,63.510,64.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.713 |  Acc: 49.864,72.142,72.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.511 |  Acc: 45.430,63.810,65.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.688 |  Acc: 49.932,72.384,72.376,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.665 |  Acc: 44.000,62.770,64.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.684 |  Acc: 50.410,72.340,72.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.571 |  Acc: 45.200,63.350,65.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.667 |  Acc: 50.114,72.220,72.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.573 |  Acc: 44.510,63.580,65.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 3.655 |  Acc: 50.220,72.584,72.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.592 |  Acc: 44.850,63.640,65.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 3.649 |  Acc: 50.084,72.794,73.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.603 |  Acc: 44.990,63.400,64.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 3.626 |  Acc: 50.174,72.786,73.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.581 |  Acc: 44.770,63.260,64.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 3.629 |  Acc: 50.250,72.658,73.060,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.518 |  Acc: 45.640,64.370,65.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 3.608 |  Acc: 50.150,73.028,73.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.589 |  Acc: 44.800,63.020,65.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 3.584 |  Acc: 50.602,73.192,73.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.618 |  Acc: 44.910,63.200,65.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 3.581 |  Acc: 50.706,73.452,74.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.686 |  Acc: 44.360,63.100,64.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 3.580 |  Acc: 50.334,73.296,74.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.621 |  Acc: 45.140,63.210,64.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 3.563 |  Acc: 50.524,73.350,74.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.587 |  Acc: 45.190,62.960,64.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 3.552 |  Acc: 50.614,73.484,74.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.610 |  Acc: 45.050,62.860,64.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 3.550 |  Acc: 50.172,73.464,74.250,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.672 |  Acc: 44.900,62.740,64.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 3.530 |  Acc: 50.430,73.752,74.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.559 |  Acc: 45.390,62.970,65.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 3.527 |  Acc: 50.404,73.670,75.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.689 |  Acc: 45.230,63.000,64.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 3.515 |  Acc: 50.448,73.878,74.774,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.621 |  Acc: 44.910,62.940,64.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 3.515 |  Acc: 50.282,73.810,75.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.722 |  Acc: 44.810,62.340,64.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 3.499 |  Acc: 50.654,73.994,75.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.682 |  Acc: 44.680,62.830,64.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 3.505 |  Acc: 50.338,74.078,75.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.590 |  Acc: 45.920,63.540,64.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 3.481 |  Acc: 50.556,73.884,75.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 5.083 |  Acc: 41.540,61.290,63.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 3.469 |  Acc: 50.568,74.092,75.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.684 |  Acc: 45.340,63.060,65.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 3.458 |  Acc: 50.668,74.424,75.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.725 |  Acc: 44.560,62.540,64.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 3.454 |  Acc: 50.712,74.180,75.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.698 |  Acc: 44.910,62.410,63.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 3.446 |  Acc: 50.736,74.310,75.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.600 |  Acc: 45.490,62.370,64.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 3.455 |  Acc: 50.610,74.176,75.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.678 |  Acc: 45.130,62.590,64.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 3.431 |  Acc: 50.592,74.406,76.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.725 |  Acc: 44.640,62.560,64.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 3.426 |  Acc: 50.668,74.614,76.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.873 |  Acc: 43.440,61.310,63.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 3.420 |  Acc: 50.634,74.616,76.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.759 |  Acc: 44.680,61.680,64.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 3.402 |  Acc: 50.824,74.830,76.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.731 |  Acc: 44.290,62.630,64.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 3.407 |  Acc: 50.670,74.670,76.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.809 |  Acc: 43.170,62.100,63.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 3.390 |  Acc: 50.730,74.640,76.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.749 |  Acc: 45.080,62.210,64.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 3.388 |  Acc: 50.782,74.676,76.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.679 |  Acc: 45.130,62.740,65.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 3.384 |  Acc: 50.854,74.956,77.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.853 |  Acc: 43.900,62.320,64.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 3.394 |  Acc: 50.548,74.528,76.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.898 |  Acc: 43.810,61.880,63.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 3.373 |  Acc: 50.846,74.784,77.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.649 |  Acc: 45.670,63.220,64.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 3.373 |  Acc: 50.956,74.988,77.154,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.838 |  Acc: 44.460,61.550,62.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 3.360 |  Acc: 50.886,75.138,77.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.875 |  Acc: 43.980,61.640,63.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 3.368 |  Acc: 51.034,74.994,77.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.713 |  Acc: 45.670,62.740,64.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 3.345 |  Acc: 50.940,75.150,77.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.776 |  Acc: 44.600,62.830,63.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 3.340 |  Acc: 51.306,75.022,77.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.763 |  Acc: 44.420,62.320,63.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 3.338 |  Acc: 50.696,75.158,77.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.965 |  Acc: 43.470,60.280,62.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 3.340 |  Acc: 50.682,75.292,77.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.813 |  Acc: 44.970,62.500,63.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 3.334 |  Acc: 50.872,75.038,77.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.847 |  Acc: 44.420,61.410,63.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 3.323 |  Acc: 50.674,75.142,77.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.937 |  Acc: 44.190,61.610,63.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 3.321 |  Acc: 50.590,75.496,77.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.912 |  Acc: 44.280,61.570,63.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 3.307 |  Acc: 50.830,75.338,78.192,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.728 |  Acc: 45.670,62.740,64.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 3.302 |  Acc: 51.020,75.282,78.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.790 |  Acc: 44.830,61.870,64.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 3.300 |  Acc: 50.836,75.480,78.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.985 |  Acc: 44.090,61.510,63.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 3.282 |  Acc: 51.108,75.720,78.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.776 |  Acc: 44.540,62.260,63.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 3.309 |  Acc: 50.794,75.386,78.394,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.858 |  Acc: 44.130,61.800,63.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 3.295 |  Acc: 50.738,75.530,78.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.809 |  Acc: 44.680,62.210,63.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 3.273 |  Acc: 51.054,75.778,78.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 5.133 |  Acc: 43.420,60.310,63.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 3.265 |  Acc: 51.102,75.788,79.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.931 |  Acc: 43.580,61.680,62.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 3.262 |  Acc: 51.256,75.834,79.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.830 |  Acc: 45.260,61.230,63.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 3.269 |  Acc: 50.744,75.778,79.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.883 |  Acc: 44.800,61.230,63.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 3.262 |  Acc: 50.932,75.940,79.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.873 |  Acc: 43.990,61.540,63.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 3.259 |  Acc: 50.792,75.918,79.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.886 |  Acc: 45.030,61.840,63.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 3.268 |  Acc: 50.866,75.640,79.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.706 |  Acc: 45.120,62.930,64.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 3.237 |  Acc: 50.994,75.854,79.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.864 |  Acc: 44.600,62.000,63.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 3.239 |  Acc: 51.312,75.894,79.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.944 |  Acc: 43.870,60.770,63.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 3.040 |  Acc: 52.238,78.464,82.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.530 |  Acc: 46.260,64.360,66.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.974 |  Acc: 52.220,79.090,83.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.519 |  Acc: 46.540,64.420,66.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.949 |  Acc: 52.360,79.394,84.146,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.541 |  Acc: 46.500,64.340,66.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.933 |  Acc: 52.664,79.104,84.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.523 |  Acc: 46.490,64.450,66.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.936 |  Acc: 52.384,79.606,84.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.544 |  Acc: 46.450,64.320,66.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.921 |  Acc: 52.762,79.710,84.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.538 |  Acc: 46.450,64.250,66.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.906 |  Acc: 52.458,79.614,84.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.572 |  Acc: 46.310,64.160,66.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.908 |  Acc: 52.498,79.808,84.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.544 |  Acc: 46.720,64.340,66.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.905 |  Acc: 52.614,79.672,84.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.547 |  Acc: 46.570,64.250,66.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.891 |  Acc: 52.890,79.896,85.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.558 |  Acc: 46.440,64.480,66.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.891 |  Acc: 52.508,79.982,85.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.552 |  Acc: 46.010,64.470,66.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.890 |  Acc: 52.646,79.916,84.954,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.563 |  Acc: 46.480,64.510,66.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.892 |  Acc: 52.754,79.788,85.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.577 |  Acc: 46.330,64.230,66.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.873 |  Acc: 52.776,80.088,85.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.573 |  Acc: 46.210,64.530,66.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.882 |  Acc: 52.794,80.056,85.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.595 |  Acc: 46.420,64.200,66.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.862 |  Acc: 52.738,79.934,85.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.577 |  Acc: 46.290,64.570,66.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.877 |  Acc: 52.626,80.120,85.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.582 |  Acc: 46.580,64.400,66.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.871 |  Acc: 52.572,80.068,85.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.567 |  Acc: 46.650,64.220,66.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.876 |  Acc: 52.720,79.944,85.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.585 |  Acc: 46.470,64.320,66.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.865 |  Acc: 52.486,79.946,85.596,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.576 |  Acc: 46.400,64.230,66.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.860 |  Acc: 52.640,80.022,85.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.589 |  Acc: 46.450,64.330,66.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.859 |  Acc: 52.844,80.180,85.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.593 |  Acc: 46.760,64.160,66.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.865 |  Acc: 52.594,79.982,85.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.584 |  Acc: 46.580,64.460,66.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.853 |  Acc: 52.746,80.232,85.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.601 |  Acc: 46.490,64.200,66.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.851 |  Acc: 52.936,80.286,85.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.577 |  Acc: 46.350,64.350,66.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.854 |  Acc: 52.668,80.156,85.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.586 |  Acc: 46.690,64.330,66.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.844 |  Acc: 52.636,80.156,86.152,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.605 |  Acc: 46.370,64.270,66.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.834 |  Acc: 52.752,80.304,86.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.605 |  Acc: 46.150,64.280,66.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.845 |  Acc: 52.652,80.362,86.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.600 |  Acc: 46.390,64.400,66.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.841 |  Acc: 52.694,80.380,86.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.608 |  Acc: 46.650,64.290,65.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.839 |  Acc: 52.808,80.298,86.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.611 |  Acc: 46.330,64.270,65.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.829 |  Acc: 52.796,80.468,86.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.590 |  Acc: 46.780,64.250,66.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.824 |  Acc: 52.596,80.358,86.230,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.596 |  Acc: 46.740,64.280,66.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.832 |  Acc: 52.562,80.136,86.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.607 |  Acc: 46.590,64.290,66.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.826 |  Acc: 52.826,80.292,86.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.607 |  Acc: 46.460,64.340,66.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.826 |  Acc: 52.770,80.340,86.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.595 |  Acc: 46.560,64.490,65.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.826 |  Acc: 52.678,80.500,86.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.625 |  Acc: 46.500,64.120,65.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.807 |  Acc: 52.964,80.554,86.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.598 |  Acc: 46.430,64.290,66.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.801 |  Acc: 52.828,80.550,86.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.599 |  Acc: 46.490,64.450,65.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.804 |  Acc: 52.704,80.652,86.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.600 |  Acc: 46.610,64.240,66.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.795 |  Acc: 53.036,80.546,86.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.606 |  Acc: 46.290,64.530,66.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.784 |  Acc: 53.050,80.818,87.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.617 |  Acc: 46.790,64.190,65.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.789 |  Acc: 52.888,80.874,86.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.611 |  Acc: 46.670,64.350,65.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.797 |  Acc: 52.794,80.782,86.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.611 |  Acc: 46.490,64.310,65.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.792 |  Acc: 52.962,80.790,86.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.615 |  Acc: 46.710,64.320,65.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.795 |  Acc: 52.998,80.602,86.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.602 |  Acc: 46.730,64.520,66.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.790 |  Acc: 53.052,80.850,86.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.598 |  Acc: 46.590,64.450,65.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.779 |  Acc: 53.072,80.928,87.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.606 |  Acc: 46.520,64.450,65.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.801 |  Acc: 53.076,80.682,86.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.608 |  Acc: 46.720,64.520,66.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.784 |  Acc: 52.902,80.806,87.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.589 |  Acc: 46.710,64.460,66.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.794 |  Acc: 53.096,80.724,86.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.597 |  Acc: 46.720,64.550,65.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.780 |  Acc: 53.112,80.780,87.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.612 |  Acc: 46.640,64.350,65.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.789 |  Acc: 52.916,80.470,86.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.600 |  Acc: 46.710,64.350,66.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.783 |  Acc: 53.008,80.896,86.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.593 |  Acc: 46.580,64.670,66.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.781 |  Acc: 52.850,80.858,87.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.622 |  Acc: 46.670,64.400,65.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.794 |  Acc: 53.008,80.716,86.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.596 |  Acc: 46.630,64.470,66.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.776 |  Acc: 52.734,81.072,87.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.597 |  Acc: 46.560,64.280,66.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.780 |  Acc: 52.938,80.930,87.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.601 |  Acc: 46.820,64.350,66.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.797 |  Acc: 52.920,80.542,87.152,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.595 |  Acc: 46.780,64.540,66.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.782 |  Acc: 52.986,80.824,87.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.624 |  Acc: 46.510,64.420,66.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.786 |  Acc: 52.784,80.882,87.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.617 |  Acc: 46.560,64.580,65.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.780 |  Acc: 53.078,80.994,87.274,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.616 |  Acc: 46.590,64.330,66.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.788 |  Acc: 53.214,80.762,87.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.625 |  Acc: 46.390,64.310,65.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.782 |  Acc: 52.758,80.906,87.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.611 |  Acc: 46.670,64.310,65.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.784 |  Acc: 53.008,80.942,86.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.622 |  Acc: 46.670,64.390,65.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.777 |  Acc: 53.066,80.932,87.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.601 |  Acc: 46.540,64.570,65.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.785 |  Acc: 52.990,80.708,86.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.610 |  Acc: 46.560,64.440,65.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.781 |  Acc: 52.948,80.688,87.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.605 |  Acc: 46.680,64.540,66.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.787 |  Acc: 52.936,80.714,86.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.618 |  Acc: 46.490,64.460,65.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.776 |  Acc: 52.968,81.048,87.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.604 |  Acc: 46.570,64.340,65.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.782 |  Acc: 52.846,81.014,86.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.604 |  Acc: 46.650,64.400,66.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.775 |  Acc: 53.132,80.870,87.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.616 |  Acc: 46.640,64.290,66.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.777 |  Acc: 52.872,81.054,87.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.619 |  Acc: 46.520,64.490,65.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.778 |  Acc: 52.880,80.804,87.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.623 |  Acc: 46.610,64.370,66.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.777 |  Acc: 53.108,80.802,87.112,% | Adaptive Acc:81.534% | clf_exit: 0.372 0.423 0.206
Testing: Epoch=299 | Loss: 4.618 |  Acc: 46.300,64.280,65.910,% | Adaptive Acc:61.340% | clf_exit: 0.438 0.341 0.221

circles: 0
Testing: Epoch=299 | Loss: 14.910 |  Acc: 46.300,8.770,3.500,% | Adaptive Acc:34.160% | clf_exit: 0.438 0.221 0.341
circles: 1
Testing: Epoch=299 | Loss: 12.373 |  Acc: 46.300,20.770,3.370,% | Adaptive Acc:36.490% | clf_exit: 0.438 0.211 0.351
circles: 2
Testing: Epoch=299 | Loss: 10.213 |  Acc: 46.300,32.650,5.810,% | Adaptive Acc:39.770% | clf_exit: 0.438 0.219 0.343
circles: 3
Testing: Epoch=299 | Loss: 8.610 |  Acc: 46.300,39.400,14.820,% | Adaptive Acc:43.340% | clf_exit: 0.438 0.226 0.337
circles: 4
Testing: Epoch=299 | Loss: 7.044 |  Acc: 46.300,44.340,35.580,% | Adaptive Acc:48.650% | clf_exit: 0.438 0.229 0.333
circles: 5
Testing: Epoch=299 | Loss: 6.544 |  Acc: 46.300,51.510,38.830,% | Adaptive Acc:50.870% | clf_exit: 0.438 0.238 0.325
circles: 6
Testing: Epoch=299 | Loss: 5.708 |  Acc: 46.300,59.210,49.130,% | Adaptive Acc:55.410% | clf_exit: 0.438 0.269 0.293
circles: 7
Testing: Epoch=299 | Loss: 5.015 |  Acc: 46.300,63.370,60.450,% | Adaptive Acc:59.140% | clf_exit: 0.438 0.316 0.246
circles: 8
Testing: Epoch=299 | Loss: 4.618 |  Acc: 46.300,64.280,65.910,% | Adaptive Acc:61.340% | clf_exit: 0.438 0.341 0.221
