==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
******************************
IMPORTANT: attention 2 is default to yes!!!!!!
******************************
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=16, out_features=16, bias=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (BN1d): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=48, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (attention_1): ScanLayer(
        (conv): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=48, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention_2): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=16, out_features=4, bias=True)
          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=4, out_features=16, bias=True)
          (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=96, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=96, out_features=100, bias=True)
      (attention): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=32, out_features=8, bias=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=8, out_features=32, bias=True)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.158 | Acc: 0.781,0.781,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.487 | Acc: 1.228,1.302,1.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.229 | Acc: 1.353,1.505,1.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.119 | Acc: 1.550,1.755,1.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.047 | Acc: 1.582,1.910,2.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.990 | Acc: 1.632,1.988,2.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.936 | Acc: 1.814,2.092,2.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.890 | Acc: 1.867,2.139,2.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.858 | Acc: 1.907,2.208,2.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.817 | Acc: 1.981,2.275,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.779 | Acc: 2.118,2.394,3.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.747 | Acc: 2.213,2.453,3.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.712 | Acc: 2.208,2.503,3.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.680 | Acc: 2.254,2.538,3.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.642 | Acc: 2.285,2.541,3.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.607 | Acc: 2.328,2.551,3.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.572 | Acc: 2.322,2.575,4.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.538 | Acc: 2.346,2.593,4.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.508 | Acc: 2.372,2.608,4.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.481 | Acc: 2.397,2.608,4.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.901 | Acc: 3.906,2.344,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.923 | Acc: 3.906,2.976,6.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.927 | Acc: 3.563,2.934,6.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.931 | Acc: 3.330,3.023,6.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 13.035 | Acc: 3.906,2.344,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.888 | Acc: 3.162,3.088,7.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.827 | Acc: 3.373,3.106,7.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.816 | Acc: 3.484,3.202,8.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.793 | Acc: 3.598,3.250,8.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.766 | Acc: 3.620,3.295,8.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.748 | Acc: 3.738,3.467,8.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.747 | Acc: 3.701,3.535,8.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.724 | Acc: 3.746,3.576,8.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.696 | Acc: 3.807,3.682,8.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.674 | Acc: 3.867,3.727,9.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.663 | Acc: 3.896,3.768,9.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.646 | Acc: 3.919,3.867,9.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.633 | Acc: 3.942,3.906,9.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.619 | Acc: 3.923,3.965,9.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.604 | Acc: 3.966,4.013,9.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.592 | Acc: 3.933,4.064,9.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.574 | Acc: 3.954,4.213,9.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.556 | Acc: 4.019,4.320,9.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.538 | Acc: 4.046,4.415,10.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.088 | Acc: 4.688,5.469,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.354 | Acc: 3.795,5.729,9.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.340 | Acc: 4.173,5.907,9.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.347 | Acc: 4.175,5.930,9.439,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 12.165 | Acc: 6.250,8.594,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.105 | Acc: 4.725,7.143,13.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.125 | Acc: 4.497,6.612,12.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.110 | Acc: 4.572,6.737,12.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.100 | Acc: 4.514,6.645,12.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.083 | Acc: 4.657,6.730,12.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.073 | Acc: 4.765,6.915,12.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.049 | Acc: 4.959,6.893,12.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.028 | Acc: 5.144,7.119,12.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.012 | Acc: 5.240,7.182,12.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.001 | Acc: 5.360,7.121,12.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.990 | Acc: 5.458,7.091,12.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.977 | Acc: 5.478,7.138,12.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.964 | Acc: 5.594,7.199,13.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.961 | Acc: 5.633,7.245,13.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.952 | Acc: 5.687,7.273,13.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.936 | Acc: 5.792,7.440,13.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.918 | Acc: 5.856,7.572,13.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.900 | Acc: 5.930,7.644,13.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.881 | Acc: 5.967,7.718,13.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.578 | Acc: 10.156,6.250,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.636 | Acc: 6.027,7.552,14.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.607 | Acc: 6.898,8.079,14.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.627 | Acc: 6.698,8.466,14.716,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 11.855 | Acc: 4.688,10.156,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.616 | Acc: 6.771,8.259,14.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.577 | Acc: 6.669,8.575,14.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.554 | Acc: 6.698,8.671,14.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.521 | Acc: 6.935,8.912,14.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.491 | Acc: 7.147,9.205,15.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.465 | Acc: 7.270,9.220,15.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.439 | Acc: 7.342,9.342,15.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.437 | Acc: 7.468,9.419,15.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.422 | Acc: 7.502,9.556,15.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.412 | Acc: 7.606,9.585,15.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.404 | Acc: 7.639,9.630,15.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.399 | Acc: 7.624,9.699,15.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.388 | Acc: 7.690,9.812,15.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.367 | Acc: 7.815,9.992,15.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.352 | Acc: 7.880,10.034,16.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.335 | Acc: 7.939,10.134,16.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.325 | Acc: 7.973,10.163,16.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.312 | Acc: 8.001,10.197,16.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.296 | Acc: 8.007,10.246,16.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.517 | Acc: 6.250,7.812,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.522 | Acc: 8.073,7.478,15.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.488 | Acc: 8.632,7.489,16.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.484 | Acc: 8.478,7.646,16.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 11.339 | Acc: 10.938,7.031,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.863 | Acc: 10.751,12.351,19.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.889 | Acc: 10.099,12.233,19.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.885 | Acc: 10.067,12.205,18.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.864 | Acc: 10.195,12.317,19.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.889 | Acc: 10.087,12.322,18.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.878 | Acc: 10.014,12.345,18.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.874 | Acc: 10.023,12.461,18.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.857 | Acc: 10.054,12.451,18.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.851 | Acc: 10.061,12.569,18.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.847 | Acc: 10.005,12.578,18.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.826 | Acc: 10.100,12.564,18.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.810 | Acc: 10.163,12.639,18.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.793 | Acc: 10.231,12.686,18.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.773 | Acc: 10.287,12.781,19.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.766 | Acc: 10.325,12.827,19.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.758 | Acc: 10.366,12.848,19.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.744 | Acc: 10.470,12.988,19.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.734 | Acc: 10.474,13.054,19.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.718 | Acc: 10.593,13.224,19.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.739 | Acc: 12.500,10.156,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.802 | Acc: 11.496,11.496,18.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.762 | Acc: 11.833,11.719,18.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.771 | Acc: 11.732,11.680,18.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 10.298 | Acc: 12.500,21.094,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.295 | Acc: 11.421,16.295,21.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.372 | Acc: 11.528,15.873,21.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.367 | Acc: 11.834,15.804,21.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.356 | Acc: 11.786,15.644,21.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.339 | Acc: 11.881,15.470,21.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.345 | Acc: 11.912,15.528,21.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.331 | Acc: 12.112,15.730,21.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.318 | Acc: 12.151,15.863,21.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.288 | Acc: 12.306,15.949,21.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.283 | Acc: 12.391,15.901,21.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.275 | Acc: 12.465,15.897,22.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.266 | Acc: 12.526,15.959,22.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.252 | Acc: 12.626,15.969,22.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.240 | Acc: 12.656,16.000,22.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.222 | Acc: 12.765,16.045,22.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.208 | Acc: 12.868,16.124,22.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.193 | Acc: 12.922,16.214,22.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.190 | Acc: 12.959,16.190,22.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.179 | Acc: 13.033,16.291,22.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.765 | Acc: 17.188,15.625,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.509 | Acc: 13.281,11.570,22.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.498 | Acc: 13.872,11.357,22.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.528 | Acc: 13.473,11.219,21.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 10.019 | Acc: 14.062,20.312,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.848 | Acc: 14.509,17.634,25.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.802 | Acc: 14.958,17.530,25.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.803 | Acc: 15.382,17.956,25.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.798 | Acc: 15.201,17.978,25.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.801 | Acc: 15.161,18.046,25.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.802 | Acc: 15.192,18.066,25.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.799 | Acc: 15.187,18.080,24.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.793 | Acc: 15.222,18.216,24.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.790 | Acc: 15.275,18.292,25.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.775 | Acc: 15.388,18.462,25.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.766 | Acc: 15.431,18.453,25.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.754 | Acc: 15.430,18.507,25.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.748 | Acc: 15.535,18.505,25.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.741 | Acc: 15.530,18.405,25.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.726 | Acc: 15.602,18.592,25.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.716 | Acc: 15.693,18.640,25.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.718 | Acc: 15.691,18.617,25.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.713 | Acc: 15.757,18.655,25.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.695 | Acc: 15.896,18.789,25.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.135 | Acc: 14.844,23.438,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.188 | Acc: 13.765,17.894,22.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.129 | Acc: 14.310,17.759,22.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.117 | Acc: 14.062,17.277,22.656,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 9.304 | Acc: 17.188,17.188,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.555 | Acc: 16.555,19.606,25.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.541 | Acc: 16.273,19.417,25.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.536 | Acc: 16.650,19.544,25.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.481 | Acc: 17.255,20.052,26.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.451 | Acc: 17.350,19.964,26.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.423 | Acc: 17.485,20.209,26.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.390 | Acc: 17.598,20.761,27.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.379 | Acc: 17.619,20.905,27.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.367 | Acc: 17.628,20.947,27.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.346 | Acc: 17.786,21.032,27.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.345 | Acc: 17.866,20.974,27.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.330 | Acc: 17.888,21.026,27.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.332 | Acc: 17.987,20.941,27.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.330 | Acc: 17.935,20.846,27.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.325 | Acc: 18.002,20.938,27.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.314 | Acc: 18.078,21.009,27.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.311 | Acc: 18.086,20.993,27.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.302 | Acc: 18.159,21.029,27.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.290 | Acc: 18.239,21.163,28.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.122 | Acc: 15.625,18.750,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.247 | Acc: 12.426,14.286,23.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.218 | Acc: 12.252,14.634,23.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.232 | Acc: 12.129,14.613,22.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 9.374 | Acc: 15.625,21.094,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.054 | Acc: 17.969,21.689,28.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.115 | Acc: 18.388,22.389,28.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.043 | Acc: 19.006,22.848,29.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.040 | Acc: 19.242,22.782,29.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.023 | Acc: 19.547,22.896,29.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.020 | Acc: 19.615,22.960,29.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.998 | Acc: 20.013,23.111,29.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.986 | Acc: 20.065,23.083,29.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.991 | Acc: 20.006,23.179,29.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.993 | Acc: 19.974,23.068,29.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.974 | Acc: 20.016,23.215,30.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.957 | Acc: 20.121,23.292,30.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.958 | Acc: 20.064,23.237,30.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.949 | Acc: 20.123,23.304,30.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.942 | Acc: 20.162,23.357,30.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.940 | Acc: 20.198,23.323,30.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.944 | Acc: 20.164,23.295,30.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.939 | Acc: 20.226,23.342,30.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.934 | Acc: 20.200,23.339,30.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.972 | Acc: 21.875,19.531,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.122 | Acc: 16.890,15.513,25.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.101 | Acc: 16.482,15.854,25.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.116 | Acc: 16.150,15.856,24.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 8.066 | Acc: 22.656,23.438,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.686 | Acc: 20.350,23.847,33.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.692 | Acc: 20.617,24.333,32.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.726 | Acc: 20.517,23.937,31.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.726 | Acc: 20.534,24.103,31.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.710 | Acc: 20.792,24.381,31.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.683 | Acc: 21.139,24.619,32.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.666 | Acc: 21.221,24.873,32.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.679 | Acc: 21.137,24.830,32.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.659 | Acc: 21.158,25.043,32.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.644 | Acc: 21.245,25.140,32.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.641 | Acc: 21.384,25.134,32.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.642 | Acc: 21.324,25.152,32.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.644 | Acc: 21.405,25.156,32.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.639 | Acc: 21.472,25.167,32.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.637 | Acc: 21.491,25.213,32.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.628 | Acc: 21.588,25.251,32.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.626 | Acc: 21.573,25.273,32.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.626 | Acc: 21.566,25.301,32.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.615 | Acc: 21.633,25.431,32.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.091 | Acc: 18.750,17.969,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.267 | Acc: 17.485,20.982,30.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.234 | Acc: 18.140,21.265,30.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.260 | Acc: 17.956,21.004,29.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 7.783 | Acc: 28.906,29.688,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.413 | Acc: 22.805,26.749,33.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.377 | Acc: 22.713,26.905,33.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.396 | Acc: 22.669,26.396,33.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.354 | Acc: 23.158,26.910,34.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.361 | Acc: 23.283,27.073,34.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.358 | Acc: 23.444,27.253,34.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.363 | Acc: 23.404,27.117,34.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.350 | Acc: 23.462,27.106,34.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.344 | Acc: 23.476,27.162,34.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.334 | Acc: 23.461,27.270,34.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.337 | Acc: 23.423,27.248,34.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.342 | Acc: 23.350,27.169,34.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.346 | Acc: 23.267,27.137,34.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.350 | Acc: 23.310,27.208,34.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.351 | Acc: 23.313,27.134,34.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.347 | Acc: 23.374,27.134,34.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.337 | Acc: 23.360,27.193,34.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.336 | Acc: 23.318,27.262,34.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.326 | Acc: 23.345,27.356,34.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.616 | Acc: 21.875,29.688,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.974 | Acc: 19.308,22.805,31.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.855 | Acc: 19.855,23.990,32.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.844 | Acc: 20.108,24.001,31.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 8.112 | Acc: 29.688,31.250,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.252 | Acc: 22.879,27.307,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.156 | Acc: 23.819,28.296,36.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.131 | Acc: 23.899,28.612,36.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.133 | Acc: 23.708,28.588,36.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.140 | Acc: 23.747,28.574,35.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.100 | Acc: 24.186,29.055,36.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.087 | Acc: 24.263,29.072,36.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.097 | Acc: 24.141,28.901,36.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.088 | Acc: 24.253,28.962,36.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.095 | Acc: 24.145,28.984,36.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.095 | Acc: 24.243,29.076,36.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.088 | Acc: 24.348,29.068,36.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.084 | Acc: 24.330,29.032,36.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.089 | Acc: 24.333,29.048,36.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.084 | Acc: 24.359,29.088,36.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.082 | Acc: 24.314,29.035,36.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.074 | Acc: 24.416,29.099,36.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.071 | Acc: 24.513,29.168,36.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.072 | Acc: 24.526,29.122,36.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.460 | Acc: 21.094,28.125,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.103 | Acc: 18.750,24.330,32.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.020 | Acc: 19.607,24.257,32.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.049 | Acc: 19.339,23.770,32.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 8.243 | Acc: 17.188,23.438,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.853 | Acc: 26.004,31.771,38.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.840 | Acc: 25.381,30.736,38.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.828 | Acc: 25.615,30.802,38.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.829 | Acc: 25.434,31.105,38.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.876 | Acc: 25.387,30.910,38.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.880 | Acc: 25.336,30.792,38.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.870 | Acc: 25.366,30.918,38.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.894 | Acc: 25.233,30.721,38.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.913 | Acc: 25.186,30.719,38.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.904 | Acc: 25.307,30.737,38.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.902 | Acc: 25.354,30.812,38.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.895 | Acc: 25.324,30.832,38.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.880 | Acc: 25.371,30.807,38.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.869 | Acc: 25.434,30.900,38.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.857 | Acc: 25.498,31.045,38.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.849 | Acc: 25.533,31.058,38.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.844 | Acc: 25.554,31.051,38.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.855 | Acc: 25.556,31.003,38.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.851 | Acc: 25.572,31.115,38.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.427 | Acc: 27.344,28.125,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.933 | Acc: 21.019,24.479,31.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.889 | Acc: 21.018,24.181,31.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.891 | Acc: 20.581,24.129,31.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 7.539 | Acc: 24.219,31.250,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.544 | Acc: 26.562,32.924,41.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.607 | Acc: 26.086,32.508,40.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.644 | Acc: 26.012,32.582,40.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.671 | Acc: 25.868,32.378,40.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.684 | Acc: 26.122,32.403,40.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.669 | Acc: 26.427,32.709,40.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.643 | Acc: 26.463,32.873,41.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.653 | Acc: 26.431,32.657,40.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.661 | Acc: 26.299,32.515,40.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.675 | Acc: 26.224,32.521,40.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.656 | Acc: 26.347,32.678,40.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.664 | Acc: 26.326,32.660,40.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.662 | Acc: 26.281,32.696,40.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.652 | Acc: 26.404,32.793,40.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.649 | Acc: 26.365,32.802,40.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.640 | Acc: 26.414,32.912,40.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.636 | Acc: 26.459,32.922,40.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.638 | Acc: 26.443,32.932,40.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.639 | Acc: 26.376,32.927,40.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.779 | Acc: 26.562,31.250,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.125 | Acc: 21.949,29.092,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.059 | Acc: 22.409,29.592,39.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.085 | Acc: 22.374,29.098,38.819,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 7.530 | Acc: 26.562,37.500,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.518 | Acc: 27.716,34.077,41.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.526 | Acc: 27.077,33.765,41.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.518 | Acc: 26.767,33.504,41.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.497 | Acc: 26.784,33.951,41.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.483 | Acc: 26.942,34.120,41.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.472 | Acc: 27.027,34.375,42.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.487 | Acc: 26.718,34.220,41.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.487 | Acc: 26.766,34.195,41.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.479 | Acc: 26.895,34.099,41.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.476 | Acc: 27.072,34.177,41.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.486 | Acc: 27.072,34.060,41.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.484 | Acc: 27.081,34.009,41.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.487 | Acc: 27.086,34.052,41.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.480 | Acc: 27.124,34.116,41.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.470 | Acc: 27.243,34.209,41.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.469 | Acc: 27.237,34.253,41.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.466 | Acc: 27.309,34.274,41.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.468 | Acc: 27.246,34.271,41.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.462 | Acc: 27.208,34.281,41.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.091 | Acc: 21.875,31.250,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.004 | Acc: 18.973,29.315,37.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.942 | Acc: 19.455,28.716,37.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.933 | Acc: 19.557,27.805,36.591,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 8.046 | Acc: 19.531,32.031,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.229 | Acc: 28.013,35.342,43.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.249 | Acc: 28.030,35.366,43.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.262 | Acc: 27.907,35.515,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.279 | Acc: 27.865,35.494,43.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.252 | Acc: 28.264,35.852,43.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.269 | Acc: 28.196,35.770,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.269 | Acc: 28.142,35.793,43.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.266 | Acc: 28.426,35.792,43.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.272 | Acc: 28.302,35.748,43.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.279 | Acc: 28.207,35.728,43.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.271 | Acc: 28.245,35.810,43.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.266 | Acc: 28.423,35.934,43.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.277 | Acc: 28.341,35.902,43.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.280 | Acc: 28.289,35.843,43.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.284 | Acc: 28.224,35.836,43.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.273 | Acc: 28.286,35.877,43.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.271 | Acc: 28.260,35.857,43.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.270 | Acc: 28.233,35.896,43.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.272 | Acc: 28.246,35.909,43.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.465 | Acc: 19.531,22.656,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.368 | Acc: 19.271,25.632,32.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.381 | Acc: 19.627,25.343,32.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.400 | Acc: 19.467,25.115,32.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 7.564 | Acc: 21.875,35.156,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.112 | Acc: 28.571,37.500,45.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.093 | Acc: 28.678,37.252,45.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.110 | Acc: 29.162,36.924,44.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.093 | Acc: 29.253,36.998,44.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.075 | Acc: 29.239,37.338,45.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.078 | Acc: 29.326,37.397,45.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.075 | Acc: 29.344,37.400,45.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.074 | Acc: 29.372,37.379,45.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.089 | Acc: 29.217,37.280,45.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.086 | Acc: 29.272,37.364,45.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.082 | Acc: 29.306,37.366,45.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.088 | Acc: 29.188,37.283,45.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.079 | Acc: 29.325,37.344,45.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.074 | Acc: 29.332,37.414,45.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.075 | Acc: 29.309,37.433,45.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.080 | Acc: 29.240,37.390,45.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.084 | Acc: 29.243,37.401,45.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.082 | Acc: 29.164,37.405,45.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.085 | Acc: 29.134,37.424,45.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.859 | Acc: 25.781,37.500,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.052 | Acc: 22.768,31.920,41.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.104 | Acc: 22.694,30.602,39.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.105 | Acc: 22.285,30.264,39.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 6.723 | Acc: 30.469,38.281,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.826 | Acc: 29.799,39.695,48.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.878 | Acc: 29.802,38.948,47.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.860 | Acc: 30.161,39.383,47.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.874 | Acc: 30.179,39.246,47.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.883 | Acc: 29.958,38.931,46.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.888 | Acc: 30.088,39.075,47.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.895 | Acc: 30.164,39.179,46.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.911 | Acc: 29.867,39.043,46.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.909 | Acc: 29.890,39.119,46.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.914 | Acc: 29.897,38.923,46.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.920 | Acc: 29.942,38.854,46.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.920 | Acc: 29.992,38.956,46.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.917 | Acc: 30.059,38.922,46.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.933 | Acc: 29.974,38.865,46.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.928 | Acc: 29.983,38.860,46.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.938 | Acc: 29.982,38.875,46.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.935 | Acc: 29.967,38.925,46.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.942 | Acc: 29.878,38.820,46.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.942 | Acc: 29.866,38.771,46.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.291 | Acc: 28.125,35.938,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.418 | Acc: 26.451,35.193,43.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.404 | Acc: 26.562,35.252,43.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.387 | Acc: 26.268,35.079,43.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 7.298 | Acc: 21.875,35.938,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.960 | Acc: 29.092,38.244,45.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.834 | Acc: 29.935,39.710,47.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.831 | Acc: 30.072,39.677,47.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.798 | Acc: 30.237,39.873,47.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.772 | Acc: 30.407,40.300,48.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.762 | Acc: 30.553,40.218,48.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.786 | Acc: 30.341,39.993,48.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.790 | Acc: 30.323,39.931,47.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.797 | Acc: 30.149,39.809,47.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.788 | Acc: 30.243,39.906,47.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.798 | Acc: 30.296,39.953,47.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.801 | Acc: 30.349,40.045,47.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.822 | Acc: 30.325,39.957,47.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.820 | Acc: 30.421,39.924,47.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.824 | Acc: 30.318,39.914,47.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.813 | Acc: 30.384,39.956,47.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.813 | Acc: 30.373,39.906,47.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.813 | Acc: 30.430,39.878,47.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.808 | Acc: 30.547,39.975,47.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.265 | Acc: 25.781,29.688,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.552 | Acc: 25.558,27.158,39.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.512 | Acc: 25.610,27.344,39.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.571 | Acc: 24.821,26.972,38.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 6.018 | Acc: 40.625,42.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.648 | Acc: 32.254,41.778,49.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.763 | Acc: 30.983,40.149,48.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.729 | Acc: 31.032,40.484,48.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.725 | Acc: 30.980,40.683,48.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.693 | Acc: 31.018,40.888,48.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.690 | Acc: 30.979,40.941,48.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.697 | Acc: 30.807,40.847,48.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.687 | Acc: 30.959,40.892,48.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.691 | Acc: 31.069,40.836,48.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.686 | Acc: 31.219,40.831,48.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.685 | Acc: 31.243,40.880,48.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.670 | Acc: 31.240,41.085,48.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.664 | Acc: 31.334,41.194,48.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.676 | Acc: 31.269,41.084,48.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.672 | Acc: 31.328,41.110,48.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.672 | Acc: 31.384,41.175,48.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.671 | Acc: 31.353,41.200,48.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.665 | Acc: 31.365,41.259,48.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.658 | Acc: 31.410,41.277,48.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.110 | Acc: 36.719,40.625,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.448 | Acc: 25.893,37.872,44.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.460 | Acc: 25.648,37.729,44.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.472 | Acc: 25.666,37.334,44.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 6.953 | Acc: 28.906,42.969,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.582 | Acc: 31.920,41.890,49.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.587 | Acc: 31.764,41.959,49.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.531 | Acc: 32.018,42.277,49.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.527 | Acc: 31.694,42.139,49.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.559 | Acc: 31.606,41.584,49.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.561 | Acc: 31.586,41.742,49.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.545 | Acc: 31.810,42.043,49.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.522 | Acc: 32.046,42.202,49.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.512 | Acc: 32.169,42.295,49.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.534 | Acc: 32.074,42.079,49.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.540 | Acc: 32.084,42.067,49.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.541 | Acc: 32.154,42.149,49.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.538 | Acc: 32.193,42.155,49.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.528 | Acc: 32.384,42.285,49.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.528 | Acc: 32.327,42.320,49.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.528 | Acc: 32.318,42.353,49.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.537 | Acc: 32.260,42.302,49.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.542 | Acc: 32.174,42.226,49.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.555 | Acc: 32.029,42.097,49.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.835 | Acc: 27.344,34.375,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.501 | Acc: 27.939,35.045,43.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.461 | Acc: 28.754,35.575,43.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.448 | Acc: 28.612,36.053,43.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 6.490 | Acc: 30.469,40.625,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.510 | Acc: 32.366,41.741,50.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.493 | Acc: 32.908,41.902,51.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.452 | Acc: 32.659,41.970,50.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.448 | Acc: 32.764,42.274,50.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.460 | Acc: 32.596,42.520,50.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.466 | Acc: 32.367,42.510,50.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.460 | Acc: 32.524,42.686,50.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.422 | Acc: 32.730,43.148,51.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.418 | Acc: 32.838,43.349,51.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.400 | Acc: 32.855,43.622,51.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.405 | Acc: 32.866,43.520,51.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.410 | Acc: 32.890,43.491,51.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.417 | Acc: 32.681,43.343,50.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.429 | Acc: 32.618,43.258,50.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.433 | Acc: 32.566,43.246,50.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.429 | Acc: 32.647,43.346,50.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.433 | Acc: 32.622,43.344,50.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.433 | Acc: 32.613,43.332,50.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.431 | Acc: 32.591,43.420,50.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.954 | Acc: 26.562,35.156,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.444 | Acc: 27.381,36.830,47.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.511 | Acc: 27.268,36.147,45.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.564 | Acc: 26.934,35.745,44.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 6.512 | Acc: 27.344,40.625,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.268 | Acc: 33.854,45.833,51.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.290 | Acc: 32.851,44.474,51.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.297 | Acc: 32.723,44.339,51.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.346 | Acc: 32.542,43.866,51.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.370 | Acc: 32.859,43.758,51.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.372 | Acc: 32.884,43.750,51.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.371 | Acc: 32.862,43.750,51.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.374 | Acc: 32.885,43.643,51.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.376 | Acc: 32.864,43.655,51.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.364 | Acc: 32.886,43.711,51.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.358 | Acc: 32.858,43.732,51.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.350 | Acc: 32.825,43.828,51.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.360 | Acc: 32.753,43.918,51.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.359 | Acc: 32.707,43.959,51.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.349 | Acc: 32.805,43.991,51.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.346 | Acc: 32.810,44.069,51.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.348 | Acc: 32.796,44.043,51.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.343 | Acc: 32.804,44.070,51.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.337 | Acc: 32.837,44.082,51.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.878 | Acc: 29.688,41.406,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.148 | Acc: 28.348,40.030,47.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.132 | Acc: 27.992,39.367,46.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.147 | Acc: 27.638,39.139,46.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 5.895 | Acc: 39.844,50.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.100 | Acc: 34.040,45.536,53.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.110 | Acc: 34.108,45.236,54.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.169 | Acc: 34.029,45.108,53.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.172 | Acc: 34.153,45.351,53.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.173 | Acc: 33.957,45.514,53.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.203 | Acc: 33.858,45.384,53.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.198 | Acc: 33.871,45.379,53.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.201 | Acc: 33.827,45.424,53.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.208 | Acc: 33.732,45.537,53.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.196 | Acc: 33.765,45.476,53.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.201 | Acc: 33.781,45.426,53.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.200 | Acc: 33.749,45.445,53.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.208 | Acc: 33.663,45.384,53.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.216 | Acc: 33.580,45.293,53.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.227 | Acc: 33.396,45.107,52.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.219 | Acc: 33.382,45.096,52.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.221 | Acc: 33.323,45.077,52.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.222 | Acc: 33.375,45.135,53.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.223 | Acc: 33.380,45.109,52.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.920 | Acc: 22.656,35.938,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.476 | Acc: 28.125,37.500,45.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.439 | Acc: 28.544,37.367,45.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.430 | Acc: 28.189,37.666,45.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 6.218 | Acc: 31.250,45.312,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.195 | Acc: 34.561,46.726,54.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.111 | Acc: 35.175,47.409,54.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.080 | Acc: 34.810,47.298,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.111 | Acc: 34.057,46.875,54.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.134 | Acc: 33.710,46.542,54.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.143 | Acc: 33.729,46.539,54.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.139 | Acc: 33.793,46.554,54.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.108 | Acc: 34.006,46.860,54.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.117 | Acc: 33.939,46.780,54.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.123 | Acc: 33.920,46.696,53.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.125 | Acc: 33.760,46.631,53.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.131 | Acc: 33.727,46.509,53.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.132 | Acc: 33.684,46.546,53.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.141 | Acc: 33.633,46.475,53.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.150 | Acc: 33.653,46.403,53.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.153 | Acc: 33.569,46.332,53.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.150 | Acc: 33.610,46.341,53.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.146 | Acc: 33.587,46.377,53.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.158 | Acc: 33.495,46.266,53.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.085 | Acc: 27.344,46.094,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.383 | Acc: 23.400,39.509,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.353 | Acc: 23.838,39.329,49.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.343 | Acc: 24.116,39.088,48.630,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 5.268 | Acc: 40.625,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.927 | Acc: 34.970,48.214,56.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.001 | Acc: 34.508,47.409,55.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.041 | Acc: 34.260,47.503,55.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.057 | Acc: 34.539,47.550,55.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.078 | Acc: 34.282,47.169,55.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.095 | Acc: 34.104,46.894,54.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.097 | Acc: 34.048,46.742,54.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.093 | Acc: 34.191,46.793,54.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.091 | Acc: 34.189,46.866,54.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.088 | Acc: 34.029,46.856,54.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.097 | Acc: 33.976,46.748,54.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.089 | Acc: 33.989,46.645,54.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.083 | Acc: 34.025,46.695,54.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.078 | Acc: 34.072,46.742,54.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.082 | Acc: 33.913,46.652,54.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.071 | Acc: 34.029,46.727,54.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.064 | Acc: 34.057,46.790,54.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.059 | Acc: 34.117,46.907,54.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.059 | Acc: 34.088,46.965,54.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.499 | Acc: 33.594,40.625,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.135 | Acc: 27.939,38.504,47.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.205 | Acc: 28.201,37.805,46.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.201 | Acc: 28.176,38.307,46.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 5.654 | Acc: 39.062,51.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.799 | Acc: 35.640,48.772,57.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.882 | Acc: 34.947,48.380,56.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.857 | Acc: 35.259,48.514,56.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.888 | Acc: 35.185,48.399,56.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.901 | Acc: 35.032,48.190,56.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.913 | Acc: 34.911,48.024,55.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.921 | Acc: 34.912,48.000,56.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.947 | Acc: 34.676,47.778,55.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.957 | Acc: 34.647,47.825,55.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.966 | Acc: 34.589,47.734,55.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.959 | Acc: 34.601,47.833,55.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.974 | Acc: 34.586,47.809,55.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.977 | Acc: 34.573,47.803,55.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.976 | Acc: 34.647,47.823,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.989 | Acc: 34.609,47.752,55.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.997 | Acc: 34.536,47.654,55.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.002 | Acc: 34.439,47.654,55.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.004 | Acc: 34.444,47.591,55.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.005 | Acc: 34.445,47.644,55.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.827 | Acc: 20.312,39.062,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.619 | Acc: 25.298,37.984,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.716 | Acc: 25.438,37.176,46.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.733 | Acc: 25.474,37.641,47.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 5.787 | Acc: 35.156,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.733 | Acc: 35.603,47.805,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.883 | Acc: 35.118,47.504,55.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.939 | Acc: 34.695,47.298,55.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.916 | Acc: 34.433,47.492,55.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.913 | Acc: 34.352,47.571,55.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.919 | Acc: 34.356,47.585,55.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.908 | Acc: 34.519,47.717,56.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.903 | Acc: 34.656,47.681,56.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.894 | Acc: 34.625,47.838,56.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.905 | Acc: 34.519,47.831,56.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.910 | Acc: 34.520,47.960,56.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.907 | Acc: 34.505,47.977,55.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.912 | Acc: 34.540,47.971,55.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.922 | Acc: 34.456,47.887,55.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.935 | Acc: 34.318,47.872,55.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.934 | Acc: 34.341,47.929,55.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.932 | Acc: 34.409,47.998,55.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.937 | Acc: 34.392,47.970,55.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.937 | Acc: 34.371,48.019,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.539 | Acc: 27.344,41.406,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.444 | Acc: 25.670,37.537,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.542 | Acc: 25.019,36.986,46.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.582 | Acc: 24.616,36.911,46.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 6.223 | Acc: 24.219,47.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.674 | Acc: 36.533,50.000,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.734 | Acc: 35.690,50.210,56.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.720 | Acc: 36.104,50.282,57.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.776 | Acc: 35.745,50.039,57.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.797 | Acc: 35.613,49.729,57.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.802 | Acc: 35.363,49.400,56.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.797 | Acc: 35.328,49.363,56.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.803 | Acc: 35.447,49.423,56.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.809 | Acc: 35.385,49.400,56.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.829 | Acc: 35.234,49.215,56.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.822 | Acc: 35.266,49.392,56.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.824 | Acc: 35.169,49.310,56.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.826 | Acc: 35.123,49.309,56.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.829 | Acc: 35.120,49.260,56.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.839 | Acc: 35.172,49.110,56.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.849 | Acc: 35.098,48.961,56.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.856 | Acc: 35.097,48.912,56.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.860 | Acc: 34.985,48.885,56.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.862 | Acc: 34.976,48.885,56.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.271 | Acc: 25.000,39.062,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.212 | Acc: 27.567,40.365,48.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.218 | Acc: 27.725,39.920,48.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.224 | Acc: 28.087,39.857,48.348,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 5.641 | Acc: 33.594,48.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.797 | Acc: 34.710,48.549,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.862 | Acc: 34.489,48.266,57.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.821 | Acc: 34.657,48.963,57.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.809 | Acc: 34.703,49.450,57.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.827 | Acc: 34.468,49.056,57.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.847 | Acc: 34.530,48.889,56.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.847 | Acc: 34.646,48.969,56.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.846 | Acc: 34.574,49.015,56.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.840 | Acc: 34.552,49.042,56.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.819 | Acc: 34.787,49.370,56.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.823 | Acc: 34.824,49.268,56.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.823 | Acc: 34.667,49.293,57.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.817 | Acc: 34.779,49.485,57.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.815 | Acc: 34.809,49.402,57.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.813 | Acc: 34.897,49.478,57.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.813 | Acc: 34.932,49.455,57.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.809 | Acc: 34.888,49.512,57.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.811 | Acc: 34.927,49.468,57.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.813 | Acc: 34.968,49.461,57.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.221 | Acc: 22.656,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.939 | Acc: 26.302,43.378,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.066 | Acc: 26.429,41.768,51.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.077 | Acc: 26.012,41.714,50.628,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 6.118 | Acc: 34.375,49.219,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.675 | Acc: 34.524,51.079,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.651 | Acc: 35.385,51.391,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.660 | Acc: 35.297,51.089,58.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.665 | Acc: 35.253,50.675,58.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.723 | Acc: 34.978,50.271,57.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.725 | Acc: 34.859,50.155,57.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.730 | Acc: 34.918,50.238,57.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.719 | Acc: 35.117,50.369,57.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.715 | Acc: 35.178,50.371,58.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.732 | Acc: 35.195,50.323,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.733 | Acc: 35.167,50.286,58.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.727 | Acc: 35.237,50.366,58.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.729 | Acc: 35.159,50.335,58.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.745 | Acc: 35.059,50.270,57.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.747 | Acc: 35.006,50.182,57.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.748 | Acc: 35.039,50.165,57.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.745 | Acc: 35.117,50.229,57.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.742 | Acc: 35.221,50.277,57.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.740 | Acc: 35.341,50.308,57.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.972 | Acc: 34.375,41.406,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.196 | Acc: 28.162,40.774,46.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.199 | Acc: 28.659,40.282,47.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.209 | Acc: 27.984,40.420,47.374,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 5.132 | Acc: 45.312,55.469,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.554 | Acc: 37.128,51.376,60.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.596 | Acc: 36.261,51.543,60.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.547 | Acc: 36.514,52.113,60.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.548 | Acc: 35.976,52.064,60.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.562 | Acc: 36.255,51.872,59.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.568 | Acc: 36.312,51.905,59.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.576 | Acc: 36.436,51.751,59.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.591 | Acc: 36.530,51.703,59.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.612 | Acc: 36.278,51.329,59.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.619 | Acc: 36.361,51.232,59.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.614 | Acc: 36.238,51.269,59.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.623 | Acc: 36.035,51.157,59.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.643 | Acc: 35.800,51.012,58.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.649 | Acc: 35.626,50.929,58.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.652 | Acc: 35.585,50.888,58.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.648 | Acc: 35.718,50.942,58.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.660 | Acc: 35.660,50.868,58.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.664 | Acc: 35.708,50.866,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.667 | Acc: 35.749,50.798,58.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.249 | Acc: 20.312,37.500,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.950 | Acc: 25.744,36.942,46.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.982 | Acc: 25.362,36.871,46.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.007 | Acc: 24.872,36.693,45.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 6.105 | Acc: 32.031,48.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.482 | Acc: 36.310,52.381,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.504 | Acc: 35.957,52.382,59.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.512 | Acc: 35.899,51.755,59.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.530 | Acc: 35.754,51.543,59.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.534 | Acc: 35.806,51.508,59.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.559 | Acc: 35.847,51.459,59.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.573 | Acc: 35.871,51.502,59.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.578 | Acc: 35.831,51.441,59.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.567 | Acc: 35.825,51.502,59.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.580 | Acc: 35.794,51.430,59.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.585 | Acc: 35.863,51.290,59.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.597 | Acc: 35.892,51.186,58.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.601 | Acc: 35.973,51.158,58.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.597 | Acc: 35.996,51.182,58.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.600 | Acc: 36.031,51.171,58.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.609 | Acc: 36.037,51.083,58.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.608 | Acc: 36.080,51.075,58.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.609 | Acc: 36.065,51.084,58.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.603 | Acc: 36.141,51.152,58.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.572 | Acc: 28.125,42.969,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.778 | Acc: 28.906,44.531,51.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.861 | Acc: 28.601,44.131,50.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.899 | Acc: 28.087,43.430,49.898,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 5.475 | Acc: 36.719,56.250,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.737 | Acc: 34.152,50.000,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.577 | Acc: 35.537,51.639,59.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.529 | Acc: 35.669,51.755,59.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.538 | Acc: 35.909,51.794,59.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.555 | Acc: 35.783,51.694,59.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.553 | Acc: 35.744,51.743,59.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.555 | Acc: 35.932,51.745,59.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.569 | Acc: 35.850,51.621,59.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.566 | Acc: 35.881,51.731,59.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.569 | Acc: 35.801,51.640,59.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.567 | Acc: 35.902,51.775,59.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.568 | Acc: 35.856,51.776,59.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.578 | Acc: 35.860,51.769,59.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.578 | Acc: 35.754,51.760,59.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.580 | Acc: 35.800,51.723,59.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.575 | Acc: 35.935,51.796,59.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.569 | Acc: 35.958,51.897,59.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.568 | Acc: 35.976,51.943,59.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.574 | Acc: 35.938,51.899,59.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.297 | Acc: 30.469,42.969,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.998 | Acc: 27.939,41.443,51.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.015 | Acc: 27.630,40.739,50.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.030 | Acc: 27.497,41.214,50.743,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.389 | Acc: 34.375,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.440 | Acc: 36.830,52.604,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.366 | Acc: 37.252,54.021,61.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.339 | Acc: 37.462,54.726,61.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.340 | Acc: 37.432,54.620,61.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.383 | Acc: 37.291,54.022,61.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.428 | Acc: 37.080,53.596,60.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.427 | Acc: 36.885,53.674,60.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.447 | Acc: 36.685,53.358,60.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.470 | Acc: 36.395,52.948,60.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.487 | Acc: 36.443,52.725,60.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.510 | Acc: 36.323,52.372,60.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.526 | Acc: 36.291,52.295,60.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.529 | Acc: 36.201,52.284,59.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.539 | Acc: 36.135,52.202,59.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.542 | Acc: 36.127,52.294,59.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.542 | Acc: 36.186,52.271,59.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.550 | Acc: 36.160,52.165,59.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.544 | Acc: 36.212,52.238,59.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.554 | Acc: 36.186,52.114,59.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.159 | Acc: 28.906,40.625,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.213 | Acc: 28.646,40.737,48.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.235 | Acc: 28.144,40.835,48.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.234 | Acc: 27.561,40.126,47.772,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 5.433 | Acc: 36.719,53.906,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.351 | Acc: 36.049,54.278,62.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.376 | Acc: 35.938,53.125,62.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.408 | Acc: 36.270,53.266,61.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.427 | Acc: 36.265,53.376,61.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.441 | Acc: 36.255,53.187,61.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.425 | Acc: 36.557,53.332,61.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.426 | Acc: 36.658,53.402,61.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.441 | Acc: 36.690,53.363,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.461 | Acc: 36.537,52.996,60.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.472 | Acc: 36.528,52.896,60.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.490 | Acc: 36.496,52.835,60.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.487 | Acc: 36.563,52.778,60.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.473 | Acc: 36.722,52.871,60.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.482 | Acc: 36.569,52.830,60.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.488 | Acc: 36.506,52.738,60.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.485 | Acc: 36.597,52.738,60.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.488 | Acc: 36.552,52.671,60.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.488 | Acc: 36.496,52.658,60.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.492 | Acc: 36.526,52.672,60.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.606 | Acc: 29.688,50.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.420 | Acc: 30.432,45.461,54.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.428 | Acc: 31.098,45.694,54.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.471 | Acc: 30.622,44.941,53.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 5.720 | Acc: 33.594,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.377 | Acc: 37.128,53.311,62.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.354 | Acc: 36.947,53.544,62.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.340 | Acc: 37.129,53.548,61.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.328 | Acc: 37.220,54.003,62.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.346 | Acc: 36.951,53.489,61.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.364 | Acc: 36.719,53.351,61.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.381 | Acc: 36.780,53.258,61.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.394 | Acc: 36.966,53.149,61.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.416 | Acc: 36.909,53.013,60.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.418 | Acc: 36.866,53.074,60.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.425 | Acc: 36.705,53.090,60.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.431 | Acc: 36.686,53.054,60.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.431 | Acc: 36.815,53.116,60.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.434 | Acc: 36.802,53.047,60.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.436 | Acc: 36.729,52.998,60.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.437 | Acc: 36.777,53.008,60.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.437 | Acc: 36.765,53.026,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.447 | Acc: 36.688,53.015,60.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.444 | Acc: 36.752,53.002,60.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.858 | Acc: 30.469,48.438,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.240 | Acc: 26.190,41.964,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.273 | Acc: 26.220,41.292,51.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.276 | Acc: 26.153,41.368,50.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 5.697 | Acc: 31.250,47.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.391 | Acc: 35.565,51.749,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.436 | Acc: 36.128,52.649,60.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.397 | Acc: 36.757,53.215,62.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.367 | Acc: 37.114,53.453,62.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.395 | Acc: 36.843,53.195,62.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.397 | Acc: 36.971,53.248,62.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.411 | Acc: 36.841,53.059,61.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.402 | Acc: 36.966,53.154,61.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.406 | Acc: 36.848,53.047,61.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.409 | Acc: 36.874,53.032,61.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.415 | Acc: 36.860,52.962,61.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.407 | Acc: 36.900,53.164,61.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.402 | Acc: 36.955,53.224,61.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.410 | Acc: 36.944,53.220,61.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.412 | Acc: 36.947,53.226,61.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.420 | Acc: 36.831,53.125,61.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.420 | Acc: 36.776,53.065,61.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.412 | Acc: 36.881,53.170,61.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.414 | Acc: 36.934,53.146,61.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.841 | Acc: 32.031,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.021 | Acc: 28.981,43.490,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.995 | Acc: 28.887,42.988,51.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.982 | Acc: 28.573,42.892,51.140,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 5.495 | Acc: 35.938,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.226 | Acc: 37.612,54.725,63.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.283 | Acc: 37.005,54.345,62.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.281 | Acc: 37.628,54.111,62.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.302 | Acc: 37.780,54.186,62.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.294 | Acc: 37.755,54.293,62.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.317 | Acc: 37.668,54.429,62.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.316 | Acc: 37.528,54.300,62.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.320 | Acc: 37.563,54.265,62.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.339 | Acc: 37.323,53.975,61.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.348 | Acc: 37.135,53.914,61.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.346 | Acc: 37.069,53.882,61.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.354 | Acc: 37.069,53.861,61.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.351 | Acc: 37.072,53.897,61.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.366 | Acc: 36.927,53.823,61.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.368 | Acc: 36.971,53.836,61.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.373 | Acc: 36.986,53.770,61.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.375 | Acc: 37.030,53.799,61.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.370 | Acc: 37.056,53.826,61.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.373 | Acc: 37.026,53.800,61.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.618 | Acc: 27.344,45.312,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.704 | Acc: 28.683,43.527,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.707 | Acc: 29.154,43.121,53.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.718 | Acc: 28.996,43.122,53.125,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 5.418 | Acc: 35.938,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.188 | Acc: 36.830,53.757,62.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.190 | Acc: 37.424,54.954,63.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.209 | Acc: 37.846,54.636,63.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.225 | Acc: 37.616,54.620,63.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.249 | Acc: 37.392,54.347,62.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.269 | Acc: 37.100,54.261,62.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.265 | Acc: 37.190,54.538,62.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.278 | Acc: 37.146,54.566,62.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.275 | Acc: 37.211,54.562,62.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.283 | Acc: 37.197,54.454,62.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.294 | Acc: 37.196,54.458,62.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.303 | Acc: 37.195,54.347,62.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.298 | Acc: 37.293,54.469,62.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.300 | Acc: 37.317,54.493,62.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.295 | Acc: 37.344,54.475,62.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.302 | Acc: 37.383,54.454,62.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.300 | Acc: 37.381,54.497,62.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.301 | Acc: 37.372,54.488,62.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.310 | Acc: 37.387,54.476,62.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.406 | Acc: 30.469,41.406,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.958 | Acc: 27.641,43.006,50.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.956 | Acc: 27.668,43.045,49.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.968 | Acc: 27.267,43.058,49.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 5.130 | Acc: 39.844,53.906,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.367 | Acc: 36.830,53.981,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.281 | Acc: 37.729,54.802,62.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.275 | Acc: 37.628,55.008,62.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.253 | Acc: 37.867,54.958,63.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.243 | Acc: 37.879,54.711,63.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.263 | Acc: 37.984,54.545,62.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.266 | Acc: 37.749,54.488,62.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.275 | Acc: 37.704,54.421,62.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.273 | Acc: 37.686,54.502,62.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.271 | Acc: 37.655,54.571,62.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.275 | Acc: 37.553,54.543,62.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.276 | Acc: 37.568,54.464,62.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.275 | Acc: 37.569,54.493,62.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.281 | Acc: 37.472,54.462,62.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.285 | Acc: 37.510,54.506,62.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.295 | Acc: 37.478,54.478,62.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.301 | Acc: 37.408,54.383,62.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.299 | Acc: 37.390,54.341,62.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.306 | Acc: 37.332,54.277,62.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.562 | Acc: 33.594,47.656,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.372 | Acc: 31.510,48.214,54.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.372 | Acc: 31.726,48.018,54.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.377 | Acc: 31.749,48.028,53.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 5.349 | Acc: 37.500,56.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.102 | Acc: 37.909,56.659,64.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.078 | Acc: 37.748,56.688,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.140 | Acc: 37.731,55.610,64.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.147 | Acc: 37.780,55.363,64.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.143 | Acc: 37.987,55.322,64.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.181 | Acc: 38.055,55.346,63.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.201 | Acc: 37.899,55.098,63.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.202 | Acc: 37.714,55.173,63.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.218 | Acc: 37.716,54.977,63.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.234 | Acc: 37.601,54.812,63.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.248 | Acc: 37.553,54.673,63.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.250 | Acc: 37.494,54.720,62.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.252 | Acc: 37.629,54.646,62.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.251 | Acc: 37.686,54.662,62.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.258 | Acc: 37.653,54.628,62.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.261 | Acc: 37.583,54.595,62.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.264 | Acc: 37.514,54.571,62.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.265 | Acc: 37.509,54.655,62.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.271 | Acc: 37.500,54.657,62.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.777 | Acc: 29.688,43.750,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.694 | Acc: 29.948,45.387,54.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.724 | Acc: 30.011,44.036,53.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.719 | Acc: 29.611,44.237,53.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 5.201 | Acc: 29.688,53.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.141 | Acc: 39.100,55.357,63.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.131 | Acc: 38.014,55.545,64.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.099 | Acc: 38.601,55.994,65.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.135 | Acc: 38.378,55.970,64.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.140 | Acc: 38.575,55.879,64.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.144 | Acc: 38.365,55.766,64.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.172 | Acc: 38.220,55.657,63.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.179 | Acc: 38.267,55.595,63.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.176 | Acc: 38.186,55.486,63.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.176 | Acc: 38.382,55.648,63.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.196 | Acc: 38.228,55.585,63.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.207 | Acc: 38.158,55.534,63.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.215 | Acc: 38.150,55.406,63.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.214 | Acc: 38.176,55.296,63.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.227 | Acc: 38.066,55.155,62.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.222 | Acc: 38.145,55.155,63.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.229 | Acc: 38.121,55.143,62.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.233 | Acc: 38.186,55.135,62.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.231 | Acc: 38.195,55.118,62.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.905 | Acc: 27.344,44.531,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.110 | Acc: 24.814,43.378,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.207 | Acc: 24.390,42.511,52.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.199 | Acc: 24.385,42.892,53.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 5.412 | Acc: 35.938,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.180 | Acc: 37.686,53.869,64.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.122 | Acc: 38.510,55.564,64.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.131 | Acc: 38.166,55.123,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.140 | Acc: 38.233,55.411,64.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.147 | Acc: 38.250,55.399,64.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.156 | Acc: 37.829,55.436,64.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.163 | Acc: 37.794,55.291,64.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.182 | Acc: 37.777,55.280,63.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.190 | Acc: 37.673,55.197,63.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.192 | Acc: 37.745,55.173,63.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.184 | Acc: 37.829,55.186,63.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.178 | Acc: 37.964,55.320,63.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.183 | Acc: 37.883,55.271,63.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.192 | Acc: 37.784,55.163,63.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.206 | Acc: 37.700,54.981,63.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.209 | Acc: 37.612,54.955,63.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.210 | Acc: 37.546,54.974,63.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.212 | Acc: 37.600,54.967,63.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.215 | Acc: 37.590,54.979,63.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.950 | Acc: 30.469,43.750,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.739 | Acc: 27.790,44.420,53.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.809 | Acc: 27.134,44.093,52.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.837 | Acc: 26.985,44.134,52.152,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 4.847 | Acc: 44.531,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.085 | Acc: 38.988,56.027,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.108 | Acc: 37.881,56.536,65.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.178 | Acc: 37.090,55.789,64.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.132 | Acc: 37.596,56.047,65.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.151 | Acc: 37.136,55.709,64.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.140 | Acc: 37.229,55.888,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.135 | Acc: 37.478,55.884,64.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.135 | Acc: 37.524,56.017,64.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.123 | Acc: 37.768,56.034,64.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.136 | Acc: 37.702,55.966,64.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.145 | Acc: 37.772,55.889,64.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.147 | Acc: 37.892,55.893,64.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.157 | Acc: 37.991,55.948,64.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.166 | Acc: 37.984,55.822,64.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.169 | Acc: 37.949,55.793,64.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.173 | Acc: 37.965,55.705,64.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.171 | Acc: 38.015,55.686,63.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.173 | Acc: 37.980,55.657,63.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.179 | Acc: 37.953,55.559,63.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.375 | Acc: 31.250,44.531,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.415 | Acc: 28.348,41.853,50.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.410 | Acc: 28.201,42.073,50.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.423 | Acc: 27.459,42.546,50.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 6.346 | Acc: 25.000,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.975 | Acc: 38.839,57.775,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.012 | Acc: 38.758,56.479,66.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.049 | Acc: 38.755,56.288,65.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.051 | Acc: 38.899,56.289,65.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.057 | Acc: 39.109,56.227,65.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.063 | Acc: 39.159,56.457,64.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.056 | Acc: 39.118,56.699,65.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.077 | Acc: 38.854,56.585,65.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.098 | Acc: 38.614,56.453,64.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.115 | Acc: 38.382,56.273,64.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.142 | Acc: 38.218,55.946,64.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.137 | Acc: 38.236,56.036,64.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.146 | Acc: 38.281,55.918,64.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.140 | Acc: 38.367,55.972,64.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.134 | Acc: 38.362,55.959,64.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.139 | Acc: 38.301,55.885,64.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.149 | Acc: 38.238,55.808,63.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.156 | Acc: 38.149,55.733,63.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.154 | Acc: 38.205,55.801,63.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.913 | Acc: 27.344,46.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.721 | Acc: 30.692,43.899,53.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.835 | Acc: 29.783,43.007,52.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.857 | Acc: 29.752,42.764,51.895,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 5.432 | Acc: 32.812,52.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.052 | Acc: 38.095,57.031,63.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.005 | Acc: 38.967,57.260,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.037 | Acc: 38.525,56.942,64.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.066 | Acc: 38.059,56.588,64.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.068 | Acc: 38.049,56.528,64.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.078 | Acc: 38.146,56.605,64.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.071 | Acc: 38.270,56.538,64.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.079 | Acc: 38.107,56.502,64.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.090 | Acc: 38.035,56.500,64.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.097 | Acc: 37.931,56.386,64.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.100 | Acc: 37.864,56.501,64.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.098 | Acc: 37.905,56.509,64.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.104 | Acc: 37.868,56.400,64.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.109 | Acc: 37.936,56.317,64.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.108 | Acc: 37.978,56.390,64.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.116 | Acc: 37.933,56.360,64.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.115 | Acc: 37.942,56.321,64.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.127 | Acc: 37.946,56.129,64.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.129 | Acc: 37.980,56.186,64.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.463 | Acc: 25.781,39.062,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.766 | Acc: 30.915,44.085,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.824 | Acc: 30.545,43.941,52.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.845 | Acc: 29.777,43.929,52.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 5.062 | Acc: 39.844,57.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.944 | Acc: 38.914,57.068,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.005 | Acc: 38.681,56.993,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.949 | Acc: 38.768,57.659,66.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.977 | Acc: 38.764,57.330,66.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.998 | Acc: 38.761,57.047,65.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.040 | Acc: 38.410,56.741,65.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.044 | Acc: 38.453,56.677,65.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.059 | Acc: 38.199,56.565,65.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.060 | Acc: 38.484,56.638,64.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.070 | Acc: 38.464,56.503,64.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.073 | Acc: 38.472,56.388,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.087 | Acc: 38.456,56.250,64.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.090 | Acc: 38.425,56.232,64.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.088 | Acc: 38.426,56.328,64.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.086 | Acc: 38.421,56.273,64.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.091 | Acc: 38.340,56.211,64.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.091 | Acc: 38.345,56.190,64.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.094 | Acc: 38.374,56.259,64.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.092 | Acc: 38.470,56.271,64.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.912 | Acc: 22.656,44.531,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.980 | Acc: 26.302,43.899,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.955 | Acc: 25.686,43.845,51.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.930 | Acc: 25.141,44.057,52.100,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 5.162 | Acc: 34.375,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.087 | Acc: 36.942,56.213,65.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.062 | Acc: 37.881,56.326,65.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.036 | Acc: 38.397,57.364,65.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.049 | Acc: 38.358,57.147,65.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.051 | Acc: 38.475,56.931,65.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.050 | Acc: 38.423,57.051,65.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.042 | Acc: 38.503,57.281,65.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.038 | Acc: 38.437,57.284,65.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.047 | Acc: 38.359,57.165,65.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.043 | Acc: 38.413,57.066,65.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.061 | Acc: 38.246,56.872,65.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.060 | Acc: 38.356,56.921,64.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.065 | Acc: 38.269,56.900,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.064 | Acc: 38.190,56.837,64.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.059 | Acc: 38.297,56.826,64.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.061 | Acc: 38.323,56.873,64.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.067 | Acc: 38.327,56.754,64.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.070 | Acc: 38.262,56.666,64.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.068 | Acc: 38.330,56.674,64.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.235 | Acc: 28.125,54.688,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.221 | Acc: 28.571,48.810,57.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.263 | Acc: 28.011,48.990,56.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.264 | Acc: 28.535,49.142,56.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 4.978 | Acc: 39.844,58.594,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.940 | Acc: 37.612,57.701,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.934 | Acc: 38.472,57.717,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.967 | Acc: 38.281,57.608,66.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.987 | Acc: 38.079,57.350,65.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.011 | Acc: 37.871,57.364,65.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.003 | Acc: 37.900,57.393,65.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.017 | Acc: 37.882,57.125,65.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.021 | Acc: 37.912,57.133,65.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.024 | Acc: 37.962,56.979,65.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.020 | Acc: 38.184,57.066,65.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.031 | Acc: 38.168,56.922,65.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.046 | Acc: 38.132,56.798,65.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.061 | Acc: 38.108,56.696,64.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.067 | Acc: 38.126,56.531,64.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.077 | Acc: 38.087,56.468,64.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.077 | Acc: 38.130,56.467,64.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.073 | Acc: 38.187,56.513,64.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.066 | Acc: 38.249,56.583,64.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.061 | Acc: 38.314,56.654,64.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.655 | Acc: 17.969,43.750,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.924 | Acc: 20.536,40.960,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.079 | Acc: 20.198,40.149,51.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.085 | Acc: 20.018,39.882,51.217,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 4.738 | Acc: 37.500,54.688,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.840 | Acc: 38.504,58.185,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.860 | Acc: 39.253,58.041,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.915 | Acc: 38.896,57.672,66.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.951 | Acc: 38.715,57.456,66.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.947 | Acc: 38.815,57.457,66.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.946 | Acc: 38.830,57.361,66.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.939 | Acc: 38.885,57.502,66.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.941 | Acc: 38.893,57.570,66.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.953 | Acc: 39.011,57.519,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.964 | Acc: 38.837,57.420,66.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.959 | Acc: 38.914,57.459,66.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.971 | Acc: 38.943,57.362,65.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.969 | Acc: 38.997,57.390,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.987 | Acc: 38.879,57.240,65.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.995 | Acc: 38.868,57.190,65.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.994 | Acc: 38.780,57.204,65.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.003 | Acc: 38.673,57.134,65.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.007 | Acc: 38.589,57.077,65.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.004 | Acc: 38.618,57.054,65.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.722 | Acc: 27.344,53.125,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.917 | Acc: 28.460,45.424,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.941 | Acc: 27.973,44.627,51.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.965 | Acc: 28.112,44.429,51.178,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.642 | Acc: 40.625,57.031,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.996 | Acc: 37.500,56.101,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.964 | Acc: 38.338,56.917,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.937 | Acc: 38.845,56.929,66.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.918 | Acc: 38.831,57.523,66.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.934 | Acc: 38.908,57.457,66.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.939 | Acc: 38.991,57.361,66.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.965 | Acc: 38.691,57.258,65.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.984 | Acc: 38.422,57.182,65.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.986 | Acc: 38.406,57.178,65.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.995 | Acc: 38.398,57.074,65.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.989 | Acc: 38.476,57.113,65.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.989 | Acc: 38.586,57.135,65.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.997 | Acc: 38.628,57.100,65.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.011 | Acc: 38.440,56.998,65.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.017 | Acc: 38.406,56.935,65.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.019 | Acc: 38.495,56.939,65.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.014 | Acc: 38.655,56.963,65.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.012 | Acc: 38.656,57.053,65.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.010 | Acc: 38.712,57.087,65.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.291 | Acc: 34.375,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.394 | Acc: 29.985,48.103,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.415 | Acc: 29.592,47.142,55.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.426 | Acc: 29.047,47.387,55.725,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 5.307 | Acc: 39.844,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.954 | Acc: 37.798,57.775,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.983 | Acc: 37.824,56.955,65.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.923 | Acc: 38.320,57.659,65.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.957 | Acc: 37.818,57.417,65.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.964 | Acc: 37.848,57.170,65.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.964 | Acc: 38.223,57.206,65.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.959 | Acc: 38.370,57.209,65.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.962 | Acc: 38.335,57.216,65.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.977 | Acc: 38.208,57.217,65.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.972 | Acc: 38.262,57.249,65.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.966 | Acc: 38.377,57.328,65.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.960 | Acc: 38.424,57.414,65.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.977 | Acc: 38.422,57.271,65.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.983 | Acc: 38.495,57.223,65.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.982 | Acc: 38.445,57.327,65.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.977 | Acc: 38.556,57.326,65.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.976 | Acc: 38.584,57.350,65.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.985 | Acc: 38.502,57.293,65.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.987 | Acc: 38.513,57.277,65.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.182 | Acc: 29.688,42.188,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.686 | Acc: 27.121,45.610,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.768 | Acc: 27.553,45.179,54.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.809 | Acc: 26.883,45.056,54.060,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 5.060 | Acc: 39.844,60.938,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.866 | Acc: 39.472,58.333,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.820 | Acc: 40.701,59.204,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.813 | Acc: 40.420,59.004,67.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.838 | Acc: 39.747,59.144,67.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.840 | Acc: 39.790,58.919,67.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.840 | Acc: 39.657,59.072,67.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.862 | Acc: 39.517,58.777,67.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.879 | Acc: 39.465,58.506,66.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.900 | Acc: 39.408,58.356,66.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.912 | Acc: 39.498,58.384,66.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.911 | Acc: 39.543,58.378,66.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.927 | Acc: 39.419,58.205,66.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.940 | Acc: 39.386,58.088,66.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.941 | Acc: 39.243,58.013,66.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.947 | Acc: 39.184,57.787,65.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.952 | Acc: 39.223,57.808,65.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.973 | Acc: 39.092,57.686,65.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.970 | Acc: 39.073,57.748,65.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.970 | Acc: 39.087,57.767,65.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.776 | Acc: 28.906,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.530 | Acc: 29.315,46.875,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.549 | Acc: 29.154,46.589,55.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.569 | Acc: 29.188,46.926,55.225,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 4.092 | Acc: 45.312,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.828 | Acc: 39.509,59.115,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.886 | Acc: 39.615,58.460,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.904 | Acc: 39.677,58.440,67.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.896 | Acc: 39.506,58.767,67.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.919 | Acc: 39.202,58.292,66.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.929 | Acc: 39.360,58.264,66.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.927 | Acc: 39.273,58.084,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.933 | Acc: 39.160,58.026,66.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.928 | Acc: 39.218,58.128,66.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.926 | Acc: 39.140,58.139,66.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.917 | Acc: 39.165,58.276,66.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.928 | Acc: 39.241,58.114,66.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.931 | Acc: 39.152,58.034,66.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.930 | Acc: 39.190,58.046,66.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.939 | Acc: 39.179,58.002,66.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.943 | Acc: 39.216,57.932,66.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.941 | Acc: 39.136,57.897,66.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.938 | Acc: 39.207,57.888,66.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.943 | Acc: 39.171,57.886,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.239 | Acc: 17.188,46.875,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.371 | Acc: 22.247,45.908,52.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.313 | Acc: 22.218,45.694,53.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.295 | Acc: 22.131,46.273,52.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 4.968 | Acc: 40.625,56.250,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.858 | Acc: 38.876,58.557,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.828 | Acc: 38.948,59.070,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.790 | Acc: 39.331,59.401,67.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.812 | Acc: 39.458,58.980,67.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.831 | Acc: 39.271,58.756,67.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.848 | Acc: 39.205,58.684,67.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.840 | Acc: 39.362,58.638,67.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.851 | Acc: 39.436,58.613,67.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.870 | Acc: 39.352,58.464,66.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.881 | Acc: 39.362,58.384,66.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.879 | Acc: 39.349,58.325,66.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.885 | Acc: 39.166,58.390,66.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.899 | Acc: 39.131,58.256,66.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.902 | Acc: 39.104,58.216,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.905 | Acc: 39.050,58.116,66.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.908 | Acc: 39.097,58.097,66.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.907 | Acc: 39.175,58.110,66.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.912 | Acc: 39.223,58.118,66.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.915 | Acc: 39.261,58.106,66.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.657 | Acc: 31.250,46.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.784 | Acc: 29.092,41.927,53.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.784 | Acc: 28.449,41.959,53.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.813 | Acc: 28.356,42.328,53.125,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 4.639 | Acc: 36.719,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.681 | Acc: 40.030,60.528,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.813 | Acc: 39.329,58.784,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.842 | Acc: 38.896,58.338,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.875 | Acc: 38.860,57.919,67.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.880 | Acc: 39.062,58.099,67.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.862 | Acc: 39.276,58.161,67.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.860 | Acc: 39.317,58.350,67.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.859 | Acc: 39.528,58.312,67.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.865 | Acc: 39.593,58.300,67.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.865 | Acc: 39.731,58.232,67.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.867 | Acc: 39.748,58.191,66.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.874 | Acc: 39.652,58.289,66.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.870 | Acc: 39.604,58.297,66.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.881 | Acc: 39.571,58.241,66.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.875 | Acc: 39.621,58.300,66.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.887 | Acc: 39.564,58.119,66.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.886 | Acc: 39.548,58.204,66.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.888 | Acc: 39.552,58.178,66.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.895 | Acc: 39.557,58.151,66.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.878 | Acc: 26.562,39.062,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.528 | Acc: 24.740,42.485,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.574 | Acc: 24.790,42.245,52.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.564 | Acc: 24.782,42.456,52.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 4.781 | Acc: 35.156,57.031,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.845 | Acc: 38.728,59.189,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.832 | Acc: 39.806,59.146,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.801 | Acc: 39.844,59.401,67.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.804 | Acc: 39.940,59.404,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.789 | Acc: 39.805,59.336,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.799 | Acc: 39.611,59.214,67.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.844 | Acc: 39.046,58.826,67.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.856 | Acc: 39.232,58.822,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.863 | Acc: 39.378,58.775,67.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.864 | Acc: 39.377,58.749,67.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.856 | Acc: 39.490,58.753,67.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.855 | Acc: 39.494,58.714,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.863 | Acc: 39.601,58.713,67.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.869 | Acc: 39.580,58.708,66.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.879 | Acc: 39.418,58.552,66.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.878 | Acc: 39.393,58.557,66.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.879 | Acc: 39.374,58.548,66.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.881 | Acc: 39.430,58.444,66.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.889 | Acc: 39.411,58.319,66.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.412 | Acc: 27.344,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.971 | Acc: 26.860,45.052,54.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.943 | Acc: 26.582,45.027,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.944 | Acc: 26.498,44.992,54.457,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 4.736 | Acc: 47.656,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.732 | Acc: 41.257,60.119,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.742 | Acc: 40.339,60.442,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.796 | Acc: 39.716,59.529,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.818 | Acc: 39.612,59.250,67.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.811 | Acc: 39.774,59.390,67.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.833 | Acc: 39.353,59.143,67.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.844 | Acc: 39.284,59.009,67.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.844 | Acc: 39.407,59.006,67.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.856 | Acc: 39.365,58.827,67.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.867 | Acc: 39.362,58.741,67.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.875 | Acc: 39.328,58.654,67.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.875 | Acc: 39.348,58.652,67.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.872 | Acc: 39.293,58.600,67.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.873 | Acc: 39.349,58.597,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.877 | Acc: 39.374,58.609,67.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.878 | Acc: 39.420,58.589,67.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.878 | Acc: 39.386,58.617,66.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.885 | Acc: 39.322,58.431,66.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.887 | Acc: 39.268,58.370,66.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.253 | Acc: 25.781,42.188,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.957 | Acc: 25.893,44.940,54.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.079 | Acc: 25.534,44.169,53.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.084 | Acc: 25.461,44.237,54.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 4.543 | Acc: 41.406,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.700 | Acc: 40.439,60.119,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.761 | Acc: 39.939,59.546,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.770 | Acc: 39.472,59.183,67.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.748 | Acc: 39.882,59.703,67.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.759 | Acc: 39.898,59.344,67.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.791 | Acc: 39.850,58.962,66.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.811 | Acc: 39.694,58.954,66.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.830 | Acc: 39.494,58.671,66.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.831 | Acc: 39.386,58.723,66.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.838 | Acc: 39.447,58.563,66.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.856 | Acc: 39.367,58.364,66.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.861 | Acc: 39.273,58.393,66.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.869 | Acc: 39.380,58.324,66.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.875 | Acc: 39.457,58.224,66.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.878 | Acc: 39.304,58.194,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.871 | Acc: 39.350,58.338,66.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.864 | Acc: 39.305,58.438,66.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.858 | Acc: 39.318,58.477,66.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.857 | Acc: 39.389,58.547,66.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.260 | Acc: 32.812,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.125 | Acc: 32.552,49.963,57.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.168 | Acc: 32.870,49.219,57.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.148 | Acc: 32.198,49.039,56.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 4.698 | Acc: 43.750,53.906,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.833 | Acc: 38.616,59.189,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.753 | Acc: 39.482,59.546,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.778 | Acc: 39.191,59.196,68.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.720 | Acc: 39.815,59.761,68.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.776 | Acc: 39.720,59.329,68.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.781 | Acc: 39.857,59.155,68.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.784 | Acc: 39.838,59.148,68.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.785 | Acc: 39.819,58.982,68.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.807 | Acc: 39.770,58.887,67.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.816 | Acc: 39.840,58.846,67.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.817 | Acc: 39.989,58.778,67.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.835 | Acc: 39.834,58.672,67.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.840 | Acc: 39.772,58.681,67.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.836 | Acc: 39.721,58.794,67.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.840 | Acc: 39.610,58.716,67.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.848 | Acc: 39.498,58.577,67.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.856 | Acc: 39.466,58.500,67.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.859 | Acc: 39.448,58.460,67.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.859 | Acc: 39.481,58.411,67.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.485 | Acc: 28.125,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.730 | Acc: 26.042,47.805,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.851 | Acc: 26.105,46.589,55.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.833 | Acc: 26.127,46.427,55.584,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 5.377 | Acc: 38.281,54.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.816 | Acc: 38.542,59.077,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.805 | Acc: 39.101,59.623,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.763 | Acc: 39.716,59.503,68.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.798 | Acc: 39.371,59.144,67.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.796 | Acc: 39.287,59.182,67.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.789 | Acc: 39.405,59.059,67.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.788 | Acc: 39.556,59.087,67.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.803 | Acc: 39.480,59.001,67.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.798 | Acc: 39.494,59.060,67.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.785 | Acc: 39.447,59.243,67.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.780 | Acc: 39.462,59.227,67.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.791 | Acc: 39.490,59.112,67.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.796 | Acc: 39.461,59.106,67.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.799 | Acc: 39.474,59.116,67.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.805 | Acc: 39.405,59.077,67.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.805 | Acc: 39.476,58.986,67.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.812 | Acc: 39.466,58.843,67.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.814 | Acc: 39.461,58.888,67.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.819 | Acc: 39.462,58.860,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.497 | Acc: 32.812,50.000,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.430 | Acc: 31.659,47.768,56.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.445 | Acc: 31.460,46.570,55.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.475 | Acc: 31.186,46.388,54.854,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 5.101 | Acc: 32.031,53.125,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.904 | Acc: 38.318,57.812,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.869 | Acc: 38.434,58.289,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.824 | Acc: 39.178,58.696,67.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.776 | Acc: 39.497,59.356,67.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.769 | Acc: 39.527,59.421,67.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.757 | Acc: 39.734,59.582,68.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.752 | Acc: 39.633,59.580,68.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.762 | Acc: 39.582,59.491,68.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.772 | Acc: 39.826,59.422,67.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.789 | Acc: 39.572,59.181,67.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.797 | Acc: 39.412,59.092,67.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.784 | Acc: 39.601,59.236,67.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.791 | Acc: 39.667,59.145,67.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.799 | Acc: 39.616,59.080,67.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.803 | Acc: 39.545,59.043,67.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.806 | Acc: 39.542,59.115,67.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.813 | Acc: 39.550,58.937,67.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.809 | Acc: 39.623,59.003,67.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.810 | Acc: 39.672,59.020,67.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.507 | Acc: 32.812,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.566 | Acc: 30.729,48.289,54.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.617 | Acc: 31.002,48.075,53.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.666 | Acc: 30.251,47.720,53.035,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.337 | Acc: 36.719,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.674 | Acc: 39.658,60.826,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.660 | Acc: 39.939,60.118,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.713 | Acc: 39.562,59.298,68.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.736 | Acc: 39.525,59.443,68.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.736 | Acc: 39.774,59.506,68.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.730 | Acc: 39.979,59.420,68.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.723 | Acc: 40.121,59.353,68.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.731 | Acc: 40.111,59.424,68.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.737 | Acc: 40.077,59.349,67.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.742 | Acc: 40.100,59.289,67.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.747 | Acc: 40.084,59.386,67.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.760 | Acc: 39.931,59.378,67.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.767 | Acc: 39.963,59.336,67.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.778 | Acc: 39.894,59.331,67.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.786 | Acc: 39.800,59.284,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.787 | Acc: 39.759,59.283,67.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.791 | Acc: 39.786,59.272,67.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.783 | Acc: 39.783,59.366,67.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.790 | Acc: 39.827,59.270,67.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.477 | Acc: 35.156,48.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.627 | Acc: 28.646,46.689,57.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.738 | Acc: 28.049,45.922,55.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.768 | Acc: 27.497,45.786,55.225,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 5.009 | Acc: 39.844,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.782 | Acc: 39.918,59.040,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.725 | Acc: 40.454,59.699,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.729 | Acc: 40.023,59.862,69.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.724 | Acc: 40.220,59.886,69.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.729 | Acc: 40.037,59.916,69.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.731 | Acc: 39.850,59.898,68.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.726 | Acc: 39.927,59.940,68.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.733 | Acc: 39.737,59.972,68.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.733 | Acc: 39.891,60.014,68.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.744 | Acc: 39.859,59.838,68.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.749 | Acc: 39.787,59.707,68.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.767 | Acc: 39.643,59.534,68.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.771 | Acc: 39.721,59.474,68.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.773 | Acc: 39.644,59.397,68.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.779 | Acc: 39.659,59.378,68.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.778 | Acc: 39.664,59.368,68.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.785 | Acc: 39.635,59.382,68.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.790 | Acc: 39.610,59.317,68.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.791 | Acc: 39.589,59.258,67.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.797 | Acc: 37.500,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.968 | Acc: 35.603,49.888,58.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.995 | Acc: 35.023,48.971,57.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.026 | Acc: 34.337,49.027,57.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 4.466 | Acc: 42.188,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.697 | Acc: 40.439,59.784,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.661 | Acc: 39.977,60.099,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.663 | Acc: 40.049,60.438,68.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.685 | Acc: 40.075,60.233,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.686 | Acc: 40.053,60.125,68.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.704 | Acc: 39.954,60.040,68.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.720 | Acc: 40.154,59.802,68.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.723 | Acc: 40.256,59.729,68.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.741 | Acc: 40.107,59.582,68.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.746 | Acc: 39.999,59.546,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.749 | Acc: 39.893,59.576,68.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.743 | Acc: 39.977,59.615,68.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.739 | Acc: 39.910,59.650,68.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.757 | Acc: 39.680,59.539,67.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.771 | Acc: 39.711,59.391,67.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.782 | Acc: 39.744,59.419,67.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.779 | Acc: 39.812,59.510,67.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.784 | Acc: 39.811,59.468,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.781 | Acc: 39.858,59.514,67.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.049 | Acc: 36.719,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.233 | Acc: 31.882,47.731,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.314 | Acc: 31.517,47.523,56.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.305 | Acc: 31.237,47.887,55.405,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 4.595 | Acc: 35.156,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.626 | Acc: 40.216,60.342,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.668 | Acc: 39.825,59.832,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 40.036,60.041,69.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.651 | Acc: 40.345,60.417,69.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.651 | Acc: 40.532,60.613,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.639 | Acc: 40.677,60.640,69.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.657 | Acc: 40.492,60.433,69.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.662 | Acc: 40.479,60.321,69.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.666 | Acc: 40.357,60.290,69.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.682 | Acc: 40.283,60.110,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.682 | Acc: 40.328,60.033,69.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.681 | Acc: 40.230,60.088,69.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.690 | Acc: 40.206,60.057,69.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.690 | Acc: 40.222,60.059,69.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.697 | Acc: 40.080,59.925,68.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.704 | Acc: 40.009,59.854,68.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.711 | Acc: 39.965,59.831,68.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.717 | Acc: 39.982,59.762,68.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.719 | Acc: 39.950,59.736,68.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.592 | Acc: 26.562,52.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.894 | Acc: 27.865,45.685,55.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.884 | Acc: 27.458,45.122,55.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.882 | Acc: 27.395,45.108,54.931,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 4.542 | Acc: 36.719,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 41.071,62.537,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.537 | Acc: 40.758,60.995,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 41.073,61.002,70.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.592 | Acc: 40.307,60.909,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.599 | Acc: 40.393,60.783,69.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.614 | Acc: 40.289,60.673,70.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.623 | Acc: 40.359,60.594,69.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.630 | Acc: 40.314,60.588,69.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.661 | Acc: 40.150,60.225,69.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.664 | Acc: 40.116,60.137,69.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.669 | Acc: 40.180,60.103,69.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.680 | Acc: 40.136,60.043,69.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.687 | Acc: 40.128,60.004,69.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.690 | Acc: 40.189,60.006,69.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.702 | Acc: 40.010,59.912,68.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.702 | Acc: 40.000,59.915,68.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.705 | Acc: 40.013,59.845,68.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.711 | Acc: 40.017,59.791,68.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.716 | Acc: 40.018,59.785,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.016 | Acc: 31.250,52.344,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.415 | Acc: 32.068,49.628,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.425 | Acc: 31.079,48.628,55.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.436 | Acc: 30.712,48.514,55.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 4.842 | Acc: 41.406,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.664 | Acc: 40.327,60.156,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.649 | Acc: 40.320,60.804,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.635 | Acc: 40.369,60.797,69.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.659 | Acc: 40.287,60.523,69.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.651 | Acc: 40.331,60.419,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.660 | Acc: 40.205,60.324,69.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.659 | Acc: 40.237,60.262,69.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.655 | Acc: 40.261,60.360,69.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.678 | Acc: 40.297,60.191,69.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.679 | Acc: 40.318,60.156,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.672 | Acc: 40.356,60.248,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.677 | Acc: 40.372,60.260,68.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.683 | Acc: 40.332,60.240,68.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.690 | Acc: 40.366,60.103,68.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.698 | Acc: 40.407,60.019,68.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.699 | Acc: 40.445,60.018,68.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.711 | Acc: 40.327,59.877,68.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.717 | Acc: 40.303,59.825,68.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.726 | Acc: 40.174,59.734,68.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.683 | Acc: 37.500,43.750,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.540 | Acc: 31.920,46.019,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.548 | Acc: 31.955,44.989,54.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.534 | Acc: 31.749,45.108,54.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 5.142 | Acc: 38.281,55.469,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.644 | Acc: 41.443,59.821,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.662 | Acc: 39.901,59.527,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.667 | Acc: 39.664,60.515,70.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.683 | Acc: 39.950,60.552,69.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.670 | Acc: 39.975,60.295,69.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.666 | Acc: 39.902,60.505,69.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.676 | Acc: 39.811,60.478,69.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.687 | Acc: 39.679,60.307,69.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.690 | Acc: 39.796,60.303,69.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.694 | Acc: 39.840,60.269,69.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.701 | Acc: 39.741,60.170,69.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.719 | Acc: 39.623,59.988,69.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.718 | Acc: 39.745,59.971,69.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.715 | Acc: 39.813,59.992,68.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.718 | Acc: 39.776,59.904,68.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.718 | Acc: 39.946,59.871,68.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.719 | Acc: 39.977,59.879,68.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.721 | Acc: 39.907,59.784,68.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.722 | Acc: 39.922,59.758,68.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.061 | Acc: 25.781,44.531,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.084 | Acc: 26.079,42.188,57.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.169 | Acc: 25.686,42.130,56.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.164 | Acc: 25.192,42.751,55.904,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 4.780 | Acc: 35.938,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 41.332,60.826,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.662 | Acc: 39.996,59.870,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.675 | Acc: 39.882,60.092,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.687 | Acc: 39.670,60.050,68.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.691 | Acc: 39.627,60.388,68.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.703 | Acc: 39.644,60.150,68.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.692 | Acc: 39.755,60.106,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.694 | Acc: 39.708,60.151,68.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.690 | Acc: 39.697,60.186,68.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.684 | Acc: 39.727,60.242,68.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.683 | Acc: 39.805,60.209,68.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.693 | Acc: 39.759,60.124,68.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.694 | Acc: 39.826,60.066,68.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.689 | Acc: 39.922,60.103,68.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.695 | Acc: 39.877,60.058,68.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.694 | Acc: 39.890,60.008,68.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.696 | Acc: 39.963,59.959,68.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.703 | Acc: 39.924,59.920,68.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.712 | Acc: 39.854,59.910,68.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.006 | Acc: 25.781,44.531,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.423 | Acc: 27.232,48.958,57.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.442 | Acc: 27.706,49.066,57.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.440 | Acc: 27.894,48.668,56.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.454 | Acc: 40.625,59.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.540 | Acc: 40.402,61.458,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 40.587,61.452,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 40.164,60.694,70.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.613 | Acc: 40.287,60.475,69.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.624 | Acc: 40.122,60.342,69.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.642 | Acc: 40.283,60.221,69.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.639 | Acc: 40.442,60.372,69.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.650 | Acc: 40.310,60.161,68.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.667 | Acc: 40.142,60.204,68.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.657 | Acc: 40.466,60.401,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.663 | Acc: 40.378,60.379,68.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.659 | Acc: 40.327,60.425,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.659 | Acc: 40.335,60.453,68.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.660 | Acc: 40.316,60.473,68.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.657 | Acc: 40.433,60.496,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.677 | Acc: 40.301,60.324,68.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.681 | Acc: 40.291,60.250,68.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.687 | Acc: 40.253,60.258,68.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.691 | Acc: 40.299,60.208,68.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.608 | Acc: 25.781,46.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.615 | Acc: 30.804,47.545,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.633 | Acc: 30.659,47.523,54.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.672 | Acc: 30.123,47.336,54.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.483 | Acc: 39.062,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.635 | Acc: 40.365,62.091,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.600 | Acc: 40.072,62.176,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 40.446,62.013,69.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.573 | Acc: 40.451,62.269,70.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.588 | Acc: 40.377,61.657,69.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.571 | Acc: 40.612,61.712,70.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.583 | Acc: 40.553,61.674,69.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.594 | Acc: 40.387,61.389,69.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.603 | Acc: 40.319,61.205,69.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.609 | Acc: 40.357,61.062,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.615 | Acc: 40.416,61.029,69.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.627 | Acc: 40.424,60.853,69.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.635 | Acc: 40.365,60.686,69.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.642 | Acc: 40.391,60.643,69.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.644 | Acc: 40.386,60.631,69.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.649 | Acc: 40.257,60.587,69.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.657 | Acc: 40.238,60.498,69.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.660 | Acc: 40.188,60.479,69.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.668 | Acc: 40.137,60.443,68.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.590 | Acc: 29.688,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.182 | Acc: 29.167,49.070,58.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.255 | Acc: 29.287,48.266,57.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.255 | Acc: 29.086,48.258,57.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 3.906 | Acc: 49.219,66.406,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.626 | Acc: 41.109,60.900,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 41.349,61.700,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.563 | Acc: 41.240,61.732,70.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.552 | Acc: 41.358,61.825,70.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.543 | Acc: 41.290,61.703,71.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.563 | Acc: 40.987,61.428,70.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.569 | Acc: 40.980,61.453,70.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.591 | Acc: 40.970,61.224,70.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.603 | Acc: 40.815,61.119,70.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.615 | Acc: 40.804,61.116,70.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.629 | Acc: 40.781,60.952,69.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.631 | Acc: 40.703,60.989,69.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.636 | Acc: 40.787,60.935,69.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.642 | Acc: 40.650,60.798,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.659 | Acc: 40.498,60.644,69.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.675 | Acc: 40.362,60.514,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.677 | Acc: 40.295,60.541,69.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.673 | Acc: 40.346,60.570,69.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.671 | Acc: 40.365,60.607,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.362 | Acc: 29.688,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.254 | Acc: 30.990,48.326,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.296 | Acc: 30.602,48.037,56.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.307 | Acc: 30.366,48.066,55.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 4.598 | Acc: 39.062,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 40.030,60.677,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 40.434,61.395,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 40.638,61.603,70.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.569 | Acc: 40.856,61.642,70.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.584 | Acc: 40.873,61.765,70.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.583 | Acc: 40.799,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.586 | Acc: 40.752,61.553,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.589 | Acc: 40.829,61.510,70.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.601 | Acc: 40.698,61.335,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.620 | Acc: 40.633,61.171,69.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.635 | Acc: 40.568,61.090,69.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.636 | Acc: 40.606,61.100,69.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.639 | Acc: 40.688,60.997,69.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.649 | Acc: 40.672,60.951,69.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.655 | Acc: 40.643,60.896,69.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.653 | Acc: 40.662,60.838,69.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.656 | Acc: 40.607,60.800,69.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.650 | Acc: 40.634,60.829,69.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.654 | Acc: 40.510,60.716,69.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.231 | Acc: 26.562,43.750,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.447 | Acc: 30.320,46.057,56.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.537 | Acc: 30.545,45.636,55.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.562 | Acc: 30.161,46.145,55.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.556 | Acc: 44.531,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 39.881,61.161,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.540 | Acc: 40.072,61.547,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.541 | Acc: 40.907,61.872,70.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.549 | Acc: 40.934,61.844,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.540 | Acc: 40.903,61.812,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.567 | Acc: 40.832,61.460,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.582 | Acc: 40.564,61.431,70.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.587 | Acc: 40.649,61.326,70.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.604 | Acc: 40.448,61.201,70.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.620 | Acc: 40.244,61.042,70.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.623 | Acc: 40.123,60.877,69.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.635 | Acc: 40.054,60.785,69.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.635 | Acc: 40.119,60.668,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.628 | Acc: 40.208,60.768,69.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.627 | Acc: 40.179,60.751,69.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.626 | Acc: 40.262,60.694,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.624 | Acc: 40.375,60.704,69.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.636 | Acc: 40.344,60.635,69.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.639 | Acc: 40.363,60.591,69.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.812 | Acc: 26.562,45.312,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.210 | Acc: 23.661,44.978,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.208 | Acc: 23.990,44.512,52.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.231 | Acc: 23.297,44.147,52.011,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.699 | Acc: 38.281,55.469,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 41.257,62.128,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.572 | Acc: 40.739,61.433,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 40.292,61.565,70.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.555 | Acc: 40.577,61.246,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.540 | Acc: 40.787,61.471,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.546 | Acc: 40.515,61.486,70.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.567 | Acc: 40.392,61.181,70.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.587 | Acc: 40.285,60.894,69.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.592 | Acc: 40.284,60.825,69.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.602 | Acc: 40.256,60.778,69.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.608 | Acc: 40.370,60.803,69.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.630 | Acc: 40.242,60.649,69.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.642 | Acc: 40.197,60.542,69.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.646 | Acc: 40.177,60.545,69.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.643 | Acc: 40.186,60.525,69.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.636 | Acc: 40.202,60.602,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.647 | Acc: 40.169,60.537,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.654 | Acc: 40.116,60.487,69.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.657 | Acc: 40.182,60.493,69.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.408 | Acc: 29.688,38.281,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.158 | Acc: 27.009,43.006,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.229 | Acc: 26.696,42.416,53.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.222 | Acc: 25.653,42.982,52.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 4.242 | Acc: 44.531,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.399 | Acc: 42.262,63.542,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.430 | Acc: 42.245,62.919,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.478 | Acc: 41.765,62.923,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.482 | Acc: 41.705,62.847,71.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.500 | Acc: 41.344,62.508,71.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.500 | Acc: 41.232,62.390,71.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.491 | Acc: 41.379,62.489,71.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.501 | Acc: 41.401,62.408,70.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.509 | Acc: 41.264,62.293,70.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.529 | Acc: 41.243,62.119,70.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.535 | Acc: 41.120,61.970,70.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.553 | Acc: 40.965,61.800,70.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.552 | Acc: 40.948,61.785,70.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.571 | Acc: 40.889,61.541,69.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.584 | Acc: 40.859,61.392,69.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.592 | Acc: 40.693,61.412,69.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.595 | Acc: 40.705,61.322,69.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.602 | Acc: 40.694,61.202,69.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.615 | Acc: 40.594,61.110,69.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.594 | Acc: 33.594,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.591 | Acc: 26.972,48.251,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.629 | Acc: 27.134,47.428,56.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.621 | Acc: 26.524,47.413,56.391,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 4.592 | Acc: 44.531,67.188,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.662 | Acc: 39.025,59.970,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 39.939,61.128,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.530 | Acc: 40.241,61.539,70.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.550 | Acc: 40.422,61.410,70.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.553 | Acc: 40.586,61.286,70.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.554 | Acc: 40.431,61.273,70.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.559 | Acc: 40.547,61.370,70.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.554 | Acc: 40.698,61.442,70.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.553 | Acc: 40.703,61.373,70.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.564 | Acc: 40.683,61.322,70.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.572 | Acc: 40.664,61.270,70.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.572 | Acc: 40.745,61.349,70.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.573 | Acc: 40.712,61.378,69.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.571 | Acc: 40.800,61.413,69.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.573 | Acc: 40.822,61.400,70.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.576 | Acc: 40.834,61.366,69.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.594 | Acc: 40.792,61.141,69.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.603 | Acc: 40.764,61.046,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.604 | Acc: 40.748,61.015,69.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.164 | Acc: 22.656,37.500,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.360 | Acc: 22.098,44.010,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.351 | Acc: 22.428,44.245,55.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.313 | Acc: 22.451,44.352,55.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 3.697 | Acc: 47.656,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.415 | Acc: 40.662,63.467,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.464 | Acc: 41.197,63.034,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.472 | Acc: 40.945,62.577,71.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.498 | Acc: 40.307,62.471,71.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.516 | Acc: 40.408,62.268,71.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.522 | Acc: 40.554,62.171,70.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.533 | Acc: 40.448,61.946,70.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.553 | Acc: 40.217,61.588,70.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.543 | Acc: 40.375,61.766,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.553 | Acc: 40.450,61.575,70.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.550 | Acc: 40.625,61.652,70.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.554 | Acc: 40.505,61.609,70.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.566 | Acc: 40.436,61.452,70.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.562 | Acc: 40.530,61.405,70.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.568 | Acc: 40.568,61.355,70.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.565 | Acc: 40.659,61.427,70.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.570 | Acc: 40.648,61.398,70.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.578 | Acc: 40.664,61.312,69.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.581 | Acc: 40.691,61.302,69.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.722 | Acc: 30.469,44.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.421 | Acc: 31.324,47.396,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.478 | Acc: 31.288,46.075,56.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.446 | Acc: 31.045,45.863,56.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 4.441 | Acc: 40.625,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.460 | Acc: 40.811,62.202,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 40.816,63.034,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.466 | Acc: 41.124,62.500,71.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.498 | Acc: 41.329,62.326,71.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.508 | Acc: 41.321,62.075,70.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.518 | Acc: 41.213,61.958,70.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.533 | Acc: 41.057,61.979,70.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.538 | Acc: 41.173,61.787,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.539 | Acc: 41.078,61.840,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.555 | Acc: 41.088,61.703,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.559 | Acc: 41.042,61.673,70.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.570 | Acc: 41.037,61.696,70.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.574 | Acc: 40.951,61.536,70.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.562 | Acc: 40.992,61.683,70.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.560 | Acc: 41.071,61.654,70.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.568 | Acc: 40.993,61.604,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.568 | Acc: 41.042,61.561,70.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.575 | Acc: 40.991,61.507,69.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.584 | Acc: 40.906,61.452,69.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.511 | Acc: 21.094,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.257 | Acc: 22.061,41.704,52.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.286 | Acc: 21.380,40.511,51.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.282 | Acc: 21.350,41.073,51.114,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.654 | Acc: 36.719,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 40.588,62.314,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.450 | Acc: 41.025,62.843,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.462 | Acc: 40.996,62.999,72.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.508 | Acc: 40.866,62.558,71.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.550 | Acc: 40.509,62.206,71.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.556 | Acc: 40.696,62.093,70.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.566 | Acc: 40.636,61.918,70.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.566 | Acc: 40.460,61.976,70.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.565 | Acc: 40.664,61.939,70.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.565 | Acc: 40.683,61.843,70.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.566 | Acc: 40.745,61.758,70.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.566 | Acc: 40.735,61.780,70.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.575 | Acc: 40.619,61.662,70.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.571 | Acc: 40.692,61.719,70.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.574 | Acc: 40.687,61.685,70.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.573 | Acc: 40.669,61.643,70.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.571 | Acc: 40.659,61.611,70.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.576 | Acc: 40.612,61.507,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.589 | Acc: 40.549,61.329,69.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.706 | Acc: 33.594,50.781,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.108 | Acc: 32.515,50.930,60.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.135 | Acc: 32.107,50.572,60.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.188 | Acc: 31.532,50.102,59.477,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 5.118 | Acc: 42.188,56.250,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.447 | Acc: 41.481,62.686,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.460 | Acc: 40.739,61.928,72.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.516 | Acc: 40.663,61.757,71.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.506 | Acc: 40.750,62.076,71.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.525 | Acc: 40.610,61.819,71.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.522 | Acc: 40.767,61.667,71.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.536 | Acc: 40.719,61.608,71.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.540 | Acc: 40.892,61.665,71.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.553 | Acc: 40.888,61.434,70.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.556 | Acc: 40.734,61.318,70.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.555 | Acc: 40.713,61.256,70.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.562 | Acc: 40.680,61.304,70.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.573 | Acc: 40.619,61.258,70.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.575 | Acc: 40.636,61.221,70.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.576 | Acc: 40.654,61.200,70.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.586 | Acc: 40.606,61.101,70.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.596 | Acc: 40.625,60.960,69.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.591 | Acc: 40.653,61.009,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.593 | Acc: 40.699,60.991,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.120 | Acc: 25.000,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.555 | Acc: 29.204,49.777,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.591 | Acc: 29.116,48.952,56.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.625 | Acc: 28.778,48.604,55.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 4.297 | Acc: 38.281,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.393 | Acc: 42.113,63.132,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.388 | Acc: 41.787,63.319,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.425 | Acc: 41.534,62.641,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.425 | Acc: 41.860,62.838,71.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.400 | Acc: 41.917,62.933,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.435 | Acc: 41.716,62.571,71.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.453 | Acc: 41.622,62.295,71.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.462 | Acc: 41.484,62.170,71.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.469 | Acc: 41.419,62.202,71.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.489 | Acc: 41.239,61.987,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.496 | Acc: 41.311,62.016,70.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.503 | Acc: 41.348,62.030,70.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.514 | Acc: 41.301,61.895,70.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.520 | Acc: 41.234,61.827,70.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.528 | Acc: 41.144,61.750,70.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.539 | Acc: 41.068,61.668,70.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.546 | Acc: 40.969,61.586,70.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.551 | Acc: 40.891,61.524,70.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.556 | Acc: 40.898,61.524,70.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.040 | Acc: 25.781,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.364 | Acc: 22.173,45.164,53.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.419 | Acc: 22.008,44.931,52.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.376 | Acc: 22.298,44.582,52.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 4.666 | Acc: 37.500,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.348 | Acc: 40.699,63.653,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.452 | Acc: 40.720,62.424,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.485 | Acc: 41.112,62.205,70.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.528 | Acc: 41.049,61.642,70.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.537 | Acc: 40.787,61.355,70.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.564 | Acc: 40.496,61.028,70.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.560 | Acc: 40.559,61.209,70.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.559 | Acc: 40.518,61.360,70.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.558 | Acc: 40.569,61.425,70.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.561 | Acc: 40.633,61.318,70.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.562 | Acc: 40.565,61.379,70.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.554 | Acc: 40.596,61.508,70.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.556 | Acc: 40.631,61.548,70.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.552 | Acc: 40.700,61.566,70.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.549 | Acc: 40.807,61.550,70.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.555 | Acc: 40.742,61.473,70.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.554 | Acc: 40.774,61.460,70.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.560 | Acc: 40.787,61.459,70.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.567 | Acc: 40.812,61.462,69.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.069 | Acc: 28.906,53.125,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.649 | Acc: 25.781,48.921,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.693 | Acc: 25.762,49.181,57.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.720 | Acc: 25.000,49.283,56.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 4.161 | Acc: 43.750,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.445 | Acc: 41.183,62.426,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.461 | Acc: 40.777,62.214,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.466 | Acc: 40.459,62.372,71.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.451 | Acc: 40.673,62.770,70.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.466 | Acc: 40.803,62.709,70.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.476 | Acc: 40.864,62.765,70.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.487 | Acc: 41.002,62.500,70.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.502 | Acc: 40.936,62.296,70.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.505 | Acc: 40.949,62.168,70.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.505 | Acc: 40.936,62.111,70.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.502 | Acc: 41.024,62.245,70.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.501 | Acc: 41.118,62.218,70.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.513 | Acc: 40.951,62.093,70.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.516 | Acc: 40.856,61.947,70.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.527 | Acc: 40.859,61.859,70.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.534 | Acc: 40.846,61.699,70.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.533 | Acc: 40.847,61.728,70.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.535 | Acc: 40.824,61.710,70.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.536 | Acc: 40.877,61.655,70.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.672 | Acc: 31.250,53.906,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.963 | Acc: 32.366,51.190,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.123 | Acc: 31.650,49.466,57.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.156 | Acc: 31.263,49.526,57.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 4.162 | Acc: 37.500,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.269 | Acc: 41.927,64.435,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 41.787,63.091,72.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.376 | Acc: 41.675,62.385,72.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.383 | Acc: 41.667,62.404,72.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.445 | Acc: 41.205,61.796,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.456 | Acc: 41.032,61.583,71.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.470 | Acc: 40.996,61.469,71.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.502 | Acc: 40.872,61.301,71.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.514 | Acc: 40.819,61.352,70.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.529 | Acc: 40.691,61.194,70.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.535 | Acc: 40.781,61.181,70.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.535 | Acc: 40.706,61.304,70.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.525 | Acc: 41.020,61.363,70.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.529 | Acc: 40.911,61.355,70.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.530 | Acc: 40.931,61.363,70.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.529 | Acc: 40.993,61.400,70.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.532 | Acc: 41.035,61.403,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.534 | Acc: 40.954,61.388,70.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.541 | Acc: 40.883,61.298,70.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.149 | Acc: 37.500,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.186 | Acc: 32.217,49.144,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.225 | Acc: 32.336,48.971,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.242 | Acc: 31.839,48.950,58.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.701 | Acc: 56.250,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.345 | Acc: 42.336,63.988,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.462 | Acc: 41.254,62.843,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.470 | Acc: 41.534,62.705,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.464 | Acc: 41.483,62.789,71.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.479 | Acc: 41.282,62.670,71.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.471 | Acc: 41.548,62.816,71.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.467 | Acc: 41.683,62.910,71.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.477 | Acc: 41.440,62.757,71.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.487 | Acc: 41.316,62.513,71.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.484 | Acc: 41.410,62.477,71.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.509 | Acc: 41.145,62.313,71.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.513 | Acc: 41.056,62.260,71.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.520 | Acc: 41.080,62.162,70.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.522 | Acc: 41.039,62.158,70.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.525 | Acc: 40.960,62.041,70.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.538 | Acc: 40.893,61.889,70.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.543 | Acc: 40.962,61.822,70.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.548 | Acc: 40.965,61.756,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.557 | Acc: 40.910,61.655,70.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.506 | Acc: 29.688,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.304 | Acc: 29.576,50.223,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.338 | Acc: 29.516,49.962,56.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.347 | Acc: 29.150,50.128,56.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 4.227 | Acc: 35.938,63.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.551 | Acc: 39.211,61.272,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.462 | Acc: 40.701,62.424,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.464 | Acc: 40.574,62.679,71.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.473 | Acc: 40.683,62.259,71.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.453 | Acc: 41.058,62.214,71.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.447 | Acc: 41.413,62.274,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.453 | Acc: 41.307,62.190,71.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.462 | Acc: 41.173,62.097,71.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.469 | Acc: 41.113,62.168,71.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.470 | Acc: 41.115,62.228,71.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.462 | Acc: 41.169,62.415,71.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.475 | Acc: 41.124,62.276,71.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.497 | Acc: 40.969,62.132,70.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.512 | Acc: 40.953,61.924,70.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.522 | Acc: 40.939,61.994,70.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.519 | Acc: 40.961,61.984,70.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.521 | Acc: 40.989,62.046,70.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.527 | Acc: 40.971,62.026,70.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.530 | Acc: 40.961,61.948,70.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.034 | Acc: 28.125,44.531,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.650 | Acc: 26.935,48.810,58.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.771 | Acc: 26.086,48.037,56.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.822 | Acc: 25.692,47.797,56.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 4.425 | Acc: 46.875,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.252 | Acc: 41.592,63.951,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.280 | Acc: 42.359,63.396,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.354 | Acc: 41.637,63.012,72.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.396 | Acc: 41.339,62.596,71.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.411 | Acc: 41.290,62.546,71.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.424 | Acc: 41.116,62.229,71.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.430 | Acc: 41.079,62.084,71.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.438 | Acc: 41.207,62.058,71.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.462 | Acc: 41.044,61.973,71.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.480 | Acc: 41.041,61.882,71.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.483 | Acc: 41.003,61.729,71.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.494 | Acc: 40.923,61.583,70.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.498 | Acc: 40.799,61.572,70.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.497 | Acc: 40.925,61.605,70.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.495 | Acc: 40.921,61.628,70.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.497 | Acc: 40.905,61.619,70.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.496 | Acc: 40.838,61.696,70.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.508 | Acc: 40.696,61.589,70.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.509 | Acc: 40.777,61.647,70.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.407 | Acc: 30.469,44.531,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.804 | Acc: 29.650,46.317,56.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.869 | Acc: 29.078,46.113,55.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.883 | Acc: 28.650,46.260,55.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 4.548 | Acc: 42.969,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.442 | Acc: 40.885,62.612,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.450 | Acc: 40.816,62.233,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.429 | Acc: 41.048,62.065,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.418 | Acc: 40.924,62.047,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.437 | Acc: 40.888,61.711,71.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.433 | Acc: 41.122,61.764,71.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.440 | Acc: 40.980,61.874,71.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.438 | Acc: 40.999,61.961,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.453 | Acc: 40.953,61.801,71.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.473 | Acc: 40.901,61.439,71.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.481 | Acc: 40.901,61.390,71.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.490 | Acc: 40.904,61.482,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.494 | Acc: 40.852,61.482,71.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.486 | Acc: 40.931,61.538,71.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.489 | Acc: 40.833,61.566,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.494 | Acc: 40.849,61.617,71.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.498 | Acc: 40.829,61.577,71.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.494 | Acc: 40.774,61.649,71.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.501 | Acc: 40.715,61.590,70.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.122 | Acc: 36.719,50.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.304 | Acc: 32.626,49.665,58.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.279 | Acc: 32.870,49.886,58.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.286 | Acc: 32.428,49.936,58.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 4.351 | Acc: 42.969,60.938,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.341 | Acc: 41.815,64.137,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 42.302,64.310,73.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.333 | Acc: 42.034,64.191,72.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.391 | Acc: 41.416,63.677,72.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.417 | Acc: 41.383,63.072,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.427 | Acc: 41.593,62.939,72.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.428 | Acc: 41.661,62.816,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.435 | Acc: 41.508,62.655,71.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.448 | Acc: 41.385,62.668,71.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.459 | Acc: 41.255,62.570,71.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.474 | Acc: 41.173,62.419,71.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.469 | Acc: 41.147,62.461,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.467 | Acc: 41.152,62.464,71.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.472 | Acc: 41.178,62.405,71.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.474 | Acc: 41.160,62.433,71.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.474 | Acc: 41.192,62.432,71.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.486 | Acc: 41.053,62.319,71.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.497 | Acc: 41.105,62.219,70.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.501 | Acc: 41.090,62.131,70.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.741 | Acc: 24.219,46.875,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.043 | Acc: 22.879,46.131,57.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.961 | Acc: 24.200,46.646,57.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.949 | Acc: 24.065,46.747,57.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 4.155 | Acc: 42.969,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.392 | Acc: 40.290,62.612,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.374 | Acc: 41.559,63.148,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.377 | Acc: 41.586,63.102,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.389 | Acc: 41.782,63.243,71.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.402 | Acc: 41.561,62.887,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.416 | Acc: 41.245,62.687,71.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.424 | Acc: 41.229,62.639,71.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.440 | Acc: 41.280,62.519,71.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.454 | Acc: 41.303,62.491,71.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.456 | Acc: 41.259,62.488,71.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.462 | Acc: 41.180,62.405,71.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.467 | Acc: 40.995,62.318,71.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.466 | Acc: 41.119,62.305,71.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.467 | Acc: 41.081,62.169,71.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.471 | Acc: 41.045,62.134,71.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.469 | Acc: 41.134,62.140,71.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.485 | Acc: 40.923,62.014,71.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.495 | Acc: 40.958,61.868,70.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.498 | Acc: 40.912,61.813,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.168 | Acc: 34.375,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.541 | Acc: 29.576,47.656,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.613 | Acc: 29.306,47.123,55.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.650 | Acc: 28.727,46.619,54.086,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 4.117 | Acc: 42.969,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.408 | Acc: 40.662,63.244,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.464 | Acc: 40.320,63.434,72.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.486 | Acc: 40.433,62.846,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.480 | Acc: 40.664,62.461,71.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.457 | Acc: 40.664,62.763,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.440 | Acc: 40.683,62.939,71.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.453 | Acc: 40.581,62.805,71.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.448 | Acc: 40.785,62.883,71.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.444 | Acc: 40.901,62.936,71.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.457 | Acc: 40.948,62.772,71.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.458 | Acc: 40.805,62.733,71.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.466 | Acc: 40.751,62.617,71.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.466 | Acc: 40.709,62.575,71.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.461 | Acc: 40.822,62.522,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.462 | Acc: 40.825,62.544,71.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.465 | Acc: 40.849,62.583,71.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.473 | Acc: 40.776,62.440,71.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.473 | Acc: 40.859,62.403,71.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.478 | Acc: 40.832,62.359,71.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.500 | Acc: 19.531,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.572 | Acc: 21.540,43.787,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.589 | Acc: 22.142,43.121,54.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.528 | Acc: 21.606,43.571,53.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 4.634 | Acc: 42.188,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.322 | Acc: 42.150,63.876,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.373 | Acc: 41.806,62.919,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.350 | Acc: 42.098,63.192,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.350 | Acc: 41.773,63.185,72.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.364 | Acc: 41.716,62.918,72.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.392 | Acc: 41.548,62.823,72.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.410 | Acc: 41.362,62.572,71.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.416 | Acc: 41.299,62.461,71.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.411 | Acc: 41.566,62.582,71.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.414 | Acc: 41.484,62.593,71.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.417 | Acc: 41.473,62.564,71.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.427 | Acc: 41.445,62.549,71.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.438 | Acc: 41.364,62.464,71.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.447 | Acc: 41.340,62.414,71.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.453 | Acc: 41.367,62.386,71.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.460 | Acc: 41.338,62.305,71.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.463 | Acc: 41.305,62.273,71.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.465 | Acc: 41.281,62.238,71.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.467 | Acc: 41.230,62.256,71.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.266 | Acc: 36.719,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.344 | Acc: 31.324,47.842,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.331 | Acc: 31.803,47.923,56.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.333 | Acc: 31.532,48.309,56.468,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 4.655 | Acc: 39.062,60.156,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.418 | Acc: 41.592,61.793,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.380 | Acc: 41.635,63.167,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 41.816,63.153,72.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.380 | Acc: 41.773,63.349,72.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.378 | Acc: 41.739,63.041,71.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.409 | Acc: 41.406,62.661,71.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.411 | Acc: 41.351,62.611,71.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.419 | Acc: 41.338,62.660,71.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.430 | Acc: 41.449,62.535,71.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.444 | Acc: 41.231,62.438,71.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.457 | Acc: 41.159,62.468,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.459 | Acc: 41.228,62.367,71.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.462 | Acc: 41.278,62.338,71.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.471 | Acc: 41.192,62.155,71.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.466 | Acc: 41.214,62.233,71.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.467 | Acc: 41.280,62.242,71.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.468 | Acc: 41.299,62.230,71.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.474 | Acc: 41.313,62.199,71.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.477 | Acc: 41.203,62.133,71.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.561 | Acc: 32.812,42.969,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.012 | Acc: 27.827,46.689,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.011 | Acc: 28.239,46.570,54.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.041 | Acc: 27.651,46.440,53.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 4.133 | Acc: 46.094,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.312 | Acc: 42.597,64.323,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.305 | Acc: 42.359,63.891,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.301 | Acc: 42.111,64.011,73.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.318 | Acc: 42.081,63.850,72.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.344 | Acc: 41.801,63.467,72.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.368 | Acc: 41.729,63.236,72.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.383 | Acc: 41.922,63.248,72.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.396 | Acc: 41.906,63.102,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.404 | Acc: 41.812,63.070,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.425 | Acc: 41.756,63.005,71.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.432 | Acc: 41.632,62.931,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.433 | Acc: 41.494,62.863,71.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.436 | Acc: 41.442,62.829,71.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.441 | Acc: 41.415,62.806,71.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.443 | Acc: 41.466,62.721,71.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.450 | Acc: 41.438,62.607,71.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.451 | Acc: 41.393,62.582,71.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.462 | Acc: 41.276,62.409,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.463 | Acc: 41.248,62.387,71.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.658 | Acc: 34.375,47.656,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.628 | Acc: 30.171,47.805,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.669 | Acc: 30.164,47.275,57.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.747 | Acc: 28.932,47.054,56.596,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 4.577 | Acc: 36.719,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.436 | Acc: 39.658,62.760,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.338 | Acc: 41.635,63.586,72.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.305 | Acc: 42.149,63.922,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.312 | Acc: 42.216,64.072,73.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.335 | Acc: 41.909,63.869,73.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.332 | Acc: 42.007,63.772,72.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.326 | Acc: 41.883,63.785,73.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.338 | Acc: 41.901,63.713,72.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.354 | Acc: 41.829,63.566,72.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.360 | Acc: 41.818,63.499,72.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.379 | Acc: 41.643,63.221,72.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.397 | Acc: 41.539,62.983,71.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.406 | Acc: 41.484,62.901,71.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.418 | Acc: 41.401,62.848,71.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.420 | Acc: 41.331,62.811,71.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.425 | Acc: 41.343,62.756,71.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.434 | Acc: 41.239,62.658,71.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.442 | Acc: 41.250,62.582,71.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.450 | Acc: 41.220,62.543,71.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.170 | Acc: 29.688,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.476 | Acc: 31.324,49.368,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.590 | Acc: 30.240,47.961,57.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.581 | Acc: 29.918,48.412,56.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 4.108 | Acc: 44.531,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.218 | Acc: 43.787,63.653,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.305 | Acc: 42.740,63.319,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.334 | Acc: 42.162,63.345,72.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.338 | Acc: 42.091,63.503,72.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.347 | Acc: 42.087,63.444,72.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.356 | Acc: 42.020,63.423,72.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.386 | Acc: 41.711,63.143,72.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.390 | Acc: 41.799,63.145,72.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.396 | Acc: 41.708,63.065,71.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.407 | Acc: 41.562,62.982,71.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.420 | Acc: 41.558,62.875,71.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.422 | Acc: 41.435,62.941,71.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.430 | Acc: 41.481,62.781,71.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.433 | Acc: 41.462,62.811,71.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.443 | Acc: 41.370,62.664,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.453 | Acc: 41.353,62.612,71.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.455 | Acc: 41.331,62.580,71.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.455 | Acc: 41.387,62.552,71.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.460 | Acc: 41.320,62.533,71.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.274 | Acc: 25.000,44.531,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.605 | Acc: 29.725,46.987,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.619 | Acc: 30.030,46.570,56.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.611 | Acc: 29.483,46.773,56.455,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 4.500 | Acc: 36.719,57.812,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.370 | Acc: 39.993,62.054,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.326 | Acc: 41.311,62.976,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 40.881,63.051,72.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.374 | Acc: 40.577,63.233,72.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.383 | Acc: 40.501,63.034,72.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.398 | Acc: 40.715,62.900,72.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.387 | Acc: 40.869,63.071,72.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.385 | Acc: 40.994,63.291,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.379 | Acc: 41.113,63.368,72.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.390 | Acc: 41.177,63.157,72.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.395 | Acc: 41.240,63.108,72.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.399 | Acc: 41.260,63.051,72.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.404 | Acc: 41.272,62.967,72.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.412 | Acc: 41.315,62.898,71.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.426 | Acc: 41.162,62.721,71.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.429 | Acc: 41.119,62.702,71.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.436 | Acc: 41.058,62.686,71.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.440 | Acc: 41.164,62.602,71.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.441 | Acc: 41.072,62.570,71.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.085 | Acc: 37.500,50.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.245 | Acc: 33.147,49.516,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.294 | Acc: 32.812,49.085,57.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.291 | Acc: 32.275,48.975,57.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.446 | Acc: 42.188,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.196 | Acc: 42.783,64.062,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.246 | Acc: 42.912,63.605,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.263 | Acc: 42.661,63.704,73.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.275 | Acc: 42.255,63.821,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.278 | Acc: 42.265,63.761,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.304 | Acc: 42.052,63.694,73.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.315 | Acc: 41.861,63.586,73.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.330 | Acc: 41.678,63.495,72.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.346 | Acc: 41.531,63.549,72.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.358 | Acc: 41.437,63.425,72.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.371 | Acc: 41.512,63.129,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.379 | Acc: 41.659,63.048,72.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.376 | Acc: 41.822,63.111,72.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.382 | Acc: 41.698,63.056,72.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.392 | Acc: 41.541,62.949,72.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.407 | Acc: 41.496,62.841,71.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.413 | Acc: 41.489,62.741,71.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.412 | Acc: 41.523,62.827,71.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.420 | Acc: 41.492,62.771,71.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.693 | Acc: 39.844,50.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.005 | Acc: 33.482,50.335,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.025 | Acc: 32.660,50.248,58.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.016 | Acc: 32.979,50.384,57.979,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 4.491 | Acc: 44.531,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.349 | Acc: 42.560,64.918,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.296 | Acc: 42.550,64.405,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.272 | Acc: 42.661,64.344,73.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.298 | Acc: 42.564,63.908,72.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.289 | Acc: 42.559,64.202,73.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.324 | Acc: 42.226,63.785,72.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.359 | Acc: 42.032,63.497,72.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.369 | Acc: 41.930,63.369,72.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.383 | Acc: 41.739,63.290,72.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.394 | Acc: 41.566,63.149,71.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.401 | Acc: 41.413,63.115,71.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.410 | Acc: 41.400,62.970,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.416 | Acc: 41.287,62.937,71.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.424 | Acc: 41.326,62.850,71.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.419 | Acc: 41.269,62.832,71.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.425 | Acc: 41.165,62.850,71.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.434 | Acc: 41.102,62.761,71.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.440 | Acc: 41.036,62.677,71.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.442 | Acc: 41.095,62.646,71.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.100 | Acc: 31.250,35.156,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.610 | Acc: 27.121,40.997,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.594 | Acc: 26.696,41.482,54.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.578 | Acc: 26.268,41.445,54.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 4.109 | Acc: 35.938,62.500,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.216 | Acc: 41.667,64.249,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.252 | Acc: 41.635,63.529,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.265 | Acc: 41.880,63.870,73.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.336 | Acc: 41.541,63.358,72.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.349 | Acc: 41.538,63.289,72.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.382 | Acc: 41.387,63.042,72.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.376 | Acc: 41.595,63.254,72.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.374 | Acc: 41.731,63.272,72.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.383 | Acc: 41.674,63.212,72.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.389 | Acc: 41.554,63.219,72.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.389 | Acc: 41.636,63.267,72.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.393 | Acc: 41.714,63.165,72.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.395 | Acc: 41.736,63.060,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.396 | Acc: 41.751,63.017,72.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.402 | Acc: 41.814,62.889,72.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.406 | Acc: 41.839,62.809,72.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.407 | Acc: 41.734,62.738,72.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.417 | Acc: 41.727,62.721,71.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.419 | Acc: 41.722,62.623,71.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.835 | Acc: 32.812,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.066 | Acc: 24.665,47.991,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.021 | Acc: 25.248,47.370,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.013 | Acc: 25.166,47.567,58.901,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 4.141 | Acc: 39.062,65.625,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.328 | Acc: 40.290,62.351,73.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.277 | Acc: 41.178,63.072,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 41.432,63.268,73.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.331 | Acc: 41.416,63.156,72.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.339 | Acc: 41.174,63.219,72.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.362 | Acc: 41.129,63.204,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.394 | Acc: 40.980,62.855,72.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.395 | Acc: 41.183,62.995,72.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.412 | Acc: 41.035,62.923,72.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.415 | Acc: 41.235,63.013,71.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.422 | Acc: 41.180,62.917,71.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.423 | Acc: 41.157,62.805,71.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.423 | Acc: 41.122,62.814,71.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.430 | Acc: 41.053,62.695,71.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.437 | Acc: 41.087,62.599,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.433 | Acc: 41.097,62.663,71.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.431 | Acc: 41.140,62.674,71.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.436 | Acc: 41.138,62.677,71.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.429 | Acc: 41.191,62.693,71.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.604 | Acc: 22.656,42.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.832 | Acc: 18.824,40.923,50.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.829 | Acc: 18.921,40.206,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.823 | Acc: 18.545,40.330,50.525,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 4.341 | Acc: 35.938,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.374 | Acc: 40.662,62.388,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.344 | Acc: 41.254,62.862,73.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 41.406,62.449,72.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.400 | Acc: 41.474,62.770,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.382 | Acc: 41.569,63.003,72.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.371 | Acc: 41.555,63.126,72.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.362 | Acc: 41.572,63.259,72.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.371 | Acc: 41.503,63.145,72.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.358 | Acc: 41.682,63.324,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.364 | Acc: 41.639,63.378,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.373 | Acc: 41.647,63.260,72.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.383 | Acc: 41.669,63.210,72.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.393 | Acc: 41.613,63.126,72.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.393 | Acc: 41.604,63.134,72.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.395 | Acc: 41.591,63.009,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.403 | Acc: 41.528,62.958,72.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.405 | Acc: 41.530,62.912,72.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.401 | Acc: 41.551,62.991,72.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.399 | Acc: 41.558,62.992,71.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.931 | Acc: 35.156,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.482 | Acc: 31.213,48.549,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.549 | Acc: 30.774,48.075,56.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.556 | Acc: 30.328,47.720,56.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 4.349 | Acc: 41.406,59.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.198 | Acc: 42.448,65.365,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.219 | Acc: 42.626,65.568,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.281 | Acc: 42.418,64.703,73.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.308 | Acc: 42.072,64.111,73.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.329 | Acc: 41.948,63.946,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.334 | Acc: 41.865,63.662,72.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.334 | Acc: 41.733,63.630,72.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.350 | Acc: 41.629,63.558,72.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.356 | Acc: 41.424,63.488,72.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.368 | Acc: 41.344,63.371,72.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.375 | Acc: 41.314,63.345,72.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.383 | Acc: 41.257,63.197,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.376 | Acc: 41.355,63.305,72.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.383 | Acc: 41.378,63.248,72.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.387 | Acc: 41.406,63.149,72.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.388 | Acc: 41.435,63.169,71.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.393 | Acc: 41.477,63.135,71.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.394 | Acc: 41.469,63.160,71.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.399 | Acc: 41.476,63.062,71.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.759 | Acc: 42.188,52.344,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.548 | Acc: 38.058,53.125,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.615 | Acc: 37.938,52.630,59.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.652 | Acc: 37.269,52.024,58.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 4.856 | Acc: 43.750,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.449 | Acc: 40.848,64.509,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 41.044,63.415,72.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.393 | Acc: 41.355,63.461,72.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.388 | Acc: 41.464,63.368,72.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.388 | Acc: 41.298,63.691,72.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.380 | Acc: 41.419,63.617,72.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.373 | Acc: 41.539,63.730,72.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.371 | Acc: 41.528,63.592,72.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.386 | Acc: 41.484,63.337,72.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.387 | Acc: 41.445,63.316,72.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.401 | Acc: 41.505,63.104,72.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.400 | Acc: 41.393,63.171,72.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.401 | Acc: 41.481,63.182,72.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.396 | Acc: 41.565,63.170,72.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.394 | Acc: 41.705,63.185,72.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.391 | Acc: 41.769,63.213,72.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.398 | Acc: 41.743,63.105,71.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.413 | Acc: 41.592,62.892,71.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.418 | Acc: 41.490,62.842,71.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.251 | Acc: 34.375,50.781,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.174 | Acc: 33.482,48.996,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.238 | Acc: 33.079,48.857,56.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.301 | Acc: 32.582,48.450,55.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 3.692 | Acc: 42.969,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.270 | Acc: 40.848,63.839,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.293 | Acc: 41.178,63.986,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.257 | Acc: 41.611,64.408,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.282 | Acc: 41.763,64.448,74.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.295 | Acc: 41.515,64.117,73.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.314 | Acc: 41.535,64.030,73.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.344 | Acc: 41.345,63.669,73.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.363 | Acc: 41.387,63.621,72.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.365 | Acc: 41.501,63.614,72.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.371 | Acc: 41.527,63.518,72.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.378 | Acc: 41.424,63.380,72.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.383 | Acc: 41.520,63.223,72.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.395 | Acc: 41.367,63.042,72.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.395 | Acc: 41.398,63.028,72.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.399 | Acc: 41.398,62.882,72.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.397 | Acc: 41.470,62.911,72.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.393 | Acc: 41.502,62.910,72.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.400 | Acc: 41.408,62.855,72.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.396 | Acc: 41.384,62.972,72.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.081 | Acc: 28.125,43.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.160 | Acc: 22.619,45.089,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.198 | Acc: 22.713,44.646,52.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.165 | Acc: 22.695,45.082,52.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 4.122 | Acc: 42.188,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.356 | Acc: 40.923,64.732,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.361 | Acc: 41.254,63.110,73.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.335 | Acc: 40.996,63.371,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.331 | Acc: 41.368,63.638,73.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.334 | Acc: 41.723,63.598,73.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.354 | Acc: 41.471,63.410,72.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.374 | Acc: 41.290,63.159,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.373 | Acc: 41.299,63.092,72.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.363 | Acc: 41.424,63.186,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.354 | Acc: 41.461,63.417,72.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.358 | Acc: 41.470,63.462,72.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.372 | Acc: 41.432,63.317,72.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.383 | Acc: 41.281,63.147,71.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.390 | Acc: 41.203,63.070,71.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.389 | Acc: 41.334,63.068,71.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.390 | Acc: 41.392,63.043,71.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.388 | Acc: 41.393,63.020,71.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.397 | Acc: 41.341,62.970,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.398 | Acc: 41.445,62.943,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.642 | Acc: 31.250,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.314 | Acc: 30.320,48.958,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.388 | Acc: 29.116,48.266,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.349 | Acc: 28.842,48.566,58.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 4.130 | Acc: 38.281,67.969,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.123 | Acc: 43.452,65.811,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.287 | Acc: 42.207,64.310,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.277 | Acc: 42.085,64.075,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.309 | Acc: 41.879,63.812,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.296 | Acc: 42.102,63.885,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.301 | Acc: 41.929,63.908,73.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.296 | Acc: 42.160,64.002,72.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.302 | Acc: 42.154,63.883,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.311 | Acc: 42.019,64.011,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.333 | Acc: 41.935,63.802,72.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.337 | Acc: 41.968,63.758,72.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.340 | Acc: 41.999,63.768,72.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.340 | Acc: 41.942,63.751,72.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.358 | Acc: 41.846,63.520,72.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.366 | Acc: 41.827,63.437,72.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.378 | Acc: 41.710,63.254,72.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.378 | Acc: 41.766,63.210,72.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.379 | Acc: 41.705,63.240,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.382 | Acc: 41.681,63.222,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.528 | Acc: 25.000,42.969,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.271 | Acc: 30.915,48.772,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.338 | Acc: 30.373,48.095,58.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.333 | Acc: 29.995,47.810,58.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 4.469 | Acc: 32.812,58.594,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.267 | Acc: 41.257,63.542,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.312 | Acc: 41.540,63.796,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.325 | Acc: 41.522,63.358,72.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.336 | Acc: 41.541,63.638,72.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.353 | Acc: 41.337,63.343,72.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.341 | Acc: 41.426,63.475,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.350 | Acc: 41.268,63.309,72.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.342 | Acc: 41.547,63.310,72.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.338 | Acc: 41.773,63.359,72.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.330 | Acc: 41.857,63.410,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.327 | Acc: 41.866,63.522,72.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.328 | Acc: 41.876,63.417,72.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.327 | Acc: 41.945,63.410,72.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.337 | Acc: 41.859,63.365,72.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.339 | Acc: 41.892,63.354,72.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.342 | Acc: 41.912,63.323,72.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.345 | Acc: 41.933,63.261,72.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.355 | Acc: 41.932,63.190,72.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.359 | Acc: 41.870,63.140,72.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.111 | Acc: 35.938,50.000,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.518 | Acc: 29.836,48.698,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.614 | Acc: 29.364,48.247,56.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.600 | Acc: 29.239,48.181,55.815,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 4.689 | Acc: 41.406,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 41.406,65.439,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.335 | Acc: 41.120,64.234,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.358 | Acc: 40.958,63.832,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.329 | Acc: 41.329,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.324 | Acc: 41.414,64.109,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.325 | Acc: 41.516,63.901,73.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.331 | Acc: 41.345,63.730,73.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.339 | Acc: 41.411,63.694,73.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.361 | Acc: 41.113,63.514,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.358 | Acc: 41.208,63.553,72.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.367 | Acc: 41.300,63.553,72.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.367 | Acc: 41.442,63.628,72.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.377 | Acc: 41.493,63.554,72.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.367 | Acc: 41.656,63.657,72.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.370 | Acc: 41.718,63.621,72.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.370 | Acc: 41.686,63.568,72.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.375 | Acc: 41.677,63.476,72.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.371 | Acc: 41.701,63.476,72.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.371 | Acc: 41.738,63.402,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.465 | Acc: 35.156,49.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.437 | Acc: 30.580,50.112,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.476 | Acc: 29.916,49.581,56.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.502 | Acc: 29.265,49.436,56.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 4.172 | Acc: 39.062,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.274 | Acc: 42.076,63.728,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.297 | Acc: 41.825,63.548,73.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.273 | Acc: 42.188,63.640,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.280 | Acc: 42.245,63.657,73.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.276 | Acc: 42.551,63.707,73.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.276 | Acc: 42.743,63.798,73.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.290 | Acc: 42.509,63.841,73.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.298 | Acc: 42.464,63.631,73.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.307 | Acc: 42.416,63.562,73.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.324 | Acc: 42.203,63.452,73.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.319 | Acc: 42.177,63.465,72.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.319 | Acc: 42.181,63.473,72.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.336 | Acc: 42.065,63.434,72.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.346 | Acc: 42.062,63.412,72.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.344 | Acc: 42.185,63.466,72.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.349 | Acc: 42.071,63.396,72.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.354 | Acc: 42.027,63.350,72.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.358 | Acc: 41.962,63.379,72.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.360 | Acc: 41.980,63.388,72.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.723 | Acc: 25.000,42.969,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.115 | Acc: 24.851,46.131,55.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.242 | Acc: 24.638,45.389,55.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.236 | Acc: 24.731,45.274,55.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 4.292 | Acc: 36.719,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.215 | Acc: 42.783,64.509,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.232 | Acc: 42.302,64.634,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.272 | Acc: 41.714,63.947,73.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.272 | Acc: 41.898,64.024,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.250 | Acc: 42.017,64.186,73.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.262 | Acc: 42.142,64.056,73.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.275 | Acc: 42.282,64.013,73.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.282 | Acc: 42.406,63.830,73.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.290 | Acc: 42.270,63.834,73.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.306 | Acc: 42.059,63.619,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.312 | Acc: 42.099,63.614,72.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.312 | Acc: 42.093,63.661,72.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.321 | Acc: 42.092,63.572,72.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.328 | Acc: 42.096,63.531,72.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.339 | Acc: 42.003,63.473,72.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.340 | Acc: 42.024,63.488,72.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.344 | Acc: 41.935,63.423,72.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.353 | Acc: 41.813,63.247,72.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.362 | Acc: 41.722,63.125,72.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.515 | Acc: 31.250,49.219,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.074 | Acc: 28.497,42.336,53.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.002 | Acc: 29.078,42.092,54.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.002 | Acc: 28.829,42.482,53.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 4.124 | Acc: 42.188,63.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.311 | Acc: 41.927,65.439,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.266 | Acc: 41.921,64.748,73.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.294 | Acc: 41.176,64.203,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.297 | Acc: 41.213,63.918,73.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.305 | Acc: 41.360,63.676,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.303 | Acc: 41.568,63.404,72.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.309 | Acc: 41.578,63.342,72.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.308 | Acc: 41.659,63.165,72.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.308 | Acc: 41.605,63.290,72.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.314 | Acc: 41.542,63.367,72.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.322 | Acc: 41.700,63.437,72.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.332 | Acc: 41.704,63.460,72.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.343 | Acc: 41.634,63.389,72.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.349 | Acc: 41.709,63.309,72.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.353 | Acc: 41.627,63.209,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.356 | Acc: 41.698,63.194,72.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.364 | Acc: 41.608,63.153,71.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.371 | Acc: 41.586,63.080,71.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.370 | Acc: 41.609,63.035,71.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.776 | Acc: 32.031,42.969,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.834 | Acc: 28.311,48.326,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.926 | Acc: 28.335,47.218,54.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.921 | Acc: 27.536,47.170,55.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 4.278 | Acc: 34.375,63.281,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.280 | Acc: 40.588,63.951,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.282 | Acc: 41.178,64.158,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.307 | Acc: 41.457,63.858,73.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.305 | Acc: 41.503,63.831,73.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.309 | Acc: 41.615,63.815,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.301 | Acc: 41.639,63.785,73.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.312 | Acc: 41.672,63.752,73.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.324 | Acc: 41.566,63.407,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.329 | Acc: 41.510,63.303,73.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.332 | Acc: 41.686,63.410,73.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.331 | Acc: 41.802,63.529,73.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.332 | Acc: 41.792,63.570,72.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.336 | Acc: 41.685,63.431,72.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.348 | Acc: 41.509,63.259,72.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.352 | Acc: 41.492,63.222,72.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.353 | Acc: 41.528,63.211,72.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.352 | Acc: 41.578,63.201,72.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.351 | Acc: 41.599,63.240,72.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.351 | Acc: 41.548,63.238,72.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.315 | Acc: 35.938,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.169 | Acc: 34.598,49.702,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.177 | Acc: 34.070,49.123,58.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.184 | Acc: 33.683,49.155,57.979,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 4.308 | Acc: 38.281,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.250 | Acc: 41.443,64.881,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.280 | Acc: 42.111,64.215,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.281 | Acc: 42.188,63.986,73.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.318 | Acc: 41.676,63.513,73.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.321 | Acc: 41.569,63.598,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.324 | Acc: 41.639,63.501,72.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.330 | Acc: 41.484,63.464,72.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.325 | Acc: 41.494,63.470,72.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.323 | Acc: 41.765,63.437,72.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.319 | Acc: 41.884,63.526,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.328 | Acc: 41.852,63.345,72.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.316 | Acc: 41.980,63.502,72.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.325 | Acc: 41.852,63.428,72.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.333 | Acc: 41.762,63.345,72.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.333 | Acc: 41.728,63.460,72.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.336 | Acc: 41.618,63.442,72.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.343 | Acc: 41.649,63.471,72.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.358 | Acc: 41.597,63.376,72.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.365 | Acc: 41.533,63.253,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.941 | Acc: 30.469,43.750,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.910 | Acc: 29.018,44.903,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.984 | Acc: 29.916,44.588,54.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.921 | Acc: 29.547,45.082,55.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 5.000 | Acc: 39.062,53.906,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.260 | Acc: 42.374,64.360,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.255 | Acc: 42.416,64.501,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.263 | Acc: 41.944,64.395,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.251 | Acc: 42.245,64.458,74.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.238 | Acc: 42.288,64.372,73.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.241 | Acc: 42.407,64.327,73.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.270 | Acc: 42.176,64.040,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.258 | Acc: 42.454,64.155,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.267 | Acc: 42.485,63.993,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.284 | Acc: 42.304,63.853,73.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.291 | Acc: 42.184,63.889,73.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.307 | Acc: 42.038,63.758,72.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.318 | Acc: 42.029,63.742,72.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.322 | Acc: 42.018,63.648,72.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.325 | Acc: 42.032,63.629,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.330 | Acc: 41.981,63.585,72.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.343 | Acc: 41.919,63.503,72.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.350 | Acc: 41.841,63.465,72.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.350 | Acc: 41.786,63.449,72.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.427 | Acc: 27.344,42.969,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.416 | Acc: 29.613,48.103,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.425 | Acc: 29.497,47.904,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.418 | Acc: 29.508,48.386,59.106,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 4.123 | Acc: 38.281,67.188,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.160 | Acc: 41.146,65.253,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.203 | Acc: 41.711,64.501,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.200 | Acc: 41.906,64.575,74.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.240 | Acc: 41.599,64.140,74.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.233 | Acc: 41.986,64.225,74.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.236 | Acc: 41.878,64.360,74.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.230 | Acc: 42.154,64.367,73.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.260 | Acc: 42.110,64.130,73.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.268 | Acc: 41.972,64.088,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.268 | Acc: 42.055,64.097,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.266 | Acc: 42.163,64.020,73.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.284 | Acc: 42.110,63.884,73.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.302 | Acc: 42.035,63.805,73.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.308 | Acc: 42.007,63.798,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.315 | Acc: 42.011,63.712,73.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.316 | Acc: 42.076,63.646,73.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.319 | Acc: 42.094,63.618,73.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.329 | Acc: 41.993,63.493,72.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.330 | Acc: 41.997,63.456,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.465 | Acc: 32.812,46.875,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.167 | Acc: 26.190,46.205,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.313 | Acc: 25.133,45.941,53.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.341 | Acc: 24.821,45.466,54.150,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 4.214 | Acc: 42.188,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.296 | Acc: 42.597,62.760,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.237 | Acc: 42.645,63.967,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.225 | Acc: 42.815,64.127,74.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.238 | Acc: 42.506,63.783,73.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.260 | Acc: 42.319,63.838,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.279 | Acc: 42.271,63.720,73.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.276 | Acc: 42.066,63.758,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.278 | Acc: 42.154,63.689,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.288 | Acc: 42.036,63.579,73.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.299 | Acc: 41.954,63.526,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.310 | Acc: 41.922,63.416,73.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.310 | Acc: 42.012,63.505,73.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.304 | Acc: 41.981,63.548,73.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.303 | Acc: 42.048,63.598,73.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.320 | Acc: 41.980,63.510,72.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.330 | Acc: 41.915,63.366,72.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.338 | Acc: 41.897,63.281,72.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.344 | Acc: 41.958,63.270,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.348 | Acc: 41.915,63.193,72.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.802 | Acc: 24.219,48.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.546 | Acc: 25.149,46.540,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.571 | Acc: 25.476,46.456,56.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.635 | Acc: 24.821,46.401,55.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 4.200 | Acc: 40.625,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.249 | Acc: 42.076,64.509,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.243 | Acc: 42.130,64.825,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.283 | Acc: 41.880,64.370,74.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.283 | Acc: 42.110,64.516,74.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.253 | Acc: 42.273,64.527,74.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.254 | Acc: 42.413,64.443,73.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.270 | Acc: 42.453,64.306,73.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.275 | Acc: 42.357,64.203,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.278 | Acc: 42.321,64.205,73.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.277 | Acc: 42.261,64.191,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.267 | Acc: 42.212,64.398,73.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.262 | Acc: 42.230,64.390,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.270 | Acc: 42.253,64.338,73.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.281 | Acc: 42.204,64.193,73.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.291 | Acc: 42.203,64.094,73.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.308 | Acc: 42.097,63.853,73.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.321 | Acc: 42.041,63.746,72.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.325 | Acc: 42.058,63.727,72.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.339 | Acc: 41.991,63.640,72.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.361 | Acc: 29.688,55.469,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.114 | Acc: 24.479,48.847,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.097 | Acc: 25.152,47.866,56.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.102 | Acc: 24.744,47.964,56.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 4.259 | Acc: 41.406,71.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.270 | Acc: 42.150,64.844,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.222 | Acc: 41.768,64.996,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.262 | Acc: 42.008,64.267,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.262 | Acc: 41.763,64.342,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.295 | Acc: 41.623,63.993,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.291 | Acc: 41.587,64.004,73.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.304 | Acc: 41.578,63.990,73.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.299 | Acc: 41.528,63.985,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.302 | Acc: 41.441,63.739,73.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.305 | Acc: 41.321,63.752,73.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.325 | Acc: 41.311,63.578,72.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.335 | Acc: 41.283,63.550,72.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.333 | Acc: 41.406,63.524,72.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.335 | Acc: 41.381,63.437,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.339 | Acc: 41.240,63.406,72.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.333 | Acc: 41.306,63.442,72.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.337 | Acc: 41.376,63.405,72.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.341 | Acc: 41.441,63.424,72.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.340 | Acc: 41.556,63.400,72.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.537 | Acc: 29.688,39.844,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.362 | Acc: 27.269,43.564,54.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.334 | Acc: 26.982,43.579,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.327 | Acc: 26.985,44.006,54.252,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 4.452 | Acc: 34.375,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.267 | Acc: 41.183,64.360,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.238 | Acc: 41.673,63.872,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.213 | Acc: 42.136,64.639,74.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.203 | Acc: 42.101,64.931,74.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.198 | Acc: 42.412,65.138,74.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.227 | Acc: 42.116,65.031,74.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.239 | Acc: 42.193,64.960,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.248 | Acc: 42.212,64.795,73.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.255 | Acc: 42.213,64.783,73.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.258 | Acc: 42.207,64.692,73.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.266 | Acc: 42.301,64.589,73.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.281 | Acc: 42.249,64.416,73.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.291 | Acc: 42.170,64.239,73.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.301 | Acc: 42.057,64.026,72.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.310 | Acc: 41.977,64.016,72.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.311 | Acc: 41.985,63.904,72.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.320 | Acc: 41.901,63.746,72.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.316 | Acc: 41.910,63.753,72.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.323 | Acc: 41.878,63.628,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.223 | Acc: 32.812,45.312,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.099 | Acc: 25.372,44.271,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.169 | Acc: 25.286,44.207,55.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.171 | Acc: 25.320,44.390,55.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 4.372 | Acc: 49.219,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.327 | Acc: 42.113,63.467,73.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.276 | Acc: 42.340,64.291,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.245 | Acc: 42.456,64.690,74.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.268 | Acc: 41.985,64.564,73.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.274 | Acc: 41.979,64.302,73.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.264 | Acc: 42.200,64.360,73.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.272 | Acc: 42.160,64.245,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.275 | Acc: 41.877,64.169,73.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.284 | Acc: 41.851,64.153,73.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.293 | Acc: 41.830,64.129,73.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.299 | Acc: 41.746,63.995,73.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.298 | Acc: 41.792,63.978,73.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.307 | Acc: 41.924,63.868,72.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.301 | Acc: 42.015,63.890,72.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.305 | Acc: 42.060,63.844,72.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.310 | Acc: 42.005,63.795,72.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.318 | Acc: 41.961,63.675,72.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.323 | Acc: 41.941,63.563,72.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.335 | Acc: 41.859,63.480,72.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.960 | Acc: 39.844,49.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.900 | Acc: 35.751,49.554,57.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.903 | Acc: 36.109,49.962,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.931 | Acc: 35.592,49.910,57.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 4.429 | Acc: 32.812,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.271 | Acc: 41.890,63.914,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.225 | Acc: 42.569,64.539,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.215 | Acc: 42.687,64.588,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.207 | Acc: 42.766,64.670,73.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.255 | Acc: 42.218,64.062,73.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.257 | Acc: 42.252,64.056,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.253 | Acc: 42.287,64.035,73.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.243 | Acc: 42.285,63.990,73.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.249 | Acc: 42.248,63.924,73.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.261 | Acc: 42.211,63.818,73.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.277 | Acc: 42.043,63.702,73.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.297 | Acc: 41.918,63.612,72.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.310 | Acc: 41.733,63.563,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.318 | Acc: 41.690,63.568,72.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.318 | Acc: 41.775,63.533,72.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.324 | Acc: 41.754,63.547,72.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.322 | Acc: 41.807,63.565,72.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.328 | Acc: 41.804,63.632,72.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.324 | Acc: 41.859,63.642,72.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.123 | Acc: 35.156,47.656,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.296 | Acc: 30.506,49.665,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.397 | Acc: 30.202,49.505,57.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.432 | Acc: 29.598,49.219,57.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 4.280 | Acc: 44.531,61.719,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.205 | Acc: 42.225,63.876,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.219 | Acc: 41.425,64.425,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.231 | Acc: 41.509,64.203,74.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.237 | Acc: 41.889,64.140,74.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.245 | Acc: 41.793,64.101,73.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.258 | Acc: 41.890,63.914,73.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.278 | Acc: 41.728,63.846,73.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.295 | Acc: 41.668,63.742,73.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.294 | Acc: 41.717,63.812,73.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.298 | Acc: 41.717,63.825,73.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.310 | Acc: 41.647,63.691,73.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.320 | Acc: 41.675,63.628,73.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.316 | Acc: 41.756,63.682,73.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.317 | Acc: 41.823,63.712,73.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.320 | Acc: 41.796,63.704,73.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.322 | Acc: 41.757,63.700,73.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.327 | Acc: 41.709,63.678,72.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.325 | Acc: 41.765,63.645,72.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.330 | Acc: 41.831,63.605,72.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.403 | Acc: 21.875,37.500,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.151 | Acc: 19.940,39.807,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.064 | Acc: 19.989,40.816,53.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.026 | Acc: 19.980,41.022,53.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 3.855 | Acc: 37.500,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 41.778,64.993,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.226 | Acc: 42.550,64.825,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.224 | Acc: 43.174,64.613,74.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.254 | Acc: 42.699,64.053,73.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.264 | Acc: 42.350,63.877,73.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.274 | Acc: 42.116,63.830,73.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.269 | Acc: 42.193,63.918,73.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.266 | Acc: 42.221,64.072,73.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.280 | Acc: 41.937,63.955,73.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.288 | Acc: 41.950,64.004,73.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.284 | Acc: 41.940,63.946,73.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.286 | Acc: 41.996,64.004,73.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.295 | Acc: 42.059,63.952,73.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.307 | Acc: 41.982,63.851,72.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.312 | Acc: 41.923,63.839,72.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.306 | Acc: 41.937,63.831,72.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.322 | Acc: 41.887,63.721,72.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.323 | Acc: 41.787,63.742,72.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.325 | Acc: 41.755,63.724,72.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.275 | Acc: 28.125,45.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.285 | Acc: 26.935,41.778,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.374 | Acc: 25.896,41.254,53.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.374 | Acc: 25.461,41.381,53.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 4.098 | Acc: 41.406,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.369 | Acc: 40.513,62.984,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.283 | Acc: 41.654,64.291,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.235 | Acc: 42.354,64.972,74.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.197 | Acc: 42.766,65.181,74.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.241 | Acc: 42.304,64.867,74.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.244 | Acc: 42.188,64.702,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.249 | Acc: 42.176,64.705,73.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.243 | Acc: 42.328,64.635,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.246 | Acc: 42.455,64.658,73.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.254 | Acc: 42.386,64.568,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.265 | Acc: 42.233,64.405,73.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.274 | Acc: 42.204,64.302,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.289 | Acc: 42.211,64.119,73.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.305 | Acc: 42.154,63.951,73.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.314 | Acc: 42.130,63.834,73.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.316 | Acc: 42.185,63.710,72.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.314 | Acc: 42.162,63.730,72.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.316 | Acc: 42.101,63.688,72.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.323 | Acc: 42.054,63.615,72.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.106 | Acc: 31.250,53.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.684 | Acc: 30.357,49.814,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.698 | Acc: 30.335,48.552,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.737 | Acc: 30.315,48.796,55.136,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 4.031 | Acc: 41.406,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.206 | Acc: 41.592,65.067,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.185 | Acc: 42.816,65.301,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.192 | Acc: 42.738,65.113,74.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.212 | Acc: 42.737,64.747,74.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.224 | Acc: 42.435,64.635,74.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.230 | Acc: 42.433,64.657,74.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.238 | Acc: 42.320,64.533,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.255 | Acc: 42.086,64.373,73.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.244 | Acc: 42.118,64.524,73.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.255 | Acc: 41.931,64.428,73.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.275 | Acc: 41.915,64.186,73.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.282 | Acc: 41.870,64.037,73.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.291 | Acc: 41.867,64.012,73.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.287 | Acc: 41.907,64.029,73.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.290 | Acc: 41.886,64.062,73.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.283 | Acc: 41.942,64.097,73.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.289 | Acc: 41.826,64.005,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.287 | Acc: 41.863,64.008,73.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.288 | Acc: 41.915,64.062,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.637 | Acc: 32.812,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.697 | Acc: 30.990,47.619,55.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.661 | Acc: 31.612,47.637,55.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.673 | Acc: 31.468,47.362,55.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 4.480 | Acc: 37.500,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.089 | Acc: 44.122,66.257,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.202 | Acc: 42.969,65.091,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.232 | Acc: 42.700,64.664,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.233 | Acc: 42.535,64.699,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.256 | Acc: 42.242,64.364,74.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.250 | Acc: 42.097,64.353,73.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.259 | Acc: 42.138,64.229,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.261 | Acc: 41.945,64.295,73.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.268 | Acc: 42.084,64.296,73.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.274 | Acc: 42.180,64.179,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.284 | Acc: 42.173,64.066,73.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.296 | Acc: 42.081,64.056,73.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.289 | Acc: 42.140,64.131,73.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.293 | Acc: 42.082,64.004,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.295 | Acc: 42.211,64.034,73.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.308 | Acc: 42.073,63.831,73.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.310 | Acc: 42.034,63.847,72.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.307 | Acc: 42.030,63.842,72.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.314 | Acc: 41.923,63.786,72.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.639 | Acc: 36.719,53.125,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.150 | Acc: 31.920,54.018,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.178 | Acc: 31.498,53.106,59.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.225 | Acc: 30.776,53.112,59.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 4.556 | Acc: 42.969,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.174 | Acc: 42.597,64.769,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.179 | Acc: 42.797,64.710,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.167 | Acc: 43.033,65.126,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.201 | Acc: 42.361,64.419,74.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.220 | Acc: 42.157,64.341,74.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.233 | Acc: 42.020,64.353,74.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.239 | Acc: 42.104,64.317,73.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.249 | Acc: 42.105,64.179,73.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.259 | Acc: 41.825,64.114,73.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.267 | Acc: 41.764,64.020,73.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.261 | Acc: 41.770,64.133,73.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.270 | Acc: 41.795,64.092,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.271 | Acc: 41.867,64.006,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.284 | Acc: 41.871,63.776,73.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.284 | Acc: 41.967,63.878,73.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.285 | Acc: 42.017,63.829,73.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.293 | Acc: 41.956,63.760,73.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.293 | Acc: 42.008,63.809,73.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.292 | Acc: 42.050,63.839,73.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.638 | Acc: 34.375,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.438 | Acc: 31.845,46.801,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.480 | Acc: 32.489,46.875,54.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.491 | Acc: 32.172,46.901,53.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 4.391 | Acc: 40.625,61.719,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.173 | Acc: 43.155,65.216,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.172 | Acc: 43.178,64.710,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.157 | Acc: 43.443,65.343,74.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.167 | Acc: 43.673,65.075,74.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.162 | Acc: 43.781,64.991,74.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.179 | Acc: 43.530,64.947,74.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.200 | Acc: 43.190,64.761,74.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.203 | Acc: 43.022,64.727,74.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.214 | Acc: 42.969,64.589,74.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.211 | Acc: 42.821,64.568,74.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.218 | Acc: 42.668,64.437,74.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.224 | Acc: 42.664,64.426,74.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.240 | Acc: 42.514,64.404,73.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.248 | Acc: 42.418,64.391,73.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.253 | Acc: 42.367,64.332,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.275 | Acc: 42.278,64.128,73.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.278 | Acc: 42.334,64.138,73.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.287 | Acc: 42.244,64.052,73.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.289 | Acc: 42.229,64.065,73.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.344 | Acc: 26.562,47.656,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.323 | Acc: 29.427,49.479,57.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.315 | Acc: 29.421,49.867,57.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.362 | Acc: 29.406,49.462,57.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 4.053 | Acc: 46.875,67.188,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.172 | Acc: 42.262,64.472,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.118 | Acc: 43.083,65.225,75.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.175 | Acc: 42.546,64.818,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.168 | Acc: 42.612,65.123,74.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.194 | Acc: 42.652,64.968,74.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.181 | Acc: 42.788,65.121,74.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.175 | Acc: 42.913,65.276,74.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.185 | Acc: 42.615,65.261,74.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.206 | Acc: 42.602,65.038,74.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.240 | Acc: 42.347,64.630,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.243 | Acc: 42.233,64.639,73.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.252 | Acc: 42.152,64.581,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.249 | Acc: 42.176,64.509,73.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.257 | Acc: 42.096,64.429,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.259 | Acc: 42.086,64.400,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.264 | Acc: 42.005,64.376,73.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.271 | Acc: 41.942,64.349,73.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.274 | Acc: 41.993,64.251,73.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.280 | Acc: 42.054,64.181,73.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.454 | Acc: 28.906,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.294 | Acc: 30.432,50.707,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.322 | Acc: 30.164,50.724,58.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.351 | Acc: 29.790,50.704,57.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 4.077 | Acc: 42.969,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.365 | Acc: 39.323,62.537,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.285 | Acc: 40.415,63.243,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.281 | Acc: 41.099,63.614,74.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.244 | Acc: 41.551,63.783,74.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.267 | Acc: 41.832,63.761,74.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.256 | Acc: 42.194,63.972,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.261 | Acc: 42.027,63.913,73.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.250 | Acc: 42.231,64.082,73.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.261 | Acc: 42.179,64.028,73.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.278 | Acc: 42.032,63.985,73.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.274 | Acc: 42.113,64.024,73.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.274 | Acc: 42.184,64.118,73.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.274 | Acc: 42.125,64.179,73.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.264 | Acc: 42.218,64.274,73.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.270 | Acc: 42.221,64.223,73.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.275 | Acc: 42.214,64.199,73.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.284 | Acc: 42.169,64.106,73.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.292 | Acc: 42.164,64.024,73.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.289 | Acc: 42.091,64.040,73.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.192 | Acc: 30.469,53.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.237 | Acc: 28.199,52.976,61.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.302 | Acc: 27.477,53.030,60.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.346 | Acc: 27.075,52.766,59.874,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 3.649 | Acc: 48.438,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.064 | Acc: 44.308,66.741,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.126 | Acc: 43.712,65.892,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.143 | Acc: 43.007,65.830,74.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.163 | Acc: 42.911,65.548,74.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.172 | Acc: 42.706,65.285,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.172 | Acc: 42.865,65.322,73.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.173 | Acc: 42.891,65.464,73.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.171 | Acc: 43.056,65.421,73.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.192 | Acc: 42.762,65.224,73.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.203 | Acc: 42.697,65.046,73.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.212 | Acc: 42.559,64.914,73.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.220 | Acc: 42.515,64.844,73.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.226 | Acc: 42.565,64.787,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.222 | Acc: 42.585,64.708,73.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.230 | Acc: 42.491,64.678,73.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.246 | Acc: 42.355,64.561,73.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.262 | Acc: 42.178,64.353,73.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.267 | Acc: 42.170,64.311,73.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.264 | Acc: 42.165,64.302,73.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.838 | Acc: 32.031,47.656,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.740 | Acc: 24.107,44.531,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.773 | Acc: 24.428,43.845,54.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.757 | Acc: 24.129,43.788,53.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 4.459 | Acc: 37.500,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.204 | Acc: 43.266,65.253,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.233 | Acc: 42.969,64.520,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.234 | Acc: 42.764,64.844,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.191 | Acc: 42.670,65.268,74.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.215 | Acc: 42.489,65.053,74.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.211 | Acc: 42.368,65.179,74.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.229 | Acc: 42.248,64.966,74.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.245 | Acc: 42.386,64.742,73.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.256 | Acc: 42.317,64.481,73.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.256 | Acc: 42.289,64.490,73.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.269 | Acc: 42.156,64.207,73.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.277 | Acc: 42.016,64.024,73.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.272 | Acc: 42.008,64.107,73.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.273 | Acc: 42.068,64.088,73.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.274 | Acc: 42.120,64.107,73.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.274 | Acc: 42.124,64.121,73.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.275 | Acc: 42.155,64.131,73.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.273 | Acc: 42.129,64.104,73.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.272 | Acc: 42.181,64.147,73.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.626 | Acc: 38.281,57.812,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.111 | Acc: 32.961,49.107,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.176 | Acc: 32.317,48.952,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.204 | Acc: 31.993,48.988,58.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 4.561 | Acc: 36.719,58.594,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.168 | Acc: 42.262,64.211,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.152 | Acc: 41.635,64.787,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.140 | Acc: 42.047,65.138,75.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.162 | Acc: 42.033,64.709,75.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.184 | Acc: 42.342,64.411,74.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.192 | Acc: 42.336,64.288,74.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.200 | Acc: 42.370,64.123,74.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.216 | Acc: 42.217,63.990,74.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.228 | Acc: 42.058,64.024,74.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.241 | Acc: 41.981,63.926,73.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.236 | Acc: 41.993,64.094,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.244 | Acc: 41.860,64.053,73.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.257 | Acc: 41.894,63.922,73.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.274 | Acc: 41.812,63.823,73.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.273 | Acc: 41.822,63.780,73.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.275 | Acc: 41.830,63.734,73.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.278 | Acc: 41.837,63.753,73.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.279 | Acc: 41.891,63.792,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.282 | Acc: 41.935,63.759,73.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.063 | Acc: 32.031,48.438,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.015 | Acc: 33.110,51.786,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.068 | Acc: 32.450,51.181,59.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.136 | Acc: 31.647,50.794,59.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 4.395 | Acc: 42.969,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.162 | Acc: 42.671,64.881,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.132 | Acc: 42.130,65.111,75.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.123 | Acc: 42.969,65.074,75.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.120 | Acc: 42.824,65.451,75.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.132 | Acc: 42.830,65.308,75.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.156 | Acc: 42.646,65.025,75.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.157 | Acc: 42.681,64.993,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.173 | Acc: 42.522,64.941,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.185 | Acc: 42.559,64.857,74.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.199 | Acc: 42.510,64.719,74.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.199 | Acc: 42.583,64.706,74.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.216 | Acc: 42.482,64.546,74.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.223 | Acc: 42.538,64.476,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.232 | Acc: 42.499,64.388,73.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.237 | Acc: 42.431,64.317,73.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.244 | Acc: 42.394,64.223,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.252 | Acc: 42.281,64.230,73.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.262 | Acc: 42.155,64.153,73.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.272 | Acc: 42.019,64.048,73.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.596 | Acc: 25.781,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.507 | Acc: 24.777,44.792,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.581 | Acc: 24.505,44.226,53.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.612 | Acc: 23.950,44.019,53.227,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 4.067 | Acc: 43.750,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.155 | Acc: 42.857,64.881,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.152 | Acc: 42.435,64.939,75.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.135 | Acc: 42.802,65.266,75.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.146 | Acc: 42.988,65.316,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.178 | Acc: 42.799,64.952,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.183 | Acc: 42.562,64.753,74.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.186 | Acc: 42.509,64.716,74.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.197 | Acc: 42.522,64.669,74.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.207 | Acc: 42.421,64.555,74.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.219 | Acc: 42.428,64.471,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.209 | Acc: 42.534,64.564,74.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.216 | Acc: 42.411,64.542,73.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.220 | Acc: 42.421,64.473,73.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.250 | Acc: 42.246,64.271,73.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.248 | Acc: 42.315,64.345,73.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.252 | Acc: 42.234,64.282,73.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.252 | Acc: 42.318,64.303,73.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.260 | Acc: 42.209,64.214,73.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.262 | Acc: 42.142,64.227,73.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.739 | Acc: 33.594,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.046 | Acc: 28.609,46.168,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.147 | Acc: 27.706,46.151,55.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.220 | Acc: 26.883,46.247,55.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 4.142 | Acc: 44.531,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.103 | Acc: 42.671,66.667,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.139 | Acc: 42.073,66.482,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.206 | Acc: 41.701,65.138,74.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.250 | Acc: 41.406,64.747,74.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.243 | Acc: 41.507,64.813,74.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.249 | Acc: 41.748,64.585,74.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.255 | Acc: 41.777,64.655,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.248 | Acc: 41.843,64.625,74.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.259 | Acc: 41.851,64.546,73.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.268 | Acc: 41.737,64.490,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.269 | Acc: 41.728,64.487,73.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.280 | Acc: 41.724,64.341,73.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.275 | Acc: 41.825,64.332,73.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.272 | Acc: 41.865,64.310,73.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.269 | Acc: 41.798,64.283,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.275 | Acc: 41.822,64.170,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.279 | Acc: 41.842,64.150,73.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.287 | Acc: 41.824,64.032,73.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.288 | Acc: 41.915,63.995,73.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.226 | Acc: 40.625,52.344,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.122 | Acc: 33.705,50.260,58.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.186 | Acc: 33.556,49.562,57.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.200 | Acc: 33.184,49.372,57.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 4.600 | Acc: 42.969,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.225 | Acc: 43.043,65.885,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.222 | Acc: 43.236,64.539,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.179 | Acc: 43.122,64.959,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.181 | Acc: 43.007,64.815,74.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.191 | Acc: 42.814,64.596,74.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.220 | Acc: 42.194,64.353,74.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.220 | Acc: 42.276,64.317,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.223 | Acc: 42.367,64.431,74.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.228 | Acc: 42.136,64.261,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.234 | Acc: 42.098,64.315,73.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.238 | Acc: 42.089,64.345,73.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.247 | Acc: 42.119,64.273,73.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.251 | Acc: 42.125,64.251,73.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.255 | Acc: 42.096,64.232,73.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.257 | Acc: 42.084,64.278,73.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.249 | Acc: 42.163,64.389,73.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.252 | Acc: 42.188,64.402,73.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.260 | Acc: 42.179,64.283,73.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.260 | Acc: 42.226,64.251,73.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.163 | Acc: 30.469,42.188,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.292 | Acc: 24.926,45.312,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.293 | Acc: 24.943,45.332,57.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.323 | Acc: 24.769,45.274,57.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 4.026 | Acc: 46.094,65.625,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.126 | Acc: 42.113,64.621,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.070 | Acc: 42.721,65.168,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.093 | Acc: 42.802,65.100,75.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.106 | Acc: 42.940,65.210,75.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.153 | Acc: 42.830,64.751,75.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.159 | Acc: 42.672,64.960,75.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.184 | Acc: 42.598,64.761,74.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.194 | Acc: 42.440,64.688,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.203 | Acc: 42.412,64.585,74.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.204 | Acc: 42.502,64.665,74.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.217 | Acc: 42.385,64.603,74.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.232 | Acc: 42.301,64.565,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.237 | Acc: 42.367,64.506,73.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.243 | Acc: 42.329,64.404,73.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.242 | Acc: 42.377,64.382,73.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.244 | Acc: 42.365,64.459,73.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.249 | Acc: 42.339,64.402,73.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.250 | Acc: 42.330,64.333,73.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.257 | Acc: 42.290,64.294,73.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.678 | Acc: 35.156,55.469,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.761 | Acc: 34.115,53.311,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.881 | Acc: 33.232,53.125,60.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.912 | Acc: 32.339,52.882,60.272,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 3.654 | Acc: 46.875,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.041 | Acc: 44.457,65.513,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.079 | Acc: 44.188,65.053,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.145 | Acc: 43.225,64.588,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.157 | Acc: 42.911,64.718,74.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.166 | Acc: 42.853,64.697,74.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.191 | Acc: 42.717,64.456,74.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.188 | Acc: 42.570,64.572,74.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.205 | Acc: 42.571,64.465,74.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.207 | Acc: 42.619,64.382,74.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.212 | Acc: 42.771,64.366,74.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.213 | Acc: 42.937,64.395,74.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.214 | Acc: 42.985,64.396,73.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.228 | Acc: 42.879,64.251,73.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.225 | Acc: 42.858,64.313,73.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.229 | Acc: 42.722,64.255,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.241 | Acc: 42.694,64.109,73.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.243 | Acc: 42.701,64.095,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.244 | Acc: 42.774,64.121,73.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.248 | Acc: 42.729,64.147,73.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.047 | Acc: 35.938,46.875,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.197 | Acc: 29.911,44.903,53.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.363 | Acc: 28.773,44.093,52.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.419 | Acc: 27.933,44.045,52.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 4.374 | Acc: 36.719,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.139 | Acc: 43.973,65.885,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.157 | Acc: 42.931,65.244,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.149 | Acc: 43.058,65.087,74.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.150 | Acc: 42.978,64.882,74.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.158 | Acc: 42.915,64.952,74.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.189 | Acc: 42.627,64.740,74.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.189 | Acc: 42.647,64.794,74.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.211 | Acc: 42.401,64.650,73.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.222 | Acc: 42.352,64.537,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.226 | Acc: 42.324,64.373,73.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.232 | Acc: 42.255,64.275,73.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.231 | Acc: 42.350,64.228,73.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.236 | Acc: 42.217,64.131,73.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.236 | Acc: 42.207,64.146,73.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.240 | Acc: 42.273,64.117,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.250 | Acc: 42.287,63.994,73.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.255 | Acc: 42.277,63.980,73.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.252 | Acc: 42.365,64.032,73.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.255 | Acc: 42.345,63.952,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.440 | Acc: 35.938,57.031,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.107 | Acc: 31.882,52.269,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.103 | Acc: 31.784,52.744,60.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.095 | Acc: 31.685,52.600,59.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.136 | Acc: 46.875,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.878 | Acc: 46.354,66.481,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.966 | Acc: 44.512,65.606,76.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.023 | Acc: 43.827,65.599,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.024 | Acc: 43.519,65.828,76.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.038 | Acc: 43.247,65.896,76.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.071 | Acc: 42.982,65.560,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.093 | Acc: 43.412,65.420,75.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.100 | Acc: 43.604,65.266,75.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.111 | Acc: 43.456,64.991,75.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.127 | Acc: 43.330,64.871,75.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.140 | Acc: 43.234,64.791,74.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.158 | Acc: 43.072,64.662,74.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.178 | Acc: 42.843,64.607,74.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.185 | Acc: 42.746,64.591,74.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.202 | Acc: 42.561,64.441,74.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.219 | Acc: 42.467,64.316,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.225 | Acc: 42.421,64.195,73.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.229 | Acc: 42.454,64.192,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.237 | Acc: 42.440,64.169,73.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.388 | Acc: 27.344,49.219,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.792 | Acc: 26.414,47.917,57.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.853 | Acc: 25.457,47.885,57.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.831 | Acc: 25.346,47.964,57.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 4.102 | Acc: 47.656,65.625,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.983 | Acc: 44.420,67.336,76.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.013 | Acc: 43.826,66.482,76.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.078 | Acc: 43.430,66.112,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.100 | Acc: 43.258,65.866,75.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.111 | Acc: 43.348,65.756,75.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.118 | Acc: 43.369,65.496,75.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.122 | Acc: 43.185,65.464,75.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.139 | Acc: 43.119,65.237,75.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.146 | Acc: 43.159,65.098,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.161 | Acc: 43.050,64.960,74.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.166 | Acc: 43.078,64.858,74.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.167 | Acc: 43.043,64.902,74.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.183 | Acc: 42.966,64.790,74.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.201 | Acc: 42.908,64.708,74.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.204 | Acc: 42.904,64.613,74.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.218 | Acc: 42.852,64.464,74.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.221 | Acc: 42.724,64.450,74.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.224 | Acc: 42.748,64.441,73.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.230 | Acc: 42.719,64.352,73.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.433 | Acc: 21.875,42.969,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.317 | Acc: 18.638,42.113,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.380 | Acc: 18.674,42.645,56.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.432 | Acc: 18.238,42.188,55.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 3.626 | Acc: 45.312,71.094,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.097 | Acc: 43.750,66.295,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.101 | Acc: 43.102,65.587,75.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.122 | Acc: 42.892,65.394,75.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.120 | Acc: 43.113,65.471,74.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.144 | Acc: 42.876,65.091,74.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.159 | Acc: 42.807,65.289,74.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.169 | Acc: 42.841,65.049,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.174 | Acc: 42.881,65.120,74.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.182 | Acc: 42.727,65.073,74.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.192 | Acc: 42.576,64.906,74.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.206 | Acc: 42.428,64.770,73.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.219 | Acc: 42.421,64.711,73.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.234 | Acc: 42.337,64.586,73.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.243 | Acc: 42.279,64.480,73.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.246 | Acc: 42.309,64.473,73.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.244 | Acc: 42.409,64.462,73.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.246 | Acc: 42.327,64.420,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.250 | Acc: 42.352,64.361,73.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.250 | Acc: 42.296,64.350,73.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.545 | Acc: 39.062,54.688,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.778 | Acc: 34.598,53.943,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.798 | Acc: 33.803,54.116,59.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.819 | Acc: 33.837,53.689,59.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 3.841 | Acc: 41.406,68.750,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.095 | Acc: 42.597,65.997,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.137 | Acc: 42.492,65.930,75.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.133 | Acc: 42.674,65.817,75.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.129 | Acc: 42.949,65.693,75.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.136 | Acc: 43.031,65.625,75.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.131 | Acc: 43.221,65.664,75.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.142 | Acc: 43.146,65.354,74.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.153 | Acc: 43.027,65.208,74.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.158 | Acc: 42.848,65.232,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.167 | Acc: 42.875,65.089,74.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.175 | Acc: 42.831,64.971,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.189 | Acc: 42.615,64.798,74.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.190 | Acc: 42.541,64.748,74.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.198 | Acc: 42.479,64.671,74.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.209 | Acc: 42.380,64.595,74.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.212 | Acc: 42.407,64.525,74.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.211 | Acc: 42.433,64.541,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.222 | Acc: 42.302,64.422,73.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.231 | Acc: 42.315,64.368,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.956 | Acc: 37.500,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.260 | Acc: 32.589,51.190,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.294 | Acc: 31.441,49.848,56.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.303 | Acc: 31.429,49.859,56.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 4.414 | Acc: 36.719,55.469,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.238 | Acc: 42.076,64.360,73.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.179 | Acc: 41.730,64.787,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.195 | Acc: 41.867,65.036,74.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.200 | Acc: 42.226,64.959,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.203 | Acc: 42.273,64.898,74.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.188 | Acc: 42.691,65.063,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.208 | Acc: 42.337,64.855,74.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.196 | Acc: 42.498,64.887,74.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.200 | Acc: 42.408,64.956,74.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.193 | Acc: 42.479,65.073,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.187 | Acc: 42.453,65.098,74.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.196 | Acc: 42.356,64.954,74.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.191 | Acc: 42.451,64.949,74.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.197 | Acc: 42.471,64.905,74.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.210 | Acc: 42.369,64.836,74.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.226 | Acc: 42.287,64.644,73.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.230 | Acc: 42.194,64.580,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.232 | Acc: 42.185,64.552,73.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.238 | Acc: 42.175,64.530,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.456 | Acc: 26.562,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.835 | Acc: 23.251,51.079,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.881 | Acc: 22.904,50.877,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.900 | Acc: 22.836,51.140,59.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 3.819 | Acc: 46.094,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.033 | Acc: 43.192,66.890,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.127 | Acc: 42.550,65.606,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.165 | Acc: 42.072,65.061,74.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.162 | Acc: 42.216,65.095,74.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.141 | Acc: 42.427,65.447,74.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.149 | Acc: 42.691,65.322,74.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.172 | Acc: 42.559,65.154,74.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.185 | Acc: 42.450,64.941,74.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.192 | Acc: 42.485,64.844,73.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.197 | Acc: 42.382,64.723,73.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.199 | Acc: 42.393,64.709,73.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.206 | Acc: 42.453,64.617,73.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.209 | Acc: 42.487,64.679,73.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.218 | Acc: 42.449,64.674,73.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.221 | Acc: 42.325,64.696,73.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.231 | Acc: 42.290,64.564,73.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.230 | Acc: 42.316,64.505,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.238 | Acc: 42.322,64.510,73.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.241 | Acc: 42.282,64.475,73.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.062 | Acc: 24.219,39.062,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.952 | Acc: 22.768,43.304,53.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.883 | Acc: 22.828,43.197,53.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.850 | Acc: 22.746,43.660,53.343,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 3.616 | Acc: 45.312,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.900 | Acc: 44.122,68.936,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.808 | Acc: 45.122,69.627,79.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.783 | Acc: 45.236,69.890,78.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.743 | Acc: 45.486,70.177,79.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.706 | Acc: 45.900,70.367,79.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.669 | Acc: 46.423,70.861,80.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.647 | Acc: 46.315,70.972,80.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.645 | Acc: 46.283,71.026,80.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.629 | Acc: 46.301,71.180,80.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.609 | Acc: 46.525,71.230,80.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.603 | Acc: 46.620,71.355,80.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.592 | Acc: 46.648,71.356,81.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.585 | Acc: 46.710,71.399,81.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.570 | Acc: 46.750,71.533,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.560 | Acc: 46.940,71.711,81.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.553 | Acc: 46.965,71.809,81.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.552 | Acc: 46.909,71.864,81.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.550 | Acc: 46.845,71.849,81.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.542 | Acc: 46.939,71.920,81.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.201 | Acc: 50.000,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 45.499,64.881,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.330 | Acc: 44.703,63.872,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.343 | Acc: 44.595,63.665,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.465 | Acc: 47.656,74.219,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.333 | Acc: 48.065,74.144,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.372 | Acc: 47.885,73.285,84.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.349 | Acc: 47.925,73.860,84.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.343 | Acc: 47.926,73.785,84.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.348 | Acc: 47.973,73.855,84.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.348 | Acc: 48.024,73.586,84.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.354 | Acc: 47.944,73.559,83.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.354 | Acc: 47.894,73.714,84.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.360 | Acc: 47.842,73.563,83.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.360 | Acc: 47.921,73.554,83.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.363 | Acc: 47.904,73.568,83.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.363 | Acc: 47.864,73.538,83.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.361 | Acc: 47.923,73.479,83.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.361 | Acc: 47.862,73.468,83.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.365 | Acc: 47.734,73.443,83.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.363 | Acc: 47.700,73.476,83.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.366 | Acc: 47.684,73.387,83.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.365 | Acc: 47.721,73.455,83.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.368 | Acc: 47.751,73.349,84.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.221 | Acc: 46.094,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.329 | Acc: 44.903,65.179,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.367 | Acc: 44.379,64.234,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 44.121,63.934,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.333 | Acc: 53.906,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.303 | Acc: 49.107,73.698,84.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.285 | Acc: 48.533,73.666,84.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.269 | Acc: 48.745,73.770,85.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.288 | Acc: 48.206,73.563,85.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.290 | Acc: 48.058,73.739,85.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.294 | Acc: 48.018,73.696,85.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.277 | Acc: 48.288,73.958,85.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.270 | Acc: 48.316,74.209,85.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.275 | Acc: 48.222,74.240,85.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.273 | Acc: 48.193,74.223,85.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.268 | Acc: 48.155,74.286,85.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.274 | Acc: 48.126,74.280,85.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.277 | Acc: 48.087,74.234,85.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.281 | Acc: 48.143,74.199,85.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.284 | Acc: 48.295,74.151,85.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.286 | Acc: 48.255,74.165,85.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.285 | Acc: 48.211,74.152,85.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.290 | Acc: 48.212,74.093,85.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.295 | Acc: 48.107,74.030,85.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.188 | Acc: 49.219,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.299 | Acc: 46.019,65.290,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 45.655,64.729,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.338 | Acc: 45.082,64.331,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 2.979 | Acc: 47.656,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.227 | Acc: 47.768,75.037,87.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.213 | Acc: 47.961,74.752,86.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.209 | Acc: 48.322,75.179,86.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.188 | Acc: 48.563,75.347,86.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.186 | Acc: 48.615,75.309,86.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.200 | Acc: 48.767,75.265,86.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.212 | Acc: 48.576,75.017,86.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.219 | Acc: 48.515,74.922,86.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.229 | Acc: 48.494,74.888,86.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.234 | Acc: 48.426,74.813,86.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.248 | Acc: 48.169,74.625,86.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.253 | Acc: 48.194,74.634,86.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.252 | Acc: 48.210,74.542,86.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.252 | Acc: 48.251,74.530,85.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.253 | Acc: 48.175,74.432,85.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.249 | Acc: 48.175,74.460,85.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.251 | Acc: 48.176,74.457,85.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.255 | Acc: 48.156,74.437,85.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.258 | Acc: 48.189,74.409,85.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.297 | Acc: 48.438,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.279 | Acc: 45.275,65.737,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.307 | Acc: 44.950,64.825,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.325 | Acc: 44.826,64.242,70.850,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 3.192 | Acc: 48.438,78.906,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.159 | Acc: 49.107,75.484,86.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.167 | Acc: 48.876,75.610,86.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.192 | Acc: 48.489,74.974,86.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.215 | Acc: 48.495,74.865,86.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.211 | Acc: 48.631,74.822,86.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.201 | Acc: 48.644,75.142,86.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.220 | Acc: 48.498,74.828,86.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.215 | Acc: 48.622,74.680,86.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.215 | Acc: 48.589,74.676,86.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.218 | Acc: 48.430,74.685,86.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.227 | Acc: 48.367,74.668,86.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.223 | Acc: 48.415,74.708,86.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.222 | Acc: 48.318,74.692,86.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.219 | Acc: 48.340,74.736,86.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.219 | Acc: 48.370,74.782,86.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.221 | Acc: 48.408,74.793,86.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.219 | Acc: 48.438,74.785,86.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.221 | Acc: 48.414,74.725,86.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.220 | Acc: 48.462,74.727,86.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.186 | Acc: 50.000,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.289 | Acc: 46.094,65.141,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.323 | Acc: 45.598,64.482,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.335 | Acc: 45.184,64.229,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.340 | Acc: 41.406,69.531,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.111 | Acc: 50.186,75.781,88.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.106 | Acc: 49.466,76.505,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.149 | Acc: 48.860,75.948,87.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.155 | Acc: 48.698,75.376,87.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.139 | Acc: 48.817,75.472,87.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.166 | Acc: 48.399,75.161,87.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.176 | Acc: 48.415,75.116,87.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.174 | Acc: 48.539,75.121,87.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.171 | Acc: 48.584,75.065,87.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.177 | Acc: 48.624,74.988,87.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.169 | Acc: 48.706,75.039,87.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.168 | Acc: 48.765,74.984,87.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.173 | Acc: 48.644,75.045,87.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.185 | Acc: 48.485,74.969,87.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.180 | Acc: 48.598,75.010,87.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.184 | Acc: 48.532,75.017,87.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.180 | Acc: 48.669,75.053,87.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.179 | Acc: 48.715,75.022,87.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.183 | Acc: 48.692,74.971,87.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.343 | Acc: 51.562,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.312 | Acc: 45.647,65.997,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.362 | Acc: 45.084,64.291,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.368 | Acc: 44.775,63.934,70.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 2.999 | Acc: 53.125,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.209 | Acc: 48.400,74.293,87.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.156 | Acc: 47.980,75.229,87.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.171 | Acc: 48.489,74.898,87.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.176 | Acc: 48.534,74.990,87.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.181 | Acc: 48.414,74.861,87.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.182 | Acc: 48.418,74.884,87.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.187 | Acc: 48.349,74.856,87.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.190 | Acc: 48.156,74.709,87.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.188 | Acc: 48.286,74.793,87.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.181 | Acc: 48.309,74.918,87.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.170 | Acc: 48.501,74.908,87.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.164 | Acc: 48.570,75.029,87.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.159 | Acc: 48.647,75.114,87.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.155 | Acc: 48.677,75.150,87.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.157 | Acc: 48.726,75.169,87.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.158 | Acc: 48.688,75.183,87.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.157 | Acc: 48.772,75.250,87.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.154 | Acc: 48.788,75.225,87.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.155 | Acc: 48.778,75.201,87.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.126 | Acc: 46.875,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 44.903,64.955,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.345 | Acc: 44.341,64.120,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.361 | Acc: 44.249,63.998,70.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.129 | Acc: 49.219,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.124 | Acc: 49.926,76.376,88.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.097 | Acc: 49.428,76.010,88.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.095 | Acc: 49.475,76.063,88.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.119 | Acc: 49.074,75.762,87.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.108 | Acc: 49.041,75.735,88.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.107 | Acc: 49.180,75.846,88.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.112 | Acc: 49.285,75.693,88.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.108 | Acc: 49.364,75.645,88.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.109 | Acc: 49.301,75.807,88.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.120 | Acc: 49.102,75.746,87.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.115 | Acc: 49.304,75.732,87.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.111 | Acc: 49.293,75.684,87.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.115 | Acc: 49.249,75.635,87.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.111 | Acc: 49.208,75.648,87.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.123 | Acc: 48.980,75.548,87.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.126 | Acc: 48.912,75.574,87.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.135 | Acc: 48.749,75.467,87.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.136 | Acc: 48.699,75.441,87.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.142 | Acc: 48.632,75.357,87.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.187 | Acc: 47.656,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.274 | Acc: 45.610,65.141,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.313 | Acc: 45.008,64.577,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.356 | Acc: 44.736,64.088,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 3.206 | Acc: 49.219,71.875,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.144 | Acc: 48.884,74.256,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.118 | Acc: 48.952,75.152,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.122 | Acc: 48.899,75.615,88.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.097 | Acc: 49.122,75.801,88.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.103 | Acc: 49.157,75.719,88.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.095 | Acc: 49.251,75.846,88.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.080 | Acc: 49.424,75.970,88.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.088 | Acc: 49.097,75.810,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.084 | Acc: 49.331,75.876,88.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.101 | Acc: 49.168,75.731,88.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.104 | Acc: 49.162,75.718,87.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.099 | Acc: 49.222,75.710,88.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.099 | Acc: 49.168,75.748,88.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.110 | Acc: 49.169,75.628,87.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.111 | Acc: 49.172,75.589,87.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.114 | Acc: 49.121,75.523,87.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.111 | Acc: 49.079,75.529,87.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.116 | Acc: 49.065,75.489,87.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.122 | Acc: 49.049,75.398,87.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.284 | Acc: 50.000,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.357 | Acc: 45.647,64.062,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.373 | Acc: 45.446,63.929,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.385 | Acc: 45.274,63.973,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 2.858 | Acc: 54.688,78.125,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.104 | Acc: 49.219,75.074,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.114 | Acc: 49.162,75.553,88.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.132 | Acc: 48.706,75.512,88.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.124 | Acc: 48.052,75.550,88.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.114 | Acc: 48.422,75.541,88.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.098 | Acc: 48.786,75.633,88.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.106 | Acc: 48.836,75.510,88.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.110 | Acc: 48.738,75.476,88.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.112 | Acc: 48.774,75.470,88.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.107 | Acc: 48.706,75.490,88.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.105 | Acc: 48.837,75.534,88.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.106 | Acc: 48.771,75.434,88.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.105 | Acc: 48.794,75.404,88.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.102 | Acc: 48.841,75.325,88.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.101 | Acc: 48.884,75.356,88.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.104 | Acc: 48.893,75.316,88.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.103 | Acc: 48.942,75.309,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.102 | Acc: 48.976,75.344,88.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.106 | Acc: 48.940,75.320,88.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.166 | Acc: 50.000,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.320 | Acc: 45.126,64.955,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.350 | Acc: 44.970,64.425,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.372 | Acc: 44.864,64.075,70.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 2.662 | Acc: 56.250,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.070 | Acc: 49.479,74.963,88.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.025 | Acc: 49.143,75.857,88.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 49.372,76.319,88.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.018 | Acc: 49.074,76.341,88.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.010 | Acc: 49.489,76.624,88.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.034 | Acc: 49.270,76.472,88.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.055 | Acc: 49.102,76.197,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.060 | Acc: 49.204,76.126,88.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.062 | Acc: 49.098,76.079,88.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.068 | Acc: 49.110,76.003,88.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.074 | Acc: 49.130,75.983,88.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.082 | Acc: 49.002,75.872,88.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.080 | Acc: 49.138,75.889,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.080 | Acc: 49.230,75.848,88.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.082 | Acc: 49.162,75.877,88.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.083 | Acc: 49.146,75.864,88.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.085 | Acc: 49.139,75.790,88.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.085 | Acc: 49.124,75.751,88.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.091 | Acc: 49.065,75.695,88.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.337 | Acc: 47.656,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.304 | Acc: 46.577,65.402,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.341 | Acc: 45.694,64.596,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.356 | Acc: 45.492,64.165,70.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 2.948 | Acc: 48.438,73.438,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 48.847,77.083,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.000 | Acc: 49.028,76.791,88.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.005 | Acc: 49.347,76.947,88.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.027 | Acc: 48.659,77.006,88.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.042 | Acc: 48.445,76.748,88.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.029 | Acc: 48.857,76.847,88.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.029 | Acc: 48.920,76.845,89.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.029 | Acc: 49.020,76.737,88.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.034 | Acc: 49.085,76.493,88.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.047 | Acc: 48.939,76.380,88.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.049 | Acc: 48.961,76.407,88.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.041 | Acc: 49.102,76.329,88.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.047 | Acc: 49.021,76.269,88.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.052 | Acc: 48.988,76.204,88.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.056 | Acc: 49.001,76.139,88.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.053 | Acc: 49.109,76.197,88.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.058 | Acc: 49.095,76.097,88.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.067 | Acc: 49.024,75.959,88.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.066 | Acc: 48.962,75.958,88.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.202 | Acc: 50.000,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.343 | Acc: 45.275,64.658,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.380 | Acc: 44.779,64.444,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.392 | Acc: 44.762,64.165,70.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 3.336 | Acc: 47.656,71.094,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.997 | Acc: 50.372,75.893,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.041 | Acc: 49.409,75.495,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.023 | Acc: 49.910,75.807,89.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.033 | Acc: 49.720,75.781,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.042 | Acc: 49.714,75.843,89.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.044 | Acc: 49.522,75.968,89.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.038 | Acc: 49.512,75.986,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.043 | Acc: 49.427,75.830,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.045 | Acc: 49.163,75.868,88.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.046 | Acc: 49.238,75.902,88.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.051 | Acc: 49.113,75.905,88.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.053 | Acc: 49.105,75.911,88.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.055 | Acc: 49.090,75.889,88.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.056 | Acc: 49.032,75.876,88.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.052 | Acc: 48.972,75.963,88.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.053 | Acc: 48.956,75.954,88.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.060 | Acc: 48.861,75.871,88.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.055 | Acc: 48.976,75.889,88.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.057 | Acc: 48.989,75.892,88.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.370 | Acc: 45.312,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.405 | Acc: 45.164,64.546,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.418 | Acc: 44.798,64.329,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.442 | Acc: 44.557,63.960,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 2.955 | Acc: 54.688,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.958 | Acc: 49.665,77.567,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.920 | Acc: 50.248,78.182,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.942 | Acc: 49.923,77.946,90.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.972 | Acc: 49.846,77.556,90.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.983 | Acc: 49.737,77.359,89.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.982 | Acc: 49.690,77.215,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.984 | Acc: 49.668,77.139,89.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.998 | Acc: 49.675,76.951,89.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.996 | Acc: 49.732,76.826,89.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.002 | Acc: 49.724,76.757,89.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.009 | Acc: 49.551,76.753,89.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.015 | Acc: 49.611,76.660,89.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.022 | Acc: 49.485,76.557,89.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.023 | Acc: 49.438,76.510,89.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.024 | Acc: 49.315,76.441,89.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.028 | Acc: 49.321,76.412,89.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.032 | Acc: 49.283,76.388,89.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.036 | Acc: 49.223,76.307,88.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.043 | Acc: 49.108,76.228,88.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.273 | Acc: 51.562,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.434 | Acc: 45.015,64.472,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.458 | Acc: 45.274,64.043,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.487 | Acc: 44.685,63.691,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 3.288 | Acc: 46.094,69.531,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.914 | Acc: 51.079,77.269,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.932 | Acc: 50.286,77.458,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.993 | Acc: 49.552,76.691,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.020 | Acc: 49.219,76.611,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.022 | Acc: 49.002,76.493,89.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.018 | Acc: 49.012,76.298,89.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.015 | Acc: 48.958,76.291,89.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.011 | Acc: 49.151,76.296,89.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.005 | Acc: 49.227,76.537,89.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.013 | Acc: 49.118,76.469,89.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.021 | Acc: 48.971,76.375,89.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.019 | Acc: 49.002,76.290,89.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.021 | Acc: 49.090,76.296,89.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.021 | Acc: 49.121,76.279,89.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.025 | Acc: 49.169,76.287,89.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.027 | Acc: 49.199,76.246,89.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.029 | Acc: 49.237,76.255,89.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.024 | Acc: 49.256,76.307,89.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.025 | Acc: 49.280,76.261,89.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.285 | Acc: 46.875,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.350 | Acc: 45.312,65.253,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.369 | Acc: 44.989,64.653,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 45.005,64.139,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 3.087 | Acc: 49.219,75.781,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.016 | Acc: 48.958,76.153,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.028 | Acc: 48.876,75.953,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.031 | Acc: 48.911,75.768,89.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.016 | Acc: 49.055,75.974,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.015 | Acc: 49.087,76.168,89.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.007 | Acc: 49.180,76.253,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.015 | Acc: 49.053,76.313,89.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.013 | Acc: 49.224,76.257,89.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.012 | Acc: 49.115,76.329,89.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.004 | Acc: 49.160,76.426,89.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.999 | Acc: 49.251,76.534,89.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.003 | Acc: 49.245,76.465,89.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.007 | Acc: 49.276,76.398,89.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.008 | Acc: 49.347,76.335,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.006 | Acc: 49.369,76.313,89.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.015 | Acc: 49.224,76.234,89.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.017 | Acc: 49.336,76.230,89.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.017 | Acc: 49.318,76.188,89.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.018 | Acc: 49.276,76.177,89.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.515 | Acc: 46.875,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.406 | Acc: 45.387,65.067,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.445 | Acc: 44.646,64.329,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.464 | Acc: 44.442,64.050,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 2.951 | Acc: 52.344,78.906,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.057 | Acc: 48.438,76.414,89.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.079 | Acc: 48.418,75.438,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.038 | Acc: 49.078,75.961,89.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.035 | Acc: 48.688,75.752,89.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.025 | Acc: 48.399,75.789,89.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.008 | Acc: 48.644,76.065,89.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.996 | Acc: 48.931,76.208,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.001 | Acc: 49.088,76.145,89.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.004 | Acc: 49.076,76.191,89.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.002 | Acc: 49.083,76.271,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.999 | Acc: 49.141,76.322,89.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.998 | Acc: 49.147,76.352,89.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.996 | Acc: 49.222,76.449,89.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.998 | Acc: 49.241,76.482,89.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.002 | Acc: 49.216,76.456,89.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.008 | Acc: 49.207,76.429,89.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.006 | Acc: 49.189,76.386,89.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.005 | Acc: 49.201,76.376,89.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.005 | Acc: 49.252,76.374,89.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.268 | Acc: 46.875,64.062,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.408 | Acc: 45.796,64.621,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.441 | Acc: 45.408,64.577,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.456 | Acc: 45.402,64.242,70.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 2.564 | Acc: 57.812,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.978 | Acc: 49.107,75.930,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.937 | Acc: 49.409,76.753,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.953 | Acc: 49.296,76.998,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.969 | Acc: 49.518,76.755,90.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.975 | Acc: 49.319,76.539,90.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.971 | Acc: 49.419,76.640,90.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.976 | Acc: 49.601,76.490,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.986 | Acc: 49.384,76.349,90.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.989 | Acc: 49.301,76.360,90.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.991 | Acc: 49.277,76.376,90.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.989 | Acc: 49.332,76.464,90.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.987 | Acc: 49.365,76.491,90.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.993 | Acc: 49.273,76.332,90.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.991 | Acc: 49.269,76.382,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.992 | Acc: 49.278,76.425,89.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.995 | Acc: 49.224,76.368,89.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.995 | Acc: 49.232,76.398,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.994 | Acc: 49.320,76.376,89.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.995 | Acc: 49.383,76.357,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.347 | Acc: 46.875,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.384 | Acc: 45.387,65.030,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.425 | Acc: 45.312,64.253,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.447 | Acc: 44.877,64.088,70.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 3.167 | Acc: 42.969,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.021 | Acc: 49.293,75.893,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.985 | Acc: 49.104,76.867,89.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.965 | Acc: 49.296,76.985,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.956 | Acc: 49.373,76.871,90.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.954 | Acc: 49.381,76.864,90.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.947 | Acc: 49.412,76.853,90.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.952 | Acc: 49.463,76.756,90.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.956 | Acc: 49.510,76.703,90.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.956 | Acc: 49.538,76.761,90.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.961 | Acc: 49.436,76.687,90.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.959 | Acc: 49.629,76.718,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.959 | Acc: 49.543,76.763,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.964 | Acc: 49.644,76.763,90.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.961 | Acc: 49.652,76.749,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.967 | Acc: 49.517,76.775,90.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.966 | Acc: 49.535,76.803,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.971 | Acc: 49.521,76.760,89.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.967 | Acc: 49.576,76.788,89.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.972 | Acc: 49.539,76.727,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.288 | Acc: 47.656,64.062,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.422 | Acc: 46.057,64.472,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.450 | Acc: 45.351,64.463,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.460 | Acc: 45.236,64.024,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 2.750 | Acc: 55.469,75.781,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 49.740,77.009,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.934 | Acc: 49.409,77.420,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.964 | Acc: 49.116,76.639,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.947 | Acc: 49.470,77.045,90.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.927 | Acc: 49.598,77.235,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.935 | Acc: 49.613,77.040,90.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.953 | Acc: 49.208,76.862,90.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.947 | Acc: 49.355,76.912,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.955 | Acc: 49.417,76.761,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.954 | Acc: 49.448,76.761,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.957 | Acc: 49.487,76.683,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.960 | Acc: 49.423,76.640,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.969 | Acc: 49.365,76.619,90.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.967 | Acc: 49.427,76.638,90.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.964 | Acc: 49.356,76.708,90.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.963 | Acc: 49.435,76.735,90.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.967 | Acc: 49.363,76.677,90.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.970 | Acc: 49.292,76.634,90.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.970 | Acc: 49.366,76.659,90.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.439 | Acc: 47.656,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.421 | Acc: 45.461,64.546,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.452 | Acc: 45.008,63.948,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.458 | Acc: 44.903,63.806,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 3.143 | Acc: 49.219,75.781,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.861 | Acc: 51.042,77.902,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.948 | Acc: 49.771,77.268,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.939 | Acc: 49.513,77.126,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.932 | Acc: 49.470,77.064,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.937 | Acc: 49.536,76.864,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.943 | Acc: 49.354,76.776,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.947 | Acc: 49.479,76.684,90.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.936 | Acc: 49.782,76.703,90.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.946 | Acc: 49.603,76.718,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.956 | Acc: 49.499,76.597,90.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.958 | Acc: 49.491,76.676,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.954 | Acc: 49.507,76.657,90.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.958 | Acc: 49.503,76.583,90.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.954 | Acc: 49.577,76.626,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.952 | Acc: 49.642,76.617,90.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.954 | Acc: 49.635,76.626,90.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.958 | Acc: 49.583,76.569,90.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.960 | Acc: 49.524,76.556,90.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.962 | Acc: 49.543,76.511,90.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.461 | Acc: 51.562,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.426 | Acc: 45.052,65.476,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.455 | Acc: 45.160,64.729,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.464 | Acc: 45.197,64.562,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 3.166 | Acc: 43.750,75.781,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.923 | Acc: 50.744,77.344,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.960 | Acc: 49.238,77.077,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.953 | Acc: 49.539,76.857,90.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.932 | Acc: 49.846,77.373,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.920 | Acc: 50.263,77.189,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.928 | Acc: 50.200,77.163,90.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.939 | Acc: 49.989,77.056,90.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.930 | Acc: 49.981,77.174,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.935 | Acc: 49.953,77.180,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.935 | Acc: 49.868,77.111,90.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.945 | Acc: 49.593,76.983,90.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.949 | Acc: 49.605,77.029,90.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.946 | Acc: 49.647,77.000,90.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.951 | Acc: 49.544,76.966,90.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.948 | Acc: 49.561,76.952,90.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.950 | Acc: 49.530,76.898,90.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.948 | Acc: 49.633,76.931,90.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.946 | Acc: 49.634,76.989,90.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.946 | Acc: 49.674,76.946,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.362 | Acc: 50.000,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.391 | Acc: 45.015,64.881,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.428 | Acc: 45.160,64.367,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.444 | Acc: 45.184,64.139,69.864,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 2.896 | Acc: 44.531,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.972 | Acc: 49.702,76.972,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.935 | Acc: 49.638,77.001,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 49.680,76.998,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.908 | Acc: 50.029,77.247,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.905 | Acc: 49.706,77.251,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.898 | Acc: 49.839,77.286,90.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.913 | Acc: 49.668,77.205,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.921 | Acc: 49.617,77.077,90.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.922 | Acc: 49.715,77.150,90.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.932 | Acc: 49.588,77.056,90.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.923 | Acc: 49.668,77.185,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.928 | Acc: 49.536,77.049,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.934 | Acc: 49.404,76.952,90.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.936 | Acc: 49.477,76.946,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.936 | Acc: 49.561,76.936,90.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.938 | Acc: 49.642,76.879,90.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.933 | Acc: 49.716,76.963,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.937 | Acc: 49.595,76.920,90.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.941 | Acc: 49.573,76.839,90.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.301 | Acc: 47.656,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.420 | Acc: 45.759,64.137,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.458 | Acc: 45.179,63.567,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.470 | Acc: 45.108,63.717,69.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 3.069 | Acc: 49.219,72.656,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.922 | Acc: 49.814,77.158,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 49.829,76.734,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.923 | Acc: 49.962,76.870,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.918 | Acc: 49.932,76.939,90.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.917 | Acc: 49.838,76.880,90.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.926 | Acc: 49.716,76.976,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.929 | Acc: 49.535,77.083,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.921 | Acc: 49.622,77.358,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.910 | Acc: 49.737,77.404,90.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.914 | Acc: 49.693,77.379,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.918 | Acc: 49.664,77.284,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.909 | Acc: 49.718,77.370,90.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.918 | Acc: 49.656,77.224,90.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.914 | Acc: 49.705,77.277,90.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.919 | Acc: 49.639,77.152,90.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.921 | Acc: 49.623,77.115,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.927 | Acc: 49.507,77.069,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.932 | Acc: 49.487,76.991,90.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.934 | Acc: 49.479,76.983,90.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.425 | Acc: 44.531,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 44.457,63.988,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.505 | Acc: 44.379,63.434,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 44.557,63.166,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 3.004 | Acc: 46.875,71.875,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.978 | Acc: 49.442,76.339,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.927 | Acc: 49.238,76.677,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.933 | Acc: 49.769,76.767,90.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.944 | Acc: 49.450,76.755,90.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.958 | Acc: 49.188,76.431,90.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.946 | Acc: 49.606,76.627,90.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.922 | Acc: 49.861,76.906,90.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.919 | Acc: 49.835,77.019,90.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.923 | Acc: 49.883,77.059,90.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.916 | Acc: 49.848,77.192,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.921 | Acc: 49.781,77.110,90.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.924 | Acc: 49.692,77.058,90.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.921 | Acc: 49.811,77.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.923 | Acc: 49.864,77.171,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.930 | Acc: 49.829,77.076,90.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.933 | Acc: 49.810,77.044,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.938 | Acc: 49.686,77.030,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.937 | Acc: 49.673,77.084,90.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.939 | Acc: 49.615,77.085,90.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.453 | Acc: 49.219,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.410 | Acc: 45.982,64.658,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.440 | Acc: 45.503,64.444,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.455 | Acc: 45.556,63.986,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 2.671 | Acc: 52.344,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.903 | Acc: 50.744,77.493,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.893 | Acc: 49.371,77.268,91.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.892 | Acc: 49.078,77.536,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.879 | Acc: 49.363,77.730,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.899 | Acc: 49.033,77.498,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.885 | Acc: 49.199,77.518,91.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.890 | Acc: 49.341,77.565,91.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.898 | Acc: 49.078,77.484,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.903 | Acc: 49.137,77.400,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.904 | Acc: 49.145,77.464,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.899 | Acc: 49.258,77.467,91.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.895 | Acc: 49.391,77.535,91.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.899 | Acc: 49.485,77.452,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.902 | Acc: 49.419,77.508,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.903 | Acc: 49.390,77.515,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.910 | Acc: 49.377,77.409,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.912 | Acc: 49.379,77.412,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.913 | Acc: 49.377,77.376,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.912 | Acc: 49.393,77.354,90.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.416 | Acc: 47.656,64.062,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.476 | Acc: 44.978,63.765,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.510 | Acc: 45.046,63.529,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.517 | Acc: 45.210,63.576,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 2.548 | Acc: 46.875,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.856 | Acc: 49.740,77.046,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.837 | Acc: 49.752,77.973,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.851 | Acc: 50.090,78.048,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.862 | Acc: 50.289,78.221,91.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.868 | Acc: 49.899,78.055,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.870 | Acc: 49.722,77.873,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.888 | Acc: 49.523,77.759,91.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.882 | Acc: 49.670,77.790,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.885 | Acc: 49.685,77.793,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.888 | Acc: 49.561,77.709,91.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.885 | Acc: 49.611,77.793,91.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.888 | Acc: 49.572,77.642,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.892 | Acc: 49.575,77.553,91.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 49.597,77.566,91.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.899 | Acc: 49.447,77.424,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.896 | Acc: 49.562,77.461,91.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.895 | Acc: 49.599,77.445,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.900 | Acc: 49.597,77.361,90.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.905 | Acc: 49.524,77.254,90.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.582 | Acc: 50.000,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.493 | Acc: 45.350,64.211,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.528 | Acc: 45.084,63.758,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 44.864,63.601,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.883 | Acc: 56.250,81.250,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.872 | Acc: 49.591,77.530,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.879 | Acc: 50.038,77.630,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.893 | Acc: 49.949,77.433,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.895 | Acc: 49.932,77.411,91.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.882 | Acc: 50.209,77.483,91.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.896 | Acc: 50.071,77.318,91.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.903 | Acc: 49.867,77.277,91.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.908 | Acc: 49.782,77.072,91.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.904 | Acc: 49.888,77.210,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.906 | Acc: 49.755,77.212,90.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.901 | Acc: 49.855,77.216,90.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.888 | Acc: 49.948,77.412,90.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.887 | Acc: 49.913,77.431,91.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 49.850,77.308,91.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 49.865,77.240,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.902 | Acc: 49.744,77.137,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.909 | Acc: 49.627,77.133,90.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.913 | Acc: 49.582,77.151,90.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.913 | Acc: 49.569,77.200,90.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.351 | Acc: 50.781,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.402 | Acc: 45.982,65.141,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.424 | Acc: 45.579,64.653,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.449 | Acc: 45.735,64.357,69.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 2.586 | Acc: 45.312,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.897 | Acc: 49.554,77.158,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.892 | Acc: 49.562,77.001,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.885 | Acc: 49.360,77.254,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.872 | Acc: 49.325,77.691,91.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.881 | Acc: 49.312,77.553,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.879 | Acc: 49.393,77.441,91.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.869 | Acc: 49.546,77.504,91.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.885 | Acc: 49.457,77.315,91.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.890 | Acc: 49.353,77.124,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.887 | Acc: 49.444,77.282,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.888 | Acc: 49.494,77.252,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.893 | Acc: 49.449,77.182,91.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.896 | Acc: 49.476,77.191,91.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.889 | Acc: 49.639,77.221,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.891 | Acc: 49.590,77.201,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.895 | Acc: 49.521,77.103,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 49.468,77.103,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.896 | Acc: 49.509,77.218,91.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.902 | Acc: 49.530,77.182,90.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.244 | Acc: 51.562,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.470 | Acc: 46.019,64.695,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.510 | Acc: 45.579,64.177,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.535 | Acc: 45.645,63.781,69.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 2.488 | Acc: 54.688,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.800 | Acc: 50.930,77.344,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.823 | Acc: 50.114,77.363,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.840 | Acc: 49.974,77.549,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.812 | Acc: 49.855,77.922,91.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.851 | Acc: 49.544,77.413,91.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.857 | Acc: 49.329,77.395,91.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 49.485,77.294,91.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.864 | Acc: 49.452,77.460,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.858 | Acc: 49.573,77.516,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.862 | Acc: 49.499,77.414,91.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.872 | Acc: 49.569,77.475,91.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.872 | Acc: 49.546,77.509,91.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.867 | Acc: 49.665,77.589,91.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.881 | Acc: 49.602,77.435,91.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.883 | Acc: 49.631,77.401,91.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.885 | Acc: 49.650,77.388,91.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.886 | Acc: 49.601,77.376,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.887 | Acc: 49.582,77.337,91.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.888 | Acc: 49.649,77.305,91.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.251 | Acc: 46.875,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.438 | Acc: 45.424,64.583,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.472 | Acc: 44.893,64.024,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.503 | Acc: 44.890,63.409,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 3.010 | Acc: 49.219,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.776 | Acc: 51.525,78.423,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.809 | Acc: 50.724,77.896,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.829 | Acc: 50.730,77.664,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.833 | Acc: 50.646,77.604,91.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.850 | Acc: 50.286,77.498,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.857 | Acc: 50.155,77.628,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 49.889,77.554,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.874 | Acc: 49.820,77.601,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.876 | Acc: 49.965,77.508,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.885 | Acc: 49.802,77.437,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.883 | Acc: 49.795,77.570,91.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.884 | Acc: 49.676,77.590,91.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.891 | Acc: 49.653,77.487,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.890 | Acc: 49.711,77.494,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.892 | Acc: 49.608,77.507,91.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.893 | Acc: 49.567,77.470,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.892 | Acc: 49.627,77.504,91.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.894 | Acc: 49.652,77.404,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.895 | Acc: 49.717,77.401,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.460 | Acc: 45.312,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.488 | Acc: 45.685,64.323,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.512 | Acc: 44.989,64.291,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 44.877,64.088,70.044,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 2.497 | Acc: 51.562,83.594,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.803 | Acc: 51.451,78.348,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.836 | Acc: 51.086,77.725,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.852 | Acc: 50.512,77.574,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.860 | Acc: 50.289,77.633,91.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.857 | Acc: 50.309,77.831,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.859 | Acc: 50.310,77.705,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.854 | Acc: 50.299,77.870,91.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.857 | Acc: 50.165,77.950,91.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.860 | Acc: 50.047,77.875,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.866 | Acc: 49.961,77.717,91.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.869 | Acc: 49.897,77.673,91.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 49.945,77.713,91.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.877 | Acc: 49.802,77.478,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.885 | Acc: 49.722,77.372,91.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.881 | Acc: 49.766,77.406,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.886 | Acc: 49.669,77.383,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.886 | Acc: 49.629,77.396,91.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.886 | Acc: 49.584,77.394,91.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.884 | Acc: 49.653,77.399,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.574 | Acc: 45.312,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.569 | Acc: 44.866,63.616,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.585 | Acc: 44.036,63.300,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.615 | Acc: 43.929,63.268,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.684 | Acc: 50.000,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.820 | Acc: 49.144,78.609,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.850 | Acc: 50.305,78.373,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.860 | Acc: 50.166,77.830,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.855 | Acc: 49.759,77.865,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.853 | Acc: 49.915,77.746,91.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.848 | Acc: 49.858,77.757,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.851 | Acc: 49.762,77.920,91.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 49.719,77.907,91.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.854 | Acc: 49.806,77.892,91.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.864 | Acc: 49.658,77.764,91.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.870 | Acc: 49.675,77.690,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 49.822,77.658,91.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.868 | Acc: 49.719,77.649,91.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.867 | Acc: 49.728,77.727,91.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.869 | Acc: 49.689,77.702,91.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.876 | Acc: 49.603,77.636,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.877 | Acc: 49.670,77.626,91.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.877 | Acc: 49.708,77.573,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.876 | Acc: 49.699,77.606,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 47.656,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 46.280,64.211,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.538 | Acc: 45.351,63.777,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.559 | Acc: 45.312,63.678,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 3.102 | Acc: 43.750,74.219,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.889 | Acc: 49.219,77.567,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.811 | Acc: 50.362,78.220,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.843 | Acc: 49.680,77.920,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.846 | Acc: 49.354,77.913,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.850 | Acc: 49.343,77.831,92.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 49.186,77.641,91.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.867 | Acc: 49.097,77.682,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.868 | Acc: 49.088,77.688,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.866 | Acc: 49.085,77.797,91.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.867 | Acc: 49.164,77.779,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.865 | Acc: 49.155,77.740,91.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.867 | Acc: 49.228,77.742,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 49.150,77.727,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.873 | Acc: 49.197,77.650,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 49.263,77.712,91.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.872 | Acc: 49.246,77.682,91.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.872 | Acc: 49.271,77.669,91.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.874 | Acc: 49.273,77.619,91.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.873 | Acc: 49.381,77.604,91.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.485 | Acc: 46.094,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.469 | Acc: 46.168,64.137,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.508 | Acc: 45.617,63.624,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.542 | Acc: 45.223,63.717,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 2.314 | Acc: 57.031,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.845 | Acc: 51.042,77.641,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.835 | Acc: 50.743,77.992,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.849 | Acc: 50.423,77.830,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.838 | Acc: 50.444,77.971,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 50.286,77.901,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.830 | Acc: 50.278,77.899,92.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.831 | Acc: 50.183,78.014,91.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.832 | Acc: 50.330,78.072,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.828 | Acc: 50.535,78.263,91.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.839 | Acc: 50.268,78.051,91.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.841 | Acc: 50.269,77.924,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.835 | Acc: 50.360,77.927,91.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.840 | Acc: 50.413,77.877,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 50.228,77.822,91.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.848 | Acc: 50.169,77.824,91.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.854 | Acc: 50.000,77.704,91.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 50.119,77.653,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.853 | Acc: 50.071,77.642,91.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.851 | Acc: 50.086,77.655,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.473 | Acc: 45.312,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 44.345,64.807,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.524 | Acc: 44.874,64.272,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 45.095,63.922,69.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 2.896 | Acc: 47.656,77.344,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.882 | Acc: 48.214,77.865,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.843 | Acc: 49.333,78.563,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.825 | Acc: 49.974,78.765,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.840 | Acc: 50.048,78.453,91.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.848 | Acc: 49.729,78.156,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.846 | Acc: 49.994,78.338,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.853 | Acc: 50.266,78.081,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 50.063,77.955,91.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.857 | Acc: 50.160,77.823,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.867 | Acc: 49.918,77.756,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.867 | Acc: 49.827,77.651,91.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 49.705,77.606,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.868 | Acc: 49.656,77.571,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.867 | Acc: 49.658,77.547,91.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 49.733,77.593,91.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.866 | Acc: 49.742,77.565,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.863 | Acc: 49.819,77.623,91.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.862 | Acc: 49.885,77.692,91.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.865 | Acc: 49.865,77.647,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.542 | Acc: 46.875,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.479 | Acc: 45.647,64.323,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.508 | Acc: 45.332,63.777,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.536 | Acc: 45.556,63.397,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.918 | Acc: 53.125,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.932 | Acc: 48.996,76.525,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.858 | Acc: 49.219,77.858,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.828 | Acc: 49.834,78.356,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.846 | Acc: 49.759,78.086,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 49.838,78.295,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.836 | Acc: 49.871,78.299,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.830 | Acc: 50.055,78.446,92.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.833 | Acc: 49.956,78.377,92.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.818 | Acc: 50.397,78.591,92.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.816 | Acc: 50.517,78.564,92.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.828 | Acc: 50.304,78.489,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.839 | Acc: 50.104,78.349,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.842 | Acc: 50.168,78.215,91.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.848 | Acc: 50.067,78.178,91.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.844 | Acc: 50.034,78.133,91.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.853 | Acc: 49.890,78.028,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.849 | Acc: 49.970,77.994,91.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.850 | Acc: 49.994,77.974,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.850 | Acc: 49.988,77.945,91.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.552 | Acc: 49.219,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.539 | Acc: 44.792,64.583,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.574 | Acc: 44.569,64.215,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 44.442,63.909,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 3.003 | Acc: 49.219,77.344,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.812 | Acc: 49.070,78.571,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.791 | Acc: 49.790,78.468,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.795 | Acc: 49.795,78.778,92.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.795 | Acc: 49.614,78.646,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.790 | Acc: 49.675,78.674,92.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.805 | Acc: 49.845,78.551,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.811 | Acc: 49.878,78.446,92.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.805 | Acc: 50.039,78.494,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 49.927,78.406,92.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.818 | Acc: 49.965,78.261,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.828 | Acc: 49.735,78.097,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.838 | Acc: 49.569,78.012,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.839 | Acc: 49.650,77.924,91.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.844 | Acc: 49.589,77.919,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.849 | Acc: 49.585,77.769,91.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.854 | Acc: 49.538,77.711,91.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.851 | Acc: 49.537,77.717,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.851 | Acc: 49.522,77.684,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.851 | Acc: 49.481,77.694,91.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.208 | Acc: 47.656,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.533 | Acc: 45.833,64.137,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.560 | Acc: 45.179,64.120,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.579 | Acc: 45.261,63.768,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 2.802 | Acc: 53.125,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.846 | Acc: 49.368,77.865,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.814 | Acc: 49.695,78.068,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.808 | Acc: 50.115,77.933,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.808 | Acc: 49.904,78.135,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.801 | Acc: 50.054,78.125,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.808 | Acc: 49.948,77.899,92.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.821 | Acc: 49.839,77.798,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.816 | Acc: 50.082,77.858,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.815 | Acc: 50.035,77.866,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.815 | Acc: 50.113,77.845,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.820 | Acc: 50.078,77.814,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.819 | Acc: 50.185,77.869,92.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.826 | Acc: 50.063,77.814,92.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.828 | Acc: 50.036,77.819,92.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.834 | Acc: 49.956,77.767,91.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.834 | Acc: 49.925,77.745,91.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 49.851,77.715,91.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.838 | Acc: 49.859,77.694,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.843 | Acc: 49.787,77.649,91.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.474 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.513 | Acc: 45.424,63.951,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 45.408,63.491,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 45.402,63.537,69.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 2.508 | Acc: 54.688,81.250,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.816 | Acc: 49.888,78.237,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.799 | Acc: 50.553,78.087,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.796 | Acc: 50.474,78.189,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.809 | Acc: 50.309,78.202,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.804 | Acc: 50.015,78.458,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.804 | Acc: 50.142,78.538,92.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 50.011,78.491,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.808 | Acc: 49.854,78.436,92.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.816 | Acc: 49.745,78.384,92.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.812 | Acc: 49.899,78.393,92.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.815 | Acc: 49.926,78.358,92.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.815 | Acc: 49.883,78.290,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.817 | Acc: 49.874,78.338,92.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.821 | Acc: 49.853,78.295,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.822 | Acc: 49.836,78.200,92.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.831 | Acc: 49.732,78.115,91.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.831 | Acc: 49.727,78.100,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.837 | Acc: 49.621,78.021,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 49.676,77.953,91.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.480 | Acc: 50.781,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 46.094,64.137,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 45.827,63.453,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 45.530,63.448,68.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 2.795 | Acc: 52.344,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.862 | Acc: 47.842,77.381,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.847 | Acc: 48.819,77.896,92.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.815 | Acc: 49.603,78.074,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.846 | Acc: 49.228,77.807,92.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.844 | Acc: 49.343,77.584,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.831 | Acc: 49.406,77.802,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.827 | Acc: 49.463,77.870,92.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.821 | Acc: 49.500,77.975,92.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.828 | Acc: 49.327,77.909,92.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.829 | Acc: 49.343,78.020,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 49.484,78.012,92.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.824 | Acc: 49.559,77.966,92.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.824 | Acc: 49.608,78.071,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.826 | Acc: 49.622,78.036,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.828 | Acc: 49.574,78.052,91.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.830 | Acc: 49.598,78.003,91.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.831 | Acc: 49.608,77.976,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.836 | Acc: 49.604,77.919,91.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.835 | Acc: 49.680,77.955,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.599 | Acc: 47.656,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.644 | Acc: 44.382,63.579,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.650 | Acc: 44.474,63.472,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 44.262,62.961,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 2.995 | Acc: 44.531,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.789 | Acc: 49.628,79.055,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.781 | Acc: 49.867,79.192,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 50.371,78.970,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.800 | Acc: 49.682,78.906,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.803 | Acc: 49.714,78.968,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.820 | Acc: 49.587,78.732,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.840 | Acc: 49.424,78.546,92.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.835 | Acc: 49.413,78.455,92.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.837 | Acc: 49.525,78.272,92.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.833 | Acc: 49.697,78.253,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.828 | Acc: 49.707,78.238,91.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.821 | Acc: 49.805,78.287,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.815 | Acc: 49.844,78.326,92.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.816 | Acc: 49.864,78.233,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.817 | Acc: 49.868,78.218,92.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.822 | Acc: 49.779,78.215,92.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.820 | Acc: 49.796,78.292,92.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.820 | Acc: 49.747,78.251,91.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.823 | Acc: 49.791,78.236,91.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.503 | Acc: 52.344,64.844,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 45.424,64.435,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.564 | Acc: 45.389,63.720,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 45.492,63.627,69.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.580 | Acc: 52.344,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.762 | Acc: 49.182,79.911,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 49.466,78.735,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.770 | Acc: 49.859,78.535,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.784 | Acc: 50.019,78.366,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.781 | Acc: 50.224,78.550,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.772 | Acc: 50.245,78.642,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.787 | Acc: 49.845,78.302,92.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 49.927,78.314,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.798 | Acc: 49.797,78.319,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 49.759,78.214,92.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.805 | Acc: 49.781,78.192,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 49.838,78.206,92.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.813 | Acc: 49.796,78.083,92.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 49.714,78.061,92.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.821 | Acc: 49.595,77.938,92.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.823 | Acc: 49.555,77.930,92.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.823 | Acc: 49.654,77.903,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.819 | Acc: 49.738,77.969,92.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.819 | Acc: 49.764,77.955,92.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.466 | Acc: 49.219,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.710 | Acc: 44.680,63.207,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.715 | Acc: 44.398,63.129,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.719 | Acc: 44.160,62.974,68.635,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 3.216 | Acc: 42.188,77.344,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.871 | Acc: 49.405,77.269,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.812 | Acc: 49.943,78.163,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.816 | Acc: 50.026,77.971,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.819 | Acc: 50.222,77.980,92.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.807 | Acc: 50.240,77.978,92.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.807 | Acc: 50.284,77.938,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.803 | Acc: 50.399,78.092,92.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.809 | Acc: 50.092,78.067,92.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.799 | Acc: 50.298,78.242,92.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 50.210,78.245,92.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.801 | Acc: 50.148,78.242,92.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 50.126,78.258,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.804 | Acc: 50.162,78.242,92.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.807 | Acc: 50.136,78.211,92.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.806 | Acc: 50.176,78.221,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.809 | Acc: 50.085,78.140,92.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 50.062,78.196,92.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.813 | Acc: 50.102,78.131,92.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.815 | Acc: 50.103,78.074,92.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.362 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.614 | Acc: 45.610,63.728,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 44.912,63.396,69.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.619 | Acc: 44.839,63.204,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.415 | Acc: 53.906,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.733 | Acc: 50.707,79.241,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.809 | Acc: 50.000,77.420,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 50.077,77.587,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.793 | Acc: 50.502,77.961,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.797 | Acc: 50.449,77.808,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.791 | Acc: 50.575,77.776,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 50.404,77.654,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.796 | Acc: 50.354,77.708,92.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.796 | Acc: 50.376,77.724,92.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.801 | Acc: 50.408,77.771,92.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.799 | Acc: 50.304,77.902,92.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.806 | Acc: 50.078,77.908,92.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.808 | Acc: 50.027,77.880,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.811 | Acc: 50.006,77.855,92.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.812 | Acc: 49.953,77.806,92.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.811 | Acc: 49.925,77.845,92.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 49.929,77.850,92.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.811 | Acc: 49.974,77.850,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.813 | Acc: 50.043,77.867,92.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.431 | Acc: 45.312,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.607 | Acc: 44.234,64.249,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.635 | Acc: 44.284,63.624,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.656 | Acc: 44.467,63.653,68.865,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 2.328 | Acc: 57.031,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 52.009,78.795,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.757 | Acc: 51.315,79.116,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.755 | Acc: 50.909,78.791,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 50.270,78.482,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.770 | Acc: 50.162,78.504,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.759 | Acc: 50.174,78.732,92.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.761 | Acc: 50.216,78.613,92.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.775 | Acc: 50.121,78.508,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.786 | Acc: 50.017,78.380,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.794 | Acc: 50.016,78.315,92.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.793 | Acc: 50.110,78.273,92.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.797 | Acc: 50.049,78.229,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.802 | Acc: 49.931,78.170,92.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 50.070,78.156,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.799 | Acc: 50.075,78.198,92.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.805 | Acc: 49.925,78.152,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.808 | Acc: 49.849,78.065,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.809 | Acc: 49.857,78.064,92.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.809 | Acc: 49.893,78.049,92.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.524 | Acc: 47.656,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.598 | Acc: 44.866,63.765,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 44.341,63.548,69.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.630 | Acc: 44.083,63.256,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.723 | Acc: 52.344,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.820 | Acc: 49.926,78.274,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.832 | Acc: 49.886,77.077,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.806 | Acc: 50.346,77.741,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.806 | Acc: 50.395,77.951,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.806 | Acc: 50.387,78.086,92.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.808 | Acc: 50.187,78.157,92.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.808 | Acc: 50.066,78.203,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 50.180,78.280,92.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.799 | Acc: 50.134,78.371,92.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 50.089,78.269,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 50.025,78.256,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 50.152,78.349,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.803 | Acc: 50.039,78.341,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 50.122,78.283,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.802 | Acc: 50.104,78.237,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.801 | Acc: 50.127,78.283,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.800 | Acc: 50.218,78.251,92.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.805 | Acc: 50.175,78.218,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.804 | Acc: 50.240,78.215,92.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 44.531,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 44.234,64.211,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 44.874,63.739,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.617 | Acc: 45.031,63.486,68.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.742 | Acc: 48.438,85.156,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.715 | Acc: 51.562,80.394,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.788 | Acc: 49.981,79.421,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.764 | Acc: 50.064,79.419,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.760 | Acc: 50.434,79.311,92.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.767 | Acc: 50.286,79.216,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.784 | Acc: 49.974,78.816,92.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.765 | Acc: 50.227,78.934,92.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.770 | Acc: 50.306,78.678,92.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.776 | Acc: 50.298,78.703,92.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.774 | Acc: 50.412,78.630,92.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.771 | Acc: 50.322,78.715,92.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.775 | Acc: 50.285,78.663,92.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.776 | Acc: 50.440,78.670,92.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.783 | Acc: 50.384,78.628,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.788 | Acc: 50.215,78.652,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.794 | Acc: 50.178,78.534,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.794 | Acc: 50.211,78.517,92.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.795 | Acc: 50.322,78.406,92.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.798 | Acc: 50.285,78.383,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.698 | Acc: 47.656,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.675 | Acc: 44.085,63.393,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.709 | Acc: 43.788,63.110,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.737 | Acc: 43.763,62.999,68.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 2.930 | Acc: 49.219,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.834 | Acc: 48.958,77.046,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.784 | Acc: 49.543,77.782,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.783 | Acc: 49.744,78.279,92.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.781 | Acc: 50.077,78.270,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.773 | Acc: 49.954,78.442,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.767 | Acc: 50.161,78.493,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.764 | Acc: 50.194,78.541,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.776 | Acc: 50.087,78.445,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.776 | Acc: 50.138,78.427,92.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.781 | Acc: 50.136,78.389,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.786 | Acc: 50.067,78.408,92.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.786 | Acc: 50.081,78.511,92.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.786 | Acc: 50.192,78.529,92.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.791 | Acc: 50.047,78.461,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.792 | Acc: 50.132,78.457,92.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.794 | Acc: 50.105,78.407,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.794 | Acc: 50.126,78.434,92.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.796 | Acc: 50.058,78.467,92.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.793 | Acc: 50.107,78.494,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.382 | Acc: 50.000,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.631 | Acc: 45.685,63.653,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.640 | Acc: 44.722,63.167,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.668 | Acc: 44.698,63.192,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.565 | Acc: 50.000,85.156,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.784 | Acc: 48.549,77.604,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.775 | Acc: 49.390,78.373,92.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.779 | Acc: 49.680,78.291,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.791 | Acc: 49.759,78.299,92.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.776 | Acc: 49.930,78.388,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.793 | Acc: 49.845,78.125,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.789 | Acc: 49.939,78.269,92.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.792 | Acc: 50.150,78.159,92.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.793 | Acc: 50.164,78.289,92.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.791 | Acc: 50.218,78.362,92.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 50.279,78.362,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.790 | Acc: 50.230,78.430,92.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.797 | Acc: 50.147,78.335,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.797 | Acc: 50.234,78.289,92.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.796 | Acc: 50.231,78.268,92.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.796 | Acc: 50.243,78.144,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.793 | Acc: 50.369,78.150,92.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.794 | Acc: 50.318,78.112,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.794 | Acc: 50.246,78.066,92.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.825 | Acc: 46.875,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.609 | Acc: 45.238,63.616,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.647 | Acc: 44.703,62.786,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.678 | Acc: 44.839,62.654,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 2.678 | Acc: 46.094,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 51.674,78.646,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.756 | Acc: 50.514,78.887,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.758 | Acc: 50.692,78.624,92.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.757 | Acc: 50.367,78.704,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.753 | Acc: 50.317,78.968,92.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.756 | Acc: 50.245,78.932,92.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.766 | Acc: 50.122,78.740,92.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.783 | Acc: 49.888,78.508,92.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.774 | Acc: 49.927,78.656,92.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.774 | Acc: 49.984,78.638,92.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.781 | Acc: 49.890,78.588,92.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.783 | Acc: 49.848,78.563,92.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.783 | Acc: 49.949,78.451,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.788 | Acc: 49.864,78.342,92.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.790 | Acc: 49.847,78.338,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.795 | Acc: 49.866,78.249,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.795 | Acc: 49.940,78.205,92.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.795 | Acc: 49.890,78.175,92.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.796 | Acc: 49.975,78.162,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.090 | Acc: 43.750,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.796 | Acc: 43.341,62.872,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.827 | Acc: 42.873,62.309,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.855 | Acc: 42.841,62.487,68.635,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 2.964 | Acc: 46.094,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.796 | Acc: 50.558,77.567,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.778 | Acc: 50.381,77.725,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.740 | Acc: 50.410,78.522,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.760 | Acc: 50.260,78.279,92.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.758 | Acc: 50.688,78.481,92.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.760 | Acc: 50.588,78.538,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.760 | Acc: 50.465,78.613,92.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.762 | Acc: 50.306,78.639,92.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.769 | Acc: 50.255,78.764,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.766 | Acc: 50.268,78.759,92.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.770 | Acc: 50.148,78.733,92.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.774 | Acc: 50.045,78.614,92.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.776 | Acc: 50.000,78.631,92.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.779 | Acc: 50.025,78.561,92.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.781 | Acc: 50.023,78.423,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.781 | Acc: 50.022,78.456,92.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.787 | Acc: 50.023,78.400,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.789 | Acc: 50.115,78.346,92.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.789 | Acc: 50.076,78.328,92.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.961 | Acc: 46.875,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.803 | Acc: 44.494,62.463,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.853 | Acc: 43.464,61.890,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.876 | Acc: 43.084,61.949,68.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.739 | Acc: 49.219,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.678 | Acc: 51.042,79.911,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.711 | Acc: 50.038,79.954,93.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.713 | Acc: 50.448,79.700,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.724 | Acc: 50.820,79.321,92.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.735 | Acc: 50.657,79.100,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.748 | Acc: 50.426,79.042,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.743 | Acc: 50.443,79.039,92.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.751 | Acc: 50.422,78.877,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.751 | Acc: 50.552,78.911,92.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.758 | Acc: 50.389,78.825,92.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.767 | Acc: 50.308,78.680,92.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.769 | Acc: 50.289,78.650,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.778 | Acc: 50.075,78.547,92.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.777 | Acc: 50.047,78.534,92.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.777 | Acc: 50.101,78.478,92.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.775 | Acc: 50.085,78.556,92.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.779 | Acc: 50.147,78.453,92.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.780 | Acc: 50.160,78.409,92.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.785 | Acc: 50.090,78.346,92.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.814 | Acc: 46.094,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.638 | Acc: 44.457,63.318,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.693 | Acc: 44.379,62.919,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.732 | Acc: 44.390,62.743,68.417,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.692 | Acc: 57.031,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.823 | Acc: 47.359,77.939,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.811 | Acc: 49.085,78.030,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.813 | Acc: 48.796,78.189,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.806 | Acc: 48.785,78.144,92.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.810 | Acc: 49.095,78.017,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.799 | Acc: 49.464,78.248,92.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 49.496,78.219,92.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.790 | Acc: 49.597,78.353,92.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.783 | Acc: 49.827,78.349,93.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.776 | Acc: 50.167,78.467,92.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.779 | Acc: 50.194,78.390,92.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.780 | Acc: 50.156,78.378,92.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.783 | Acc: 50.236,78.299,92.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.789 | Acc: 50.145,78.195,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.786 | Acc: 50.143,78.229,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.791 | Acc: 50.056,78.188,92.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.794 | Acc: 49.995,78.180,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.792 | Acc: 50.019,78.203,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.792 | Acc: 50.039,78.250,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.415 | Acc: 46.875,67.188,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.516 | Acc: 46.205,64.807,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 45.675,64.043,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 45.902,63.870,69.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 3.343 | Acc: 43.750,72.656,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.693 | Acc: 51.488,79.501,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.696 | Acc: 50.781,79.116,93.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.727 | Acc: 50.704,79.329,92.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.737 | Acc: 50.482,79.244,92.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.748 | Acc: 50.325,79.015,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.763 | Acc: 50.142,78.751,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.761 | Acc: 50.283,78.773,92.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.759 | Acc: 50.301,78.804,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.764 | Acc: 50.358,78.764,92.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.764 | Acc: 50.377,78.794,92.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.771 | Acc: 50.414,78.595,92.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.778 | Acc: 50.373,78.566,92.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.776 | Acc: 50.359,78.598,92.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.771 | Acc: 50.548,78.536,92.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.776 | Acc: 50.485,78.439,92.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.773 | Acc: 50.496,78.514,92.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.779 | Acc: 50.458,78.524,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.781 | Acc: 50.444,78.465,92.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.785 | Acc: 50.367,78.455,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.560 | Acc: 45.312,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.791 | Acc: 43.713,62.835,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.775 | Acc: 43.883,62.976,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.810 | Acc: 43.660,62.884,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 2.526 | Acc: 49.219,85.938,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.683 | Acc: 50.074,78.943,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.696 | Acc: 50.896,79.478,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 50.474,79.303,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.745 | Acc: 50.521,78.935,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.728 | Acc: 50.851,79.115,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.730 | Acc: 50.620,79.093,93.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.733 | Acc: 50.609,79.089,93.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.730 | Acc: 50.723,79.071,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.742 | Acc: 50.617,79.062,92.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.748 | Acc: 50.548,78.996,92.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.754 | Acc: 50.410,78.945,92.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.760 | Acc: 50.321,78.952,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.761 | Acc: 50.257,78.975,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.762 | Acc: 50.303,78.917,92.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.764 | Acc: 50.317,78.787,92.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.766 | Acc: 50.256,78.695,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.767 | Acc: 50.222,78.645,92.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.770 | Acc: 50.128,78.660,92.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.774 | Acc: 50.014,78.652,92.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.465 | Acc: 48.438,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 45.759,64.397,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.646 | Acc: 44.569,63.453,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.674 | Acc: 44.454,63.128,68.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 3.073 | Acc: 46.875,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.755 | Acc: 49.963,79.315,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.783 | Acc: 50.076,79.021,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.749 | Acc: 50.423,79.086,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.764 | Acc: 50.318,78.954,92.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.765 | Acc: 50.170,78.891,92.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.753 | Acc: 50.291,79.055,92.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.752 | Acc: 50.288,79.034,93.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.755 | Acc: 50.238,78.969,92.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.759 | Acc: 50.233,78.980,92.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.763 | Acc: 50.260,78.984,92.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.764 | Acc: 50.156,78.871,92.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.767 | Acc: 50.039,78.793,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.763 | Acc: 50.114,78.781,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.762 | Acc: 50.131,78.742,92.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.763 | Acc: 50.161,78.595,92.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.768 | Acc: 50.102,78.502,92.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.765 | Acc: 50.179,78.547,92.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.768 | Acc: 50.130,78.536,92.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.769 | Acc: 50.146,78.484,92.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.270 | Acc: 44.531,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.662 | Acc: 44.978,63.765,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.661 | Acc: 45.160,63.510,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.696 | Acc: 45.018,63.422,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.484 | Acc: 50.781,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.773 | Acc: 50.818,78.274,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.802 | Acc: 50.000,78.182,93.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.804 | Acc: 49.795,78.394,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 49.817,78.829,92.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.769 | Acc: 49.954,78.713,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.781 | Acc: 49.955,78.383,92.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.776 | Acc: 50.133,78.419,92.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.784 | Acc: 49.981,78.329,92.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.775 | Acc: 50.289,78.535,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.763 | Acc: 50.463,78.584,92.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.760 | Acc: 50.354,78.627,92.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.755 | Acc: 50.567,78.741,92.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.756 | Acc: 50.563,78.697,92.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.760 | Acc: 50.531,78.667,92.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.763 | Acc: 50.410,78.623,92.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.767 | Acc: 50.316,78.561,92.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.767 | Acc: 50.204,78.586,92.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.770 | Acc: 50.214,78.571,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.774 | Acc: 50.148,78.562,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.900 | Acc: 49.219,64.062,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.838 | Acc: 42.708,63.244,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.896 | Acc: 42.340,62.786,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.931 | Acc: 42.328,62.180,67.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 2.346 | Acc: 51.562,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.730 | Acc: 49.107,79.092,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.753 | Acc: 49.333,79.059,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 50.115,79.034,93.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.736 | Acc: 49.942,78.733,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.734 | Acc: 49.930,79.022,93.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.751 | Acc: 49.800,78.951,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.750 | Acc: 49.961,78.884,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.763 | Acc: 49.830,78.790,93.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.768 | Acc: 49.698,78.729,93.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.767 | Acc: 49.767,78.642,92.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.763 | Acc: 49.951,78.662,92.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.759 | Acc: 50.071,78.663,92.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.763 | Acc: 50.030,78.532,92.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.765 | Acc: 50.017,78.467,92.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.765 | Acc: 50.148,78.507,92.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.768 | Acc: 50.039,78.507,92.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.773 | Acc: 49.993,78.473,92.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.776 | Acc: 49.983,78.493,92.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.778 | Acc: 49.930,78.476,92.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.723 | Acc: 47.656,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.776 | Acc: 43.973,62.835,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.804 | Acc: 43.483,61.966,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.845 | Acc: 43.481,62.001,67.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 3.218 | Acc: 42.969,77.344,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.781 | Acc: 49.405,78.348,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.762 | Acc: 49.771,78.354,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.745 | Acc: 50.192,78.650,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.768 | Acc: 50.019,78.675,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.776 | Acc: 49.869,78.728,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.770 | Acc: 50.071,78.835,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.773 | Acc: 49.756,78.823,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.770 | Acc: 49.762,78.824,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.765 | Acc: 49.957,78.872,92.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.766 | Acc: 50.039,78.766,92.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.762 | Acc: 50.166,78.821,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.766 | Acc: 50.217,78.699,92.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.761 | Acc: 50.350,78.679,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.763 | Acc: 50.292,78.742,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.758 | Acc: 50.436,78.740,92.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.761 | Acc: 50.433,78.702,92.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.763 | Acc: 50.392,78.677,92.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.764 | Acc: 50.348,78.718,92.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.762 | Acc: 50.328,78.724,92.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.422 | Acc: 51.562,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.602 | Acc: 44.643,63.542,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.648 | Acc: 44.874,63.319,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.665 | Acc: 44.915,63.115,68.353,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 2.319 | Acc: 53.125,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.663 | Acc: 50.335,80.394,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.708 | Acc: 50.591,78.982,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 50.256,79.239,93.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.744 | Acc: 49.990,78.974,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.737 | Acc: 50.139,78.899,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.741 | Acc: 49.994,78.835,93.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.736 | Acc: 49.867,79.000,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.741 | Acc: 49.869,78.964,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.740 | Acc: 50.000,78.958,93.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.742 | Acc: 49.860,78.976,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.744 | Acc: 50.049,78.906,93.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.742 | Acc: 50.039,78.890,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.740 | Acc: 50.132,78.873,93.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.750 | Acc: 50.019,78.798,92.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.752 | Acc: 50.021,78.860,92.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.760 | Acc: 49.932,78.738,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.763 | Acc: 49.929,78.679,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.763 | Acc: 49.961,78.703,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.757 | Acc: 50.070,78.705,92.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.115 | Acc: 46.094,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.846 | Acc: 43.341,63.021,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.882 | Acc: 42.626,62.348,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.901 | Acc: 42.469,62.116,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 3.069 | Acc: 48.438,76.562,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.784 | Acc: 49.479,78.906,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 50.076,78.906,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.737 | Acc: 50.295,79.214,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.723 | Acc: 50.685,79.437,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.736 | Acc: 50.394,79.162,93.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.730 | Acc: 50.194,79.216,93.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.739 | Acc: 50.017,79.095,93.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.747 | Acc: 49.879,79.018,93.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.748 | Acc: 50.022,79.018,93.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.745 | Acc: 50.155,78.906,93.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.749 | Acc: 50.081,78.998,93.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.759 | Acc: 50.049,78.932,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.763 | Acc: 49.988,78.882,93.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.765 | Acc: 50.022,78.801,92.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.768 | Acc: 50.000,78.758,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.766 | Acc: 50.080,78.772,92.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.767 | Acc: 50.186,78.810,92.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.765 | Acc: 50.242,78.856,92.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.767 | Acc: 50.197,78.824,92.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.736 | Acc: 46.875,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.689 | Acc: 45.833,64.249,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.702 | Acc: 45.027,63.396,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.733 | Acc: 44.864,63.012,68.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.849 | Acc: 46.094,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.791 | Acc: 50.409,78.571,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 49.867,78.449,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.747 | Acc: 50.243,78.778,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.738 | Acc: 50.087,79.012,93.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.729 | Acc: 50.193,79.069,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.741 | Acc: 49.864,78.971,93.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.744 | Acc: 49.856,78.729,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.738 | Acc: 49.884,78.863,93.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.739 | Acc: 49.840,78.833,93.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.737 | Acc: 49.949,78.778,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.750 | Acc: 49.862,78.616,93.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.748 | Acc: 49.925,78.692,93.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.751 | Acc: 49.853,78.616,93.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.748 | Acc: 49.944,78.642,92.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.750 | Acc: 49.925,78.610,92.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.754 | Acc: 49.946,78.534,92.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.754 | Acc: 50.007,78.549,92.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.754 | Acc: 50.002,78.560,92.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.761 | Acc: 49.963,78.465,92.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.319 | Acc: 46.875,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.708 | Acc: 44.234,63.170,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.714 | Acc: 44.112,62.995,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.736 | Acc: 44.314,63.204,68.750,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 2.881 | Acc: 42.969,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.782 | Acc: 49.665,78.832,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 50.610,79.040,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.738 | Acc: 50.231,78.996,93.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.734 | Acc: 50.231,79.061,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.742 | Acc: 50.309,78.906,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.754 | Acc: 49.942,78.893,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.749 | Acc: 50.083,79.106,92.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.752 | Acc: 49.922,79.091,92.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.749 | Acc: 50.125,78.906,92.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.749 | Acc: 50.190,78.902,92.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.748 | Acc: 50.226,78.966,92.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.753 | Acc: 50.201,78.945,92.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.753 | Acc: 50.042,78.957,92.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.753 | Acc: 49.950,79.029,92.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.754 | Acc: 50.036,79.000,92.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.755 | Acc: 49.985,79.018,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.759 | Acc: 49.918,78.966,92.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.759 | Acc: 49.974,78.963,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.762 | Acc: 49.904,78.917,92.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.797 | Acc: 46.094,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.784 | Acc: 44.420,64.062,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.812 | Acc: 43.864,63.491,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.844 | Acc: 43.545,62.807,68.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 2.615 | Acc: 52.344,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.746 | Acc: 49.516,79.055,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.694 | Acc: 50.457,79.649,93.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 50.512,79.086,93.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.729 | Acc: 50.154,78.935,93.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.724 | Acc: 50.201,79.084,93.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.739 | Acc: 49.845,78.926,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.740 | Acc: 49.911,78.923,93.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.748 | Acc: 49.796,79.023,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.742 | Acc: 49.871,79.165,93.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.741 | Acc: 49.864,79.093,93.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.741 | Acc: 49.834,79.023,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.741 | Acc: 49.900,79.049,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.742 | Acc: 49.907,78.975,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.746 | Acc: 49.839,78.976,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.750 | Acc: 49.831,78.870,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.754 | Acc: 49.839,78.809,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.757 | Acc: 49.819,78.750,92.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.760 | Acc: 49.799,78.698,92.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.763 | Acc: 49.900,78.636,92.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.003 | Acc: 42.969,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.746 | Acc: 45.275,63.802,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.776 | Acc: 44.646,62.881,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.778 | Acc: 44.544,62.641,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.492 | Acc: 46.875,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.726 | Acc: 51.786,78.832,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.719 | Acc: 50.800,78.601,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 50.961,78.957,93.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.732 | Acc: 50.376,78.366,93.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.735 | Acc: 50.348,78.473,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.722 | Acc: 50.678,78.532,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.737 | Acc: 50.537,78.391,93.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.734 | Acc: 50.641,78.450,93.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.735 | Acc: 50.570,78.449,93.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.745 | Acc: 50.358,78.459,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.741 | Acc: 50.407,78.585,93.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.743 | Acc: 50.363,78.598,93.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.738 | Acc: 50.419,78.742,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.739 | Acc: 50.400,78.720,93.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.749 | Acc: 50.270,78.629,92.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.749 | Acc: 50.304,78.609,92.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.754 | Acc: 50.277,78.558,92.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.759 | Acc: 50.335,78.523,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.754 | Acc: 50.392,78.562,92.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.634 | Acc: 48.438,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.671 | Acc: 45.722,62.872,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.689 | Acc: 45.484,62.633,68.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.710 | Acc: 45.466,62.999,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.894 | Acc: 46.875,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.693 | Acc: 49.405,79.539,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.676 | Acc: 50.610,79.611,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.680 | Acc: 50.538,79.662,93.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.693 | Acc: 50.289,79.562,93.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.702 | Acc: 50.619,79.455,93.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.713 | Acc: 50.342,79.339,93.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.717 | Acc: 50.371,79.222,93.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.720 | Acc: 50.301,79.197,93.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.727 | Acc: 50.194,79.100,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.735 | Acc: 50.206,79.104,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.732 | Acc: 50.201,79.210,93.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.737 | Acc: 50.178,79.029,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.737 | Acc: 50.162,79.002,92.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.740 | Acc: 50.192,78.998,92.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.740 | Acc: 50.184,79.015,92.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.745 | Acc: 50.148,78.909,92.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.748 | Acc: 50.151,78.819,92.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.749 | Acc: 50.149,78.800,92.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.755 | Acc: 50.133,78.736,92.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.487 | Acc: 50.000,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.699 | Acc: 45.052,62.909,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.763 | Acc: 44.912,62.748,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.773 | Acc: 44.762,62.705,68.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 3.102 | Acc: 41.406,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.740 | Acc: 49.256,78.869,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 50.038,78.906,93.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 50.269,79.713,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.726 | Acc: 50.347,79.311,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.721 | Acc: 50.356,79.162,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.709 | Acc: 50.626,79.294,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.708 | Acc: 50.593,79.510,93.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.710 | Acc: 50.674,79.586,93.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.709 | Acc: 50.565,79.605,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.714 | Acc: 50.540,79.575,93.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.717 | Acc: 50.463,79.405,93.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.724 | Acc: 50.353,79.298,93.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.724 | Acc: 50.374,79.233,93.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.725 | Acc: 50.414,79.198,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.729 | Acc: 50.293,79.127,93.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.724 | Acc: 50.448,79.198,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.734 | Acc: 50.415,79.046,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.740 | Acc: 50.327,78.965,93.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.743 | Acc: 50.289,78.912,93.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.682 | Acc: 50.781,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.825 | Acc: 43.490,62.909,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.865 | Acc: 42.664,62.519,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.878 | Acc: 42.405,61.911,68.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 2.825 | Acc: 50.000,74.219,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 49.702,80.022,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.701 | Acc: 50.286,79.707,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 50.026,79.483,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.729 | Acc: 50.145,79.456,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.720 | Acc: 50.410,79.494,93.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.712 | Acc: 50.626,79.352,93.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.711 | Acc: 50.676,79.433,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.715 | Acc: 50.776,79.343,93.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.717 | Acc: 50.786,79.230,93.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.726 | Acc: 50.735,79.136,93.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.730 | Acc: 50.647,79.072,93.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.734 | Acc: 50.590,79.094,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.734 | Acc: 50.587,79.047,92.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.737 | Acc: 50.509,79.015,92.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.741 | Acc: 50.433,78.958,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.743 | Acc: 50.380,78.870,92.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.750 | Acc: 50.302,78.787,92.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.752 | Acc: 50.206,78.772,92.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.756 | Acc: 50.193,78.810,92.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.936 | Acc: 46.875,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.867 | Acc: 43.713,62.054,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.864 | Acc: 43.464,62.062,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.899 | Acc: 43.289,61.911,68.289,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 2.285 | Acc: 57.031,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.749 | Acc: 49.554,79.501,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 49.962,79.078,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.729 | Acc: 50.679,79.239,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.740 | Acc: 50.357,78.954,92.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.719 | Acc: 50.565,79.247,93.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.717 | Acc: 50.549,79.197,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.719 | Acc: 50.504,79.272,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.716 | Acc: 50.480,79.348,93.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.716 | Acc: 50.341,79.364,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.713 | Acc: 50.459,79.415,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.717 | Acc: 50.332,79.338,93.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.715 | Acc: 50.350,79.334,93.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.713 | Acc: 50.347,79.397,93.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.718 | Acc: 50.450,79.304,93.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.722 | Acc: 50.387,79.249,93.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.728 | Acc: 50.385,79.111,93.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.735 | Acc: 50.261,79.019,92.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.736 | Acc: 50.279,78.995,92.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.738 | Acc: 50.195,78.949,92.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.465 | Acc: 50.781,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.729 | Acc: 45.833,62.835,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.762 | Acc: 45.255,62.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.809 | Acc: 44.954,62.385,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.473 | Acc: 55.469,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.704 | Acc: 50.744,78.832,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.665 | Acc: 51.181,79.021,93.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.677 | Acc: 50.871,79.226,93.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.676 | Acc: 51.003,79.379,93.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.681 | Acc: 50.897,79.324,93.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.710 | Acc: 50.691,79.010,93.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.729 | Acc: 50.593,78.862,93.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.734 | Acc: 50.723,78.722,93.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.743 | Acc: 50.652,78.716,93.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.739 | Acc: 50.641,78.661,93.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.743 | Acc: 50.647,78.687,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.745 | Acc: 50.668,78.699,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.738 | Acc: 50.736,78.819,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.737 | Acc: 50.756,78.803,93.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.739 | Acc: 50.613,78.779,92.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.740 | Acc: 50.628,78.748,92.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.743 | Acc: 50.568,78.691,92.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.745 | Acc: 50.526,78.655,92.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.749 | Acc: 50.529,78.586,92.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.589 | Acc: 49.219,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.717 | Acc: 45.424,64.211,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.769 | Acc: 44.341,63.034,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.810 | Acc: 43.878,62.372,68.238,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.639 | Acc: 57.031,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.631 | Acc: 52.232,80.580,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 50.934,79.268,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.689 | Acc: 51.089,79.585,93.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.682 | Acc: 51.138,79.803,93.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.688 | Acc: 50.859,79.626,93.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.704 | Acc: 50.639,79.332,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.712 | Acc: 50.709,79.338,93.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.713 | Acc: 50.694,79.227,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.705 | Acc: 50.777,79.282,93.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.706 | Acc: 50.649,79.365,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.713 | Acc: 50.668,79.345,93.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.718 | Acc: 50.600,79.256,93.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.723 | Acc: 50.461,79.241,93.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.726 | Acc: 50.492,79.207,92.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.726 | Acc: 50.514,79.200,92.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.733 | Acc: 50.523,79.154,92.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.730 | Acc: 50.577,79.092,92.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.730 | Acc: 50.489,79.053,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.735 | Acc: 50.431,79.058,92.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.785 | Acc: 49.219,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.838 | Acc: 44.085,62.165,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.886 | Acc: 43.559,61.871,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.917 | Acc: 43.494,61.757,68.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.789 | Acc: 51.562,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.761 | Acc: 48.735,79.390,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 49.733,79.345,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.685 | Acc: 50.743,79.508,93.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.675 | Acc: 50.907,79.552,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.674 | Acc: 50.696,79.672,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.679 | Acc: 50.788,79.520,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.689 | Acc: 50.604,79.466,93.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.691 | Acc: 50.568,79.348,93.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.701 | Acc: 50.462,79.239,93.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.709 | Acc: 50.404,79.143,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.718 | Acc: 50.357,79.083,93.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.724 | Acc: 50.292,79.004,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.728 | Acc: 50.204,78.918,93.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.734 | Acc: 50.125,78.934,93.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.734 | Acc: 50.127,78.943,93.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.736 | Acc: 50.170,78.918,93.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.735 | Acc: 50.218,78.945,93.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.739 | Acc: 50.145,78.952,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.741 | Acc: 50.180,78.906,92.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.393 | Acc: 49.219,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.664 | Acc: 45.610,62.984,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.738 | Acc: 45.084,62.843,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.769 | Acc: 45.005,62.500,67.930,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 2.737 | Acc: 52.344,81.250,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.807 | Acc: 49.777,78.348,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.752 | Acc: 49.848,79.402,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.716 | Acc: 50.256,79.816,93.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.698 | Acc: 50.907,79.745,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.699 | Acc: 50.696,79.742,93.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.710 | Acc: 50.826,79.545,93.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.708 | Acc: 50.720,79.599,93.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.707 | Acc: 50.704,79.464,93.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.708 | Acc: 50.704,79.411,93.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.713 | Acc: 50.532,79.439,93.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.718 | Acc: 50.654,79.369,93.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.720 | Acc: 50.590,79.324,93.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.721 | Acc: 50.554,79.301,93.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.721 | Acc: 50.598,79.282,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.720 | Acc: 50.589,79.360,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.718 | Acc: 50.669,79.325,93.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.724 | Acc: 50.662,79.250,92.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.725 | Acc: 50.684,79.227,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.729 | Acc: 50.632,79.169,92.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.972 | Acc: 50.000,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.792 | Acc: 44.531,63.021,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.807 | Acc: 44.607,62.157,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.795 | Acc: 44.582,62.039,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.272 | Acc: 56.250,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.753 | Acc: 48.698,78.534,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.747 | Acc: 49.714,78.430,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.717 | Acc: 49.923,79.137,93.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.703 | Acc: 50.154,79.234,93.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.721 | Acc: 50.139,79.208,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.736 | Acc: 49.994,79.042,93.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.725 | Acc: 50.161,79.122,93.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.730 | Acc: 50.078,79.071,93.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.725 | Acc: 50.332,79.096,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.731 | Acc: 50.447,78.922,93.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.733 | Acc: 50.322,78.991,93.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.731 | Acc: 50.259,79.101,93.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.735 | Acc: 50.329,79.014,92.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.737 | Acc: 50.295,78.998,92.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.736 | Acc: 50.260,78.984,92.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.739 | Acc: 50.287,78.996,92.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.737 | Acc: 50.318,79.009,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.741 | Acc: 50.277,78.947,92.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.746 | Acc: 50.246,78.906,92.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.884 | Acc: 46.875,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.712 | Acc: 44.382,63.170,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.730 | Acc: 44.588,63.262,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.774 | Acc: 44.595,62.679,68.660,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.581 | Acc: 50.781,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.656 | Acc: 52.344,81.399,93.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.650 | Acc: 51.296,80.697,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.633 | Acc: 51.204,80.571,94.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.635 | Acc: 51.013,80.652,94.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.629 | Acc: 51.253,80.569,94.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.636 | Acc: 50.904,80.456,94.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.637 | Acc: 50.837,80.336,94.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.631 | Acc: 50.946,80.260,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.621 | Acc: 51.066,80.309,94.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.614 | Acc: 51.252,80.360,94.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.609 | Acc: 51.350,80.370,94.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.605 | Acc: 51.284,80.420,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.606 | Acc: 51.236,80.397,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.611 | Acc: 51.043,80.385,94.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.610 | Acc: 51.085,80.417,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.610 | Acc: 51.064,80.449,94.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.606 | Acc: 51.194,80.576,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.607 | Acc: 51.164,80.607,94.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.602 | Acc: 51.159,80.674,94.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.400 | Acc: 45.312,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.424 | Acc: 46.429,64.993,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.464 | Acc: 46.570,64.882,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.492 | Acc: 46.593,64.588,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.602 | Acc: 43.750,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.581 | Acc: 51.451,81.585,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.598 | Acc: 50.877,81.193,94.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.574 | Acc: 51.742,81.404,94.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.569 | Acc: 51.861,81.530,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.556 | Acc: 51.818,81.737,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.563 | Acc: 51.608,81.573,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.567 | Acc: 51.496,81.521,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.566 | Acc: 51.645,81.454,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.564 | Acc: 51.692,81.267,95.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.561 | Acc: 51.644,81.308,95.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.555 | Acc: 51.623,81.345,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.550 | Acc: 51.595,81.415,95.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.552 | Acc: 51.530,81.406,95.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.548 | Acc: 51.660,81.517,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.549 | Acc: 51.594,81.478,95.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.546 | Acc: 51.638,81.552,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.545 | Acc: 51.654,81.479,95.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.544 | Acc: 51.617,81.488,95.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.545 | Acc: 51.608,81.506,95.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.405 | Acc: 46.094,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.431 | Acc: 46.689,65.253,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.466 | Acc: 46.761,64.901,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.493 | Acc: 46.901,64.511,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.399 | Acc: 57.031,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.517 | Acc: 53.311,81.548,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 52.039,81.441,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.511 | Acc: 51.819,81.942,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.522 | Acc: 51.717,81.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.537 | Acc: 51.292,81.675,95.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.539 | Acc: 51.207,81.676,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.537 | Acc: 51.346,81.660,95.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.546 | Acc: 51.315,81.507,95.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.546 | Acc: 51.252,81.574,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.547 | Acc: 51.201,81.499,95.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.555 | Acc: 51.043,81.462,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.553 | Acc: 51.079,81.516,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.545 | Acc: 51.185,81.645,95.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.540 | Acc: 51.385,81.664,95.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.539 | Acc: 51.479,81.673,95.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.541 | Acc: 51.502,81.600,95.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.536 | Acc: 51.604,81.644,95.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.537 | Acc: 51.588,81.581,95.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.536 | Acc: 51.524,81.640,95.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.455 | Acc: 46.875,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.446 | Acc: 46.689,65.179,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.477 | Acc: 46.532,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.501 | Acc: 46.709,64.562,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.543 | Acc: 47.656,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.578 | Acc: 50.707,81.399,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.536 | Acc: 51.905,81.955,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.518 | Acc: 52.241,81.903,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.513 | Acc: 51.977,81.925,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.522 | Acc: 51.849,81.799,95.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 51.840,81.805,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.533 | Acc: 51.723,81.776,95.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.531 | Acc: 51.829,81.764,95.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.528 | Acc: 51.809,81.738,95.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.534 | Acc: 51.862,81.639,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.530 | Acc: 51.874,81.646,95.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 51.942,81.616,95.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.525 | Acc: 51.937,81.669,95.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.524 | Acc: 51.957,81.675,95.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.522 | Acc: 51.923,81.689,95.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 51.699,81.695,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.528 | Acc: 51.698,81.711,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.533 | Acc: 51.608,81.653,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.533 | Acc: 51.575,81.679,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.377 | Acc: 47.656,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.441 | Acc: 46.726,65.253,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.470 | Acc: 46.608,64.920,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.496 | Acc: 46.760,64.511,70.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 2.746 | Acc: 47.656,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.472 | Acc: 54.204,81.808,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 53.944,81.707,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.491 | Acc: 53.240,81.647,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.489 | Acc: 52.556,81.645,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 52.189,81.482,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.496 | Acc: 52.357,81.586,95.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.501 | Acc: 52.305,81.577,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.506 | Acc: 52.247,81.687,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.510 | Acc: 52.175,81.651,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.508 | Acc: 52.328,81.759,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.511 | Acc: 52.089,81.724,95.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.515 | Acc: 52.101,81.730,95.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.516 | Acc: 51.979,81.861,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.517 | Acc: 51.968,81.859,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.516 | Acc: 51.973,81.759,95.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.518 | Acc: 51.891,81.744,95.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.515 | Acc: 51.982,81.740,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.516 | Acc: 51.881,81.746,95.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.514 | Acc: 51.934,81.728,95.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.387 | Acc: 46.875,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.443 | Acc: 46.726,64.955,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.475 | Acc: 46.570,65.149,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.502 | Acc: 46.606,64.690,69.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.583 | Acc: 46.875,78.125,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.443 | Acc: 51.265,82.478,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.495 | Acc: 51.258,81.402,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.517 | Acc: 50.871,81.237,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.539 | Acc: 51.042,81.385,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.544 | Acc: 50.959,81.451,95.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.528 | Acc: 51.356,81.728,95.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.533 | Acc: 51.413,81.704,95.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.533 | Acc: 51.558,81.818,95.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.534 | Acc: 51.580,81.733,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.528 | Acc: 51.699,81.782,95.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.533 | Acc: 51.608,81.699,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.534 | Acc: 51.556,81.694,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 51.613,81.783,95.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.524 | Acc: 51.568,81.798,95.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 51.555,81.821,95.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.522 | Acc: 51.502,81.795,95.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 51.576,81.701,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.523 | Acc: 51.673,81.715,95.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 51.804,81.781,95.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.342 | Acc: 46.875,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.432 | Acc: 46.875,64.881,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 46.627,64.882,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.502 | Acc: 46.862,64.575,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.390 | Acc: 53.125,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.518 | Acc: 51.228,82.626,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.468 | Acc: 52.229,82.946,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.487 | Acc: 52.305,82.223,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.483 | Acc: 52.595,82.070,95.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.487 | Acc: 52.537,82.170,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.487 | Acc: 52.157,82.231,95.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.499 | Acc: 52.017,82.125,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.503 | Acc: 51.854,82.041,95.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.496 | Acc: 51.925,82.225,95.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.505 | Acc: 51.679,82.070,95.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.504 | Acc: 51.750,82.077,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.499 | Acc: 51.851,82.119,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.499 | Acc: 51.847,82.121,95.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.499 | Acc: 52.018,82.092,95.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.503 | Acc: 52.004,82.026,95.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.505 | Acc: 51.920,82.036,95.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.511 | Acc: 51.803,81.969,95.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 51.827,81.932,95.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.510 | Acc: 51.788,81.937,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.357 | Acc: 47.656,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.462 | Acc: 47.321,65.327,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.501 | Acc: 46.989,64.996,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.528 | Acc: 46.939,64.524,69.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.748 | Acc: 44.531,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.531 | Acc: 51.190,81.436,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.500 | Acc: 51.982,81.784,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.507 | Acc: 51.729,81.775,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.513 | Acc: 51.591,81.819,95.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.499 | Acc: 51.810,82.024,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.496 | Acc: 51.905,82.109,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.500 | Acc: 51.973,82.159,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.500 | Acc: 51.694,82.085,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.499 | Acc: 51.787,82.070,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.503 | Acc: 51.772,82.020,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.500 | Acc: 51.838,82.014,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.505 | Acc: 51.812,81.970,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.511 | Acc: 51.709,81.918,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.513 | Acc: 51.718,81.951,95.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.515 | Acc: 51.705,81.948,95.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.514 | Acc: 51.740,81.934,95.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.512 | Acc: 51.707,81.965,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.507 | Acc: 51.801,82.072,95.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.507 | Acc: 51.780,82.095,95.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.355 | Acc: 46.875,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.455 | Acc: 46.615,65.179,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.494 | Acc: 46.761,64.996,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.524 | Acc: 46.913,64.703,69.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.571 | Acc: 50.000,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.465 | Acc: 51.525,82.701,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.465 | Acc: 51.696,82.050,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.474 | Acc: 51.806,81.916,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.484 | Acc: 51.726,82.166,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 51.562,82.310,95.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 51.672,82.264,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.498 | Acc: 51.801,82.192,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.507 | Acc: 51.669,82.143,95.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.502 | Acc: 51.765,82.213,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.501 | Acc: 51.870,82.284,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.504 | Acc: 51.771,82.311,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.509 | Acc: 51.686,82.151,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.513 | Acc: 51.554,82.124,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.515 | Acc: 51.507,82.115,95.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 51.443,82.096,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.518 | Acc: 51.358,82.090,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.516 | Acc: 51.407,82.093,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.514 | Acc: 51.489,82.105,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.512 | Acc: 51.569,82.062,95.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.345 | Acc: 46.875,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.442 | Acc: 46.726,65.290,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.486 | Acc: 46.551,65.091,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.512 | Acc: 46.875,64.728,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.876 | Acc: 60.156,89.844,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.457 | Acc: 52.716,82.626,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 52.344,82.755,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 52.510,82.825,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.461 | Acc: 52.296,82.620,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.466 | Acc: 52.135,82.611,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.467 | Acc: 52.247,82.354,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.480 | Acc: 52.172,82.292,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.485 | Acc: 51.980,82.235,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 52.033,82.230,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.486 | Acc: 51.928,82.198,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.489 | Acc: 51.912,82.187,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 51.906,82.187,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 51.859,82.166,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 51.685,82.204,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 51.794,82.190,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 51.813,82.148,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.496 | Acc: 51.677,82.043,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.494 | Acc: 51.716,82.012,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.494 | Acc: 51.679,81.998,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.370 | Acc: 46.875,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.461 | Acc: 46.949,65.625,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.504 | Acc: 46.837,65.263,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.533 | Acc: 46.875,64.741,69.813,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.431 | Acc: 51.562,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.503 | Acc: 51.600,82.143,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.528 | Acc: 51.315,81.669,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 51.370,81.929,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 51.755,81.867,96.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.499 | Acc: 51.787,81.815,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.494 | Acc: 51.646,82.064,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.505 | Acc: 51.524,82.048,96.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 51.655,82.153,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.493 | Acc: 51.796,82.204,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.493 | Acc: 51.652,82.152,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.492 | Acc: 51.729,82.137,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.495 | Acc: 51.744,82.060,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.493 | Acc: 51.829,82.136,96.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 51.916,82.140,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 51.895,82.114,96.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.495 | Acc: 51.884,82.129,96.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.491 | Acc: 51.943,82.095,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.493 | Acc: 51.861,82.075,96.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 51.899,82.109,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 45.312,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.464 | Acc: 46.540,65.439,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.510 | Acc: 46.818,65.130,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.539 | Acc: 46.837,64.613,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.486 | Acc: 53.906,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.409 | Acc: 51.823,83.631,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.454 | Acc: 52.096,82.832,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.479 | Acc: 51.947,82.223,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 51.968,82.108,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.482 | Acc: 52.112,82.178,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.478 | Acc: 52.286,82.328,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.478 | Acc: 52.344,82.386,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.484 | Acc: 52.038,82.347,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.481 | Acc: 52.085,82.398,96.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.481 | Acc: 52.009,82.463,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.490 | Acc: 51.877,82.431,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.497 | Acc: 51.845,82.352,96.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.496 | Acc: 51.799,82.331,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.495 | Acc: 51.788,82.359,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.499 | Acc: 51.744,82.299,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.504 | Acc: 51.672,82.204,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.507 | Acc: 51.693,82.157,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.507 | Acc: 51.770,82.148,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.507 | Acc: 51.768,82.150,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.425 | Acc: 47.656,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.474 | Acc: 46.503,64.955,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.518 | Acc: 46.361,64.863,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.541 | Acc: 46.683,64.536,69.915,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.577 | Acc: 50.000,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.510 | Acc: 51.265,82.515,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.521 | Acc: 51.582,81.993,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.498 | Acc: 52.190,81.993,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.509 | Acc: 51.900,81.848,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 51.679,81.815,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.503 | Acc: 51.705,81.850,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.500 | Acc: 51.657,81.848,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.482 | Acc: 51.960,82.114,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.478 | Acc: 51.929,82.299,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.482 | Acc: 51.912,82.233,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.483 | Acc: 51.760,82.215,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.482 | Acc: 51.747,82.187,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 51.682,82.226,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.484 | Acc: 51.749,82.254,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.486 | Acc: 51.690,82.205,96.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 51.762,82.158,96.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 51.679,82.093,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 51.690,82.116,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.496 | Acc: 51.675,82.048,96.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.399 | Acc: 47.656,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.492 | Acc: 46.689,65.141,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 46.646,64.920,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 46.798,64.639,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.446 | Acc: 51.562,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.436 | Acc: 53.274,83.594,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 52.458,83.155,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.458 | Acc: 52.626,83.517,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.470 | Acc: 52.681,83.256,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.472 | Acc: 52.591,83.091,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.465 | Acc: 52.712,83.006,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.472 | Acc: 52.671,82.873,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 52.713,82.788,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 52.447,82.705,95.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.484 | Acc: 52.558,82.556,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.481 | Acc: 52.528,82.593,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.482 | Acc: 52.405,82.469,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.487 | Acc: 52.242,82.387,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.483 | Acc: 52.299,82.404,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 52.204,82.460,95.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.481 | Acc: 52.237,82.467,95.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.487 | Acc: 52.142,82.370,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.114,82.373,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.130,82.390,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.411 | Acc: 49.219,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.461 | Acc: 47.061,65.216,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.503 | Acc: 46.913,65.034,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 47.131,64.754,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.326 | Acc: 57.812,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.430 | Acc: 51.972,83.073,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.445 | Acc: 51.524,83.518,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.444 | Acc: 51.857,83.581,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.460 | Acc: 51.746,83.382,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.444 | Acc: 52.081,83.416,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.459 | Acc: 51.982,83.077,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.469 | Acc: 51.945,82.702,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.470 | Acc: 52.004,82.609,96.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.478 | Acc: 51.869,82.497,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.477 | Acc: 51.811,82.533,96.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.474 | Acc: 51.806,82.487,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 51.744,82.466,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.485 | Acc: 51.757,82.483,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 51.821,82.482,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 51.822,82.472,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 51.820,82.391,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 51.812,82.398,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 51.915,82.421,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.485 | Acc: 51.985,82.400,96.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.368 | Acc: 48.438,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.452 | Acc: 46.987,65.551,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.495 | Acc: 46.875,65.091,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.522 | Acc: 46.888,64.805,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.387 | Acc: 57.812,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.472 | Acc: 52.641,81.287,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.491 | Acc: 52.611,82.127,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.510 | Acc: 51.575,81.826,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.517 | Acc: 51.669,81.559,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 51.454,81.699,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.516 | Acc: 51.382,81.760,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 51.313,81.782,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.506 | Acc: 51.349,82.031,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.502 | Acc: 51.368,82.122,96.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 51.469,82.167,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 51.619,82.265,96.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 51.754,82.291,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.488 | Acc: 51.751,82.295,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.489 | Acc: 51.768,82.345,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 51.796,82.389,96.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 51.674,82.279,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.495 | Acc: 51.684,82.235,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.496 | Acc: 51.627,82.226,96.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 51.661,82.214,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.385 | Acc: 48.438,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.468 | Acc: 47.135,64.769,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.511 | Acc: 47.123,64.806,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.534 | Acc: 47.182,64.575,69.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 3.064 | Acc: 44.531,75.000,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.483 | Acc: 51.637,82.068,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.452 | Acc: 51.677,82.927,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 51.306,82.646,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.464 | Acc: 51.514,82.658,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.470 | Acc: 51.323,82.426,96.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.461 | Acc: 51.788,82.457,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.461 | Acc: 51.806,82.452,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.461 | Acc: 51.970,82.390,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.465 | Acc: 51.951,82.191,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.469 | Acc: 51.803,82.292,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.470 | Acc: 51.934,82.250,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.468 | Acc: 51.994,82.287,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.474 | Acc: 51.820,82.271,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.474 | Acc: 51.746,82.329,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.474 | Acc: 51.708,82.304,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.477 | Acc: 51.682,82.323,96.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.478 | Acc: 51.753,82.352,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.478 | Acc: 51.762,82.330,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 51.815,82.370,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.397 | Acc: 47.656,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 46.689,64.769,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 46.513,64.710,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 46.747,64.383,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.955 | Acc: 58.594,92.969,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.507 | Acc: 52.381,83.296,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.471 | Acc: 52.630,82.870,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.487 | Acc: 52.190,82.505,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.487 | Acc: 51.707,82.465,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.494 | Acc: 51.833,82.457,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.490 | Acc: 51.827,82.490,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.483 | Acc: 51.768,82.508,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.481 | Acc: 51.800,82.516,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.481 | Acc: 51.826,82.489,96.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.489 | Acc: 51.842,82.404,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 51.785,82.410,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.495 | Acc: 51.854,82.381,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.496 | Acc: 51.724,82.352,96.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.494 | Acc: 51.626,82.379,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.492 | Acc: 51.757,82.366,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 51.687,82.350,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 51.711,82.341,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.494 | Acc: 51.699,82.328,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 51.747,82.341,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.474 | Acc: 46.875,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.482 | Acc: 46.801,65.141,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.521 | Acc: 46.780,64.882,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.545 | Acc: 46.939,64.575,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.075 | Acc: 64.062,85.938,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.573 | Acc: 51.339,80.283,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.530 | Acc: 51.334,81.536,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.528 | Acc: 51.396,81.673,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.506 | Acc: 51.360,82.002,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.508 | Acc: 51.431,81.861,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.503 | Acc: 51.466,81.831,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.504 | Acc: 51.313,81.965,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 51.417,82.070,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.496 | Acc: 51.506,82.135,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.492 | Acc: 51.555,82.148,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.490 | Acc: 51.591,82.229,96.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.493 | Acc: 51.520,82.190,96.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 51.637,82.244,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 51.674,82.184,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 51.672,82.203,96.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 51.643,82.197,96.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 51.631,82.215,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 51.651,82.226,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 51.630,82.265,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.353 | Acc: 47.656,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.486 | Acc: 46.615,65.216,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.528 | Acc: 46.646,64.996,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.552 | Acc: 46.785,64.600,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.524 | Acc: 53.125,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.422 | Acc: 52.121,83.259,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.431 | Acc: 52.649,82.908,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.459 | Acc: 52.433,83.248,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.471 | Acc: 52.074,82.851,96.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.469 | Acc: 52.166,82.905,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.478 | Acc: 52.027,82.683,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.493 | Acc: 51.756,82.486,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.494 | Acc: 51.660,82.453,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.494 | Acc: 51.575,82.420,96.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 51.648,82.346,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 51.654,82.268,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 51.514,82.287,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.493 | Acc: 51.574,82.262,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.496 | Acc: 51.576,82.218,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.493 | Acc: 51.630,82.226,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 51.611,82.202,96.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 51.592,82.221,96.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 51.537,82.174,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.491 | Acc: 51.640,82.201,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.321 | Acc: 47.656,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.468 | Acc: 46.652,65.030,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.515 | Acc: 46.684,64.958,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 46.990,64.626,69.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.483 | Acc: 49.219,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.519 | Acc: 51.228,82.254,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.497 | Acc: 51.696,82.050,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.494 | Acc: 51.844,82.313,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 51.273,82.060,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 51.532,82.395,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 51.737,82.541,96.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.495 | Acc: 51.562,82.414,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.495 | Acc: 51.548,82.395,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.492 | Acc: 51.619,82.467,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.488 | Acc: 51.648,82.533,96.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 51.566,82.597,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 51.595,82.530,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.483 | Acc: 51.712,82.573,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.482 | Acc: 51.721,82.623,96.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.484 | Acc: 51.729,82.584,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 51.777,82.511,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 51.817,82.483,96.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.482 | Acc: 51.824,82.533,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 51.784,82.460,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.408 | Acc: 47.656,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 46.838,65.476,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.531 | Acc: 46.894,65.149,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.553 | Acc: 46.913,64.741,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.319 | Acc: 53.906,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.495 | Acc: 53.088,82.031,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.509 | Acc: 52.363,82.146,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.493 | Acc: 52.216,82.480,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.474 | Acc: 52.016,82.552,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.464 | Acc: 52.073,82.426,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.461 | Acc: 51.905,82.302,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.470 | Acc: 51.723,82.247,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.468 | Acc: 51.800,82.308,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.467 | Acc: 51.852,82.303,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.468 | Acc: 51.908,82.334,96.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.475 | Acc: 51.923,82.364,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 51.857,82.411,96.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.478 | Acc: 51.766,82.319,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.483 | Acc: 51.654,82.187,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.484 | Acc: 51.710,82.200,96.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 51.577,82.170,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.485 | Acc: 51.661,82.240,96.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 51.686,82.196,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.486 | Acc: 51.700,82.212,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.397 | Acc: 47.656,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.493 | Acc: 47.061,64.955,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.522 | Acc: 46.989,64.768,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.545 | Acc: 47.003,64.498,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 2.623 | Acc: 46.875,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.469 | Acc: 50.818,82.403,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.470 | Acc: 51.086,83.022,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.463 | Acc: 51.550,82.710,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.463 | Acc: 51.601,82.446,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.460 | Acc: 51.648,82.488,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.467 | Acc: 51.821,82.264,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.472 | Acc: 51.823,82.397,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.474 | Acc: 51.810,82.400,96.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.475 | Acc: 51.791,82.359,96.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.478 | Acc: 51.726,82.366,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 51.782,82.455,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 51.809,82.423,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 51.766,82.495,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 51.921,82.479,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.475 | Acc: 51.960,82.460,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.476 | Acc: 51.969,82.445,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.477 | Acc: 51.982,82.407,96.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.479 | Acc: 51.930,82.323,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.480 | Acc: 51.893,82.320,96.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.452 | Acc: 46.875,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.513 | Acc: 46.652,64.955,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.546 | Acc: 46.551,64.539,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 46.926,64.101,69.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.313 | Acc: 60.156,87.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.449 | Acc: 52.679,81.585,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.413 | Acc: 52.611,82.851,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.425 | Acc: 52.485,82.595,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.446 | Acc: 51.968,82.157,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.467 | Acc: 51.725,82.000,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.479 | Acc: 51.808,82.089,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.478 | Acc: 51.812,82.236,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 51.645,82.230,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 51.601,82.191,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.484 | Acc: 51.671,82.163,96.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.481 | Acc: 51.849,82.197,96.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.474 | Acc: 51.861,82.291,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.478 | Acc: 51.847,82.259,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.477 | Acc: 51.849,82.226,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.471 | Acc: 51.892,82.299,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.472 | Acc: 51.842,82.323,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.472 | Acc: 51.918,82.295,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.474 | Acc: 51.870,82.317,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.475 | Acc: 51.878,82.324,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.415 | Acc: 46.094,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.500 | Acc: 46.503,65.216,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 46.551,65.015,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 46.798,64.664,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 2.703 | Acc: 46.094,75.781,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.447 | Acc: 52.009,82.403,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.468 | Acc: 51.220,82.298,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.463 | Acc: 51.755,82.364,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.451 | Acc: 52.180,82.629,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.462 | Acc: 51.795,82.395,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.452 | Acc: 51.963,82.548,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.450 | Acc: 51.945,82.580,96.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.454 | Acc: 51.936,82.648,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.453 | Acc: 51.891,82.636,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.455 | Acc: 52.177,82.606,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.464 | Acc: 52.107,82.505,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.471 | Acc: 51.997,82.368,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.472 | Acc: 51.859,82.298,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.476 | Acc: 51.774,82.231,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.471 | Acc: 51.835,82.249,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.472 | Acc: 51.791,82.306,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.472 | Acc: 51.789,82.334,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.472 | Acc: 51.798,82.362,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.470 | Acc: 51.733,82.411,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.421 | Acc: 46.875,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.875,65.104,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 46.913,64.768,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 47.067,64.536,69.736,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.310 | Acc: 53.906,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.460 | Acc: 52.865,82.626,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.455 | Acc: 52.496,82.870,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 52.664,82.928,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.470 | Acc: 52.286,82.784,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.464 | Acc: 52.096,82.952,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.465 | Acc: 52.060,82.967,96.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.464 | Acc: 51.845,82.901,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.466 | Acc: 51.757,82.769,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.472 | Acc: 51.580,82.648,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.474 | Acc: 51.508,82.556,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.474 | Acc: 51.545,82.586,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.475 | Acc: 51.462,82.556,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.472 | Acc: 51.509,82.678,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.471 | Acc: 51.510,82.612,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 51.534,82.545,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.476 | Acc: 51.448,82.518,96.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.476 | Acc: 51.517,82.542,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.474 | Acc: 51.584,82.555,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.469 | Acc: 51.675,82.564,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 46.875,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.391,65.290,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.528 | Acc: 46.589,65.034,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 46.888,64.793,69.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.486 | Acc: 50.781,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.407 | Acc: 52.418,83.817,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.438 | Acc: 52.344,83.232,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.442 | Acc: 52.267,83.453,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.455 | Acc: 52.112,83.092,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.457 | Acc: 52.266,82.619,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.462 | Acc: 52.131,82.554,96.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.465 | Acc: 52.028,82.497,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.467 | Acc: 52.111,82.541,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 51.998,82.480,96.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.466 | Acc: 52.130,82.595,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.472 | Acc: 52.036,82.508,96.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.467 | Acc: 52.033,82.579,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.461 | Acc: 52.032,82.642,96.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.464 | Acc: 51.957,82.587,96.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.466 | Acc: 51.978,82.581,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.466 | Acc: 51.996,82.642,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.467 | Acc: 51.934,82.602,96.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.466 | Acc: 52.017,82.596,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.467 | Acc: 52.032,82.599,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 46.875,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 46.615,65.290,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.550 | Acc: 46.761,65.111,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 46.901,64.703,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.379 | Acc: 52.344,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.459 | Acc: 52.604,83.371,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.476 | Acc: 52.153,82.622,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.499 | Acc: 51.345,82.531,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.486 | Acc: 51.591,82.716,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.478 | Acc: 51.586,82.704,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.465 | Acc: 51.627,82.748,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.471 | Acc: 51.391,82.569,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.476 | Acc: 51.373,82.468,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.474 | Acc: 51.334,82.338,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.476 | Acc: 51.364,82.296,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.473 | Acc: 51.365,82.445,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.478 | Acc: 51.381,82.388,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.471 | Acc: 51.497,82.474,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 51.437,82.440,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.476 | Acc: 51.402,82.418,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.474 | Acc: 51.536,82.387,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.471 | Acc: 51.533,82.391,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.471 | Acc: 51.558,82.395,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.469 | Acc: 51.729,82.368,96.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.399 | Acc: 47.656,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.493 | Acc: 46.689,65.141,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 46.684,64.901,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.558 | Acc: 46.939,64.613,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.311 | Acc: 56.250,86.719,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.428 | Acc: 50.632,83.222,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.442 | Acc: 51.848,82.603,96.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.430 | Acc: 52.497,82.582,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.451 | Acc: 52.267,82.504,96.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.444 | Acc: 52.251,82.503,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.441 | Acc: 52.318,82.606,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.440 | Acc: 52.455,82.569,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.441 | Acc: 52.611,82.609,96.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.459 | Acc: 52.262,82.480,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.459 | Acc: 52.352,82.533,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.461 | Acc: 52.305,82.540,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.459 | Acc: 52.292,82.556,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.462 | Acc: 52.200,82.564,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.471 | Acc: 52.018,82.462,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.474 | Acc: 51.991,82.421,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.475 | Acc: 51.954,82.413,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.475 | Acc: 51.929,82.347,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.478 | Acc: 51.855,82.390,96.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.475 | Acc: 51.907,82.384,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.376 | Acc: 46.094,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.488 | Acc: 46.689,64.844,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.528 | Acc: 46.704,64.920,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.551 | Acc: 46.926,64.626,69.864,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.574 | Acc: 51.562,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.424 | Acc: 54.427,83.259,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.440 | Acc: 53.182,82.927,96.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.437 | Acc: 52.933,83.210,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.427 | Acc: 53.000,83.198,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.439 | Acc: 52.607,82.990,96.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.441 | Acc: 52.460,82.942,96.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.441 | Acc: 52.477,82.923,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.451 | Acc: 52.494,82.740,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.454 | Acc: 52.240,82.644,96.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.455 | Acc: 52.149,82.606,96.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.461 | Acc: 52.072,82.533,96.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.468 | Acc: 51.990,82.498,96.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.465 | Acc: 51.958,82.552,96.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.465 | Acc: 51.941,82.585,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.467 | Acc: 51.991,82.610,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.469 | Acc: 52.032,82.601,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.468 | Acc: 52.018,82.583,96.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.469 | Acc: 51.926,82.620,96.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.469 | Acc: 51.891,82.560,96.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 46.875,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.515 | Acc: 46.912,65.253,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.541 | Acc: 46.646,64.863,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.564 | Acc: 46.849,64.588,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.928 | Acc: 43.750,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.494 | Acc: 51.562,82.031,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.455 | Acc: 52.420,82.851,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.445 | Acc: 51.985,82.723,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.448 | Acc: 51.804,82.716,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.452 | Acc: 51.648,82.611,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.458 | Acc: 51.446,82.509,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.466 | Acc: 51.507,82.231,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.464 | Acc: 51.737,82.390,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.466 | Acc: 51.714,82.377,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.465 | Acc: 51.667,82.369,96.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.470 | Acc: 51.555,82.293,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.468 | Acc: 51.566,82.326,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.474 | Acc: 51.470,82.307,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.474 | Acc: 51.479,82.348,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.470 | Acc: 51.516,82.444,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.464 | Acc: 51.543,82.494,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.467 | Acc: 51.592,82.478,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.467 | Acc: 51.744,82.427,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.467 | Acc: 51.768,82.443,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 46.875,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 46.689,64.844,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.549 | Acc: 46.665,64.710,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 46.862,64.280,69.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.141 | Acc: 47.656,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.523 | Acc: 50.372,82.068,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.479 | Acc: 51.486,82.622,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.449 | Acc: 51.934,82.851,96.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.441 | Acc: 52.103,83.025,96.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.449 | Acc: 51.818,82.967,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.442 | Acc: 51.918,83.084,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.454 | Acc: 51.734,82.923,96.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.456 | Acc: 51.553,82.910,96.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.457 | Acc: 51.580,82.752,96.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.462 | Acc: 51.574,82.762,96.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.467 | Acc: 51.492,82.798,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.468 | Acc: 51.546,82.754,96.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.470 | Acc: 51.551,82.702,96.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.468 | Acc: 51.618,82.726,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.466 | Acc: 51.695,82.784,96.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.462 | Acc: 51.796,82.817,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.461 | Acc: 51.831,82.819,96.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 51.852,82.761,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.462 | Acc: 51.884,82.774,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.433 | Acc: 46.875,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 46.317,65.141,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.540 | Acc: 46.818,64.748,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 47.041,64.562,69.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.862 | Acc: 47.656,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.470 | Acc: 51.897,82.366,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.459 | Acc: 52.172,83.460,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.443 | Acc: 52.254,83.376,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.459 | Acc: 51.910,82.870,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.448 | Acc: 52.119,82.890,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.448 | Acc: 52.305,82.974,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.446 | Acc: 52.377,82.940,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.452 | Acc: 52.329,82.866,96.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.464 | Acc: 51.985,82.687,96.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.462 | Acc: 51.842,82.785,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.463 | Acc: 51.895,82.742,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.462 | Acc: 51.893,82.787,96.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.457 | Acc: 51.958,82.744,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.457 | Acc: 51.941,82.754,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.453 | Acc: 52.004,82.768,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.455 | Acc: 52.064,82.727,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.453 | Acc: 52.041,82.739,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.456 | Acc: 52.054,82.696,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.455 | Acc: 52.094,82.644,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.492 | Acc: 45.312,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 46.726,64.993,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.546 | Acc: 46.704,64.748,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 46.901,64.498,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.522 | Acc: 52.344,81.250,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.435 | Acc: 51.823,82.887,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.480 | Acc: 50.857,82.603,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 51.422,82.953,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.457 | Acc: 51.746,83.034,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.463 | Acc: 51.880,82.836,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.474 | Acc: 51.614,82.729,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.469 | Acc: 51.635,82.668,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.469 | Acc: 51.703,82.623,96.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.462 | Acc: 51.714,82.748,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.460 | Acc: 51.803,82.820,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.455 | Acc: 51.920,82.830,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.458 | Acc: 51.857,82.741,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.459 | Acc: 51.796,82.759,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.458 | Acc: 51.918,82.657,96.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.465 | Acc: 51.768,82.607,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.466 | Acc: 51.735,82.628,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.465 | Acc: 51.821,82.586,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.463 | Acc: 51.889,82.585,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.464 | Acc: 51.835,82.616,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.489 | Acc: 47.656,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 46.949,65.030,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 46.932,64.729,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 46.837,64.549,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.241 | Acc: 58.594,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 52.269,82.924,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.431 | Acc: 53.011,82.717,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.438 | Acc: 53.099,82.569,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.439 | Acc: 52.604,82.687,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.426 | Acc: 52.777,82.735,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.430 | Acc: 52.550,82.877,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.446 | Acc: 52.371,82.657,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.451 | Acc: 52.363,82.618,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.450 | Acc: 52.292,82.692,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.447 | Acc: 52.118,82.820,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.461 | Acc: 51.944,82.657,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.460 | Acc: 52.000,82.702,96.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.461 | Acc: 52.044,82.696,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.458 | Acc: 52.005,82.718,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.457 | Acc: 52.001,82.678,96.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.456 | Acc: 52.018,82.637,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.460 | Acc: 51.879,82.586,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.458 | Acc: 51.909,82.574,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.461 | Acc: 51.891,82.624,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 47.656,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 46.540,64.435,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 46.551,64.215,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 46.734,64.203,69.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.157 | Acc: 54.688,87.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.431 | Acc: 52.865,83.110,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.432 | Acc: 52.534,83.022,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.419 | Acc: 52.792,82.941,96.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.429 | Acc: 52.604,82.494,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.450 | Acc: 52.406,82.472,96.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.458 | Acc: 52.247,82.432,96.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.459 | Acc: 52.205,82.469,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.453 | Acc: 52.358,82.531,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.452 | Acc: 52.326,82.528,96.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.450 | Acc: 52.282,82.583,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.448 | Acc: 52.347,82.660,96.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.447 | Acc: 52.289,82.780,96.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.444 | Acc: 52.314,82.753,96.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.447 | Acc: 52.144,82.696,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.448 | Acc: 52.188,82.711,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.447 | Acc: 52.242,82.730,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.451 | Acc: 52.181,82.700,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.451 | Acc: 52.201,82.672,96.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.455 | Acc: 52.159,82.651,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.491 | Acc: 46.875,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 46.801,64.807,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 46.837,64.768,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 46.990,64.549,69.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.396 | Acc: 58.594,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.441 | Acc: 53.274,82.775,96.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.449 | Acc: 52.706,82.927,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 52.408,82.544,96.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.466 | Acc: 52.160,82.639,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.471 | Acc: 52.019,82.782,96.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.463 | Acc: 52.040,82.800,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.455 | Acc: 51.973,82.885,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.455 | Acc: 51.805,82.842,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.453 | Acc: 51.912,82.821,96.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.446 | Acc: 51.936,82.867,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.447 | Acc: 51.895,82.791,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.455 | Acc: 51.832,82.754,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.461 | Acc: 51.739,82.648,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.456 | Acc: 51.768,82.718,96.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.460 | Acc: 51.723,82.620,96.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.461 | Acc: 51.730,82.555,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.458 | Acc: 51.837,82.570,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.457 | Acc: 51.902,82.577,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.456 | Acc: 51.913,82.519,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.383 | Acc: 48.438,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 46.652,64.732,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.550 | Acc: 46.684,64.672,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 46.888,64.383,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.433 | Acc: 50.000,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 52.158,82.329,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.441 | Acc: 51.772,82.565,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.430 | Acc: 52.382,82.518,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.442 | Acc: 51.910,82.620,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.444 | Acc: 51.733,82.642,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.453 | Acc: 51.834,82.574,96.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.457 | Acc: 51.668,82.635,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.456 | Acc: 51.626,82.609,96.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.454 | Acc: 51.657,82.700,96.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.455 | Acc: 51.800,82.735,96.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.454 | Acc: 51.831,82.763,96.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.451 | Acc: 51.819,82.793,96.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.446 | Acc: 51.940,82.839,96.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.445 | Acc: 52.046,82.846,96.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.449 | Acc: 51.967,82.761,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.451 | Acc: 51.981,82.761,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.449 | Acc: 51.945,82.778,96.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.448 | Acc: 51.948,82.804,96.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.447 | Acc: 51.966,82.860,96.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.386 | Acc: 47.656,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 46.652,65.290,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.540 | Acc: 46.570,64.977,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.570 | Acc: 46.785,64.588,69.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.421 | Acc: 50.000,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.457 | Acc: 51.749,82.626,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.418 | Acc: 52.306,83.422,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.452 | Acc: 52.062,82.928,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.447 | Acc: 52.382,82.716,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.448 | Acc: 52.297,82.658,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.461 | Acc: 52.189,82.587,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.460 | Acc: 52.067,82.752,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.454 | Acc: 52.101,82.769,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.451 | Acc: 52.102,82.726,96.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.448 | Acc: 52.149,82.696,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.451 | Acc: 52.068,82.731,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.447 | Acc: 52.117,82.832,96.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.448 | Acc: 52.080,82.786,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.443 | Acc: 52.091,82.885,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.443 | Acc: 52.076,82.932,96.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.445 | Acc: 51.976,82.963,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.444 | Acc: 51.954,82.925,96.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.446 | Acc: 52.015,82.882,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.444 | Acc: 52.046,82.874,96.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.375 | Acc: 47.656,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.489 | Acc: 46.838,65.253,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 46.894,65.015,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.563 | Acc: 47.003,64.754,69.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.559 | Acc: 50.000,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.534 | Acc: 51.414,81.585,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.499 | Acc: 52.153,81.974,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.476 | Acc: 52.369,82.070,96.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.474 | Acc: 52.286,82.359,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.470 | Acc: 52.197,82.542,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.469 | Acc: 52.176,82.767,96.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.464 | Acc: 52.089,82.940,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.460 | Acc: 52.053,83.075,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.452 | Acc: 52.102,83.106,96.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.449 | Acc: 52.192,83.057,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.453 | Acc: 52.128,83.018,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.449 | Acc: 52.130,83.043,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.450 | Acc: 51.886,83.061,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.450 | Acc: 51.935,83.004,96.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.454 | Acc: 51.853,82.929,96.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.454 | Acc: 51.803,82.983,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.453 | Acc: 51.833,83.012,96.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.455 | Acc: 51.822,82.979,96.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.452 | Acc: 51.854,82.991,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.405 | Acc: 48.438,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.501 | Acc: 46.689,65.327,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.532 | Acc: 46.761,65.168,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.558 | Acc: 46.977,64.844,69.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.319 | Acc: 57.812,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.384 | Acc: 51.116,84.040,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.389 | Acc: 51.925,83.537,97.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.393 | Acc: 52.011,83.850,97.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.407 | Acc: 51.977,83.497,96.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.403 | Acc: 51.895,83.718,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.406 | Acc: 51.976,83.510,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.425 | Acc: 51.961,83.261,96.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.426 | Acc: 51.931,83.176,96.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.427 | Acc: 52.033,83.197,96.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.421 | Acc: 52.072,83.182,96.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.422 | Acc: 52.068,83.109,96.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.428 | Acc: 52.003,83.023,96.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.431 | Acc: 52.062,82.980,96.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.434 | Acc: 52.005,82.982,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.433 | Acc: 52.074,82.994,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.437 | Acc: 52.035,82.980,96.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.440 | Acc: 51.968,82.957,96.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.442 | Acc: 51.935,82.949,96.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.443 | Acc: 51.971,82.897,96.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.395 | Acc: 48.438,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 46.801,64.993,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 46.875,64.920,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.570 | Acc: 47.029,64.575,69.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.265 | Acc: 54.688,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.478 | Acc: 52.269,81.994,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.413 | Acc: 53.220,82.736,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.431 | Acc: 53.023,82.723,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.435 | Acc: 53.048,82.735,96.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.447 | Acc: 52.754,82.851,96.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.457 | Acc: 52.324,82.909,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.447 | Acc: 52.338,83.128,96.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.458 | Acc: 52.237,82.880,96.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.448 | Acc: 52.236,82.882,96.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.446 | Acc: 52.235,82.882,96.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.449 | Acc: 52.216,82.890,96.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.445 | Acc: 52.259,82.949,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.440 | Acc: 52.275,83.010,96.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.438 | Acc: 52.230,83.046,96.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.437 | Acc: 52.191,83.056,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.437 | Acc: 52.166,83.080,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.436 | Acc: 52.147,83.097,96.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.437 | Acc: 52.099,83.111,96.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.438 | Acc: 52.032,83.104,96.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 47.656,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.501 | Acc: 46.726,65.402,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.546 | Acc: 46.589,65.111,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 46.824,64.767,69.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.230 | Acc: 53.906,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.448 | Acc: 52.902,82.366,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.444 | Acc: 52.420,82.279,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.435 | Acc: 52.408,82.646,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.425 | Acc: 52.546,82.649,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.422 | Acc: 52.622,82.959,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.426 | Acc: 52.596,82.825,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.427 | Acc: 52.482,82.774,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.432 | Acc: 52.460,82.735,96.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.437 | Acc: 52.348,82.700,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.436 | Acc: 52.258,82.836,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.436 | Acc: 52.238,82.897,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.441 | Acc: 52.172,82.832,96.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.439 | Acc: 52.215,82.926,96.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.443 | Acc: 52.174,82.952,96.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.449 | Acc: 52.089,82.862,96.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.451 | Acc: 52.020,82.844,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.445 | Acc: 52.112,82.900,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.447 | Acc: 52.130,82.895,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.450 | Acc: 52.120,82.829,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.423 | Acc: 46.875,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 46.503,65.253,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.537 | Acc: 46.627,64.977,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.565 | Acc: 46.837,64.741,69.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.658 | Acc: 54.688,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.430 | Acc: 52.827,83.408,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.490 | Acc: 51.829,82.317,96.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.477 | Acc: 51.614,82.608,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.470 | Acc: 51.524,82.764,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.479 | Acc: 51.269,82.851,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.466 | Acc: 51.569,82.864,96.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.458 | Acc: 51.729,82.896,96.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.458 | Acc: 51.737,82.890,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.450 | Acc: 51.834,82.877,96.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.451 | Acc: 51.803,82.859,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.449 | Acc: 51.895,82.901,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.443 | Acc: 51.909,82.949,96.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.443 | Acc: 51.922,82.977,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.446 | Acc: 51.832,82.940,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.446 | Acc: 51.796,82.901,96.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.445 | Acc: 51.850,82.839,96.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.444 | Acc: 51.812,82.842,96.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.444 | Acc: 51.920,82.875,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.443 | Acc: 51.919,82.905,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.332 | Acc: 46.875,70.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.501 | Acc: 46.763,65.179,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.534 | Acc: 46.932,64.977,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.558 | Acc: 47.093,64.639,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.452 | Acc: 53.125,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.507 | Acc: 51.376,81.473,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.506 | Acc: 51.181,82.012,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.487 | Acc: 51.434,82.518,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.465 | Acc: 51.852,82.697,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.448 | Acc: 51.895,82.867,96.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.438 | Acc: 51.931,82.903,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.440 | Acc: 52.006,82.918,96.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.436 | Acc: 52.310,83.011,96.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.429 | Acc: 52.534,83.171,96.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.427 | Acc: 52.515,83.077,96.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.428 | Acc: 52.513,83.003,96.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.423 | Acc: 52.483,83.052,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.418 | Acc: 52.550,83.148,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.425 | Acc: 52.447,83.096,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.423 | Acc: 52.445,83.111,96.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.427 | Acc: 52.400,83.046,96.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.428 | Acc: 52.344,83.023,96.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.433 | Acc: 52.279,82.962,96.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.437 | Acc: 52.215,82.948,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.395 | Acc: 46.875,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.508 | Acc: 46.726,65.141,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 46.742,64.844,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 46.849,64.472,69.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.216 | Acc: 60.156,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.447 | Acc: 51.711,83.185,96.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.463 | Acc: 51.448,82.184,97.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.451 | Acc: 51.575,82.300,97.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.442 | Acc: 52.180,82.417,96.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.435 | Acc: 52.181,82.542,96.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.434 | Acc: 52.040,82.515,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.432 | Acc: 52.045,82.558,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.434 | Acc: 52.009,82.589,96.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.446 | Acc: 51.869,82.497,96.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.448 | Acc: 51.741,82.525,96.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.457 | Acc: 51.658,82.554,96.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.457 | Acc: 51.601,82.605,96.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.459 | Acc: 51.515,82.615,96.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.458 | Acc: 51.476,82.635,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.460 | Acc: 51.433,82.597,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.452 | Acc: 51.643,82.662,96.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.446 | Acc: 51.718,82.783,96.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.443 | Acc: 51.781,82.808,96.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.441 | Acc: 51.870,82.810,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.360 | Acc: 46.875,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 46.652,65.030,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.538 | Acc: 46.799,65.015,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.564 | Acc: 47.016,64.677,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.569 | Acc: 50.000,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.434 | Acc: 51.860,83.482,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.449 | Acc: 51.391,83.194,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 52.062,82.889,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.458 | Acc: 51.804,82.919,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.442 | Acc: 52.042,82.990,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.444 | Acc: 51.956,82.993,96.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.447 | Acc: 51.607,82.796,96.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.441 | Acc: 51.689,82.934,96.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.432 | Acc: 52.003,83.050,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.431 | Acc: 52.114,82.937,96.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.434 | Acc: 52.132,82.915,96.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.439 | Acc: 52.062,82.952,96.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.441 | Acc: 52.062,82.881,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.439 | Acc: 52.096,82.885,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.434 | Acc: 52.175,82.981,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.434 | Acc: 52.147,82.963,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.433 | Acc: 52.135,82.945,96.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.433 | Acc: 52.136,82.942,96.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.434 | Acc: 52.120,82.972,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.396 | Acc: 47.656,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.505 | Acc: 46.280,65.290,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 46.513,65.111,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 46.798,64.805,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.623 | Acc: 44.531,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.481 | Acc: 51.674,82.068,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.459 | Acc: 52.268,82.660,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.462 | Acc: 52.241,82.569,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.453 | Acc: 52.199,82.456,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.445 | Acc: 52.235,82.689,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.440 | Acc: 52.098,82.787,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.437 | Acc: 52.089,82.973,96.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.434 | Acc: 52.242,83.036,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.436 | Acc: 52.206,83.158,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.442 | Acc: 52.130,83.112,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.439 | Acc: 52.132,83.010,96.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.437 | Acc: 52.230,83.078,96.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.440 | Acc: 52.089,83.049,96.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.446 | Acc: 51.955,83.015,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.446 | Acc: 51.874,83.051,96.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.448 | Acc: 51.896,83.027,96.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.442 | Acc: 52.016,83.067,96.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.440 | Acc: 52.062,83.170,96.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.437 | Acc: 52.092,83.175,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.401 | Acc: 46.875,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 46.466,65.216,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.549 | Acc: 46.475,65.015,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 46.798,64.664,69.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.684 | Acc: 45.312,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.533 | Acc: 51.004,81.771,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.506 | Acc: 51.353,82.774,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.468 | Acc: 51.575,83.286,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.445 | Acc: 52.498,83.169,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.431 | Acc: 52.777,83.207,96.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.433 | Acc: 52.596,82.980,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.431 | Acc: 52.416,83.067,96.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.435 | Acc: 52.417,83.041,96.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.432 | Acc: 52.452,83.054,96.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.433 | Acc: 52.262,83.053,96.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.432 | Acc: 52.386,83.081,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.437 | Acc: 52.269,83.107,96.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.439 | Acc: 52.194,83.073,96.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.445 | Acc: 52.141,82.982,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.444 | Acc: 52.144,82.953,96.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.448 | Acc: 52.176,82.924,96.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.448 | Acc: 52.108,82.895,96.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.442 | Acc: 52.162,83.027,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.445 | Acc: 52.135,82.981,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.373 | Acc: 48.438,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 46.726,65.104,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.532 | Acc: 46.780,64.882,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.557 | Acc: 46.965,64.485,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.360 | Acc: 47.656,85.938,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.475 | Acc: 50.930,82.812,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.471 | Acc: 51.639,83.003,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.469 | Acc: 51.742,82.941,96.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.464 | Acc: 51.678,82.851,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.453 | Acc: 52.034,82.805,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.458 | Acc: 52.040,82.825,96.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.452 | Acc: 52.349,82.923,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.444 | Acc: 52.504,83.118,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.444 | Acc: 52.452,83.162,96.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.448 | Acc: 52.363,83.022,96.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.442 | Acc: 52.457,83.028,96.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.445 | Acc: 52.289,82.958,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.447 | Acc: 52.215,82.944,96.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.440 | Acc: 52.302,82.999,96.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.441 | Acc: 52.230,82.979,96.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.440 | Acc: 52.215,83.058,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.441 | Acc: 52.199,83.071,96.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.438 | Acc: 52.127,83.157,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.437 | Acc: 52.172,83.104,96.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 48.438,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 46.540,65.141,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.546 | Acc: 46.646,64.825,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 46.977,64.575,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.248 | Acc: 54.688,81.250,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.444 | Acc: 53.199,82.515,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.436 | Acc: 52.210,82.622,97.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.451 | Acc: 51.793,82.659,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.445 | Acc: 51.707,82.986,96.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.445 | Acc: 52.058,82.983,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.438 | Acc: 52.105,83.116,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.451 | Acc: 51.950,82.763,96.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.449 | Acc: 52.048,82.769,96.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.445 | Acc: 52.240,82.830,96.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.448 | Acc: 52.087,82.832,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.446 | Acc: 52.026,82.851,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.445 | Acc: 52.114,82.780,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.442 | Acc: 52.173,82.753,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.439 | Acc: 52.227,82.782,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.437 | Acc: 52.217,82.802,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.437 | Acc: 52.176,82.830,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.441 | Acc: 52.236,82.762,96.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.442 | Acc: 52.201,82.795,96.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.439 | Acc: 52.260,82.866,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.439 | Acc: 46.875,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 46.243,65.476,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 46.437,64.977,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 46.849,64.575,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.364 | Acc: 47.656,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.394 | Acc: 54.278,83.371,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.428 | Acc: 53.296,82.755,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.421 | Acc: 52.882,82.928,96.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.422 | Acc: 52.720,83.102,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.416 | Acc: 52.614,83.308,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.415 | Acc: 52.608,83.200,96.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.416 | Acc: 52.804,83.339,96.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.429 | Acc: 52.504,83.181,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.425 | Acc: 52.443,83.192,96.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.425 | Acc: 52.429,83.151,96.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.425 | Acc: 52.372,83.102,96.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.431 | Acc: 52.331,83.010,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.429 | Acc: 52.362,83.052,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.429 | Acc: 52.338,83.113,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.425 | Acc: 52.377,83.197,96.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.429 | Acc: 52.300,83.136,96.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.434 | Acc: 52.209,83.124,96.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.434 | Acc: 52.207,83.122,96.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.434 | Acc: 52.204,83.151,96.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.389 | Acc: 48.438,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 47.024,65.290,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 46.818,64.996,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 47.016,64.805,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.555 | Acc: 46.094,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.428 | Acc: 51.562,82.924,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.461 | Acc: 50.857,82.889,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.455 | Acc: 51.063,82.774,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.455 | Acc: 51.148,82.716,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.448 | Acc: 51.346,82.696,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.447 | Acc: 51.698,82.709,96.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.441 | Acc: 51.923,82.768,96.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.444 | Acc: 51.791,82.900,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.449 | Acc: 51.899,82.817,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.457 | Acc: 51.897,82.649,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.454 | Acc: 51.937,82.660,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.450 | Acc: 52.065,82.670,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.447 | Acc: 51.919,82.699,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.447 | Acc: 51.960,82.735,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.446 | Acc: 51.973,82.800,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.448 | Acc: 51.967,82.808,96.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.449 | Acc: 51.957,82.806,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.446 | Acc: 52.004,82.810,96.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.443 | Acc: 52.051,82.829,96.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.422 | Acc: 47.656,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.503 | Acc: 46.987,65.216,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 46.951,64.939,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.570 | Acc: 47.016,64.588,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.341 | Acc: 52.344,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.397 | Acc: 52.902,82.812,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.393 | Acc: 53.487,82.755,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.404 | Acc: 53.343,83.005,96.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.400 | Acc: 52.932,82.957,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.418 | Acc: 52.638,82.898,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.420 | Acc: 52.492,82.922,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.420 | Acc: 52.449,83.006,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.415 | Acc: 52.615,83.060,96.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.418 | Acc: 52.465,83.037,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.425 | Acc: 52.375,82.956,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.426 | Acc: 52.323,82.911,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.428 | Acc: 52.269,82.923,96.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.438 | Acc: 52.140,82.792,96.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.435 | Acc: 52.149,82.807,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.445 | Acc: 52.087,82.703,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.446 | Acc: 52.096,82.713,96.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.442 | Acc: 52.101,82.721,96.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.441 | Acc: 52.084,82.745,96.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.441 | Acc: 52.071,82.720,96.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.423 | Acc: 47.656,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.838,65.290,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 46.951,64.977,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 47.106,64.600,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.842 | Acc: 47.656,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.454 | Acc: 51.302,82.626,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 51.239,82.584,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.466 | Acc: 51.422,82.582,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.452 | Acc: 51.852,82.793,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.444 | Acc: 51.988,82.898,96.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.451 | Acc: 51.943,82.729,96.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.443 | Acc: 52.166,82.757,96.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.450 | Acc: 52.222,82.715,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.447 | Acc: 52.378,82.670,96.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.449 | Acc: 52.359,82.754,96.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.455 | Acc: 52.231,82.632,96.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.449 | Acc: 52.373,82.780,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.448 | Acc: 52.389,82.741,96.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.451 | Acc: 52.269,82.793,96.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.451 | Acc: 52.250,82.815,96.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.445 | Acc: 52.290,82.871,96.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.447 | Acc: 52.188,82.842,96.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.445 | Acc: 52.285,82.856,96.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.448 | Acc: 52.249,82.849,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 46.094,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 46.726,65.439,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 46.761,64.882,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 47.041,64.536,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 2.710 | Acc: 53.125,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.483 | Acc: 51.749,82.403,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.446 | Acc: 51.620,82.755,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.430 | Acc: 52.433,82.915,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.422 | Acc: 52.267,83.054,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.416 | Acc: 52.282,82.975,96.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.421 | Acc: 52.292,82.890,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.426 | Acc: 52.017,82.962,96.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.438 | Acc: 51.926,82.914,96.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.430 | Acc: 52.141,83.007,96.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.427 | Acc: 52.266,83.007,96.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.422 | Acc: 52.231,83.032,96.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.419 | Acc: 52.243,83.114,96.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.418 | Acc: 52.320,83.076,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.422 | Acc: 52.308,83.082,96.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.422 | Acc: 52.284,83.049,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.426 | Acc: 52.266,83.022,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.429 | Acc: 52.229,82.996,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.431 | Acc: 52.181,82.977,96.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.432 | Acc: 52.225,82.960,96.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.370 | Acc: 47.656,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.491 | Acc: 46.466,65.327,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.532 | Acc: 46.627,65.149,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 46.888,64.946,69.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.439 | Acc: 52.344,80.469,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 51.228,82.254,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.471 | Acc: 50.476,82.450,96.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.441 | Acc: 51.716,82.761,97.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.424 | Acc: 52.025,82.861,96.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.436 | Acc: 51.756,82.797,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.434 | Acc: 51.956,82.935,96.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.442 | Acc: 51.884,82.835,96.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.438 | Acc: 52.038,82.924,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.442 | Acc: 52.158,82.774,96.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.439 | Acc: 52.056,82.914,96.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.440 | Acc: 52.047,82.919,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.439 | Acc: 52.020,82.958,96.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.440 | Acc: 52.023,82.986,96.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.439 | Acc: 52.057,82.935,96.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.439 | Acc: 52.009,82.857,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.437 | Acc: 52.030,82.912,96.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.437 | Acc: 52.053,82.890,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.437 | Acc: 52.030,82.908,96.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.438 | Acc: 52.042,82.870,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.404 | Acc: 46.875,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.487 | Acc: 46.726,65.327,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.529 | Acc: 46.742,64.901,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.558 | Acc: 46.913,64.613,69.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.308 | Acc: 52.344,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.429 | Acc: 51.860,82.366,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.456 | Acc: 51.753,81.860,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.463 | Acc: 51.498,81.993,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.451 | Acc: 51.524,82.456,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.440 | Acc: 51.825,82.666,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.445 | Acc: 51.666,82.748,96.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.434 | Acc: 51.989,82.763,96.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.438 | Acc: 52.043,82.749,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.435 | Acc: 52.037,82.787,96.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.435 | Acc: 51.924,82.847,96.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.434 | Acc: 52.086,82.820,96.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.438 | Acc: 52.055,82.793,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.440 | Acc: 52.152,82.851,96.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.442 | Acc: 52.124,82.838,96.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.441 | Acc: 52.105,82.916,96.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.437 | Acc: 52.137,82.937,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.438 | Acc: 52.089,82.980,96.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.435 | Acc: 52.084,82.986,96.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.437 | Acc: 52.087,83.009,96.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 46.875,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 47.024,65.216,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.529 | Acc: 46.913,64.958,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.559 | Acc: 47.093,64.652,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.487 | Acc: 50.781,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.437 | Acc: 52.046,83.594,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 51.105,83.308,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.446 | Acc: 52.203,83.389,96.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.449 | Acc: 52.103,83.295,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.463 | Acc: 51.856,82.727,96.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.460 | Acc: 51.892,82.825,96.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.459 | Acc: 51.928,82.763,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.452 | Acc: 52.087,82.788,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.455 | Acc: 52.132,82.705,96.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.460 | Acc: 51.982,82.692,96.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.455 | Acc: 52.118,82.689,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.450 | Acc: 52.211,82.777,96.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.447 | Acc: 52.188,82.860,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.446 | Acc: 52.322,82.829,96.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.442 | Acc: 52.403,82.909,96.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.442 | Acc: 52.380,82.934,96.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.444 | Acc: 52.351,82.920,96.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.445 | Acc: 52.225,82.910,96.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.441 | Acc: 52.180,82.956,96.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.437 | Acc: 47.656,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.801,64.993,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 47.027,64.787,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.570 | Acc: 47.246,64.447,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.422 | Acc: 61.719,85.938,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.443 | Acc: 51.935,83.557,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.441 | Acc: 52.382,83.289,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.447 | Acc: 52.267,83.081,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.449 | Acc: 51.968,83.063,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.431 | Acc: 52.158,83.253,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.429 | Acc: 52.092,83.206,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.434 | Acc: 52.111,83.289,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.437 | Acc: 52.023,83.220,96.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.441 | Acc: 51.955,83.197,96.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.438 | Acc: 52.060,83.053,96.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.433 | Acc: 51.976,83.095,96.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.437 | Acc: 51.929,83.023,96.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.432 | Acc: 52.003,83.094,96.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.428 | Acc: 52.043,83.102,96.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.434 | Acc: 52.043,83.041,96.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.434 | Acc: 52.025,83.017,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.435 | Acc: 52.028,83.010,96.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.437 | Acc: 51.935,82.996,96.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.436 | Acc: 51.962,82.972,96.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.406 | Acc: 47.656,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.501 | Acc: 46.875,65.141,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.540 | Acc: 46.970,64.882,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.567 | Acc: 47.131,64.524,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.284 | Acc: 55.469,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.404 | Acc: 51.860,83.705,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.407 | Acc: 52.229,83.213,97.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.418 | Acc: 52.216,82.953,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.429 | Acc: 52.363,82.803,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.425 | Acc: 52.259,82.944,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.424 | Acc: 52.299,82.987,96.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.426 | Acc: 52.233,83.067,96.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.431 | Acc: 52.101,83.002,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.431 | Acc: 52.111,83.166,96.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.430 | Acc: 52.317,83.112,96.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.426 | Acc: 52.368,83.124,96.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.428 | Acc: 52.321,83.120,96.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.426 | Acc: 52.413,83.109,96.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.427 | Acc: 52.397,83.052,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.428 | Acc: 52.359,83.077,96.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.428 | Acc: 52.356,83.070,96.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.428 | Acc: 52.305,83.085,96.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.432 | Acc: 52.244,83.033,96.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.432 | Acc: 52.208,83.040,96.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.414 | Acc: 49.219,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 46.540,64.993,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 46.589,64.653,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 46.824,64.460,69.736,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.705 | Acc: 46.094,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.405 | Acc: 51.562,83.296,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.423 | Acc: 51.391,82.812,96.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.423 | Acc: 51.806,83.222,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.423 | Acc: 51.765,83.314,96.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.427 | Acc: 51.740,83.354,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.432 | Acc: 51.834,83.342,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.425 | Acc: 52.061,83.400,96.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.432 | Acc: 51.883,83.307,96.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.432 | Acc: 51.929,83.223,96.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.434 | Acc: 51.967,83.318,96.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.425 | Acc: 52.107,83.240,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.426 | Acc: 52.052,83.292,96.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.426 | Acc: 52.035,83.297,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.427 | Acc: 52.055,83.271,96.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.423 | Acc: 52.232,83.249,96.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.427 | Acc: 52.212,83.243,96.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.432 | Acc: 52.172,83.156,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.435 | Acc: 52.158,83.150,96.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.440 | Acc: 52.128,83.059,96.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.443 | Acc: 46.875,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.516 | Acc: 46.726,65.067,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.559 | Acc: 46.742,64.787,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 46.965,64.447,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.132 | Acc: 46.875,85.156,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.461 | Acc: 51.637,82.440,96.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.489 | Acc: 50.819,82.584,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 51.268,82.928,96.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.467 | Acc: 51.157,82.870,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.458 | Acc: 51.431,82.959,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.458 | Acc: 51.679,82.929,96.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.453 | Acc: 51.806,82.901,97.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.453 | Acc: 51.713,82.973,96.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.449 | Acc: 51.791,83.080,96.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.445 | Acc: 51.870,83.061,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.447 | Acc: 51.895,82.986,96.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.443 | Acc: 52.055,83.013,96.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.444 | Acc: 52.086,82.914,96.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.437 | Acc: 52.169,82.985,96.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.435 | Acc: 52.180,82.901,96.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.433 | Acc: 52.220,82.929,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.432 | Acc: 52.213,82.911,96.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.428 | Acc: 52.264,82.932,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.429 | Acc: 52.260,82.925,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.460 | Acc: 46.094,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.875,65.067,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.552 | Acc: 46.875,64.882,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 47.041,64.600,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.752 | Acc: 48.438,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.437 | Acc: 51.190,82.961,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.458 | Acc: 51.982,83.232,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 51.396,83.005,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.472 | Acc: 51.861,83.179,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.459 | Acc: 51.942,83.184,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.463 | Acc: 51.956,83.090,96.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.447 | Acc: 52.133,83.223,96.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.440 | Acc: 52.121,83.201,96.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.437 | Acc: 52.171,83.235,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.436 | Acc: 52.130,83.248,96.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.436 | Acc: 52.160,83.223,96.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.440 | Acc: 52.130,83.117,96.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.441 | Acc: 52.029,83.079,96.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.439 | Acc: 52.149,83.043,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.436 | Acc: 52.092,83.142,96.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.434 | Acc: 52.086,83.161,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.432 | Acc: 52.103,83.179,96.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.430 | Acc: 52.119,83.180,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.432 | Acc: 52.061,83.106,96.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.363 | Acc: 46.875,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 46.875,64.993,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 46.989,64.882,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 47.221,64.588,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 2.464 | Acc: 50.000,86.719,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.450 | Acc: 52.455,83.445,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.463 | Acc: 51.982,83.003,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.470 | Acc: 52.100,82.838,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.477 | Acc: 52.035,82.870,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.466 | Acc: 52.220,82.874,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.446 | Acc: 52.486,82.922,96.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.439 | Acc: 52.693,83.023,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.447 | Acc: 52.446,82.939,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.449 | Acc: 52.214,82.847,96.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.446 | Acc: 52.161,82.910,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.445 | Acc: 52.241,82.975,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.442 | Acc: 52.331,83.010,96.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.443 | Acc: 52.389,83.001,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.449 | Acc: 52.132,83.002,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.445 | Acc: 52.170,83.059,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.444 | Acc: 52.181,83.041,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.443 | Acc: 52.204,83.007,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.442 | Acc: 52.173,83.003,96.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.443 | Acc: 52.106,82.968,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.438 | Acc: 45.312,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 46.317,65.141,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 46.513,64.863,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 46.773,64.536,69.736,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.238 | Acc: 55.469,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.418 | Acc: 52.790,82.961,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.415 | Acc: 52.382,83.194,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.442 | Acc: 52.446,82.877,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.454 | Acc: 52.267,82.870,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.462 | Acc: 52.135,82.673,96.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.465 | Acc: 51.982,82.683,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.464 | Acc: 52.022,82.641,96.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.457 | Acc: 52.033,82.798,96.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.451 | Acc: 52.150,82.808,96.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.450 | Acc: 52.122,82.890,96.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.449 | Acc: 52.057,82.876,96.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.444 | Acc: 52.071,82.903,96.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.440 | Acc: 52.155,82.932,96.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.438 | Acc: 52.246,82.990,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.440 | Acc: 52.222,82.927,96.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.442 | Acc: 52.164,82.910,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.436 | Acc: 52.261,82.950,96.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.437 | Acc: 52.270,82.908,96.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.435 | Acc: 52.319,82.909,96.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.406 | Acc: 46.875,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 46.838,65.365,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.552 | Acc: 46.799,65.034,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.584 | Acc: 46.990,64.626,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.233 | Acc: 55.469,86.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 51.414,83.631,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.400 | Acc: 52.401,83.651,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.400 | Acc: 52.382,83.299,97.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.399 | Acc: 52.662,83.304,96.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.410 | Acc: 52.437,83.230,96.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.419 | Acc: 52.182,83.110,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.422 | Acc: 52.111,83.106,96.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.431 | Acc: 52.082,82.982,96.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.429 | Acc: 52.214,82.985,96.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.428 | Acc: 52.247,83.034,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.427 | Acc: 52.195,83.113,96.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.430 | Acc: 52.078,83.120,96.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.433 | Acc: 52.062,83.100,96.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.433 | Acc: 52.185,83.091,96.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.437 | Acc: 52.170,83.033,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.438 | Acc: 52.108,82.951,96.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.435 | Acc: 52.103,82.957,96.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.438 | Acc: 52.093,82.908,96.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.437 | Acc: 52.063,82.936,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.428 | Acc: 47.656,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.515 | Acc: 46.801,65.290,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.559 | Acc: 46.742,64.996,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 46.977,64.741,70.044,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.435 | Acc: 52.344,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.421 | Acc: 51.935,82.701,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.399 | Acc: 52.458,83.232,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.391 | Acc: 53.035,83.235,96.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.409 | Acc: 53.057,82.822,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.415 | Acc: 52.661,82.975,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.411 | Acc: 52.718,82.864,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.424 | Acc: 52.305,82.990,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.422 | Acc: 52.276,83.079,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.421 | Acc: 52.326,83.084,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.419 | Acc: 52.289,83.123,96.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.421 | Acc: 52.432,83.120,96.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.426 | Acc: 52.289,83.078,96.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.429 | Acc: 52.302,83.064,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.428 | Acc: 52.235,83.110,96.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.433 | Acc: 52.105,83.051,96.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.435 | Acc: 52.057,82.997,96.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.436 | Acc: 52.071,83.007,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.439 | Acc: 52.062,82.979,96.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.440 | Acc: 52.085,82.968,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.441 | Acc: 46.094,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 46.615,65.067,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 46.665,64.844,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 46.798,64.690,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.374 | Acc: 50.000,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.461 | Acc: 52.232,82.329,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.467 | Acc: 52.153,82.470,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.466 | Acc: 52.126,82.684,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.446 | Acc: 52.199,82.928,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.446 | Acc: 52.073,83.068,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.435 | Acc: 52.266,83.206,96.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.428 | Acc: 52.504,83.228,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.425 | Acc: 52.441,83.230,96.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.429 | Acc: 52.326,83.257,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.432 | Acc: 52.282,83.131,96.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.434 | Acc: 52.199,83.063,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.438 | Acc: 52.276,83.020,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.438 | Acc: 52.320,82.935,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.440 | Acc: 52.213,82.899,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.437 | Acc: 52.279,82.901,96.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.436 | Acc: 52.293,82.851,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.439 | Acc: 52.275,82.888,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.442 | Acc: 52.216,82.888,96.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.443 | Acc: 52.182,82.876,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.422 | Acc: 46.875,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 46.726,64.955,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 46.665,64.901,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.558 | Acc: 46.773,64.600,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.655 | Acc: 55.469,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.485 | Acc: 51.823,83.408,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.471 | Acc: 51.067,82.908,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.453 | Acc: 51.332,83.005,96.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.443 | Acc: 51.890,83.237,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.437 | Acc: 52.112,83.284,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.439 | Acc: 52.228,83.193,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.428 | Acc: 52.416,83.311,96.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.428 | Acc: 52.290,83.283,96.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.424 | Acc: 52.383,83.279,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.423 | Acc: 52.418,83.213,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.426 | Acc: 52.277,83.180,96.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.428 | Acc: 52.295,83.130,96.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.427 | Acc: 52.212,83.127,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.429 | Acc: 52.238,83.074,96.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.428 | Acc: 52.292,83.049,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.429 | Acc: 52.353,83.029,96.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.428 | Acc: 52.280,83.007,96.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.427 | Acc: 52.231,82.990,96.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.432 | Acc: 52.159,82.938,96.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.392 | Acc: 46.875,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.511 | Acc: 46.949,65.253,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 46.932,65.015,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.570 | Acc: 47.054,64.767,69.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.176 | Acc: 59.375,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.367 | Acc: 52.939,83.445,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.395 | Acc: 52.744,83.022,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.404 | Acc: 52.293,83.030,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.414 | Acc: 51.948,83.044,96.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.415 | Acc: 52.158,83.060,96.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.429 | Acc: 52.176,82.890,96.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.435 | Acc: 52.078,82.990,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.433 | Acc: 51.970,83.016,96.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.441 | Acc: 52.046,82.964,96.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.448 | Acc: 51.897,82.863,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.451 | Acc: 51.835,82.774,96.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.450 | Acc: 51.802,82.822,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.445 | Acc: 51.916,82.938,96.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.444 | Acc: 51.955,82.899,96.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.443 | Acc: 51.965,82.862,96.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.438 | Acc: 52.057,82.951,96.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.439 | Acc: 52.083,82.847,96.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.436 | Acc: 52.041,82.893,96.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.439 | Acc: 51.921,82.915,96.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.427 | Acc: 46.875,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 47.061,65.216,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.547 | Acc: 46.761,64.977,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 46.990,64.703,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.516 | Acc: 50.781,79.688,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.431 | Acc: 51.525,82.738,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.422 | Acc: 52.115,82.965,96.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.426 | Acc: 52.536,82.992,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.423 | Acc: 52.160,83.169,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.428 | Acc: 52.158,83.130,96.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.417 | Acc: 52.279,83.168,96.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.426 | Acc: 52.094,82.951,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.425 | Acc: 51.985,82.997,96.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.427 | Acc: 52.029,83.007,96.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.434 | Acc: 52.052,82.929,96.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.439 | Acc: 52.146,82.823,96.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.433 | Acc: 52.188,82.939,96.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.433 | Acc: 52.215,82.968,96.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.437 | Acc: 52.135,83.035,96.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.439 | Acc: 52.061,82.979,96.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.437 | Acc: 52.120,82.937,96.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.439 | Acc: 52.140,82.845,96.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.433 | Acc: 52.223,82.888,96.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.432 | Acc: 52.198,82.913,96.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.338 | Acc: 46.875,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.513 | Acc: 46.912,65.104,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.549 | Acc: 46.723,64.806,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 46.913,64.498,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.359 | Acc: 53.906,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.516 | Acc: 50.744,81.399,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.444 | Acc: 51.905,82.298,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.416 | Acc: 52.446,82.748,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.422 | Acc: 52.604,82.687,96.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.433 | Acc: 52.235,82.789,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.439 | Acc: 52.105,82.670,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.443 | Acc: 52.017,82.707,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.434 | Acc: 52.242,82.827,96.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.433 | Acc: 52.206,82.933,96.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.431 | Acc: 52.181,82.921,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.427 | Acc: 52.185,82.911,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.429 | Acc: 52.110,82.949,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.431 | Acc: 52.038,82.908,96.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.435 | Acc: 52.063,82.871,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.435 | Acc: 52.063,82.867,96.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.436 | Acc: 52.052,82.888,96.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.434 | Acc: 52.062,82.888,96.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.436 | Acc: 52.039,82.838,96.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.437 | Acc: 52.030,82.817,96.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.416 | Acc: 46.094,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 46.577,65.551,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.546 | Acc: 46.704,65.091,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 46.862,64.690,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 2.117 | Acc: 57.812,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.434 | Acc: 52.121,81.622,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.454 | Acc: 51.886,81.841,96.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.454 | Acc: 52.177,82.287,97.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.453 | Acc: 52.247,82.272,96.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.448 | Acc: 52.104,82.356,96.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.444 | Acc: 52.215,82.612,96.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.446 | Acc: 52.288,82.663,96.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.444 | Acc: 52.315,82.817,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.441 | Acc: 52.391,82.869,96.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.440 | Acc: 52.379,82.828,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.437 | Acc: 52.429,82.897,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.438 | Acc: 52.412,82.945,96.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.435 | Acc: 52.386,83.019,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.434 | Acc: 52.419,82.979,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.428 | Acc: 52.435,83.036,96.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.426 | Acc: 52.436,83.078,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.427 | Acc: 52.412,83.087,96.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.429 | Acc: 52.443,83.005,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.433 | Acc: 52.315,82.946,96.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.373 | Acc: 46.875,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 46.577,65.104,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 46.723,64.977,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.557 | Acc: 46.990,64.600,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.223 | Acc: 53.125,82.031,96.875,% | Adaptive Acc: 89.844% | clf_exit: 0.375 0.461 0.164
Batch: 20 | Loss: 2.402 | Acc: 54.278,82.999,96.280,% | Adaptive Acc: 87.426% | clf_exit: 0.373 0.440 0.187
Batch: 40 | Loss: 2.418 | Acc: 53.716,83.003,96.875,% | Adaptive Acc: 87.652% | clf_exit: 0.364 0.450 0.186
Batch: 60 | Loss: 2.442 | Acc: 53.330,82.812,96.696,% | Adaptive Acc: 87.487% | clf_exit: 0.361 0.452 0.186
Batch: 80 | Loss: 2.449 | Acc: 52.951,82.774,96.740,% | Adaptive Acc: 87.529% | clf_exit: 0.360 0.451 0.189
Batch: 100 | Loss: 2.449 | Acc: 52.715,82.789,96.720,% | Adaptive Acc: 87.330% | clf_exit: 0.360 0.453 0.187
Batch: 120 | Loss: 2.456 | Acc: 52.260,82.754,96.791,% | Adaptive Acc: 87.145% | clf_exit: 0.357 0.458 0.185
Batch: 140 | Loss: 2.449 | Acc: 52.166,82.812,96.792,% | Adaptive Acc: 87.040% | clf_exit: 0.356 0.459 0.185
Batch: 160 | Loss: 2.448 | Acc: 52.043,82.798,96.812,% | Adaptive Acc: 86.971% | clf_exit: 0.355 0.461 0.184
Batch: 180 | Loss: 2.443 | Acc: 52.111,82.869,96.806,% | Adaptive Acc: 87.021% | clf_exit: 0.355 0.461 0.184
Batch: 200 | Loss: 2.441 | Acc: 52.161,82.921,96.824,% | Adaptive Acc: 87.034% | clf_exit: 0.355 0.463 0.182
Batch: 220 | Loss: 2.446 | Acc: 52.181,82.820,96.840,% | Adaptive Acc: 86.970% | clf_exit: 0.355 0.463 0.182
Batch: 240 | Loss: 2.444 | Acc: 52.140,82.764,96.875,% | Adaptive Acc: 86.952% | clf_exit: 0.355 0.462 0.183
Batch: 260 | Loss: 2.443 | Acc: 52.176,82.884,96.890,% | Adaptive Acc: 87.027% | clf_exit: 0.355 0.461 0.183
Batch: 280 | Loss: 2.440 | Acc: 52.263,82.932,96.850,% | Adaptive Acc: 86.969% | clf_exit: 0.357 0.461 0.182
Batch: 300 | Loss: 2.443 | Acc: 52.274,82.898,96.797,% | Adaptive Acc: 86.986% | clf_exit: 0.356 0.462 0.182
Batch: 320 | Loss: 2.442 | Acc: 52.273,82.929,96.783,% | Adaptive Acc: 87.004% | clf_exit: 0.356 0.462 0.182
Batch: 340 | Loss: 2.440 | Acc: 52.293,82.989,96.767,% | Adaptive Acc: 87.026% | clf_exit: 0.356 0.461 0.182
Batch: 360 | Loss: 2.443 | Acc: 52.316,82.910,96.754,% | Adaptive Acc: 87.015% | clf_exit: 0.355 0.462 0.182
Batch: 380 | Loss: 2.441 | Acc: 52.331,82.929,96.746,% | Adaptive Acc: 86.998% | clf_exit: 0.356 0.462 0.182
Batch: 0 | Loss: 4.405 | Acc: 46.094,69.531,71.094,% | Adaptive Acc: 63.281% | clf_exit: 0.477 0.336 0.188
Batch: 20 | Loss: 4.502 | Acc: 46.429,65.179,71.168,% | Adaptive Acc: 64.658% | clf_exit: 0.432 0.368 0.200
Batch: 40 | Loss: 4.543 | Acc: 46.818,64.920,70.408,% | Adaptive Acc: 64.082% | clf_exit: 0.430 0.362 0.208
Batch: 60 | Loss: 4.572 | Acc: 47.054,64.703,69.890,% | Adaptive Acc: 63.973% | clf_exit: 0.428 0.361 0.211
model is save as models/resnet56_2con3_att3_cifar100_adaptive0_circles5_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 8.372 | Acc: 46.094,26.562,36.719,% | Adaptive Acc: 46.094% | clf_exit: 0.477 0.055 0.469
Batch: 20 | Loss: 8.635 | Acc: 46.429,21.838,33.296,% | Adaptive Acc: 46.652% | clf_exit: 0.432 0.078 0.489
Batch: 40 | Loss: 8.692 | Acc: 46.818,20.560,33.022,% | Adaptive Acc: 46.132% | clf_exit: 0.430 0.080 0.489
Batch: 60 | Loss: 8.705 | Acc: 47.054,20.876,32.467,% | Adaptive Acc: 45.863% | clf_exit: 0.428 0.082 0.489
Batch: 0 | Loss: 6.280 | Acc: 46.094,48.438,60.938,% | Adaptive Acc: 53.125% | clf_exit: 0.477 0.094 0.430
Batch: 20 | Loss: 6.493 | Acc: 46.429,44.234,53.906,% | Adaptive Acc: 55.915% | clf_exit: 0.432 0.133 0.435
Batch: 40 | Loss: 6.550 | Acc: 46.818,43.712,53.030,% | Adaptive Acc: 55.431% | clf_exit: 0.430 0.132 0.438
Batch: 60 | Loss: 6.572 | Acc: 47.054,43.494,52.446,% | Adaptive Acc: 55.315% | clf_exit: 0.428 0.133 0.439
Batch: 0 | Loss: 5.238 | Acc: 46.094,57.812,63.281,% | Adaptive Acc: 57.031% | clf_exit: 0.477 0.180 0.344
Batch: 20 | Loss: 5.439 | Acc: 46.429,56.027,61.607,% | Adaptive Acc: 60.082% | clf_exit: 0.432 0.217 0.351
Batch: 40 | Loss: 5.495 | Acc: 46.818,55.678,60.652,% | Adaptive Acc: 59.261% | clf_exit: 0.430 0.218 0.351
Batch: 60 | Loss: 5.519 | Acc: 47.054,55.635,59.990,% | Adaptive Acc: 58.876% | clf_exit: 0.428 0.215 0.356
Batch: 0 | Loss: 4.643 | Acc: 46.094,64.844,67.188,% | Adaptive Acc: 60.938% | clf_exit: 0.477 0.273 0.250
Batch: 20 | Loss: 4.832 | Acc: 46.429,61.607,66.629,% | Adaptive Acc: 62.872% | clf_exit: 0.432 0.282 0.286
Batch: 40 | Loss: 4.880 | Acc: 46.818,61.357,66.197,% | Adaptive Acc: 62.024% | clf_exit: 0.430 0.279 0.291
Batch: 60 | Loss: 4.905 | Acc: 47.054,61.335,65.625,% | Adaptive Acc: 61.847% | clf_exit: 0.428 0.278 0.294
Batch: 0 | Loss: 4.374 | Acc: 46.094,67.188,71.875,% | Adaptive Acc: 61.719% | clf_exit: 0.477 0.328 0.195
Batch: 20 | Loss: 4.501 | Acc: 46.429,64.360,70.350,% | Adaptive Acc: 64.472% | clf_exit: 0.432 0.333 0.235
Batch: 40 | Loss: 4.542 | Acc: 46.818,64.043,69.550,% | Adaptive Acc: 63.796% | clf_exit: 0.430 0.329 0.241
Batch: 60 | Loss: 4.567 | Acc: 47.054,63.845,69.019,% | Adaptive Acc: 63.691% | clf_exit: 0.428 0.327 0.245
Batch: 0 | Loss: 4.405 | Acc: 46.094,69.531,71.094,% | Adaptive Acc: 63.281% | clf_exit: 0.477 0.336 0.188
Batch: 20 | Loss: 4.502 | Acc: 46.429,65.179,71.168,% | Adaptive Acc: 64.658% | clf_exit: 0.432 0.368 0.200
Batch: 40 | Loss: 4.543 | Acc: 46.818,64.920,70.408,% | Adaptive Acc: 64.082% | clf_exit: 0.430 0.362 0.208
Batch: 60 | Loss: 4.572 | Acc: 47.054,64.703,69.890,% | Adaptive Acc: 63.973% | clf_exit: 0.428 0.361 0.211







Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.465 |  Acc: 2.402,2.624,4.586,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 12.917 |  Acc: 3.550,3.440,6.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 12.532 |  Acc: 4.078,4.484,10.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 12.326 |  Acc: 4.480,6.040,9.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 11.872 |  Acc: 6.010,7.760,13.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 11.606 |  Acc: 7.020,8.450,14.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 11.286 |  Acc: 8.038,10.318,16.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 11.452 |  Acc: 8.730,7.730,16.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 10.712 |  Acc: 10.594,13.242,19.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 10.748 |  Acc: 11.650,11.670,18.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 10.175 |  Acc: 13.032,16.304,22.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 10.506 |  Acc: 13.440,11.220,21.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 9.695 |  Acc: 15.898,18.772,25.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 10.093 |  Acc: 14.300,17.470,22.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 9.287 |  Acc: 18.264,21.174,28.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 10.180 |  Acc: 12.430,14.750,22.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 8.934 |  Acc: 20.176,23.322,30.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 10.092 |  Acc: 16.440,16.030,25.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 8.612 |  Acc: 21.660,25.452,32.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 9.227 |  Acc: 18.000,21.270,30.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 8.326 |  Acc: 23.304,27.350,34.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 8.818 |  Acc: 20.070,24.160,31.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 8.072 |  Acc: 24.510,29.114,36.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 8.990 |  Acc: 19.500,24.100,32.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 7.849 |  Acc: 25.548,31.074,38.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 8.839 |  Acc: 20.740,24.360,32.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 7.639 |  Acc: 26.396,32.964,40.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 8.068 |  Acc: 22.480,29.410,39.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 7.463 |  Acc: 27.194,34.302,41.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 8.896 |  Acc: 19.640,27.790,36.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 7.272 |  Acc: 28.264,35.912,43.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 9.341 |  Acc: 19.450,25.200,32.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 7.081 |  Acc: 29.194,37.436,45.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 8.111 |  Acc: 22.100,30.440,39.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 6.941 |  Acc: 29.880,38.820,46.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 7.363 |  Acc: 26.320,35.010,44.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 6.813 |  Acc: 30.482,39.964,47.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 8.537 |  Acc: 24.940,27.210,38.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 6.659 |  Acc: 31.402,41.274,48.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 7.428 |  Acc: 25.770,37.030,44.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 6.557 |  Acc: 32.014,42.062,49.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 7.428 |  Acc: 28.650,35.730,43.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 6.428 |  Acc: 32.602,43.440,50.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 7.538 |  Acc: 26.530,35.610,44.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 6.332 |  Acc: 32.900,44.118,51.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 7.113 |  Acc: 27.790,39.110,46.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 6.225 |  Acc: 33.366,45.092,52.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 7.413 |  Acc: 28.020,37.780,45.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 6.153 |  Acc: 33.556,46.348,53.586,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 7.323 |  Acc: 24.110,39.260,48.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 6.058 |  Acc: 34.088,46.954,54.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 7.165 |  Acc: 27.990,38.480,47.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 6.006 |  Acc: 34.384,47.656,55.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 7.694 |  Acc: 25.170,37.600,47.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 5.938 |  Acc: 34.328,48.032,55.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 7.538 |  Acc: 24.290,37.150,47.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 5.860 |  Acc: 34.980,48.940,56.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 7.169 |  Acc: 28.050,39.800,48.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 5.814 |  Acc: 34.998,49.474,57.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 7.056 |  Acc: 25.710,41.720,51.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 5.743 |  Acc: 35.302,50.308,57.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 7.203 |  Acc: 27.740,40.370,47.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 5.667 |  Acc: 35.756,50.804,58.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 7.982 |  Acc: 24.520,36.720,45.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 5.608 |  Acc: 36.120,51.122,58.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 6.870 |  Acc: 27.900,43.710,50.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 5.574 |  Acc: 35.972,51.908,59.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 6.980 |  Acc: 27.310,41.620,50.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 5.549 |  Acc: 36.236,52.144,59.586,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 7.205 |  Acc: 27.350,40.370,48.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.494 |  Acc: 36.510,52.666,60.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 6.417 |  Acc: 30.690,45.300,53.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.448 |  Acc: 36.736,52.952,60.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 7.246 |  Acc: 26.210,41.180,50.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.406 |  Acc: 36.958,53.166,61.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 6.941 |  Acc: 28.940,43.040,51.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.370 |  Acc: 37.068,53.838,61.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 6.681 |  Acc: 29.070,43.380,53.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.318 |  Acc: 37.392,54.454,62.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 6.922 |  Acc: 27.580,43.240,50.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.312 |  Acc: 37.322,54.248,62.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 6.368 |  Acc: 31.860,48.150,54.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.273 |  Acc: 37.450,54.634,62.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 6.685 |  Acc: 29.610,44.430,53.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.237 |  Acc: 38.152,55.032,62.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 7.146 |  Acc: 24.410,42.810,53.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.218 |  Acc: 37.620,54.946,63.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 6.801 |  Acc: 27.330,44.250,52.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.178 |  Acc: 37.954,55.598,63.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 7.379 |  Acc: 27.410,42.690,50.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 5.157 |  Acc: 38.184,55.754,63.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 6.853 |  Acc: 29.670,42.720,52.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 5.137 |  Acc: 37.980,56.130,63.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 6.779 |  Acc: 29.830,44.220,53.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 5.094 |  Acc: 38.492,56.230,64.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 6.854 |  Acc: 25.580,44.610,52.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 5.074 |  Acc: 38.310,56.636,64.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 6.248 |  Acc: 28.670,49.690,56.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 5.061 |  Acc: 38.356,56.652,64.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 8.108 |  Acc: 19.960,39.920,51.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 5.010 |  Acc: 38.558,57.018,65.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 6.893 |  Acc: 28.190,44.730,51.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 5.008 |  Acc: 38.758,57.106,65.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 6.366 |  Acc: 29.640,47.620,55.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 4.992 |  Acc: 38.524,57.266,65.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 6.758 |  Acc: 27.010,45.380,54.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 4.966 |  Acc: 39.112,57.790,65.736,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 6.511 |  Acc: 29.200,47.360,55.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 4.945 |  Acc: 39.182,57.890,66.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 7.233 |  Acc: 22.700,46.230,52.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 4.911 |  Acc: 39.228,58.138,66.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 6.790 |  Acc: 28.360,42.510,53.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 4.896 |  Acc: 39.514,58.170,66.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 7.500 |  Acc: 25.120,42.800,52.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 4.888 |  Acc: 39.412,58.282,66.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.900 |  Acc: 27.060,45.410,54.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 4.888 |  Acc: 39.300,58.372,66.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 7.045 |  Acc: 25.310,44.520,54.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 4.857 |  Acc: 39.390,58.544,66.512,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 6.082 |  Acc: 32.600,49.400,57.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 4.850 |  Acc: 39.608,58.444,67.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 6.807 |  Acc: 26.230,46.530,55.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.820 |  Acc: 39.428,58.862,67.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 6.422 |  Acc: 31.150,46.610,55.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.813 |  Acc: 39.686,59.028,67.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 6.635 |  Acc: 30.270,47.830,53.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.792 |  Acc: 39.844,59.266,67.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 6.726 |  Acc: 27.640,45.770,55.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.788 |  Acc: 39.646,59.274,67.954,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 5.983 |  Acc: 34.900,49.170,57.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.780 |  Acc: 39.822,59.516,67.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 6.284 |  Acc: 31.410,48.150,55.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.720 |  Acc: 39.954,59.732,68.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 6.879 |  Acc: 27.260,45.340,55.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.717 |  Acc: 40.024,59.784,68.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 6.415 |  Acc: 30.710,49.070,55.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.725 |  Acc: 40.186,59.716,68.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 6.493 |  Acc: 32.010,45.420,54.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.722 |  Acc: 39.908,59.832,68.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 7.131 |  Acc: 25.200,42.560,55.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.714 |  Acc: 39.890,59.900,68.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 6.397 |  Acc: 28.180,48.840,57.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.692 |  Acc: 40.282,60.292,68.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 6.621 |  Acc: 29.880,47.660,54.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.668 |  Acc: 40.154,60.434,68.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 6.224 |  Acc: 29.590,48.600,57.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.669 |  Acc: 40.354,60.618,69.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.297 |  Acc: 30.260,48.670,56.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.656 |  Acc: 40.510,60.676,69.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 6.533 |  Acc: 30.100,46.530,55.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.641 |  Acc: 40.390,60.544,69.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 7.190 |  Acc: 23.430,44.280,52.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.654 |  Acc: 40.180,60.528,69.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 7.197 |  Acc: 25.660,43.210,53.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.619 |  Acc: 40.588,61.110,69.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 6.562 |  Acc: 26.950,47.670,56.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.602 |  Acc: 40.788,61.054,69.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 7.259 |  Acc: 22.240,44.500,55.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.583 |  Acc: 40.694,61.254,69.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 6.414 |  Acc: 31.270,46.260,56.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.588 |  Acc: 40.792,61.430,69.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 8.248 |  Acc: 21.490,41.100,51.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.587 |  Acc: 40.610,61.340,69.892,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.163 |  Acc: 31.670,50.230,59.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.593 |  Acc: 40.682,61.006,69.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 6.603 |  Acc: 28.700,48.790,56.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.556 |  Acc: 40.902,61.508,70.308,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 7.356 |  Acc: 22.500,44.930,53.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.566 |  Acc: 40.802,61.440,69.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 6.733 |  Acc: 25.340,48.990,56.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.539 |  Acc: 40.908,61.656,70.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 6.140 |  Acc: 31.470,49.860,57.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.539 |  Acc: 40.960,61.328,70.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 6.214 |  Acc: 31.650,49.020,58.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.559 |  Acc: 40.918,61.660,70.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 6.329 |  Acc: 29.290,50.270,56.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.537 |  Acc: 40.912,61.890,70.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 6.782 |  Acc: 25.770,48.320,56.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.510 |  Acc: 40.754,61.652,70.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 6.844 |  Acc: 28.810,46.530,55.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.507 |  Acc: 40.698,61.572,70.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 6.278 |  Acc: 32.580,50.070,58.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.503 |  Acc: 41.108,62.120,70.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 6.937 |  Acc: 24.020,46.740,57.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.500 |  Acc: 40.952,61.784,70.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 6.672 |  Acc: 29.000,46.630,54.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.483 |  Acc: 40.796,62.332,71.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 7.468 |  Acc: 22.070,44.040,54.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.471 |  Acc: 41.174,62.226,71.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 6.282 |  Acc: 31.740,48.940,56.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.481 |  Acc: 41.186,62.078,71.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 7.017 |  Acc: 27.710,46.570,53.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.463 |  Acc: 41.268,62.358,71.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 6.719 |  Acc: 28.950,47.080,56.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.457 |  Acc: 41.174,62.504,71.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 6.559 |  Acc: 29.860,48.410,57.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.456 |  Acc: 41.380,62.572,71.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 6.564 |  Acc: 29.840,47.280,56.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.442 |  Acc: 41.094,62.532,71.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 6.255 |  Acc: 32.380,49.170,57.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.425 |  Acc: 41.470,62.696,71.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 5.985 |  Acc: 33.080,50.760,58.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.439 |  Acc: 41.124,62.640,71.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 7.548 |  Acc: 26.480,41.720,55.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.419 |  Acc: 41.692,62.578,71.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.993 |  Acc: 25.210,47.730,59.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.438 |  Acc: 41.128,62.596,71.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 8.851 |  Acc: 18.760,40.450,50.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.403 |  Acc: 41.564,63.010,71.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 6.562 |  Acc: 30.120,47.750,56.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.401 |  Acc: 41.474,63.046,71.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 5.649 |  Acc: 37.040,51.920,59.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.419 |  Acc: 41.498,62.806,71.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 6.285 |  Acc: 32.930,48.650,56.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.402 |  Acc: 41.338,62.882,71.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 8.145 |  Acc: 22.880,45.380,53.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.400 |  Acc: 41.458,62.932,71.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 6.328 |  Acc: 28.810,48.770,58.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.381 |  Acc: 41.694,63.200,72.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 6.304 |  Acc: 30.250,48.520,58.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.367 |  Acc: 41.832,63.072,72.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 6.547 |  Acc: 29.620,48.530,56.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.377 |  Acc: 41.698,63.350,72.192,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 6.436 |  Acc: 29.590,49.850,56.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.365 |  Acc: 41.990,63.362,72.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 7.174 |  Acc: 24.910,45.760,55.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.364 |  Acc: 41.700,63.104,72.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 6.968 |  Acc: 29.320,42.510,54.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.369 |  Acc: 41.620,63.106,71.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 6.906 |  Acc: 27.600,47.350,55.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.354 |  Acc: 41.554,63.252,72.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.195 |  Acc: 33.580,49.000,58.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.361 |  Acc: 41.580,63.294,72.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 6.852 |  Acc: 29.760,45.620,55.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.347 |  Acc: 41.808,63.470,72.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 6.395 |  Acc: 29.530,48.580,59.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.335 |  Acc: 42.008,63.386,72.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 7.362 |  Acc: 24.810,45.630,53.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.348 |  Acc: 41.878,63.216,72.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 7.624 |  Acc: 24.840,46.690,55.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.343 |  Acc: 41.946,63.570,72.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 7.080 |  Acc: 24.760,48.020,56.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.342 |  Acc: 41.534,63.406,72.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 7.299 |  Acc: 26.820,44.380,54.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.328 |  Acc: 41.842,63.584,72.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 7.145 |  Acc: 25.370,44.550,55.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.336 |  Acc: 41.900,63.442,72.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 5.893 |  Acc: 35.780,50.480,58.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.328 |  Acc: 41.840,63.626,72.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 6.411 |  Acc: 29.740,49.130,57.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.334 |  Acc: 41.826,63.574,72.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 8.011 |  Acc: 20.100,41.450,53.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.332 |  Acc: 41.726,63.644,72.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 7.346 |  Acc: 25.570,41.430,54.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.328 |  Acc: 42.048,63.598,72.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 6.713 |  Acc: 30.660,49.100,55.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.291 |  Acc: 41.944,64.032,73.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 6.686 |  Acc: 31.420,47.360,55.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.317 |  Acc: 41.914,63.778,72.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 6.221 |  Acc: 30.660,53.500,59.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.294 |  Acc: 42.022,63.808,73.190,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 6.466 |  Acc: 32.070,47.210,54.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.290 |  Acc: 42.210,64.038,73.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 6.343 |  Acc: 29.860,49.670,57.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.281 |  Acc: 42.028,64.182,73.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 6.322 |  Acc: 29.860,50.690,57.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.289 |  Acc: 42.086,64.054,73.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 6.317 |  Acc: 27.200,53.000,59.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.272 |  Acc: 42.096,64.222,73.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 7.756 |  Acc: 24.180,44.000,54.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.273 |  Acc: 42.176,64.126,73.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 6.182 |  Acc: 32.080,49.290,58.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.289 |  Acc: 41.846,63.698,73.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 6.148 |  Acc: 31.750,50.780,59.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.276 |  Acc: 41.996,64.010,73.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 7.566 |  Acc: 24.040,44.490,53.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.267 |  Acc: 42.116,64.156,73.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 7.242 |  Acc: 26.390,46.380,54.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.283 |  Acc: 41.996,64.030,73.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 6.185 |  Acc: 33.290,49.750,57.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.258 |  Acc: 42.302,64.244,73.586,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 7.311 |  Acc: 24.640,45.270,57.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.258 |  Acc: 42.332,64.320,73.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 5.933 |  Acc: 32.180,52.960,60.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.250 |  Acc: 42.710,64.142,73.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 7.402 |  Acc: 28.070,44.250,52.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.263 |  Acc: 42.304,63.926,73.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 6.103 |  Acc: 32.010,52.580,59.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.241 |  Acc: 42.408,64.174,73.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 6.819 |  Acc: 25.330,48.340,57.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.237 |  Acc: 42.710,64.318,73.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 8.420 |  Acc: 18.190,42.220,55.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.251 |  Acc: 42.252,64.342,73.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 5.795 |  Acc: 34.060,53.930,59.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.235 |  Acc: 42.292,64.336,73.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 6.294 |  Acc: 31.590,50.110,56.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.236 |  Acc: 42.204,64.542,73.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 6.911 |  Acc: 23.040,51.390,59.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.244 |  Acc: 42.236,64.426,73.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 7.797 |  Acc: 23.050,43.790,53.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.544 |  Acc: 46.936,71.908,81.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.333 |  Acc: 44.480,63.960,70.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.369 |  Acc: 47.744,73.332,84.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.359 |  Acc: 44.170,64.250,70.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.296 |  Acc: 48.122,74.000,85.250,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.323 |  Acc: 45.110,64.580,70.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.257 |  Acc: 48.212,74.410,85.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.307 |  Acc: 44.860,64.710,71.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.217 |  Acc: 48.540,74.744,86.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.320 |  Acc: 45.100,64.410,70.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.185 |  Acc: 48.686,74.952,87.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.350 |  Acc: 44.780,64.150,70.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.159 |  Acc: 48.746,75.182,87.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.348 |  Acc: 44.290,64.240,70.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.142 |  Acc: 48.684,75.364,87.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.352 |  Acc: 44.730,64.330,70.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.121 |  Acc: 49.030,75.448,87.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.365 |  Acc: 45.250,64.310,70.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.104 |  Acc: 48.954,75.322,88.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.353 |  Acc: 44.930,64.410,70.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.089 |  Acc: 49.086,75.708,88.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.336 |  Acc: 45.550,64.410,70.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.064 |  Acc: 48.964,76.000,88.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.377 |  Acc: 44.780,64.410,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.054 |  Acc: 48.998,75.904,88.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.427 |  Acc: 44.520,64.360,70.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.044 |  Acc: 49.082,76.192,88.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.471 |  Acc: 44.620,63.950,70.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.026 |  Acc: 49.308,76.198,89.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.379 |  Acc: 45.040,64.480,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.022 |  Acc: 49.264,76.136,89.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.440 |  Acc: 44.610,64.510,70.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.005 |  Acc: 49.254,76.370,89.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.445 |  Acc: 45.360,64.450,70.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 2.994 |  Acc: 49.368,76.348,89.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.439 |  Acc: 45.080,64.310,70.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 2.970 |  Acc: 49.530,76.746,89.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.450 |  Acc: 45.310,64.340,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 2.970 |  Acc: 49.384,76.646,90.090,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.442 |  Acc: 44.990,64.060,70.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 2.963 |  Acc: 49.494,76.498,90.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.445 |  Acc: 45.330,64.750,70.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 2.949 |  Acc: 49.630,76.882,90.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.438 |  Acc: 45.300,64.440,69.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 2.944 |  Acc: 49.554,76.816,90.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.452 |  Acc: 45.270,63.940,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 2.932 |  Acc: 49.510,77.012,90.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.525 |  Acc: 44.630,63.490,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 2.937 |  Acc: 49.638,77.116,90.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.448 |  Acc: 45.560,64.290,70.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 2.916 |  Acc: 49.352,77.302,90.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.501 |  Acc: 45.200,63.920,70.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.908 |  Acc: 49.504,77.186,90.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.528 |  Acc: 44.890,64.020,69.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.913 |  Acc: 49.554,77.198,90.778,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.444 |  Acc: 45.700,64.520,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.901 |  Acc: 49.538,77.174,90.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.524 |  Acc: 45.860,63.920,69.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.890 |  Acc: 49.614,77.290,91.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.490 |  Acc: 45.080,63.720,70.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.891 |  Acc: 49.744,77.442,91.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.529 |  Acc: 45.280,64.240,70.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.886 |  Acc: 49.622,77.418,91.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.601 |  Acc: 44.260,63.490,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.877 |  Acc: 49.728,77.596,91.432,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.549 |  Acc: 45.230,64.020,69.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.872 |  Acc: 49.418,77.614,91.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.526 |  Acc: 45.430,64.120,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.850 |  Acc: 50.084,77.666,91.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.523 |  Acc: 45.300,64.130,69.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.867 |  Acc: 49.828,77.604,91.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.533 |  Acc: 45.780,63.620,69.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.852 |  Acc: 49.958,77.938,91.636,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.599 |  Acc: 44.570,64.120,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.853 |  Acc: 49.452,77.660,91.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.555 |  Acc: 45.330,63.950,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.845 |  Acc: 49.790,77.646,91.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.563 |  Acc: 45.510,63.830,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.839 |  Acc: 49.694,77.938,91.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.583 |  Acc: 45.780,63.670,69.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.837 |  Acc: 49.688,77.918,91.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.677 |  Acc: 44.240,63.240,69.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.821 |  Acc: 49.828,78.272,91.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.581 |  Acc: 45.370,63.660,69.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.819 |  Acc: 49.844,77.932,92.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.705 |  Acc: 44.040,63.100,68.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.819 |  Acc: 50.066,78.030,91.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.616 |  Acc: 44.860,63.270,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.814 |  Acc: 50.026,77.856,92.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.642 |  Acc: 44.750,63.660,69.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.813 |  Acc: 49.840,78.024,92.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.639 |  Acc: 44.110,63.480,69.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.802 |  Acc: 50.286,78.230,92.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.604 |  Acc: 45.280,63.560,68.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.799 |  Acc: 50.280,78.348,92.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.725 |  Acc: 44.050,63.160,68.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.796 |  Acc: 50.094,78.474,92.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.667 |  Acc: 44.670,63.330,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.798 |  Acc: 50.206,78.028,92.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.680 |  Acc: 44.840,62.890,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.798 |  Acc: 49.962,78.162,92.318,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.827 |  Acc: 43.040,62.680,68.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.789 |  Acc: 50.050,78.308,92.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.870 |  Acc: 43.170,61.890,68.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.782 |  Acc: 50.130,78.366,92.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.721 |  Acc: 44.710,63.030,68.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.794 |  Acc: 49.976,78.234,92.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.562 |  Acc: 46.040,64.040,69.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.788 |  Acc: 50.312,78.406,92.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.815 |  Acc: 43.710,62.880,68.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.774 |  Acc: 50.096,78.614,92.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.669 |  Acc: 44.520,63.460,69.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.769 |  Acc: 50.160,78.508,92.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.695 |  Acc: 45.130,63.610,69.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.776 |  Acc: 50.136,78.532,92.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.930 |  Acc: 42.430,62.200,67.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.779 |  Acc: 49.930,78.452,92.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.859 |  Acc: 43.520,62.210,67.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.766 |  Acc: 50.294,78.662,92.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.660 |  Acc: 44.920,63.200,68.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.760 |  Acc: 50.008,78.712,92.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.883 |  Acc: 42.610,62.340,68.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.765 |  Acc: 50.218,78.828,92.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.725 |  Acc: 44.830,63.310,68.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.762 |  Acc: 49.930,78.464,92.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.736 |  Acc: 44.480,63.300,68.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.762 |  Acc: 49.960,78.906,92.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.833 |  Acc: 43.540,63.010,68.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.765 |  Acc: 49.910,78.612,92.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.770 |  Acc: 44.720,62.720,68.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.753 |  Acc: 50.400,78.580,92.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.706 |  Acc: 45.440,63.210,68.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.754 |  Acc: 50.102,78.762,92.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.769 |  Acc: 44.730,62.690,68.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.746 |  Acc: 50.250,78.880,93.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.868 |  Acc: 42.460,62.180,68.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.757 |  Acc: 50.182,78.754,92.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.888 |  Acc: 43.330,62.180,68.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.740 |  Acc: 50.196,78.890,92.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.804 |  Acc: 45.170,62.430,68.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.748 |  Acc: 50.536,78.602,92.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.795 |  Acc: 44.010,62.630,68.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.736 |  Acc: 50.406,79.082,92.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.908 |  Acc: 43.600,61.950,68.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.741 |  Acc: 50.118,78.930,92.954,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.765 |  Acc: 45.130,62.710,68.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.732 |  Acc: 50.566,79.134,92.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.790 |  Acc: 44.690,61.970,67.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.748 |  Acc: 50.252,78.920,92.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.773 |  Acc: 44.630,62.700,68.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.597 |  Acc: 51.212,80.716,94.746,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.488 |  Acc: 46.740,64.660,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.547 |  Acc: 51.532,81.496,95.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.490 |  Acc: 46.930,64.600,70.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.540 |  Acc: 51.456,81.576,95.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.496 |  Acc: 46.850,64.650,70.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.530 |  Acc: 51.592,81.736,95.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.489 |  Acc: 46.900,64.610,70.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.515 |  Acc: 51.854,81.728,95.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.498 |  Acc: 46.750,64.670,70.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.521 |  Acc: 51.796,81.796,95.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.499 |  Acc: 47.020,64.750,70.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.512 |  Acc: 51.752,81.928,95.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.523 |  Acc: 47.040,64.530,69.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.508 |  Acc: 51.754,82.148,95.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.521 |  Acc: 47.100,64.700,70.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.511 |  Acc: 51.574,82.054,95.912,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.506 |  Acc: 47.100,64.910,69.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.498 |  Acc: 51.674,81.940,95.988,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.525 |  Acc: 47.000,64.720,69.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.496 |  Acc: 51.874,82.088,96.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.534 |  Acc: 47.090,64.590,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.511 |  Acc: 51.728,82.110,96.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.539 |  Acc: 46.800,64.550,69.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.498 |  Acc: 51.668,82.050,96.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.550 |  Acc: 46.830,64.620,70.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.490 |  Acc: 52.096,82.360,95.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.529 |  Acc: 47.220,64.720,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.488 |  Acc: 51.926,82.346,96.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.519 |  Acc: 47.080,64.770,70.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.489 |  Acc: 51.696,82.208,96.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.528 |  Acc: 47.320,64.710,69.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.474 |  Acc: 51.804,82.412,96.346,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.538 |  Acc: 46.970,64.530,69.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.490 |  Acc: 51.736,82.328,96.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.545 |  Acc: 47.180,64.640,69.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.489 |  Acc: 51.664,82.216,96.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.551 |  Acc: 47.010,64.630,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.492 |  Acc: 51.598,82.200,96.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.532 |  Acc: 47.100,64.710,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.485 |  Acc: 51.782,82.420,96.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.550 |  Acc: 47.100,64.780,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.487 |  Acc: 51.610,82.222,96.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.540 |  Acc: 47.190,64.570,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.481 |  Acc: 51.882,82.312,96.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.571 |  Acc: 47.060,64.230,69.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.473 |  Acc: 51.928,82.356,96.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.559 |  Acc: 46.960,64.680,69.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.473 |  Acc: 51.718,82.340,96.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.567 |  Acc: 47.160,64.560,69.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.472 |  Acc: 51.646,82.522,96.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.549 |  Acc: 47.000,64.750,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.468 |  Acc: 52.050,82.594,96.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.575 |  Acc: 47.050,64.720,69.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.471 |  Acc: 51.720,82.344,96.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.560 |  Acc: 47.110,64.650,69.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.473 |  Acc: 51.948,82.390,96.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.546 |  Acc: 47.130,64.680,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.470 |  Acc: 51.922,82.562,96.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.563 |  Acc: 47.030,64.580,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.466 |  Acc: 51.796,82.462,96.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.577 |  Acc: 46.950,64.430,69.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.462 |  Acc: 51.894,82.790,96.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.565 |  Acc: 47.210,64.670,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.457 |  Acc: 52.124,82.650,96.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.566 |  Acc: 46.960,64.740,69.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.464 |  Acc: 51.870,82.566,96.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.590 |  Acc: 46.970,64.710,69.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.462 |  Acc: 51.904,82.592,96.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.570 |  Acc: 46.920,64.410,69.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.457 |  Acc: 52.072,82.630,96.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.592 |  Acc: 47.150,64.610,69.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.460 |  Acc: 51.870,82.510,96.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.576 |  Acc: 47.110,64.490,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.446 |  Acc: 51.996,82.834,96.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.569 |  Acc: 46.980,64.720,69.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.443 |  Acc: 52.060,82.914,96.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.562 |  Acc: 47.120,64.830,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.448 |  Acc: 51.898,83.010,96.536,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.555 |  Acc: 47.200,64.940,70.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.442 |  Acc: 51.962,82.886,96.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.566 |  Acc: 47.220,64.640,69.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.440 |  Acc: 51.984,83.098,96.662,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.570 |  Acc: 46.980,64.820,69.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.448 |  Acc: 52.130,82.840,96.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.562 |  Acc: 47.000,64.850,69.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.445 |  Acc: 51.884,82.860,96.596,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.558 |  Acc: 47.270,64.780,70.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.437 |  Acc: 52.182,82.934,96.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.577 |  Acc: 47.050,64.560,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.440 |  Acc: 51.912,82.796,96.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.564 |  Acc: 47.220,64.740,70.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.435 |  Acc: 52.080,82.964,96.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.567 |  Acc: 47.020,64.870,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.437 |  Acc: 52.088,83.176,96.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.577 |  Acc: 47.030,64.760,69.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.444 |  Acc: 52.162,82.980,96.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.555 |  Acc: 47.200,64.600,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.438 |  Acc: 52.188,83.120,96.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.571 |  Acc: 47.100,64.680,69.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.440 |  Acc: 52.218,82.836,96.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.573 |  Acc: 47.000,64.660,69.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.437 |  Acc: 52.146,83.100,96.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.567 |  Acc: 47.230,64.890,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.442 |  Acc: 52.064,82.842,96.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.572 |  Acc: 47.140,64.620,69.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.444 |  Acc: 52.026,82.710,96.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.569 |  Acc: 47.210,64.620,69.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.451 |  Acc: 52.246,82.840,96.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.576 |  Acc: 47.160,64.650,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.433 |  Acc: 52.184,82.932,96.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.560 |  Acc: 47.090,64.930,69.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.437 |  Acc: 52.100,82.862,96.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.557 |  Acc: 47.090,64.660,69.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.437 |  Acc: 52.062,83.032,96.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.558 |  Acc: 47.160,64.690,70.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.438 |  Acc: 52.226,83.000,96.774,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.570 |  Acc: 47.280,64.490,69.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.440 |  Acc: 51.942,82.924,96.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.569 |  Acc: 47.290,64.590,69.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.430 |  Acc: 52.206,83.080,96.950,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.567 |  Acc: 47.020,64.590,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.438 |  Acc: 52.138,83.066,96.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.583 |  Acc: 47.030,64.540,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.430 |  Acc: 52.270,82.932,96.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.576 |  Acc: 47.200,64.700,69.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.430 |  Acc: 52.120,83.114,96.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.560 |  Acc: 47.380,64.670,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.442 |  Acc: 52.120,83.014,96.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.580 |  Acc: 46.880,64.600,69.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.436 |  Acc: 52.310,82.900,96.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.584 |  Acc: 47.150,64.650,69.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.437 |  Acc: 52.062,82.962,96.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.593 |  Acc: 47.150,64.720,69.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.436 |  Acc: 52.142,83.024,96.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.567 |  Acc: 46.940,64.700,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.444 |  Acc: 52.154,82.866,96.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.555 |  Acc: 46.930,64.700,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.433 |  Acc: 52.134,82.948,96.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.568 |  Acc: 47.300,64.750,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.442 |  Acc: 51.908,82.916,96.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.573 |  Acc: 47.140,64.760,69.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.435 |  Acc: 52.156,82.936,96.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.578 |  Acc: 47.100,64.690,69.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.440 |  Acc: 51.980,82.816,96.778,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.575 |  Acc: 47.030,64.780,69.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.433 |  Acc: 52.272,82.958,96.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.556 |  Acc: 47.210,64.730,69.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.443 |  Acc: 52.326,82.912,96.740,% | Adaptive Acc:87.030% | clf_exit: 0.356 0.462 0.182
Testing: Epoch=299 | Loss: 4.570 |  Acc: 47.230,64.710,69.920,% | Adaptive Acc:63.940% | clf_exit: 0.428 0.363 0.209

circles: 0
Testing: Epoch=299 | Loss: 8.679 |  Acc: 47.230,21.310,33.110,% | Adaptive Acc:46.140% | clf_exit: 0.428 0.084 0.488
circles: 1
Testing: Epoch=299 | Loss: 6.549 |  Acc: 47.230,44.000,52.770,% | Adaptive Acc:55.580% | clf_exit: 0.428 0.135 0.438
circles: 2
Testing: Epoch=299 | Loss: 5.503 |  Acc: 47.230,56.080,60.330,% | Adaptive Acc:59.230% | clf_exit: 0.428 0.221 0.352
circles: 3
Testing: Epoch=299 | Loss: 4.898 |  Acc: 47.230,61.650,65.810,% | Adaptive Acc:62.070% | clf_exit: 0.428 0.285 0.287
circles: 4
Testing: Epoch=299 | Loss: 4.564 |  Acc: 47.230,64.130,69.190,% | Adaptive Acc:63.790% | clf_exit: 0.428 0.332 0.240
circles: 5
Testing: Epoch=299 | Loss: 4.570 |  Acc: 47.230,64.710,69.920,% | Adaptive Acc:63.940% | clf_exit: 0.428 0.363 0.209
