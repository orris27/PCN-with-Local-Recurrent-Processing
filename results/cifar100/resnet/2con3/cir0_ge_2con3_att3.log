==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
******************************
IMPORTANT: attention 2 is default to yes!!!!!!
******************************
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=16, out_features=16, bias=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (BN1d): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=48, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (attention_1): ScanLayer(
        (conv): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention_2): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=16, out_features=4, bias=True)
          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=4, out_features=16, bias=True)
          (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=96, out_features=100, bias=True)
      (attention): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=32, out_features=8, bias=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=8, out_features=32, bias=True)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.279 | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.734 | Acc: 0.893,0.930,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.442 | Acc: 0.991,1.277,1.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.269 | Acc: 1.204,1.562,1.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.157 | Acc: 1.331,1.640,2.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.061 | Acc: 1.369,1.887,2.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.986 | Acc: 1.446,2.021,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.919 | Acc: 1.468,2.067,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.866 | Acc: 1.524,2.193,3.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.817 | Acc: 1.606,2.314,3.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.766 | Acc: 1.632,2.460,3.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.719 | Acc: 1.722,2.517,3.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.673 | Acc: 1.786,2.606,3.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.625 | Acc: 1.862,2.733,4.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.577 | Acc: 1.938,2.847,4.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.534 | Acc: 1.991,2.904,4.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.489 | Acc: 2.020,3.033,4.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.448 | Acc: 2.048,3.152,5.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.406 | Acc: 2.084,3.307,5.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.364 | Acc: 2.151,3.504,5.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.360 | Acc: 2.344,8.594,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.556 | Acc: 3.683,6.473,10.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.549 | Acc: 3.373,6.745,10.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.563 | Acc: 3.496,6.570,10.540,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 12.205 | Acc: 4.688,9.375,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.420 | Acc: 4.464,7.180,12.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.449 | Acc: 4.192,6.764,11.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.435 | Acc: 4.175,6.634,11.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.420 | Acc: 4.070,6.790,11.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.407 | Acc: 4.053,7.093,11.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.380 | Acc: 4.165,7.406,11.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.352 | Acc: 4.355,7.552,12.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.326 | Acc: 4.474,7.657,12.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.301 | Acc: 4.562,7.899,12.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.278 | Acc: 4.614,8.046,12.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.256 | Acc: 4.659,8.230,12.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.243 | Acc: 4.733,8.296,12.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.218 | Acc: 4.732,8.435,12.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.202 | Acc: 4.754,8.488,13.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.180 | Acc: 4.778,8.560,13.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.165 | Acc: 4.731,8.638,13.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.144 | Acc: 4.784,8.766,13.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.128 | Acc: 4.800,8.845,13.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.110 | Acc: 4.849,8.918,13.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.502 | Acc: 6.250,8.594,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.886 | Acc: 4.315,9.487,15.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.835 | Acc: 4.325,9.394,16.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.840 | Acc: 4.419,9.068,15.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 11.833 | Acc: 7.812,9.375,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.697 | Acc: 5.655,10.975,15.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.683 | Acc: 5.545,11.585,16.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.677 | Acc: 5.418,11.104,16.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.649 | Acc: 5.633,11.294,16.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.622 | Acc: 5.817,11.471,16.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.591 | Acc: 5.927,11.596,17.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.575 | Acc: 5.884,11.658,17.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.542 | Acc: 5.983,11.845,17.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.520 | Acc: 6.030,11.900,17.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.501 | Acc: 6.153,12.045,17.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.485 | Acc: 6.169,12.171,17.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.468 | Acc: 6.247,12.361,17.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.456 | Acc: 6.340,12.458,17.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.448 | Acc: 6.367,12.369,17.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.440 | Acc: 6.359,12.417,17.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.433 | Acc: 6.340,12.468,17.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.419 | Acc: 6.383,12.498,18.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.405 | Acc: 6.436,12.513,18.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.392 | Acc: 6.400,12.605,18.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.908 | Acc: 7.812,14.844,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.202 | Acc: 6.882,13.058,19.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.155 | Acc: 7.069,13.472,20.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.169 | Acc: 6.865,13.192,19.736,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 10.950 | Acc: 9.375,12.500,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.044 | Acc: 7.106,14.583,20.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.968 | Acc: 7.622,14.748,21.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.960 | Acc: 7.480,14.664,21.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.960 | Acc: 7.504,14.487,21.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.954 | Acc: 7.457,14.766,21.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.945 | Acc: 7.503,14.941,21.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.927 | Acc: 7.596,14.955,21.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.925 | Acc: 7.531,14.902,21.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.913 | Acc: 7.562,15.073,21.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.907 | Acc: 7.665,15.127,21.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.905 | Acc: 7.710,15.250,21.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.884 | Acc: 7.819,15.547,21.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.868 | Acc: 7.827,15.748,21.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.854 | Acc: 7.818,15.808,21.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.835 | Acc: 7.872,15.877,21.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.816 | Acc: 7.988,16.005,21.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.790 | Acc: 8.055,16.166,22.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.779 | Acc: 8.077,16.168,22.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.766 | Acc: 8.110,16.257,22.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.269 | Acc: 10.938,15.625,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.397 | Acc: 9.933,17.448,25.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.375 | Acc: 9.337,17.835,25.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.378 | Acc: 9.209,17.713,24.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 10.058 | Acc: 10.156,20.312,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.307 | Acc: 8.705,18.341,24.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.358 | Acc: 9.204,18.255,23.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.380 | Acc: 8.952,17.700,23.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.369 | Acc: 9.028,17.940,23.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.365 | Acc: 9.135,18.108,23.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.356 | Acc: 9.304,18.350,24.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.356 | Acc: 9.264,18.290,24.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.349 | Acc: 9.254,18.459,24.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.340 | Acc: 9.349,18.405,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.323 | Acc: 9.476,18.528,24.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.306 | Acc: 9.619,18.534,24.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.285 | Acc: 9.774,18.662,24.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.278 | Acc: 9.812,18.762,24.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.261 | Acc: 9.859,18.875,24.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.240 | Acc: 10.026,18.958,24.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.229 | Acc: 10.078,19.040,24.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.213 | Acc: 10.131,19.144,24.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.207 | Acc: 10.180,19.168,24.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.196 | Acc: 10.199,19.203,25.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.672 | Acc: 10.156,23.438,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.927 | Acc: 11.012,20.350,27.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.921 | Acc: 10.918,20.027,27.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.919 | Acc: 10.745,19.877,27.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 9.929 | Acc: 10.938,21.875,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.856 | Acc: 10.640,21.131,28.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.849 | Acc: 11.319,20.884,27.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.867 | Acc: 11.142,20.748,27.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.837 | Acc: 11.507,20.968,27.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.826 | Acc: 11.873,21.109,27.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.785 | Acc: 12.074,21.488,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.784 | Acc: 12.090,21.504,28.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.793 | Acc: 12.029,21.564,28.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.777 | Acc: 12.120,21.664,28.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.767 | Acc: 12.216,21.650,28.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.751 | Acc: 12.337,21.762,28.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.738 | Acc: 12.322,21.898,28.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.743 | Acc: 12.276,21.911,28.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.724 | Acc: 12.344,21.981,28.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.706 | Acc: 12.484,22.176,28.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.700 | Acc: 12.524,22.162,28.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.689 | Acc: 12.548,22.274,28.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.675 | Acc: 12.636,22.375,28.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.659 | Acc: 12.734,22.412,28.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.687 | Acc: 7.812,25.000,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.826 | Acc: 12.277,20.238,27.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.773 | Acc: 12.443,21.056,28.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.786 | Acc: 12.564,21.055,27.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 10.266 | Acc: 12.500,16.406,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.274 | Acc: 14.397,24.293,31.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.276 | Acc: 14.444,24.447,31.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.314 | Acc: 13.960,23.591,31.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.326 | Acc: 14.188,23.765,31.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.326 | Acc: 14.225,23.847,31.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.327 | Acc: 14.121,23.864,31.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.350 | Acc: 13.935,23.687,30.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.337 | Acc: 14.067,23.952,31.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.321 | Acc: 14.222,24.050,31.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.312 | Acc: 14.292,24.164,31.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.281 | Acc: 14.437,24.304,31.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.268 | Acc: 14.623,24.381,31.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.254 | Acc: 14.808,24.446,31.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.240 | Acc: 14.908,24.547,31.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.229 | Acc: 15.057,24.735,31.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.229 | Acc: 15.063,24.708,31.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.225 | Acc: 15.089,24.663,31.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.215 | Acc: 15.145,24.673,31.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.203 | Acc: 15.223,24.750,31.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.927 | Acc: 15.625,29.688,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.980 | Acc: 16.518,25.521,33.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.986 | Acc: 17.054,25.095,33.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.002 | Acc: 17.098,24.987,32.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 9.142 | Acc: 17.188,26.562,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.903 | Acc: 17.671,27.083,34.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.872 | Acc: 16.883,27.248,34.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.850 | Acc: 16.675,27.408,34.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.854 | Acc: 16.946,27.421,34.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.834 | Acc: 16.940,27.468,34.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.843 | Acc: 17.104,27.195,34.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.834 | Acc: 17.337,27.383,34.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.832 | Acc: 17.450,27.300,34.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.862 | Acc: 17.274,27.037,34.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.851 | Acc: 17.250,27.041,34.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.841 | Acc: 17.304,27.121,34.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.824 | Acc: 17.440,27.195,34.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.827 | Acc: 17.373,27.119,34.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.826 | Acc: 17.388,27.182,34.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.817 | Acc: 17.437,27.175,34.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.813 | Acc: 17.494,27.149,34.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.808 | Acc: 17.524,27.195,34.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.808 | Acc: 17.577,27.158,34.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.803 | Acc: 17.639,27.215,34.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.391 | Acc: 17.969,28.125,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.828 | Acc: 18.936,25.595,34.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.809 | Acc: 18.464,25.648,34.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.806 | Acc: 18.263,25.564,34.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 8.569 | Acc: 14.844,28.906,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.646 | Acc: 17.969,27.641,35.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.550 | Acc: 18.521,28.659,36.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.493 | Acc: 18.724,28.509,36.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.482 | Acc: 18.875,28.800,37.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.489 | Acc: 18.897,28.666,36.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.507 | Acc: 18.802,28.474,36.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.482 | Acc: 18.972,28.746,37.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.493 | Acc: 19.104,28.766,37.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.473 | Acc: 19.268,28.949,37.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.467 | Acc: 19.228,29.003,37.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.468 | Acc: 19.309,29.023,37.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.470 | Acc: 19.311,29.004,37.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.472 | Acc: 19.226,28.996,37.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.473 | Acc: 19.209,29.017,37.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.462 | Acc: 19.254,29.041,37.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.449 | Acc: 19.351,29.157,37.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.443 | Acc: 19.371,29.149,37.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.446 | Acc: 19.410,29.075,37.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.439 | Acc: 19.482,29.095,37.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.519 | Acc: 17.188,28.125,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.002 | Acc: 16.257,25.670,34.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.997 | Acc: 16.444,25.572,34.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.006 | Acc: 16.470,25.410,34.618,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 8.522 | Acc: 20.312,28.125,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.399 | Acc: 19.978,28.385,37.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.329 | Acc: 20.655,28.963,38.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.288 | Acc: 20.620,29.431,38.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.264 | Acc: 20.602,29.495,38.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.236 | Acc: 20.413,29.834,38.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.210 | Acc: 20.713,30.256,39.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.202 | Acc: 20.916,30.275,39.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.187 | Acc: 20.919,30.512,39.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.196 | Acc: 20.852,30.382,39.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.193 | Acc: 20.915,30.535,39.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.181 | Acc: 21.048,30.631,39.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.176 | Acc: 21.071,30.670,39.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.164 | Acc: 21.112,30.738,39.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.152 | Acc: 21.211,30.933,39.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.142 | Acc: 21.218,30.858,39.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.134 | Acc: 21.240,30.951,39.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.136 | Acc: 21.206,30.964,39.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.132 | Acc: 21.228,31.031,39.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.126 | Acc: 21.254,31.133,39.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.255 | Acc: 19.531,33.594,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.548 | Acc: 18.043,28.460,38.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.533 | Acc: 18.274,28.316,38.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.551 | Acc: 18.097,28.087,37.756,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 7.658 | Acc: 25.781,38.281,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.991 | Acc: 22.842,33.594,39.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.924 | Acc: 23.037,33.822,40.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.971 | Acc: 22.451,33.158,40.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.935 | Acc: 22.425,33.536,41.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.944 | Acc: 22.316,33.261,40.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.938 | Acc: 22.282,33.342,40.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.925 | Acc: 22.418,33.322,40.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.932 | Acc: 22.389,33.099,40.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.930 | Acc: 22.298,33.037,40.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.924 | Acc: 22.240,32.933,40.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.918 | Acc: 22.267,32.841,40.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.903 | Acc: 22.293,32.790,40.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.892 | Acc: 22.384,32.866,41.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.890 | Acc: 22.323,32.762,41.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.879 | Acc: 22.363,32.877,41.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.868 | Acc: 22.435,33.005,41.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.875 | Acc: 22.434,32.968,41.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.867 | Acc: 22.438,32.986,41.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.858 | Acc: 22.457,33.040,41.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.883 | Acc: 26.562,35.156,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.092 | Acc: 21.391,30.208,40.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.113 | Acc: 20.789,30.469,40.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.105 | Acc: 21.004,30.328,40.190,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 7.123 | Acc: 26.562,40.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.518 | Acc: 24.442,35.714,45.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.552 | Acc: 23.895,35.880,45.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.548 | Acc: 23.694,35.451,44.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.568 | Acc: 23.515,35.378,44.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.563 | Acc: 23.569,35.326,44.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.567 | Acc: 23.786,35.524,44.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.584 | Acc: 23.842,35.428,43.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.601 | Acc: 23.874,35.350,43.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.616 | Acc: 23.865,35.109,43.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.609 | Acc: 23.869,35.009,43.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.610 | Acc: 23.943,34.994,43.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.614 | Acc: 23.963,34.952,43.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.608 | Acc: 24.111,35.141,43.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.608 | Acc: 24.063,35.123,43.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.598 | Acc: 24.107,35.143,43.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.595 | Acc: 24.211,35.161,43.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.585 | Acc: 24.216,35.248,43.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.592 | Acc: 24.240,35.154,43.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.588 | Acc: 24.211,35.195,43.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.537 | Acc: 23.438,35.938,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.451 | Acc: 21.057,30.655,37.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.555 | Acc: 20.160,30.259,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.641 | Acc: 19.647,29.713,36.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 7.346 | Acc: 29.688,35.938,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.401 | Acc: 23.921,37.388,45.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.470 | Acc: 23.914,36.528,45.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.465 | Acc: 24.616,36.527,44.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.448 | Acc: 25.164,36.294,44.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.433 | Acc: 25.240,36.394,44.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.409 | Acc: 25.336,36.415,44.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.412 | Acc: 25.177,36.431,44.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.406 | Acc: 25.155,36.573,44.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.395 | Acc: 25.384,36.805,45.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.392 | Acc: 25.412,36.828,45.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.392 | Acc: 25.477,36.871,45.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.384 | Acc: 25.444,36.842,45.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.381 | Acc: 25.437,36.883,45.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.376 | Acc: 25.464,36.838,45.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.380 | Acc: 25.426,36.841,45.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.383 | Acc: 25.394,36.789,45.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.379 | Acc: 25.360,36.753,45.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.371 | Acc: 25.368,36.864,45.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.369 | Acc: 25.377,36.885,45.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.687 | Acc: 23.438,35.156,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.181 | Acc: 19.903,31.510,41.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.150 | Acc: 19.874,31.479,41.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.152 | Acc: 19.839,31.340,41.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 7.064 | Acc: 27.344,39.062,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.197 | Acc: 25.595,38.728,47.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.152 | Acc: 25.915,38.662,47.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.220 | Acc: 25.858,38.076,47.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.256 | Acc: 25.675,37.577,46.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.218 | Acc: 26.253,37.925,46.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.206 | Acc: 26.265,37.868,46.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.213 | Acc: 26.197,37.816,46.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.205 | Acc: 26.242,37.878,46.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.198 | Acc: 26.260,37.958,47.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.182 | Acc: 26.423,38.118,47.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.184 | Acc: 26.343,38.203,47.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.174 | Acc: 26.433,38.242,47.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.179 | Acc: 26.308,38.209,47.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.178 | Acc: 26.382,38.317,47.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.171 | Acc: 26.516,38.364,47.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.170 | Acc: 26.575,38.335,47.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.174 | Acc: 26.549,38.352,47.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.185 | Acc: 26.495,38.247,46.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.182 | Acc: 26.489,38.320,46.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.056 | Acc: 23.438,32.812,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.131 | Acc: 23.847,32.403,42.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.171 | Acc: 23.247,31.860,42.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.189 | Acc: 23.002,31.186,42.303,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 6.879 | Acc: 25.781,41.406,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.931 | Acc: 27.418,39.100,49.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.067 | Acc: 26.334,38.567,48.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.056 | Acc: 26.217,38.883,48.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.048 | Acc: 26.553,39.217,48.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.022 | Acc: 26.601,39.387,48.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.019 | Acc: 26.834,39.366,48.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.018 | Acc: 26.801,39.301,48.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.006 | Acc: 26.994,39.499,48.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.009 | Acc: 27.085,39.537,48.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.993 | Acc: 27.130,39.723,48.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.985 | Acc: 27.255,39.752,48.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.977 | Acc: 27.366,39.886,48.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.968 | Acc: 27.455,40.035,48.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.968 | Acc: 27.458,39.999,48.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.975 | Acc: 27.388,39.909,48.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.970 | Acc: 27.426,39.953,48.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.981 | Acc: 27.325,39.908,48.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.987 | Acc: 27.246,39.829,48.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.995 | Acc: 27.194,39.809,48.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.949 | Acc: 19.531,23.438,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.841 | Acc: 19.606,27.121,36.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.834 | Acc: 19.512,27.115,35.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.835 | Acc: 19.262,26.934,35.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 6.900 | Acc: 25.781,41.406,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.819 | Acc: 27.455,41.667,50.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.808 | Acc: 27.763,41.921,50.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.783 | Acc: 28.458,42.482,50.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.818 | Acc: 28.279,41.840,50.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.836 | Acc: 27.978,41.453,50.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.824 | Acc: 28.170,41.458,50.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.819 | Acc: 28.247,41.384,50.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.830 | Acc: 28.115,41.319,50.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.838 | Acc: 28.060,41.139,50.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.840 | Acc: 28.086,41.068,50.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.837 | Acc: 28.086,41.123,50.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.855 | Acc: 27.973,41.037,49.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.864 | Acc: 27.906,40.948,49.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.859 | Acc: 27.939,40.961,49.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.861 | Acc: 27.917,40.916,49.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.871 | Acc: 27.923,40.846,49.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.860 | Acc: 27.894,40.914,49.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.855 | Acc: 27.995,40.999,49.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.855 | Acc: 27.955,40.967,49.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.329 | Acc: 32.031,35.938,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.520 | Acc: 26.153,35.714,45.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.523 | Acc: 25.972,35.404,46.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.540 | Acc: 25.704,35.246,46.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 6.453 | Acc: 33.594,44.531,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.633 | Acc: 30.469,42.857,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.773 | Acc: 28.906,41.502,51.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.717 | Acc: 29.060,42.098,51.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.748 | Acc: 28.742,41.831,50.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.735 | Acc: 28.682,41.863,50.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.726 | Acc: 28.545,41.910,50.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.739 | Acc: 28.491,41.805,50.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.730 | Acc: 28.605,41.969,50.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.732 | Acc: 28.595,42.213,50.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.727 | Acc: 28.440,42.188,50.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.735 | Acc: 28.295,42.043,50.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.729 | Acc: 28.310,42.022,50.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.730 | Acc: 28.248,42.008,50.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.734 | Acc: 28.203,41.973,50.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.728 | Acc: 28.291,42.050,50.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.724 | Acc: 28.329,42.127,50.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.720 | Acc: 28.386,42.103,50.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.727 | Acc: 28.374,42.064,50.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.717 | Acc: 28.467,42.224,50.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.175 | Acc: 26.562,39.062,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.091 | Acc: 25.967,39.546,48.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.127 | Acc: 25.229,39.120,48.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.135 | Acc: 25.256,38.973,48.438,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 6.676 | Acc: 29.688,39.844,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.440 | Acc: 30.208,45.089,53.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.438 | Acc: 30.183,44.836,53.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.474 | Acc: 29.636,44.160,53.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.500 | Acc: 29.784,43.808,52.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.500 | Acc: 29.811,43.881,53.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.506 | Acc: 29.487,43.750,52.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.533 | Acc: 29.588,43.473,52.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.539 | Acc: 29.712,43.425,52.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.529 | Acc: 29.761,43.715,52.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.540 | Acc: 29.684,43.653,52.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.542 | Acc: 29.620,43.637,52.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.546 | Acc: 29.743,43.653,52.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.548 | Acc: 29.702,43.612,52.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.558 | Acc: 29.665,43.503,52.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.553 | Acc: 29.594,43.529,52.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.554 | Acc: 29.583,43.521,52.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.553 | Acc: 29.587,43.567,51.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.553 | Acc: 29.553,43.581,52.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.555 | Acc: 29.491,43.602,51.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.709 | Acc: 27.344,42.188,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.568 | Acc: 24.740,38.542,46.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.596 | Acc: 24.390,37.595,46.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.630 | Acc: 24.014,37.103,45.786,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 6.840 | Acc: 29.688,45.312,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.528 | Acc: 29.613,45.052,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.440 | Acc: 29.592,45.179,54.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.428 | Acc: 29.854,45.325,53.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.431 | Acc: 29.967,45.110,53.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.444 | Acc: 30.082,44.740,53.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.467 | Acc: 29.868,44.551,53.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.464 | Acc: 30.020,44.631,53.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.443 | Acc: 30.148,44.779,53.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.456 | Acc: 29.929,44.540,53.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.456 | Acc: 29.905,44.465,53.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.462 | Acc: 29.723,44.408,52.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.466 | Acc: 29.636,44.382,52.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.453 | Acc: 29.676,44.483,52.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.453 | Acc: 29.574,44.528,53.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.455 | Acc: 29.649,44.523,53.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.455 | Acc: 29.741,44.568,53.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.461 | Acc: 29.678,44.433,52.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.457 | Acc: 29.726,44.542,52.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.449 | Acc: 29.827,44.621,53.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.832 | Acc: 25.000,41.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.877 | Acc: 28.385,42.411,51.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.956 | Acc: 27.477,40.854,49.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.978 | Acc: 27.357,40.804,49.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 6.204 | Acc: 26.562,42.188,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.240 | Acc: 30.246,46.503,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.296 | Acc: 30.069,46.094,55.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.286 | Acc: 30.213,45.927,54.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.274 | Acc: 30.527,45.959,54.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.272 | Acc: 30.817,45.808,54.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.292 | Acc: 30.611,45.487,54.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.320 | Acc: 30.513,45.445,54.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.325 | Acc: 30.449,45.380,53.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.344 | Acc: 30.322,45.213,53.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.347 | Acc: 30.352,45.301,53.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.352 | Acc: 30.352,45.231,53.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.361 | Acc: 30.229,45.173,53.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.364 | Acc: 30.193,45.262,53.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.361 | Acc: 30.171,45.287,53.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.363 | Acc: 30.085,45.263,53.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.360 | Acc: 30.099,45.364,53.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.352 | Acc: 30.187,45.452,53.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.349 | Acc: 30.341,45.432,53.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.339 | Acc: 30.401,45.532,53.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.087 | Acc: 30.469,38.281,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.205 | Acc: 26.860,40.179,48.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.159 | Acc: 26.715,39.558,47.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.186 | Acc: 26.844,39.434,47.003,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 5.653 | Acc: 32.812,53.906,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.112 | Acc: 31.027,47.991,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.142 | Acc: 31.441,47.904,56.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.153 | Acc: 31.314,47.759,56.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.198 | Acc: 31.202,46.682,56.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.186 | Acc: 31.111,47.053,56.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.205 | Acc: 31.095,46.752,55.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.213 | Acc: 30.962,46.581,55.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.202 | Acc: 30.915,46.613,55.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.216 | Acc: 30.866,46.310,55.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.212 | Acc: 30.920,46.304,55.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.223 | Acc: 30.950,46.228,55.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.234 | Acc: 30.858,46.191,55.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.226 | Acc: 30.909,46.348,55.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.230 | Acc: 30.908,46.338,55.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.225 | Acc: 31.032,46.320,55.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.236 | Acc: 30.931,46.225,55.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.233 | Acc: 30.977,46.227,55.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.234 | Acc: 30.904,46.239,55.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.230 | Acc: 30.922,46.250,55.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.106 | Acc: 25.781,39.844,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.294 | Acc: 25.000,38.914,50.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.384 | Acc: 23.876,38.396,50.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.441 | Acc: 23.604,38.064,49.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 6.638 | Acc: 23.438,42.188,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.118 | Acc: 31.176,46.317,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.120 | Acc: 31.498,46.989,56.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.096 | Acc: 31.762,47.195,56.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.103 | Acc: 31.935,47.020,56.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.107 | Acc: 31.761,46.929,56.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.134 | Acc: 31.663,47.017,55.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.159 | Acc: 31.555,46.792,55.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.163 | Acc: 31.706,46.802,55.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.142 | Acc: 31.690,47.030,55.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.133 | Acc: 31.674,47.326,56.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.129 | Acc: 31.741,47.313,56.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.112 | Acc: 31.775,47.481,56.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.120 | Acc: 31.714,47.447,56.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.126 | Acc: 31.698,47.353,56.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.135 | Acc: 31.665,47.314,56.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.138 | Acc: 31.627,47.250,56.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.143 | Acc: 31.536,47.203,55.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.141 | Acc: 31.572,47.217,55.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.142 | Acc: 31.584,47.222,55.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.804 | Acc: 30.469,41.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.829 | Acc: 28.646,42.746,50.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.869 | Acc: 27.782,41.902,50.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.871 | Acc: 27.600,41.368,50.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 6.010 | Acc: 34.375,44.531,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.218 | Acc: 32.440,47.173,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.169 | Acc: 31.745,46.322,55.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.150 | Acc: 31.404,46.862,56.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.107 | Acc: 31.491,47.357,56.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.099 | Acc: 31.791,47.455,56.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.084 | Acc: 31.883,47.611,56.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.064 | Acc: 31.904,47.678,56.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.050 | Acc: 31.939,47.719,56.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.062 | Acc: 31.751,47.751,56.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.048 | Acc: 31.899,47.893,56.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.048 | Acc: 31.879,48.084,56.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.058 | Acc: 31.889,47.922,56.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.056 | Acc: 31.855,47.965,56.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.054 | Acc: 31.878,47.959,56.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.051 | Acc: 31.886,47.952,56.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.057 | Acc: 31.849,47.836,56.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.054 | Acc: 31.944,47.844,56.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.062 | Acc: 31.849,47.736,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.065 | Acc: 31.836,47.720,56.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.989 | Acc: 28.125,36.719,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.152 | Acc: 26.674,40.327,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.120 | Acc: 26.105,41.082,51.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.137 | Acc: 25.653,40.484,50.935,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 5.794 | Acc: 39.062,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.728 | Acc: 34.747,51.116,60.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.871 | Acc: 33.479,50.114,59.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.897 | Acc: 33.261,49.718,58.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.928 | Acc: 32.832,49.518,58.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.936 | Acc: 32.573,49.613,58.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.904 | Acc: 32.761,49.606,58.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.908 | Acc: 32.907,49.535,58.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.925 | Acc: 33.002,49.432,58.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.939 | Acc: 32.705,49.296,58.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.944 | Acc: 32.645,49.172,57.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.952 | Acc: 32.558,49.031,57.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.949 | Acc: 32.612,48.914,57.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.957 | Acc: 32.564,48.803,57.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.953 | Acc: 32.473,48.743,57.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.958 | Acc: 32.519,48.733,57.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.957 | Acc: 32.479,48.764,57.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.962 | Acc: 32.526,48.726,57.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.964 | Acc: 32.490,48.756,57.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.959 | Acc: 32.552,48.778,57.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.676 | Acc: 29.688,45.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.269 | Acc: 26.600,39.695,48.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.214 | Acc: 26.410,39.405,48.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.233 | Acc: 25.781,38.934,47.989,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 5.072 | Acc: 39.844,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.725 | Acc: 33.333,50.707,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.742 | Acc: 33.708,50.991,59.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.755 | Acc: 33.927,50.781,59.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.795 | Acc: 33.700,50.203,59.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.812 | Acc: 33.787,49.876,58.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.836 | Acc: 33.749,49.554,58.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.845 | Acc: 33.655,49.407,58.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.858 | Acc: 33.438,49.490,58.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.870 | Acc: 33.443,49.404,58.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.871 | Acc: 33.353,49.460,58.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.878 | Acc: 33.276,49.289,58.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.885 | Acc: 33.166,49.245,58.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.879 | Acc: 33.241,49.303,58.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.880 | Acc: 33.227,49.333,58.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.880 | Acc: 33.207,49.291,58.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.885 | Acc: 33.124,49.151,58.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.895 | Acc: 32.987,49.111,58.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.899 | Acc: 32.962,49.085,58.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.899 | Acc: 32.954,49.161,57.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.818 | Acc: 33.594,42.969,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.942 | Acc: 27.307,42.894,50.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.984 | Acc: 27.153,42.264,49.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.983 | Acc: 26.780,42.059,49.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 6.112 | Acc: 32.812,40.625,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.745 | Acc: 33.036,50.186,60.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.682 | Acc: 33.308,50.972,61.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.663 | Acc: 33.901,51.383,61.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.721 | Acc: 33.488,51.167,60.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.738 | Acc: 33.470,51.075,60.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.757 | Acc: 33.368,51.046,60.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.776 | Acc: 33.267,50.842,59.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.789 | Acc: 33.434,50.708,59.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.807 | Acc: 33.283,50.470,59.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.809 | Acc: 33.221,50.330,59.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.812 | Acc: 33.198,50.308,59.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.812 | Acc: 33.270,50.321,59.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.806 | Acc: 33.211,50.251,59.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.815 | Acc: 33.129,50.131,59.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.817 | Acc: 33.085,50.067,59.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.827 | Acc: 32.983,49.998,58.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.825 | Acc: 33.048,50.002,58.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.835 | Acc: 33.072,49.864,58.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.834 | Acc: 33.128,49.867,58.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.065 | Acc: 18.750,45.312,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.050 | Acc: 24.182,44.978,51.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.037 | Acc: 23.342,43.960,50.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.048 | Acc: 23.220,43.545,50.384,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 5.777 | Acc: 29.688,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.645 | Acc: 33.966,52.455,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.682 | Acc: 33.422,51.677,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.702 | Acc: 33.261,50.743,60.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.700 | Acc: 33.333,50.521,60.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.688 | Acc: 33.679,50.804,59.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.690 | Acc: 33.645,50.878,59.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.706 | Acc: 33.522,50.975,59.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.722 | Acc: 33.477,50.946,59.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.723 | Acc: 33.620,50.928,59.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.737 | Acc: 33.516,50.738,59.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.737 | Acc: 33.495,50.799,59.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.733 | Acc: 33.448,50.849,59.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.733 | Acc: 33.432,50.889,59.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.738 | Acc: 33.427,50.809,59.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.739 | Acc: 33.428,50.812,59.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.746 | Acc: 33.350,50.767,59.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.748 | Acc: 33.342,50.731,59.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.751 | Acc: 33.297,50.619,59.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.748 | Acc: 33.346,50.677,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.461 | Acc: 28.906,35.156,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.348 | Acc: 24.591,38.802,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.296 | Acc: 24.314,38.910,51.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.297 | Acc: 23.873,39.075,51.550,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 6.313 | Acc: 28.125,48.438,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.714 | Acc: 33.445,51.674,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.664 | Acc: 33.575,51.753,61.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.653 | Acc: 33.991,51.998,61.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.662 | Acc: 33.555,51.948,61.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.647 | Acc: 33.748,52.081,61.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.642 | Acc: 33.936,52.098,61.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.636 | Acc: 34.065,52.083,61.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.644 | Acc: 34.040,51.907,60.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.643 | Acc: 34.008,51.886,60.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.653 | Acc: 33.862,51.730,60.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.663 | Acc: 33.869,51.729,60.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.672 | Acc: 33.817,51.657,60.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.670 | Acc: 33.854,51.787,60.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.673 | Acc: 33.813,51.724,60.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.670 | Acc: 33.923,51.700,60.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.667 | Acc: 33.961,51.726,60.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.665 | Acc: 34.068,51.659,60.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.671 | Acc: 34.018,51.608,60.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.680 | Acc: 34.028,51.528,60.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.228 | Acc: 32.812,47.656,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.564 | Acc: 29.018,45.908,55.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.560 | Acc: 27.706,45.274,55.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.559 | Acc: 27.638,45.069,55.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 6.187 | Acc: 28.125,49.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.489 | Acc: 35.045,53.869,62.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.531 | Acc: 33.937,52.934,62.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.533 | Acc: 33.837,52.779,62.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.547 | Acc: 34.211,52.604,61.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.568 | Acc: 34.058,52.406,61.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.600 | Acc: 34.052,52.124,61.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.605 | Acc: 34.009,51.961,61.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.629 | Acc: 34.205,51.810,60.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.617 | Acc: 34.276,51.990,61.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.621 | Acc: 34.200,51.858,60.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.614 | Acc: 34.082,51.983,60.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.614 | Acc: 34.009,51.952,60.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.619 | Acc: 33.980,51.829,60.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.620 | Acc: 33.966,51.802,60.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.619 | Acc: 34.092,51.749,60.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.623 | Acc: 34.042,51.667,60.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.622 | Acc: 34.036,51.709,60.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.616 | Acc: 34.150,51.835,60.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.623 | Acc: 34.082,51.739,60.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.732 | Acc: 32.812,46.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.046 | Acc: 25.595,41.853,52.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.052 | Acc: 25.114,41.444,51.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.036 | Acc: 25.064,41.752,52.164,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 5.380 | Acc: 36.719,53.125,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.442 | Acc: 34.859,52.269,63.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.474 | Acc: 34.394,52.382,62.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.488 | Acc: 34.823,52.561,62.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.513 | Acc: 34.635,52.411,61.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.535 | Acc: 34.398,52.475,61.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.534 | Acc: 34.517,52.647,61.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.526 | Acc: 34.746,52.937,61.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.534 | Acc: 34.705,52.999,61.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.545 | Acc: 34.725,52.870,61.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.553 | Acc: 34.593,52.826,61.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.547 | Acc: 34.637,52.839,61.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.541 | Acc: 34.696,52.914,61.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.560 | Acc: 34.591,52.715,61.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.570 | Acc: 34.547,52.600,61.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.573 | Acc: 34.564,52.484,61.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.578 | Acc: 34.555,52.436,61.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.580 | Acc: 34.561,52.399,60.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.588 | Acc: 34.494,52.326,60.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.588 | Acc: 34.543,52.391,60.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.762 | Acc: 32.812,47.656,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.876 | Acc: 27.641,43.155,53.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.948 | Acc: 27.630,42.759,52.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.993 | Acc: 27.267,42.469,52.203,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 5.679 | Acc: 30.469,51.562,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.355 | Acc: 35.379,54.241,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.401 | Acc: 35.385,54.059,64.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.473 | Acc: 34.951,53.458,63.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.501 | Acc: 34.780,53.144,63.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.513 | Acc: 34.731,53.187,62.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.525 | Acc: 34.698,53.106,62.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.511 | Acc: 34.646,53.064,62.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.501 | Acc: 34.686,53.246,62.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.503 | Acc: 34.889,53.203,62.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.508 | Acc: 34.997,53.113,62.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.528 | Acc: 34.873,52.870,61.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.527 | Acc: 34.852,52.859,61.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.531 | Acc: 34.821,52.790,61.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.532 | Acc: 34.859,52.775,61.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.527 | Acc: 34.975,52.827,61.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.533 | Acc: 34.940,52.784,61.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.532 | Acc: 34.952,52.832,61.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.530 | Acc: 34.981,52.822,61.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.533 | Acc: 34.974,52.795,61.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.240 | Acc: 26.562,44.531,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.460 | Acc: 23.884,42.522,52.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.431 | Acc: 23.819,41.825,51.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.467 | Acc: 23.591,41.265,50.871,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 5.885 | Acc: 30.469,50.781,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.339 | Acc: 35.454,55.097,64.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.395 | Acc: 34.985,54.306,63.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.435 | Acc: 34.785,53.330,62.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.448 | Acc: 34.780,53.164,62.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.433 | Acc: 34.754,53.519,62.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.430 | Acc: 34.782,53.319,62.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.428 | Acc: 34.735,53.324,62.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.445 | Acc: 34.632,53.144,62.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.455 | Acc: 34.751,53.147,62.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.459 | Acc: 34.701,53.133,62.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.477 | Acc: 34.665,53.086,62.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.473 | Acc: 34.803,53.122,62.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.478 | Acc: 34.875,53.077,62.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.476 | Acc: 34.900,53.106,62.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.476 | Acc: 34.964,53.107,62.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.481 | Acc: 34.991,53.081,62.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.485 | Acc: 35.069,53.143,61.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.483 | Acc: 35.141,53.190,61.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.476 | Acc: 35.183,53.195,61.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.377 | Acc: 33.594,44.531,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.410 | Acc: 28.943,46.317,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.504 | Acc: 27.858,45.808,54.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.510 | Acc: 27.485,45.620,54.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 5.292 | Acc: 39.062,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.445 | Acc: 34.487,54.129,63.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.441 | Acc: 35.042,54.192,62.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.386 | Acc: 35.374,54.278,62.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.372 | Acc: 35.571,54.321,62.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.358 | Acc: 36.038,54.448,63.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.357 | Acc: 36.009,54.429,63.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.368 | Acc: 35.899,54.217,63.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.382 | Acc: 35.709,54.086,63.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.391 | Acc: 35.484,54.036,62.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.404 | Acc: 35.448,53.848,62.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.410 | Acc: 35.453,53.903,62.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.421 | Acc: 35.454,53.835,62.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.411 | Acc: 35.596,53.849,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.417 | Acc: 35.582,53.787,62.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.419 | Acc: 35.470,53.813,62.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.430 | Acc: 35.392,53.697,62.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.430 | Acc: 35.450,53.693,62.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.432 | Acc: 35.459,53.701,62.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.438 | Acc: 35.415,53.664,62.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.647 | Acc: 27.344,50.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.970 | Acc: 26.302,45.126,51.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.115 | Acc: 25.781,42.702,49.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.131 | Acc: 25.525,42.508,49.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 5.310 | Acc: 33.594,55.469,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.412 | Acc: 34.710,53.906,62.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.353 | Acc: 34.794,54.497,63.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.340 | Acc: 35.400,54.700,63.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.337 | Acc: 35.455,54.591,63.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.333 | Acc: 35.473,54.556,63.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.345 | Acc: 35.621,54.313,63.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.329 | Acc: 35.871,54.244,63.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.339 | Acc: 35.899,54.256,63.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.333 | Acc: 36.102,54.368,63.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.332 | Acc: 36.066,54.241,63.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.349 | Acc: 35.909,54.143,63.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.344 | Acc: 35.950,54.162,63.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.364 | Acc: 35.719,54.095,63.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.362 | Acc: 35.696,54.145,63.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.365 | Acc: 35.699,54.023,63.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.370 | Acc: 35.689,53.977,63.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.370 | Acc: 35.665,53.957,63.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.374 | Acc: 35.736,53.960,63.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.379 | Acc: 35.667,53.919,62.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.938 | Acc: 25.000,41.406,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.876 | Acc: 28.534,45.275,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.879 | Acc: 28.544,44.760,53.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.860 | Acc: 28.727,44.864,53.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.167 | Acc: 34.375,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.271 | Acc: 34.859,55.134,64.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.251 | Acc: 35.995,55.278,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.226 | Acc: 36.014,55.622,64.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.241 | Acc: 36.015,55.421,64.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.256 | Acc: 36.200,55.438,64.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.276 | Acc: 36.138,55.146,64.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.312 | Acc: 35.899,54.915,63.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.328 | Acc: 35.884,54.775,63.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.313 | Acc: 36.132,54.942,63.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.305 | Acc: 36.120,55.103,63.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.294 | Acc: 36.192,55.204,64.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.294 | Acc: 36.168,55.183,64.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.299 | Acc: 36.117,55.056,64.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.300 | Acc: 36.199,54.954,63.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.317 | Acc: 36.044,54.804,63.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.330 | Acc: 36.006,54.683,63.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.332 | Acc: 35.905,54.688,63.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.343 | Acc: 35.864,54.614,63.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.344 | Acc: 35.942,54.577,63.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.640 | Acc: 25.781,48.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.841 | Acc: 26.004,45.759,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.919 | Acc: 26.277,44.817,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.936 | Acc: 25.820,44.647,54.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 5.733 | Acc: 35.938,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.172 | Acc: 38.132,56.064,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.159 | Acc: 37.443,56.212,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.235 | Acc: 36.860,55.059,64.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.239 | Acc: 36.806,55.064,64.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.233 | Acc: 36.541,55.128,64.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.253 | Acc: 36.493,54.997,64.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.246 | Acc: 36.458,55.059,64.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.230 | Acc: 36.374,55.241,64.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.220 | Acc: 36.585,55.266,64.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.225 | Acc: 36.466,55.243,64.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.229 | Acc: 36.454,55.278,64.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.231 | Acc: 36.463,55.407,64.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.242 | Acc: 36.419,55.286,64.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.251 | Acc: 36.355,55.280,64.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.254 | Acc: 36.340,55.168,64.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.252 | Acc: 36.320,55.194,63.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.247 | Acc: 36.421,55.308,63.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.254 | Acc: 36.368,55.287,63.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.264 | Acc: 36.302,55.186,63.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.913 | Acc: 33.594,45.312,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.999 | Acc: 28.088,42.634,52.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.008 | Acc: 28.011,42.378,52.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.054 | Acc: 27.510,42.520,52.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 5.200 | Acc: 34.375,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.252 | Acc: 36.086,54.501,64.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.127 | Acc: 36.966,55.602,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.140 | Acc: 37.282,55.763,65.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.179 | Acc: 36.651,55.932,65.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.204 | Acc: 36.363,55.739,65.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.235 | Acc: 36.157,55.391,64.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.253 | Acc: 35.971,55.247,64.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.251 | Acc: 36.035,55.280,64.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.259 | Acc: 36.041,55.210,64.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.252 | Acc: 36.124,55.088,64.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.249 | Acc: 36.238,55.186,64.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.249 | Acc: 36.151,55.232,64.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.254 | Acc: 36.144,55.196,64.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.257 | Acc: 36.185,55.235,64.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.265 | Acc: 36.148,55.162,64.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.271 | Acc: 36.040,55.048,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.272 | Acc: 36.002,55.038,64.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.271 | Acc: 36.091,55.001,64.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.272 | Acc: 36.077,54.995,63.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.780 | Acc: 25.781,46.875,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.155 | Acc: 24.070,43.973,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.200 | Acc: 23.495,44.436,52.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.216 | Acc: 23.399,44.019,52.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 5.105 | Acc: 39.844,56.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.195 | Acc: 36.310,56.064,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.132 | Acc: 36.433,56.498,65.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.134 | Acc: 36.655,56.455,65.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.149 | Acc: 36.671,56.453,65.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.161 | Acc: 36.835,56.242,65.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.167 | Acc: 36.706,56.244,65.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.163 | Acc: 36.697,56.150,65.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.167 | Acc: 36.758,56.153,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.181 | Acc: 36.460,56.073,64.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.197 | Acc: 36.392,55.916,64.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.194 | Acc: 36.447,55.914,64.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.187 | Acc: 36.485,55.965,64.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.200 | Acc: 36.419,55.864,64.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.201 | Acc: 36.449,55.833,64.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.201 | Acc: 36.509,55.871,64.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.205 | Acc: 36.512,55.839,64.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.219 | Acc: 36.453,55.712,64.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.220 | Acc: 36.427,55.633,64.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.221 | Acc: 36.399,55.649,64.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.822 | Acc: 35.156,39.844,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.892 | Acc: 28.981,42.708,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.919 | Acc: 27.496,42.759,51.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.960 | Acc: 27.485,42.456,51.370,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 4.935 | Acc: 34.375,55.469,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.006 | Acc: 37.240,58.519,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.122 | Acc: 36.509,56.688,65.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.115 | Acc: 36.821,56.814,65.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.121 | Acc: 36.728,56.761,65.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.117 | Acc: 36.703,56.962,65.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.119 | Acc: 36.648,56.883,65.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.128 | Acc: 36.686,56.699,65.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.129 | Acc: 36.656,56.527,65.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.140 | Acc: 36.619,56.513,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.141 | Acc: 36.703,56.514,65.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.139 | Acc: 36.797,56.501,65.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.142 | Acc: 36.881,56.500,65.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.148 | Acc: 36.868,56.376,65.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.151 | Acc: 36.872,56.367,65.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.151 | Acc: 36.976,56.426,65.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.161 | Acc: 36.855,56.313,64.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.162 | Acc: 36.863,56.273,64.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.161 | Acc: 36.927,56.269,64.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.172 | Acc: 36.903,56.227,64.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.516 | Acc: 30.469,50.000,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.830 | Acc: 26.860,45.833,53.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.908 | Acc: 26.029,45.694,54.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.929 | Acc: 26.037,45.108,54.060,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 4.461 | Acc: 40.625,57.812,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.851 | Acc: 37.798,57.626,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.896 | Acc: 38.586,57.660,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.978 | Acc: 38.025,57.159,67.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.032 | Acc: 37.587,56.607,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.059 | Acc: 37.500,56.467,66.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.071 | Acc: 37.384,56.444,66.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.083 | Acc: 37.539,56.444,66.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.104 | Acc: 37.291,56.303,66.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.114 | Acc: 37.332,56.237,66.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.121 | Acc: 37.243,56.145,65.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.127 | Acc: 37.072,56.052,65.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.138 | Acc: 36.965,55.945,65.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.129 | Acc: 37.027,56.097,65.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.137 | Acc: 37.027,56.094,65.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.146 | Acc: 36.968,56.009,65.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.152 | Acc: 36.884,55.968,65.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.159 | Acc: 36.836,56.014,65.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.154 | Acc: 36.885,56.101,65.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.158 | Acc: 36.922,56.074,65.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.028 | Acc: 25.781,47.656,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.921 | Acc: 27.865,45.238,51.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.977 | Acc: 27.325,44.455,51.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.016 | Acc: 27.280,44.288,51.140,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 4.993 | Acc: 32.812,57.812,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.000 | Acc: 38.244,59.077,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.050 | Acc: 37.691,57.641,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.043 | Acc: 37.666,57.441,66.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.060 | Acc: 37.365,57.292,66.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.061 | Acc: 37.655,57.209,66.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.058 | Acc: 37.629,57.160,66.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.064 | Acc: 37.572,56.865,66.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.085 | Acc: 37.442,56.517,65.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.084 | Acc: 37.444,56.578,66.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.084 | Acc: 37.547,56.584,66.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.105 | Acc: 37.433,56.395,65.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.114 | Acc: 37.387,56.224,65.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.118 | Acc: 37.380,56.106,65.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.115 | Acc: 37.419,56.142,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.120 | Acc: 37.438,56.195,65.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.122 | Acc: 37.390,56.231,65.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.123 | Acc: 37.333,56.236,65.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.122 | Acc: 37.284,56.272,65.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.123 | Acc: 37.289,56.328,65.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.047 | Acc: 28.906,43.750,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.584 | Acc: 31.250,44.531,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.547 | Acc: 30.888,45.370,54.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.567 | Acc: 30.405,45.338,55.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 5.378 | Acc: 41.406,61.719,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.014 | Acc: 37.835,57.589,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.063 | Acc: 37.595,57.336,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.043 | Acc: 37.731,57.249,66.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.045 | Acc: 37.664,57.465,66.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.058 | Acc: 37.399,57.140,66.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.046 | Acc: 37.565,57.231,66.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.065 | Acc: 37.422,56.865,66.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.076 | Acc: 37.219,56.643,65.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.078 | Acc: 37.254,56.660,65.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.085 | Acc: 37.127,56.588,65.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.080 | Acc: 37.161,56.664,65.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.073 | Acc: 37.150,56.697,65.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.073 | Acc: 37.021,56.723,65.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.078 | Acc: 37.002,56.648,65.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.069 | Acc: 37.061,56.803,65.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.069 | Acc: 37.052,56.778,65.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.082 | Acc: 36.964,56.704,65.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.086 | Acc: 37.035,56.676,65.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.082 | Acc: 37.059,56.763,65.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.887 | Acc: 34.375,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.359 | Acc: 30.394,48.103,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.317 | Acc: 30.678,47.713,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.329 | Acc: 30.482,47.759,55.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 4.832 | Acc: 42.969,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.901 | Acc: 37.612,58.705,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.930 | Acc: 37.481,58.460,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.934 | Acc: 37.756,58.619,67.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.957 | Acc: 37.568,58.700,67.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.963 | Acc: 37.817,58.671,66.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.967 | Acc: 37.842,58.471,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.983 | Acc: 37.666,58.278,66.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.001 | Acc: 37.582,58.138,66.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.005 | Acc: 37.547,58.041,66.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.029 | Acc: 37.368,57.645,66.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.039 | Acc: 37.373,57.632,66.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.036 | Acc: 37.487,57.534,66.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.045 | Acc: 37.452,57.441,65.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.057 | Acc: 37.403,57.256,65.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.056 | Acc: 37.505,57.247,65.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.053 | Acc: 37.522,57.243,65.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.057 | Acc: 37.461,57.173,65.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.062 | Acc: 37.481,57.111,65.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.067 | Acc: 37.443,57.035,65.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.382 | Acc: 33.594,54.688,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.378 | Acc: 28.906,49.740,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.459 | Acc: 27.839,48.037,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.454 | Acc: 28.125,48.297,56.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 5.047 | Acc: 42.969,52.344,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.836 | Acc: 38.430,59.226,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.872 | Acc: 38.129,58.918,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.879 | Acc: 37.987,58.338,67.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.894 | Acc: 37.760,58.266,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.911 | Acc: 37.678,58.393,67.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.944 | Acc: 37.603,58.090,66.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.955 | Acc: 37.866,58.001,66.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.964 | Acc: 37.801,58.128,66.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.981 | Acc: 37.785,57.942,66.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.972 | Acc: 37.838,58.061,66.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.985 | Acc: 37.673,57.996,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.978 | Acc: 37.698,58.007,66.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.985 | Acc: 37.787,57.872,66.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.991 | Acc: 37.820,57.793,66.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.991 | Acc: 37.856,57.748,66.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.002 | Acc: 37.887,57.686,66.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.005 | Acc: 37.841,57.648,66.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.016 | Acc: 37.801,57.564,66.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.018 | Acc: 37.793,57.556,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.029 | Acc: 21.875,42.969,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.336 | Acc: 22.805,38.430,48.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.372 | Acc: 22.066,37.443,47.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.380 | Acc: 21.760,37.538,47.310,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 4.841 | Acc: 35.156,55.469,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.862 | Acc: 39.397,57.589,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.903 | Acc: 38.319,57.660,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.926 | Acc: 38.243,57.505,67.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.918 | Acc: 38.677,57.851,66.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.967 | Acc: 37.956,57.387,66.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.976 | Acc: 37.803,57.503,66.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.983 | Acc: 37.589,57.475,66.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.980 | Acc: 37.815,57.711,66.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.992 | Acc: 37.763,57.718,66.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.992 | Acc: 37.667,57.649,66.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.996 | Acc: 37.670,57.505,66.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.992 | Acc: 37.704,57.518,66.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.999 | Acc: 37.796,57.486,66.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.996 | Acc: 37.859,57.610,66.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.997 | Acc: 37.845,57.639,66.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.999 | Acc: 37.875,57.589,66.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.999 | Acc: 37.924,57.579,66.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.008 | Acc: 37.892,57.520,66.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.008 | Acc: 37.910,57.527,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.255 | Acc: 28.125,57.812,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.397 | Acc: 29.948,48.438,55.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.373 | Acc: 29.707,48.495,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.355 | Acc: 29.137,48.630,56.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 4.632 | Acc: 36.719,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.889 | Acc: 37.649,59.040,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.915 | Acc: 37.557,58.518,68.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.889 | Acc: 37.705,58.991,68.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.884 | Acc: 38.223,58.999,68.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.902 | Acc: 38.119,58.416,68.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.925 | Acc: 38.184,58.116,67.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.895 | Acc: 38.248,58.516,68.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.892 | Acc: 38.053,58.526,68.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.902 | Acc: 38.031,58.391,67.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.908 | Acc: 38.130,58.341,67.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.922 | Acc: 38.119,58.180,67.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.935 | Acc: 38.048,58.001,67.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.940 | Acc: 38.015,57.956,67.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.939 | Acc: 38.073,57.974,67.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.944 | Acc: 38.105,58.012,67.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.944 | Acc: 38.152,58.029,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.948 | Acc: 38.148,57.897,66.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.954 | Acc: 38.227,57.880,66.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.964 | Acc: 38.086,57.714,66.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.298 | Acc: 25.781,52.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.354 | Acc: 27.604,49.479,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.397 | Acc: 28.068,48.990,58.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.445 | Acc: 27.459,48.642,57.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 4.744 | Acc: 44.531,60.938,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.803 | Acc: 38.281,60.379,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.859 | Acc: 37.729,59.699,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.836 | Acc: 38.294,59.990,67.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.840 | Acc: 38.320,59.452,67.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.861 | Acc: 37.987,59.050,67.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.866 | Acc: 38.275,58.884,67.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.888 | Acc: 38.132,58.804,67.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.885 | Acc: 38.228,58.720,67.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.904 | Acc: 38.122,58.533,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.916 | Acc: 38.106,58.431,67.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.915 | Acc: 38.211,58.466,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.920 | Acc: 38.187,58.390,67.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.934 | Acc: 38.066,58.178,66.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.939 | Acc: 38.056,58.096,66.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.945 | Acc: 38.074,58.082,66.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.949 | Acc: 38.123,58.061,66.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.956 | Acc: 38.116,58.023,66.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.959 | Acc: 38.128,57.981,66.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.964 | Acc: 38.187,57.970,66.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.675 | Acc: 28.125,48.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.690 | Acc: 29.501,45.833,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.716 | Acc: 29.002,45.579,55.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.730 | Acc: 28.804,45.684,54.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 4.925 | Acc: 39.062,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.798 | Acc: 39.546,60.007,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.831 | Acc: 39.520,59.013,68.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.805 | Acc: 39.498,59.093,68.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.836 | Acc: 39.226,59.047,68.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.836 | Acc: 39.209,59.120,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.835 | Acc: 39.108,59.078,68.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.855 | Acc: 38.813,58.954,67.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.874 | Acc: 38.655,58.759,67.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.889 | Acc: 38.501,58.667,67.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.881 | Acc: 38.720,58.699,67.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.882 | Acc: 38.667,58.590,67.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.895 | Acc: 38.625,58.565,67.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.904 | Acc: 38.625,58.492,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.907 | Acc: 38.718,58.496,67.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.913 | Acc: 38.668,58.474,67.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.920 | Acc: 38.615,58.414,67.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.930 | Acc: 38.558,58.220,67.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.932 | Acc: 38.550,58.172,67.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.933 | Acc: 38.513,58.143,67.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.744 | Acc: 31.250,44.531,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.591 | Acc: 29.799,45.424,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.625 | Acc: 29.668,44.550,55.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.611 | Acc: 29.521,44.390,55.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 5.083 | Acc: 35.938,54.688,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.709 | Acc: 38.914,58.891,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.759 | Acc: 38.929,59.623,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.809 | Acc: 38.730,59.132,69.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.831 | Acc: 38.648,58.854,68.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.839 | Acc: 38.784,58.872,68.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.853 | Acc: 38.669,58.775,68.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.853 | Acc: 38.758,58.788,68.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.857 | Acc: 38.762,58.783,67.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.852 | Acc: 38.782,58.741,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.865 | Acc: 38.612,58.738,67.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.869 | Acc: 38.621,58.760,67.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.881 | Acc: 38.605,58.717,67.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.891 | Acc: 38.566,58.576,67.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.902 | Acc: 38.398,58.546,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.908 | Acc: 38.263,58.433,67.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.912 | Acc: 38.276,58.360,67.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.908 | Acc: 38.366,58.438,67.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.916 | Acc: 38.366,58.377,67.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.916 | Acc: 38.361,58.395,67.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.484 | Acc: 32.812,47.656,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.591 | Acc: 28.348,46.317,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.657 | Acc: 28.487,46.132,55.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.636 | Acc: 28.535,46.644,55.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 5.007 | Acc: 32.812,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.866 | Acc: 37.909,57.775,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.837 | Acc: 37.557,58.575,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.809 | Acc: 38.230,58.952,68.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.819 | Acc: 38.628,58.893,68.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.815 | Acc: 38.668,59.166,68.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.811 | Acc: 38.701,59.310,68.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.811 | Acc: 38.719,59.270,68.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.812 | Acc: 38.878,59.200,68.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.834 | Acc: 38.903,59.155,68.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.840 | Acc: 38.891,59.146,68.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.844 | Acc: 38.741,59.071,68.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.850 | Acc: 38.693,58.957,68.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.861 | Acc: 38.673,58.791,67.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.863 | Acc: 38.654,58.780,67.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.866 | Acc: 38.655,58.760,67.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.878 | Acc: 38.661,58.669,67.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.880 | Acc: 38.632,58.637,67.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.880 | Acc: 38.669,58.615,67.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.885 | Acc: 38.613,58.575,67.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.143 | Acc: 31.250,48.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.407 | Acc: 29.167,48.065,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.390 | Acc: 29.306,47.942,55.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.399 | Acc: 28.791,47.951,55.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 5.078 | Acc: 38.281,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.653 | Acc: 40.067,60.975,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.678 | Acc: 39.482,60.690,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.737 | Acc: 38.858,60.067,68.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.727 | Acc: 39.246,60.301,69.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.758 | Acc: 39.016,60.025,69.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.746 | Acc: 39.004,60.111,69.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.777 | Acc: 38.835,59.929,68.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.782 | Acc: 38.820,59.681,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.811 | Acc: 38.588,59.435,68.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.810 | Acc: 38.530,59.445,68.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.814 | Acc: 38.472,59.513,68.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.828 | Acc: 38.362,59.336,68.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.843 | Acc: 38.242,59.153,68.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.853 | Acc: 38.120,58.966,68.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.848 | Acc: 38.271,58.983,68.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.850 | Acc: 38.233,58.939,68.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.862 | Acc: 38.208,58.889,67.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.862 | Acc: 38.266,58.879,67.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.862 | Acc: 38.347,58.864,67.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.319 | Acc: 28.125,44.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.161 | Acc: 25.037,44.271,53.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.178 | Acc: 24.905,44.550,53.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.176 | Acc: 25.013,44.211,52.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.620 | Acc: 35.938,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.704 | Acc: 38.393,59.747,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.698 | Acc: 38.605,59.470,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.742 | Acc: 38.794,59.670,69.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.752 | Acc: 39.062,59.790,69.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.752 | Acc: 39.171,59.723,69.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.751 | Acc: 39.308,59.659,69.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.757 | Acc: 39.240,59.558,68.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.766 | Acc: 39.349,59.521,68.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.781 | Acc: 39.067,59.448,68.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.788 | Acc: 39.140,59.441,68.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.805 | Acc: 38.964,59.198,68.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.821 | Acc: 38.907,59.025,68.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.833 | Acc: 38.805,58.947,68.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.838 | Acc: 38.771,58.855,68.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.837 | Acc: 38.759,58.993,68.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.845 | Acc: 38.707,58.993,68.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.845 | Acc: 38.772,59.036,67.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.852 | Acc: 38.699,58.994,67.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.852 | Acc: 38.780,59.033,67.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.987 | Acc: 25.781,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.899 | Acc: 24.070,47.284,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.966 | Acc: 23.952,47.027,55.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.017 | Acc: 23.502,46.683,55.866,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 4.890 | Acc: 35.938,56.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.667 | Acc: 39.062,60.714,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.741 | Acc: 38.681,59.737,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.714 | Acc: 39.460,60.246,69.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.714 | Acc: 39.217,60.185,69.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.750 | Acc: 39.008,59.855,69.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.747 | Acc: 39.276,59.879,68.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.747 | Acc: 39.389,59.907,68.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.759 | Acc: 39.363,59.826,68.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.750 | Acc: 39.477,59.992,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.756 | Acc: 39.381,59.954,68.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.775 | Acc: 39.225,59.757,68.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.780 | Acc: 39.137,59.738,68.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.781 | Acc: 39.092,59.710,68.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.790 | Acc: 38.954,59.731,68.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.811 | Acc: 38.837,59.580,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.814 | Acc: 38.785,59.521,68.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.815 | Acc: 38.806,59.519,68.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.824 | Acc: 38.757,59.431,68.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.828 | Acc: 38.695,59.371,67.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.831 | Acc: 31.250,54.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.584 | Acc: 30.952,46.875,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.641 | Acc: 30.259,46.380,55.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.617 | Acc: 30.174,46.337,55.328,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 4.695 | Acc: 39.062,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.705 | Acc: 39.769,60.863,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.722 | Acc: 39.444,60.385,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.722 | Acc: 39.588,60.425,69.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.725 | Acc: 39.660,60.301,69.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.713 | Acc: 39.627,60.032,69.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.710 | Acc: 39.663,60.130,69.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.724 | Acc: 39.478,59.973,69.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.745 | Acc: 39.373,59.778,69.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.749 | Acc: 39.162,59.807,69.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.757 | Acc: 39.175,59.768,69.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.775 | Acc: 39.218,59.587,68.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.789 | Acc: 39.118,59.547,68.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.798 | Acc: 38.961,59.387,68.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.802 | Acc: 38.887,59.314,68.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.806 | Acc: 38.772,59.282,68.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.808 | Acc: 38.812,59.287,68.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.812 | Acc: 38.774,59.238,68.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.824 | Acc: 38.688,59.141,68.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.818 | Acc: 38.753,59.221,68.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.359 | Acc: 25.000,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.957 | Acc: 27.530,44.754,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.080 | Acc: 27.553,44.131,53.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.142 | Acc: 27.574,43.635,53.509,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 4.693 | Acc: 43.750,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.692 | Acc: 40.141,60.156,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.671 | Acc: 40.568,59.966,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.712 | Acc: 39.844,59.285,69.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.706 | Acc: 39.651,59.491,69.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.720 | Acc: 39.542,59.785,69.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.718 | Acc: 39.360,59.833,69.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.714 | Acc: 39.500,60.034,69.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.742 | Acc: 39.257,59.773,69.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.743 | Acc: 39.149,59.841,69.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.756 | Acc: 39.105,59.795,69.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.774 | Acc: 38.964,59.637,68.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.772 | Acc: 38.952,59.647,68.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.777 | Acc: 38.985,59.743,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.780 | Acc: 38.907,59.625,68.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.775 | Acc: 38.969,59.544,68.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.785 | Acc: 38.953,59.504,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.794 | Acc: 38.904,59.425,68.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.804 | Acc: 38.863,59.358,68.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.807 | Acc: 38.859,59.359,68.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.518 | Acc: 28.125,48.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.647 | Acc: 28.274,45.536,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.670 | Acc: 27.954,45.312,54.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.708 | Acc: 27.421,45.312,54.521,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 4.480 | Acc: 42.188,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.695 | Acc: 39.360,60.454,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.617 | Acc: 39.863,60.404,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 39.203,59.849,69.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.698 | Acc: 39.275,60.012,69.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.686 | Acc: 39.527,60.079,69.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.690 | Acc: 39.502,59.898,69.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.694 | Acc: 39.528,59.907,69.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.719 | Acc: 39.344,59.938,69.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.706 | Acc: 39.671,60.096,69.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.709 | Acc: 39.871,60.164,69.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.716 | Acc: 39.734,60.071,69.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.716 | Acc: 39.594,60.111,69.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.718 | Acc: 39.538,60.081,69.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.718 | Acc: 39.535,60.067,69.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.729 | Acc: 39.499,60.016,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.740 | Acc: 39.411,59.927,68.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.745 | Acc: 39.370,59.968,68.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.754 | Acc: 39.340,59.929,68.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.764 | Acc: 39.227,59.845,68.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.037 | Acc: 28.125,46.094,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.825 | Acc: 29.353,46.391,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.834 | Acc: 28.201,47.104,56.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.855 | Acc: 27.959,46.721,56.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 4.502 | Acc: 32.812,56.250,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.638 | Acc: 39.323,59.524,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 40.034,60.213,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.651 | Acc: 39.703,59.874,69.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.663 | Acc: 39.911,60.002,69.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.678 | Acc: 39.612,59.916,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.691 | Acc: 39.476,60.118,69.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.693 | Acc: 39.328,60.001,69.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.707 | Acc: 39.184,59.962,69.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.714 | Acc: 39.209,59.854,69.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.715 | Acc: 39.214,60.047,69.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.730 | Acc: 39.070,59.863,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.734 | Acc: 39.118,59.822,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.728 | Acc: 39.245,59.932,68.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.722 | Acc: 39.410,60.017,68.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.728 | Acc: 39.379,59.930,68.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.731 | Acc: 39.415,59.889,68.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.734 | Acc: 39.328,59.966,68.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.743 | Acc: 39.272,59.842,68.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.748 | Acc: 39.286,59.830,68.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.908 | Acc: 32.031,54.688,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.186 | Acc: 30.655,51.116,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.281 | Acc: 29.325,50.400,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.272 | Acc: 29.316,50.269,57.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 4.936 | Acc: 38.281,54.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.689 | Acc: 40.030,59.710,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 39.939,60.709,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.613 | Acc: 39.985,60.502,69.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.598 | Acc: 39.892,60.986,70.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.641 | Acc: 39.596,60.736,70.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.654 | Acc: 39.411,60.524,69.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.675 | Acc: 39.107,60.422,69.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.678 | Acc: 39.266,60.525,69.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.695 | Acc: 39.041,60.389,69.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.710 | Acc: 39.090,60.308,69.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.703 | Acc: 39.229,60.326,69.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.713 | Acc: 39.309,60.208,69.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.710 | Acc: 39.437,60.195,69.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.709 | Acc: 39.496,60.184,69.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.718 | Acc: 39.499,60.112,69.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.722 | Acc: 39.464,60.105,69.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.732 | Acc: 39.392,59.932,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.733 | Acc: 39.350,59.933,68.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.739 | Acc: 39.259,59.904,68.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.748 | Acc: 25.781,43.750,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.006 | Acc: 26.339,42.597,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.970 | Acc: 26.963,43.559,55.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.023 | Acc: 26.294,42.943,54.790,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 4.831 | Acc: 46.875,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.671 | Acc: 39.137,60.268,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.672 | Acc: 39.101,60.480,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 38.947,60.259,70.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.671 | Acc: 39.140,60.532,69.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.640 | Acc: 39.325,60.876,70.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.644 | Acc: 39.211,60.925,70.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.643 | Acc: 39.412,60.976,70.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.654 | Acc: 39.388,60.879,70.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.651 | Acc: 39.438,60.830,70.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.654 | Acc: 39.323,60.724,70.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.669 | Acc: 39.296,60.591,70.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.675 | Acc: 39.231,60.513,70.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.694 | Acc: 39.116,60.282,69.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.705 | Acc: 39.065,60.173,69.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.712 | Acc: 39.037,60.195,69.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.718 | Acc: 39.084,60.100,69.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.721 | Acc: 39.113,60.071,69.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.731 | Acc: 39.110,59.920,69.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.731 | Acc: 39.198,59.888,69.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.749 | Acc: 35.938,57.812,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.459 | Acc: 28.385,49.219,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.437 | Acc: 28.430,48.628,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.456 | Acc: 28.099,49.065,57.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 4.727 | Acc: 38.281,53.125,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.589 | Acc: 40.737,61.086,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 40.187,61.662,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.590 | Acc: 40.023,61.898,71.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.629 | Acc: 39.738,61.294,70.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.643 | Acc: 39.728,61.170,70.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.627 | Acc: 39.837,61.286,70.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.632 | Acc: 39.722,61.148,70.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.637 | Acc: 39.684,61.078,70.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.651 | Acc: 39.697,60.955,70.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.653 | Acc: 39.525,61.039,69.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.672 | Acc: 39.511,60.906,69.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.671 | Acc: 39.523,60.905,69.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.682 | Acc: 39.571,60.854,69.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.691 | Acc: 39.555,60.693,69.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.696 | Acc: 39.569,60.592,69.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.700 | Acc: 39.557,60.519,69.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.708 | Acc: 39.493,60.479,69.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.709 | Acc: 39.500,60.461,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.708 | Acc: 39.530,60.429,69.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.882 | Acc: 28.906,53.906,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.486 | Acc: 30.729,45.275,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.472 | Acc: 30.011,45.465,57.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.466 | Acc: 29.662,45.505,56.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 4.775 | Acc: 35.156,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 41.704,60.379,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 40.644,60.385,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.588 | Acc: 40.868,60.861,70.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.599 | Acc: 40.963,61.063,70.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.607 | Acc: 40.780,61.154,70.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.628 | Acc: 40.728,60.944,70.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.640 | Acc: 40.575,60.788,70.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.638 | Acc: 40.450,60.753,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.640 | Acc: 40.366,60.700,70.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.663 | Acc: 40.054,60.557,69.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.674 | Acc: 39.978,60.365,69.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.678 | Acc: 39.860,60.396,69.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.678 | Acc: 39.781,60.408,69.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.688 | Acc: 39.694,60.329,69.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.691 | Acc: 39.691,60.320,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.700 | Acc: 39.608,60.234,69.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.701 | Acc: 39.654,60.200,69.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.705 | Acc: 39.677,60.174,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.714 | Acc: 39.538,60.093,69.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.722 | Acc: 24.219,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.182 | Acc: 25.818,45.201,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.184 | Acc: 25.705,44.931,53.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.186 | Acc: 25.615,45.351,53.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 4.473 | Acc: 43.750,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 41.369,62.463,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 41.235,61.928,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 41.483,62.052,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.553 | Acc: 41.175,61.873,70.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.576 | Acc: 40.826,61.572,70.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.581 | Acc: 40.877,61.409,70.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.604 | Acc: 40.608,61.093,70.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.621 | Acc: 40.411,60.986,70.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.635 | Acc: 40.383,60.877,70.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.645 | Acc: 40.283,60.922,70.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.656 | Acc: 40.236,60.870,69.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.666 | Acc: 40.168,60.746,69.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.674 | Acc: 40.071,60.680,69.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.673 | Acc: 39.980,60.726,69.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.668 | Acc: 39.981,60.665,69.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.676 | Acc: 39.917,60.631,69.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.681 | Acc: 39.878,60.537,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.685 | Acc: 39.813,60.526,69.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.692 | Acc: 39.751,60.476,69.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.145 | Acc: 32.031,50.781,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.261 | Acc: 28.720,50.335,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.244 | Acc: 28.487,50.915,58.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.221 | Acc: 28.701,51.447,58.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 4.078 | Acc: 44.531,67.188,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.577 | Acc: 39.844,60.975,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 40.072,60.728,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.553 | Acc: 40.292,61.206,70.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.530 | Acc: 40.856,61.651,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.560 | Acc: 40.532,61.286,70.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.571 | Acc: 40.644,61.299,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.586 | Acc: 40.475,61.109,70.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.603 | Acc: 40.251,60.904,70.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.602 | Acc: 40.331,60.903,70.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.609 | Acc: 40.252,60.778,70.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.624 | Acc: 40.042,60.619,69.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.627 | Acc: 40.016,60.730,69.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.638 | Acc: 39.969,60.731,69.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.645 | Acc: 39.913,60.782,69.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.652 | Acc: 39.753,60.712,69.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.657 | Acc: 39.703,60.653,69.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.654 | Acc: 39.729,60.692,69.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.665 | Acc: 39.640,60.658,69.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.675 | Acc: 39.594,60.591,69.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.322 | Acc: 30.469,44.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.039 | Acc: 31.101,42.522,51.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.017 | Acc: 30.888,42.378,51.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.988 | Acc: 30.955,42.700,51.434,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.449 | Acc: 36.719,63.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.545 | Acc: 40.216,62.426,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 39.405,61.147,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 39.383,61.181,71.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.570 | Acc: 39.255,61.265,71.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.581 | Acc: 39.287,61.386,71.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.578 | Acc: 39.495,61.183,71.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.582 | Acc: 39.561,61.043,71.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.598 | Acc: 39.485,60.942,70.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.597 | Acc: 39.637,60.981,70.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.605 | Acc: 39.614,60.883,70.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.611 | Acc: 39.621,60.785,70.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.609 | Acc: 39.704,60.798,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.601 | Acc: 39.817,60.905,70.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.602 | Acc: 39.944,60.963,70.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.608 | Acc: 39.911,60.849,70.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.616 | Acc: 39.819,60.789,70.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.626 | Acc: 39.786,60.708,70.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.633 | Acc: 39.731,60.684,70.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.639 | Acc: 39.741,60.609,70.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.411 | Acc: 31.250,52.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.431 | Acc: 29.278,49.740,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.435 | Acc: 29.630,49.447,55.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.427 | Acc: 29.905,49.501,55.802,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 3.859 | Acc: 46.094,65.625,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.453 | Acc: 41.109,62.388,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.497 | Acc: 40.492,61.814,72.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.513 | Acc: 40.126,61.642,72.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.551 | Acc: 39.931,61.236,71.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.545 | Acc: 40.269,61.448,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.565 | Acc: 40.225,61.532,71.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.586 | Acc: 40.193,61.392,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.584 | Acc: 40.120,61.525,71.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.590 | Acc: 40.098,61.447,71.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.605 | Acc: 40.046,61.155,70.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.608 | Acc: 39.950,61.192,70.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.599 | Acc: 40.045,61.216,70.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.609 | Acc: 39.990,61.039,70.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.602 | Acc: 40.083,61.138,70.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.614 | Acc: 40.062,61.085,70.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.626 | Acc: 39.970,61.030,70.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.627 | Acc: 39.990,61.025,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.634 | Acc: 39.913,60.912,70.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.643 | Acc: 39.833,60.814,70.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.867 | Acc: 35.938,50.000,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.869 | Acc: 35.863,51.004,58.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.876 | Acc: 35.709,50.248,58.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.872 | Acc: 35.502,50.128,57.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 4.544 | Acc: 39.062,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.430 | Acc: 41.146,61.682,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.469 | Acc: 40.758,61.376,72.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.473 | Acc: 41.035,61.322,72.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.497 | Acc: 40.567,61.343,71.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.506 | Acc: 40.594,61.247,71.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.506 | Acc: 40.690,61.163,71.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.518 | Acc: 40.553,61.148,71.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.545 | Acc: 40.392,60.874,71.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.563 | Acc: 40.055,60.817,71.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.581 | Acc: 39.995,60.829,70.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.592 | Acc: 40.063,60.754,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.597 | Acc: 40.048,60.788,70.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.604 | Acc: 39.859,60.698,70.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.604 | Acc: 39.827,60.704,70.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.609 | Acc: 39.761,60.730,70.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.618 | Acc: 39.746,60.677,70.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.622 | Acc: 39.780,60.679,70.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.627 | Acc: 39.733,60.643,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.626 | Acc: 39.788,60.679,70.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.661 | Acc: 32.812,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.238 | Acc: 30.729,50.112,58.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.246 | Acc: 30.602,49.714,57.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.222 | Acc: 30.443,50.038,58.056,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 4.707 | Acc: 32.812,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.508 | Acc: 39.769,62.872,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.498 | Acc: 39.996,62.024,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.471 | Acc: 40.446,62.193,71.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.499 | Acc: 40.461,62.172,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.490 | Acc: 40.416,62.353,71.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.509 | Acc: 40.367,62.242,71.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.532 | Acc: 40.204,61.846,71.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.549 | Acc: 39.999,61.612,71.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.562 | Acc: 39.926,61.533,71.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.567 | Acc: 39.964,61.466,70.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.571 | Acc: 40.148,61.464,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.569 | Acc: 40.067,61.456,70.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.572 | Acc: 40.083,61.467,70.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.571 | Acc: 40.094,61.491,70.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.570 | Acc: 40.155,61.415,70.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.582 | Acc: 40.126,61.315,70.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.592 | Acc: 40.110,61.215,70.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.599 | Acc: 40.090,61.126,70.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.602 | Acc: 40.139,61.015,70.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.304 | Acc: 33.594,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.021 | Acc: 33.482,51.302,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.103 | Acc: 32.431,50.286,58.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.086 | Acc: 32.351,50.551,58.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 4.791 | Acc: 35.156,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.587 | Acc: 40.551,62.091,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.527 | Acc: 40.301,61.928,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.502 | Acc: 40.523,62.205,71.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.500 | Acc: 40.847,62.085,71.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.495 | Acc: 40.888,62.307,71.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.513 | Acc: 40.793,62.255,71.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.534 | Acc: 40.553,62.134,71.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.541 | Acc: 40.640,61.850,71.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.530 | Acc: 40.664,61.805,71.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.547 | Acc: 40.431,61.653,70.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.556 | Acc: 40.342,61.500,70.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.564 | Acc: 40.262,61.388,70.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.575 | Acc: 40.200,61.294,70.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.579 | Acc: 40.100,61.274,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.581 | Acc: 40.134,61.252,70.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.588 | Acc: 40.090,61.227,70.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.599 | Acc: 40.013,61.153,70.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.611 | Acc: 39.948,61.028,70.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.607 | Acc: 40.000,61.104,70.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.916 | Acc: 28.125,50.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.650 | Acc: 25.967,48.475,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.737 | Acc: 25.972,48.742,57.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.709 | Acc: 26.306,49.398,57.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 4.143 | Acc: 45.312,60.156,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.488 | Acc: 40.179,60.975,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.470 | Acc: 40.492,61.643,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.448 | Acc: 40.356,61.834,72.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.489 | Acc: 39.796,61.738,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.517 | Acc: 39.968,61.494,71.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.529 | Acc: 39.779,61.615,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.540 | Acc: 39.860,61.830,71.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.532 | Acc: 39.887,61.826,71.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.552 | Acc: 39.839,61.494,71.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.551 | Acc: 39.817,61.552,71.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.566 | Acc: 39.752,61.365,70.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.573 | Acc: 39.743,61.317,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.561 | Acc: 39.928,61.419,70.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.564 | Acc: 39.988,61.338,70.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.562 | Acc: 39.974,61.451,70.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.564 | Acc: 40.007,61.434,70.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.571 | Acc: 39.984,61.419,70.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.573 | Acc: 40.121,61.347,70.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.577 | Acc: 40.092,61.315,70.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.227 | Acc: 28.125,46.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.458 | Acc: 24.479,43.824,53.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.427 | Acc: 24.447,44.264,54.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.472 | Acc: 24.155,44.314,54.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 5.070 | Acc: 37.500,53.125,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.540 | Acc: 39.583,63.095,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.521 | Acc: 39.253,62.671,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.499 | Acc: 39.690,62.756,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.485 | Acc: 40.249,62.674,71.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.486 | Acc: 40.308,62.570,71.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.482 | Acc: 40.451,62.571,71.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.516 | Acc: 40.248,62.179,71.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.526 | Acc: 40.378,62.088,71.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.530 | Acc: 40.500,61.965,71.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.539 | Acc: 40.454,61.960,71.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.537 | Acc: 40.399,61.828,71.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.539 | Acc: 40.411,61.806,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.552 | Acc: 40.335,61.584,71.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.553 | Acc: 40.366,61.630,70.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.557 | Acc: 40.275,61.646,70.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.557 | Acc: 40.304,61.726,70.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.562 | Acc: 40.293,61.723,70.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.563 | Acc: 40.300,61.643,70.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.567 | Acc: 40.262,61.608,70.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.505 | Acc: 25.000,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.371 | Acc: 24.479,41.629,52.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.398 | Acc: 24.333,41.921,52.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.382 | Acc: 24.565,42.597,52.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 4.438 | Acc: 39.844,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.518 | Acc: 39.993,62.091,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.489 | Acc: 40.263,62.481,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.517 | Acc: 40.702,62.244,71.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.516 | Acc: 40.750,62.143,71.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.498 | Acc: 40.710,62.384,71.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.497 | Acc: 40.541,62.410,71.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.509 | Acc: 40.470,62.267,71.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.522 | Acc: 40.392,62.238,71.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.541 | Acc: 40.249,61.909,71.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.535 | Acc: 40.135,61.987,71.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.533 | Acc: 40.102,61.998,71.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.540 | Acc: 40.100,61.891,71.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.536 | Acc: 40.206,61.895,71.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.546 | Acc: 40.264,61.785,71.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.546 | Acc: 40.327,61.825,71.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.553 | Acc: 40.331,61.709,70.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.567 | Acc: 40.231,61.510,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.574 | Acc: 40.231,61.396,70.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.579 | Acc: 40.207,61.364,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.690 | Acc: 32.031,53.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.005 | Acc: 30.766,50.707,59.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.997 | Acc: 31.231,51.220,59.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.016 | Acc: 31.084,51.422,58.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.716 | Acc: 38.281,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.475 | Acc: 40.439,61.905,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.461 | Acc: 41.025,62.214,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.480 | Acc: 40.510,61.898,72.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.468 | Acc: 40.442,62.076,72.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.481 | Acc: 40.563,62.113,72.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.497 | Acc: 40.438,61.900,72.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.494 | Acc: 40.503,62.040,71.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.512 | Acc: 40.402,61.826,71.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.515 | Acc: 40.496,61.719,71.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.532 | Acc: 40.438,61.559,71.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.546 | Acc: 40.342,61.323,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.545 | Acc: 40.343,61.327,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.549 | Acc: 40.329,61.333,70.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.552 | Acc: 40.294,61.366,70.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.553 | Acc: 40.285,61.405,70.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.549 | Acc: 40.260,61.410,70.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.562 | Acc: 40.174,61.322,70.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.564 | Acc: 40.158,61.301,70.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.575 | Acc: 40.020,61.204,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.662 | Acc: 32.031,51.562,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.252 | Acc: 30.655,48.735,57.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.232 | Acc: 31.155,48.933,57.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.217 | Acc: 31.173,48.988,57.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.666 | Acc: 39.062,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.397 | Acc: 42.076,62.649,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.405 | Acc: 41.254,62.519,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.423 | Acc: 41.355,62.436,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.438 | Acc: 41.175,62.664,72.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.451 | Acc: 41.166,62.593,72.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.455 | Acc: 41.006,62.552,72.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.454 | Acc: 41.041,62.489,72.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.473 | Acc: 40.984,62.175,71.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.482 | Acc: 40.858,62.137,71.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.477 | Acc: 40.777,62.208,71.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.486 | Acc: 40.657,62.097,71.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.496 | Acc: 40.644,61.994,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.502 | Acc: 40.592,61.919,71.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.507 | Acc: 40.567,61.913,71.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.504 | Acc: 40.690,62.030,71.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.517 | Acc: 40.623,61.928,71.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.514 | Acc: 40.664,61.925,71.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.524 | Acc: 40.593,61.836,71.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.530 | Acc: 40.617,61.735,71.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.411 | Acc: 31.250,57.812,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.457 | Acc: 27.753,49.330,59.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.455 | Acc: 27.858,49.447,59.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.490 | Acc: 27.933,49.565,58.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 4.621 | Acc: 38.281,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.453 | Acc: 41.146,63.318,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.416 | Acc: 40.854,63.662,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.424 | Acc: 40.599,63.166,72.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.417 | Acc: 41.040,63.291,72.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.427 | Acc: 41.097,63.390,72.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.425 | Acc: 40.896,63.397,72.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.424 | Acc: 40.963,63.226,72.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.422 | Acc: 41.003,63.063,72.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.443 | Acc: 40.888,62.802,71.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.475 | Acc: 40.738,62.465,71.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.493 | Acc: 40.742,62.253,71.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.497 | Acc: 40.764,62.234,71.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.503 | Acc: 40.721,62.237,71.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.512 | Acc: 40.658,62.116,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.523 | Acc: 40.547,62.054,71.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.530 | Acc: 40.562,61.999,71.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.528 | Acc: 40.602,61.989,71.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.532 | Acc: 40.608,61.985,71.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.536 | Acc: 40.592,62.045,71.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.380 | Acc: 34.375,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.419 | Acc: 33.371,47.619,57.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.441 | Acc: 32.870,47.389,57.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.458 | Acc: 32.390,47.144,56.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 4.583 | Acc: 38.281,60.156,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 41.927,64.509,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.373 | Acc: 41.120,63.053,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.404 | Acc: 41.317,62.820,72.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.414 | Acc: 41.098,62.818,72.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.424 | Acc: 40.934,62.802,72.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.448 | Acc: 40.896,62.771,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.453 | Acc: 41.013,62.622,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.471 | Acc: 40.863,62.432,72.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.474 | Acc: 40.836,62.418,72.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.475 | Acc: 40.831,62.488,71.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.484 | Acc: 40.816,62.447,71.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.493 | Acc: 40.742,62.338,71.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.497 | Acc: 40.703,62.276,71.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.501 | Acc: 40.583,62.272,71.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.511 | Acc: 40.500,62.220,71.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.510 | Acc: 40.627,62.232,71.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.519 | Acc: 40.533,62.108,71.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.519 | Acc: 40.599,62.043,71.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.524 | Acc: 40.584,61.991,71.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.605 | Acc: 35.156,50.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.799 | Acc: 29.948,43.899,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.808 | Acc: 30.202,43.883,54.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.819 | Acc: 30.072,43.763,53.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.519 | Acc: 40.625,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.438 | Acc: 39.658,61.793,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.426 | Acc: 40.892,62.691,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.402 | Acc: 40.920,63.153,72.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.379 | Acc: 41.020,63.696,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.379 | Acc: 41.136,63.312,72.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.380 | Acc: 41.309,63.243,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.405 | Acc: 41.151,63.076,72.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.433 | Acc: 40.965,62.733,71.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.431 | Acc: 40.931,62.815,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.436 | Acc: 40.858,62.764,71.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.441 | Acc: 40.834,62.772,71.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.448 | Acc: 40.813,62.730,71.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.454 | Acc: 40.820,62.647,71.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.467 | Acc: 40.656,62.444,71.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.476 | Acc: 40.622,62.386,71.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.488 | Acc: 40.606,62.313,71.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.492 | Acc: 40.556,62.275,71.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.504 | Acc: 40.458,62.078,71.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.508 | Acc: 40.367,62.073,71.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.024 | Acc: 35.156,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.016 | Acc: 34.301,49.107,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.083 | Acc: 34.337,49.162,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.098 | Acc: 33.709,48.514,57.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.745 | Acc: 38.281,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.417 | Acc: 40.923,62.463,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 41.139,63.205,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.422 | Acc: 40.574,62.615,73.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.418 | Acc: 40.905,62.645,73.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.426 | Acc: 40.834,62.515,73.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.450 | Acc: 40.709,62.358,72.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.438 | Acc: 40.747,62.544,72.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.440 | Acc: 40.722,62.437,72.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.448 | Acc: 40.802,62.371,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.454 | Acc: 40.847,62.352,72.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.459 | Acc: 40.929,62.366,72.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.468 | Acc: 40.852,62.351,72.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.470 | Acc: 40.751,62.353,72.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.475 | Acc: 40.675,62.233,72.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.481 | Acc: 40.539,62.191,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.492 | Acc: 40.394,62.145,71.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.503 | Acc: 40.313,62.092,71.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.505 | Acc: 40.324,62.004,71.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.505 | Acc: 40.344,61.961,71.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.575 | Acc: 35.938,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.030 | Acc: 33.594,50.595,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.092 | Acc: 33.194,50.667,57.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.149 | Acc: 32.812,49.898,57.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 4.145 | Acc: 48.438,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 42.634,62.574,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.288 | Acc: 42.245,63.434,73.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.315 | Acc: 41.547,63.665,73.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.330 | Acc: 41.821,63.773,73.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.327 | Acc: 41.855,63.629,73.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.342 | Acc: 41.994,63.494,72.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.375 | Acc: 41.534,63.326,72.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.390 | Acc: 41.382,63.073,72.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.422 | Acc: 41.126,62.876,72.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.436 | Acc: 41.103,62.733,71.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.444 | Acc: 41.127,62.634,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.460 | Acc: 40.888,62.471,71.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.468 | Acc: 40.826,62.326,71.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.482 | Acc: 40.781,62.102,71.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.494 | Acc: 40.703,61.986,71.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.500 | Acc: 40.737,61.860,71.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.498 | Acc: 40.740,61.852,71.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.499 | Acc: 40.744,61.792,71.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.505 | Acc: 40.674,61.713,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.499 | Acc: 32.812,49.219,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.677 | Acc: 29.874,45.015,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.755 | Acc: 29.497,44.893,54.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.721 | Acc: 29.521,45.172,55.020,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 4.730 | Acc: 35.938,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.437 | Acc: 39.323,62.612,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.368 | Acc: 40.644,63.586,72.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.348 | Acc: 41.368,63.614,73.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.357 | Acc: 41.339,63.493,72.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.372 | Acc: 41.213,63.451,73.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.409 | Acc: 41.193,63.165,72.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.402 | Acc: 41.174,63.154,72.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.412 | Acc: 41.115,63.165,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.441 | Acc: 40.858,62.798,72.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.448 | Acc: 40.676,62.714,72.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.453 | Acc: 40.682,62.595,72.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.443 | Acc: 40.907,62.659,72.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.457 | Acc: 40.930,62.461,71.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.464 | Acc: 40.900,62.375,71.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.466 | Acc: 40.939,62.360,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.468 | Acc: 40.866,62.310,71.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.467 | Acc: 40.925,62.415,71.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.477 | Acc: 40.729,62.403,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.482 | Acc: 40.664,62.270,71.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.827 | Acc: 26.562,49.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.375 | Acc: 30.766,48.586,58.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.419 | Acc: 30.583,48.628,57.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.446 | Acc: 30.200,49.078,57.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 3.892 | Acc: 43.750,66.406,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.297 | Acc: 40.997,63.839,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.433 | Acc: 40.187,62.538,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.419 | Acc: 40.394,62.436,72.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.406 | Acc: 40.519,62.432,72.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.395 | Acc: 40.726,62.601,72.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.406 | Acc: 40.754,62.423,72.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.418 | Acc: 40.553,62.179,72.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.421 | Acc: 40.586,62.374,72.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.431 | Acc: 40.435,62.371,72.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.431 | Acc: 40.493,62.422,72.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.444 | Acc: 40.544,62.327,72.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.452 | Acc: 40.567,62.361,72.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.463 | Acc: 40.520,62.192,71.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.456 | Acc: 40.656,62.389,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.452 | Acc: 40.643,62.438,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.458 | Acc: 40.664,62.320,71.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.464 | Acc: 40.733,62.218,71.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.468 | Acc: 40.705,62.184,71.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.469 | Acc: 40.797,62.254,71.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.668 | Acc: 33.594,46.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.834 | Acc: 28.943,45.424,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.998 | Acc: 28.639,44.493,55.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.016 | Acc: 28.304,44.634,54.393,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 4.247 | Acc: 48.438,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.356 | Acc: 42.336,62.946,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.371 | Acc: 41.406,62.919,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.374 | Acc: 41.086,62.756,73.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.373 | Acc: 40.982,62.857,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.393 | Acc: 40.880,63.127,73.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.401 | Acc: 40.735,62.952,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.419 | Acc: 40.658,62.683,73.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.405 | Acc: 40.906,62.772,73.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.418 | Acc: 40.875,62.634,73.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.422 | Acc: 40.862,62.706,73.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.430 | Acc: 40.784,62.571,72.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.432 | Acc: 40.829,62.597,72.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.440 | Acc: 40.826,62.587,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.440 | Acc: 40.931,62.589,72.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.446 | Acc: 40.872,62.518,72.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.449 | Acc: 40.900,62.422,72.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.459 | Acc: 40.895,62.365,72.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.467 | Acc: 40.889,62.329,72.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.466 | Acc: 40.890,62.299,72.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.622 | Acc: 28.906,50.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.615 | Acc: 28.423,48.363,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.704 | Acc: 28.258,47.618,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.713 | Acc: 27.510,47.900,57.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.104 | Acc: 40.625,62.500,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.397 | Acc: 40.253,62.388,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.427 | Acc: 40.072,62.100,72.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.421 | Acc: 40.612,62.577,72.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.438 | Acc: 40.644,62.278,72.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.428 | Acc: 40.610,62.492,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.451 | Acc: 40.606,62.345,72.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.442 | Acc: 40.736,62.400,72.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.430 | Acc: 40.785,62.563,72.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.438 | Acc: 40.729,62.595,72.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.434 | Acc: 41.010,62.675,72.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.442 | Acc: 40.855,62.641,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.445 | Acc: 40.910,62.704,72.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.442 | Acc: 40.939,62.680,72.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.436 | Acc: 40.986,62.683,72.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.437 | Acc: 40.957,62.715,72.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.444 | Acc: 40.890,62.700,72.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.453 | Acc: 40.792,62.635,72.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.454 | Acc: 40.833,62.574,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.469 | Acc: 40.719,62.422,71.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.929 | Acc: 25.000,49.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.955 | Acc: 22.024,47.396,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.928 | Acc: 22.961,48.571,58.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.929 | Acc: 22.387,48.438,58.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 3.924 | Acc: 50.781,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.351 | Acc: 39.435,63.690,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.338 | Acc: 40.606,63.872,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 40.394,63.435,73.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.428 | Acc: 40.316,63.098,73.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.424 | Acc: 40.555,63.080,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.427 | Acc: 40.702,62.933,72.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.433 | Acc: 40.697,62.927,72.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.434 | Acc: 40.800,62.825,72.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.417 | Acc: 40.871,62.958,72.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.414 | Acc: 40.850,63.036,72.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.404 | Acc: 40.908,63.168,72.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.425 | Acc: 40.771,62.860,72.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.434 | Acc: 40.748,62.730,72.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.439 | Acc: 40.728,62.650,72.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.446 | Acc: 40.692,62.606,72.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.442 | Acc: 40.725,62.573,72.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.446 | Acc: 40.744,62.553,72.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.450 | Acc: 40.805,62.511,72.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.453 | Acc: 40.822,62.479,72.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.003 | Acc: 32.812,53.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.247 | Acc: 33.333,46.801,57.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.332 | Acc: 33.194,46.303,56.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.344 | Acc: 32.710,46.427,56.250,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 3.746 | Acc: 37.500,65.625,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.278 | Acc: 42.113,63.356,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.355 | Acc: 41.235,63.357,73.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.351 | Acc: 40.715,63.627,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.381 | Acc: 40.326,63.551,73.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.374 | Acc: 40.540,63.366,72.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.369 | Acc: 40.838,63.262,72.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.383 | Acc: 40.769,63.248,72.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.393 | Acc: 40.945,62.985,72.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.403 | Acc: 40.936,62.837,72.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.416 | Acc: 40.893,62.679,72.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.413 | Acc: 40.851,62.624,72.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.414 | Acc: 41.011,62.727,72.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.422 | Acc: 40.876,62.674,72.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.422 | Acc: 40.911,62.622,72.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.418 | Acc: 40.895,62.669,72.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.424 | Acc: 40.915,62.617,72.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.434 | Acc: 40.792,62.557,72.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.437 | Acc: 40.800,62.545,72.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.440 | Acc: 40.812,62.600,72.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.990 | Acc: 30.469,52.344,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.352 | Acc: 29.353,51.116,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.354 | Acc: 29.516,50.343,58.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.351 | Acc: 29.342,50.730,58.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 4.457 | Acc: 45.312,60.156,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.487 | Acc: 38.728,62.054,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.368 | Acc: 40.034,63.624,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.343 | Acc: 40.625,63.627,74.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.343 | Acc: 40.770,63.667,73.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.354 | Acc: 40.996,63.490,73.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.390 | Acc: 40.838,63.210,73.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.391 | Acc: 40.703,63.093,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.390 | Acc: 40.911,63.053,72.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.402 | Acc: 41.022,63.018,72.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.408 | Acc: 40.963,62.928,72.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.409 | Acc: 40.964,62.942,72.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.407 | Acc: 41.008,62.989,72.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.417 | Acc: 41.029,62.976,72.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.423 | Acc: 40.925,63.017,72.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.424 | Acc: 41.014,62.946,72.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.425 | Acc: 41.027,62.853,72.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.428 | Acc: 41.102,62.828,72.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.426 | Acc: 41.105,62.848,72.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.429 | Acc: 41.134,62.783,72.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.328 | Acc: 28.906,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.908 | Acc: 31.399,50.335,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.939 | Acc: 31.383,51.239,58.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.941 | Acc: 31.096,51.729,59.234,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 4.722 | Acc: 35.156,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.310 | Acc: 41.332,62.946,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.332 | Acc: 41.025,63.034,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.380 | Acc: 40.740,62.910,73.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.388 | Acc: 40.673,63.088,73.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.384 | Acc: 40.934,63.335,73.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.385 | Acc: 40.967,63.146,72.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.384 | Acc: 40.791,62.971,72.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.391 | Acc: 40.848,62.738,72.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.392 | Acc: 40.953,62.768,72.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.399 | Acc: 40.905,62.784,72.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.401 | Acc: 40.883,62.737,72.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.413 | Acc: 40.787,62.617,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.418 | Acc: 40.790,62.566,72.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.417 | Acc: 40.859,62.650,72.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.424 | Acc: 40.796,62.601,72.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.435 | Acc: 40.679,62.468,72.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.437 | Acc: 40.650,62.530,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.440 | Acc: 40.629,62.472,72.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.437 | Acc: 40.672,62.521,72.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.610 | Acc: 34.375,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.165 | Acc: 29.167,50.632,58.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.137 | Acc: 29.421,51.772,59.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.103 | Acc: 29.175,51.831,59.311,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 3.660 | Acc: 50.781,67.969,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.400 | Acc: 40.365,62.277,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.442 | Acc: 40.339,62.329,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.445 | Acc: 40.510,62.257,72.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.399 | Acc: 40.712,62.529,73.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.380 | Acc: 41.089,62.601,73.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.378 | Acc: 40.941,62.577,73.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.382 | Acc: 40.847,62.699,73.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.380 | Acc: 40.863,62.874,73.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.379 | Acc: 40.875,62.949,73.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.380 | Acc: 40.963,62.861,73.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.372 | Acc: 41.014,63.013,73.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.384 | Acc: 41.089,63.015,72.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.390 | Acc: 41.137,63.018,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.393 | Acc: 41.137,62.970,72.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.402 | Acc: 41.084,62.949,72.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.406 | Acc: 41.022,62.948,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.408 | Acc: 41.035,62.979,72.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.416 | Acc: 41.038,62.866,72.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.413 | Acc: 41.099,62.865,72.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.990 | Acc: 32.031,52.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.355 | Acc: 29.985,47.061,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.394 | Acc: 30.126,47.142,57.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.351 | Acc: 30.046,47.682,57.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.265 | Acc: 50.000,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.221 | Acc: 42.411,64.769,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.275 | Acc: 41.768,64.024,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.308 | Acc: 41.406,63.448,73.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.292 | Acc: 41.705,63.638,73.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.315 | Acc: 41.290,63.537,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.324 | Acc: 41.477,63.707,73.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.338 | Acc: 41.656,63.664,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.351 | Acc: 41.329,63.577,73.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.360 | Acc: 41.333,63.450,73.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.366 | Acc: 41.492,63.410,72.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.383 | Acc: 41.265,63.211,72.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.393 | Acc: 41.186,63.155,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.388 | Acc: 41.310,63.159,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.397 | Acc: 41.242,63.062,72.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.397 | Acc: 41.292,63.115,72.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.402 | Acc: 41.309,63.070,72.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.401 | Acc: 41.283,63.135,72.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.408 | Acc: 41.240,62.946,72.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.411 | Acc: 41.201,62.888,72.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.602 | Acc: 33.594,56.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.010 | Acc: 32.180,51.525,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.006 | Acc: 32.527,50.514,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.983 | Acc: 32.659,50.948,58.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 4.353 | Acc: 38.281,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.330 | Acc: 41.815,63.876,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.292 | Acc: 42.340,64.444,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 42.008,63.858,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.300 | Acc: 41.879,64.053,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.329 | Acc: 41.824,63.707,73.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.324 | Acc: 41.652,63.688,73.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.347 | Acc: 41.451,63.414,73.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.352 | Acc: 41.445,63.335,73.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.370 | Acc: 41.350,63.044,72.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.371 | Acc: 41.375,63.071,72.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.376 | Acc: 41.328,62.981,72.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.381 | Acc: 41.199,62.944,72.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.381 | Acc: 41.107,62.910,72.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.382 | Acc: 41.120,63.009,72.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.391 | Acc: 41.064,62.913,72.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.394 | Acc: 41.090,62.894,72.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.397 | Acc: 41.079,62.938,72.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.402 | Acc: 40.997,62.866,72.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.408 | Acc: 40.976,62.861,72.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.958 | Acc: 28.906,51.562,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.978 | Acc: 28.869,45.908,56.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.109 | Acc: 28.830,45.160,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.165 | Acc: 28.471,45.184,55.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 4.469 | Acc: 42.188,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.394 | Acc: 39.546,63.914,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.404 | Acc: 40.168,63.281,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.360 | Acc: 41.150,63.409,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.356 | Acc: 41.416,63.329,73.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.353 | Acc: 41.429,63.653,73.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.348 | Acc: 41.619,63.546,73.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.339 | Acc: 41.672,63.619,73.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.365 | Acc: 41.464,63.403,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.380 | Acc: 41.290,63.169,73.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.377 | Acc: 41.363,63.227,73.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.391 | Acc: 41.240,63.115,72.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.406 | Acc: 41.209,62.999,72.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.406 | Acc: 41.340,62.988,72.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.408 | Acc: 41.328,62.978,72.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.411 | Acc: 41.344,62.988,72.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.420 | Acc: 41.299,62.863,72.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.422 | Acc: 41.342,62.786,72.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.425 | Acc: 41.356,62.773,72.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.427 | Acc: 41.343,62.775,72.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.069 | Acc: 35.938,53.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.904 | Acc: 32.812,51.339,61.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.963 | Acc: 33.022,51.372,60.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.977 | Acc: 32.569,51.447,59.926,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 4.052 | Acc: 42.188,64.062,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.293 | Acc: 41.034,63.616,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.316 | Acc: 41.559,64.139,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.333 | Acc: 41.329,63.909,74.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.319 | Acc: 41.358,64.091,74.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.349 | Acc: 41.561,63.629,73.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.352 | Acc: 41.535,63.649,73.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.338 | Acc: 41.678,63.713,73.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.325 | Acc: 41.702,63.776,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.338 | Acc: 41.695,63.527,73.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.347 | Acc: 41.597,63.398,73.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.340 | Acc: 41.583,63.529,73.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.352 | Acc: 41.491,63.466,73.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.373 | Acc: 41.322,63.287,73.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.380 | Acc: 41.362,63.251,73.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.384 | Acc: 41.417,63.177,72.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.393 | Acc: 41.404,63.072,72.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.396 | Acc: 41.402,62.995,72.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.391 | Acc: 41.443,63.078,72.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.400 | Acc: 41.349,62.957,72.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.777 | Acc: 24.219,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.706 | Acc: 27.716,47.991,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.699 | Acc: 27.649,47.675,57.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.664 | Acc: 27.254,48.271,57.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 4.216 | Acc: 40.625,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.362 | Acc: 42.522,62.760,73.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.332 | Acc: 42.073,63.205,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.341 | Acc: 41.739,63.115,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.328 | Acc: 41.657,63.455,73.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.324 | Acc: 41.422,63.312,73.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.325 | Acc: 41.593,63.249,73.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.330 | Acc: 41.617,63.337,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.336 | Acc: 41.702,63.310,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.373 | Acc: 41.333,62.979,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.369 | Acc: 41.402,63.044,72.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.381 | Acc: 41.300,62.914,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.389 | Acc: 41.312,62.944,72.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.382 | Acc: 41.218,63.027,72.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.379 | Acc: 41.195,63.095,72.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.384 | Acc: 41.206,63.071,72.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.381 | Acc: 41.209,63.155,72.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.386 | Acc: 41.228,63.125,72.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.394 | Acc: 41.183,63.032,72.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.403 | Acc: 41.076,62.908,72.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.045 | Acc: 37.500,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.019 | Acc: 32.812,51.600,60.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.005 | Acc: 32.984,50.972,59.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.980 | Acc: 32.736,50.935,59.874,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 4.393 | Acc: 39.062,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.237 | Acc: 42.336,64.360,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.262 | Acc: 41.825,64.139,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.309 | Acc: 41.265,63.806,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.349 | Acc: 40.953,63.368,73.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.360 | Acc: 41.004,63.343,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.350 | Acc: 41.284,63.527,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.338 | Acc: 41.739,63.614,73.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.338 | Acc: 41.528,63.568,73.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.339 | Acc: 41.402,63.704,73.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.347 | Acc: 41.375,63.678,73.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.348 | Acc: 41.502,63.776,73.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.358 | Acc: 41.445,63.729,73.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.365 | Acc: 41.514,63.611,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.362 | Acc: 41.473,63.615,73.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.375 | Acc: 41.354,63.512,72.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.381 | Acc: 41.306,63.427,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.381 | Acc: 41.246,63.458,72.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.386 | Acc: 41.153,63.368,72.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.386 | Acc: 41.154,63.380,72.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.871 | Acc: 35.156,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.800 | Acc: 34.301,52.939,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.814 | Acc: 33.670,53.144,59.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.834 | Acc: 33.299,53.087,59.477,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 4.386 | Acc: 41.406,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.291 | Acc: 41.257,63.616,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.260 | Acc: 41.864,63.891,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.318 | Acc: 41.150,63.332,74.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.339 | Acc: 41.098,63.320,73.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.347 | Acc: 41.050,63.188,73.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.338 | Acc: 41.219,63.230,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.351 | Acc: 41.273,63.109,73.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.341 | Acc: 41.280,63.228,73.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.358 | Acc: 40.983,63.078,73.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.356 | Acc: 41.060,63.130,73.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.353 | Acc: 41.092,63.044,73.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.353 | Acc: 41.137,63.139,73.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.351 | Acc: 41.164,63.138,73.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.365 | Acc: 41.170,63.112,72.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.365 | Acc: 41.201,63.102,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.369 | Acc: 41.265,63.035,72.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.370 | Acc: 41.244,63.073,72.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.378 | Acc: 41.281,63.056,72.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.387 | Acc: 41.248,62.984,72.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.476 | Acc: 35.156,56.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.105 | Acc: 32.887,50.558,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.167 | Acc: 32.508,50.114,57.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.180 | Acc: 32.262,49.949,56.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 4.258 | Acc: 43.750,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.323 | Acc: 41.481,63.207,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.363 | Acc: 41.006,63.091,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.369 | Acc: 41.137,63.166,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.344 | Acc: 41.069,63.272,73.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.368 | Acc: 41.190,62.755,73.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.351 | Acc: 41.193,62.739,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.336 | Acc: 41.168,63.143,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.321 | Acc: 41.183,63.276,73.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.346 | Acc: 41.044,63.018,73.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.348 | Acc: 41.227,63.029,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.346 | Acc: 41.360,63.104,73.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.345 | Acc: 41.358,63.184,73.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.363 | Acc: 41.242,63.087,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.367 | Acc: 41.214,63.012,73.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.371 | Acc: 41.238,63.027,72.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.373 | Acc: 41.328,62.972,72.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.379 | Acc: 41.393,62.942,72.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.377 | Acc: 41.369,62.965,72.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.373 | Acc: 41.474,62.970,72.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.722 | Acc: 38.281,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.831 | Acc: 34.821,53.237,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.867 | Acc: 33.861,52.325,58.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.873 | Acc: 33.760,52.318,58.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 4.130 | Acc: 40.625,59.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.328 | Acc: 39.993,62.463,73.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.307 | Acc: 41.330,63.491,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.315 | Acc: 41.496,63.268,73.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.285 | Acc: 41.889,63.735,73.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.281 | Acc: 41.863,63.776,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.256 | Acc: 42.323,64.153,73.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.274 | Acc: 42.071,63.985,73.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.286 | Acc: 41.858,63.834,73.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.290 | Acc: 41.903,63.739,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.298 | Acc: 41.845,63.689,73.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.306 | Acc: 41.799,63.787,73.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.311 | Acc: 41.798,63.797,73.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.310 | Acc: 41.864,63.769,73.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.320 | Acc: 41.754,63.707,73.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.336 | Acc: 41.666,63.616,73.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.337 | Acc: 41.740,63.603,73.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.339 | Acc: 41.683,63.563,73.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.343 | Acc: 41.640,63.487,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.347 | Acc: 41.591,63.484,73.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.167 | Acc: 30.469,48.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.986 | Acc: 27.046,46.801,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.062 | Acc: 26.601,47.180,55.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.009 | Acc: 26.473,47.900,55.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 4.375 | Acc: 39.062,60.938,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.147 | Acc: 41.927,64.844,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.193 | Acc: 41.635,64.177,75.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.231 | Acc: 41.470,64.613,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.259 | Acc: 41.435,64.082,74.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.262 | Acc: 41.298,64.240,74.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.265 | Acc: 41.426,64.295,74.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.287 | Acc: 41.323,64.018,74.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.290 | Acc: 41.348,63.951,74.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.301 | Acc: 41.441,63.847,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.306 | Acc: 41.395,63.787,73.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.320 | Acc: 41.300,63.592,73.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.319 | Acc: 41.348,63.622,73.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.331 | Acc: 41.272,63.512,73.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.339 | Acc: 41.273,63.420,73.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.348 | Acc: 41.256,63.279,73.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.348 | Acc: 41.282,63.298,73.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.353 | Acc: 41.234,63.322,73.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.357 | Acc: 41.300,63.348,73.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.362 | Acc: 41.314,63.275,72.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.924 | Acc: 39.062,53.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.742 | Acc: 35.156,52.493,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.796 | Acc: 35.156,51.982,60.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.792 | Acc: 34.900,51.998,60.694,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 4.181 | Acc: 39.062,61.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.212 | Acc: 42.969,64.100,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.241 | Acc: 42.759,64.158,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.261 | Acc: 42.354,64.280,74.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.265 | Acc: 42.438,64.304,74.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.259 | Acc: 41.986,64.534,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.275 | Acc: 41.852,64.314,74.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.286 | Acc: 41.855,64.201,74.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.300 | Acc: 41.785,64.126,74.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.304 | Acc: 41.803,64.028,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.294 | Acc: 41.943,64.144,74.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.301 | Acc: 41.919,64.017,74.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.313 | Acc: 41.747,63.904,74.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.313 | Acc: 41.804,63.949,73.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.317 | Acc: 41.879,63.893,73.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.325 | Acc: 41.873,63.774,73.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.331 | Acc: 41.715,63.710,73.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.335 | Acc: 41.667,63.641,73.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.338 | Acc: 41.651,63.647,73.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.342 | Acc: 41.671,63.695,73.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.920 | Acc: 35.938,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.173 | Acc: 34.375,49.591,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.225 | Acc: 33.460,48.609,56.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.199 | Acc: 33.299,48.617,56.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 5.092 | Acc: 35.156,57.031,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.356 | Acc: 40.811,63.393,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.354 | Acc: 41.521,63.834,73.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.354 | Acc: 41.150,64.037,73.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.368 | Acc: 41.464,63.879,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.363 | Acc: 41.213,63.738,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.352 | Acc: 41.439,63.740,73.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.341 | Acc: 41.406,63.652,73.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.325 | Acc: 41.610,63.776,73.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.328 | Acc: 41.566,63.601,73.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.330 | Acc: 41.476,63.581,73.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.327 | Acc: 41.555,63.578,73.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.326 | Acc: 41.500,63.579,73.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.330 | Acc: 41.496,63.587,73.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.338 | Acc: 41.362,63.404,73.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.351 | Acc: 41.230,63.369,73.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.352 | Acc: 41.302,63.376,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.353 | Acc: 41.276,63.387,73.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.345 | Acc: 41.400,63.476,73.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.346 | Acc: 41.361,63.486,73.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.618 | Acc: 32.812,51.562,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.892 | Acc: 32.589,51.674,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.914 | Acc: 32.489,51.524,60.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.931 | Acc: 32.006,51.345,59.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 4.118 | Acc: 40.625,62.500,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.317 | Acc: 40.290,63.542,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.283 | Acc: 40.606,64.005,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.221 | Acc: 41.048,64.831,74.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.222 | Acc: 41.474,64.776,74.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.230 | Acc: 41.801,64.720,74.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.252 | Acc: 41.742,64.469,74.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.276 | Acc: 41.656,64.190,74.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.286 | Acc: 41.528,63.941,73.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.280 | Acc: 41.726,63.985,73.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.302 | Acc: 41.737,63.822,73.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.313 | Acc: 41.763,63.769,73.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.322 | Acc: 41.753,63.748,73.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.319 | Acc: 41.855,63.808,73.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.322 | Acc: 41.873,63.765,73.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.329 | Acc: 41.840,63.712,72.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.338 | Acc: 41.703,63.566,72.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.348 | Acc: 41.603,63.538,72.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.349 | Acc: 41.579,63.504,72.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.352 | Acc: 41.540,63.513,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.591 | Acc: 36.719,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.249 | Acc: 33.705,49.740,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.191 | Acc: 33.613,49.466,58.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.165 | Acc: 33.171,49.424,58.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.128 | Acc: 37.500,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.196 | Acc: 41.853,65.513,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.173 | Acc: 41.959,64.901,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.187 | Acc: 42.047,64.818,74.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.232 | Acc: 41.831,64.689,74.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.248 | Acc: 41.940,64.217,74.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.253 | Acc: 41.774,64.004,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.247 | Acc: 41.971,64.057,74.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.260 | Acc: 41.833,63.936,74.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.271 | Acc: 41.859,63.881,74.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.276 | Acc: 41.807,63.740,73.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.280 | Acc: 41.845,63.734,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.289 | Acc: 41.727,63.602,73.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.304 | Acc: 41.634,63.497,73.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.302 | Acc: 41.701,63.548,73.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.305 | Acc: 41.731,63.497,73.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.303 | Acc: 41.625,63.517,73.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.317 | Acc: 41.512,63.380,73.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.326 | Acc: 41.491,63.327,73.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.331 | Acc: 41.468,63.255,73.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.215 | Acc: 35.156,52.344,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.057 | Acc: 32.292,51.525,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.098 | Acc: 31.898,50.267,58.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.087 | Acc: 31.942,50.551,58.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 4.704 | Acc: 33.594,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.219 | Acc: 41.853,63.690,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.274 | Acc: 41.635,63.758,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.244 | Acc: 42.431,64.088,74.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.243 | Acc: 42.294,64.169,74.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.241 | Acc: 42.288,64.256,74.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.247 | Acc: 42.142,64.288,74.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.251 | Acc: 42.171,64.240,74.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.249 | Acc: 42.023,64.242,74.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.260 | Acc: 41.907,64.106,73.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.253 | Acc: 42.075,64.191,74.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.259 | Acc: 41.908,64.165,74.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.261 | Acc: 41.931,64.173,73.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.278 | Acc: 41.795,64.006,73.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.277 | Acc: 41.759,64.021,73.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.290 | Acc: 41.700,63.847,73.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.302 | Acc: 41.720,63.785,73.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.311 | Acc: 41.651,63.641,73.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.314 | Acc: 41.636,63.597,73.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.326 | Acc: 41.574,63.505,73.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.426 | Acc: 28.906,49.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.039 | Acc: 27.381,47.098,54.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.064 | Acc: 26.848,47.771,54.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.043 | Acc: 26.178,47.695,55.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 4.491 | Acc: 39.062,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.130 | Acc: 41.815,65.551,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.177 | Acc: 42.607,64.844,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.222 | Acc: 42.316,64.728,74.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.207 | Acc: 42.525,64.680,74.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.253 | Acc: 42.087,64.418,74.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.259 | Acc: 42.155,64.179,74.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.256 | Acc: 42.160,64.279,74.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.244 | Acc: 42.348,64.557,74.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.250 | Acc: 42.339,64.416,74.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.237 | Acc: 42.397,64.405,74.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.249 | Acc: 42.371,64.321,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.257 | Acc: 42.327,64.257,74.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.276 | Acc: 42.143,64.030,73.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.286 | Acc: 42.079,63.923,73.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.294 | Acc: 42.037,63.857,73.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.296 | Acc: 42.039,63.826,73.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.301 | Acc: 41.968,63.744,73.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.310 | Acc: 41.915,63.660,73.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.319 | Acc: 41.866,63.574,73.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.428 | Acc: 33.594,56.250,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.487 | Acc: 31.101,48.475,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.532 | Acc: 31.098,47.561,54.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.540 | Acc: 30.776,47.554,54.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 4.030 | Acc: 40.625,62.500,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.294 | Acc: 40.960,63.021,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.244 | Acc: 41.540,63.662,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.256 | Acc: 41.970,63.601,74.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.261 | Acc: 42.024,63.686,74.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.269 | Acc: 42.002,63.954,74.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.283 | Acc: 41.903,64.069,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.285 | Acc: 41.971,64.040,73.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.302 | Acc: 41.998,63.781,73.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.310 | Acc: 41.773,63.527,73.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.313 | Acc: 41.842,63.619,73.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.324 | Acc: 41.558,63.507,73.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.316 | Acc: 41.740,63.544,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.309 | Acc: 41.831,63.545,73.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.314 | Acc: 41.776,63.431,73.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.322 | Acc: 41.692,63.434,73.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.321 | Acc: 41.701,63.444,73.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.323 | Acc: 41.686,63.426,73.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.320 | Acc: 41.753,63.506,73.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.315 | Acc: 41.798,63.574,73.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.469 | Acc: 28.906,56.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.779 | Acc: 25.967,46.838,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.753 | Acc: 26.448,47.523,57.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.768 | Acc: 25.794,47.029,57.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 4.874 | Acc: 35.938,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.318 | Acc: 40.476,64.137,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.272 | Acc: 40.854,65.034,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.236 | Acc: 41.470,65.177,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.223 | Acc: 42.072,64.796,74.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.238 | Acc: 42.304,64.387,74.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.223 | Acc: 42.368,64.527,74.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.205 | Acc: 42.537,64.694,74.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.211 | Acc: 42.493,64.538,74.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.239 | Acc: 42.183,64.166,74.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.244 | Acc: 42.121,64.269,74.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.261 | Acc: 42.035,64.204,73.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.267 | Acc: 41.899,64.150,73.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.269 | Acc: 41.882,64.131,73.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.281 | Acc: 41.904,63.993,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.278 | Acc: 41.894,64.073,73.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.283 | Acc: 41.791,63.989,73.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.300 | Acc: 41.624,63.721,73.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.299 | Acc: 41.655,63.705,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.306 | Acc: 41.599,63.632,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.464 | Acc: 32.031,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.037 | Acc: 28.237,45.536,55.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.042 | Acc: 28.182,45.236,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.062 | Acc: 27.651,45.364,55.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 3.770 | Acc: 44.531,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.147 | Acc: 41.146,65.960,76.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.099 | Acc: 42.188,65.816,76.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.141 | Acc: 42.636,65.523,75.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.119 | Acc: 43.191,65.529,75.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.145 | Acc: 42.636,65.277,75.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.177 | Acc: 42.207,64.676,75.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.203 | Acc: 42.021,64.461,74.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.213 | Acc: 42.013,64.392,74.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.222 | Acc: 42.023,64.265,74.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.218 | Acc: 42.044,64.307,74.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.226 | Acc: 42.110,64.215,74.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.244 | Acc: 42.064,64.108,74.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.254 | Acc: 42.065,64.000,74.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.273 | Acc: 42.079,63.910,73.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.277 | Acc: 42.032,63.886,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.285 | Acc: 41.959,63.824,73.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.291 | Acc: 41.784,63.824,73.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.300 | Acc: 41.716,63.729,73.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.314 | Acc: 41.673,63.618,73.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.688 | Acc: 39.844,50.000,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.954 | Acc: 34.040,50.521,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.946 | Acc: 33.708,50.629,59.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.940 | Acc: 33.350,50.973,58.952,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 4.180 | Acc: 47.656,64.062,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.226 | Acc: 43.452,62.798,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.233 | Acc: 42.702,64.158,75.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.193 | Acc: 42.661,64.741,75.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.199 | Acc: 42.679,64.747,75.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.190 | Acc: 42.690,65.006,75.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.208 | Acc: 42.368,64.657,75.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.210 | Acc: 42.509,64.417,74.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.215 | Acc: 42.459,64.368,74.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.223 | Acc: 42.421,64.369,74.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.225 | Acc: 42.324,64.237,74.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.241 | Acc: 42.279,64.183,74.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.256 | Acc: 42.119,63.965,74.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.257 | Acc: 42.140,64.051,74.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.266 | Acc: 42.093,63.974,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.280 | Acc: 41.975,63.860,73.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.278 | Acc: 42.010,63.919,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.282 | Acc: 42.066,63.845,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.292 | Acc: 41.969,63.773,73.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.298 | Acc: 41.915,63.693,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.787 | Acc: 28.906,54.688,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.926 | Acc: 29.018,47.396,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.909 | Acc: 29.021,47.561,56.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.905 | Acc: 28.689,47.951,56.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 3.510 | Acc: 49.219,70.312,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.072 | Acc: 43.676,65.699,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.117 | Acc: 43.159,65.358,75.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.138 | Acc: 42.994,65.318,75.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.152 | Acc: 42.959,65.210,74.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.150 | Acc: 42.814,65.029,74.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.171 | Acc: 42.543,64.728,74.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.195 | Acc: 42.420,64.511,74.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.215 | Acc: 42.289,64.528,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.215 | Acc: 42.425,64.373,74.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.221 | Acc: 42.417,64.478,74.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.224 | Acc: 42.435,64.490,74.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.236 | Acc: 42.408,64.422,74.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.242 | Acc: 42.289,64.302,74.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.248 | Acc: 42.274,64.199,74.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.254 | Acc: 42.294,64.135,74.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.256 | Acc: 42.334,64.172,74.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.269 | Acc: 42.233,64.042,73.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.277 | Acc: 42.164,63.972,73.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.290 | Acc: 42.038,63.866,73.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.635 | Acc: 35.156,55.469,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.660 | Acc: 29.278,48.586,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.654 | Acc: 29.230,48.266,57.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.653 | Acc: 28.765,48.245,57.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 4.030 | Acc: 42.188,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.154 | Acc: 41.667,65.290,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.171 | Acc: 41.787,64.901,76.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.172 | Acc: 41.752,65.279,75.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.237 | Acc: 41.397,64.882,75.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.250 | Acc: 41.275,64.689,75.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.249 | Acc: 41.387,64.598,74.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.241 | Acc: 41.650,64.495,74.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.267 | Acc: 41.552,64.242,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.255 | Acc: 41.769,64.429,74.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.250 | Acc: 41.962,64.397,74.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.254 | Acc: 42.064,64.275,74.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.264 | Acc: 42.116,64.150,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.266 | Acc: 42.086,64.104,74.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.268 | Acc: 42.040,64.068,74.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.276 | Acc: 41.936,63.959,73.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.280 | Acc: 41.964,63.999,73.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.295 | Acc: 41.837,63.785,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.300 | Acc: 41.768,63.734,73.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.299 | Acc: 41.837,63.747,73.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.931 | Acc: 34.375,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.028 | Acc: 32.738,50.818,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.994 | Acc: 31.993,51.029,60.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.991 | Acc: 31.468,51.396,60.284,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 4.098 | Acc: 42.969,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.205 | Acc: 41.964,64.844,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.177 | Acc: 42.645,64.768,75.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.209 | Acc: 41.842,64.831,74.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.218 | Acc: 41.946,64.728,74.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.211 | Acc: 41.994,64.735,74.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.208 | Acc: 41.936,64.663,74.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.234 | Acc: 41.717,64.445,74.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.225 | Acc: 41.765,64.650,74.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.235 | Acc: 41.639,64.473,74.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.250 | Acc: 41.562,64.331,74.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.248 | Acc: 41.746,64.352,74.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.255 | Acc: 41.730,64.212,74.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.250 | Acc: 41.771,64.245,74.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.249 | Acc: 41.929,64.190,74.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.254 | Acc: 41.910,64.122,74.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.263 | Acc: 41.898,64.058,73.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.268 | Acc: 41.853,64.005,73.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.270 | Acc: 41.859,63.985,73.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.270 | Acc: 41.923,63.993,73.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.475 | Acc: 32.031,53.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.383 | Acc: 28.683,50.372,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.335 | Acc: 29.535,50.381,59.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.310 | Acc: 29.073,50.243,59.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 3.546 | Acc: 46.094,68.750,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.090 | Acc: 42.746,65.290,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.087 | Acc: 43.540,65.282,75.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.131 | Acc: 43.225,64.921,75.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.145 | Acc: 42.959,65.056,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.172 | Acc: 42.621,64.550,74.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.164 | Acc: 42.801,64.928,75.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.184 | Acc: 42.559,64.705,74.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.199 | Acc: 42.396,64.587,74.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.218 | Acc: 42.226,64.542,74.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.217 | Acc: 42.153,64.405,74.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.229 | Acc: 41.997,64.324,74.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.233 | Acc: 42.016,64.263,74.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.238 | Acc: 42.035,64.233,74.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.247 | Acc: 42.048,64.252,74.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.258 | Acc: 41.925,64.179,74.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.259 | Acc: 41.908,64.182,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.264 | Acc: 41.880,64.168,74.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.272 | Acc: 41.787,64.088,73.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.277 | Acc: 41.794,64.009,73.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.864 | Acc: 32.812,42.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.321 | Acc: 21.391,35.603,50.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.229 | Acc: 20.865,36.585,49.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.140 | Acc: 20.530,36.744,49.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 4.512 | Acc: 33.594,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.217 | Acc: 43.080,64.583,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.265 | Acc: 42.473,64.577,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.251 | Acc: 42.905,64.344,74.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.224 | Acc: 42.718,64.699,74.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.247 | Acc: 42.443,64.890,74.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.244 | Acc: 42.536,64.786,74.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.242 | Acc: 42.570,64.777,74.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.256 | Acc: 42.188,64.519,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.266 | Acc: 42.006,64.408,74.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.266 | Acc: 42.048,64.358,74.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.274 | Acc: 42.057,64.239,74.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.280 | Acc: 42.012,64.079,74.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.282 | Acc: 42.035,64.054,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.286 | Acc: 42.004,63.926,73.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.288 | Acc: 42.011,63.917,73.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.299 | Acc: 41.915,63.841,73.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.298 | Acc: 41.917,63.918,73.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.298 | Acc: 41.917,63.928,73.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.292 | Acc: 41.984,64.044,73.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.212 | Acc: 35.938,51.562,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.195 | Acc: 33.222,51.637,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.220 | Acc: 32.736,50.934,58.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.192 | Acc: 32.979,50.935,58.120,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 4.616 | Acc: 39.062,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.171 | Acc: 41.704,65.848,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.143 | Acc: 41.521,65.816,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.109 | Acc: 41.816,65.830,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.142 | Acc: 42.120,65.326,75.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.174 | Acc: 41.839,64.921,75.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.195 | Acc: 41.884,64.863,74.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.204 | Acc: 41.755,64.644,74.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.213 | Acc: 41.673,64.514,74.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.224 | Acc: 41.695,64.278,74.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.219 | Acc: 41.768,64.346,74.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.217 | Acc: 41.830,64.388,74.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.226 | Acc: 41.915,64.341,74.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.223 | Acc: 41.927,64.458,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.229 | Acc: 42.004,64.349,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.232 | Acc: 42.060,64.242,74.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.235 | Acc: 42.095,64.272,74.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.240 | Acc: 42.041,64.225,74.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.245 | Acc: 41.984,64.160,74.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.247 | Acc: 41.935,64.171,74.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.456 | Acc: 47.656,57.812,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.011 | Acc: 33.854,51.674,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.059 | Acc: 32.927,51.734,60.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.028 | Acc: 32.351,51.844,60.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 3.894 | Acc: 42.188,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.062 | Acc: 42.039,66.518,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.076 | Acc: 42.797,66.216,75.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.101 | Acc: 42.495,66.060,75.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.130 | Acc: 41.985,65.741,75.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.132 | Acc: 42.056,65.563,75.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.146 | Acc: 42.097,65.457,75.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.152 | Acc: 42.143,65.453,74.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.166 | Acc: 42.144,65.368,74.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.176 | Acc: 42.222,65.137,74.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.183 | Acc: 42.292,64.960,74.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.189 | Acc: 42.212,64.999,74.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.193 | Acc: 42.252,64.879,74.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.200 | Acc: 42.170,64.913,74.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.213 | Acc: 42.179,64.738,74.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.220 | Acc: 42.224,64.696,74.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.225 | Acc: 42.192,64.686,74.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.230 | Acc: 42.133,64.555,74.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.238 | Acc: 42.112,64.404,74.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.249 | Acc: 42.042,64.259,73.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.676 | Acc: 31.250,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.608 | Acc: 30.878,50.260,54.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.702 | Acc: 30.240,49.714,53.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.737 | Acc: 30.072,49.821,53.714,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 3.879 | Acc: 45.312,68.750,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.178 | Acc: 42.560,65.551,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.227 | Acc: 41.711,64.672,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.174 | Acc: 42.418,64.985,75.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.197 | Acc: 42.342,64.506,75.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.197 | Acc: 41.986,64.503,74.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.196 | Acc: 42.207,64.676,74.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.203 | Acc: 42.287,64.655,74.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.203 | Acc: 42.372,64.587,74.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.215 | Acc: 42.183,64.637,74.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.218 | Acc: 41.970,64.529,74.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.212 | Acc: 42.035,64.533,74.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.211 | Acc: 42.093,64.507,74.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.228 | Acc: 41.912,64.383,74.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.230 | Acc: 41.918,64.404,74.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.232 | Acc: 42.019,64.364,74.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.242 | Acc: 41.961,64.325,74.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.243 | Acc: 41.952,64.342,74.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.255 | Acc: 41.949,64.225,73.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.259 | Acc: 41.952,64.157,73.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.002 | Acc: 27.344,43.750,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.854 | Acc: 22.098,45.722,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.787 | Acc: 22.561,46.037,56.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.715 | Acc: 22.221,46.427,56.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 3.933 | Acc: 50.000,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.034 | Acc: 45.126,65.699,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.109 | Acc: 43.559,65.720,76.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.163 | Acc: 43.251,65.074,75.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.161 | Acc: 43.297,64.979,75.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.162 | Acc: 43.441,64.944,75.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.189 | Acc: 42.930,64.773,75.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.217 | Acc: 42.797,64.539,74.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.221 | Acc: 42.590,64.645,74.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.214 | Acc: 42.675,64.637,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.212 | Acc: 42.712,64.653,74.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.227 | Acc: 42.492,64.497,74.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.232 | Acc: 42.528,64.429,74.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.241 | Acc: 42.382,64.269,74.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.242 | Acc: 42.371,64.354,74.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.241 | Acc: 42.416,64.387,74.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.241 | Acc: 42.416,64.325,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.255 | Acc: 42.297,64.143,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.258 | Acc: 42.317,64.093,74.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.259 | Acc: 42.257,64.124,73.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.080 | Acc: 33.594,55.469,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.160 | Acc: 32.850,48.549,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.153 | Acc: 33.861,49.028,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.175 | Acc: 33.414,49.001,58.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 3.393 | Acc: 48.438,78.125,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.054 | Acc: 42.485,66.071,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.140 | Acc: 42.626,65.339,75.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.174 | Acc: 42.341,64.588,75.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.186 | Acc: 42.207,64.439,75.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.191 | Acc: 42.512,64.457,74.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.189 | Acc: 42.420,64.631,74.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.196 | Acc: 42.309,64.578,74.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.202 | Acc: 42.396,64.514,74.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.209 | Acc: 42.252,64.438,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.210 | Acc: 42.281,64.486,74.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.212 | Acc: 42.364,64.533,74.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.219 | Acc: 42.269,64.481,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.217 | Acc: 42.511,64.544,74.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.227 | Acc: 42.371,64.507,73.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.235 | Acc: 42.330,64.441,73.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.239 | Acc: 42.338,64.391,73.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.241 | Acc: 42.414,64.360,73.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.244 | Acc: 42.393,64.357,73.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.245 | Acc: 42.364,64.423,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.297 | Acc: 39.062,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.704 | Acc: 32.366,45.424,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.640 | Acc: 33.098,46.627,54.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.592 | Acc: 32.851,46.837,54.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 4.231 | Acc: 35.938,59.375,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.102 | Acc: 41.964,64.807,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.086 | Acc: 43.350,65.111,75.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.103 | Acc: 42.892,64.933,76.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.107 | Acc: 42.737,64.853,76.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.128 | Acc: 42.969,64.712,76.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.154 | Acc: 42.801,64.534,75.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.156 | Acc: 42.819,64.594,75.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.163 | Acc: 42.687,64.621,75.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.171 | Acc: 42.623,64.606,75.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.178 | Acc: 42.568,64.576,75.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.185 | Acc: 42.636,64.561,74.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.199 | Acc: 42.596,64.575,74.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.210 | Acc: 42.580,64.491,74.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.222 | Acc: 42.443,64.379,74.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.229 | Acc: 42.426,64.299,74.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.237 | Acc: 42.312,64.245,74.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.243 | Acc: 42.242,64.138,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.239 | Acc: 42.311,64.143,74.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.245 | Acc: 42.206,64.120,74.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.199 | Acc: 28.125,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.594 | Acc: 25.223,43.452,54.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.583 | Acc: 24.638,44.264,54.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.561 | Acc: 24.308,44.493,54.214,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 3.862 | Acc: 46.094,65.625,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.257 | Acc: 41.778,64.360,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.164 | Acc: 42.759,65.358,76.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.176 | Acc: 42.239,65.202,75.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.196 | Acc: 41.811,65.095,75.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.191 | Acc: 41.955,65.215,75.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.191 | Acc: 41.852,65.418,75.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.205 | Acc: 41.949,65.160,75.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.207 | Acc: 42.061,65.106,75.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.220 | Acc: 42.067,64.835,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.221 | Acc: 42.211,64.789,75.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.230 | Acc: 42.096,64.625,74.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.230 | Acc: 42.032,64.571,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.219 | Acc: 42.205,64.733,74.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.217 | Acc: 42.196,64.766,74.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.223 | Acc: 42.188,64.514,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.223 | Acc: 42.158,64.503,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.230 | Acc: 42.153,64.447,74.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.236 | Acc: 42.092,64.301,74.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.235 | Acc: 42.095,64.286,74.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.031 | Acc: 25.781,54.688,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.768 | Acc: 28.385,47.173,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.821 | Acc: 27.401,47.656,57.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.852 | Acc: 27.049,47.797,56.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 4.086 | Acc: 39.844,64.844,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.135 | Acc: 42.597,64.695,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.167 | Acc: 42.264,64.367,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.164 | Acc: 42.264,64.447,75.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.123 | Acc: 42.130,64.950,75.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.125 | Acc: 42.180,65.037,75.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.136 | Acc: 42.278,64.973,75.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.150 | Acc: 42.210,64.838,75.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.163 | Acc: 42.168,64.771,75.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.165 | Acc: 42.300,64.624,74.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.176 | Acc: 42.366,64.704,74.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.191 | Acc: 42.223,64.642,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.205 | Acc: 42.162,64.581,74.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.208 | Acc: 42.319,64.640,74.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.207 | Acc: 42.329,64.616,74.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.206 | Acc: 42.413,64.569,74.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.216 | Acc: 42.365,64.452,74.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.221 | Acc: 42.410,64.450,74.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.228 | Acc: 42.322,64.409,74.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.238 | Acc: 42.208,64.257,74.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.295 | Acc: 22.656,41.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.772 | Acc: 21.987,46.689,58.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.789 | Acc: 22.237,46.551,57.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.839 | Acc: 21.939,46.017,57.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 3.570 | Acc: 46.094,68.750,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.032 | Acc: 43.750,65.997,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.084 | Acc: 43.921,65.758,76.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.107 | Acc: 43.648,65.689,76.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.149 | Acc: 42.843,65.172,75.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.173 | Acc: 42.845,64.898,75.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.171 | Acc: 42.936,64.979,75.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.163 | Acc: 42.985,65.132,75.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.172 | Acc: 42.780,65.009,75.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.181 | Acc: 42.662,64.857,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.197 | Acc: 42.428,64.739,75.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.212 | Acc: 42.233,64.646,74.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.218 | Acc: 42.171,64.461,74.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.218 | Acc: 42.074,64.452,74.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.219 | Acc: 42.190,64.413,74.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.221 | Acc: 42.255,64.428,74.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.227 | Acc: 42.253,64.389,74.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.232 | Acc: 42.272,64.333,74.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.233 | Acc: 42.237,64.329,74.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.230 | Acc: 42.265,64.364,74.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.497 | Acc: 36.719,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.130 | Acc: 32.999,50.484,59.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.147 | Acc: 32.508,50.781,58.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.163 | Acc: 32.121,50.832,59.029,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 3.872 | Acc: 46.094,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.133 | Acc: 43.787,65.699,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.159 | Acc: 42.797,65.720,75.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.141 | Acc: 42.687,65.292,75.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.134 | Acc: 43.065,65.056,75.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.143 | Acc: 42.868,65.200,75.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.133 | Acc: 42.904,65.296,75.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.142 | Acc: 42.708,65.137,75.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.157 | Acc: 42.600,64.975,75.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.176 | Acc: 42.403,64.839,75.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.189 | Acc: 42.285,64.844,75.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.193 | Acc: 42.311,64.798,75.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.202 | Acc: 42.311,64.652,74.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.202 | Acc: 42.349,64.613,74.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.210 | Acc: 42.349,64.577,74.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.218 | Acc: 42.320,64.478,74.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.220 | Acc: 42.455,64.498,74.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.220 | Acc: 42.579,64.470,74.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.226 | Acc: 42.560,64.415,74.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.218 | Acc: 42.647,64.497,74.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.664 | Acc: 32.812,46.094,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.406 | Acc: 33.110,47.768,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.427 | Acc: 33.708,48.152,56.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.385 | Acc: 32.851,48.527,56.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 3.585 | Acc: 50.781,71.094,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.014 | Acc: 43.862,66.034,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.017 | Acc: 43.540,66.235,76.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.040 | Acc: 43.379,65.753,76.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.067 | Acc: 43.104,65.548,75.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.073 | Acc: 43.170,65.439,75.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.099 | Acc: 42.898,65.334,75.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.114 | Acc: 42.897,65.270,75.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.132 | Acc: 42.648,65.067,75.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.154 | Acc: 42.321,64.908,75.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.165 | Acc: 42.432,64.817,75.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.174 | Acc: 42.453,64.861,74.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.178 | Acc: 42.470,64.853,74.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.184 | Acc: 42.511,64.790,74.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.185 | Acc: 42.510,64.680,74.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.191 | Acc: 42.447,64.659,74.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.199 | Acc: 42.482,64.617,74.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.206 | Acc: 42.428,64.557,74.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.215 | Acc: 42.389,64.430,74.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.213 | Acc: 42.397,64.458,74.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.401 | Acc: 39.844,46.875,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.656 | Acc: 35.379,43.973,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.672 | Acc: 35.042,44.245,54.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.628 | Acc: 34.823,44.647,55.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 4.196 | Acc: 36.719,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.210 | Acc: 41.815,64.621,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.213 | Acc: 42.111,64.882,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.163 | Acc: 42.623,65.369,75.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.182 | Acc: 42.506,65.143,75.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.161 | Acc: 42.613,65.145,75.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.153 | Acc: 42.465,65.192,75.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.163 | Acc: 42.548,65.143,75.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.176 | Acc: 42.459,64.955,75.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.178 | Acc: 42.373,64.943,75.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.182 | Acc: 42.347,64.739,74.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.188 | Acc: 42.456,64.699,74.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.181 | Acc: 42.482,64.759,74.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.192 | Acc: 42.370,64.643,74.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.198 | Acc: 42.441,64.563,74.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.198 | Acc: 42.463,64.571,74.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.200 | Acc: 42.482,64.574,74.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.199 | Acc: 42.600,64.580,74.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.202 | Acc: 42.614,64.586,74.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.207 | Acc: 42.534,64.528,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.943 | Acc: 34.375,53.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.944 | Acc: 34.784,51.897,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.976 | Acc: 34.356,51.391,58.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.968 | Acc: 34.567,51.422,57.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 4.861 | Acc: 35.156,60.156,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.128 | Acc: 42.634,65.811,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.094 | Acc: 42.816,66.178,75.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.125 | Acc: 42.661,65.484,76.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.126 | Acc: 42.785,65.365,76.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.158 | Acc: 42.427,64.913,75.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.153 | Acc: 42.523,65.044,75.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.144 | Acc: 42.825,65.121,75.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.139 | Acc: 42.949,65.198,75.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.158 | Acc: 42.779,64.930,75.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.163 | Acc: 42.786,64.774,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.167 | Acc: 42.750,64.692,75.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.173 | Acc: 42.593,64.678,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.182 | Acc: 42.490,64.589,74.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.194 | Acc: 42.396,64.507,74.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.189 | Acc: 42.439,64.535,74.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.207 | Acc: 42.397,64.342,74.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.216 | Acc: 42.355,64.303,74.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.220 | Acc: 42.287,64.249,74.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.222 | Acc: 42.306,64.224,74.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.664 | Acc: 35.938,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.986 | Acc: 33.185,51.637,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.939 | Acc: 33.518,51.543,60.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.960 | Acc: 33.210,51.857,60.067,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 3.774 | Acc: 50.781,67.969,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 42.336,64.881,76.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.089 | Acc: 42.969,65.053,76.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.129 | Acc: 42.982,65.215,76.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.127 | Acc: 42.911,65.365,76.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.142 | Acc: 42.953,65.060,75.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.171 | Acc: 42.504,64.760,75.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.180 | Acc: 42.514,64.605,75.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.167 | Acc: 42.697,64.815,75.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.179 | Acc: 42.869,64.753,75.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.191 | Acc: 42.704,64.665,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.198 | Acc: 42.689,64.593,74.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.205 | Acc: 42.664,64.516,74.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.210 | Acc: 42.613,64.500,74.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.214 | Acc: 42.571,64.449,74.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.214 | Acc: 42.592,64.473,74.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.216 | Acc: 42.645,64.425,74.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.212 | Acc: 42.698,64.402,74.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.214 | Acc: 42.631,64.374,74.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.213 | Acc: 42.688,64.354,74.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.124 | Acc: 35.156,49.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.298 | Acc: 32.999,49.814,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.346 | Acc: 33.041,49.752,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.367 | Acc: 32.684,49.168,58.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 3.929 | Acc: 46.875,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.145 | Acc: 41.295,66.295,76.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.104 | Acc: 42.130,66.463,76.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.176 | Acc: 42.123,65.548,75.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.167 | Acc: 42.419,65.461,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.146 | Acc: 42.512,65.563,75.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.130 | Acc: 42.814,65.399,75.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.142 | Acc: 42.880,65.099,75.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.125 | Acc: 43.056,65.266,75.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.138 | Acc: 42.775,65.129,75.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.146 | Acc: 42.712,65.139,75.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.153 | Acc: 42.735,65.024,75.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.161 | Acc: 42.784,64.990,74.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.174 | Acc: 42.756,64.892,74.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.177 | Acc: 42.707,64.855,74.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.175 | Acc: 42.810,64.789,74.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.182 | Acc: 42.774,64.700,74.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.185 | Acc: 42.756,64.713,74.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.190 | Acc: 42.703,64.638,74.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.206 | Acc: 42.511,64.505,74.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.542 | Acc: 35.938,56.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.874 | Acc: 35.268,52.939,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.920 | Acc: 35.061,51.658,59.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.945 | Acc: 34.631,51.691,59.439,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 3.760 | Acc: 42.969,67.969,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.924 | Acc: 43.043,67.076,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.991 | Acc: 42.816,66.349,76.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.025 | Acc: 43.122,65.894,76.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.053 | Acc: 42.380,65.596,76.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.080 | Acc: 42.551,65.555,76.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.104 | Acc: 42.342,65.405,75.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.096 | Acc: 42.442,65.509,75.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.122 | Acc: 42.406,65.247,75.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.120 | Acc: 42.541,65.262,75.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.129 | Acc: 42.467,65.186,75.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.137 | Acc: 42.534,65.197,75.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.146 | Acc: 42.450,65.084,75.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.159 | Acc: 42.328,64.901,75.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.167 | Acc: 42.249,64.860,74.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.167 | Acc: 42.245,64.888,74.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.170 | Acc: 42.270,64.875,74.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.179 | Acc: 42.265,64.857,74.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.182 | Acc: 42.300,64.833,74.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.191 | Acc: 42.278,64.784,74.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.536 | Acc: 35.938,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.832 | Acc: 27.195,48.698,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.889 | Acc: 27.115,48.171,55.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.876 | Acc: 26.908,48.233,56.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 4.493 | Acc: 40.625,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.113 | Acc: 42.299,64.695,76.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.081 | Acc: 42.454,64.939,75.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.098 | Acc: 42.623,65.279,75.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.114 | Acc: 42.506,65.307,75.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.137 | Acc: 42.342,65.138,75.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.127 | Acc: 42.736,65.096,75.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.113 | Acc: 42.897,65.171,75.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.118 | Acc: 42.789,65.179,75.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.129 | Acc: 42.822,64.991,75.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.146 | Acc: 42.763,64.789,75.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.150 | Acc: 42.788,64.777,75.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.154 | Acc: 42.765,64.808,74.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.161 | Acc: 42.708,64.697,74.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.176 | Acc: 42.599,64.541,74.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.181 | Acc: 42.525,64.608,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.187 | Acc: 42.426,64.552,74.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.197 | Acc: 42.401,64.475,74.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.206 | Acc: 42.337,64.430,74.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.209 | Acc: 42.294,64.399,74.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.191 | Acc: 26.562,53.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.401 | Acc: 31.138,50.484,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.482 | Acc: 30.011,50.248,56.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.499 | Acc: 29.713,49.962,56.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 3.852 | Acc: 46.094,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.996 | Acc: 44.978,66.629,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.048 | Acc: 44.112,66.178,76.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.069 | Acc: 43.494,65.996,76.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.072 | Acc: 43.268,65.895,76.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.102 | Acc: 43.255,65.880,76.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.096 | Acc: 43.208,65.909,75.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.107 | Acc: 43.224,65.863,75.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.117 | Acc: 43.260,65.761,75.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.135 | Acc: 43.077,65.590,75.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.141 | Acc: 43.004,65.403,75.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.149 | Acc: 43.025,65.307,74.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.156 | Acc: 43.050,65.194,74.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.167 | Acc: 42.960,65.110,74.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.182 | Acc: 42.902,64.874,74.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.187 | Acc: 42.893,64.852,74.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.193 | Acc: 42.815,64.778,74.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.199 | Acc: 42.824,64.709,74.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.200 | Acc: 42.819,64.673,74.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.209 | Acc: 42.725,64.643,74.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.923 | Acc: 27.344,52.344,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.790 | Acc: 27.902,49.107,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.737 | Acc: 28.182,48.838,57.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.761 | Acc: 27.766,48.847,57.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 4.059 | Acc: 41.406,66.406,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.046 | Acc: 43.452,66.704,76.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.096 | Acc: 43.312,65.644,75.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.119 | Acc: 42.982,65.394,75.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.137 | Acc: 42.892,65.384,75.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.152 | Acc: 42.690,65.254,75.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.164 | Acc: 42.614,65.134,75.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.147 | Acc: 42.719,65.398,75.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.150 | Acc: 42.716,65.407,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.157 | Acc: 42.710,65.331,75.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.153 | Acc: 42.704,65.345,75.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.153 | Acc: 42.640,65.406,75.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.156 | Acc: 42.709,65.437,75.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.161 | Acc: 42.634,65.314,74.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.176 | Acc: 42.466,65.027,74.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.180 | Acc: 42.452,64.955,74.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.184 | Acc: 42.448,64.985,74.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.181 | Acc: 42.513,65.036,74.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.184 | Acc: 42.460,65.034,74.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.190 | Acc: 42.425,64.944,74.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.071 | Acc: 39.062,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.496 | Acc: 30.692,50.409,60.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.498 | Acc: 30.354,50.248,60.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.471 | Acc: 30.174,50.397,60.003,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 4.400 | Acc: 40.625,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.122 | Acc: 43.192,65.960,76.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.123 | Acc: 42.931,65.606,76.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.073 | Acc: 43.545,66.662,76.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.121 | Acc: 42.795,66.030,76.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.121 | Acc: 42.636,65.996,76.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.136 | Acc: 42.672,65.825,75.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.151 | Acc: 42.476,65.614,75.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.149 | Acc: 42.581,65.426,75.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.151 | Acc: 42.446,65.271,75.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.140 | Acc: 42.627,65.361,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.144 | Acc: 42.633,65.346,75.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.153 | Acc: 42.577,65.304,75.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.160 | Acc: 42.556,65.266,75.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.169 | Acc: 42.496,65.177,75.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.176 | Acc: 42.608,65.088,75.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.171 | Acc: 42.764,65.129,74.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.176 | Acc: 42.726,65.082,74.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.171 | Acc: 42.828,65.119,74.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.176 | Acc: 42.809,65.022,74.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.777 | Acc: 29.688,50.000,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.670 | Acc: 26.525,49.330,58.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.738 | Acc: 26.143,49.505,57.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.734 | Acc: 25.897,49.526,58.056,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 4.007 | Acc: 45.312,65.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.144 | Acc: 43.452,64.025,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.105 | Acc: 43.236,64.634,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.102 | Acc: 43.212,64.857,75.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.106 | Acc: 43.084,65.017,75.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.130 | Acc: 42.976,64.851,75.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.120 | Acc: 42.911,65.063,75.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.120 | Acc: 42.958,65.121,75.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.124 | Acc: 42.925,65.057,75.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.129 | Acc: 42.796,64.908,75.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.134 | Acc: 42.755,64.894,74.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.146 | Acc: 42.753,64.738,74.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.151 | Acc: 42.632,64.695,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.164 | Acc: 42.607,64.550,74.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.176 | Acc: 42.482,64.485,74.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.178 | Acc: 42.380,64.532,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.188 | Acc: 42.287,64.498,74.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.192 | Acc: 42.268,64.438,74.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.191 | Acc: 42.378,64.502,74.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.201 | Acc: 42.413,64.503,74.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.679 | Acc: 35.156,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.456 | Acc: 33.705,49.293,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.493 | Acc: 32.965,48.418,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.516 | Acc: 32.441,48.706,57.979,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 3.802 | Acc: 47.656,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.115 | Acc: 41.890,64.360,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.070 | Acc: 42.607,65.111,76.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.101 | Acc: 42.597,65.049,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.094 | Acc: 42.496,65.201,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.115 | Acc: 42.334,65.161,76.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.124 | Acc: 42.342,65.296,76.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.128 | Acc: 42.359,65.259,76.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.129 | Acc: 42.474,65.305,75.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.125 | Acc: 42.662,65.370,75.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.131 | Acc: 42.681,65.283,75.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.143 | Acc: 42.587,65.268,75.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.143 | Acc: 42.632,65.278,75.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.146 | Acc: 42.631,65.170,75.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.153 | Acc: 42.694,65.055,75.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.157 | Acc: 42.707,64.987,75.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.160 | Acc: 42.694,64.948,75.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.163 | Acc: 42.705,64.931,75.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.167 | Acc: 42.690,64.878,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.172 | Acc: 42.641,64.815,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.793 | Acc: 38.281,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.003 | Acc: 32.664,53.646,62.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.040 | Acc: 32.012,53.163,61.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.005 | Acc: 32.018,53.189,61.040,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 4.218 | Acc: 38.281,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 42.225,64.955,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.210 | Acc: 41.635,64.463,76.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.131 | Acc: 42.508,64.831,76.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.108 | Acc: 43.123,64.979,76.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.094 | Acc: 43.232,65.169,75.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.097 | Acc: 43.253,65.167,76.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.127 | Acc: 43.035,65.010,75.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.125 | Acc: 42.847,65.145,75.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.131 | Acc: 42.844,64.969,75.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.145 | Acc: 42.798,64.817,75.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.146 | Acc: 42.863,64.780,75.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.154 | Acc: 42.726,64.802,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.167 | Acc: 42.610,64.688,75.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.167 | Acc: 42.627,64.694,74.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.162 | Acc: 42.642,64.833,75.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.171 | Acc: 42.565,64.705,74.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.180 | Acc: 42.485,64.654,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.184 | Acc: 42.408,64.673,74.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.179 | Acc: 42.509,64.674,74.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.569 | Acc: 37.500,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.751 | Acc: 33.966,54.576,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.725 | Acc: 34.756,54.402,60.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.752 | Acc: 33.607,53.791,60.374,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 4.488 | Acc: 39.844,61.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.153 | Acc: 42.225,64.323,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.124 | Acc: 42.035,64.977,75.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.129 | Acc: 42.226,65.023,76.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.132 | Acc: 42.371,65.201,76.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.140 | Acc: 42.435,65.145,76.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.132 | Acc: 42.607,65.179,75.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.112 | Acc: 42.958,65.248,76.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.128 | Acc: 42.799,65.169,75.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.122 | Acc: 42.740,65.172,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.131 | Acc: 42.786,65.225,75.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.139 | Acc: 42.767,65.059,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.154 | Acc: 42.586,64.850,75.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.169 | Acc: 42.538,64.715,75.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.181 | Acc: 42.529,64.644,74.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.180 | Acc: 42.626,64.631,74.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.174 | Acc: 42.672,64.700,74.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.173 | Acc: 42.641,64.695,74.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.175 | Acc: 42.653,64.718,74.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.177 | Acc: 42.714,64.665,74.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.886 | Acc: 28.125,53.906,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.088 | Acc: 32.738,50.818,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.105 | Acc: 32.546,50.743,60.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.112 | Acc: 32.351,50.871,60.451,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 4.214 | Acc: 45.312,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.986 | Acc: 44.382,66.629,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.017 | Acc: 44.550,65.892,77.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.061 | Acc: 44.070,65.894,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.026 | Acc: 44.165,66.271,76.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.023 | Acc: 44.021,66.406,76.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.037 | Acc: 44.008,66.309,76.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.044 | Acc: 43.700,66.373,76.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.076 | Acc: 43.318,66.081,75.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.076 | Acc: 43.362,66.039,75.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.080 | Acc: 43.214,65.948,75.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.088 | Acc: 43.227,65.819,75.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.094 | Acc: 43.199,65.709,75.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.113 | Acc: 43.053,65.553,75.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.123 | Acc: 43.047,65.422,75.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.123 | Acc: 42.938,65.472,75.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.130 | Acc: 42.915,65.374,75.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.141 | Acc: 42.937,65.350,75.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.142 | Acc: 42.925,65.283,74.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.149 | Acc: 42.866,65.180,74.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.069 | Acc: 30.469,53.125,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.479 | Acc: 28.051,48.103,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.554 | Acc: 28.182,47.713,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.575 | Acc: 27.984,47.707,58.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 3.365 | Acc: 51.562,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.966 | Acc: 44.308,68.118,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.030 | Acc: 44.074,67.302,77.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.045 | Acc: 43.814,66.790,76.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.049 | Acc: 43.654,66.609,76.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.039 | Acc: 43.827,66.530,76.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.057 | Acc: 43.640,66.032,76.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.078 | Acc: 43.484,65.946,76.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.079 | Acc: 43.444,65.936,76.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.089 | Acc: 43.314,65.819,76.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.102 | Acc: 43.241,65.582,75.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.107 | Acc: 43.114,65.590,75.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.115 | Acc: 43.011,65.447,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.127 | Acc: 42.816,65.415,75.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.140 | Acc: 42.705,65.269,75.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.148 | Acc: 42.771,65.108,75.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.148 | Acc: 42.781,65.077,75.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.155 | Acc: 42.698,65.034,75.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.162 | Acc: 42.713,64.989,75.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.163 | Acc: 42.743,65.012,74.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.180 | Acc: 26.562,53.906,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.460 | Acc: 28.237,52.046,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.454 | Acc: 28.525,52.191,58.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.474 | Acc: 28.035,51.972,58.952,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 4.055 | Acc: 46.094,64.844,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.089 | Acc: 42.188,66.369,76.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.118 | Acc: 42.550,65.758,76.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.134 | Acc: 42.559,65.766,75.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.135 | Acc: 42.380,65.529,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.137 | Acc: 42.412,65.354,75.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.128 | Acc: 42.607,65.373,75.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.140 | Acc: 42.459,65.254,75.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.137 | Acc: 42.566,65.247,75.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.132 | Acc: 42.541,65.306,75.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.126 | Acc: 42.650,65.368,75.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.128 | Acc: 42.605,65.293,75.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.134 | Acc: 42.645,65.233,75.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.152 | Acc: 42.493,65.017,75.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.149 | Acc: 42.541,65.100,75.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.157 | Acc: 42.489,65.041,75.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.164 | Acc: 42.477,64.980,74.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.171 | Acc: 42.490,64.931,74.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.176 | Acc: 42.480,64.939,74.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.180 | Acc: 42.503,64.879,74.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.634 | Acc: 30.469,55.469,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.887 | Acc: 28.311,47.805,57.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.938 | Acc: 27.649,47.027,56.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.960 | Acc: 27.626,47.131,56.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 3.779 | Acc: 43.750,64.062,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.139 | Acc: 43.043,64.137,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.099 | Acc: 42.778,65.301,76.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.115 | Acc: 42.597,65.228,76.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.089 | Acc: 43.094,65.365,75.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.104 | Acc: 43.000,65.207,75.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.121 | Acc: 42.878,65.089,75.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.116 | Acc: 42.963,65.232,75.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.113 | Acc: 43.095,65.280,75.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.103 | Acc: 43.185,65.513,75.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.109 | Acc: 43.198,65.411,75.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.111 | Acc: 43.177,65.484,75.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.115 | Acc: 42.998,65.456,75.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.119 | Acc: 43.062,65.347,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.126 | Acc: 43.010,65.286,75.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.137 | Acc: 42.932,65.215,75.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.137 | Acc: 42.993,65.167,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.149 | Acc: 42.948,65.016,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.159 | Acc: 42.891,64.993,74.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.163 | Acc: 42.885,64.936,74.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.613 | Acc: 34.375,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.731 | Acc: 34.375,53.497,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.751 | Acc: 33.765,52.915,61.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.788 | Acc: 33.863,53.637,60.784,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 3.731 | Acc: 42.188,69.531,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.940 | Acc: 43.601,67.560,76.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.999 | Acc: 42.816,67.321,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.978 | Acc: 43.712,67.303,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.006 | Acc: 43.191,66.686,77.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.020 | Acc: 43.402,66.692,76.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.030 | Acc: 43.485,66.645,76.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.044 | Acc: 43.434,66.451,76.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.046 | Acc: 43.551,66.397,76.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.065 | Acc: 43.426,66.216,76.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.071 | Acc: 43.322,66.169,75.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.080 | Acc: 43.223,66.092,75.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.087 | Acc: 43.069,65.933,75.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.101 | Acc: 42.930,65.799,75.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.112 | Acc: 42.902,65.750,75.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.114 | Acc: 42.883,65.713,75.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.125 | Acc: 42.881,65.615,75.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.129 | Acc: 42.882,65.643,75.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.134 | Acc: 42.858,65.530,75.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.140 | Acc: 42.901,65.434,74.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.595 | Acc: 32.812,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.596 | Acc: 30.804,48.289,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.573 | Acc: 30.412,48.780,59.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.580 | Acc: 30.392,48.783,59.080,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 4.422 | Acc: 38.281,62.500,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.033 | Acc: 43.713,66.332,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.096 | Acc: 42.569,65.739,76.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.126 | Acc: 42.252,65.420,76.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.103 | Acc: 42.699,65.577,76.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.089 | Acc: 42.783,65.702,76.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.095 | Acc: 42.820,65.761,76.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.100 | Acc: 42.897,65.669,76.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.101 | Acc: 42.862,65.601,76.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.104 | Acc: 42.796,65.543,76.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.118 | Acc: 42.739,65.477,76.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.126 | Acc: 42.658,65.395,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.144 | Acc: 42.499,65.239,75.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.155 | Acc: 42.535,65.140,75.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.163 | Acc: 42.463,65.116,75.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.170 | Acc: 42.512,65.072,75.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.177 | Acc: 42.579,65.021,75.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.172 | Acc: 42.637,65.073,75.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.177 | Acc: 42.646,65.006,75.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.179 | Acc: 42.700,64.995,75.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.836 | Acc: 29.688,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.445 | Acc: 33.371,48.512,53.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.407 | Acc: 33.441,47.999,54.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.407 | Acc: 33.081,48.092,54.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 4.339 | Acc: 39.062,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.087 | Acc: 43.564,65.030,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.099 | Acc: 43.636,65.282,75.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.117 | Acc: 43.353,65.356,75.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.128 | Acc: 43.248,65.162,75.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.092 | Acc: 43.348,65.385,75.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.088 | Acc: 43.388,65.451,75.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.083 | Acc: 43.512,65.553,75.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.082 | Acc: 43.483,65.669,75.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.088 | Acc: 43.560,65.651,75.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.100 | Acc: 43.272,65.602,75.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.116 | Acc: 43.131,65.522,75.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.126 | Acc: 43.076,65.418,75.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.129 | Acc: 42.996,65.371,75.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.133 | Acc: 42.969,65.322,75.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.140 | Acc: 43.002,65.267,75.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.140 | Acc: 43.061,65.289,74.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.139 | Acc: 43.115,65.242,75.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.144 | Acc: 43.070,65.268,74.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.143 | Acc: 43.057,65.324,74.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.258 | Acc: 31.250,51.562,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.439 | Acc: 30.878,49.777,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.408 | Acc: 31.250,50.076,58.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.386 | Acc: 30.712,50.346,58.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 3.802 | Acc: 49.219,69.531,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.951 | Acc: 43.266,67.634,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.018 | Acc: 43.598,66.463,76.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.069 | Acc: 43.225,65.971,75.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.107 | Acc: 42.699,65.693,75.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.100 | Acc: 42.744,65.555,75.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.088 | Acc: 42.710,65.683,75.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.103 | Acc: 42.764,65.586,75.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.096 | Acc: 42.838,65.775,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.109 | Acc: 42.645,65.599,75.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.116 | Acc: 42.634,65.551,75.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.120 | Acc: 42.658,65.501,75.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.121 | Acc: 42.729,65.450,75.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.126 | Acc: 42.720,65.359,75.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.138 | Acc: 42.785,65.158,75.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.143 | Acc: 42.766,65.080,75.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.147 | Acc: 42.854,65.063,75.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.141 | Acc: 42.863,65.116,75.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.145 | Acc: 42.835,65.093,75.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.149 | Acc: 42.799,65.047,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.697 | Acc: 31.250,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.059 | Acc: 31.771,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.115 | Acc: 31.860,52.096,59.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.116 | Acc: 31.404,51.819,59.695,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.292 | Acc: 41.406,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.171 | Acc: 43.118,65.030,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.157 | Acc: 42.454,64.958,76.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.127 | Acc: 42.892,64.844,76.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.102 | Acc: 43.152,65.365,76.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.077 | Acc: 43.178,65.571,76.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.072 | Acc: 43.130,65.651,76.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.071 | Acc: 43.068,65.664,76.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.083 | Acc: 42.969,65.601,76.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.095 | Acc: 42.999,65.448,76.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.111 | Acc: 43.004,65.326,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.123 | Acc: 42.951,65.215,75.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.120 | Acc: 42.914,65.161,75.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.119 | Acc: 43.005,65.170,75.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.125 | Acc: 42.997,65.066,75.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.133 | Acc: 42.901,65.054,75.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.138 | Acc: 42.947,64.973,75.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.143 | Acc: 42.978,64.892,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.149 | Acc: 42.915,64.803,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.151 | Acc: 42.889,64.825,75.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.129 | Acc: 32.812,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.477 | Acc: 30.246,49.182,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.454 | Acc: 30.488,49.257,57.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.457 | Acc: 30.085,49.462,57.646,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 4.006 | Acc: 42.969,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 44.382,66.629,76.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.019 | Acc: 44.303,66.254,76.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.010 | Acc: 44.480,66.176,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.017 | Acc: 44.059,66.397,76.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.024 | Acc: 43.704,66.383,76.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.062 | Acc: 43.388,66.122,76.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.059 | Acc: 43.401,66.307,76.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.055 | Acc: 43.575,66.227,76.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.062 | Acc: 43.379,66.126,76.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.072 | Acc: 43.338,65.951,76.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.084 | Acc: 43.248,65.816,75.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.089 | Acc: 43.131,65.781,75.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.098 | Acc: 43.118,65.709,75.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.105 | Acc: 43.144,65.661,75.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.105 | Acc: 43.119,65.602,75.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.107 | Acc: 43.154,65.554,75.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.121 | Acc: 43.028,65.368,75.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.134 | Acc: 42.969,65.244,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.141 | Acc: 42.944,65.211,75.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.572 | Acc: 31.250,48.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.334 | Acc: 31.659,49.888,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.303 | Acc: 32.870,50.819,57.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.288 | Acc: 32.774,50.845,57.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 3.556 | Acc: 44.531,71.094,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.033 | Acc: 44.940,66.853,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.111 | Acc: 43.636,65.663,76.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.064 | Acc: 44.070,65.625,76.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.059 | Acc: 44.088,65.808,76.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.051 | Acc: 43.951,66.043,76.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.057 | Acc: 43.802,66.090,76.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.061 | Acc: 43.750,66.018,76.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.059 | Acc: 43.731,65.974,76.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.075 | Acc: 43.595,65.750,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.079 | Acc: 43.497,65.637,75.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.086 | Acc: 43.453,65.593,75.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.097 | Acc: 43.390,65.395,75.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.105 | Acc: 43.232,65.350,75.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.112 | Acc: 43.194,65.247,75.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.111 | Acc: 43.215,65.215,75.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.118 | Acc: 43.178,65.116,75.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.122 | Acc: 43.136,65.068,75.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.134 | Acc: 43.010,65.015,75.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.143 | Acc: 42.993,65.006,75.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.778 | Acc: 39.844,52.344,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.667 | Acc: 34.524,53.274,62.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.719 | Acc: 33.994,52.725,61.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.728 | Acc: 33.747,52.997,61.399,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 3.791 | Acc: 43.750,69.531,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.024 | Acc: 43.118,66.592,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.038 | Acc: 42.759,66.654,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.057 | Acc: 43.071,66.137,76.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.038 | Acc: 43.644,66.020,76.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.043 | Acc: 43.866,65.965,76.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.053 | Acc: 44.002,65.851,76.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.064 | Acc: 43.833,65.824,76.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.074 | Acc: 43.726,65.688,76.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.073 | Acc: 43.672,65.737,76.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.076 | Acc: 43.525,65.691,75.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.085 | Acc: 43.365,65.611,75.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.090 | Acc: 43.367,65.651,75.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.102 | Acc: 43.325,65.469,75.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.105 | Acc: 43.361,65.439,75.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.104 | Acc: 43.366,65.397,75.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.105 | Acc: 43.309,65.406,75.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.113 | Acc: 43.253,65.371,75.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.125 | Acc: 43.181,65.261,75.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.128 | Acc: 43.168,65.227,75.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.595 | Acc: 35.156,52.344,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.695 | Acc: 35.751,54.167,61.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.726 | Acc: 35.461,54.097,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.742 | Acc: 34.951,53.842,60.861,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 3.687 | Acc: 42.969,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.030 | Acc: 44.717,67.039,76.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.083 | Acc: 43.750,65.987,75.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.066 | Acc: 43.814,65.791,76.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.058 | Acc: 43.692,65.847,76.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.049 | Acc: 43.889,65.927,76.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.061 | Acc: 43.944,65.967,76.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.069 | Acc: 43.756,65.924,76.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.071 | Acc: 43.823,65.868,75.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.080 | Acc: 43.767,65.724,75.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.096 | Acc: 43.521,65.547,75.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.108 | Acc: 43.464,65.413,75.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.106 | Acc: 43.555,65.375,75.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.114 | Acc: 43.391,65.290,75.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.118 | Acc: 43.308,65.283,75.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.122 | Acc: 43.210,65.155,75.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.129 | Acc: 43.161,65.082,75.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.131 | Acc: 43.141,65.045,75.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.125 | Acc: 43.211,65.162,75.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.128 | Acc: 43.143,65.082,75.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.902 | Acc: 34.375,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.939 | Acc: 33.631,52.865,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.056 | Acc: 32.927,52.382,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.070 | Acc: 32.108,52.421,59.119,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 3.744 | Acc: 46.094,75.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.911 | Acc: 44.345,68.006,78.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.946 | Acc: 44.093,67.321,77.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.939 | Acc: 43.840,67.226,77.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.997 | Acc: 43.364,66.580,77.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.017 | Acc: 43.348,66.321,77.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.031 | Acc: 43.395,66.206,77.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.065 | Acc: 43.019,65.908,76.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.080 | Acc: 42.920,65.829,76.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.078 | Acc: 43.077,65.785,76.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.086 | Acc: 43.043,65.703,76.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.090 | Acc: 43.138,65.664,76.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.088 | Acc: 43.186,65.722,76.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.093 | Acc: 43.181,65.763,75.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.088 | Acc: 43.244,65.767,75.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.096 | Acc: 43.228,65.700,75.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.108 | Acc: 43.227,65.537,75.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.115 | Acc: 43.173,65.451,75.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.120 | Acc: 43.105,65.385,75.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.132 | Acc: 43.055,65.285,75.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.760 | Acc: 31.250,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.859 | Acc: 29.167,50.149,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.900 | Acc: 28.963,49.104,58.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.880 | Acc: 28.612,48.783,58.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 3.747 | Acc: 48.438,73.438,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.874 | Acc: 45.387,68.601,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.909 | Acc: 44.627,67.740,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.821 | Acc: 44.736,68.494,78.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.735 | Acc: 45.496,69.387,79.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.705 | Acc: 45.444,69.469,80.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.672 | Acc: 45.726,69.925,80.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.642 | Acc: 46.299,70.324,80.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.614 | Acc: 46.545,70.642,80.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.592 | Acc: 46.698,70.761,81.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.583 | Acc: 46.657,70.833,81.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.569 | Acc: 46.758,71.009,81.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.559 | Acc: 46.817,71.204,81.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.550 | Acc: 46.884,71.255,81.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.534 | Acc: 47.033,71.444,82.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.524 | Acc: 47.171,71.608,82.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.515 | Acc: 47.260,71.685,82.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.504 | Acc: 47.329,71.818,82.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.496 | Acc: 47.394,71.869,82.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.491 | Acc: 47.373,71.912,82.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.301 | Acc: 50.000,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 46.801,64.621,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.305 | Acc: 45.617,64.386,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.305 | Acc: 45.287,64.613,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.529 | Acc: 46.094,71.094,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.307 | Acc: 48.475,73.661,86.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.328 | Acc: 48.228,73.571,85.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.313 | Acc: 48.694,74.065,85.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.312 | Acc: 48.582,74.093,85.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.298 | Acc: 48.569,74.257,85.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.288 | Acc: 48.709,74.270,85.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.286 | Acc: 48.731,74.008,85.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.287 | Acc: 48.593,73.966,85.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.294 | Acc: 48.381,73.714,85.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.289 | Acc: 48.438,73.776,85.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.295 | Acc: 48.402,73.696,85.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.292 | Acc: 48.382,73.707,85.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.290 | Acc: 48.396,73.719,85.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.288 | Acc: 48.376,73.771,85.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.285 | Acc: 48.396,73.848,85.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.285 | Acc: 48.364,73.812,85.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.280 | Acc: 48.438,73.857,85.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.280 | Acc: 48.457,73.877,85.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.286 | Acc: 48.343,73.868,85.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.244 | Acc: 49.219,62.500,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.276 | Acc: 46.503,65.253,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.304 | Acc: 45.655,64.939,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.307 | Acc: 45.261,64.985,71.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.198 | Acc: 50.781,75.781,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.185 | Acc: 48.996,74.479,86.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.192 | Acc: 48.895,73.971,86.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.205 | Acc: 48.489,73.924,86.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.191 | Acc: 48.804,74.354,86.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.200 | Acc: 48.948,74.459,86.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.204 | Acc: 48.864,74.619,86.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.215 | Acc: 48.803,74.413,86.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.219 | Acc: 48.685,74.442,86.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.222 | Acc: 48.688,74.564,86.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.221 | Acc: 48.713,74.607,86.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.221 | Acc: 48.657,74.537,86.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.218 | Acc: 48.664,74.556,86.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.222 | Acc: 48.794,74.506,86.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.219 | Acc: 48.771,74.508,86.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.220 | Acc: 48.827,74.517,86.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.225 | Acc: 48.786,74.482,86.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.226 | Acc: 48.774,74.496,86.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.226 | Acc: 48.777,74.472,86.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.221 | Acc: 48.874,74.576,86.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.183 | Acc: 46.875,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.279 | Acc: 46.243,65.327,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.297 | Acc: 45.351,64.920,72.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.300 | Acc: 44.915,65.279,71.965,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 3.161 | Acc: 50.000,75.000,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.245 | Acc: 48.140,74.293,86.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.195 | Acc: 48.933,75.038,87.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.177 | Acc: 48.924,75.243,87.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.164 | Acc: 49.171,75.338,87.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.168 | Acc: 48.847,75.364,87.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.137 | Acc: 49.212,75.697,87.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.128 | Acc: 49.202,75.754,87.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.138 | Acc: 49.146,75.476,87.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.151 | Acc: 49.059,75.224,87.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.154 | Acc: 48.978,75.136,87.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.163 | Acc: 48.802,75.007,87.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.158 | Acc: 48.901,75.078,87.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.155 | Acc: 48.976,75.048,87.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.155 | Acc: 49.074,75.075,87.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.162 | Acc: 49.068,75.073,87.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.170 | Acc: 48.951,74.954,87.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.180 | Acc: 48.822,74.867,87.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.174 | Acc: 48.911,74.922,87.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.172 | Acc: 48.981,74.949,87.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.332 | Acc: 50.000,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.287 | Acc: 46.503,64.546,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.283 | Acc: 45.808,64.710,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.285 | Acc: 45.492,64.959,71.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 3.392 | Acc: 49.219,70.312,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.104 | Acc: 49.628,75.558,87.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.121 | Acc: 49.009,75.953,87.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.098 | Acc: 49.475,75.807,87.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.108 | Acc: 49.277,75.945,87.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.129 | Acc: 49.273,75.743,87.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.128 | Acc: 49.290,75.678,87.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.121 | Acc: 49.285,75.698,87.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.122 | Acc: 49.330,75.607,87.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.127 | Acc: 49.253,75.436,87.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.132 | Acc: 49.234,75.276,87.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.136 | Acc: 49.311,75.194,87.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.135 | Acc: 49.238,75.272,87.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.132 | Acc: 49.330,75.347,87.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.136 | Acc: 49.380,75.339,87.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.145 | Acc: 49.255,75.231,87.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.147 | Acc: 49.148,75.270,87.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.147 | Acc: 49.106,75.245,87.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.150 | Acc: 49.072,75.167,87.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.146 | Acc: 49.122,75.215,87.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.252 | Acc: 48.438,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.326 | Acc: 46.763,65.179,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.345 | Acc: 45.332,64.596,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.338 | Acc: 44.890,64.844,71.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.339 | Acc: 43.750,76.562,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.098 | Acc: 49.219,75.781,88.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.051 | Acc: 49.409,76.601,88.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.036 | Acc: 49.603,76.857,88.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.063 | Acc: 49.277,76.524,88.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.095 | Acc: 48.755,75.882,88.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.104 | Acc: 48.709,75.684,88.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.099 | Acc: 48.881,75.798,88.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.095 | Acc: 49.112,75.694,88.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.099 | Acc: 49.003,75.626,88.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.095 | Acc: 49.009,75.602,88.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.091 | Acc: 49.152,75.661,88.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.091 | Acc: 49.131,75.655,88.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.091 | Acc: 49.162,75.644,88.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.104 | Acc: 49.007,75.448,88.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.106 | Acc: 49.027,75.441,88.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.100 | Acc: 49.260,75.428,88.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.108 | Acc: 49.219,75.339,88.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.109 | Acc: 49.193,75.279,88.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.109 | Acc: 49.221,75.301,87.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.233 | Acc: 53.125,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.276 | Acc: 46.949,65.551,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.297 | Acc: 46.018,65.530,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.302 | Acc: 45.645,65.574,71.273,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 3.065 | Acc: 46.094,71.094,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.008 | Acc: 50.000,76.972,88.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.055 | Acc: 48.952,76.410,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.040 | Acc: 49.539,76.217,88.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.050 | Acc: 49.441,76.157,88.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.047 | Acc: 49.412,76.199,88.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.069 | Acc: 49.309,75.968,88.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.078 | Acc: 49.030,75.931,88.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.092 | Acc: 48.840,75.738,88.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.084 | Acc: 49.016,75.751,88.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.081 | Acc: 49.129,75.917,88.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.077 | Acc: 49.169,75.799,88.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.085 | Acc: 49.109,75.687,88.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.089 | Acc: 49.102,75.647,88.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.083 | Acc: 49.238,75.678,88.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.087 | Acc: 49.146,75.680,88.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.089 | Acc: 49.143,75.625,88.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.094 | Acc: 49.088,75.596,88.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.093 | Acc: 49.117,75.615,88.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.095 | Acc: 49.028,75.570,88.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.356 | Acc: 48.438,67.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 47.061,65.476,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.346 | Acc: 45.389,64.615,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.345 | Acc: 45.377,64.946,71.068,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.102 | Acc: 46.875,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.013 | Acc: 49.033,76.749,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.033 | Acc: 49.257,76.696,89.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.051 | Acc: 48.975,76.447,89.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.030 | Acc: 49.479,76.418,89.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.028 | Acc: 49.582,76.446,89.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.039 | Acc: 49.393,76.278,89.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.037 | Acc: 49.523,76.380,89.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.045 | Acc: 49.461,76.310,88.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.042 | Acc: 49.413,76.360,88.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.040 | Acc: 49.417,76.399,88.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.045 | Acc: 49.463,76.361,88.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.050 | Acc: 49.459,76.264,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.058 | Acc: 49.431,76.179,88.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.068 | Acc: 49.327,76.126,88.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.071 | Acc: 49.390,76.075,88.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.070 | Acc: 49.516,76.093,88.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.069 | Acc: 49.450,76.109,88.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.073 | Acc: 49.401,76.041,88.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.068 | Acc: 49.434,76.070,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.322 | Acc: 51.562,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.318 | Acc: 47.396,65.216,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.316 | Acc: 45.998,65.168,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.309 | Acc: 45.838,65.356,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 3.065 | Acc: 45.312,76.562,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.994 | Acc: 51.042,78.051,88.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.023 | Acc: 50.667,76.982,88.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.033 | Acc: 50.525,76.780,88.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.014 | Acc: 50.588,76.910,88.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.013 | Acc: 50.449,76.756,88.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.020 | Acc: 50.207,76.569,88.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.022 | Acc: 49.917,76.507,88.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.026 | Acc: 49.888,76.485,88.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.043 | Acc: 49.616,76.191,88.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.041 | Acc: 49.565,76.150,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.042 | Acc: 49.449,76.050,88.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.035 | Acc: 49.650,76.118,88.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.041 | Acc: 49.620,76.102,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.041 | Acc: 49.594,76.104,88.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.040 | Acc: 49.580,76.121,88.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.040 | Acc: 49.611,76.176,88.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.044 | Acc: 49.666,76.155,88.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.047 | Acc: 49.719,76.084,88.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.052 | Acc: 49.653,76.052,88.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.276 | Acc: 50.000,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.355 | Acc: 46.577,64.955,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.371 | Acc: 45.598,64.863,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.373 | Acc: 45.210,65.036,70.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 2.978 | Acc: 48.438,78.906,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.028 | Acc: 48.810,77.121,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.978 | Acc: 49.600,77.401,89.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 49.885,77.049,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.962 | Acc: 50.135,76.948,89.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.983 | Acc: 49.884,76.648,89.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.012 | Acc: 49.503,76.575,89.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.009 | Acc: 49.429,76.779,89.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.014 | Acc: 49.408,76.703,89.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.024 | Acc: 49.404,76.398,89.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.021 | Acc: 49.576,76.376,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.028 | Acc: 49.388,76.283,89.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.021 | Acc: 49.569,76.481,89.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.013 | Acc: 49.590,76.530,89.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.014 | Acc: 49.544,76.543,89.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.011 | Acc: 49.559,76.557,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.017 | Acc: 49.416,76.545,89.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.020 | Acc: 49.338,76.533,89.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.026 | Acc: 49.349,76.504,89.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.027 | Acc: 49.399,76.450,89.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 48.438,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.335 | Acc: 46.503,64.918,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.351 | Acc: 45.617,64.787,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.355 | Acc: 45.261,65.074,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 2.804 | Acc: 56.250,82.031,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 51.228,75.967,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.950 | Acc: 50.305,76.772,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.947 | Acc: 50.512,76.767,90.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.944 | Acc: 50.444,76.881,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.960 | Acc: 49.946,76.825,90.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.969 | Acc: 49.690,76.905,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.974 | Acc: 49.607,76.779,89.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.983 | Acc: 49.563,76.703,89.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.989 | Acc: 49.555,76.601,89.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.997 | Acc: 49.681,76.528,89.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.995 | Acc: 49.696,76.481,89.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.998 | Acc: 49.721,76.417,89.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.999 | Acc: 49.802,76.425,89.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.002 | Acc: 49.677,76.437,89.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.002 | Acc: 49.714,76.443,89.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.006 | Acc: 49.742,76.399,89.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.006 | Acc: 49.707,76.407,89.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.010 | Acc: 49.643,76.394,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.009 | Acc: 49.709,76.452,89.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.234 | Acc: 52.344,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.372 | Acc: 46.838,65.141,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.365 | Acc: 46.094,65.149,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.370 | Acc: 45.543,65.164,71.055,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 3.187 | Acc: 52.344,73.438,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.996 | Acc: 50.558,76.935,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.994 | Acc: 49.752,76.658,89.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.961 | Acc: 49.834,76.742,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.968 | Acc: 49.624,76.919,90.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.973 | Acc: 49.582,76.895,90.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.968 | Acc: 49.832,76.885,90.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.972 | Acc: 49.956,76.862,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.976 | Acc: 49.777,76.791,89.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.981 | Acc: 49.789,76.653,89.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.986 | Acc: 49.848,76.566,89.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.988 | Acc: 49.823,76.601,89.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.984 | Acc: 49.974,76.673,89.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.979 | Acc: 50.060,76.655,89.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.982 | Acc: 49.905,76.693,89.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.984 | Acc: 49.899,76.713,89.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.986 | Acc: 49.910,76.701,89.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.990 | Acc: 49.927,76.604,89.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.993 | Acc: 49.831,76.552,89.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.996 | Acc: 49.832,76.493,89.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.425 | Acc: 44.531,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.479 | Acc: 46.168,64.435,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.475 | Acc: 45.236,64.215,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.468 | Acc: 44.826,64.395,70.786,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 2.614 | Acc: 55.469,82.812,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.022 | Acc: 48.810,76.190,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.987 | Acc: 50.038,76.963,90.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.986 | Acc: 49.449,76.972,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.981 | Acc: 49.711,76.968,89.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.978 | Acc: 49.729,76.779,89.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.986 | Acc: 49.832,76.724,89.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.985 | Acc: 49.801,76.723,89.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.989 | Acc: 49.723,76.723,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.990 | Acc: 49.763,76.817,89.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.986 | Acc: 49.860,76.780,89.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.983 | Acc: 49.926,76.831,89.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.976 | Acc: 49.958,76.903,89.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.981 | Acc: 49.901,76.853,89.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.985 | Acc: 49.811,76.874,89.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.988 | Acc: 49.847,76.794,89.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.989 | Acc: 49.815,76.738,89.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.988 | Acc: 49.830,76.773,89.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.990 | Acc: 49.797,76.768,89.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.989 | Acc: 49.801,76.749,89.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.277 | Acc: 51.562,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.358 | Acc: 46.987,65.104,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.377 | Acc: 45.713,64.710,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.377 | Acc: 45.710,64.780,71.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 2.984 | Acc: 46.094,77.344,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.933 | Acc: 50.335,77.530,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.885 | Acc: 50.934,77.287,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.907 | Acc: 50.666,77.433,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.915 | Acc: 50.299,77.296,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.927 | Acc: 50.232,77.027,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.923 | Acc: 50.103,77.221,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.932 | Acc: 50.205,77.117,90.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.950 | Acc: 50.039,77.159,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.946 | Acc: 50.160,77.262,90.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.950 | Acc: 50.058,77.305,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.953 | Acc: 50.067,77.231,90.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.962 | Acc: 49.955,77.165,90.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.960 | Acc: 50.069,77.155,90.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.961 | Acc: 50.008,77.146,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.967 | Acc: 49.930,77.001,90.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.973 | Acc: 50.000,76.845,89.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.975 | Acc: 49.977,76.796,89.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.976 | Acc: 49.900,76.809,89.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.977 | Acc: 49.918,76.753,89.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.171 | Acc: 53.906,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.365 | Acc: 47.396,65.885,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.365 | Acc: 46.361,65.206,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.366 | Acc: 45.850,65.305,70.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 2.926 | Acc: 50.781,75.781,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.934 | Acc: 49.926,76.451,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.931 | Acc: 49.638,76.944,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.954 | Acc: 49.244,76.716,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.965 | Acc: 49.209,76.611,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.966 | Acc: 49.234,76.663,89.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.976 | Acc: 49.135,76.711,89.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.975 | Acc: 49.208,76.795,89.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.973 | Acc: 49.204,76.810,89.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.979 | Acc: 49.266,76.739,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.978 | Acc: 49.207,76.590,89.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.974 | Acc: 49.261,76.524,89.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.976 | Acc: 49.287,76.595,89.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.976 | Acc: 49.177,76.691,89.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.972 | Acc: 49.263,76.682,89.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.965 | Acc: 49.424,76.710,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.962 | Acc: 49.506,76.694,90.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.956 | Acc: 49.654,76.732,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.959 | Acc: 49.632,76.682,90.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.957 | Acc: 49.684,76.712,90.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.288 | Acc: 50.000,67.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.418 | Acc: 46.205,65.141,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.422 | Acc: 45.751,65.053,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.412 | Acc: 45.453,65.151,71.094,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 2.942 | Acc: 48.438,76.562,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.939 | Acc: 49.554,76.786,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.920 | Acc: 50.038,77.077,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.925 | Acc: 49.693,77.152,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.908 | Acc: 50.058,77.324,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.912 | Acc: 50.224,77.375,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.919 | Acc: 50.155,77.253,90.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.919 | Acc: 50.144,77.383,90.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.920 | Acc: 50.092,77.305,90.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.924 | Acc: 50.035,77.344,90.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.934 | Acc: 49.833,77.223,90.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.939 | Acc: 49.799,77.075,90.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.935 | Acc: 49.825,77.169,90.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.935 | Acc: 49.850,77.003,90.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.932 | Acc: 49.922,77.016,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.931 | Acc: 49.925,76.973,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.939 | Acc: 49.830,76.906,90.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.943 | Acc: 49.801,76.833,90.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.947 | Acc: 49.877,76.742,90.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.951 | Acc: 49.789,76.694,90.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.427 | Acc: 49.219,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.403 | Acc: 46.615,65.885,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 45.865,65.149,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.445 | Acc: 45.658,65.126,70.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 3.336 | Acc: 46.094,65.625,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.901 | Acc: 50.335,76.674,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.901 | Acc: 50.705,77.439,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.879 | Acc: 51.114,77.485,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.910 | Acc: 50.637,77.238,90.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.906 | Acc: 50.534,77.305,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.914 | Acc: 50.368,77.247,90.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.912 | Acc: 50.338,77.438,91.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.916 | Acc: 50.170,77.431,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.917 | Acc: 49.961,77.430,90.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.913 | Acc: 50.074,77.503,90.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.918 | Acc: 50.198,77.379,90.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.911 | Acc: 50.269,77.379,90.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.913 | Acc: 50.210,77.287,90.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.921 | Acc: 50.122,77.105,90.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.929 | Acc: 49.995,76.921,90.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.931 | Acc: 50.007,76.867,90.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.931 | Acc: 49.998,76.936,90.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.931 | Acc: 49.950,76.980,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.934 | Acc: 49.918,76.893,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.432 | Acc: 49.219,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.487 | Acc: 46.503,65.216,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 45.770,64.615,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.464 | Acc: 45.825,64.793,70.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 2.951 | Acc: 46.094,73.438,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.917 | Acc: 50.149,76.525,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.869 | Acc: 51.124,77.172,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.877 | Acc: 50.897,77.062,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.896 | Acc: 50.656,76.833,90.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.901 | Acc: 50.596,76.841,90.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.906 | Acc: 50.678,76.892,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.910 | Acc: 50.582,76.906,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.916 | Acc: 50.529,76.897,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.910 | Acc: 50.613,76.934,90.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.918 | Acc: 50.424,76.885,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.915 | Acc: 50.467,76.859,90.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.913 | Acc: 50.470,76.880,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.919 | Acc: 50.365,76.874,90.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.920 | Acc: 50.373,76.868,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.918 | Acc: 50.343,77.001,90.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.917 | Acc: 50.321,76.984,90.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.917 | Acc: 50.273,76.961,90.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.919 | Acc: 50.203,77.006,90.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.921 | Acc: 50.209,77.007,90.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.533 | Acc: 50.000,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.501 | Acc: 46.689,64.249,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.492 | Acc: 45.732,64.062,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.479 | Acc: 45.377,64.434,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.920 | Acc: 47.656,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.886 | Acc: 49.479,76.823,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.887 | Acc: 49.886,76.753,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.917 | Acc: 49.552,76.819,91.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.908 | Acc: 49.797,76.794,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.893 | Acc: 50.070,76.926,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.894 | Acc: 50.000,76.956,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.897 | Acc: 50.022,77.050,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.901 | Acc: 49.981,77.057,91.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.905 | Acc: 50.030,77.102,91.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.907 | Acc: 50.031,77.111,91.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.911 | Acc: 49.912,77.181,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.913 | Acc: 49.903,77.091,91.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.909 | Acc: 49.844,77.176,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.910 | Acc: 49.919,77.157,90.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.912 | Acc: 49.860,77.100,90.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.915 | Acc: 49.757,77.120,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.920 | Acc: 49.750,77.099,90.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.921 | Acc: 49.794,77.123,90.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.926 | Acc: 49.834,77.130,90.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.418 | Acc: 48.438,64.062,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.476 | Acc: 46.094,65.327,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 45.160,64.920,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.468 | Acc: 45.108,64.946,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 2.972 | Acc: 58.594,75.781,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.851 | Acc: 50.521,78.869,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.845 | Acc: 50.705,78.735,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.857 | Acc: 50.768,78.010,91.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.836 | Acc: 50.810,78.231,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.851 | Acc: 50.534,77.854,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.863 | Acc: 50.291,77.860,91.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 50.371,77.770,90.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.872 | Acc: 50.378,77.645,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.877 | Acc: 50.358,77.620,90.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.883 | Acc: 50.330,77.600,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.874 | Acc: 50.463,77.616,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 50.489,77.593,91.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.872 | Acc: 50.476,77.556,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.878 | Acc: 50.286,77.530,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.884 | Acc: 50.317,77.502,90.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.889 | Acc: 50.224,77.412,90.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.893 | Acc: 50.144,77.348,90.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.892 | Acc: 50.214,77.407,90.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.894 | Acc: 50.201,77.383,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 45.312,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.443 | Acc: 46.429,64.881,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.464 | Acc: 45.713,64.634,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.455 | Acc: 45.633,64.780,70.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 2.949 | Acc: 49.219,78.906,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.892 | Acc: 50.074,76.637,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.850 | Acc: 50.476,77.306,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.835 | Acc: 50.615,77.357,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.865 | Acc: 50.347,77.566,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.857 | Acc: 50.518,77.584,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.865 | Acc: 50.400,77.428,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.858 | Acc: 50.360,77.554,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.867 | Acc: 50.378,77.329,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.870 | Acc: 50.328,77.331,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.883 | Acc: 50.198,77.146,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.891 | Acc: 50.163,77.079,91.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.891 | Acc: 50.246,77.172,91.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.893 | Acc: 50.278,77.263,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 50.306,77.230,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.893 | Acc: 50.223,77.196,91.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.895 | Acc: 50.163,77.246,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.899 | Acc: 50.071,77.174,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.898 | Acc: 50.082,77.171,90.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.898 | Acc: 50.082,77.210,90.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.466 | Acc: 46.094,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.413 | Acc: 46.689,64.993,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.440 | Acc: 45.979,64.634,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.437 | Acc: 45.710,64.767,70.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 2.637 | Acc: 57.031,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.856 | Acc: 51.488,78.088,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.867 | Acc: 50.514,77.744,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.857 | Acc: 50.487,77.869,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.878 | Acc: 50.376,77.643,91.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.890 | Acc: 50.039,77.522,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.897 | Acc: 50.097,77.415,91.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.901 | Acc: 49.978,77.272,91.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.898 | Acc: 49.893,77.179,91.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.895 | Acc: 49.918,77.270,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.889 | Acc: 50.016,77.425,91.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.886 | Acc: 49.975,77.425,91.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.887 | Acc: 49.958,77.360,91.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.887 | Acc: 49.940,77.377,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 49.869,77.341,91.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.894 | Acc: 49.829,77.256,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.892 | Acc: 49.886,77.220,91.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.896 | Acc: 49.810,77.167,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.888 | Acc: 49.909,77.223,91.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.888 | Acc: 49.945,77.241,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.590 | Acc: 45.312,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.478 | Acc: 46.391,64.435,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 46.018,64.882,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.463 | Acc: 45.492,65.061,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 2.652 | Acc: 55.469,82.812,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.756 | Acc: 49.888,78.943,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.796 | Acc: 50.057,78.011,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 50.154,78.227,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.815 | Acc: 50.309,78.385,91.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.829 | Acc: 50.480,77.893,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.847 | Acc: 50.200,77.557,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.847 | Acc: 50.327,77.466,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.845 | Acc: 50.252,77.504,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.837 | Acc: 50.358,77.611,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.847 | Acc: 50.159,77.616,91.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.855 | Acc: 50.088,77.503,91.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.855 | Acc: 50.201,77.444,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.863 | Acc: 50.132,77.368,91.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.863 | Acc: 50.136,77.422,91.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.871 | Acc: 50.070,77.388,91.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.870 | Acc: 50.168,77.366,91.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.875 | Acc: 50.099,77.353,91.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.874 | Acc: 50.145,77.370,91.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.878 | Acc: 50.100,77.354,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.664 | Acc: 46.094,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.462 | Acc: 46.205,64.658,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.490 | Acc: 45.713,64.596,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.494 | Acc: 45.505,64.613,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 3.101 | Acc: 44.531,71.875,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.859 | Acc: 50.781,77.344,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.827 | Acc: 51.467,77.992,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.864 | Acc: 50.461,77.792,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.870 | Acc: 50.405,77.855,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.851 | Acc: 50.572,77.700,91.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.842 | Acc: 50.794,77.699,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.852 | Acc: 50.682,77.554,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.844 | Acc: 50.602,77.528,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.840 | Acc: 50.587,77.585,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.851 | Acc: 50.567,77.456,91.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.855 | Acc: 50.470,77.414,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.860 | Acc: 50.447,77.435,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 50.296,77.371,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.864 | Acc: 50.331,77.499,91.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.863 | Acc: 50.369,77.598,91.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.865 | Acc: 50.329,77.536,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.865 | Acc: 50.325,77.550,91.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.867 | Acc: 50.309,77.547,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.874 | Acc: 50.176,77.510,91.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.732 | Acc: 46.875,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.625 | Acc: 45.164,64.435,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 44.741,64.120,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.609 | Acc: 44.518,64.267,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 2.568 | Acc: 50.000,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.812 | Acc: 51.749,78.237,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.814 | Acc: 50.934,78.296,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.821 | Acc: 50.179,78.291,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.828 | Acc: 50.617,78.048,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.842 | Acc: 50.503,77.893,91.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.832 | Acc: 50.303,78.015,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.844 | Acc: 50.205,77.781,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.856 | Acc: 50.175,77.562,91.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.851 | Acc: 50.367,77.568,91.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.856 | Acc: 50.295,77.589,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.859 | Acc: 50.244,77.619,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.858 | Acc: 50.305,77.551,91.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.864 | Acc: 50.275,77.478,91.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.860 | Acc: 50.414,77.561,91.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.856 | Acc: 50.426,77.660,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.853 | Acc: 50.467,77.658,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.859 | Acc: 50.433,77.564,91.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.863 | Acc: 50.435,77.489,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.864 | Acc: 50.431,77.493,91.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.754 | Acc: 46.875,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 46.763,64.546,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 45.675,64.215,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.557 | Acc: 45.261,64.280,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 2.518 | Acc: 57.031,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.842 | Acc: 50.893,77.865,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.856 | Acc: 50.991,77.630,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.864 | Acc: 50.269,77.549,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.875 | Acc: 50.309,77.546,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.871 | Acc: 50.271,77.638,91.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.865 | Acc: 50.581,77.634,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.863 | Acc: 50.609,77.726,91.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 50.650,77.863,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 50.591,77.939,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.851 | Acc: 50.513,78.036,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.849 | Acc: 50.527,78.019,91.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.856 | Acc: 50.308,77.914,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.856 | Acc: 50.257,77.838,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.857 | Acc: 50.234,77.802,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.861 | Acc: 50.182,77.712,91.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.860 | Acc: 50.236,77.706,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.863 | Acc: 50.229,77.697,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.861 | Acc: 50.255,77.671,91.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.863 | Acc: 50.310,77.584,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.808 | Acc: 45.312,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.516 | Acc: 46.503,65.960,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 45.732,64.615,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.537 | Acc: 45.338,64.562,69.915,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 2.779 | Acc: 57.031,78.125,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.817 | Acc: 49.777,79.390,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.845 | Acc: 49.428,78.296,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.843 | Acc: 49.616,77.997,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.819 | Acc: 50.125,77.980,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.818 | Acc: 50.116,78.202,91.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.822 | Acc: 50.387,78.261,91.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.818 | Acc: 50.360,78.341,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.832 | Acc: 50.364,78.183,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.824 | Acc: 50.488,78.267,91.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.823 | Acc: 50.637,78.218,91.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.832 | Acc: 50.551,78.054,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.830 | Acc: 50.609,78.102,91.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.838 | Acc: 50.383,78.041,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.840 | Acc: 50.445,77.992,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 50.262,77.878,91.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.847 | Acc: 50.277,77.843,91.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.843 | Acc: 50.277,77.866,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 50.325,77.950,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 50.328,77.895,91.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.576 | Acc: 45.312,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.436 | Acc: 47.098,65.476,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.469 | Acc: 45.865,64.882,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.474 | Acc: 46.055,64.972,69.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.685 | Acc: 48.438,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.851 | Acc: 50.074,76.860,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.809 | Acc: 50.877,77.649,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.781 | Acc: 50.551,77.894,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.791 | Acc: 50.540,77.961,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.815 | Acc: 49.954,77.707,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.828 | Acc: 49.877,77.660,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.830 | Acc: 49.922,77.770,91.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.824 | Acc: 50.301,77.737,91.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.828 | Acc: 50.272,77.775,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.829 | Acc: 50.257,77.767,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.830 | Acc: 50.350,77.747,91.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.838 | Acc: 50.347,77.652,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.844 | Acc: 50.350,77.649,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 50.342,77.777,91.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 50.254,77.808,91.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.838 | Acc: 50.329,77.726,91.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.842 | Acc: 50.273,77.724,91.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.845 | Acc: 50.240,77.690,91.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.844 | Acc: 50.312,77.723,91.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.723 | Acc: 47.656,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 46.466,64.025,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 46.075,64.158,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 45.863,64.242,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 2.794 | Acc: 49.219,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.832 | Acc: 49.888,78.757,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.810 | Acc: 49.581,78.735,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.818 | Acc: 49.795,78.458,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.813 | Acc: 50.231,78.289,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.814 | Acc: 50.495,78.195,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.828 | Acc: 50.187,78.060,91.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.837 | Acc: 50.227,78.025,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.833 | Acc: 50.214,78.047,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.839 | Acc: 50.086,77.965,92.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.839 | Acc: 50.043,77.927,91.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 50.237,77.966,91.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.836 | Acc: 50.259,77.911,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.834 | Acc: 50.299,77.945,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.830 | Acc: 50.339,77.955,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.833 | Acc: 50.327,77.873,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.832 | Acc: 50.402,77.862,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.833 | Acc: 50.373,77.919,91.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.835 | Acc: 50.355,77.924,91.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.839 | Acc: 50.336,77.860,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.635 | Acc: 48.438,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.518 | Acc: 46.838,64.509,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.532 | Acc: 46.037,64.329,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.541 | Acc: 45.607,64.280,69.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 2.933 | Acc: 51.562,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.796 | Acc: 50.818,79.092,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.826 | Acc: 50.419,78.449,92.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.819 | Acc: 50.897,78.151,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.822 | Acc: 50.907,78.318,92.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.819 | Acc: 50.998,78.140,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.820 | Acc: 51.136,78.170,92.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.818 | Acc: 51.031,78.247,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.829 | Acc: 50.786,78.227,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.828 | Acc: 50.747,78.242,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.825 | Acc: 50.770,78.218,92.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.818 | Acc: 50.802,78.256,92.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.822 | Acc: 50.697,78.183,92.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 50.653,78.140,92.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.830 | Acc: 50.503,78.122,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.828 | Acc: 50.545,78.120,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.828 | Acc: 50.518,78.086,92.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 50.502,78.068,92.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.826 | Acc: 50.539,78.084,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.824 | Acc: 50.533,78.059,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.678 | Acc: 46.875,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.525 | Acc: 46.317,64.732,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.563 | Acc: 45.255,64.043,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 45.133,64.178,69.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 2.846 | Acc: 50.781,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.851 | Acc: 50.260,78.125,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 51.124,79.249,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.799 | Acc: 51.025,78.868,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 51.003,78.791,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.793 | Acc: 50.781,78.697,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.796 | Acc: 50.826,78.390,92.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 50.731,78.131,92.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.804 | Acc: 50.825,78.023,92.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 50.699,77.901,92.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.805 | Acc: 50.816,77.946,92.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 50.795,77.920,92.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.820 | Acc: 50.580,77.775,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.819 | Acc: 50.688,77.757,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 50.723,77.816,91.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.815 | Acc: 50.670,77.897,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.822 | Acc: 50.594,77.821,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.822 | Acc: 50.525,77.770,91.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.831 | Acc: 50.390,77.658,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.831 | Acc: 50.392,77.619,91.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.696 | Acc: 46.094,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 46.317,65.067,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.552 | Acc: 45.846,64.958,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.563 | Acc: 45.261,65.138,69.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 2.913 | Acc: 49.219,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.740 | Acc: 50.930,79.725,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.780 | Acc: 50.667,79.078,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.770 | Acc: 50.871,79.073,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.790 | Acc: 50.666,78.636,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.799 | Acc: 50.464,78.651,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.799 | Acc: 50.381,78.680,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.802 | Acc: 50.399,78.507,92.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.805 | Acc: 50.345,78.309,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.809 | Acc: 50.255,78.190,91.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.817 | Acc: 50.140,78.055,91.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.815 | Acc: 50.148,78.160,92.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.819 | Acc: 50.237,78.190,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 50.192,78.056,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.824 | Acc: 50.222,78.042,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.821 | Acc: 50.223,78.000,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.826 | Acc: 50.229,77.969,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.823 | Acc: 50.351,77.994,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.822 | Acc: 50.351,78.036,91.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.824 | Acc: 50.246,78.096,91.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.842 | Acc: 46.875,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.608 | Acc: 46.391,63.728,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 45.312,63.720,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 45.248,63.640,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.805 | Acc: 50.000,82.812,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.830 | Acc: 48.586,79.464,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.774 | Acc: 50.572,79.211,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.782 | Acc: 50.692,78.676,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.795 | Acc: 50.694,78.366,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.796 | Acc: 50.402,78.164,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.794 | Acc: 50.220,78.235,92.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.790 | Acc: 50.183,78.191,92.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.794 | Acc: 50.286,78.159,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.798 | Acc: 50.302,78.250,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.796 | Acc: 50.260,78.304,92.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.789 | Acc: 50.456,78.348,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.800 | Acc: 50.376,78.190,92.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.802 | Acc: 50.323,78.197,92.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.804 | Acc: 50.228,78.183,92.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.805 | Acc: 50.241,78.211,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.810 | Acc: 50.200,78.193,92.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 50.257,78.136,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.817 | Acc: 50.190,78.086,92.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.817 | Acc: 50.224,78.121,91.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.505 | Acc: 51.562,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 47.284,64.993,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.529 | Acc: 46.303,64.634,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.553 | Acc: 45.953,64.626,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 2.526 | Acc: 53.125,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.676 | Acc: 50.893,80.618,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.740 | Acc: 50.191,79.421,93.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 50.948,79.265,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.753 | Acc: 50.704,79.292,92.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 50.425,79.030,92.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.770 | Acc: 50.471,78.738,92.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.771 | Acc: 50.532,78.563,92.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.765 | Acc: 50.451,78.707,92.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.771 | Acc: 50.488,78.652,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.771 | Acc: 50.505,78.638,92.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.773 | Acc: 50.417,78.567,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.778 | Acc: 50.525,78.514,92.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.779 | Acc: 50.617,78.508,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.778 | Acc: 50.626,78.434,92.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.779 | Acc: 50.600,78.475,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.785 | Acc: 50.526,78.441,92.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.795 | Acc: 50.396,78.354,92.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.797 | Acc: 50.403,78.352,92.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.802 | Acc: 50.420,78.301,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.512 | Acc: 48.438,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 47.024,63.542,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.585 | Acc: 45.808,63.396,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 45.671,63.947,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 2.768 | Acc: 43.750,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.747 | Acc: 49.888,78.609,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 50.686,78.659,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.770 | Acc: 50.564,78.074,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 50.395,77.797,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.796 | Acc: 50.077,77.908,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.799 | Acc: 50.207,77.822,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.792 | Acc: 50.183,78.059,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 50.121,78.076,92.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.782 | Acc: 50.358,78.298,92.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 50.202,78.277,92.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.788 | Acc: 50.194,78.213,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.795 | Acc: 50.266,78.063,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.803 | Acc: 50.201,77.868,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.803 | Acc: 50.295,77.858,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.805 | Acc: 50.202,77.865,92.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.804 | Acc: 50.234,77.865,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.804 | Acc: 50.257,77.935,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.803 | Acc: 50.333,77.937,92.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.806 | Acc: 50.295,77.947,92.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.459 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.554 | Acc: 45.833,63.914,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 45.217,63.948,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 45.172,64.114,69.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 2.476 | Acc: 47.656,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.767 | Acc: 49.740,79.427,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.774 | Acc: 50.038,79.192,92.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.762 | Acc: 50.551,78.624,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.771 | Acc: 50.357,78.598,92.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.781 | Acc: 50.340,78.589,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.784 | Acc: 50.446,78.583,92.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.779 | Acc: 50.576,78.446,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.775 | Acc: 50.529,78.406,92.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.775 | Acc: 50.591,78.492,92.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.776 | Acc: 50.567,78.448,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.775 | Acc: 50.548,78.433,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.781 | Acc: 50.525,78.443,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.792 | Acc: 50.503,78.305,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.792 | Acc: 50.506,78.400,92.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.797 | Acc: 50.433,78.361,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.799 | Acc: 50.399,78.283,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.799 | Acc: 50.401,78.233,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.799 | Acc: 50.392,78.227,92.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.800 | Acc: 50.373,78.195,92.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.709 | Acc: 47.656,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.639 | Acc: 46.726,64.621,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.639 | Acc: 45.789,64.234,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.626 | Acc: 45.466,64.178,69.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.714 | Acc: 50.781,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.765 | Acc: 50.149,79.725,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.768 | Acc: 50.476,79.421,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.758 | Acc: 50.730,79.226,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 51.071,78.993,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.761 | Acc: 50.920,78.868,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.768 | Acc: 50.865,78.661,92.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.771 | Acc: 50.831,78.662,92.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.769 | Acc: 51.029,78.736,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 50.811,78.570,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.771 | Acc: 50.746,78.541,92.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.780 | Acc: 50.686,78.436,92.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.790 | Acc: 50.564,78.352,92.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.787 | Acc: 50.662,78.403,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.787 | Acc: 50.676,78.420,92.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.793 | Acc: 50.636,78.353,92.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.794 | Acc: 50.599,78.286,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.796 | Acc: 50.566,78.244,92.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.794 | Acc: 50.615,78.238,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.795 | Acc: 50.630,78.193,92.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.698 | Acc: 46.875,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.630 | Acc: 45.610,63.653,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.657 | Acc: 44.970,63.453,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.661 | Acc: 44.685,63.806,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 2.933 | Acc: 47.656,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.781 | Acc: 50.409,78.609,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.753 | Acc: 50.896,78.735,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.780 | Acc: 50.448,78.356,93.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.770 | Acc: 50.598,78.318,93.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.771 | Acc: 50.472,78.063,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.764 | Acc: 50.517,78.119,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.776 | Acc: 50.360,78.108,92.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 50.281,78.183,92.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.786 | Acc: 50.341,78.207,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.783 | Acc: 50.424,78.280,92.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.784 | Acc: 50.491,78.408,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.782 | Acc: 50.483,78.433,92.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.782 | Acc: 50.539,78.400,92.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.772 | Acc: 50.695,78.503,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.773 | Acc: 50.680,78.488,92.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.774 | Acc: 50.679,78.495,92.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.775 | Acc: 50.598,78.501,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.780 | Acc: 50.567,78.447,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.778 | Acc: 50.611,78.426,92.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.672 | Acc: 46.094,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.561 | Acc: 45.424,65.365,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 45.122,65.053,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 44.685,64.793,69.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 2.727 | Acc: 53.906,74.219,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.782 | Acc: 50.930,77.567,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.759 | Acc: 50.534,78.754,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.788 | Acc: 50.166,78.407,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.786 | Acc: 50.212,78.385,92.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.785 | Acc: 50.240,78.380,92.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.780 | Acc: 50.542,78.390,92.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.775 | Acc: 50.670,78.374,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 50.689,78.241,92.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.779 | Acc: 50.634,78.276,92.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.777 | Acc: 50.704,78.191,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.782 | Acc: 50.640,78.093,92.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.784 | Acc: 50.525,78.063,92.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.787 | Acc: 50.509,78.095,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.787 | Acc: 50.573,78.144,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.789 | Acc: 50.535,78.146,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.791 | Acc: 50.448,78.135,92.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.794 | Acc: 50.422,78.098,92.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.795 | Acc: 50.426,78.119,92.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.795 | Acc: 50.480,78.125,92.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.648 | Acc: 47.656,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.691 | Acc: 45.610,64.472,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.697 | Acc: 45.027,64.310,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.696 | Acc: 44.595,64.485,69.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 3.154 | Acc: 49.219,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.822 | Acc: 49.219,77.679,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 50.857,78.773,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.771 | Acc: 50.756,78.804,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.771 | Acc: 50.723,78.598,92.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.759 | Acc: 50.890,78.643,92.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.766 | Acc: 50.755,78.583,92.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.766 | Acc: 50.809,78.679,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.766 | Acc: 50.844,78.722,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.769 | Acc: 50.781,78.695,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.769 | Acc: 50.820,78.720,92.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.764 | Acc: 50.877,78.754,92.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.770 | Acc: 50.746,78.627,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.769 | Acc: 50.862,78.601,92.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.767 | Acc: 50.912,78.648,92.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.771 | Acc: 50.908,78.629,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.768 | Acc: 50.830,78.663,92.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.773 | Acc: 50.625,78.618,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.778 | Acc: 50.608,78.560,92.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.780 | Acc: 50.630,78.504,92.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.493 | Acc: 49.219,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.570 | Acc: 46.577,63.988,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.577 | Acc: 45.808,63.796,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 45.415,63.960,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 3.193 | Acc: 44.531,71.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.751 | Acc: 50.781,79.464,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.710 | Acc: 51.048,79.402,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 50.884,79.329,93.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.703 | Acc: 51.427,79.369,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.703 | Acc: 51.601,79.216,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.720 | Acc: 51.240,78.958,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.731 | Acc: 50.947,78.757,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.736 | Acc: 50.961,78.702,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.743 | Acc: 50.863,78.665,92.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.741 | Acc: 50.910,78.731,92.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.738 | Acc: 50.972,78.712,92.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.737 | Acc: 50.898,78.734,92.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.741 | Acc: 50.889,78.700,92.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.746 | Acc: 50.712,78.631,92.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.747 | Acc: 50.667,78.660,92.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.755 | Acc: 50.633,78.600,92.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.760 | Acc: 50.545,78.565,92.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.757 | Acc: 50.636,78.636,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.760 | Acc: 50.580,78.652,92.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.623 | Acc: 45.312,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 46.577,64.695,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 45.732,64.348,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 45.312,64.575,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 2.530 | Acc: 51.562,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 52.381,79.762,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.701 | Acc: 51.601,79.078,93.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 51.255,78.689,93.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.726 | Acc: 51.206,78.704,92.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.726 | Acc: 51.122,78.759,92.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.729 | Acc: 51.091,78.564,92.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.746 | Acc: 50.975,78.385,92.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.751 | Acc: 51.063,78.358,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.755 | Acc: 50.889,78.246,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.753 | Acc: 50.843,78.304,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.751 | Acc: 50.954,78.355,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.756 | Acc: 50.830,78.365,92.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.760 | Acc: 50.781,78.373,92.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.760 | Acc: 50.840,78.459,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.759 | Acc: 50.895,78.460,92.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.760 | Acc: 50.913,78.461,92.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.765 | Acc: 50.850,78.439,92.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.765 | Acc: 50.961,78.428,92.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.767 | Acc: 50.871,78.398,92.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.701 | Acc: 45.312,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.588 | Acc: 45.685,64.174,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.630 | Acc: 44.931,63.834,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.638 | Acc: 44.647,63.883,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.525 | Acc: 50.000,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.643 | Acc: 53.088,80.283,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.696 | Acc: 51.124,80.107,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.699 | Acc: 51.281,79.675,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.731 | Acc: 50.733,79.398,93.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.726 | Acc: 51.137,79.394,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.738 | Acc: 51.136,79.229,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.746 | Acc: 51.020,78.989,92.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.757 | Acc: 50.961,78.916,92.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.758 | Acc: 51.010,78.820,92.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.761 | Acc: 51.038,78.848,92.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.760 | Acc: 50.962,78.818,92.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.760 | Acc: 50.879,78.705,92.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.770 | Acc: 50.811,78.577,92.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.768 | Acc: 50.842,78.623,92.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.770 | Acc: 50.888,78.623,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.773 | Acc: 50.925,78.524,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.774 | Acc: 50.958,78.547,92.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.771 | Acc: 50.980,78.523,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.767 | Acc: 51.042,78.543,92.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.669 | Acc: 48.438,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.648 | Acc: 45.871,64.360,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.661 | Acc: 45.274,63.967,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.645 | Acc: 45.287,64.062,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 2.564 | Acc: 53.906,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.777 | Acc: 49.479,79.427,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.777 | Acc: 50.362,79.478,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.765 | Acc: 50.397,79.239,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.758 | Acc: 50.473,78.983,92.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.769 | Acc: 50.418,78.605,92.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.760 | Acc: 50.562,78.674,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.752 | Acc: 50.698,78.618,93.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.744 | Acc: 50.927,78.722,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.749 | Acc: 50.846,78.548,92.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 50.719,78.545,92.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.766 | Acc: 50.608,78.387,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.759 | Acc: 50.697,78.485,92.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.763 | Acc: 50.572,78.427,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.764 | Acc: 50.628,78.395,92.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.767 | Acc: 50.558,78.348,92.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.764 | Acc: 50.613,78.388,92.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.762 | Acc: 50.708,78.423,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.767 | Acc: 50.697,78.398,92.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.769 | Acc: 50.671,78.390,92.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.756 | Acc: 47.656,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.709 | Acc: 45.499,64.807,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.719 | Acc: 45.084,64.043,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.739 | Acc: 44.480,64.178,68.712,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.452 | Acc: 56.250,83.594,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.718 | Acc: 51.004,79.055,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.744 | Acc: 50.400,79.364,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.754 | Acc: 50.179,79.137,92.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.746 | Acc: 50.675,78.926,92.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.761 | Acc: 50.541,78.713,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.767 | Acc: 50.704,78.474,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.760 | Acc: 50.831,78.629,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.752 | Acc: 50.922,78.639,92.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.753 | Acc: 50.963,78.626,92.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 50.805,78.646,92.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.761 | Acc: 50.675,78.588,92.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.763 | Acc: 50.580,78.634,92.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.761 | Acc: 50.635,78.616,92.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.765 | Acc: 50.520,78.581,92.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.762 | Acc: 50.610,78.631,92.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.769 | Acc: 50.518,78.619,92.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.768 | Acc: 50.561,78.599,92.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.767 | Acc: 50.599,78.610,92.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.768 | Acc: 50.619,78.552,92.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.659 | Acc: 49.219,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.737 | Acc: 45.759,62.872,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.732 | Acc: 44.836,63.300,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.722 | Acc: 44.352,63.448,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 2.579 | Acc: 50.000,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.664 | Acc: 50.632,79.985,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.714 | Acc: 50.305,79.592,93.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.707 | Acc: 50.512,79.521,93.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.705 | Acc: 50.646,79.552,93.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.727 | Acc: 50.240,79.378,92.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.731 | Acc: 50.413,79.358,93.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.736 | Acc: 50.393,79.139,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.739 | Acc: 50.427,79.134,93.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.742 | Acc: 50.436,79.027,93.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.744 | Acc: 50.358,78.976,93.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.743 | Acc: 50.368,78.938,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.748 | Acc: 50.376,78.952,92.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.744 | Acc: 50.557,78.996,92.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.749 | Acc: 50.539,78.948,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.750 | Acc: 50.540,78.984,92.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.754 | Acc: 50.514,78.853,92.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.757 | Acc: 50.447,78.842,92.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.756 | Acc: 50.450,78.794,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.758 | Acc: 50.486,78.724,92.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.865 | Acc: 45.312,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.711 | Acc: 45.089,63.653,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.731 | Acc: 44.569,63.643,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.742 | Acc: 44.416,63.576,69.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.718 | Acc: 53.906,85.156,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.753 | Acc: 51.004,78.385,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.686 | Acc: 51.886,79.116,93.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.688 | Acc: 51.870,79.559,93.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.706 | Acc: 51.688,79.215,93.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.725 | Acc: 51.593,78.813,92.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.732 | Acc: 51.227,78.706,92.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.730 | Acc: 51.191,78.812,93.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.739 | Acc: 51.121,78.921,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.740 | Acc: 51.040,78.967,92.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.746 | Acc: 51.007,78.875,92.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.753 | Acc: 50.905,78.818,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.757 | Acc: 50.836,78.809,92.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.754 | Acc: 50.829,78.763,92.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.753 | Acc: 50.865,78.798,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.755 | Acc: 50.841,78.725,92.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.754 | Acc: 50.767,78.758,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.757 | Acc: 50.713,78.789,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.756 | Acc: 50.710,78.813,92.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.757 | Acc: 50.709,78.779,92.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.603 | Acc: 49.219,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.623 | Acc: 46.577,64.509,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.674 | Acc: 45.541,64.139,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.658 | Acc: 45.389,64.575,68.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.622 | Acc: 49.219,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.690 | Acc: 50.670,78.534,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 50.800,78.392,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 50.871,78.484,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.703 | Acc: 51.350,78.935,93.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.713 | Acc: 51.160,78.837,93.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.712 | Acc: 51.078,78.932,93.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.718 | Acc: 50.953,78.912,93.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.725 | Acc: 50.937,78.751,93.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.730 | Acc: 50.824,78.824,93.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.728 | Acc: 50.968,78.778,93.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.736 | Acc: 50.976,78.606,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.736 | Acc: 50.953,78.689,93.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.735 | Acc: 50.946,78.766,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.735 | Acc: 50.968,78.734,92.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.741 | Acc: 50.921,78.675,92.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.742 | Acc: 50.986,78.607,92.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.744 | Acc: 50.912,78.572,92.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.747 | Acc: 50.909,78.553,92.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.750 | Acc: 50.900,78.556,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.803 | Acc: 46.875,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.652 | Acc: 45.312,63.914,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.677 | Acc: 45.217,63.510,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 44.864,63.678,68.840,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 3.213 | Acc: 46.094,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 49.963,78.609,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.693 | Acc: 50.991,79.402,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.686 | Acc: 51.294,79.406,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.708 | Acc: 51.090,79.282,93.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.729 | Acc: 51.052,79.038,93.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.744 | Acc: 50.607,78.803,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.734 | Acc: 50.754,78.901,93.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.721 | Acc: 51.034,78.979,93.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.727 | Acc: 50.980,78.833,93.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.737 | Acc: 50.836,78.755,92.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.739 | Acc: 50.696,78.765,92.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.741 | Acc: 50.801,78.738,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.745 | Acc: 50.763,78.694,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.744 | Acc: 50.723,78.742,92.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.744 | Acc: 50.719,78.751,92.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.745 | Acc: 50.803,78.726,92.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.742 | Acc: 50.900,78.771,92.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.742 | Acc: 50.902,78.789,92.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.744 | Acc: 50.912,78.718,92.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.745 | Acc: 47.656,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.633 | Acc: 46.168,63.579,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.636 | Acc: 45.560,63.872,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.630 | Acc: 45.146,64.127,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.557 | Acc: 49.219,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.703 | Acc: 51.116,79.204,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.668 | Acc: 51.486,79.688,93.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.698 | Acc: 51.101,79.457,93.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.710 | Acc: 50.637,79.282,93.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.715 | Acc: 50.557,79.192,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.724 | Acc: 50.710,79.152,93.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.729 | Acc: 50.560,79.050,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.731 | Acc: 50.694,78.964,93.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.732 | Acc: 50.708,78.984,93.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.735 | Acc: 50.649,78.965,93.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.732 | Acc: 50.668,79.016,93.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.733 | Acc: 50.571,78.919,93.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.738 | Acc: 50.476,78.909,93.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.743 | Acc: 50.509,78.873,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.741 | Acc: 50.620,78.828,93.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.744 | Acc: 50.562,78.826,93.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.749 | Acc: 50.483,78.748,92.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.748 | Acc: 50.446,78.768,93.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.747 | Acc: 50.488,78.783,93.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.478 | Acc: 43.750,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.630 | Acc: 46.168,64.472,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.652 | Acc: 45.598,64.043,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.655 | Acc: 45.274,64.216,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 2.580 | Acc: 50.000,83.594,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.652 | Acc: 52.009,80.097,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.685 | Acc: 51.334,79.478,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.690 | Acc: 51.306,79.367,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.711 | Acc: 51.235,79.061,93.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.711 | Acc: 50.990,79.254,93.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.713 | Acc: 50.956,79.126,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.725 | Acc: 50.887,79.117,93.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.718 | Acc: 50.932,79.333,93.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.710 | Acc: 50.984,79.489,93.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.716 | Acc: 50.952,79.404,93.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.715 | Acc: 50.753,79.415,93.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.719 | Acc: 50.613,79.334,93.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.718 | Acc: 50.596,79.295,93.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.726 | Acc: 50.550,79.181,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.727 | Acc: 50.584,79.174,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.729 | Acc: 50.511,79.218,93.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.727 | Acc: 50.662,79.229,93.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.729 | Acc: 50.641,79.166,93.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.731 | Acc: 50.644,79.138,92.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.522 | Acc: 46.094,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.670 | Acc: 44.978,64.397,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.719 | Acc: 44.588,63.739,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.732 | Acc: 44.518,63.550,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 2.531 | Acc: 53.125,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.680 | Acc: 50.818,79.464,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.697 | Acc: 51.277,79.345,93.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 50.922,79.252,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.697 | Acc: 51.264,79.253,93.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.694 | Acc: 51.361,79.417,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.691 | Acc: 51.291,79.487,93.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.692 | Acc: 51.186,79.449,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.692 | Acc: 50.985,79.459,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.696 | Acc: 50.803,79.459,93.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.703 | Acc: 50.875,79.283,93.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.719 | Acc: 50.686,79.037,93.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.718 | Acc: 50.720,79.013,93.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.720 | Acc: 50.706,79.032,92.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.722 | Acc: 50.715,79.073,92.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.722 | Acc: 50.727,79.093,92.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.724 | Acc: 50.793,79.074,92.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.726 | Acc: 50.800,79.057,92.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.731 | Acc: 50.801,79.038,92.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.736 | Acc: 50.691,78.986,92.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.539 | Acc: 49.219,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.577 | Acc: 46.019,63.356,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 45.236,63.472,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 45.108,63.717,69.864,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.731 | Acc: 46.875,75.000,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.698 | Acc: 51.079,79.688,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.692 | Acc: 51.601,79.726,93.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.695 | Acc: 51.268,79.713,93.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.706 | Acc: 51.100,79.321,93.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.705 | Acc: 51.222,79.432,93.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.717 | Acc: 51.156,79.339,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.712 | Acc: 51.424,79.211,93.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.718 | Acc: 51.364,79.168,93.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.711 | Acc: 51.334,79.273,93.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.711 | Acc: 51.283,79.248,93.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.710 | Acc: 51.258,79.235,93.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.712 | Acc: 51.144,79.204,93.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.719 | Acc: 51.075,79.041,92.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.728 | Acc: 50.976,78.909,92.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.734 | Acc: 50.882,78.896,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.737 | Acc: 50.825,78.838,92.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.739 | Acc: 50.809,78.810,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.740 | Acc: 50.835,78.839,92.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.739 | Acc: 50.785,78.841,92.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.665 | Acc: 43.750,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.700 | Acc: 45.312,63.728,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.715 | Acc: 44.379,63.396,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.712 | Acc: 44.480,63.653,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.289 | Acc: 61.719,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.597 | Acc: 53.013,79.836,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.663 | Acc: 51.810,79.192,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.703 | Acc: 51.230,78.753,93.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.715 | Acc: 50.839,78.897,93.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.710 | Acc: 50.774,79.115,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.713 | Acc: 50.639,79.061,93.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.724 | Acc: 50.587,78.906,93.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.723 | Acc: 50.665,79.013,93.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.730 | Acc: 50.548,78.911,93.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.732 | Acc: 50.626,78.961,93.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.724 | Acc: 50.795,78.945,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.733 | Acc: 50.532,78.900,92.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.737 | Acc: 50.497,78.795,92.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.733 | Acc: 50.500,78.828,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.731 | Acc: 50.568,78.774,92.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.731 | Acc: 50.596,78.785,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.733 | Acc: 50.573,78.755,92.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.737 | Acc: 50.615,78.660,92.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.737 | Acc: 50.648,78.613,92.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.788 | Acc: 48.438,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.741 | Acc: 46.057,63.876,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.769 | Acc: 45.027,63.091,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.776 | Acc: 44.800,63.409,67.444,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.945 | Acc: 42.969,71.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.627 | Acc: 52.641,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.669 | Acc: 52.268,80.488,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.686 | Acc: 51.562,80.149,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.694 | Acc: 51.534,80.112,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.685 | Acc: 51.470,80.244,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.694 | Acc: 51.194,79.888,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.704 | Acc: 51.213,79.688,93.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.704 | Acc: 51.189,79.518,93.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.706 | Acc: 51.187,79.334,93.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.716 | Acc: 51.007,79.225,93.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.722 | Acc: 50.799,79.189,93.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.723 | Acc: 50.833,79.230,93.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.725 | Acc: 50.862,79.173,93.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.724 | Acc: 50.931,79.159,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.728 | Acc: 50.864,79.075,93.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.728 | Acc: 50.918,79.057,93.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.726 | Acc: 50.935,79.094,93.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.728 | Acc: 50.918,79.025,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.728 | Acc: 50.841,79.019,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.565 | Acc: 45.312,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.621 | Acc: 45.089,64.658,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.647 | Acc: 45.122,63.986,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.654 | Acc: 45.197,64.050,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 2.641 | Acc: 55.469,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.780 | Acc: 51.153,77.567,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.774 | Acc: 50.591,77.782,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.760 | Acc: 50.064,77.971,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.756 | Acc: 50.019,78.260,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.741 | Acc: 50.116,78.659,93.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.748 | Acc: 50.303,78.428,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.737 | Acc: 50.549,78.757,93.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.738 | Acc: 50.757,78.678,93.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.741 | Acc: 50.691,78.665,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.736 | Acc: 50.770,78.879,93.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.728 | Acc: 50.749,79.058,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.727 | Acc: 50.755,79.004,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.733 | Acc: 50.757,78.948,93.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.733 | Acc: 50.803,78.937,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.733 | Acc: 50.748,78.948,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.734 | Acc: 50.789,78.943,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.735 | Acc: 50.816,78.918,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.735 | Acc: 50.818,78.980,93.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.734 | Acc: 50.886,78.984,93.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.755 | Acc: 47.656,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.654 | Acc: 44.978,63.951,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.703 | Acc: 44.055,64.291,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.716 | Acc: 44.198,64.421,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 2.536 | Acc: 50.781,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.671 | Acc: 49.740,79.874,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.669 | Acc: 50.686,80.221,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.651 | Acc: 51.217,80.213,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.652 | Acc: 51.379,80.170,93.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.648 | Acc: 51.253,80.082,93.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.651 | Acc: 51.240,80.004,93.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.672 | Acc: 51.180,79.737,93.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.678 | Acc: 51.043,79.707,93.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.675 | Acc: 51.001,79.713,93.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.677 | Acc: 50.894,79.719,93.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.685 | Acc: 50.905,79.528,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.693 | Acc: 50.904,79.477,93.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.693 | Acc: 51.003,79.367,93.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.698 | Acc: 50.998,79.332,93.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.698 | Acc: 51.002,79.264,93.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.706 | Acc: 50.857,79.176,93.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.710 | Acc: 50.788,79.158,93.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.715 | Acc: 50.768,79.090,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.720 | Acc: 50.736,79.064,93.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.886 | Acc: 42.188,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.701 | Acc: 46.280,64.062,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.751 | Acc: 45.046,63.396,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.749 | Acc: 44.839,63.537,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.542 | Acc: 51.562,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.756 | Acc: 50.707,78.423,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.719 | Acc: 50.610,79.345,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 50.999,79.316,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.717 | Acc: 50.907,79.051,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.716 | Acc: 50.828,79.169,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.711 | Acc: 50.807,79.468,93.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.719 | Acc: 50.682,79.305,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.709 | Acc: 50.776,79.566,93.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.709 | Acc: 50.893,79.532,93.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.719 | Acc: 50.700,79.377,93.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.722 | Acc: 50.739,79.345,92.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.727 | Acc: 50.697,79.315,93.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.724 | Acc: 50.718,79.343,93.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.724 | Acc: 50.692,79.348,93.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.719 | Acc: 50.693,79.418,93.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.716 | Acc: 50.720,79.422,93.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.722 | Acc: 50.651,79.367,93.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.727 | Acc: 50.695,79.304,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.730 | Acc: 50.658,79.257,92.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.825 | Acc: 45.312,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.758 | Acc: 46.429,62.909,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.755 | Acc: 45.751,62.767,68.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.758 | Acc: 45.556,62.897,68.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 2.041 | Acc: 60.938,89.062,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.764 | Acc: 49.330,79.167,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 50.362,79.783,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.694 | Acc: 50.986,79.636,93.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.670 | Acc: 51.292,79.765,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.676 | Acc: 51.253,79.564,93.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.683 | Acc: 51.149,79.642,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.688 | Acc: 51.003,79.632,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.698 | Acc: 50.883,79.566,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.702 | Acc: 50.885,79.515,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.701 | Acc: 50.797,79.532,93.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.705 | Acc: 50.778,79.504,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.710 | Acc: 50.635,79.522,93.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.708 | Acc: 50.679,79.604,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.708 | Acc: 50.751,79.574,93.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.713 | Acc: 50.690,79.451,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.719 | Acc: 50.643,79.330,93.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.722 | Acc: 50.671,79.216,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.720 | Acc: 50.690,79.242,93.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.724 | Acc: 50.703,79.150,92.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.861 | Acc: 46.875,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.779 | Acc: 44.606,62.946,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.862 | Acc: 43.502,62.557,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.855 | Acc: 43.251,62.897,67.725,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 2.387 | Acc: 53.906,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.719 | Acc: 49.740,79.539,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.709 | Acc: 49.867,79.592,93.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 50.051,79.393,93.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.704 | Acc: 50.791,79.456,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.689 | Acc: 50.774,79.564,93.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.692 | Acc: 51.085,79.675,93.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.689 | Acc: 50.898,79.555,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.688 | Acc: 51.116,79.459,93.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.701 | Acc: 51.105,79.269,93.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.700 | Acc: 51.116,79.419,93.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.709 | Acc: 50.976,79.189,93.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.710 | Acc: 51.034,79.117,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.710 | Acc: 51.051,79.134,93.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.713 | Acc: 51.001,79.095,93.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.712 | Acc: 51.028,79.153,93.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.716 | Acc: 51.012,79.096,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.718 | Acc: 50.935,79.076,93.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.719 | Acc: 50.924,79.064,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.721 | Acc: 50.937,78.980,93.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.583 | Acc: 51.562,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.710 | Acc: 45.201,64.137,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.747 | Acc: 44.703,63.262,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.750 | Acc: 44.416,63.397,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 2.876 | Acc: 46.094,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.743 | Acc: 50.632,79.167,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.710 | Acc: 50.629,79.764,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.726 | Acc: 50.102,79.086,93.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.713 | Acc: 50.617,79.176,93.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.695 | Acc: 50.820,79.339,93.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.697 | Acc: 50.807,79.197,93.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.713 | Acc: 50.798,79.000,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.713 | Acc: 51.014,78.989,93.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.707 | Acc: 51.122,79.174,93.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.710 | Acc: 51.014,79.155,93.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.712 | Acc: 51.082,79.108,93.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.717 | Acc: 50.872,79.004,93.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.716 | Acc: 50.838,78.987,93.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.713 | Acc: 50.870,79.079,93.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.714 | Acc: 50.797,79.041,93.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.715 | Acc: 50.723,79.064,93.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.714 | Acc: 50.763,79.119,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.718 | Acc: 50.738,79.045,93.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.715 | Acc: 50.835,79.040,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.726 | Acc: 47.656,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.677 | Acc: 45.796,64.025,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.710 | Acc: 45.751,63.567,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.697 | Acc: 45.453,63.717,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 2.697 | Acc: 53.906,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.657 | Acc: 50.632,79.576,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.650 | Acc: 50.857,79.707,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.693 | Acc: 50.525,79.252,93.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.685 | Acc: 51.061,79.495,93.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.681 | Acc: 51.214,79.409,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.700 | Acc: 50.852,79.332,93.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.693 | Acc: 50.942,79.405,93.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.693 | Acc: 51.082,79.241,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.688 | Acc: 51.083,79.195,93.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.692 | Acc: 51.096,79.054,93.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.705 | Acc: 51.036,78.889,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.707 | Acc: 51.005,78.854,93.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.713 | Acc: 50.859,78.828,93.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.708 | Acc: 50.876,78.862,93.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.707 | Acc: 50.818,78.808,93.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.704 | Acc: 50.849,78.838,93.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.710 | Acc: 50.800,78.835,93.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.710 | Acc: 50.859,78.863,93.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.714 | Acc: 50.865,78.810,93.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.583 | Acc: 46.094,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.698 | Acc: 45.275,64.509,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.731 | Acc: 45.046,63.643,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.715 | Acc: 44.928,63.640,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.641 | Acc: 53.125,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.632 | Acc: 51.935,80.580,93.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.639 | Acc: 51.639,80.240,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.670 | Acc: 51.204,79.969,93.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.659 | Acc: 51.833,79.716,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.671 | Acc: 51.501,79.556,93.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.676 | Acc: 51.530,79.604,93.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.669 | Acc: 51.585,79.771,93.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.681 | Acc: 51.407,79.595,93.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.686 | Acc: 51.269,79.472,93.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.695 | Acc: 51.248,79.307,93.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.702 | Acc: 51.078,79.228,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.700 | Acc: 51.057,79.253,93.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.710 | Acc: 50.928,79.191,93.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.716 | Acc: 50.904,79.201,93.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.718 | Acc: 50.877,79.122,93.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.717 | Acc: 50.864,79.164,93.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.714 | Acc: 50.907,79.213,93.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.720 | Acc: 50.855,79.103,93.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.716 | Acc: 50.863,79.206,93.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.927 | Acc: 44.531,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.738 | Acc: 45.908,64.397,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.754 | Acc: 45.560,63.815,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.757 | Acc: 45.351,63.730,68.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 2.906 | Acc: 50.000,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.620 | Acc: 53.013,80.171,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.671 | Acc: 51.829,79.306,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.736 | Acc: 50.576,78.906,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.724 | Acc: 50.318,79.311,93.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.724 | Acc: 50.456,79.254,93.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.729 | Acc: 50.484,79.100,93.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.704 | Acc: 50.931,79.211,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.699 | Acc: 51.087,79.183,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.709 | Acc: 51.127,79.010,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.701 | Acc: 51.236,79.023,93.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.707 | Acc: 51.032,79.104,93.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.708 | Acc: 51.076,79.046,93.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.710 | Acc: 51.081,79.071,93.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.708 | Acc: 51.037,79.120,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.713 | Acc: 51.017,79.078,93.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.715 | Acc: 50.915,79.106,93.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.712 | Acc: 51.093,79.165,93.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.713 | Acc: 51.121,79.123,93.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.716 | Acc: 51.058,79.060,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.031 | Acc: 46.875,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.818 | Acc: 45.685,62.872,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.837 | Acc: 44.607,63.034,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.856 | Acc: 44.185,63.153,68.558,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 2.509 | Acc: 54.688,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.629 | Acc: 52.381,80.320,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.662 | Acc: 51.086,79.840,93.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.656 | Acc: 51.037,79.918,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.685 | Acc: 50.733,79.639,93.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.686 | Acc: 50.719,79.517,93.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.687 | Acc: 50.833,79.520,93.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.685 | Acc: 50.803,79.527,93.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.687 | Acc: 50.941,79.523,93.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.688 | Acc: 51.066,79.446,93.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.691 | Acc: 51.014,79.450,93.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.700 | Acc: 50.969,79.299,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.700 | Acc: 51.015,79.269,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.699 | Acc: 51.000,79.310,93.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.702 | Acc: 50.929,79.284,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.702 | Acc: 51.012,79.231,93.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.704 | Acc: 51.066,79.201,93.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.708 | Acc: 51.058,79.131,93.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.712 | Acc: 50.935,79.062,93.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.716 | Acc: 50.974,79.040,92.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.909 | Acc: 46.094,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.837 | Acc: 45.312,63.318,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.841 | Acc: 44.760,62.652,68.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.841 | Acc: 44.903,62.897,68.135,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.784 | Acc: 47.656,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 50.037,78.943,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.712 | Acc: 50.553,78.735,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.702 | Acc: 50.832,79.047,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.675 | Acc: 51.119,79.581,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.681 | Acc: 50.866,79.718,93.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.686 | Acc: 50.988,79.726,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.689 | Acc: 51.003,79.649,93.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.683 | Acc: 50.956,79.726,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.683 | Acc: 50.906,79.744,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.689 | Acc: 50.812,79.470,93.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.694 | Acc: 50.764,79.373,93.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.693 | Acc: 50.862,79.367,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.698 | Acc: 50.883,79.298,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.698 | Acc: 50.876,79.268,93.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.697 | Acc: 50.901,79.270,93.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.697 | Acc: 50.883,79.225,93.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.701 | Acc: 50.841,79.211,93.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.704 | Acc: 50.905,79.179,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.709 | Acc: 50.845,79.078,93.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.894 | Acc: 46.094,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.699 | Acc: 44.940,63.467,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.758 | Acc: 44.855,63.510,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.749 | Acc: 44.570,63.627,68.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.758 | Acc: 51.562,79.688,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.690 | Acc: 49.591,79.204,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 49.619,79.364,93.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 50.205,79.521,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.706 | Acc: 49.990,79.630,93.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.706 | Acc: 50.193,79.641,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.707 | Acc: 50.542,79.675,93.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.704 | Acc: 50.393,79.793,93.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.705 | Acc: 50.461,79.848,93.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.693 | Acc: 50.634,79.990,93.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.691 | Acc: 50.494,79.917,93.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.694 | Acc: 50.389,79.815,93.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.693 | Acc: 50.460,79.820,93.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.689 | Acc: 50.602,79.828,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.692 | Acc: 50.701,79.740,93.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.694 | Acc: 50.657,79.682,93.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.696 | Acc: 50.723,79.646,93.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.703 | Acc: 50.598,79.525,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.707 | Acc: 50.480,79.469,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.705 | Acc: 50.535,79.423,93.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.873 | Acc: 46.094,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.758 | Acc: 44.420,63.653,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.789 | Acc: 44.303,63.434,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.796 | Acc: 43.788,63.537,68.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 2.753 | Acc: 50.781,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.659 | Acc: 51.228,79.948,93.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.614 | Acc: 52.039,80.412,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.626 | Acc: 51.639,80.302,93.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.651 | Acc: 51.418,80.035,93.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.662 | Acc: 51.431,79.734,93.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.675 | Acc: 51.420,79.533,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.679 | Acc: 51.186,79.555,93.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.677 | Acc: 51.174,79.498,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.684 | Acc: 51.157,79.429,93.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.685 | Acc: 51.100,79.489,93.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.688 | Acc: 51.089,79.415,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.693 | Acc: 51.070,79.441,93.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.695 | Acc: 51.030,79.472,93.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.694 | Acc: 50.995,79.368,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.697 | Acc: 50.955,79.386,93.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.700 | Acc: 50.927,79.320,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.706 | Acc: 50.914,79.252,93.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.708 | Acc: 50.881,79.242,93.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.710 | Acc: 50.814,79.202,93.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.052 | Acc: 50.781,57.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.769 | Acc: 46.540,63.244,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.773 | Acc: 45.751,63.224,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.766 | Acc: 45.927,63.461,68.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 2.826 | Acc: 42.969,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 49.702,79.762,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.702 | Acc: 49.619,80.126,93.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.702 | Acc: 49.795,80.008,93.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.715 | Acc: 49.749,79.726,93.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.702 | Acc: 49.861,79.819,93.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.700 | Acc: 49.864,79.597,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.703 | Acc: 49.989,79.449,93.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.704 | Acc: 50.058,79.445,93.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.699 | Acc: 50.142,79.334,93.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.691 | Acc: 50.350,79.369,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.686 | Acc: 50.534,79.285,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.691 | Acc: 50.415,79.224,93.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.691 | Acc: 50.518,79.197,93.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.690 | Acc: 50.592,79.301,93.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.696 | Acc: 50.504,79.233,93.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.700 | Acc: 50.543,79.174,93.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.704 | Acc: 50.621,79.119,93.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.706 | Acc: 50.604,79.051,93.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.707 | Acc: 50.572,79.019,93.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.895 | Acc: 48.438,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.753 | Acc: 45.387,62.463,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.785 | Acc: 45.312,62.767,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.822 | Acc: 44.800,62.961,67.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 2.604 | Acc: 46.875,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.625 | Acc: 50.781,80.469,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.626 | Acc: 51.486,80.126,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.674 | Acc: 50.640,79.752,93.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.691 | Acc: 50.704,79.823,93.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.704 | Acc: 50.441,79.494,93.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.699 | Acc: 50.374,79.481,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.697 | Acc: 50.211,79.471,93.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.696 | Acc: 50.403,79.401,93.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.691 | Acc: 50.535,79.480,93.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.698 | Acc: 50.661,79.373,93.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.693 | Acc: 50.781,79.486,93.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.697 | Acc: 50.791,79.431,93.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.697 | Acc: 50.665,79.430,93.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.700 | Acc: 50.623,79.421,93.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.700 | Acc: 50.651,79.394,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.699 | Acc: 50.742,79.412,93.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.696 | Acc: 50.731,79.456,93.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.695 | Acc: 50.729,79.475,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.698 | Acc: 50.712,79.409,93.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.989 | Acc: 46.094,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.754 | Acc: 46.838,63.579,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.768 | Acc: 45.751,63.472,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.766 | Acc: 45.594,63.742,68.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.278 | Acc: 56.250,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.671 | Acc: 51.190,79.836,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.666 | Acc: 51.524,79.783,93.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.682 | Acc: 51.396,79.508,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.684 | Acc: 51.312,79.514,93.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.691 | Acc: 51.238,79.525,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.685 | Acc: 51.317,79.675,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.685 | Acc: 51.130,79.726,93.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.702 | Acc: 50.849,79.425,93.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.695 | Acc: 50.980,79.593,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.701 | Acc: 50.999,79.520,93.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.699 | Acc: 50.979,79.535,93.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.702 | Acc: 50.976,79.499,93.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.705 | Acc: 50.853,79.388,93.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.710 | Acc: 50.826,79.312,93.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.708 | Acc: 50.968,79.277,93.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.710 | Acc: 50.983,79.220,93.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.706 | Acc: 51.129,79.232,93.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.705 | Acc: 51.091,79.265,93.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.704 | Acc: 51.183,79.294,93.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.986 | Acc: 45.312,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.780 | Acc: 45.015,63.876,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.826 | Acc: 44.455,63.853,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.840 | Acc: 43.814,63.870,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.629 | Acc: 50.781,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.663 | Acc: 52.083,80.060,93.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.666 | Acc: 51.620,79.592,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.666 | Acc: 51.217,79.867,93.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.646 | Acc: 51.235,79.842,93.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.664 | Acc: 51.114,79.703,93.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.660 | Acc: 51.246,79.804,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.661 | Acc: 51.230,79.920,93.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.658 | Acc: 51.402,79.857,93.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.653 | Acc: 51.304,79.765,93.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.655 | Acc: 51.364,79.785,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.664 | Acc: 51.329,79.755,93.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.668 | Acc: 51.277,79.775,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.666 | Acc: 51.356,79.738,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.673 | Acc: 51.251,79.626,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.675 | Acc: 51.246,79.594,93.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.675 | Acc: 51.258,79.622,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.684 | Acc: 51.146,79.445,93.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.686 | Acc: 51.134,79.428,93.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.697 | Acc: 51.007,79.325,93.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.979 | Acc: 47.656,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.713 | Acc: 47.061,63.579,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.759 | Acc: 46.170,63.567,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.766 | Acc: 45.914,63.858,68.468,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.995 | Acc: 51.562,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.740 | Acc: 51.302,78.757,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.668 | Acc: 51.448,79.783,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.640 | Acc: 51.627,80.123,93.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.656 | Acc: 51.447,79.736,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.670 | Acc: 50.967,79.479,93.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.678 | Acc: 50.820,79.513,93.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.680 | Acc: 51.047,79.549,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.678 | Acc: 51.179,79.649,93.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.683 | Acc: 51.191,79.662,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.669 | Acc: 51.349,79.761,93.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.678 | Acc: 51.096,79.726,93.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.680 | Acc: 51.067,79.636,93.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.685 | Acc: 51.021,79.502,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.691 | Acc: 51.059,79.471,93.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.693 | Acc: 51.030,79.462,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.694 | Acc: 51.107,79.427,93.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.697 | Acc: 51.132,79.392,93.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.699 | Acc: 51.067,79.400,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.705 | Acc: 50.995,79.339,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.972 | Acc: 44.531,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.991 | Acc: 43.490,63.095,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.024 | Acc: 43.197,62.005,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.024 | Acc: 42.982,61.770,67.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 2.572 | Acc: 45.312,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.639 | Acc: 51.228,79.985,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.655 | Acc: 51.162,79.497,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.651 | Acc: 51.230,79.521,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.662 | Acc: 51.389,79.659,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.666 | Acc: 51.307,79.664,93.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.670 | Acc: 51.201,79.629,93.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.664 | Acc: 51.513,79.505,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.659 | Acc: 51.354,79.678,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.665 | Acc: 51.299,79.593,93.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.673 | Acc: 51.287,79.493,93.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.674 | Acc: 51.258,79.521,93.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.682 | Acc: 51.248,79.370,93.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.683 | Acc: 51.257,79.391,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.684 | Acc: 51.182,79.398,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.686 | Acc: 51.194,79.423,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.685 | Acc: 51.168,79.374,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.690 | Acc: 51.097,79.254,93.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.691 | Acc: 51.140,79.302,93.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.691 | Acc: 51.138,79.249,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.872 | Acc: 43.750,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.835 | Acc: 45.685,63.616,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.901 | Acc: 44.588,63.186,68.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.894 | Acc: 44.224,62.999,67.969,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.266 | Acc: 60.156,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.554 | Acc: 53.051,81.250,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.617 | Acc: 52.287,80.011,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.644 | Acc: 51.960,79.905,93.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.659 | Acc: 51.823,79.649,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.667 | Acc: 51.624,79.556,93.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.677 | Acc: 51.395,79.500,93.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.666 | Acc: 51.435,79.682,93.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.669 | Acc: 51.300,79.702,93.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.671 | Acc: 51.308,79.675,93.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.689 | Acc: 50.999,79.516,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.693 | Acc: 50.891,79.525,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.699 | Acc: 50.843,79.383,93.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.695 | Acc: 50.964,79.361,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.694 | Acc: 50.945,79.362,93.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.692 | Acc: 51.051,79.418,93.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.697 | Acc: 51.037,79.398,93.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.697 | Acc: 51.118,79.397,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.701 | Acc: 51.063,79.283,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.704 | Acc: 51.079,79.253,93.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.016 | Acc: 46.875,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.784 | Acc: 45.573,63.467,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.821 | Acc: 45.084,63.567,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.811 | Acc: 44.877,63.537,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.340 | Acc: 51.562,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 50.558,80.990,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.634 | Acc: 50.838,80.640,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.584 | Acc: 51.793,81.096,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.596 | Acc: 51.572,81.019,94.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.583 | Acc: 51.547,81.041,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.572 | Acc: 51.821,81.218,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.558 | Acc: 52.017,81.300,94.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.555 | Acc: 51.999,81.381,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.559 | Acc: 51.921,81.371,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.559 | Acc: 51.916,81.382,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.561 | Acc: 51.831,81.254,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.561 | Acc: 51.780,81.273,94.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.559 | Acc: 51.832,81.334,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.555 | Acc: 51.860,81.400,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.555 | Acc: 51.900,81.367,95.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.554 | Acc: 51.967,81.394,95.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 52.076,81.445,95.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.547 | Acc: 52.119,81.451,95.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.545 | Acc: 52.143,81.488,95.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.543 | Acc: 50.000,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.488 | Acc: 47.991,64.881,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.522 | Acc: 46.665,65.034,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.517 | Acc: 46.606,65.126,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.681 | Acc: 46.875,80.469,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.510 | Acc: 51.004,82.106,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.486 | Acc: 51.620,82.431,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.488 | Acc: 52.293,82.415,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.485 | Acc: 52.392,82.224,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 52.630,82.054,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.504 | Acc: 52.512,82.102,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.501 | Acc: 52.632,82.037,95.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.506 | Acc: 52.586,81.929,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.501 | Acc: 52.693,82.049,95.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 52.659,82.078,95.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.496 | Acc: 52.665,82.052,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.493 | Acc: 52.755,82.119,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 52.577,82.136,95.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.496 | Acc: 52.591,82.220,95.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.500 | Acc: 52.494,82.182,95.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.501 | Acc: 52.434,82.192,95.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 52.461,82.281,95.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.505 | Acc: 52.346,82.191,95.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.507 | Acc: 52.221,82.167,95.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.588 | Acc: 47.656,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.489 | Acc: 48.028,65.402,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.527 | Acc: 46.989,65.301,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.521 | Acc: 47.067,65.497,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.319 | Acc: 53.906,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.458 | Acc: 52.567,83.333,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.459 | Acc: 53.125,82.927,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.455 | Acc: 53.381,82.659,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.465 | Acc: 53.308,82.552,95.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.467 | Acc: 53.195,82.426,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.468 | Acc: 52.925,82.528,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.485 | Acc: 52.455,82.425,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 52.358,82.356,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.488 | Acc: 52.568,82.364,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.489 | Acc: 52.561,82.389,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 52.510,82.335,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 52.409,82.313,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 52.419,82.328,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 52.327,82.287,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 52.263,82.319,95.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.493 | Acc: 52.217,82.301,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 52.218,82.288,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.494 | Acc: 52.207,82.200,95.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.495 | Acc: 52.190,82.173,95.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.574 | Acc: 50.000,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.488 | Acc: 48.065,65.030,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.534 | Acc: 47.123,65.187,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.525 | Acc: 47.259,65.292,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.373 | Acc: 51.562,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.522 | Acc: 51.860,81.920,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.525 | Acc: 51.715,81.917,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.501 | Acc: 52.241,82.300,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 52.276,82.282,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.518 | Acc: 52.205,82.062,95.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.497 | Acc: 52.531,82.218,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.493 | Acc: 52.588,82.325,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.492 | Acc: 52.480,82.250,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.495 | Acc: 52.387,82.182,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 52.445,82.198,95.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.489 | Acc: 52.432,82.346,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.480 | Acc: 52.554,82.417,95.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 52.514,82.495,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.477 | Acc: 52.522,82.526,95.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.480 | Acc: 52.484,82.498,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.482 | Acc: 52.543,82.472,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 52.557,82.416,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.523,82.395,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 52.444,82.320,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.608 | Acc: 46.875,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.486 | Acc: 47.991,64.881,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 47.027,65.225,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.536 | Acc: 46.939,65.241,69.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 2.545 | Acc: 50.781,77.344,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.459 | Acc: 52.381,82.626,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.489 | Acc: 51.620,82.374,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.457 | Acc: 52.241,82.748,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.470 | Acc: 52.083,82.301,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.469 | Acc: 52.220,82.433,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.474 | Acc: 52.402,82.348,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.466 | Acc: 52.765,82.314,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.473 | Acc: 52.548,82.264,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.499,82.299,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.477 | Acc: 52.429,82.311,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 52.588,82.282,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.474 | Acc: 52.597,82.388,95.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 52.505,82.381,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.479 | Acc: 52.444,82.376,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.476 | Acc: 52.453,82.376,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.476 | Acc: 52.458,82.382,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.476 | Acc: 52.467,82.478,95.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.476 | Acc: 52.539,82.445,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 52.557,82.409,95.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.541 | Acc: 50.000,63.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.511 | Acc: 47.954,64.807,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 46.951,64.958,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.541 | Acc: 46.990,65.254,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.331 | Acc: 48.438,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.478 | Acc: 52.865,81.659,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.454 | Acc: 52.858,82.031,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.463 | Acc: 52.574,82.313,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.473 | Acc: 52.180,82.417,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.460 | Acc: 52.529,82.681,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.470 | Acc: 52.428,82.619,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.464 | Acc: 52.527,82.724,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.468 | Acc: 52.504,82.584,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.471 | Acc: 52.598,82.562,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.468 | Acc: 52.627,82.533,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.467 | Acc: 52.591,82.583,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.468 | Acc: 52.655,82.469,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.474 | Acc: 52.577,82.364,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.473 | Acc: 52.644,82.332,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.474 | Acc: 52.570,82.325,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.473 | Acc: 52.517,82.345,96.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.469 | Acc: 52.557,82.361,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.474 | Acc: 52.517,82.362,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 52.485,82.347,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.492 | Acc: 49.219,63.281,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.485 | Acc: 48.251,64.918,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.529 | Acc: 47.161,65.072,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.528 | Acc: 47.131,65.254,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.565 | Acc: 50.000,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.420 | Acc: 53.125,83.371,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.461 | Acc: 52.572,83.041,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.467 | Acc: 52.613,82.467,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.469 | Acc: 52.614,82.292,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.467 | Acc: 52.584,82.310,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.455 | Acc: 52.608,82.625,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.460 | Acc: 52.660,82.547,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.468 | Acc: 52.548,82.449,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.472 | Acc: 52.551,82.472,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.470 | Acc: 52.530,82.435,96.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.465 | Acc: 52.605,82.576,96.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.461 | Acc: 52.788,82.592,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.466 | Acc: 52.679,82.477,96.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.468 | Acc: 52.652,82.543,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.471 | Acc: 52.489,82.467,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.471 | Acc: 52.541,82.408,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.472 | Acc: 52.543,82.407,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.473 | Acc: 52.526,82.442,95.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.474 | Acc: 52.487,82.501,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.520 | Acc: 48.438,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 47.507,64.509,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 46.913,64.863,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.540 | Acc: 46.824,65.100,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.706 | Acc: 49.219,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.380 | Acc: 55.655,83.371,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.398 | Acc: 53.792,83.365,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.463 | Acc: 52.766,82.351,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.443 | Acc: 52.585,82.745,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.441 | Acc: 52.607,83.060,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.446 | Acc: 52.486,83.038,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.443 | Acc: 52.493,83.073,96.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.451 | Acc: 52.363,82.939,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.447 | Acc: 52.465,82.981,96.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.453 | Acc: 52.453,82.859,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.454 | Acc: 52.531,82.795,96.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.459 | Acc: 52.412,82.803,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.462 | Acc: 52.320,82.812,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.463 | Acc: 52.360,82.768,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.466 | Acc: 52.313,82.659,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.467 | Acc: 52.227,82.613,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.467 | Acc: 52.264,82.615,96.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.467 | Acc: 52.257,82.583,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.469 | Acc: 52.278,82.497,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.550 | Acc: 50.000,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.493 | Acc: 48.326,64.993,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 47.256,65.149,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.532 | Acc: 47.170,65.356,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.443 | Acc: 49.219,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.377 | Acc: 53.311,84.077,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.403 | Acc: 53.011,83.689,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.440 | Acc: 52.382,83.120,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.444 | Acc: 52.556,83.005,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.445 | Acc: 52.584,82.929,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.455 | Acc: 52.518,82.955,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.461 | Acc: 52.493,82.746,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.467 | Acc: 52.290,82.648,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.472 | Acc: 52.115,82.648,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.472 | Acc: 52.200,82.603,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.472 | Acc: 52.319,82.572,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.471 | Acc: 52.341,82.576,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.475 | Acc: 52.269,82.483,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.471 | Acc: 52.291,82.532,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.463 | Acc: 52.419,82.649,96.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.460 | Acc: 52.526,82.696,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.463 | Acc: 52.504,82.675,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 52.530,82.670,96.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.463 | Acc: 52.534,82.636,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.631 | Acc: 49.219,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 48.028,64.658,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.554 | Acc: 46.932,65.072,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 46.939,65.279,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.757 | Acc: 50.781,75.000,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.405 | Acc: 54.129,82.180,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.417 | Acc: 53.430,82.889,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.461 | Acc: 52.382,82.620,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.460 | Acc: 52.353,82.485,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.445 | Acc: 52.382,82.689,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.448 | Acc: 52.421,82.761,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.458 | Acc: 52.316,82.724,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.460 | Acc: 52.441,82.715,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.460 | Acc: 52.352,82.713,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.455 | Acc: 52.488,82.758,96.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.456 | Acc: 52.503,82.784,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.459 | Acc: 52.460,82.673,96.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.463 | Acc: 52.437,82.651,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.466 | Acc: 52.413,82.573,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.462 | Acc: 52.435,82.579,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.464 | Acc: 52.366,82.589,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.463 | Acc: 52.351,82.620,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.465 | Acc: 52.335,82.531,96.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.465 | Acc: 52.272,82.530,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.622 | Acc: 50.000,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.503 | Acc: 48.326,64.695,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.553 | Acc: 47.370,65.072,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.552 | Acc: 47.272,65.241,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.145 | Acc: 53.125,90.625,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.446 | Acc: 52.567,82.887,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.439 | Acc: 52.248,82.546,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.467 | Acc: 51.831,82.364,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.456 | Acc: 52.286,82.475,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.460 | Acc: 52.437,82.464,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.455 | Acc: 52.789,82.670,96.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.461 | Acc: 52.693,82.685,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.471 | Acc: 52.562,82.516,96.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.466 | Acc: 52.516,82.670,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.464 | Acc: 52.402,82.704,96.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.461 | Acc: 52.429,82.699,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.460 | Acc: 52.289,82.748,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.459 | Acc: 52.287,82.774,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.458 | Acc: 52.397,82.762,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.458 | Acc: 52.401,82.670,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.461 | Acc: 52.392,82.659,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.456 | Acc: 52.408,82.774,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.457 | Acc: 52.441,82.789,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.456 | Acc: 52.446,82.774,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.607 | Acc: 49.219,62.500,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.540 | Acc: 47.396,64.583,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 46.742,64.882,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 46.849,65.177,69.915,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.372 | Acc: 46.875,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.427 | Acc: 51.823,82.999,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.460 | Acc: 51.410,82.946,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 51.422,82.928,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.477 | Acc: 51.987,82.378,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.476 | Acc: 51.965,82.317,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.472 | Acc: 52.098,82.348,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.467 | Acc: 51.923,82.524,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.463 | Acc: 52.072,82.633,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.463 | Acc: 51.951,82.640,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.458 | Acc: 52.021,82.544,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.458 | Acc: 52.026,82.600,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.460 | Acc: 52.084,82.556,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.460 | Acc: 52.128,82.567,96.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.465 | Acc: 52.157,82.484,96.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.464 | Acc: 52.146,82.563,96.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.465 | Acc: 52.166,82.635,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.458 | Acc: 52.351,82.693,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.457 | Acc: 52.350,82.700,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.457 | Acc: 52.325,82.651,96.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.673 | Acc: 50.781,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 47.991,65.365,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.554 | Acc: 47.237,65.396,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.552 | Acc: 47.349,65.330,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.798 | Acc: 47.656,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.444 | Acc: 51.414,83.780,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.413 | Acc: 52.096,83.518,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.415 | Acc: 52.561,83.171,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.423 | Acc: 52.170,82.899,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.422 | Acc: 52.305,82.983,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.436 | Acc: 52.247,82.890,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.443 | Acc: 52.178,82.840,96.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.449 | Acc: 52.266,82.715,96.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.457 | Acc: 52.240,82.648,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.457 | Acc: 52.134,82.618,96.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.458 | Acc: 52.234,82.572,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.463 | Acc: 52.266,82.579,96.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.458 | Acc: 52.410,82.654,96.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.457 | Acc: 52.372,82.676,96.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.456 | Acc: 52.359,82.685,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.458 | Acc: 52.371,82.713,96.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.455 | Acc: 52.458,82.714,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.451 | Acc: 52.575,82.678,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.455 | Acc: 52.518,82.642,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.614 | Acc: 50.781,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 47.470,64.472,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.554 | Acc: 46.818,64.958,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.545 | Acc: 46.888,65.215,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.367 | Acc: 56.250,85.938,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.425 | Acc: 52.716,83.333,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.432 | Acc: 52.858,83.422,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.436 | Acc: 52.766,83.440,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.423 | Acc: 53.135,83.198,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.433 | Acc: 52.684,83.075,96.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.431 | Acc: 52.692,83.174,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.440 | Acc: 52.599,83.023,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.442 | Acc: 52.431,82.929,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.449 | Acc: 52.335,82.946,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.450 | Acc: 52.398,82.902,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.453 | Acc: 52.400,82.823,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.452 | Acc: 52.473,82.832,96.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.450 | Acc: 52.475,82.878,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.453 | Acc: 52.413,82.843,96.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.449 | Acc: 52.476,82.916,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.449 | Acc: 52.453,82.893,96.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.449 | Acc: 52.385,82.856,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.447 | Acc: 52.381,82.882,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.448 | Acc: 52.360,82.849,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.584 | Acc: 47.656,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.511 | Acc: 48.065,65.588,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 47.256,65.339,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 47.182,65.433,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.267 | Acc: 55.469,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.508 | Acc: 51.562,82.031,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.480 | Acc: 52.020,82.393,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.451 | Acc: 52.382,82.812,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.446 | Acc: 52.623,82.706,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.466 | Acc: 52.321,82.480,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.455 | Acc: 52.602,82.535,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.452 | Acc: 52.643,82.475,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.458 | Acc: 52.451,82.512,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.456 | Acc: 52.447,82.545,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.453 | Acc: 52.612,82.638,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.449 | Acc: 52.605,82.646,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.458 | Acc: 52.490,82.540,96.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.457 | Acc: 52.410,82.603,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.452 | Acc: 52.530,82.618,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.446 | Acc: 52.601,82.698,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.445 | Acc: 52.604,82.737,96.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.445 | Acc: 52.616,82.714,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.447 | Acc: 52.651,82.722,96.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.446 | Acc: 52.690,82.769,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.609 | Acc: 49.219,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.525 | Acc: 47.879,64.993,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 47.104,64.996,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 47.106,65.164,69.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.194 | Acc: 53.906,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.347 | Acc: 53.237,84.896,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.416 | Acc: 52.668,83.651,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.432 | Acc: 52.651,83.299,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.442 | Acc: 52.517,83.121,96.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.448 | Acc: 52.754,83.052,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.437 | Acc: 52.822,83.103,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.436 | Acc: 52.842,83.117,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.436 | Acc: 52.756,83.094,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.440 | Acc: 52.542,83.028,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.440 | Acc: 52.472,83.050,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.441 | Acc: 52.598,83.056,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.442 | Acc: 52.577,83.095,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.447 | Acc: 52.643,82.962,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.452 | Acc: 52.577,82.929,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.451 | Acc: 52.567,82.883,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.452 | Acc: 52.444,82.830,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.454 | Acc: 52.408,82.826,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.452 | Acc: 52.526,82.873,96.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.451 | Acc: 52.541,82.812,96.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.652 | Acc: 50.000,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.527 | Acc: 48.140,64.918,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 47.294,65.072,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.563 | Acc: 47.106,65.138,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.181 | Acc: 56.250,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.419 | Acc: 52.753,84.077,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.399 | Acc: 53.449,84.146,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.405 | Acc: 52.907,83.773,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.418 | Acc: 52.980,83.227,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.415 | Acc: 52.963,83.292,96.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.417 | Acc: 52.983,83.355,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.419 | Acc: 52.992,83.283,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.427 | Acc: 52.664,83.162,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.430 | Acc: 52.741,82.994,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.432 | Acc: 52.600,82.914,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.429 | Acc: 52.623,82.911,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.430 | Acc: 52.610,82.949,96.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.431 | Acc: 52.670,82.968,96.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.437 | Acc: 52.722,82.843,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.436 | Acc: 52.754,82.844,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.437 | Acc: 52.760,82.834,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.441 | Acc: 52.724,82.861,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.441 | Acc: 52.768,82.836,96.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.440 | Acc: 52.752,82.876,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.632 | Acc: 48.438,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 47.954,65.030,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 47.066,65.206,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.559 | Acc: 46.862,65.228,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 2.210 | Acc: 57.031,86.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.415 | Acc: 52.641,83.817,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.440 | Acc: 52.363,83.403,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.461 | Acc: 52.113,83.466,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.445 | Acc: 52.305,83.468,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.432 | Acc: 52.228,83.184,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.422 | Acc: 52.557,83.148,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.420 | Acc: 52.610,83.317,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.405 | Acc: 52.873,83.463,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.408 | Acc: 52.831,83.391,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.413 | Acc: 52.779,83.372,96.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.415 | Acc: 52.775,83.368,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.420 | Acc: 52.759,83.273,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.429 | Acc: 52.583,83.109,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.433 | Acc: 52.625,83.024,96.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.433 | Acc: 52.728,83.005,96.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.429 | Acc: 52.794,83.046,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.431 | Acc: 52.626,82.948,96.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.436 | Acc: 52.616,82.899,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.435 | Acc: 52.569,82.960,96.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.622 | Acc: 50.000,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.528 | Acc: 47.768,65.104,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.574 | Acc: 46.875,64.977,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 46.901,65.036,69.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.341 | Acc: 46.875,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.365 | Acc: 52.865,83.296,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.379 | Acc: 53.792,82.698,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.396 | Acc: 53.356,82.992,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.408 | Acc: 53.289,82.784,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.406 | Acc: 53.318,83.037,96.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.415 | Acc: 53.080,82.909,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.429 | Acc: 52.914,82.868,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.437 | Acc: 52.640,82.876,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.435 | Acc: 52.685,83.002,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.434 | Acc: 52.662,82.937,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.430 | Acc: 52.722,82.979,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.425 | Acc: 52.746,82.955,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.430 | Acc: 52.610,82.896,96.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.434 | Acc: 52.544,82.851,96.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.434 | Acc: 52.596,82.818,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.437 | Acc: 52.536,82.798,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.438 | Acc: 52.564,82.817,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.441 | Acc: 52.517,82.817,96.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.443 | Acc: 52.547,82.802,96.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.594 | Acc: 50.000,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 47.917,65.141,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.557 | Acc: 47.027,65.111,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.558 | Acc: 46.901,65.292,69.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.770 | Acc: 48.438,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.471 | Acc: 52.902,82.403,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.456 | Acc: 52.858,83.136,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 52.754,83.235,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.431 | Acc: 52.961,83.198,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.444 | Acc: 52.901,82.696,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.437 | Acc: 52.654,82.942,96.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.433 | Acc: 52.798,83.045,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.437 | Acc: 52.805,82.929,96.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.433 | Acc: 52.836,83.059,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.441 | Acc: 52.596,82.976,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.443 | Acc: 52.641,82.926,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.447 | Acc: 52.571,82.812,96.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.453 | Acc: 52.550,82.654,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.456 | Acc: 52.477,82.612,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.453 | Acc: 52.580,82.636,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.455 | Acc: 52.536,82.635,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.452 | Acc: 52.603,82.709,96.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.450 | Acc: 52.580,82.784,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.449 | Acc: 52.522,82.774,96.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.615 | Acc: 50.000,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.542 | Acc: 48.177,65.067,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.585 | Acc: 47.199,65.263,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.581 | Acc: 47.221,65.420,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.386 | Acc: 51.562,83.594,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.451 | Acc: 50.856,82.812,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 51.601,82.755,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.443 | Acc: 52.369,82.864,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.443 | Acc: 52.652,82.812,96.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.443 | Acc: 52.862,82.604,96.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.441 | Acc: 52.828,82.496,96.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.442 | Acc: 52.743,82.458,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.441 | Acc: 52.834,82.580,96.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.437 | Acc: 52.909,82.601,96.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.437 | Acc: 52.806,82.696,96.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.433 | Acc: 52.863,82.774,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.435 | Acc: 52.824,82.790,96.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.440 | Acc: 52.790,82.687,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.443 | Acc: 52.769,82.657,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.443 | Acc: 52.764,82.633,96.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.443 | Acc: 52.687,82.640,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.445 | Acc: 52.681,82.696,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.446 | Acc: 52.647,82.711,96.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.447 | Acc: 52.619,82.689,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.605 | Acc: 50.781,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.528 | Acc: 47.991,65.774,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 47.142,65.396,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 47.003,65.420,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.413 | Acc: 50.000,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.444 | Acc: 51.265,82.440,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.440 | Acc: 51.353,82.489,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.415 | Acc: 52.024,82.902,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.433 | Acc: 51.804,82.764,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.435 | Acc: 51.686,82.650,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.438 | Acc: 51.853,82.677,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.435 | Acc: 51.812,82.812,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.431 | Acc: 51.873,82.939,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.432 | Acc: 51.929,82.972,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.431 | Acc: 52.130,82.995,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.428 | Acc: 52.227,83.003,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.436 | Acc: 52.130,82.942,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.437 | Acc: 52.272,82.884,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.433 | Acc: 52.349,82.990,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.432 | Acc: 52.489,82.976,96.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.435 | Acc: 52.519,82.903,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.436 | Acc: 52.564,82.858,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.437 | Acc: 52.610,82.845,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.440 | Acc: 52.528,82.839,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.618 | Acc: 48.438,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 47.619,65.030,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.574 | Acc: 47.027,65.168,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 47.118,65.343,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 2.259 | Acc: 53.906,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.443 | Acc: 52.827,83.036,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.421 | Acc: 52.325,83.498,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.406 | Acc: 52.510,83.466,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.413 | Acc: 52.585,83.372,96.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.420 | Acc: 52.491,83.385,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.418 | Acc: 52.647,83.264,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.417 | Acc: 52.698,83.223,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.421 | Acc: 52.572,83.186,96.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.421 | Acc: 52.629,83.153,96.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.428 | Acc: 52.480,83.139,96.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.427 | Acc: 52.513,83.071,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.432 | Acc: 52.529,83.013,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.433 | Acc: 52.538,82.998,96.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.440 | Acc: 52.486,82.990,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.441 | Acc: 52.468,82.922,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.439 | Acc: 52.609,82.941,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.433 | Acc: 52.687,82.980,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.432 | Acc: 52.686,82.962,96.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.432 | Acc: 52.674,82.933,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.629 | Acc: 48.438,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 47.656,64.918,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 46.837,64.939,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 46.824,65.074,69.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.254 | Acc: 58.594,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.401 | Acc: 53.125,84.040,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.415 | Acc: 52.801,83.327,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.422 | Acc: 52.856,82.838,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.443 | Acc: 52.623,82.639,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.435 | Acc: 53.040,82.851,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.425 | Acc: 53.054,83.058,96.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.424 | Acc: 53.114,82.840,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.421 | Acc: 53.043,82.803,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.423 | Acc: 52.974,82.886,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.436 | Acc: 52.752,82.844,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.449 | Acc: 52.609,82.710,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.441 | Acc: 52.707,82.803,96.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.441 | Acc: 52.697,82.875,96.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.437 | Acc: 52.733,82.863,96.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.432 | Acc: 52.788,82.922,96.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.433 | Acc: 52.738,82.903,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.431 | Acc: 52.793,82.916,96.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.430 | Acc: 52.753,82.955,96.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.434 | Acc: 52.707,82.942,96.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.574 | Acc: 50.000,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 48.326,65.104,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 47.294,65.168,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 47.106,65.215,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 2.206 | Acc: 55.469,85.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.366 | Acc: 54.501,84.189,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.374 | Acc: 54.059,84.261,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.399 | Acc: 53.522,83.683,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.392 | Acc: 53.366,83.816,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.404 | Acc: 53.264,83.594,96.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.412 | Acc: 53.041,83.465,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.410 | Acc: 53.059,83.500,96.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.409 | Acc: 53.251,83.482,96.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.417 | Acc: 53.155,83.451,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.427 | Acc: 53.036,83.302,96.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.428 | Acc: 53.008,83.290,96.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.431 | Acc: 52.963,83.260,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.429 | Acc: 52.984,83.256,96.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.430 | Acc: 52.983,83.243,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.432 | Acc: 52.915,83.111,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.433 | Acc: 52.921,83.092,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.430 | Acc: 52.962,83.115,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.429 | Acc: 52.941,83.048,96.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.431 | Acc: 52.895,83.032,96.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.668 | Acc: 47.656,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 47.954,64.732,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 46.856,64.825,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 46.747,64.985,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.506 | Acc: 51.562,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.403 | Acc: 53.497,83.557,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.449 | Acc: 52.915,82.946,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.412 | Acc: 53.343,83.440,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.436 | Acc: 53.048,83.131,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.424 | Acc: 53.133,83.238,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.440 | Acc: 52.854,83.058,96.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.435 | Acc: 52.842,83.090,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.431 | Acc: 52.790,83.079,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.428 | Acc: 52.996,83.110,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.420 | Acc: 53.133,83.170,96.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.428 | Acc: 52.927,83.003,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.424 | Acc: 52.976,83.082,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.427 | Acc: 52.945,83.028,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.426 | Acc: 52.936,83.010,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.429 | Acc: 52.946,82.927,96.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.432 | Acc: 52.904,82.827,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.433 | Acc: 52.807,82.787,96.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.436 | Acc: 52.729,82.802,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.438 | Acc: 52.686,82.798,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.586 | Acc: 48.438,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 47.842,65.253,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 47.085,65.244,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.595 | Acc: 46.862,65.228,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.355 | Acc: 50.000,87.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.412 | Acc: 51.302,84.189,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.414 | Acc: 52.287,83.537,96.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.426 | Acc: 52.203,83.274,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.428 | Acc: 52.228,83.237,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.427 | Acc: 52.143,83.176,96.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.423 | Acc: 52.395,83.155,96.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.414 | Acc: 52.460,83.289,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.419 | Acc: 52.358,83.283,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.415 | Acc: 52.430,83.287,96.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.423 | Acc: 52.282,83.287,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.429 | Acc: 52.298,83.201,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.427 | Acc: 52.357,83.153,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.425 | Acc: 52.356,83.163,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.425 | Acc: 52.399,83.141,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.420 | Acc: 52.510,83.186,96.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.420 | Acc: 52.582,83.141,96.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.420 | Acc: 52.582,83.097,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.421 | Acc: 52.590,83.083,96.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.423 | Acc: 52.594,83.061,96.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.653 | Acc: 50.000,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.541 | Acc: 47.693,64.844,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 47.142,64.825,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 47.118,65.074,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.649 | Acc: 50.781,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.452 | Acc: 53.720,82.664,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.466 | Acc: 53.030,82.889,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.475 | Acc: 52.472,82.838,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.472 | Acc: 52.537,82.668,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.454 | Acc: 52.746,82.782,96.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.443 | Acc: 52.964,82.793,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.458 | Acc: 52.732,82.624,96.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.441 | Acc: 52.941,82.779,96.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.439 | Acc: 52.926,82.739,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.438 | Acc: 52.927,82.778,96.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.434 | Acc: 53.093,82.805,96.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.437 | Acc: 53.018,82.806,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.431 | Acc: 53.002,82.914,96.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.433 | Acc: 52.922,82.863,96.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.433 | Acc: 52.915,82.841,96.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.433 | Acc: 52.930,82.842,96.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.437 | Acc: 52.829,82.893,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.435 | Acc: 52.779,82.906,96.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.433 | Acc: 52.781,82.909,96.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.658 | Acc: 46.875,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 47.619,64.435,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 47.123,64.768,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 47.118,64.997,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.176 | Acc: 57.031,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.373 | Acc: 53.832,83.371,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.413 | Acc: 52.496,83.689,96.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.423 | Acc: 52.228,83.338,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.415 | Acc: 52.382,83.353,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.415 | Acc: 52.421,83.037,96.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.415 | Acc: 52.570,83.116,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.409 | Acc: 52.682,83.322,96.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.416 | Acc: 52.528,83.273,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.422 | Acc: 52.443,83.197,96.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.423 | Acc: 52.503,83.240,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.428 | Acc: 52.460,83.177,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.429 | Acc: 52.454,83.205,96.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.424 | Acc: 52.529,83.199,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.421 | Acc: 52.511,83.166,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.421 | Acc: 52.492,83.111,96.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.419 | Acc: 52.490,83.151,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.420 | Acc: 52.518,83.076,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.419 | Acc: 52.541,83.077,96.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.423 | Acc: 52.403,83.040,96.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.663 | Acc: 48.438,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.544 | Acc: 47.731,65.439,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 47.256,65.320,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.587 | Acc: 47.118,65.446,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.417 | Acc: 52.344,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.423 | Acc: 51.488,83.147,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.466 | Acc: 51.543,82.527,96.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.454 | Acc: 51.716,82.672,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.429 | Acc: 52.836,82.812,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.422 | Acc: 52.800,82.774,96.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.424 | Acc: 52.809,82.819,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.423 | Acc: 52.876,82.885,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.424 | Acc: 52.708,82.876,96.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.423 | Acc: 52.814,83.041,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.423 | Acc: 52.627,83.061,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.423 | Acc: 52.637,82.922,96.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.423 | Acc: 52.571,82.897,96.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.423 | Acc: 52.688,82.899,96.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.424 | Acc: 52.647,82.874,96.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.427 | Acc: 52.580,82.836,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.422 | Acc: 52.694,82.951,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.424 | Acc: 52.635,82.893,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.427 | Acc: 52.577,82.895,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.425 | Acc: 52.623,82.876,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.641 | Acc: 50.000,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 47.917,65.104,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 47.447,64.977,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 47.182,65.138,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.498 | Acc: 52.344,85.938,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.418 | Acc: 52.083,83.333,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.425 | Acc: 52.268,83.232,96.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.406 | Acc: 52.369,83.645,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.420 | Acc: 52.488,83.401,96.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.416 | Acc: 52.475,83.416,96.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.417 | Acc: 52.583,83.271,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.419 | Acc: 52.588,83.272,96.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.423 | Acc: 52.625,83.099,96.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.414 | Acc: 52.814,83.162,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.420 | Acc: 52.674,83.077,96.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.425 | Acc: 52.616,83.099,96.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.428 | Acc: 52.610,83.036,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.427 | Acc: 52.610,83.019,96.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.429 | Acc: 52.522,83.002,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.431 | Acc: 52.427,82.973,96.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.427 | Acc: 52.521,83.007,96.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.428 | Acc: 52.509,83.032,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.426 | Acc: 52.552,83.083,96.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.427 | Acc: 52.541,83.024,96.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.704 | Acc: 48.438,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 47.693,65.290,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 46.989,64.939,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 47.106,65.100,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.262 | Acc: 50.781,87.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.394 | Acc: 52.716,82.812,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.406 | Acc: 52.877,82.774,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.413 | Acc: 52.472,82.941,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.415 | Acc: 52.922,82.938,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.419 | Acc: 52.939,83.060,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.417 | Acc: 52.899,83.135,96.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.409 | Acc: 52.903,83.156,96.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.416 | Acc: 52.907,83.147,96.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.417 | Acc: 53.004,83.011,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.423 | Acc: 52.911,82.910,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.418 | Acc: 53.037,82.943,96.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.419 | Acc: 52.921,82.949,96.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.417 | Acc: 52.868,82.998,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.418 | Acc: 52.841,82.993,96.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.426 | Acc: 52.738,82.864,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.422 | Acc: 52.831,82.917,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.421 | Acc: 52.848,82.895,96.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.422 | Acc: 52.846,82.903,96.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.421 | Acc: 52.867,82.919,96.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.615 | Acc: 50.000,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 48.289,64.881,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 47.428,65.091,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.579 | Acc: 47.323,65.202,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.389 | Acc: 50.781,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.465 | Acc: 52.753,81.882,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.461 | Acc: 52.801,81.993,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.444 | Acc: 52.997,82.275,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.431 | Acc: 53.115,82.542,96.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.418 | Acc: 53.249,82.650,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.430 | Acc: 52.964,82.509,96.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.425 | Acc: 52.914,82.630,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.423 | Acc: 52.858,82.779,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.431 | Acc: 52.836,82.709,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.431 | Acc: 52.833,82.704,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.431 | Acc: 52.952,82.636,96.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.431 | Acc: 52.781,82.612,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.429 | Acc: 52.760,82.591,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.424 | Acc: 52.833,82.665,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.425 | Acc: 52.749,82.696,96.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.427 | Acc: 52.694,82.791,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.426 | Acc: 52.710,82.778,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.427 | Acc: 52.709,82.769,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.426 | Acc: 52.649,82.767,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.650 | Acc: 49.219,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.519 | Acc: 48.289,65.104,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.572 | Acc: 47.389,65.168,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 47.272,65.254,69.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.297 | Acc: 52.344,88.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.366 | Acc: 53.051,84.226,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.380 | Acc: 53.030,83.556,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.379 | Acc: 53.112,83.594,97.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.381 | Acc: 53.434,83.584,96.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.385 | Acc: 53.342,83.485,96.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.392 | Acc: 53.299,83.297,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.390 | Acc: 53.191,83.261,97.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.384 | Acc: 53.135,83.298,97.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.387 | Acc: 53.155,83.218,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.393 | Acc: 53.036,83.085,97.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.400 | Acc: 52.962,82.996,96.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.407 | Acc: 52.882,82.968,96.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.406 | Acc: 52.823,83.094,96.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.406 | Acc: 52.891,83.188,96.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.405 | Acc: 52.894,83.202,96.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.407 | Acc: 52.860,83.202,96.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.411 | Acc: 52.687,83.136,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.413 | Acc: 52.655,83.167,96.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.411 | Acc: 52.723,83.163,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.655 | Acc: 50.000,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.535 | Acc: 47.879,64.918,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 47.370,64.996,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.588 | Acc: 47.246,65.177,70.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.378 | Acc: 55.469,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.421 | Acc: 52.046,82.887,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.439 | Acc: 52.096,82.946,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.437 | Acc: 52.139,83.017,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.420 | Acc: 52.209,83.314,96.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.435 | Acc: 52.112,82.983,96.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.433 | Acc: 52.176,82.980,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.431 | Acc: 52.128,83.023,96.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.428 | Acc: 52.300,82.958,96.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.439 | Acc: 52.128,82.800,96.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.436 | Acc: 52.076,82.801,96.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.428 | Acc: 52.125,82.897,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.422 | Acc: 52.175,83.010,96.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.429 | Acc: 52.134,82.914,96.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.428 | Acc: 52.208,82.896,96.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.425 | Acc: 52.307,82.896,96.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.424 | Acc: 52.351,82.907,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.426 | Acc: 52.348,82.870,96.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.426 | Acc: 52.311,82.821,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.424 | Acc: 52.321,82.901,96.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.662 | Acc: 50.000,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 47.656,65.290,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 47.046,65.091,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 47.041,65.241,70.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.299 | Acc: 57.031,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.429 | Acc: 53.088,83.147,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.407 | Acc: 53.449,83.384,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.415 | Acc: 53.445,83.338,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.423 | Acc: 53.077,82.928,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.418 | Acc: 53.024,82.836,96.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.416 | Acc: 53.060,82.903,96.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.406 | Acc: 53.036,83.134,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.402 | Acc: 53.251,83.152,96.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.402 | Acc: 53.147,83.227,96.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.410 | Acc: 52.997,83.120,96.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.410 | Acc: 53.051,83.035,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.412 | Acc: 52.982,83.001,96.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.413 | Acc: 52.993,82.992,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.416 | Acc: 52.841,83.010,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.419 | Acc: 52.762,82.919,96.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.415 | Acc: 52.787,82.966,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.415 | Acc: 52.823,82.966,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.417 | Acc: 52.790,82.908,96.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.421 | Acc: 52.766,82.841,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.643 | Acc: 50.000,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 48.251,64.955,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.612 | Acc: 47.351,64.863,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.609 | Acc: 47.285,65.061,69.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.243 | Acc: 51.562,89.844,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.380 | Acc: 51.042,84.710,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.394 | Acc: 51.486,84.032,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.399 | Acc: 52.305,83.837,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.399 | Acc: 52.064,83.729,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.407 | Acc: 52.220,83.694,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.414 | Acc: 52.131,83.632,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.415 | Acc: 52.299,83.610,96.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.422 | Acc: 52.286,83.526,96.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.421 | Acc: 52.352,83.456,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.426 | Acc: 52.235,83.368,96.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.422 | Acc: 52.344,83.368,96.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.420 | Acc: 52.464,83.402,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.427 | Acc: 52.293,83.342,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.429 | Acc: 52.397,83.288,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.426 | Acc: 52.422,83.298,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.425 | Acc: 52.480,83.287,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.424 | Acc: 52.474,83.271,96.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.427 | Acc: 52.402,83.159,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.424 | Acc: 52.389,83.194,96.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.628 | Acc: 50.000,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.549 | Acc: 47.991,64.955,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.600 | Acc: 47.409,64.996,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 47.221,65.100,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.480 | Acc: 53.125,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.433 | Acc: 52.939,82.775,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.420 | Acc: 52.401,83.117,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.396 | Acc: 53.202,83.402,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.424 | Acc: 52.865,82.938,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.419 | Acc: 52.916,82.874,96.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.428 | Acc: 52.647,82.716,96.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.419 | Acc: 52.781,82.829,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.419 | Acc: 52.698,82.846,96.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.417 | Acc: 52.655,82.951,96.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.417 | Acc: 52.647,83.077,96.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.417 | Acc: 52.655,83.060,96.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.411 | Acc: 52.668,83.140,96.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.412 | Acc: 52.697,83.127,96.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.413 | Acc: 52.714,83.093,96.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.412 | Acc: 52.743,83.077,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.416 | Acc: 52.653,83.066,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.417 | Acc: 52.674,83.069,96.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.421 | Acc: 52.603,83.040,96.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.416 | Acc: 52.684,83.139,96.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.596 | Acc: 50.000,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 47.768,64.918,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 47.142,64.863,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 47.016,65.113,69.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.602 | Acc: 44.531,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.427 | Acc: 51.190,83.594,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.412 | Acc: 52.115,83.727,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.425 | Acc: 52.075,83.530,96.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.433 | Acc: 52.296,83.131,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.433 | Acc: 52.073,83.176,96.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.421 | Acc: 52.273,83.277,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.429 | Acc: 52.327,83.078,96.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.431 | Acc: 52.232,83.079,96.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.425 | Acc: 52.465,83.084,96.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.417 | Acc: 52.569,83.092,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.416 | Acc: 52.528,83.145,96.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.411 | Acc: 52.652,83.208,96.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.416 | Acc: 52.613,83.145,96.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.414 | Acc: 52.594,83.185,96.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.412 | Acc: 52.577,83.215,96.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.413 | Acc: 52.607,83.258,96.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.415 | Acc: 52.653,83.335,96.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.408 | Acc: 52.794,83.444,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.408 | Acc: 52.785,83.444,96.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.631 | Acc: 49.219,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 48.103,64.621,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 47.428,64.748,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 47.285,65.074,69.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.181 | Acc: 57.812,87.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.375 | Acc: 52.827,83.631,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.369 | Acc: 53.506,83.708,97.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.370 | Acc: 53.535,83.414,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.393 | Acc: 52.932,83.140,97.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.391 | Acc: 52.885,83.230,97.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.384 | Acc: 52.802,83.258,97.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.393 | Acc: 52.809,83.029,97.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.397 | Acc: 52.727,83.026,97.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.399 | Acc: 52.689,83.046,97.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.403 | Acc: 52.612,82.976,96.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.410 | Acc: 52.535,83.014,96.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.405 | Acc: 52.684,83.075,96.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.401 | Acc: 52.823,83.085,97.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.394 | Acc: 52.905,83.205,97.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.398 | Acc: 52.881,83.147,97.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.401 | Acc: 52.899,83.092,97.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.401 | Acc: 52.875,83.120,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.402 | Acc: 52.865,83.159,97.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.404 | Acc: 52.842,83.136,97.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.580 | Acc: 50.000,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.544 | Acc: 48.326,65.179,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 47.523,65.130,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 47.490,65.254,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.513 | Acc: 53.906,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.386 | Acc: 51.637,84.040,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.388 | Acc: 52.001,83.975,97.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.387 | Acc: 52.152,84.055,97.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.400 | Acc: 51.871,83.951,97.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.396 | Acc: 51.942,84.050,97.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.387 | Acc: 52.228,84.104,97.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.382 | Acc: 52.482,83.993,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.378 | Acc: 52.611,84.040,97.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.385 | Acc: 52.555,83.861,97.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.379 | Acc: 52.709,83.905,97.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.384 | Acc: 52.729,83.824,96.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.384 | Acc: 52.665,83.876,96.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.387 | Acc: 52.712,83.791,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.389 | Acc: 52.697,83.744,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.389 | Acc: 52.738,83.711,96.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.397 | Acc: 52.675,83.616,96.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.397 | Acc: 52.655,83.635,96.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.398 | Acc: 52.649,83.568,96.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.398 | Acc: 52.623,83.524,96.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.694 | Acc: 48.438,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 48.140,64.807,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 47.275,64.958,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.622 | Acc: 47.298,64.985,69.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.200 | Acc: 53.125,85.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.342 | Acc: 53.199,83.147,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.383 | Acc: 52.477,82.774,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.383 | Acc: 52.664,82.941,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.398 | Acc: 52.546,82.851,96.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.389 | Acc: 52.622,82.843,96.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.387 | Acc: 52.770,83.045,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.390 | Acc: 52.881,83.139,97.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.383 | Acc: 53.009,83.283,96.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.394 | Acc: 52.797,83.166,96.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.393 | Acc: 52.903,83.217,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.395 | Acc: 52.863,83.261,96.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.394 | Acc: 52.862,83.321,96.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.401 | Acc: 52.730,83.345,96.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.401 | Acc: 52.744,83.371,96.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.400 | Acc: 52.845,83.339,96.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.403 | Acc: 52.884,83.328,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.403 | Acc: 52.891,83.323,96.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.401 | Acc: 52.846,83.315,96.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.405 | Acc: 52.824,83.296,96.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.644 | Acc: 50.000,61.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 48.140,64.546,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 47.294,64.653,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 47.259,64.997,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.421 | Acc: 53.125,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.369 | Acc: 53.460,83.668,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.385 | Acc: 52.611,83.765,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.368 | Acc: 52.843,83.683,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.377 | Acc: 52.836,83.767,97.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.378 | Acc: 52.839,83.679,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.383 | Acc: 52.976,83.671,97.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.384 | Acc: 52.704,83.588,97.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.379 | Acc: 53.038,83.560,97.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.377 | Acc: 52.965,83.576,97.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.380 | Acc: 52.938,83.629,96.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.390 | Acc: 52.697,83.502,96.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.391 | Acc: 52.691,83.464,97.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.396 | Acc: 52.622,83.366,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.394 | Acc: 52.641,83.416,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.395 | Acc: 52.647,83.420,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.392 | Acc: 52.633,83.518,97.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.391 | Acc: 52.694,83.527,96.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.392 | Acc: 52.733,83.537,96.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.389 | Acc: 52.776,83.583,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.686 | Acc: 50.781,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 47.991,64.621,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 47.180,64.806,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 47.195,65.318,69.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.605 | Acc: 56.250,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.416 | Acc: 53.460,83.147,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.392 | Acc: 53.887,83.422,97.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.385 | Acc: 53.996,83.645,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.383 | Acc: 53.791,83.613,96.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.400 | Acc: 53.465,83.424,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.389 | Acc: 53.467,83.400,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.381 | Acc: 53.552,83.367,96.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.381 | Acc: 53.557,83.526,96.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.393 | Acc: 53.332,83.417,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.397 | Acc: 53.214,83.450,96.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.397 | Acc: 53.139,83.484,96.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.394 | Acc: 53.141,83.464,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.395 | Acc: 53.131,83.471,96.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.395 | Acc: 53.131,83.491,96.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.398 | Acc: 53.060,83.409,96.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.400 | Acc: 53.030,83.397,96.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.396 | Acc: 53.130,83.355,96.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.399 | Acc: 53.056,83.304,96.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.404 | Acc: 52.994,83.286,96.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.734 | Acc: 50.781,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 47.991,65.216,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 47.161,65.111,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.609 | Acc: 47.182,65.292,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.401 | Acc: 51.562,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.320 | Acc: 53.757,83.780,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.373 | Acc: 54.116,83.460,96.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.394 | Acc: 53.471,82.877,96.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.391 | Acc: 53.540,82.986,96.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.388 | Acc: 53.543,83.199,96.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.396 | Acc: 53.396,83.239,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.394 | Acc: 53.247,83.389,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.394 | Acc: 53.280,83.366,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.395 | Acc: 53.237,83.361,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.399 | Acc: 53.218,83.291,96.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.404 | Acc: 53.203,83.205,96.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.402 | Acc: 53.196,83.163,96.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.400 | Acc: 53.287,83.282,96.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.395 | Acc: 53.283,83.335,96.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.397 | Acc: 53.198,83.332,96.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.400 | Acc: 53.183,83.282,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.403 | Acc: 53.187,83.259,96.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.404 | Acc: 53.123,83.271,96.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.408 | Acc: 53.018,83.249,96.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.667 | Acc: 50.000,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 48.028,65.030,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 47.180,65.072,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 47.131,65.343,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.505 | Acc: 54.688,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.366 | Acc: 52.753,83.705,96.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.393 | Acc: 52.668,83.022,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.393 | Acc: 53.343,83.094,97.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.394 | Acc: 53.086,83.324,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.387 | Acc: 52.947,83.455,97.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.386 | Acc: 53.009,83.426,96.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.388 | Acc: 52.970,83.433,96.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.397 | Acc: 52.873,83.337,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.397 | Acc: 52.836,83.326,96.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.400 | Acc: 52.764,83.341,96.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.401 | Acc: 52.892,83.353,96.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.400 | Acc: 52.921,83.383,96.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.401 | Acc: 52.963,83.333,96.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.398 | Acc: 53.028,83.377,96.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.395 | Acc: 53.039,83.425,96.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.395 | Acc: 53.076,83.438,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.397 | Acc: 53.056,83.383,96.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.397 | Acc: 53.028,83.410,96.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.399 | Acc: 53.039,83.389,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.711 | Acc: 48.438,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 48.103,64.844,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 47.313,64.977,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 47.170,65.202,69.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.502 | Acc: 53.906,78.125,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.428 | Acc: 52.865,83.780,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.416 | Acc: 52.077,84.280,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.410 | Acc: 52.100,83.991,96.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.377 | Acc: 52.845,83.902,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.385 | Acc: 52.785,83.942,96.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.388 | Acc: 52.893,84.046,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.392 | Acc: 52.665,83.987,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.392 | Acc: 52.567,84.016,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.387 | Acc: 52.680,84.034,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.391 | Acc: 52.561,83.982,96.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.381 | Acc: 52.768,84.071,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.381 | Acc: 52.824,83.992,96.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.383 | Acc: 52.796,83.959,96.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.381 | Acc: 52.911,83.986,96.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.384 | Acc: 52.954,83.952,96.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.387 | Acc: 52.894,83.881,96.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.387 | Acc: 52.905,83.837,96.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.389 | Acc: 52.917,83.704,96.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.390 | Acc: 52.856,83.672,96.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.618 | Acc: 49.219,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 47.991,64.658,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 47.085,64.672,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 47.144,64.997,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.519 | Acc: 50.000,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.486 | Acc: 52.083,82.217,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.411 | Acc: 52.668,83.041,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.422 | Acc: 52.497,83.171,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.398 | Acc: 52.903,83.256,96.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.408 | Acc: 52.715,83.230,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.408 | Acc: 52.447,83.310,96.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.402 | Acc: 52.721,83.295,96.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.398 | Acc: 52.659,83.371,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.396 | Acc: 52.827,83.460,96.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.395 | Acc: 52.744,83.547,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.398 | Acc: 52.612,83.534,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.398 | Acc: 52.671,83.522,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.399 | Acc: 52.793,83.534,96.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.407 | Acc: 52.691,83.424,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.405 | Acc: 52.756,83.477,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.401 | Acc: 52.848,83.535,96.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.402 | Acc: 52.843,83.591,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.399 | Acc: 52.902,83.572,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.398 | Acc: 52.871,83.575,96.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.628 | Acc: 50.781,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 48.103,64.993,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.612 | Acc: 47.409,65.072,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 47.310,65.292,69.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.463 | Acc: 53.125,82.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.368 | Acc: 53.534,83.110,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.409 | Acc: 52.191,83.632,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.407 | Acc: 52.510,83.517,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.396 | Acc: 52.932,83.574,96.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.397 | Acc: 53.233,83.509,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.398 | Acc: 53.202,83.555,96.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.398 | Acc: 53.191,83.483,96.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.405 | Acc: 53.106,83.438,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.407 | Acc: 52.922,83.382,96.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.410 | Acc: 53.005,83.318,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.414 | Acc: 53.019,83.254,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.398 | Acc: 53.225,83.438,96.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.400 | Acc: 53.131,83.429,96.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.401 | Acc: 53.044,83.455,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.399 | Acc: 52.998,83.493,96.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.393 | Acc: 53.052,83.533,96.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.392 | Acc: 53.031,83.520,96.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.390 | Acc: 53.056,83.561,96.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.392 | Acc: 53.012,83.563,96.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.629 | Acc: 50.781,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 48.251,64.844,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.608 | Acc: 47.466,64.882,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 47.400,65.266,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.308 | Acc: 50.000,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.436 | Acc: 52.530,83.519,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.414 | Acc: 52.477,83.079,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.397 | Acc: 52.959,83.619,97.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.401 | Acc: 52.556,83.729,97.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.414 | Acc: 52.468,83.571,96.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.407 | Acc: 52.583,83.568,96.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.397 | Acc: 52.737,83.638,97.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.401 | Acc: 52.713,83.608,97.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.403 | Acc: 52.879,83.555,97.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.405 | Acc: 52.822,83.567,96.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.409 | Acc: 52.673,83.576,96.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.406 | Acc: 52.658,83.620,96.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.399 | Acc: 52.712,83.627,96.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.394 | Acc: 52.841,83.572,96.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.396 | Acc: 52.850,83.594,96.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.397 | Acc: 52.828,83.548,96.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.396 | Acc: 52.834,83.555,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.396 | Acc: 52.800,83.514,96.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.396 | Acc: 52.793,83.520,96.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.639 | Acc: 48.438,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 48.028,64.918,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.615 | Acc: 47.409,64.806,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.609 | Acc: 47.118,65.074,69.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.294 | Acc: 51.562,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.338 | Acc: 53.162,83.482,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.400 | Acc: 52.649,83.384,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.402 | Acc: 52.779,83.338,96.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.384 | Acc: 52.845,83.632,97.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.385 | Acc: 52.916,83.772,96.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.381 | Acc: 53.009,83.820,96.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.389 | Acc: 52.992,83.721,96.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.393 | Acc: 52.984,83.647,96.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.398 | Acc: 52.901,83.460,96.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.394 | Acc: 53.059,83.547,96.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.400 | Acc: 53.008,83.470,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.399 | Acc: 53.008,83.548,96.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.396 | Acc: 53.032,83.567,96.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.393 | Acc: 53.106,83.608,96.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.395 | Acc: 52.972,83.537,96.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.394 | Acc: 53.081,83.589,96.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.394 | Acc: 53.065,83.562,96.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.395 | Acc: 53.073,83.490,96.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.395 | Acc: 53.072,83.419,96.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.672 | Acc: 48.438,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 48.103,64.769,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 47.218,64.863,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 47.118,65.190,70.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.039 | Acc: 60.938,87.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.416 | Acc: 53.162,82.850,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.406 | Acc: 52.687,83.403,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.405 | Acc: 52.702,83.645,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.397 | Acc: 53.048,83.873,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.400 | Acc: 53.063,83.772,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.386 | Acc: 53.177,83.923,96.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.391 | Acc: 52.948,83.954,96.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.393 | Acc: 53.004,83.836,96.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.400 | Acc: 53.000,83.766,96.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.399 | Acc: 53.067,83.699,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.394 | Acc: 53.054,83.686,96.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.390 | Acc: 53.060,83.707,96.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.391 | Acc: 53.053,83.651,96.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.395 | Acc: 52.950,83.583,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.399 | Acc: 52.824,83.573,96.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.397 | Acc: 52.872,83.569,96.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.399 | Acc: 52.848,83.548,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.401 | Acc: 52.790,83.522,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.403 | Acc: 52.776,83.522,96.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.650 | Acc: 50.000,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 48.028,64.583,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.622 | Acc: 47.275,64.806,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.616 | Acc: 47.208,65.113,69.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.016 | Acc: 60.156,90.625,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.392 | Acc: 53.460,83.333,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.388 | Acc: 53.201,83.460,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.400 | Acc: 52.587,83.530,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.392 | Acc: 52.865,83.623,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.397 | Acc: 52.885,83.609,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.394 | Acc: 52.996,83.555,96.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.399 | Acc: 52.920,83.422,96.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.408 | Acc: 52.887,83.215,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.400 | Acc: 52.991,83.274,96.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.392 | Acc: 53.012,83.465,96.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.391 | Acc: 53.139,83.530,96.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.388 | Acc: 53.112,83.636,96.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.392 | Acc: 53.080,83.609,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.394 | Acc: 53.022,83.560,96.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.393 | Acc: 52.985,83.542,96.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.398 | Acc: 52.884,83.428,96.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.403 | Acc: 52.742,83.392,96.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.403 | Acc: 52.636,83.388,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.404 | Acc: 52.701,83.325,96.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.654 | Acc: 50.000,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 47.879,64.993,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 47.237,64.977,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 47.285,65.266,70.044,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.547 | Acc: 49.219,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.355 | Acc: 52.381,83.854,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.361 | Acc: 52.611,83.746,97.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.380 | Acc: 52.510,83.222,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.380 | Acc: 52.903,83.275,97.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.382 | Acc: 52.684,83.323,97.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.377 | Acc: 52.679,83.452,97.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.376 | Acc: 52.748,83.428,96.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.375 | Acc: 52.780,83.555,96.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.377 | Acc: 52.797,83.589,97.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.382 | Acc: 52.841,83.551,96.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.381 | Acc: 52.860,83.527,96.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.380 | Acc: 52.866,83.458,96.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.384 | Acc: 52.718,83.456,96.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.391 | Acc: 52.619,83.377,96.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.389 | Acc: 52.668,83.371,96.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.389 | Acc: 52.716,83.416,96.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.393 | Acc: 52.736,83.344,96.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.399 | Acc: 52.681,83.310,96.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.395 | Acc: 52.752,83.385,96.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.726 | Acc: 49.219,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 47.656,64.881,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 47.104,64.977,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 47.208,65.228,69.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.343 | Acc: 58.594,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.395 | Acc: 52.567,83.222,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.388 | Acc: 52.458,83.365,97.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.395 | Acc: 52.241,83.543,96.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.392 | Acc: 52.517,83.449,97.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.393 | Acc: 52.684,83.455,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.397 | Acc: 52.705,83.374,97.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.385 | Acc: 52.842,83.555,97.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.400 | Acc: 52.708,83.424,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.404 | Acc: 52.655,83.456,96.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.396 | Acc: 52.853,83.543,96.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.399 | Acc: 52.775,83.608,96.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.396 | Acc: 52.892,83.584,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.397 | Acc: 52.820,83.585,96.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.400 | Acc: 52.736,83.549,96.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.402 | Acc: 52.668,83.480,96.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.405 | Acc: 52.616,83.401,96.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.405 | Acc: 52.593,83.381,96.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.402 | Acc: 52.625,83.392,96.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.402 | Acc: 52.657,83.403,96.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.659 | Acc: 49.219,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 48.028,64.769,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 47.161,64.939,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 47.067,65.074,69.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 2.681 | Acc: 54.688,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.384 | Acc: 54.278,83.668,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.399 | Acc: 53.430,83.194,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.384 | Acc: 53.650,83.722,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.391 | Acc: 53.405,83.719,96.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.391 | Acc: 53.287,83.880,96.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.387 | Acc: 53.086,83.981,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.383 | Acc: 53.136,83.993,96.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.384 | Acc: 53.227,83.982,96.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.382 | Acc: 53.367,83.900,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.385 | Acc: 53.245,83.738,96.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.386 | Acc: 53.213,83.824,96.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.392 | Acc: 53.122,83.791,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.395 | Acc: 52.996,83.773,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.395 | Acc: 52.928,83.716,96.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.389 | Acc: 53.112,83.833,96.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.395 | Acc: 52.972,83.788,96.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.397 | Acc: 52.933,83.786,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.398 | Acc: 52.889,83.719,96.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.398 | Acc: 52.959,83.702,96.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.639 | Acc: 50.000,61.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.545 | Acc: 48.028,65.067,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 47.332,65.053,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 47.234,65.459,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.612 | Acc: 54.688,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.399 | Acc: 53.013,83.557,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.371 | Acc: 52.954,83.899,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.397 | Acc: 53.099,83.274,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.381 | Acc: 53.144,83.594,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.389 | Acc: 52.653,83.532,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.384 | Acc: 52.809,83.368,96.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.392 | Acc: 52.560,83.333,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.390 | Acc: 52.611,83.395,96.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.395 | Acc: 52.585,83.343,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.404 | Acc: 52.573,83.298,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.400 | Acc: 52.690,83.311,96.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.397 | Acc: 52.671,83.383,96.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.399 | Acc: 52.619,83.405,96.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.395 | Acc: 52.730,83.371,96.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.398 | Acc: 52.567,83.352,96.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.398 | Acc: 52.624,83.338,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.399 | Acc: 52.692,83.339,96.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.403 | Acc: 52.569,83.317,96.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.407 | Acc: 52.578,83.264,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.616 | Acc: 50.000,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.549 | Acc: 47.768,64.881,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 47.085,64.882,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 47.118,65.074,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.382 | Acc: 57.031,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.382 | Acc: 52.344,83.966,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.364 | Acc: 53.220,83.899,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.395 | Acc: 52.959,83.261,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.389 | Acc: 52.990,83.420,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.396 | Acc: 53.140,83.346,96.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.403 | Acc: 52.964,83.329,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.408 | Acc: 52.909,83.300,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.427 | Acc: 52.683,82.963,96.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.428 | Acc: 52.685,82.968,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.419 | Acc: 52.799,83.096,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.416 | Acc: 52.849,83.095,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.415 | Acc: 52.791,83.124,96.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.408 | Acc: 52.889,83.172,96.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.409 | Acc: 52.822,83.202,96.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.408 | Acc: 52.806,83.225,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.407 | Acc: 52.801,83.272,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.408 | Acc: 52.774,83.255,96.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.410 | Acc: 52.720,83.252,96.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.404 | Acc: 52.797,83.329,96.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.605 | Acc: 50.781,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 48.400,64.881,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.590 | Acc: 47.351,64.996,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.590 | Acc: 47.362,65.254,70.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.460 | Acc: 56.250,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.388 | Acc: 53.051,84.040,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.384 | Acc: 52.934,83.651,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.372 | Acc: 53.304,83.914,96.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.377 | Acc: 53.212,84.018,96.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.382 | Acc: 53.241,83.965,96.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.385 | Acc: 53.209,83.897,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.391 | Acc: 53.119,83.838,96.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.392 | Acc: 53.057,83.885,96.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.387 | Acc: 53.116,83.866,96.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.389 | Acc: 52.954,83.905,96.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.390 | Acc: 52.899,83.774,96.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.388 | Acc: 52.921,83.694,96.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.396 | Acc: 52.936,83.633,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.396 | Acc: 52.919,83.613,96.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.395 | Acc: 52.980,83.615,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.393 | Acc: 53.006,83.567,96.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.393 | Acc: 53.020,83.571,96.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.396 | Acc: 53.030,83.566,96.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.399 | Acc: 52.949,83.567,96.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.636 | Acc: 49.219,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 47.991,64.695,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 47.180,64.825,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 47.118,65.113,69.736,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.356 | Acc: 52.344,83.594,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.427 | Acc: 51.637,84.263,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.424 | Acc: 51.829,84.051,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.415 | Acc: 52.164,83.632,97.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.424 | Acc: 52.402,83.449,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.411 | Acc: 52.483,83.516,96.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.426 | Acc: 52.150,83.361,96.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.432 | Acc: 52.133,83.350,96.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.414 | Acc: 52.455,83.434,96.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.408 | Acc: 52.452,83.507,96.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.399 | Acc: 52.624,83.582,96.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.393 | Acc: 52.863,83.580,97.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.394 | Acc: 52.862,83.558,97.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.390 | Acc: 52.936,83.576,97.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.392 | Acc: 52.953,83.544,97.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.391 | Acc: 53.011,83.555,97.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.394 | Acc: 52.938,83.530,97.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.396 | Acc: 52.983,83.472,96.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.392 | Acc: 52.941,83.522,97.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.393 | Acc: 52.916,83.518,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.656 | Acc: 48.438,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 47.768,64.844,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 47.161,64.920,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 47.182,65.138,70.044,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.437 | Acc: 58.594,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.448 | Acc: 53.125,83.147,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.410 | Acc: 53.030,83.613,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.417 | Acc: 53.061,83.376,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.396 | Acc: 53.385,83.594,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.392 | Acc: 53.311,83.485,96.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.389 | Acc: 53.422,83.452,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.396 | Acc: 53.175,83.555,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.399 | Acc: 53.101,83.419,96.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.391 | Acc: 53.073,83.650,96.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.395 | Acc: 52.942,83.679,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.391 | Acc: 53.058,83.679,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.389 | Acc: 53.050,83.746,96.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.388 | Acc: 53.068,83.702,96.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.384 | Acc: 53.081,83.716,96.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.388 | Acc: 52.884,83.622,96.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.392 | Acc: 52.784,83.504,96.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.392 | Acc: 52.791,83.495,96.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.392 | Acc: 52.742,83.501,96.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.397 | Acc: 52.737,83.428,96.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.661 | Acc: 49.219,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.559 | Acc: 48.326,64.658,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 47.409,64.844,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 47.310,65.164,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.338 | Acc: 52.344,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.360 | Acc: 53.497,84.635,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.348 | Acc: 53.411,84.089,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.388 | Acc: 52.818,83.811,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.390 | Acc: 52.903,83.497,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.374 | Acc: 53.326,83.694,96.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.372 | Acc: 53.299,83.858,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.374 | Acc: 53.319,83.771,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.390 | Acc: 53.057,83.584,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.388 | Acc: 53.147,83.650,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.390 | Acc: 53.043,83.633,96.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.396 | Acc: 52.987,83.495,96.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.394 | Acc: 53.138,83.535,96.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.387 | Acc: 53.191,83.588,96.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.387 | Acc: 53.114,83.599,96.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.389 | Acc: 53.141,83.594,96.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.392 | Acc: 53.123,83.589,96.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.396 | Acc: 53.054,83.509,96.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.392 | Acc: 53.002,83.607,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.388 | Acc: 53.004,83.592,96.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.698 | Acc: 49.219,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.571 | Acc: 48.289,64.955,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 47.351,64.901,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 47.285,65.266,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.393 | Acc: 51.562,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.452 | Acc: 52.307,82.329,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.419 | Acc: 52.344,82.946,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.414 | Acc: 52.446,82.941,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.403 | Acc: 52.353,83.391,96.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.406 | Acc: 52.351,83.362,96.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.414 | Acc: 51.989,83.445,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.413 | Acc: 51.989,83.411,96.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.405 | Acc: 52.198,83.521,96.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.411 | Acc: 52.197,83.412,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.407 | Acc: 52.340,83.481,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.406 | Acc: 52.372,83.392,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.405 | Acc: 52.470,83.312,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.406 | Acc: 52.547,83.330,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.403 | Acc: 52.633,83.382,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.402 | Acc: 52.679,83.448,96.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.403 | Acc: 52.699,83.419,96.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.403 | Acc: 52.671,83.408,96.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.402 | Acc: 52.640,83.408,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.401 | Acc: 52.670,83.424,96.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.629 | Acc: 49.219,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.548 | Acc: 48.028,64.955,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 47.256,64.939,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 47.323,65.254,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.583 | Acc: 44.531,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.461 | Acc: 51.786,83.036,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.446 | Acc: 51.925,83.213,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.431 | Acc: 52.446,83.145,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.426 | Acc: 52.691,83.353,96.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.408 | Acc: 52.955,83.416,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.400 | Acc: 52.925,83.452,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.404 | Acc: 52.671,83.422,97.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.411 | Acc: 52.480,83.312,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.414 | Acc: 52.426,83.296,96.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.410 | Acc: 52.495,83.326,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.408 | Acc: 52.404,83.396,96.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.411 | Acc: 52.460,83.370,96.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.404 | Acc: 52.574,83.447,96.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.399 | Acc: 52.714,83.471,96.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.401 | Acc: 52.679,83.399,96.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.401 | Acc: 52.689,83.411,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.400 | Acc: 52.681,83.443,96.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.399 | Acc: 52.688,83.453,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.397 | Acc: 52.719,83.495,96.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.664 | Acc: 49.219,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 47.917,64.881,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 47.294,64.863,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 47.285,65.151,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 2.699 | Acc: 50.000,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.350 | Acc: 53.311,83.296,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.344 | Acc: 53.601,83.594,97.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.371 | Acc: 53.522,83.453,96.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.370 | Acc: 53.453,83.449,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.368 | Acc: 53.527,83.601,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.368 | Acc: 53.538,83.542,96.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.378 | Acc: 53.214,83.428,96.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.389 | Acc: 53.115,83.307,96.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.390 | Acc: 53.095,83.343,97.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.393 | Acc: 52.997,83.376,97.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.392 | Acc: 53.100,83.350,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.393 | Acc: 53.125,83.438,96.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.391 | Acc: 53.182,83.387,96.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.396 | Acc: 53.106,83.319,96.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.399 | Acc: 53.021,83.350,96.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.399 | Acc: 52.960,83.416,96.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.398 | Acc: 52.939,83.413,96.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.395 | Acc: 53.012,83.449,96.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.398 | Acc: 52.922,83.411,96.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.655 | Acc: 49.219,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 47.731,64.918,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 47.142,64.920,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 47.041,65.279,69.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.816 | Acc: 47.656,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.403 | Acc: 53.199,83.966,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.409 | Acc: 52.439,83.918,97.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.406 | Acc: 52.254,83.683,97.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.408 | Acc: 52.411,83.671,97.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.399 | Acc: 52.591,83.841,96.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.392 | Acc: 52.738,83.871,96.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.395 | Acc: 52.632,83.688,96.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.389 | Acc: 52.572,83.681,96.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.394 | Acc: 52.495,83.576,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.400 | Acc: 52.418,83.535,96.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.401 | Acc: 52.524,83.488,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.392 | Acc: 52.723,83.539,96.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.388 | Acc: 52.766,83.576,96.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.387 | Acc: 52.797,83.602,96.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.392 | Acc: 52.720,83.568,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.396 | Acc: 52.660,83.474,96.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.397 | Acc: 52.630,83.500,96.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.396 | Acc: 52.742,83.496,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.397 | Acc: 52.711,83.545,96.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.684 | Acc: 50.000,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.554 | Acc: 47.917,64.955,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 47.123,65.015,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 47.234,65.241,69.736,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.551 | Acc: 49.219,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.344 | Acc: 52.604,84.263,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.361 | Acc: 53.011,83.498,97.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.392 | Acc: 52.638,83.005,97.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.381 | Acc: 53.038,83.227,97.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.379 | Acc: 53.241,83.485,97.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.387 | Acc: 53.144,83.419,97.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.383 | Acc: 53.230,83.477,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.376 | Acc: 53.503,83.472,97.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.391 | Acc: 53.099,83.404,97.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.394 | Acc: 53.156,83.333,97.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.392 | Acc: 53.153,83.261,96.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.393 | Acc: 53.170,83.250,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.393 | Acc: 53.152,83.241,96.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.394 | Acc: 53.192,83.227,96.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.392 | Acc: 53.200,83.267,96.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.390 | Acc: 53.144,83.338,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.389 | Acc: 53.178,83.326,96.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.389 | Acc: 53.116,83.293,96.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.394 | Acc: 53.080,83.206,96.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.667 | Acc: 49.219,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 47.805,64.695,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.617 | Acc: 47.142,64.825,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 47.093,65.036,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.619 | Acc: 52.344,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.375 | Acc: 53.013,83.780,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.385 | Acc: 53.049,83.308,96.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.392 | Acc: 52.843,83.274,97.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.401 | Acc: 52.749,83.382,96.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.406 | Acc: 52.607,83.346,96.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.403 | Acc: 52.531,83.400,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.389 | Acc: 52.787,83.610,96.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.383 | Acc: 52.970,83.555,96.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.392 | Acc: 52.780,83.460,96.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.387 | Acc: 52.764,83.570,96.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.388 | Acc: 52.814,83.534,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.387 | Acc: 52.798,83.626,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.392 | Acc: 52.667,83.609,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.389 | Acc: 52.711,83.705,96.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.387 | Acc: 52.676,83.749,96.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.391 | Acc: 52.638,83.667,96.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.396 | Acc: 52.591,83.637,96.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.395 | Acc: 52.642,83.618,96.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.395 | Acc: 52.641,83.586,96.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.616 | Acc: 50.000,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 48.028,64.807,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 47.104,64.844,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.614 | Acc: 47.093,64.959,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.418 | Acc: 51.562,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.405 | Acc: 53.088,83.371,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.410 | Acc: 52.363,83.613,97.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.392 | Acc: 53.074,83.568,97.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.410 | Acc: 52.701,83.478,96.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.409 | Acc: 52.607,83.331,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.396 | Acc: 52.738,83.413,97.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.397 | Acc: 52.837,83.350,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.399 | Acc: 52.848,83.458,97.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.393 | Acc: 52.961,83.581,97.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.387 | Acc: 52.966,83.671,97.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.387 | Acc: 52.842,83.657,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.390 | Acc: 52.798,83.578,96.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.393 | Acc: 52.856,83.534,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.392 | Acc: 52.916,83.513,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.398 | Acc: 52.736,83.482,96.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.397 | Acc: 52.709,83.487,96.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.393 | Acc: 52.850,83.566,96.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.395 | Acc: 52.781,83.585,96.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.394 | Acc: 52.824,83.618,96.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.651 | Acc: 49.219,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.544 | Acc: 48.177,65.067,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 47.294,65.111,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.595 | Acc: 47.374,65.279,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.551 | Acc: 57.812,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.404 | Acc: 53.237,83.408,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.395 | Acc: 53.144,83.518,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.391 | Acc: 53.035,83.440,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.411 | Acc: 52.595,83.353,96.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.410 | Acc: 52.545,83.362,96.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.410 | Acc: 52.544,83.400,96.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.408 | Acc: 52.626,83.361,96.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.408 | Acc: 52.732,83.210,96.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.401 | Acc: 52.771,83.257,96.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.399 | Acc: 52.791,83.225,96.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.397 | Acc: 52.849,83.244,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.396 | Acc: 52.888,83.273,96.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.397 | Acc: 52.868,83.327,96.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.401 | Acc: 52.814,83.319,96.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.401 | Acc: 52.834,83.262,96.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.396 | Acc: 52.840,83.326,96.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.398 | Acc: 52.736,83.367,96.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.395 | Acc: 52.796,83.447,96.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.397 | Acc: 52.774,83.438,96.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.646 | Acc: 49.219,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 48.289,65.030,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 47.485,65.034,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 47.451,65.330,69.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.154 | Acc: 56.250,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.315 | Acc: 53.832,84.561,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.346 | Acc: 53.316,83.632,97.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.360 | Acc: 53.471,83.363,97.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.358 | Acc: 53.520,83.430,97.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.366 | Acc: 53.512,83.431,97.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.371 | Acc: 53.571,83.394,97.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.379 | Acc: 53.341,83.461,97.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.385 | Acc: 53.363,83.463,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.392 | Acc: 53.043,83.438,96.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.387 | Acc: 53.109,83.532,97.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.394 | Acc: 52.938,83.413,96.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.395 | Acc: 53.002,83.461,96.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.396 | Acc: 52.838,83.462,96.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.399 | Acc: 52.839,83.369,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.398 | Acc: 52.881,83.300,96.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.397 | Acc: 52.838,83.309,96.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.399 | Acc: 52.772,83.305,96.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.396 | Acc: 52.731,83.358,96.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.392 | Acc: 52.842,83.407,96.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.701 | Acc: 50.781,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 48.140,64.695,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.616 | Acc: 47.332,64.882,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.612 | Acc: 47.336,65.023,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.373 | Acc: 54.688,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.400 | Acc: 52.790,83.185,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.374 | Acc: 54.078,83.308,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.396 | Acc: 53.407,83.338,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.410 | Acc: 53.115,83.237,97.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.395 | Acc: 52.986,83.563,97.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.396 | Acc: 52.899,83.523,97.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.410 | Acc: 52.626,83.350,97.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.407 | Acc: 52.528,83.375,97.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.407 | Acc: 52.426,83.473,97.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.401 | Acc: 52.565,83.578,97.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.398 | Acc: 52.793,83.551,97.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.394 | Acc: 52.811,83.603,97.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.392 | Acc: 52.820,83.699,97.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.394 | Acc: 52.700,83.594,97.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.394 | Acc: 52.790,83.627,97.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.392 | Acc: 52.857,83.621,97.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.394 | Acc: 52.795,83.571,97.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.391 | Acc: 52.809,83.579,97.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.390 | Acc: 52.832,83.551,97.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.680 | Acc: 49.219,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 47.879,64.621,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 47.199,64.806,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 47.144,65.074,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.635 | Acc: 47.656,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.376 | Acc: 52.902,84.449,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.353 | Acc: 53.449,84.337,97.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.379 | Acc: 53.099,83.965,97.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.386 | Acc: 53.000,83.922,97.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.388 | Acc: 52.839,83.957,96.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.393 | Acc: 52.854,83.839,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.389 | Acc: 52.704,83.860,96.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.392 | Acc: 52.378,83.875,96.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.398 | Acc: 52.387,83.676,96.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.399 | Acc: 52.367,83.668,96.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.394 | Acc: 52.574,83.590,96.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.396 | Acc: 52.603,83.539,97.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.396 | Acc: 52.631,83.630,97.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.396 | Acc: 52.661,83.633,97.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.396 | Acc: 52.598,83.524,97.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.395 | Acc: 52.726,83.548,97.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.396 | Acc: 52.717,83.548,97.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.396 | Acc: 52.740,83.514,97.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.398 | Acc: 52.723,83.524,96.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.680 | Acc: 50.000,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 48.214,65.253,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.612 | Acc: 47.370,65.206,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 47.374,65.318,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 2.257 | Acc: 52.344,85.938,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.346 | Acc: 52.121,83.036,96.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.340 | Acc: 53.449,83.841,97.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.328 | Acc: 53.817,83.940,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.354 | Acc: 53.366,83.999,97.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.368 | Acc: 53.164,83.880,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.375 | Acc: 53.112,83.833,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.384 | Acc: 52.748,83.721,97.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.383 | Acc: 52.703,83.749,97.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.379 | Acc: 52.862,83.792,97.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.377 | Acc: 52.977,83.753,97.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.387 | Acc: 52.800,83.650,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.385 | Acc: 52.888,83.629,97.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.389 | Acc: 52.865,83.558,97.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.389 | Acc: 52.944,83.546,97.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.392 | Acc: 52.946,83.542,96.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.393 | Acc: 52.862,83.548,96.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.394 | Acc: 52.800,83.532,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.396 | Acc: 52.772,83.557,97.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.394 | Acc: 52.897,83.581,97.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.674 | Acc: 50.781,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 48.103,64.583,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 47.237,64.748,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 47.259,65.010,69.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.227 | Acc: 58.594,86.719,96.094,% | Adaptive Acc: 94.531% | clf_exit: 0.398 0.422 0.180
Batch: 20 | Loss: 2.395 | Acc: 52.232,85.045,97.061,% | Adaptive Acc: 87.314% | clf_exit: 0.372 0.464 0.165
Batch: 40 | Loss: 2.409 | Acc: 52.611,84.165,96.913,% | Adaptive Acc: 87.157% | clf_exit: 0.367 0.460 0.173
Batch: 60 | Loss: 2.387 | Acc: 53.112,84.196,97.067,% | Adaptive Acc: 87.833% | clf_exit: 0.369 0.454 0.177
Batch: 80 | Loss: 2.389 | Acc: 53.308,84.172,96.933,% | Adaptive Acc: 87.751% | clf_exit: 0.367 0.455 0.178
Batch: 100 | Loss: 2.398 | Acc: 53.287,83.919,96.821,% | Adaptive Acc: 87.353% | clf_exit: 0.368 0.454 0.179
Batch: 120 | Loss: 2.397 | Acc: 53.151,83.865,96.791,% | Adaptive Acc: 87.397% | clf_exit: 0.368 0.454 0.178
Batch: 140 | Loss: 2.393 | Acc: 53.020,83.932,96.842,% | Adaptive Acc: 87.456% | clf_exit: 0.368 0.455 0.177
Batch: 160 | Loss: 2.385 | Acc: 53.183,83.963,96.788,% | Adaptive Acc: 87.544% | clf_exit: 0.371 0.453 0.176
Batch: 180 | Loss: 2.385 | Acc: 53.034,83.922,96.797,% | Adaptive Acc: 87.448% | clf_exit: 0.369 0.454 0.177
Batch: 200 | Loss: 2.392 | Acc: 52.853,83.792,96.809,% | Adaptive Acc: 87.535% | clf_exit: 0.368 0.454 0.179
Batch: 220 | Loss: 2.392 | Acc: 52.853,83.809,96.815,% | Adaptive Acc: 87.521% | clf_exit: 0.369 0.453 0.177
Batch: 240 | Loss: 2.398 | Acc: 52.733,83.743,96.846,% | Adaptive Acc: 87.536% | clf_exit: 0.368 0.454 0.178
Batch: 260 | Loss: 2.396 | Acc: 52.748,83.773,96.854,% | Adaptive Acc: 87.545% | clf_exit: 0.368 0.454 0.178
Batch: 280 | Loss: 2.396 | Acc: 52.797,83.805,96.881,% | Adaptive Acc: 87.617% | clf_exit: 0.368 0.454 0.178
Batch: 300 | Loss: 2.389 | Acc: 52.837,83.851,96.906,% | Adaptive Acc: 87.638% | clf_exit: 0.368 0.454 0.178
Batch: 320 | Loss: 2.389 | Acc: 52.964,83.827,96.904,% | Adaptive Acc: 87.651% | clf_exit: 0.368 0.454 0.179
Batch: 340 | Loss: 2.394 | Acc: 52.914,83.754,96.902,% | Adaptive Acc: 87.644% | clf_exit: 0.367 0.454 0.179
Batch: 360 | Loss: 2.397 | Acc: 52.924,83.682,96.916,% | Adaptive Acc: 87.651% | clf_exit: 0.367 0.454 0.180
Batch: 380 | Loss: 2.397 | Acc: 52.881,83.645,96.943,% | Adaptive Acc: 87.639% | clf_exit: 0.367 0.452 0.180
Batch: 0 | Loss: 4.632 | Acc: 49.219,64.844,75.000,% | Adaptive Acc: 66.406% | clf_exit: 0.398 0.422 0.180
Batch: 20 | Loss: 4.550 | Acc: 48.549,64.918,71.280,% | Adaptive Acc: 65.290% | clf_exit: 0.434 0.368 0.198
Batch: 40 | Loss: 4.597 | Acc: 47.351,65.034,70.351,% | Adaptive Acc: 64.596% | clf_exit: 0.433 0.372 0.194
Batch: 60 | Loss: 4.593 | Acc: 47.246,65.318,70.159,% | Adaptive Acc: 64.626% | clf_exit: 0.430 0.373 0.197
model is save as models/resnet56_2con3_att3_cifar100_adaptive0_circles0_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 4.632 | Acc: 49.219,64.844,75.000,% | Adaptive Acc: 66.406% | clf_exit: 0.398 0.422 0.180
Batch: 20 | Loss: 4.550 | Acc: 48.549,64.918,71.280,% | Adaptive Acc: 65.290% | clf_exit: 0.434 0.368 0.198
Batch: 40 | Loss: 4.597 | Acc: 47.351,65.034,70.351,% | Adaptive Acc: 64.596% | clf_exit: 0.433 0.372 0.194
Batch: 60 | Loss: 4.593 | Acc: 47.246,65.318,70.159,% | Adaptive Acc: 64.626% | clf_exit: 0.430 0.373 0.197







Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.343 |  Acc: 2.170,3.542,5.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 12.551 |  Acc: 3.650,6.720,10.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 12.100 |  Acc: 4.844,8.954,13.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 11.835 |  Acc: 4.460,8.990,15.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 11.387 |  Acc: 6.384,12.610,18.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 11.145 |  Acc: 6.820,13.180,19.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 10.761 |  Acc: 8.104,16.220,22.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 10.361 |  Acc: 9.370,17.710,24.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 10.187 |  Acc: 10.228,19.242,25.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 9.899 |  Acc: 10.750,19.800,27.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 9.660 |  Acc: 12.738,22.416,28.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 9.760 |  Acc: 12.710,21.260,27.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 9.200 |  Acc: 15.266,24.748,31.746,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 8.978 |  Acc: 17.070,25.230,33.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 8.798 |  Acc: 17.684,27.246,34.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 8.778 |  Acc: 18.300,25.840,34.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 8.435 |  Acc: 19.524,29.090,37.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 8.986 |  Acc: 16.620,25.530,34.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 8.129 |  Acc: 21.262,31.114,39.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 8.548 |  Acc: 18.100,28.070,37.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 7.850 |  Acc: 22.520,33.070,41.432,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 8.082 |  Acc: 20.960,30.340,40.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 7.583 |  Acc: 24.254,35.196,43.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 8.609 |  Acc: 19.600,29.640,36.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 7.375 |  Acc: 25.344,36.882,45.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 8.153 |  Acc: 20.020,31.330,41.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 7.179 |  Acc: 26.494,38.314,46.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 8.187 |  Acc: 23.000,31.450,42.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 6.997 |  Acc: 27.170,39.816,48.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 8.772 |  Acc: 19.410,27.260,36.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 6.852 |  Acc: 27.980,40.962,49.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 7.532 |  Acc: 25.720,35.340,46.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 6.714 |  Acc: 28.448,42.230,50.626,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 7.127 |  Acc: 25.000,38.880,48.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 6.559 |  Acc: 29.434,43.538,51.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 7.590 |  Acc: 23.850,37.130,46.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 6.445 |  Acc: 29.850,44.690,53.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 6.976 |  Acc: 27.110,40.590,49.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 6.340 |  Acc: 30.378,45.502,53.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 7.175 |  Acc: 26.820,39.260,47.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 6.230 |  Acc: 30.916,46.262,55.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 7.431 |  Acc: 23.750,38.000,49.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 6.142 |  Acc: 31.606,47.204,55.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 6.874 |  Acc: 27.330,41.260,50.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 6.059 |  Acc: 31.912,47.794,56.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 7.118 |  Acc: 25.360,40.200,51.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 5.962 |  Acc: 32.564,48.740,57.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 7.245 |  Acc: 25.590,38.790,48.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 5.898 |  Acc: 33.000,49.212,57.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 6.972 |  Acc: 26.410,42.200,50.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 5.835 |  Acc: 33.136,49.852,58.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 7.012 |  Acc: 23.230,43.560,50.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 5.746 |  Acc: 33.384,50.706,59.440,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 7.259 |  Acc: 23.890,39.180,52.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 5.681 |  Acc: 34.018,51.522,60.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 6.553 |  Acc: 27.490,45.110,55.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 5.628 |  Acc: 34.000,51.704,60.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 7.000 |  Acc: 24.900,42.180,52.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 5.587 |  Acc: 34.558,52.368,60.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 6.979 |  Acc: 27.210,42.210,52.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 5.536 |  Acc: 34.958,52.758,61.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 7.435 |  Acc: 23.890,41.260,50.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 5.483 |  Acc: 35.150,53.094,61.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 6.483 |  Acc: 27.550,45.560,54.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 5.436 |  Acc: 35.384,53.672,62.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 7.156 |  Acc: 25.390,42.510,49.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 5.381 |  Acc: 35.656,53.872,62.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 6.834 |  Acc: 28.550,45.040,53.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 5.342 |  Acc: 35.936,54.580,63.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 6.935 |  Acc: 25.800,44.480,54.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.273 |  Acc: 36.274,55.090,63.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 7.048 |  Acc: 27.150,42.440,52.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.275 |  Acc: 36.076,54.976,63.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 7.237 |  Acc: 23.260,43.860,53.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.223 |  Acc: 36.388,55.642,64.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 6.900 |  Acc: 27.440,42.840,52.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.175 |  Acc: 36.866,56.164,64.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 6.935 |  Acc: 25.950,44.890,54.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.160 |  Acc: 36.966,56.038,65.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 7.018 |  Acc: 27.390,44.210,51.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.125 |  Acc: 37.262,56.292,65.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 6.503 |  Acc: 30.440,45.490,55.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.087 |  Acc: 37.058,56.720,65.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 6.313 |  Acc: 30.280,47.850,55.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.067 |  Acc: 37.432,57.034,65.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 6.433 |  Acc: 27.730,48.440,56.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.021 |  Acc: 37.788,57.556,66.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 8.340 |  Acc: 22.060,37.590,47.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.010 |  Acc: 37.916,57.558,66.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 6.317 |  Acc: 29.240,48.610,56.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 4.969 |  Acc: 38.078,57.672,66.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 6.405 |  Acc: 27.760,48.690,57.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 4.966 |  Acc: 38.214,57.984,66.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 6.690 |  Acc: 28.450,45.920,55.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 4.935 |  Acc: 38.496,58.138,67.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 6.596 |  Acc: 29.290,44.520,55.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 4.912 |  Acc: 38.354,58.402,67.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 6.594 |  Acc: 28.790,47.310,55.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 4.885 |  Acc: 38.630,58.536,67.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 6.375 |  Acc: 28.910,47.800,55.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 4.861 |  Acc: 38.396,58.884,67.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 7.101 |  Acc: 25.390,44.590,53.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 4.847 |  Acc: 38.812,59.068,68.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 6.993 |  Acc: 23.640,46.710,56.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 4.830 |  Acc: 38.688,59.374,67.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 6.577 |  Acc: 30.120,46.480,55.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 4.821 |  Acc: 38.708,59.190,68.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 7.111 |  Acc: 27.740,43.590,53.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 4.801 |  Acc: 38.908,59.434,68.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 6.669 |  Acc: 27.530,45.330,54.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 4.768 |  Acc: 39.214,59.812,68.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 6.837 |  Acc: 27.920,46.690,56.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 4.756 |  Acc: 39.278,59.772,68.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 6.233 |  Acc: 29.420,50.400,57.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 4.739 |  Acc: 39.304,59.910,68.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.980 |  Acc: 26.550,42.860,55.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 4.727 |  Acc: 39.266,59.966,69.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 6.401 |  Acc: 28.120,49.110,57.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 4.707 |  Acc: 39.492,60.444,69.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 6.427 |  Acc: 29.470,45.590,56.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 4.715 |  Acc: 39.564,60.074,69.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 7.187 |  Acc: 25.310,45.490,53.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.696 |  Acc: 39.714,60.444,69.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 6.191 |  Acc: 28.300,51.640,58.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.673 |  Acc: 39.598,60.582,69.654,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 6.973 |  Acc: 30.860,42.640,51.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.649 |  Acc: 39.666,60.570,70.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 6.377 |  Acc: 29.900,49.380,56.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.645 |  Acc: 39.810,60.768,70.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 5.851 |  Acc: 35.250,50.270,58.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.630 |  Acc: 39.818,60.654,69.962,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 6.174 |  Acc: 30.550,50.450,58.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.602 |  Acc: 40.134,61.010,70.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 6.058 |  Acc: 32.320,50.850,59.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.606 |  Acc: 39.984,61.132,70.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 6.683 |  Acc: 26.200,49.490,57.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.583 |  Acc: 40.056,61.288,70.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 7.437 |  Acc: 24.300,44.380,54.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.576 |  Acc: 40.224,61.502,70.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 7.324 |  Acc: 24.370,42.580,52.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.579 |  Acc: 40.224,61.412,70.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 6.011 |  Acc: 31.110,51.640,59.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.576 |  Acc: 40.074,61.248,70.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 6.181 |  Acc: 31.080,49.300,57.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.533 |  Acc: 40.560,61.748,71.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 6.425 |  Acc: 28.130,49.870,59.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.536 |  Acc: 40.598,62.058,71.270,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.425 |  Acc: 32.350,47.600,56.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.528 |  Acc: 40.512,61.948,71.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 6.772 |  Acc: 30.130,43.990,53.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.510 |  Acc: 40.360,62.090,71.156,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 6.069 |  Acc: 33.760,48.420,57.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.512 |  Acc: 40.314,61.916,71.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 6.112 |  Acc: 32.800,49.950,57.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.506 |  Acc: 40.678,61.706,71.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 6.709 |  Acc: 29.330,45.030,55.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.483 |  Acc: 40.650,62.258,71.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 6.402 |  Acc: 30.210,49.190,57.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.472 |  Acc: 40.774,62.208,71.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 6.965 |  Acc: 28.530,45.140,54.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.471 |  Acc: 40.824,62.224,71.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 6.675 |  Acc: 27.560,48.230,57.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.473 |  Acc: 40.742,62.422,71.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.885 |  Acc: 22.830,48.560,58.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.453 |  Acc: 40.830,62.442,72.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 6.310 |  Acc: 32.670,46.340,56.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.444 |  Acc: 40.786,62.572,72.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 6.325 |  Acc: 29.460,50.600,58.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.432 |  Acc: 41.142,62.764,72.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 5.902 |  Acc: 31.000,52.160,59.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.442 |  Acc: 40.618,62.490,72.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 6.089 |  Acc: 29.090,51.860,59.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.417 |  Acc: 41.046,62.836,72.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 6.305 |  Acc: 30.520,48.050,57.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.411 |  Acc: 41.152,62.874,72.270,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 5.953 |  Acc: 32.850,51.060,59.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.411 |  Acc: 40.946,62.822,72.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 7.116 |  Acc: 28.890,45.430,56.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.429 |  Acc: 41.342,62.814,72.322,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 5.919 |  Acc: 32.910,51.630,60.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.401 |  Acc: 41.364,62.924,72.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 6.611 |  Acc: 27.460,48.500,58.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.402 |  Acc: 41.038,62.936,72.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 5.934 |  Acc: 32.490,51.230,60.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.386 |  Acc: 41.182,63.398,72.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 5.794 |  Acc: 33.210,53.310,59.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.387 |  Acc: 41.288,62.964,72.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 6.141 |  Acc: 32.310,50.010,57.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.367 |  Acc: 41.492,63.006,72.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 5.861 |  Acc: 33.740,52.260,59.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.355 |  Acc: 41.538,63.448,73.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 6.956 |  Acc: 26.580,48.220,55.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.365 |  Acc: 41.344,63.256,72.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 5.748 |  Acc: 34.930,52.330,60.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.346 |  Acc: 41.676,63.694,73.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 6.196 |  Acc: 33.220,48.700,56.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.348 |  Acc: 41.394,63.498,73.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 5.891 |  Acc: 32.170,51.450,59.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.355 |  Acc: 41.510,63.474,72.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 6.123 |  Acc: 33.290,49.680,58.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.335 |  Acc: 41.496,63.232,73.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 6.019 |  Acc: 32.280,50.770,59.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.336 |  Acc: 41.526,63.398,73.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 7.061 |  Acc: 26.280,47.600,55.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.321 |  Acc: 41.892,63.558,73.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.512 |  Acc: 30.520,47.780,55.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.323 |  Acc: 41.746,63.504,73.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 6.732 |  Acc: 26.460,47.120,58.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.308 |  Acc: 41.580,63.614,73.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 7.042 |  Acc: 27.460,45.530,55.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.316 |  Acc: 41.638,63.582,73.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 5.910 |  Acc: 33.660,51.110,59.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.301 |  Acc: 41.862,63.688,73.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 6.857 |  Acc: 28.780,48.200,56.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.292 |  Acc: 42.004,63.852,73.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 6.599 |  Acc: 28.630,48.620,57.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.298 |  Acc: 41.832,63.692,73.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 5.948 |  Acc: 31.120,51.880,60.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.273 |  Acc: 41.926,63.958,73.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 6.291 |  Acc: 29.090,50.430,59.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.277 |  Acc: 41.828,64.000,73.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 9.115 |  Acc: 20.730,36.530,49.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.293 |  Acc: 41.992,64.044,73.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 6.156 |  Acc: 33.110,51.480,58.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.250 |  Acc: 41.928,64.164,73.994,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 6.003 |  Acc: 31.960,52.210,61.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.256 |  Acc: 42.008,64.158,73.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 6.702 |  Acc: 29.740,49.960,53.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.263 |  Acc: 41.886,64.138,73.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 7.657 |  Acc: 22.340,46.690,56.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.258 |  Acc: 42.240,64.134,73.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.157 |  Acc: 33.410,49.280,59.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.248 |  Acc: 42.326,64.372,73.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 6.558 |  Acc: 32.810,46.990,54.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.247 |  Acc: 42.186,64.114,74.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 7.566 |  Acc: 24.170,44.500,54.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.239 |  Acc: 42.102,64.292,74.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 6.802 |  Acc: 26.990,47.940,57.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.240 |  Acc: 42.238,64.272,74.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 7.801 |  Acc: 21.990,45.950,57.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.231 |  Acc: 42.234,64.298,74.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 6.149 |  Acc: 32.090,50.760,59.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.222 |  Acc: 42.600,64.430,74.434,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 6.338 |  Acc: 32.720,48.900,56.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.215 |  Acc: 42.366,64.454,74.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 6.627 |  Acc: 34.580,44.790,55.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.207 |  Acc: 42.530,64.522,74.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 5.946 |  Acc: 34.700,51.590,58.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.230 |  Acc: 42.232,64.156,74.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 5.941 |  Acc: 32.860,51.960,60.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.217 |  Acc: 42.666,64.364,74.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 6.353 |  Acc: 32.210,49.210,58.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.208 |  Acc: 42.492,64.488,74.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 5.880 |  Acc: 35.240,52.110,59.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.195 |  Acc: 42.284,64.766,74.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 6.862 |  Acc: 26.770,48.260,56.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.210 |  Acc: 42.334,64.420,74.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 6.468 |  Acc: 29.660,49.890,56.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.209 |  Acc: 42.742,64.642,74.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 6.723 |  Acc: 28.020,48.730,57.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.187 |  Acc: 42.490,64.950,74.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 6.454 |  Acc: 30.010,50.680,60.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.179 |  Acc: 42.762,64.978,74.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 6.686 |  Acc: 25.980,49.610,58.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.202 |  Acc: 42.424,64.498,74.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 6.493 |  Acc: 32.110,48.830,58.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.177 |  Acc: 42.564,64.728,74.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 5.974 |  Acc: 32.110,53.590,61.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.177 |  Acc: 42.566,64.710,74.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 5.738 |  Acc: 33.560,53.890,60.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.177 |  Acc: 42.760,64.690,74.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 6.092 |  Acc: 32.120,51.210,60.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.149 |  Acc: 42.854,65.166,74.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 6.547 |  Acc: 28.020,47.660,58.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.166 |  Acc: 42.772,65.002,74.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 6.431 |  Acc: 27.880,51.990,58.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.182 |  Acc: 42.530,64.904,74.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.949 |  Acc: 27.690,46.950,56.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.162 |  Acc: 42.892,64.924,74.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 5.748 |  Acc: 33.920,53.870,60.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.149 |  Acc: 42.828,65.324,74.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 6.544 |  Acc: 30.790,49.050,59.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.180 |  Acc: 42.662,64.982,75.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 6.396 |  Acc: 33.100,48.630,54.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.151 |  Acc: 43.008,65.212,74.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 6.354 |  Acc: 30.890,50.470,58.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.152 |  Acc: 42.832,65.004,74.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 6.093 |  Acc: 31.460,52.020,60.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.157 |  Acc: 42.852,64.778,75.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 6.455 |  Acc: 29.700,49.530,57.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.147 |  Acc: 42.962,65.178,75.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 6.234 |  Acc: 32.810,51.320,58.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.146 |  Acc: 42.946,64.942,75.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 5.699 |  Acc: 33.370,53.090,61.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.130 |  Acc: 43.150,65.254,75.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 5.716 |  Acc: 35.180,53.790,60.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.129 |  Acc: 43.136,65.104,75.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 6.017 |  Acc: 32.150,52.330,59.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.133 |  Acc: 43.046,65.288,75.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 6.836 |  Acc: 28.560,48.880,58.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.490 |  Acc: 47.360,71.938,82.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.280 |  Acc: 45.320,64.650,70.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.289 |  Acc: 48.306,73.826,85.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.275 |  Acc: 45.360,65.300,71.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.223 |  Acc: 48.858,74.612,86.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.278 |  Acc: 44.980,65.610,72.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.170 |  Acc: 49.004,74.994,87.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.255 |  Acc: 45.630,65.240,71.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.144 |  Acc: 49.138,75.240,87.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.313 |  Acc: 44.970,65.110,71.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.110 |  Acc: 49.242,75.296,88.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.279 |  Acc: 45.750,65.660,71.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.095 |  Acc: 49.044,75.542,88.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.322 |  Acc: 45.490,65.250,71.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.069 |  Acc: 49.430,76.074,88.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.288 |  Acc: 45.820,65.620,71.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.056 |  Acc: 49.634,75.982,88.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.346 |  Acc: 45.400,65.160,71.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.028 |  Acc: 49.428,76.446,89.192,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.331 |  Acc: 45.410,65.330,71.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.007 |  Acc: 49.694,76.516,89.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.353 |  Acc: 45.530,65.290,71.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 2.995 |  Acc: 49.850,76.508,89.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.454 |  Acc: 44.730,64.570,70.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 2.988 |  Acc: 49.782,76.728,89.626,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.355 |  Acc: 45.770,64.870,71.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 2.975 |  Acc: 49.922,76.798,89.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.345 |  Acc: 45.850,65.590,70.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 2.957 |  Acc: 49.710,76.730,90.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.388 |  Acc: 45.460,65.230,71.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 2.953 |  Acc: 49.754,76.680,90.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.427 |  Acc: 45.560,65.230,70.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 2.936 |  Acc: 49.924,76.844,90.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.452 |  Acc: 45.720,64.850,70.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 2.927 |  Acc: 50.118,76.954,90.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.457 |  Acc: 45.510,64.780,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 2.927 |  Acc: 49.854,77.126,90.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.453 |  Acc: 45.350,65.140,70.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 2.896 |  Acc: 50.166,77.352,90.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.436 |  Acc: 45.660,65.120,70.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 2.898 |  Acc: 50.068,77.190,90.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.421 |  Acc: 45.770,64.950,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 2.889 |  Acc: 49.934,77.234,91.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.436 |  Acc: 45.590,65.420,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 2.879 |  Acc: 50.120,77.380,91.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.465 |  Acc: 45.630,64.990,70.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 2.873 |  Acc: 50.248,77.554,91.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.594 |  Acc: 44.420,64.390,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 2.863 |  Acc: 50.458,77.472,91.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.532 |  Acc: 45.250,64.500,70.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 2.864 |  Acc: 50.278,77.542,91.250,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.518 |  Acc: 45.370,64.750,70.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.844 |  Acc: 50.350,77.930,91.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.450 |  Acc: 46.260,65.160,70.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.845 |  Acc: 50.260,77.740,91.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.514 |  Acc: 45.820,64.480,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.843 |  Acc: 50.276,77.812,91.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.518 |  Acc: 45.680,64.590,69.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.826 |  Acc: 50.514,78.036,92.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.541 |  Acc: 45.120,64.440,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.831 |  Acc: 50.364,77.658,91.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.534 |  Acc: 45.300,65.260,70.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.825 |  Acc: 50.218,78.086,91.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.587 |  Acc: 45.110,63.770,69.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.815 |  Acc: 50.254,78.112,91.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.527 |  Acc: 45.900,64.760,69.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.804 |  Acc: 50.384,78.270,92.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.551 |  Acc: 45.710,64.330,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.806 |  Acc: 50.284,77.950,92.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.555 |  Acc: 45.260,64.310,70.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.799 |  Acc: 50.428,78.186,92.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.612 |  Acc: 45.520,64.210,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.797 |  Acc: 50.588,78.220,92.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.653 |  Acc: 44.400,64.070,69.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.779 |  Acc: 50.586,78.388,92.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.591 |  Acc: 44.900,65.000,69.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.799 |  Acc: 50.494,78.026,92.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.669 |  Acc: 44.710,64.630,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.782 |  Acc: 50.602,78.492,92.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.551 |  Acc: 45.520,64.160,69.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.760 |  Acc: 50.576,78.636,92.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.579 |  Acc: 45.430,64.880,69.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.768 |  Acc: 50.854,78.364,92.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.613 |  Acc: 44.660,64.170,69.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.769 |  Acc: 51.012,78.544,92.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.618 |  Acc: 45.540,64.290,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.769 |  Acc: 50.616,78.400,92.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.717 |  Acc: 44.500,64.360,68.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.769 |  Acc: 50.654,78.536,92.512,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.696 |  Acc: 44.400,63.840,69.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.759 |  Acc: 50.474,78.700,92.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.730 |  Acc: 44.600,63.710,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.756 |  Acc: 50.778,78.784,92.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.644 |  Acc: 45.390,64.750,69.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.752 |  Acc: 50.868,78.544,92.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.650 |  Acc: 44.930,63.910,68.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.746 |  Acc: 50.884,78.696,92.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.614 |  Acc: 45.090,64.240,69.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.748 |  Acc: 50.494,78.782,93.038,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.640 |  Acc: 45.200,64.440,69.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.734 |  Acc: 50.622,79.068,92.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.710 |  Acc: 44.550,63.740,69.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.736 |  Acc: 50.720,79.028,92.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.594 |  Acc: 45.230,64.130,70.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.737 |  Acc: 50.806,78.832,92.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.675 |  Acc: 44.680,64.210,69.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.738 |  Acc: 50.664,78.608,92.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.745 |  Acc: 44.870,63.660,67.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.731 |  Acc: 50.750,78.972,93.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.634 |  Acc: 45.220,64.180,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.736 |  Acc: 50.848,78.980,93.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.696 |  Acc: 44.050,64.590,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.720 |  Acc: 50.718,79.032,93.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.723 |  Acc: 45.040,63.720,68.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.732 |  Acc: 50.634,79.186,92.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.734 |  Acc: 45.490,63.090,68.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.725 |  Acc: 50.680,79.106,92.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.834 |  Acc: 43.500,63.120,67.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.724 |  Acc: 50.922,78.940,93.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.736 |  Acc: 44.440,63.570,68.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.717 |  Acc: 50.760,79.018,93.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.664 |  Acc: 45.450,63.870,69.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.716 |  Acc: 50.882,78.760,93.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.682 |  Acc: 45.070,64.020,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.717 |  Acc: 50.864,79.194,93.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.754 |  Acc: 45.300,63.960,69.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.720 |  Acc: 50.986,79.048,93.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.853 |  Acc: 44.130,63.270,68.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.718 |  Acc: 50.962,78.994,92.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.825 |  Acc: 44.710,62.920,68.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.709 |  Acc: 50.856,79.080,93.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.725 |  Acc: 44.380,63.850,68.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.705 |  Acc: 50.528,79.454,93.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.776 |  Acc: 43.870,63.690,68.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.710 |  Acc: 50.812,79.174,93.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.744 |  Acc: 45.840,63.700,68.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.709 |  Acc: 50.598,78.998,93.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.812 |  Acc: 44.710,63.270,68.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.698 |  Acc: 50.742,79.430,93.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.741 |  Acc: 45.420,64.010,68.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.704 |  Acc: 51.180,79.266,93.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.826 |  Acc: 43.750,63.970,68.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.696 |  Acc: 51.058,79.324,93.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.747 |  Acc: 45.970,63.830,68.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.708 |  Acc: 50.968,79.272,93.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.995 |  Acc: 43.090,62.120,67.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.692 |  Acc: 51.132,79.246,93.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.870 |  Acc: 44.480,63.160,67.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.702 |  Acc: 51.096,79.258,93.190,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.782 |  Acc: 45.100,63.640,68.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.548 |  Acc: 52.150,81.480,94.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.503 |  Acc: 46.650,65.320,70.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.508 |  Acc: 52.176,82.142,95.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.503 |  Acc: 46.900,65.750,70.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.494 |  Acc: 52.208,82.154,95.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.504 |  Acc: 47.210,65.570,70.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.490 |  Acc: 52.426,82.296,95.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.518 |  Acc: 46.930,65.460,70.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.476 |  Acc: 52.474,82.446,95.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.523 |  Acc: 47.020,65.500,70.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.477 |  Acc: 52.388,82.338,96.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.510 |  Acc: 47.040,65.330,69.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.475 |  Acc: 52.480,82.506,95.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.523 |  Acc: 46.830,65.370,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.470 |  Acc: 52.256,82.498,96.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.516 |  Acc: 47.040,65.650,70.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.463 |  Acc: 52.506,82.610,96.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.538 |  Acc: 46.920,65.510,70.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.463 |  Acc: 52.338,82.516,96.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.530 |  Acc: 47.170,65.420,70.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.458 |  Acc: 52.402,82.734,96.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.560 |  Acc: 46.960,65.390,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.457 |  Acc: 52.328,82.656,96.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.535 |  Acc: 47.240,65.360,69.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.454 |  Acc: 52.550,82.660,96.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.527 |  Acc: 46.940,65.450,70.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.448 |  Acc: 52.368,82.818,96.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.540 |  Acc: 47.080,65.570,70.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.448 |  Acc: 52.666,82.746,96.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.551 |  Acc: 47.010,65.420,69.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.451 |  Acc: 52.530,82.778,96.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.546 |  Acc: 47.010,65.320,70.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.439 |  Acc: 52.778,82.846,96.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.546 |  Acc: 46.860,65.570,70.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.438 |  Acc: 52.550,82.896,96.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.556 |  Acc: 46.900,65.270,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.444 |  Acc: 52.520,82.778,96.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.540 |  Acc: 46.960,65.560,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.447 |  Acc: 52.584,82.780,96.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.563 |  Acc: 47.260,65.520,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.449 |  Acc: 52.576,82.688,96.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.556 |  Acc: 46.950,65.490,70.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.442 |  Acc: 52.516,82.858,96.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.561 |  Acc: 47.110,65.490,70.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.434 |  Acc: 52.650,82.964,96.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.592 |  Acc: 46.820,65.210,69.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.435 |  Acc: 52.696,82.968,96.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.556 |  Acc: 47.100,65.390,70.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.434 |  Acc: 52.806,82.992,96.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.582 |  Acc: 46.660,65.150,69.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.438 |  Acc: 52.654,82.864,96.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.574 |  Acc: 46.920,65.380,69.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.423 |  Acc: 52.570,83.070,96.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.562 |  Acc: 47.100,65.320,69.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.435 |  Acc: 52.750,82.888,96.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.584 |  Acc: 47.150,65.250,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.424 |  Acc: 52.402,83.004,96.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.569 |  Acc: 47.070,65.540,69.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.428 |  Acc: 52.568,82.828,96.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.586 |  Acc: 47.190,65.370,70.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.427 |  Acc: 52.524,83.028,96.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.578 |  Acc: 47.090,65.370,69.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.422 |  Acc: 52.846,82.940,96.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.561 |  Acc: 47.300,65.430,70.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.427 |  Acc: 52.686,82.788,96.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.562 |  Acc: 47.230,65.470,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.412 |  Acc: 52.802,83.162,96.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.572 |  Acc: 47.150,65.440,70.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.422 |  Acc: 52.310,82.906,96.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.577 |  Acc: 47.190,65.500,70.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.422 |  Acc: 52.710,82.864,96.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.590 |  Acc: 47.350,65.210,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.423 |  Acc: 52.438,83.204,96.554,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.581 |  Acc: 47.230,65.470,69.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.413 |  Acc: 52.774,83.160,96.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.581 |  Acc: 47.200,65.340,69.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.407 |  Acc: 52.800,83.458,96.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.583 |  Acc: 47.290,65.320,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.402 |  Acc: 52.846,83.198,97.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.576 |  Acc: 47.500,65.530,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.400 |  Acc: 52.620,83.502,96.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.603 |  Acc: 47.190,65.330,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.406 |  Acc: 52.834,83.310,96.778,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.568 |  Acc: 47.280,65.240,69.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.391 |  Acc: 52.728,83.580,96.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.590 |  Acc: 47.230,65.450,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.404 |  Acc: 52.982,83.282,96.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.591 |  Acc: 47.120,65.480,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.410 |  Acc: 52.994,83.228,96.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.580 |  Acc: 47.220,65.500,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.401 |  Acc: 53.010,83.366,96.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.578 |  Acc: 47.200,65.400,69.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.393 |  Acc: 52.868,83.632,96.950,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.570 |  Acc: 47.270,65.310,70.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.398 |  Acc: 52.904,83.558,96.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.588 |  Acc: 47.300,65.400,69.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.394 |  Acc: 52.990,83.526,96.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.583 |  Acc: 47.330,65.360,70.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.396 |  Acc: 52.786,83.508,96.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.589 |  Acc: 47.240,65.260,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.398 |  Acc: 53.028,83.408,96.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.583 |  Acc: 47.180,65.390,70.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.404 |  Acc: 52.770,83.500,96.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.591 |  Acc: 47.170,65.340,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.404 |  Acc: 52.716,83.328,96.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.572 |  Acc: 47.240,65.460,70.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.395 |  Acc: 52.740,83.386,96.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.587 |  Acc: 47.090,65.410,69.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.404 |  Acc: 52.658,83.404,96.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.592 |  Acc: 47.110,65.360,69.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.398 |  Acc: 52.942,83.680,96.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.585 |  Acc: 47.300,65.540,69.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.401 |  Acc: 52.618,83.318,96.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.581 |  Acc: 47.270,65.330,70.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.401 |  Acc: 52.848,83.388,96.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.571 |  Acc: 47.500,65.490,70.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.399 |  Acc: 52.934,83.552,96.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.582 |  Acc: 47.210,65.340,69.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.392 |  Acc: 52.932,83.554,97.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.582 |  Acc: 47.160,65.410,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.399 |  Acc: 52.700,83.398,96.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.585 |  Acc: 47.280,65.380,69.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.390 |  Acc: 52.914,83.562,96.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.583 |  Acc: 47.290,65.490,70.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.399 |  Acc: 52.680,83.456,96.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.580 |  Acc: 47.310,65.410,70.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.395 |  Acc: 52.772,83.500,96.994,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.585 |  Acc: 47.280,65.390,69.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.395 |  Acc: 52.984,83.450,96.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.581 |  Acc: 47.070,65.500,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.400 |  Acc: 52.702,83.486,96.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.579 |  Acc: 47.320,65.380,69.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.396 |  Acc: 53.060,83.202,96.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.593 |  Acc: 47.170,65.340,70.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.395 |  Acc: 52.644,83.574,96.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.596 |  Acc: 47.170,65.280,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.394 |  Acc: 52.888,83.604,96.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.575 |  Acc: 47.330,65.480,70.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.395 |  Acc: 52.844,83.464,96.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.587 |  Acc: 47.430,65.550,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.391 |  Acc: 52.896,83.448,96.986,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.593 |  Acc: 47.390,65.310,69.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.393 |  Acc: 52.786,83.506,97.080,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.583 |  Acc: 47.270,65.420,69.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.396 |  Acc: 52.760,83.518,96.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.586 |  Acc: 47.460,65.490,70.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.393 |  Acc: 52.946,83.578,97.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.587 |  Acc: 47.340,65.290,69.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.398 |  Acc: 52.848,83.648,96.940,% | Adaptive Acc:87.616% | clf_exit: 0.367 0.452 0.180
Testing: Epoch=299 | Loss: 4.573 |  Acc: 47.370,65.500,70.200,% | Adaptive Acc:64.860% | clf_exit: 0.428 0.373 0.199

circles: 0
Testing: Epoch=299 | Loss: 4.573 |  Acc: 47.370,65.500,70.200,% | Adaptive Acc:64.860% | clf_exit: 0.428 0.373 0.199
