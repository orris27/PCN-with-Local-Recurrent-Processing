==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
******************************
IMPORTANT: attention 2 is default to yes!!!!!!
******************************
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=16, out_features=16, bias=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (BN1d): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=48, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (attention_1): ScanLayer(
        (conv): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=48, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention_2): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=16, out_features=4, bias=True)
          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=4, out_features=16, bias=True)
          (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=96, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=96, out_features=100, bias=True)
      (attention): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=32, out_features=8, bias=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=8, out_features=32, bias=True)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
  )
)

Epoch: 0
/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1958: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn("reduction: 'mean' divides the total loss by both the batch size and the support size."
Batch: 0 | Loss: 10.120 | Acc: 0.000,0.000,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.795 | Acc: 1.376,1.153,1.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.677 | Acc: 1.391,0.953,1.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.579 | Acc: 1.217,0.909,1.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.511 | Acc: 1.244,0.945,1.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.463 | Acc: 1.361,1.044,1.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.425 | Acc: 1.375,1.149,1.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.400 | Acc: 1.374,1.252,2.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.368 | Acc: 1.417,1.441,2.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.341 | Acc: 1.558,1.623,2.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.315 | Acc: 1.636,1.679,2.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.289 | Acc: 1.623,1.743,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.259 | Acc: 1.747,1.841,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.231 | Acc: 1.829,1.913,3.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.203 | Acc: 1.857,1.949,3.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.173 | Acc: 1.949,2.014,3.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.143 | Acc: 2.032,2.103,3.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.118 | Acc: 2.094,2.144,3.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.094 | Acc: 2.168,2.212,4.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.064 | Acc: 2.258,2.309,4.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.574 | Acc: 0.781,3.125,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.534 | Acc: 3.609,3.609,7.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.557 | Acc: 3.220,3.296,7.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.554 | Acc: 3.151,3.151,7.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 8.301 | Acc: 4.688,7.031,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.508 | Acc: 3.906,3.646,8.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.481 | Acc: 4.040,3.982,8.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.471 | Acc: 3.932,4.073,8.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.449 | Acc: 3.752,4.263,8.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.432 | Acc: 3.759,4.293,9.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.413 | Acc: 3.777,4.442,9.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.400 | Acc: 3.762,4.510,9.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.390 | Acc: 3.654,4.547,9.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.378 | Acc: 3.630,4.649,9.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.359 | Acc: 3.677,4.816,9.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.346 | Acc: 3.733,4.889,10.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.330 | Acc: 3.783,4.934,10.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.313 | Acc: 3.822,5.050,10.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.301 | Acc: 3.884,5.149,10.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.285 | Acc: 3.945,5.251,10.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.272 | Acc: 3.918,5.315,11.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.260 | Acc: 3.936,5.391,11.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.247 | Acc: 3.956,5.477,11.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.233 | Acc: 3.988,5.600,11.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.029 | Acc: 2.344,6.250,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.036 | Acc: 3.832,7.068,13.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.011 | Acc: 3.906,7.184,13.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.014 | Acc: 3.855,7.159,13.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 8.104 | Acc: 5.469,7.812,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.950 | Acc: 4.241,7.180,14.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.951 | Acc: 4.287,7.431,14.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.937 | Acc: 4.431,7.659,14.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.935 | Acc: 4.552,7.533,14.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.925 | Acc: 4.417,7.580,14.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.921 | Acc: 4.339,7.625,14.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.907 | Acc: 4.350,7.851,15.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.893 | Acc: 4.382,8.011,15.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.883 | Acc: 4.385,8.033,15.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.875 | Acc: 4.396,8.030,15.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.870 | Acc: 4.412,8.060,15.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.859 | Acc: 4.409,8.146,15.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.845 | Acc: 4.478,8.235,15.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.837 | Acc: 4.585,8.307,15.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.824 | Acc: 4.615,8.321,15.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.813 | Acc: 4.661,8.377,15.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.803 | Acc: 4.630,8.443,16.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.795 | Acc: 4.644,8.544,16.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.785 | Acc: 4.659,8.629,16.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.530 | Acc: 7.031,7.812,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.561 | Acc: 5.543,9.375,19.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.541 | Acc: 5.450,9.794,19.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.541 | Acc: 5.225,9.618,19.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 7.575 | Acc: 5.469,10.938,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.614 | Acc: 4.576,10.119,17.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.565 | Acc: 5.259,10.671,18.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.550 | Acc: 5.302,10.451,18.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.539 | Acc: 5.295,10.571,18.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.535 | Acc: 5.237,10.404,18.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.533 | Acc: 5.230,10.324,18.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.524 | Acc: 5.186,10.516,18.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.513 | Acc: 5.241,10.477,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.500 | Acc: 5.318,10.506,18.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.489 | Acc: 5.321,10.599,19.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.487 | Acc: 5.324,10.644,19.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.480 | Acc: 5.388,10.668,19.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.470 | Acc: 5.397,10.713,19.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.460 | Acc: 5.405,10.807,19.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.453 | Acc: 5.399,10.917,19.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.446 | Acc: 5.384,10.967,19.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.435 | Acc: 5.460,11.031,19.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.425 | Acc: 5.482,11.163,19.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.419 | Acc: 5.485,11.247,19.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.103 | Acc: 8.594,10.156,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.301 | Acc: 5.804,11.347,19.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.283 | Acc: 5.697,11.414,20.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.281 | Acc: 5.558,11.424,20.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 7.624 | Acc: 5.469,10.938,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.223 | Acc: 6.138,12.686,21.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.168 | Acc: 6.117,13.396,22.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.158 | Acc: 5.994,13.563,23.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.158 | Acc: 6.038,13.686,23.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.153 | Acc: 5.987,13.614,23.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.161 | Acc: 6.063,13.410,23.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.149 | Acc: 6.106,13.497,23.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.142 | Acc: 6.114,13.587,23.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.141 | Acc: 6.073,13.480,23.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.137 | Acc: 6.071,13.456,23.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.127 | Acc: 6.268,13.483,23.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.121 | Acc: 6.221,13.521,23.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.116 | Acc: 6.211,13.593,23.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.113 | Acc: 6.200,13.579,23.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.105 | Acc: 6.247,13.536,23.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.094 | Acc: 6.248,13.612,23.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.089 | Acc: 6.307,13.639,23.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.082 | Acc: 6.339,13.645,23.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.071 | Acc: 6.377,13.716,23.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.824 | Acc: 7.812,12.500,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.038 | Acc: 6.473,13.356,24.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.022 | Acc: 6.364,13.072,24.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.027 | Acc: 6.378,13.281,23.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 6.738 | Acc: 7.812,16.406,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.857 | Acc: 6.845,15.179,26.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.889 | Acc: 6.879,15.072,25.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.881 | Acc: 6.954,15.087,25.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.871 | Acc: 6.819,15.085,25.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.865 | Acc: 6.846,15.138,25.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.842 | Acc: 7.005,15.328,25.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.847 | Acc: 7.053,15.342,25.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.841 | Acc: 7.085,15.329,25.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.831 | Acc: 7.109,15.521,25.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.815 | Acc: 7.179,15.714,26.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.805 | Acc: 7.222,15.791,26.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.805 | Acc: 7.219,15.855,26.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.793 | Acc: 7.280,15.897,26.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.787 | Acc: 7.368,15.867,26.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.783 | Acc: 7.395,15.861,26.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.776 | Acc: 7.469,15.922,26.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.769 | Acc: 7.538,15.989,26.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.759 | Acc: 7.570,15.986,26.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.752 | Acc: 7.609,16.058,26.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.619 | Acc: 8.594,18.750,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.700 | Acc: 7.292,16.034,27.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.683 | Acc: 7.165,16.254,27.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.682 | Acc: 7.147,16.304,27.190,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 6.116 | Acc: 14.062,19.531,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.551 | Acc: 9.561,17.299,29.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.572 | Acc: 8.708,17.607,28.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.543 | Acc: 8.658,18.071,29.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.522 | Acc: 8.767,18.094,29.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.530 | Acc: 8.919,17.814,29.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.535 | Acc: 8.839,18.020,29.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.535 | Acc: 8.771,17.886,29.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.529 | Acc: 8.807,17.877,29.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.523 | Acc: 8.917,17.848,29.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.518 | Acc: 8.936,17.914,29.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.516 | Acc: 9.053,17.972,29.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.505 | Acc: 9.064,18.124,29.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.499 | Acc: 9.219,18.148,29.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.494 | Acc: 9.283,18.186,29.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.477 | Acc: 9.333,18.309,29.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.474 | Acc: 9.321,18.300,29.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.472 | Acc: 9.318,18.312,29.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.470 | Acc: 9.369,18.309,29.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.464 | Acc: 9.410,18.377,29.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.315 | Acc: 10.156,18.750,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.574 | Acc: 9.263,17.262,28.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.529 | Acc: 9.451,17.016,28.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.532 | Acc: 9.413,17.213,28.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 6.358 | Acc: 11.719,19.531,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.352 | Acc: 11.124,18.378,30.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.300 | Acc: 11.261,19.264,31.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.294 | Acc: 11.539,19.749,31.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.282 | Acc: 11.381,19.975,31.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.279 | Acc: 11.417,20.073,31.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.277 | Acc: 11.338,20.164,31.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.264 | Acc: 11.259,20.180,31.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.256 | Acc: 11.234,20.152,31.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.260 | Acc: 11.188,20.213,31.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.243 | Acc: 11.144,20.266,31.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.241 | Acc: 11.224,20.422,32.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.232 | Acc: 11.294,20.416,32.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.228 | Acc: 11.285,20.432,32.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.219 | Acc: 11.296,20.499,32.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.211 | Acc: 11.301,20.471,32.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.205 | Acc: 11.349,20.522,32.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.202 | Acc: 11.361,20.498,32.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.197 | Acc: 11.398,20.551,32.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.192 | Acc: 11.444,20.561,32.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.101 | Acc: 9.375,21.875,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.199 | Acc: 9.859,19.494,30.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.171 | Acc: 10.156,19.893,31.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.187 | Acc: 10.297,19.787,31.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 5.780 | Acc: 14.844,21.875,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.950 | Acc: 13.132,22.061,35.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.952 | Acc: 13.167,22.046,35.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.949 | Acc: 12.846,22.298,35.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.955 | Acc: 12.799,22.232,35.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.962 | Acc: 12.585,22.262,35.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.953 | Acc: 12.565,22.411,35.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.945 | Acc: 12.711,22.435,35.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.931 | Acc: 12.971,22.593,35.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.932 | Acc: 12.945,22.635,35.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.927 | Acc: 12.966,22.606,35.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.932 | Acc: 13.083,22.525,35.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.932 | Acc: 13.045,22.520,35.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.929 | Acc: 13.111,22.575,35.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.930 | Acc: 13.178,22.553,35.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.928 | Acc: 13.151,22.565,35.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.930 | Acc: 13.167,22.464,35.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.925 | Acc: 13.217,22.397,35.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.920 | Acc: 13.299,22.461,35.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.921 | Acc: 13.353,22.560,35.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.902 | Acc: 11.719,17.969,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.059 | Acc: 12.314,19.085,34.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.037 | Acc: 12.633,19.436,35.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.062 | Acc: 12.500,19.480,34.439,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 6.133 | Acc: 9.375,20.312,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.785 | Acc: 14.695,23.624,37.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.764 | Acc: 14.520,23.552,37.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.738 | Acc: 14.664,24.091,38.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.735 | Acc: 14.574,23.939,37.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.727 | Acc: 14.658,24.110,37.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.705 | Acc: 14.960,24.277,38.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.704 | Acc: 15.043,24.235,38.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.711 | Acc: 15.154,24.243,37.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.715 | Acc: 15.120,24.232,37.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.714 | Acc: 15.190,24.207,37.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.707 | Acc: 15.236,24.268,37.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.715 | Acc: 15.129,24.157,37.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.707 | Acc: 15.116,24.270,37.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.706 | Acc: 15.169,24.260,37.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.702 | Acc: 15.241,24.349,37.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.699 | Acc: 15.296,24.350,37.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.695 | Acc: 15.323,24.443,37.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.692 | Acc: 15.337,24.474,37.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.687 | Acc: 15.379,24.541,37.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.546 | Acc: 17.188,21.875,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.687 | Acc: 15.141,23.103,36.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.690 | Acc: 14.939,23.476,36.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.709 | Acc: 15.202,23.783,36.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 5.226 | Acc: 19.531,30.469,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.520 | Acc: 16.555,25.744,40.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.521 | Acc: 16.368,25.781,40.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.518 | Acc: 16.483,25.602,40.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.525 | Acc: 16.155,25.656,39.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.515 | Acc: 16.275,25.789,39.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.507 | Acc: 16.406,25.626,39.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.515 | Acc: 16.351,25.521,39.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.500 | Acc: 16.431,25.733,39.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.501 | Acc: 16.579,25.725,39.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.510 | Acc: 16.519,25.517,39.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.504 | Acc: 16.661,25.612,39.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.502 | Acc: 16.659,25.694,39.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.499 | Acc: 16.658,25.799,39.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.499 | Acc: 16.723,25.881,39.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.490 | Acc: 16.835,26.028,39.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.487 | Acc: 16.927,26.083,39.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.485 | Acc: 16.956,26.141,39.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.485 | Acc: 16.997,26.128,39.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.481 | Acc: 17.087,26.193,39.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.630 | Acc: 18.750,29.688,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.758 | Acc: 15.476,21.838,37.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.745 | Acc: 15.587,22.294,36.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.747 | Acc: 15.177,22.003,36.924,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 4.903 | Acc: 22.656,28.125,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.353 | Acc: 18.155,27.307,42.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.316 | Acc: 18.350,28.182,42.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.303 | Acc: 18.404,28.240,42.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.317 | Acc: 18.065,27.874,42.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.297 | Acc: 18.255,28.140,42.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.294 | Acc: 18.292,28.202,42.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.298 | Acc: 18.379,28.086,42.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.311 | Acc: 18.236,28.004,42.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.310 | Acc: 18.267,27.948,42.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.311 | Acc: 18.369,27.849,42.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.309 | Acc: 18.372,27.835,42.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.315 | Acc: 18.367,27.720,42.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.315 | Acc: 18.361,27.724,42.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.312 | Acc: 18.491,27.769,42.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.303 | Acc: 18.612,27.917,42.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.296 | Acc: 18.604,27.974,42.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.291 | Acc: 18.686,28.098,42.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.289 | Acc: 18.711,28.134,42.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.287 | Acc: 18.682,28.137,42.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.649 | Acc: 15.625,22.656,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.763 | Acc: 14.881,23.996,35.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.734 | Acc: 15.644,23.628,35.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.732 | Acc: 15.535,23.540,35.669,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 4.969 | Acc: 17.188,31.250,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.197 | Acc: 18.638,28.981,43.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.178 | Acc: 19.150,28.925,43.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.150 | Acc: 19.570,29.867,44.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.132 | Acc: 19.792,29.774,44.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.122 | Acc: 19.848,29.881,44.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.141 | Acc: 19.951,29.739,43.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.142 | Acc: 20.096,29.782,43.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.152 | Acc: 20.080,29.556,44.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.161 | Acc: 20.084,29.562,43.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.167 | Acc: 20.005,29.377,43.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.166 | Acc: 20.019,29.306,43.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.158 | Acc: 19.988,29.308,43.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.155 | Acc: 19.947,29.268,43.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.153 | Acc: 19.834,29.237,43.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.156 | Acc: 19.762,29.158,43.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.152 | Acc: 19.767,29.254,43.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.149 | Acc: 19.820,29.241,43.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.143 | Acc: 19.888,29.356,43.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.138 | Acc: 19.913,29.446,43.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.563 | Acc: 16.406,28.125,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.648 | Acc: 14.509,26.674,38.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.621 | Acc: 14.920,25.857,38.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.616 | Acc: 14.997,26.089,37.884,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 4.681 | Acc: 24.219,32.031,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.913 | Acc: 20.610,31.734,47.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.966 | Acc: 20.217,31.079,46.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.976 | Acc: 20.159,30.686,45.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.999 | Acc: 19.985,30.720,45.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.003 | Acc: 19.841,30.569,45.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.980 | Acc: 20.099,30.746,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.983 | Acc: 20.119,30.834,46.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.000 | Acc: 20.046,30.605,45.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.005 | Acc: 20.118,30.646,45.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.010 | Acc: 20.281,30.683,45.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.005 | Acc: 20.397,30.695,45.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.999 | Acc: 20.595,30.741,45.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.993 | Acc: 20.663,30.705,45.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.987 | Acc: 20.707,30.672,45.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.983 | Acc: 20.798,30.785,45.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.983 | Acc: 20.702,30.817,45.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.979 | Acc: 20.784,30.897,45.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.978 | Acc: 20.838,30.908,45.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.978 | Acc: 20.821,30.887,45.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.253 | Acc: 26.562,31.250,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.209 | Acc: 20.685,26.935,41.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.202 | Acc: 20.579,27.420,42.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.215 | Acc: 20.351,27.510,42.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 4.642 | Acc: 22.656,30.469,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.749 | Acc: 21.689,32.775,48.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.810 | Acc: 21.532,32.508,47.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.824 | Acc: 21.337,31.980,47.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.835 | Acc: 21.277,32.118,47.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.836 | Acc: 21.264,32.140,47.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.849 | Acc: 21.281,31.902,47.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.860 | Acc: 21.482,31.904,47.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.862 | Acc: 21.482,32.031,47.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.858 | Acc: 21.569,32.092,47.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.850 | Acc: 21.576,32.144,47.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.862 | Acc: 21.578,32.063,47.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.863 | Acc: 21.671,32.148,47.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.866 | Acc: 21.555,32.085,47.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.862 | Acc: 21.644,32.212,47.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.866 | Acc: 21.649,32.132,47.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.860 | Acc: 21.690,32.224,47.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.860 | Acc: 21.712,32.295,47.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.859 | Acc: 21.754,32.326,47.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.853 | Acc: 21.869,32.398,47.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.952 | Acc: 24.219,38.281,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.169 | Acc: 19.196,29.167,42.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.200 | Acc: 19.074,28.639,42.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.213 | Acc: 19.378,28.599,42.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 4.546 | Acc: 20.312,28.125,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.780 | Acc: 23.326,32.515,47.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.751 | Acc: 23.037,32.679,48.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.752 | Acc: 22.989,32.428,48.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.749 | Acc: 22.656,32.542,48.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.754 | Acc: 22.679,32.666,48.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.770 | Acc: 22.488,32.619,48.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.774 | Acc: 22.390,32.779,48.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.775 | Acc: 22.292,32.948,48.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.767 | Acc: 22.345,32.951,48.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.766 | Acc: 22.407,32.984,48.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.770 | Acc: 22.296,32.968,48.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.772 | Acc: 22.413,33.104,48.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.765 | Acc: 22.465,33.175,48.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.753 | Acc: 22.565,33.374,48.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.745 | Acc: 22.503,33.503,48.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.739 | Acc: 22.520,33.479,48.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.732 | Acc: 22.608,33.591,48.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.735 | Acc: 22.561,33.639,48.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.739 | Acc: 22.529,33.577,48.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.032 | Acc: 22.656,28.906,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.137 | Acc: 20.647,31.362,42.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.090 | Acc: 20.636,30.964,43.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.085 | Acc: 20.479,30.853,43.660,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 4.584 | Acc: 23.438,34.375,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.561 | Acc: 23.772,34.710,52.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.633 | Acc: 23.056,34.070,51.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 23.399,34.247,50.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.639 | Acc: 23.331,34.394,50.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.653 | Acc: 23.283,34.259,50.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.640 | Acc: 23.392,34.388,50.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.641 | Acc: 23.471,34.464,50.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.634 | Acc: 23.467,34.385,50.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.637 | Acc: 23.550,34.315,50.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.632 | Acc: 23.682,34.519,50.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.628 | Acc: 23.639,34.548,50.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.618 | Acc: 23.694,34.722,50.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.623 | Acc: 23.662,34.704,50.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.622 | Acc: 23.565,34.731,50.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.619 | Acc: 23.661,34.793,50.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.620 | Acc: 23.603,34.723,50.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.621 | Acc: 23.676,34.758,50.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.623 | Acc: 23.643,34.671,50.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.624 | Acc: 23.641,34.666,50.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.919 | Acc: 21.875,34.375,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.129 | Acc: 20.238,29.539,43.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.159 | Acc: 20.389,28.773,42.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.174 | Acc: 20.479,28.637,42.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.489 | Acc: 23.438,42.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.548 | Acc: 23.512,35.863,51.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.565 | Acc: 23.380,35.671,50.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 23.911,36.130,51.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.550 | Acc: 23.949,36.111,51.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.544 | Acc: 24.211,36.270,50.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.536 | Acc: 24.283,36.118,50.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.540 | Acc: 24.163,36.048,50.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.539 | Acc: 24.136,36.059,51.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.536 | Acc: 24.094,35.946,50.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.536 | Acc: 24.207,35.949,51.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.532 | Acc: 24.166,35.899,51.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.546 | Acc: 24.180,35.685,50.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.540 | Acc: 24.198,35.716,50.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.536 | Acc: 24.316,35.887,51.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.529 | Acc: 24.434,35.984,51.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.526 | Acc: 24.477,35.998,51.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.529 | Acc: 24.448,35.924,51.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.524 | Acc: 24.478,35.931,51.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.521 | Acc: 24.494,35.915,51.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.811 | Acc: 26.562,41.406,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.993 | Acc: 21.875,32.812,45.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.021 | Acc: 21.894,31.879,45.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.024 | Acc: 22.067,32.006,45.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.367 | Acc: 25.781,35.156,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 22.842,36.458,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.504 | Acc: 23.285,36.261,52.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.481 | Acc: 24.180,36.194,52.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.472 | Acc: 24.354,36.420,52.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.460 | Acc: 24.745,36.665,52.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.452 | Acc: 25.006,36.751,52.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.448 | Acc: 25.199,36.874,52.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.433 | Acc: 25.446,37.015,52.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.431 | Acc: 25.410,37.012,52.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.434 | Acc: 25.435,37.010,52.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.437 | Acc: 25.346,36.888,52.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.437 | Acc: 25.357,36.972,52.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.433 | Acc: 25.434,37.132,52.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.433 | Acc: 25.473,37.116,52.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.429 | Acc: 25.413,37.189,52.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.427 | Acc: 25.382,37.169,52.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.423 | Acc: 25.410,37.170,52.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.423 | Acc: 25.420,37.186,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.419 | Acc: 25.455,37.211,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.868 | Acc: 25.000,42.188,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.838 | Acc: 22.917,34.821,45.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.840 | Acc: 23.152,34.889,45.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.836 | Acc: 23.412,34.580,45.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 4.187 | Acc: 26.562,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.382 | Acc: 23.549,37.314,53.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.359 | Acc: 25.191,37.538,53.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.341 | Acc: 25.192,37.666,53.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 25.318,37.384,53.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.340 | Acc: 25.410,37.570,53.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.342 | Acc: 25.646,37.571,53.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.343 | Acc: 25.687,37.506,53.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.345 | Acc: 25.636,37.495,53.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.340 | Acc: 25.699,37.673,53.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.347 | Acc: 25.645,37.722,53.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.340 | Acc: 25.707,37.716,53.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.341 | Acc: 25.668,37.759,53.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.335 | Acc: 25.733,37.916,53.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.335 | Acc: 25.712,37.825,53.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.336 | Acc: 25.763,37.983,53.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.328 | Acc: 25.883,38.094,53.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.332 | Acc: 25.884,38.004,53.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.329 | Acc: 25.915,38.067,53.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.327 | Acc: 25.906,38.027,53.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.997 | Acc: 25.781,35.938,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.133 | Acc: 18.452,32.143,45.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.147 | Acc: 18.693,31.498,44.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.154 | Acc: 18.622,30.725,44.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.913 | Acc: 21.875,25.781,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.205 | Acc: 25.781,38.728,54.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.235 | Acc: 26.067,38.872,54.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.258 | Acc: 26.025,39.165,53.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.251 | Acc: 26.167,39.304,54.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.250 | Acc: 26.269,39.287,53.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.246 | Acc: 26.278,39.366,54.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.249 | Acc: 26.058,39.234,54.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.247 | Acc: 26.145,39.062,54.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.251 | Acc: 26.127,38.933,54.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.258 | Acc: 26.174,38.930,54.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.255 | Acc: 26.251,39.119,54.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.258 | Acc: 26.242,39.179,54.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.254 | Acc: 26.383,39.296,54.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.265 | Acc: 26.371,39.188,54.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.269 | Acc: 26.363,39.159,54.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.267 | Acc: 26.407,39.194,54.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.269 | Acc: 26.349,39.223,54.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.266 | Acc: 26.381,39.327,54.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.267 | Acc: 26.345,39.280,54.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.463 | Acc: 25.781,38.281,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.681 | Acc: 24.888,33.222,50.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.657 | Acc: 24.771,33.327,49.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.662 | Acc: 24.590,33.274,49.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 3.994 | Acc: 32.031,36.719,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.033 | Acc: 28.162,41.704,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.068 | Acc: 28.239,41.120,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.097 | Acc: 27.766,40.548,56.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.107 | Acc: 27.604,40.731,56.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.109 | Acc: 27.584,40.563,56.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.113 | Acc: 27.434,40.586,56.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.126 | Acc: 27.238,40.398,56.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.131 | Acc: 27.387,40.465,56.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.136 | Acc: 27.270,40.414,56.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.148 | Acc: 27.192,40.368,56.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.152 | Acc: 27.245,40.402,56.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.153 | Acc: 27.263,40.408,55.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.161 | Acc: 27.212,40.299,55.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.158 | Acc: 27.271,40.241,55.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.166 | Acc: 27.222,40.277,55.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.172 | Acc: 27.171,40.279,55.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.175 | Acc: 27.119,40.236,55.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.174 | Acc: 27.130,40.285,55.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.174 | Acc: 27.178,40.289,55.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.571 | Acc: 21.875,41.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.936 | Acc: 21.763,32.515,47.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.885 | Acc: 21.799,33.365,47.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.868 | Acc: 21.696,33.466,47.912,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 4.127 | Acc: 25.000,38.281,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.030 | Acc: 27.604,41.518,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.053 | Acc: 27.611,41.044,57.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.051 | Acc: 27.830,41.086,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.069 | Acc: 27.459,40.741,56.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.045 | Acc: 27.847,41.205,57.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.046 | Acc: 28.080,41.348,57.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.051 | Acc: 28.086,41.307,57.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.061 | Acc: 27.989,41.309,57.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.074 | Acc: 27.896,41.255,56.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.082 | Acc: 27.927,41.220,56.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.092 | Acc: 27.754,41.134,56.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.100 | Acc: 27.713,41.102,56.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.098 | Acc: 27.772,41.107,56.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.104 | Acc: 27.847,41.078,56.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.105 | Acc: 27.850,41.043,56.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.101 | Acc: 27.855,41.119,56.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.104 | Acc: 27.887,41.072,56.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.108 | Acc: 27.865,41.036,56.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.110 | Acc: 27.793,41.037,56.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.610 | Acc: 24.219,41.406,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.657 | Acc: 24.628,35.454,50.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.640 | Acc: 24.543,35.633,49.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.655 | Acc: 24.142,35.438,49.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 4.105 | Acc: 23.438,37.500,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.966 | Acc: 29.167,43.006,58.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.993 | Acc: 28.354,42.511,58.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.033 | Acc: 28.125,41.393,57.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.031 | Acc: 28.183,41.454,57.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.040 | Acc: 28.032,41.228,57.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.037 | Acc: 28.144,41.471,57.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.040 | Acc: 28.191,41.622,57.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.047 | Acc: 28.033,41.605,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.049 | Acc: 27.922,41.557,57.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.050 | Acc: 27.826,41.601,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.043 | Acc: 27.895,41.717,57.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.040 | Acc: 27.979,41.737,57.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.037 | Acc: 28.083,41.718,57.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.033 | Acc: 28.175,41.757,57.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.032 | Acc: 28.200,41.736,57.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.030 | Acc: 28.259,41.830,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.037 | Acc: 28.203,41.798,57.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.034 | Acc: 28.240,41.824,57.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.030 | Acc: 28.279,41.917,57.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 28.906,42.969,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 23.810,36.421,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 23.342,36.414,50.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 22.964,36.053,50.756,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 3.748 | Acc: 32.812,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.853 | Acc: 30.060,43.750,60.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.884 | Acc: 29.211,43.274,59.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.908 | Acc: 29.111,42.905,58.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.903 | Acc: 29.379,43.104,59.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.945 | Acc: 28.659,42.830,58.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.959 | Acc: 28.396,42.633,58.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.967 | Acc: 28.441,42.631,58.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.966 | Acc: 28.576,42.770,58.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.969 | Acc: 28.501,42.649,58.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.974 | Acc: 28.502,42.627,58.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.975 | Acc: 28.563,42.527,58.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.983 | Acc: 28.533,42.450,58.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.986 | Acc: 28.496,42.379,58.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.986 | Acc: 28.525,42.427,57.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.984 | Acc: 28.564,42.496,57.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.983 | Acc: 28.602,42.572,57.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.984 | Acc: 28.560,42.572,57.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.987 | Acc: 28.595,42.612,57.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.990 | Acc: 28.590,42.645,57.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 24.219,40.625,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.359 | Acc: 24.405,37.798,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 25.381,38.281,51.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.406 | Acc: 25.218,38.115,51.985,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 3.956 | Acc: 28.125,47.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.856 | Acc: 29.241,43.527,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.896 | Acc: 28.697,42.607,59.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.904 | Acc: 28.535,42.828,59.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.916 | Acc: 28.926,42.892,59.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.934 | Acc: 28.651,42.853,59.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.932 | Acc: 28.700,43.272,59.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.914 | Acc: 29.017,43.440,59.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.923 | Acc: 28.984,43.328,59.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.920 | Acc: 29.083,43.370,59.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.910 | Acc: 29.174,43.653,59.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.908 | Acc: 29.168,43.757,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.905 | Acc: 29.172,43.808,59.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.903 | Acc: 29.200,43.864,59.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.905 | Acc: 29.190,43.786,59.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.908 | Acc: 29.155,43.758,58.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.908 | Acc: 29.118,43.774,58.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.914 | Acc: 29.083,43.748,58.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.916 | Acc: 29.045,43.718,58.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.916 | Acc: 29.101,43.707,58.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.997 | Acc: 22.656,34.375,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.120 | Acc: 22.805,31.250,47.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.125 | Acc: 22.523,30.469,46.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.110 | Acc: 22.259,30.443,46.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 3.578 | Acc: 27.344,45.312,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.796 | Acc: 29.762,44.792,61.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.815 | Acc: 30.011,44.341,60.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.791 | Acc: 30.110,45.133,61.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.807 | Acc: 29.745,45.081,61.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.818 | Acc: 29.688,44.578,61.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.836 | Acc: 29.507,44.137,60.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.831 | Acc: 29.560,44.271,60.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.841 | Acc: 29.459,44.114,60.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.846 | Acc: 29.502,44.061,60.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.842 | Acc: 29.567,44.170,60.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.854 | Acc: 29.500,44.065,59.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.862 | Acc: 29.461,44.029,59.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.863 | Acc: 29.487,44.070,59.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.870 | Acc: 29.460,43.920,59.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.871 | Acc: 29.436,43.888,59.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.867 | Acc: 29.505,44.037,59.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.874 | Acc: 29.406,43.995,59.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.876 | Acc: 29.320,43.908,59.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.875 | Acc: 29.306,43.900,59.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.771 | Acc: 22.656,31.250,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 23.921,38.802,50.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 23.590,37.881,50.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 23.105,37.884,49.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 3.927 | Acc: 30.469,41.406,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.836 | Acc: 29.353,43.824,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.794 | Acc: 30.297,45.065,60.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.826 | Acc: 29.944,44.570,59.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.828 | Acc: 29.813,44.522,60.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.841 | Acc: 29.757,44.307,60.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.829 | Acc: 29.823,44.628,60.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.824 | Acc: 29.937,44.664,60.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.837 | Acc: 29.823,44.546,59.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.832 | Acc: 29.808,44.492,60.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.837 | Acc: 29.781,44.380,59.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.834 | Acc: 29.893,44.563,59.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.833 | Acc: 29.866,44.596,59.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.832 | Acc: 29.732,44.594,59.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.833 | Acc: 29.704,44.604,59.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.826 | Acc: 29.747,44.734,59.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.826 | Acc: 29.880,44.697,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.826 | Acc: 29.914,44.756,59.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.825 | Acc: 29.897,44.802,59.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.821 | Acc: 29.891,44.900,59.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.171 | Acc: 25.781,37.500,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.136 | Acc: 25.298,41.629,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.147 | Acc: 25.838,41.082,56.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.171 | Acc: 25.973,40.894,56.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 3.602 | Acc: 32.812,48.438,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.661 | Acc: 32.180,46.391,63.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.703 | Acc: 31.803,45.922,62.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.701 | Acc: 31.416,45.902,61.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.742 | Acc: 30.845,45.341,61.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.746 | Acc: 30.623,45.150,61.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.751 | Acc: 30.553,45.015,61.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.748 | Acc: 30.469,45.030,61.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.755 | Acc: 30.347,44.876,60.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.775 | Acc: 29.998,44.592,60.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.772 | Acc: 30.100,44.644,60.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.771 | Acc: 30.105,44.634,60.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.779 | Acc: 30.038,44.674,60.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.784 | Acc: 30.044,44.693,60.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.778 | Acc: 30.085,44.832,60.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.779 | Acc: 30.111,44.876,60.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.774 | Acc: 30.152,44.964,60.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.780 | Acc: 30.180,44.905,60.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.780 | Acc: 30.157,44.968,60.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.776 | Acc: 30.245,45.066,60.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.242 | Acc: 28.906,45.312,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 26.004,40.253,54.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.337 | Acc: 25.915,39.539,54.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.337 | Acc: 25.589,39.319,54.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 3.505 | Acc: 26.562,49.219,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.674 | Acc: 29.576,45.982,63.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.639 | Acc: 30.621,46.875,63.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.641 | Acc: 30.712,46.516,62.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.661 | Acc: 30.440,46.383,62.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.662 | Acc: 30.538,46.047,62.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.672 | Acc: 30.495,45.958,62.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.676 | Acc: 30.668,46.061,61.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.678 | Acc: 30.774,46.074,61.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.686 | Acc: 30.663,45.947,61.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.683 | Acc: 30.504,45.973,61.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.688 | Acc: 30.458,45.963,61.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.689 | Acc: 30.595,46.035,61.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.696 | Acc: 30.508,45.965,61.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.694 | Acc: 30.491,45.935,61.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.703 | Acc: 30.383,45.871,61.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.708 | Acc: 30.379,45.889,61.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.715 | Acc: 30.318,45.764,61.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.719 | Acc: 30.345,45.856,61.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.716 | Acc: 30.370,45.930,61.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.030 | Acc: 25.781,28.125,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.061 | Acc: 21.949,30.394,47.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.131 | Acc: 21.856,30.050,46.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.133 | Acc: 21.862,30.187,46.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 3.750 | Acc: 29.688,39.062,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.656 | Acc: 31.622,46.131,62.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.651 | Acc: 31.098,45.827,62.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.643 | Acc: 30.994,46.030,62.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.639 | Acc: 30.556,46.171,62.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.652 | Acc: 30.260,46.156,62.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.647 | Acc: 30.301,46.074,62.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.645 | Acc: 30.436,46.160,62.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.644 | Acc: 30.585,46.234,62.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.648 | Acc: 30.572,46.348,62.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.649 | Acc: 30.578,46.440,62.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.651 | Acc: 30.716,46.377,62.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.647 | Acc: 30.725,46.424,62.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.649 | Acc: 30.780,46.414,62.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.654 | Acc: 30.752,46.394,62.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.659 | Acc: 30.733,46.327,62.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.662 | Acc: 30.766,46.359,62.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.661 | Acc: 30.817,46.440,62.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.665 | Acc: 30.741,46.375,62.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.671 | Acc: 30.668,46.373,62.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.961 | Acc: 21.094,29.688,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.829 | Acc: 21.949,33.557,48.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.798 | Acc: 22.180,34.623,49.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.833 | Acc: 21.747,34.016,49.155,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 3.498 | Acc: 35.156,48.438,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.487 | Acc: 31.473,49.405,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.512 | Acc: 31.536,48.800,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.530 | Acc: 31.596,48.450,65.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.544 | Acc: 31.366,48.167,64.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.574 | Acc: 31.180,47.741,64.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.593 | Acc: 31.153,47.585,63.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.597 | Acc: 30.940,47.606,63.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.599 | Acc: 30.930,47.617,63.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.605 | Acc: 30.905,47.674,63.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.613 | Acc: 30.978,47.505,63.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.617 | Acc: 30.925,47.402,63.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.624 | Acc: 30.923,47.326,63.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.627 | Acc: 30.939,47.288,63.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.625 | Acc: 31.128,47.337,63.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.622 | Acc: 31.146,47.389,63.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.626 | Acc: 31.104,47.306,63.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.629 | Acc: 31.140,47.299,63.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.631 | Acc: 31.153,47.252,63.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.639 | Acc: 31.092,47.135,62.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.864 | Acc: 20.312,36.719,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.664 | Acc: 23.549,35.305,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.706 | Acc: 23.323,35.099,51.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.753 | Acc: 23.028,34.247,50.871,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.607 | Acc: 28.906,46.875,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.523 | Acc: 31.845,48.735,63.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.517 | Acc: 32.012,48.361,64.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.491 | Acc: 32.044,48.860,65.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.515 | Acc: 31.944,48.418,64.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.524 | Acc: 32.140,48.175,64.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.534 | Acc: 31.825,48.115,64.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.546 | Acc: 31.871,47.967,64.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.555 | Acc: 31.949,48.059,63.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.556 | Acc: 31.772,48.027,63.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.557 | Acc: 31.891,48.029,63.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.569 | Acc: 31.699,47.921,63.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.569 | Acc: 31.778,47.948,63.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.575 | Acc: 31.780,47.857,63.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.576 | Acc: 31.731,47.784,63.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.583 | Acc: 31.676,47.677,63.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.589 | Acc: 31.671,47.586,63.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.595 | Acc: 31.612,47.530,63.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.599 | Acc: 31.609,47.490,63.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.598 | Acc: 31.553,47.507,63.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.221 | Acc: 26.562,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.370 | Acc: 26.190,41.369,53.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.380 | Acc: 26.029,40.758,53.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.380 | Acc: 25.512,40.074,52.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 3.490 | Acc: 28.125,50.000,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.569 | Acc: 30.134,46.949,64.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.563 | Acc: 30.945,47.694,64.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.547 | Acc: 31.084,47.643,64.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.557 | Acc: 31.047,47.415,64.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.555 | Acc: 31.474,47.502,64.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.550 | Acc: 31.599,47.734,64.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.552 | Acc: 31.743,47.822,64.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.537 | Acc: 31.837,48.093,64.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.531 | Acc: 31.932,48.204,64.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.534 | Acc: 32.023,48.239,64.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.542 | Acc: 32.219,48.278,64.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.544 | Acc: 32.161,48.249,64.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.544 | Acc: 32.184,48.411,63.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.553 | Acc: 32.026,48.337,63.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.561 | Acc: 31.829,48.235,63.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.566 | Acc: 31.761,48.267,63.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.560 | Acc: 31.912,48.325,63.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.560 | Acc: 31.910,48.264,63.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.563 | Acc: 31.900,48.163,63.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.174 | Acc: 27.344,39.062,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.186 | Acc: 27.269,41.443,55.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.219 | Acc: 26.582,40.701,54.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.231 | Acc: 26.870,40.932,54.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 3.353 | Acc: 35.156,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.491 | Acc: 32.254,48.475,64.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.478 | Acc: 32.222,48.533,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.485 | Acc: 32.095,48.630,64.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.508 | Acc: 31.829,48.360,64.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.510 | Acc: 31.915,48.422,64.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.510 | Acc: 32.193,48.599,64.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.513 | Acc: 31.876,48.565,64.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.513 | Acc: 31.793,48.704,64.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.520 | Acc: 31.897,48.718,64.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.520 | Acc: 31.915,48.686,64.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.521 | Acc: 31.957,48.734,64.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.522 | Acc: 31.973,48.671,64.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.525 | Acc: 31.941,48.596,64.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.524 | Acc: 31.970,48.627,63.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.528 | Acc: 31.930,48.562,63.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.539 | Acc: 31.822,48.515,63.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.544 | Acc: 31.846,48.444,63.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.543 | Acc: 31.882,48.492,63.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.548 | Acc: 31.896,48.462,63.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.711 | Acc: 26.562,37.500,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 25.074,36.458,53.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 24.771,36.319,52.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 24.257,36.142,52.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.985 | Acc: 24.219,39.844,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.493 | Acc: 32.143,48.363,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.468 | Acc: 31.612,49.181,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.459 | Acc: 31.903,49.411,65.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.486 | Acc: 32.215,49.084,65.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.487 | Acc: 32.580,48.956,65.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.500 | Acc: 32.361,48.935,64.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.496 | Acc: 32.497,48.936,65.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.502 | Acc: 32.298,48.913,64.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.507 | Acc: 32.152,48.826,64.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.503 | Acc: 32.303,48.818,64.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.509 | Acc: 32.286,48.653,64.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.511 | Acc: 32.174,48.710,64.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.506 | Acc: 32.334,48.746,64.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.509 | Acc: 32.293,48.707,64.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.516 | Acc: 32.332,48.609,64.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.516 | Acc: 32.306,48.545,64.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.519 | Acc: 32.205,48.472,64.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.518 | Acc: 32.284,48.634,64.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.517 | Acc: 32.292,48.665,64.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.085 | Acc: 24.219,45.312,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.368 | Acc: 25.223,39.993,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.376 | Acc: 24.143,38.986,55.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.388 | Acc: 23.770,38.691,55.366,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.376 | Acc: 37.500,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.391 | Acc: 32.664,49.330,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.397 | Acc: 32.660,50.057,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.413 | Acc: 32.531,50.269,66.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.426 | Acc: 32.369,50.231,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.447 | Acc: 32.085,49.714,65.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.457 | Acc: 32.173,49.580,65.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.456 | Acc: 32.209,49.590,65.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.461 | Acc: 32.293,49.481,65.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.469 | Acc: 32.200,49.577,65.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.479 | Acc: 32.082,49.514,64.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.473 | Acc: 32.339,49.576,64.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.473 | Acc: 32.414,49.536,64.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.470 | Acc: 32.408,49.578,64.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.471 | Acc: 32.393,49.533,64.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.474 | Acc: 32.317,49.452,64.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.476 | Acc: 32.333,49.443,64.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.483 | Acc: 32.283,49.416,64.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.483 | Acc: 32.269,49.418,64.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.479 | Acc: 32.337,49.483,64.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.203 | Acc: 25.781,42.969,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.208 | Acc: 25.260,42.039,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.213 | Acc: 25.229,41.406,56.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.254 | Acc: 24.552,41.048,55.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.246 | Acc: 32.031,51.562,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.451 | Acc: 33.110,48.810,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.372 | Acc: 32.641,50.095,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.398 | Acc: 32.736,49.898,65.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.408 | Acc: 32.591,50.058,65.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.395 | Acc: 32.666,50.255,66.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.403 | Acc: 32.490,50.181,65.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.405 | Acc: 32.402,50.338,65.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.417 | Acc: 32.531,50.335,65.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.415 | Acc: 32.424,50.306,65.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.421 | Acc: 32.439,50.202,65.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.430 | Acc: 32.381,50.057,65.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.430 | Acc: 32.401,50.019,65.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.431 | Acc: 32.489,50.120,65.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.436 | Acc: 32.487,49.992,65.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.447 | Acc: 32.457,49.857,65.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.449 | Acc: 32.479,49.898,65.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.448 | Acc: 32.547,49.952,65.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.453 | Acc: 32.481,49.803,64.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.452 | Acc: 32.538,49.883,65.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.385 | Acc: 27.344,39.844,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.368 | Acc: 23.735,42.001,55.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.409 | Acc: 23.647,41.044,54.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.392 | Acc: 23.694,41.214,55.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.589 | Acc: 29.688,49.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.426 | Acc: 32.701,49.888,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.416 | Acc: 32.851,50.038,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.418 | Acc: 32.851,50.307,66.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.418 | Acc: 32.784,50.106,66.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.397 | Acc: 32.898,50.650,66.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.401 | Acc: 32.832,50.374,66.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.390 | Acc: 32.957,50.598,66.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.391 | Acc: 32.924,50.466,66.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.390 | Acc: 32.929,50.423,66.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.403 | Acc: 32.941,50.443,65.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.408 | Acc: 32.890,50.527,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.418 | Acc: 32.838,50.350,65.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.416 | Acc: 32.786,50.329,65.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.418 | Acc: 32.801,50.250,65.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.423 | Acc: 32.784,50.197,65.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.426 | Acc: 32.754,50.083,65.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.425 | Acc: 32.783,50.121,65.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.426 | Acc: 32.717,50.106,65.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.427 | Acc: 32.747,50.158,65.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.339 | Acc: 26.562,46.875,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.485 | Acc: 22.917,39.137,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.489 | Acc: 22.618,39.101,54.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.477 | Acc: 22.439,39.203,54.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.394 | Acc: 39.844,47.656,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.229 | Acc: 34.896,50.632,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.286 | Acc: 33.727,50.534,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.310 | Acc: 33.837,50.884,67.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.302 | Acc: 33.825,50.984,67.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.317 | Acc: 33.485,50.673,67.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.324 | Acc: 33.361,50.633,67.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.333 | Acc: 33.311,50.510,66.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.339 | Acc: 33.366,50.417,66.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.342 | Acc: 33.166,50.388,66.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.358 | Acc: 33.139,50.276,66.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.360 | Acc: 33.088,50.354,66.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.362 | Acc: 33.172,50.415,66.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.368 | Acc: 33.070,50.476,66.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.373 | Acc: 32.968,50.384,66.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.373 | Acc: 33.041,50.439,66.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.382 | Acc: 33.041,50.375,66.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.390 | Acc: 33.005,50.318,66.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.389 | Acc: 33.014,50.286,66.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.394 | Acc: 33.020,50.238,65.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.130 | Acc: 29.688,45.312,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.191 | Acc: 25.856,44.308,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.170 | Acc: 26.429,43.750,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.195 | Acc: 26.191,43.161,55.584,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.250 | Acc: 38.281,51.562,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.373 | Acc: 33.482,50.670,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.341 | Acc: 33.441,51.315,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.321 | Acc: 33.837,51.255,66.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.313 | Acc: 34.057,51.418,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.310 | Acc: 33.950,51.276,67.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.310 | Acc: 33.723,51.343,67.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.335 | Acc: 33.500,50.837,66.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.334 | Acc: 33.652,50.932,66.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.337 | Acc: 33.529,51.109,66.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.343 | Acc: 33.535,51.096,66.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.340 | Acc: 33.498,51.092,66.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.346 | Acc: 33.597,51.015,66.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.352 | Acc: 33.588,50.979,66.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.355 | Acc: 33.713,50.948,66.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.359 | Acc: 33.711,50.958,66.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.366 | Acc: 33.664,50.891,66.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.371 | Acc: 33.614,50.880,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.376 | Acc: 33.527,50.766,66.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.378 | Acc: 33.542,50.716,66.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.315 | Acc: 25.000,43.750,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.231 | Acc: 29.278,42.783,56.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.238 | Acc: 28.506,42.607,56.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.240 | Acc: 28.304,42.149,56.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.230 | Acc: 38.281,54.688,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.382 | Acc: 31.845,50.781,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.344 | Acc: 32.851,51.048,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.334 | Acc: 33.248,50.832,67.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.335 | Acc: 33.266,50.791,67.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.333 | Acc: 33.594,51.153,66.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.347 | Acc: 33.497,50.891,66.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.344 | Acc: 33.549,51.031,66.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.344 | Acc: 33.472,51.155,66.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.334 | Acc: 33.520,51.433,66.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.338 | Acc: 33.372,51.337,66.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.336 | Acc: 33.438,51.375,66.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.342 | Acc: 33.312,51.277,66.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.339 | Acc: 33.327,51.206,66.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.344 | Acc: 33.277,51.126,66.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.342 | Acc: 33.256,51.106,66.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.345 | Acc: 33.294,51.205,66.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.349 | Acc: 33.239,51.141,66.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.349 | Acc: 33.260,51.153,66.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.352 | Acc: 33.360,51.191,66.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.473 | Acc: 25.000,39.844,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.387 | Acc: 25.670,40.402,54.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 26.029,39.615,54.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.410 | Acc: 25.525,39.652,54.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.353 | Acc: 32.031,45.312,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.313 | Acc: 33.482,50.186,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.259 | Acc: 34.470,51.696,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.272 | Acc: 34.631,51.370,67.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.284 | Acc: 34.790,51.640,67.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.284 | Acc: 34.623,51.648,67.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.300 | Acc: 34.440,51.466,67.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.299 | Acc: 34.281,51.707,67.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.301 | Acc: 34.132,51.732,67.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.305 | Acc: 33.969,51.575,67.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.306 | Acc: 33.808,51.597,67.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.296 | Acc: 33.788,51.799,67.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.305 | Acc: 33.685,51.569,67.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.302 | Acc: 33.713,51.601,67.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.308 | Acc: 33.713,51.607,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.308 | Acc: 33.773,51.666,67.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.312 | Acc: 33.652,51.614,67.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.316 | Acc: 33.596,51.627,67.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.320 | Acc: 33.570,51.582,67.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.330 | Acc: 33.467,51.403,66.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.184 | Acc: 25.781,31.250,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.767 | Acc: 22.507,37.016,49.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.779 | Acc: 21.837,36.833,49.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.782 | Acc: 21.926,37.001,49.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.011 | Acc: 34.375,52.344,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.255 | Acc: 34.412,52.381,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.255 | Acc: 34.985,52.744,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.252 | Acc: 34.682,52.946,68.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.251 | Acc: 34.462,52.739,68.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.268 | Acc: 34.282,52.545,67.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.289 | Acc: 34.026,52.221,67.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.282 | Acc: 34.164,52.311,67.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.292 | Acc: 34.030,52.125,67.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.293 | Acc: 34.107,52.145,67.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.298 | Acc: 34.002,51.959,67.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.299 | Acc: 34.057,52.054,67.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.301 | Acc: 33.876,52.052,67.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.298 | Acc: 33.866,52.110,67.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.299 | Acc: 33.939,52.063,67.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.305 | Acc: 33.833,51.996,67.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.306 | Acc: 33.813,51.993,67.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.308 | Acc: 33.807,51.952,66.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.316 | Acc: 33.758,51.822,66.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.318 | Acc: 33.762,51.735,66.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.287 | Acc: 32.031,39.844,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.569 | Acc: 24.293,38.988,53.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 23.838,39.196,52.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 23.399,39.037,52.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 2.980 | Acc: 38.281,59.375,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.213 | Acc: 33.073,52.009,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.240 | Acc: 32.946,51.467,68.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.239 | Acc: 33.491,51.767,68.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.222 | Acc: 33.931,52.537,68.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.225 | Acc: 33.973,52.731,68.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.214 | Acc: 34.259,52.905,68.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.218 | Acc: 34.187,52.975,68.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.234 | Acc: 33.890,52.688,68.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.241 | Acc: 33.784,52.508,68.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.250 | Acc: 33.730,52.472,67.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.260 | Acc: 33.696,52.347,67.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.268 | Acc: 33.591,52.221,67.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.267 | Acc: 33.654,52.272,67.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.271 | Acc: 33.616,52.196,67.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.269 | Acc: 33.653,52.230,67.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.268 | Acc: 33.718,52.332,67.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.271 | Acc: 33.766,52.321,67.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.278 | Acc: 33.756,52.255,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.281 | Acc: 33.782,52.237,67.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.231 | Acc: 28.125,38.281,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.077 | Acc: 29.018,42.671,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.150 | Acc: 27.992,42.569,57.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.155 | Acc: 27.971,42.982,56.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.396 | Acc: 32.031,51.562,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.196 | Acc: 34.301,53.571,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.174 | Acc: 34.813,53.068,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.196 | Acc: 34.388,52.638,69.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.227 | Acc: 34.163,52.479,68.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.243 | Acc: 34.027,52.460,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.248 | Acc: 33.955,52.247,68.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.254 | Acc: 33.887,52.183,68.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.247 | Acc: 33.943,52.290,68.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.247 | Acc: 34.043,52.279,68.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.249 | Acc: 34.014,52.274,68.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.247 | Acc: 34.135,52.471,68.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.253 | Acc: 34.067,52.392,68.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.263 | Acc: 34.070,52.350,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.262 | Acc: 34.166,52.430,67.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.269 | Acc: 34.108,52.349,67.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.273 | Acc: 34.037,52.237,67.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.272 | Acc: 34.006,52.197,67.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.272 | Acc: 33.959,52.082,67.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.275 | Acc: 33.938,52.112,67.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.131 | Acc: 26.562,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.019 | Acc: 27.009,47.061,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.028 | Acc: 27.058,47.066,58.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.051 | Acc: 26.767,46.209,57.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.237 | Acc: 34.375,49.219,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.127 | Acc: 35.565,53.385,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.129 | Acc: 34.851,53.430,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.148 | Acc: 34.606,53.471,69.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.173 | Acc: 34.288,53.038,69.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.188 | Acc: 34.197,53.048,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.197 | Acc: 34.381,53.067,68.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.203 | Acc: 34.558,52.948,68.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.206 | Acc: 34.763,53.052,68.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.220 | Acc: 34.630,52.905,68.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.227 | Acc: 34.379,52.616,68.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.236 | Acc: 34.258,52.581,68.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.237 | Acc: 34.249,52.532,68.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.251 | Acc: 34.151,52.404,67.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.248 | Acc: 34.133,52.505,68.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.247 | Acc: 34.152,52.564,68.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.245 | Acc: 34.063,52.546,68.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.249 | Acc: 34.089,52.470,67.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.250 | Acc: 34.102,52.474,67.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.249 | Acc: 34.115,52.510,67.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.173 | Acc: 28.125,40.625,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.089 | Acc: 25.595,45.275,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.113 | Acc: 25.724,44.569,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.135 | Acc: 25.538,43.852,57.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.148 | Acc: 31.250,48.438,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.209 | Acc: 34.040,53.460,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.224 | Acc: 34.280,53.373,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.211 | Acc: 34.196,53.035,68.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.235 | Acc: 33.777,52.334,68.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.238 | Acc: 33.702,52.398,68.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.224 | Acc: 33.691,52.725,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.222 | Acc: 33.887,53.064,68.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.228 | Acc: 34.040,52.965,68.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.230 | Acc: 34.233,53.004,68.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.235 | Acc: 34.177,52.845,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.229 | Acc: 34.241,52.977,68.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.218 | Acc: 34.450,53.177,68.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.227 | Acc: 34.261,53.032,68.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.230 | Acc: 34.261,53.025,68.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.226 | Acc: 34.333,53.138,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.223 | Acc: 34.302,53.144,68.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.220 | Acc: 34.313,53.196,68.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.223 | Acc: 34.343,53.173,68.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.229 | Acc: 34.285,53.072,68.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.973 | Acc: 29.688,46.094,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.100 | Acc: 26.674,43.601,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.118 | Acc: 26.848,42.550,56.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.110 | Acc: 26.947,42.495,56.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.101 | Acc: 35.156,54.688,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.056 | Acc: 36.570,54.725,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.086 | Acc: 34.966,54.040,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.129 | Acc: 34.862,53.804,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.135 | Acc: 34.645,53.405,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.143 | Acc: 34.661,53.342,70.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.158 | Acc: 34.588,53.170,70.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.167 | Acc: 34.464,53.158,69.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.171 | Acc: 34.676,53.193,69.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.173 | Acc: 34.699,53.354,69.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.169 | Acc: 34.756,53.409,69.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.186 | Acc: 34.598,53.249,69.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.195 | Acc: 34.524,53.196,69.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.201 | Acc: 34.459,53.191,68.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.201 | Acc: 34.533,53.206,68.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.208 | Acc: 34.458,53.185,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.211 | Acc: 34.480,53.132,68.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.217 | Acc: 34.441,53.022,68.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.220 | Acc: 34.446,53.010,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.222 | Acc: 34.426,52.992,68.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.086 | Acc: 21.875,46.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.358 | Acc: 22.693,43.341,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.358 | Acc: 23.037,41.921,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.343 | Acc: 22.605,42.111,55.213,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.041 | Acc: 41.406,55.469,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.121 | Acc: 34.338,54.762,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.150 | Acc: 34.223,53.773,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.153 | Acc: 34.426,54.047,69.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.139 | Acc: 34.934,54.234,69.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.125 | Acc: 34.824,54.216,70.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.146 | Acc: 34.749,54.068,69.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.156 | Acc: 34.613,53.696,69.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.163 | Acc: 34.778,53.586,69.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.170 | Acc: 34.858,53.449,69.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.169 | Acc: 34.849,53.584,69.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.169 | Acc: 34.994,53.553,69.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.165 | Acc: 35.095,53.715,69.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.172 | Acc: 35.051,53.685,69.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.182 | Acc: 34.887,53.545,69.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.188 | Acc: 34.801,53.444,69.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.191 | Acc: 34.708,53.412,68.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.196 | Acc: 34.726,53.320,68.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.201 | Acc: 34.659,53.270,68.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.201 | Acc: 34.701,53.340,68.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.675 | Acc: 28.906,46.094,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.912 | Acc: 28.609,45.126,59.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.920 | Acc: 28.716,44.474,59.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.943 | Acc: 28.266,44.045,59.068,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 2.959 | Acc: 39.062,56.250,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.115 | Acc: 35.938,54.799,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.101 | Acc: 35.861,54.745,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.120 | Acc: 35.220,54.278,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.115 | Acc: 35.446,54.350,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.123 | Acc: 35.388,54.316,70.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.116 | Acc: 35.292,54.468,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.118 | Acc: 35.322,54.338,70.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.122 | Acc: 35.278,54.299,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.120 | Acc: 35.359,54.390,70.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.123 | Acc: 35.238,54.147,70.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.127 | Acc: 35.365,54.058,69.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.132 | Acc: 35.383,54.110,69.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.140 | Acc: 35.336,54.062,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.155 | Acc: 35.165,53.820,69.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.162 | Acc: 35.104,53.636,69.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.167 | Acc: 35.052,53.563,69.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.176 | Acc: 34.939,53.485,69.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.176 | Acc: 34.948,53.515,69.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.181 | Acc: 34.951,53.416,68.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.874 | Acc: 28.906,44.531,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.980 | Acc: 29.650,46.354,58.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.970 | Acc: 30.050,46.037,58.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.993 | Acc: 29.739,45.607,57.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 2.669 | Acc: 46.875,62.500,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.003 | Acc: 37.314,56.436,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.108 | Acc: 35.480,54.421,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.096 | Acc: 35.630,54.649,70.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.090 | Acc: 35.918,54.649,70.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.102 | Acc: 35.814,54.587,70.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.112 | Acc: 35.595,54.378,69.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.123 | Acc: 35.395,54.322,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.126 | Acc: 35.282,54.396,69.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.123 | Acc: 35.234,54.588,69.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.134 | Acc: 34.989,54.307,69.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.138 | Acc: 35.040,54.178,69.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.145 | Acc: 34.839,54.091,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.152 | Acc: 34.725,53.909,69.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.155 | Acc: 34.670,53.926,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.153 | Acc: 34.744,53.945,69.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.154 | Acc: 34.691,53.967,69.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.152 | Acc: 34.771,53.964,69.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.158 | Acc: 34.717,53.818,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.163 | Acc: 34.674,53.730,69.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.115 | Acc: 28.125,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.183 | Acc: 25.372,43.824,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.180 | Acc: 25.133,43.178,56.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.217 | Acc: 24.565,42.687,56.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.263 | Acc: 35.156,47.656,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.094 | Acc: 35.751,54.167,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.056 | Acc: 36.052,55.221,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.047 | Acc: 35.643,55.238,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.062 | Acc: 35.224,54.832,71.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.096 | Acc: 34.878,54.247,71.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.110 | Acc: 35.021,54.068,70.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.116 | Acc: 34.924,54.194,70.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.116 | Acc: 34.894,54.227,70.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.115 | Acc: 35.156,54.342,70.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.115 | Acc: 35.106,54.415,70.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.119 | Acc: 35.227,54.465,70.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.123 | Acc: 35.179,54.487,70.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.129 | Acc: 35.258,54.421,69.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.138 | Acc: 35.290,54.376,69.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.138 | Acc: 35.322,54.397,69.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.133 | Acc: 35.502,54.403,69.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.137 | Acc: 35.468,54.312,69.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.142 | Acc: 35.396,54.211,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.146 | Acc: 35.378,54.175,69.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.998 | Acc: 25.781,43.750,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.255 | Acc: 27.567,42.969,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.271 | Acc: 27.515,42.340,56.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.332 | Acc: 26.742,41.688,55.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 3.321 | Acc: 28.906,51.562,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.046 | Acc: 36.161,56.176,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.116 | Acc: 35.709,54.535,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.124 | Acc: 35.310,54.419,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.119 | Acc: 35.600,54.726,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.125 | Acc: 35.179,54.425,70.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.127 | Acc: 35.221,54.203,70.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.136 | Acc: 35.095,53.962,69.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.128 | Acc: 35.001,54.139,70.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.135 | Acc: 34.789,53.997,69.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.131 | Acc: 34.876,54.062,69.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.137 | Acc: 34.997,53.988,69.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.133 | Acc: 35.027,54.101,69.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.131 | Acc: 35.174,54.146,69.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.136 | Acc: 35.051,54.093,69.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.139 | Acc: 35.045,54.101,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.140 | Acc: 35.069,54.077,69.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.144 | Acc: 35.113,54.053,69.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.144 | Acc: 35.083,54.021,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.145 | Acc: 35.105,53.996,69.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.888 | Acc: 28.906,42.188,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.962 | Acc: 32.515,45.015,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.004 | Acc: 31.631,44.169,56.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.026 | Acc: 31.160,43.609,56.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 2.865 | Acc: 35.156,57.812,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.076 | Acc: 34.859,54.353,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.042 | Acc: 35.842,54.859,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.061 | Acc: 35.515,54.918,71.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.068 | Acc: 36.015,55.295,70.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.071 | Acc: 36.030,54.912,70.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.075 | Acc: 36.047,54.901,70.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.076 | Acc: 36.087,54.904,70.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.090 | Acc: 35.957,54.809,70.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.092 | Acc: 35.976,54.765,70.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.096 | Acc: 35.941,54.750,70.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.096 | Acc: 35.743,54.677,70.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.101 | Acc: 35.685,54.642,70.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.108 | Acc: 35.734,54.559,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.108 | Acc: 35.837,54.599,69.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.116 | Acc: 35.712,54.519,69.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.123 | Acc: 35.626,54.395,69.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.124 | Acc: 35.527,54.401,69.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.122 | Acc: 35.624,54.434,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.122 | Acc: 35.628,54.405,69.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.852 | Acc: 28.125,48.438,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.114 | Acc: 25.893,46.838,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.155 | Acc: 24.924,45.122,58.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.168 | Acc: 24.616,44.647,57.736,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 2.818 | Acc: 37.500,55.469,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.015 | Acc: 35.863,55.878,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.997 | Acc: 36.357,55.659,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.006 | Acc: 35.989,55.507,71.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.031 | Acc: 35.503,55.083,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.048 | Acc: 35.326,54.873,70.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.061 | Acc: 35.156,54.662,70.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.074 | Acc: 35.245,54.604,70.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.079 | Acc: 35.185,54.527,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.089 | Acc: 35.035,54.549,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.100 | Acc: 34.985,54.377,70.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.102 | Acc: 35.022,54.429,70.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.109 | Acc: 35.030,54.506,70.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.111 | Acc: 35.093,54.532,69.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.114 | Acc: 35.142,54.554,70.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.120 | Acc: 35.115,54.438,69.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.125 | Acc: 35.042,54.410,69.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.130 | Acc: 35.037,54.410,69.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.134 | Acc: 35.044,54.350,69.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.138 | Acc: 34.970,54.222,69.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.407 | Acc: 23.438,39.844,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.826 | Acc: 22.582,39.249,51.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.809 | Acc: 21.799,39.043,51.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.836 | Acc: 21.247,38.922,51.063,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 3.084 | Acc: 31.250,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.938 | Acc: 37.277,57.143,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.987 | Acc: 35.880,56.136,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.991 | Acc: 36.130,56.019,72.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.027 | Acc: 35.793,55.835,71.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.029 | Acc: 36.015,55.732,71.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.024 | Acc: 36.215,55.843,71.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.028 | Acc: 35.938,55.674,71.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.030 | Acc: 36.001,55.600,71.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.043 | Acc: 35.696,55.369,71.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.056 | Acc: 35.432,55.236,70.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.060 | Acc: 35.481,55.175,70.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.062 | Acc: 35.604,55.261,70.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.071 | Acc: 35.578,55.241,70.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.077 | Acc: 35.682,55.127,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.079 | Acc: 35.732,55.085,70.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.088 | Acc: 35.641,54.948,70.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.092 | Acc: 35.699,54.930,70.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.091 | Acc: 35.663,54.845,70.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.096 | Acc: 35.595,54.774,70.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.840 | Acc: 35.156,46.094,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.974 | Acc: 31.250,45.015,57.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.967 | Acc: 31.860,45.198,57.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.996 | Acc: 31.352,45.005,57.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 2.766 | Acc: 40.625,59.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.065 | Acc: 35.417,54.874,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.052 | Acc: 35.480,54.916,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.039 | Acc: 35.950,55.558,71.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.040 | Acc: 36.044,55.372,71.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.064 | Acc: 35.597,54.695,71.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.055 | Acc: 35.737,54.959,71.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.060 | Acc: 35.727,54.798,70.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.057 | Acc: 35.850,54.814,70.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.056 | Acc: 35.963,54.864,70.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.058 | Acc: 35.844,54.890,70.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.062 | Acc: 35.853,54.868,70.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.064 | Acc: 35.818,54.837,70.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.061 | Acc: 36.009,54.936,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.059 | Acc: 35.965,54.999,70.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.061 | Acc: 35.917,55.030,70.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.066 | Acc: 35.886,54.999,70.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.067 | Acc: 35.825,54.983,70.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.066 | Acc: 35.886,55.001,70.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.072 | Acc: 35.814,54.936,70.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.342 | Acc: 26.562,42.188,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.365 | Acc: 24.182,41.964,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.402 | Acc: 24.257,42.550,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.418 | Acc: 23.899,42.226,54.956,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.169 | Acc: 29.688,56.250,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.990 | Acc: 36.012,57.068,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.002 | Acc: 36.471,56.784,71.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.006 | Acc: 36.219,56.109,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.022 | Acc: 35.938,55.758,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.028 | Acc: 35.999,55.693,71.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.032 | Acc: 35.866,55.643,71.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.037 | Acc: 35.932,55.552,71.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.032 | Acc: 36.015,55.585,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.041 | Acc: 35.890,55.382,71.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.041 | Acc: 35.941,55.488,71.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.041 | Acc: 35.923,55.529,71.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.053 | Acc: 35.808,55.342,70.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.056 | Acc: 35.827,55.280,70.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.061 | Acc: 35.776,55.319,70.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.060 | Acc: 35.849,55.391,70.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.061 | Acc: 35.877,55.369,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.066 | Acc: 35.844,55.274,70.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.075 | Acc: 35.782,55.196,70.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.077 | Acc: 35.804,55.239,70.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.780 | Acc: 33.594,50.781,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.984 | Acc: 29.911,45.833,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.019 | Acc: 29.935,44.912,57.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.063 | Acc: 29.457,44.659,57.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 3.053 | Acc: 35.156,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.030 | Acc: 35.714,54.501,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.020 | Acc: 36.109,54.630,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.018 | Acc: 35.976,54.828,71.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.037 | Acc: 36.053,55.025,71.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.036 | Acc: 35.999,55.051,71.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.041 | Acc: 35.724,55.049,71.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.036 | Acc: 35.943,55.286,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.037 | Acc: 36.088,55.270,71.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.035 | Acc: 36.032,55.326,71.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.040 | Acc: 36.050,55.204,71.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.052 | Acc: 35.842,54.974,70.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.055 | Acc: 35.831,54.953,70.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.053 | Acc: 35.914,54.993,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.054 | Acc: 35.982,55.027,70.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.059 | Acc: 36.005,55.033,70.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.057 | Acc: 36.066,55.070,70.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.059 | Acc: 36.009,55.072,70.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.059 | Acc: 36.031,55.127,70.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.060 | Acc: 36.071,55.100,70.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.778 | Acc: 32.031,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.804 | Acc: 32.738,48.624,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.805 | Acc: 32.298,48.590,59.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.817 | Acc: 31.711,48.578,59.285,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 2.776 | Acc: 35.938,58.594,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.895 | Acc: 37.760,57.292,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 37.805,56.860,72.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.959 | Acc: 36.924,56.570,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.967 | Acc: 36.834,56.337,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.967 | Acc: 36.866,56.474,71.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.981 | Acc: 36.674,56.269,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.996 | Acc: 36.292,56.023,71.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.016 | Acc: 35.933,55.760,71.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.026 | Acc: 35.938,55.482,71.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.033 | Acc: 35.988,55.387,71.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.036 | Acc: 36.058,55.458,71.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.043 | Acc: 35.908,55.362,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.043 | Acc: 36.015,55.376,70.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.049 | Acc: 35.993,55.294,70.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.050 | Acc: 36.052,55.274,70.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.052 | Acc: 36.011,55.296,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.057 | Acc: 36.050,55.201,70.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.056 | Acc: 36.072,55.233,70.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.059 | Acc: 35.970,55.225,70.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.036 | Acc: 28.125,46.875,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.095 | Acc: 28.534,45.499,57.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.124 | Acc: 28.601,45.065,56.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.153 | Acc: 28.420,44.723,56.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 2.927 | Acc: 40.625,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.909 | Acc: 36.012,55.766,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.938 | Acc: 36.071,55.793,72.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.928 | Acc: 35.899,56.545,72.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.959 | Acc: 36.044,56.221,72.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.977 | Acc: 36.061,55.933,72.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.991 | Acc: 36.170,55.733,71.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.999 | Acc: 35.932,55.635,71.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.006 | Acc: 35.976,55.624,71.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.017 | Acc: 35.851,55.469,71.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.025 | Acc: 35.809,55.445,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.025 | Acc: 35.930,55.444,71.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.030 | Acc: 35.993,55.316,70.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.033 | Acc: 36.015,55.322,70.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.036 | Acc: 35.993,55.360,70.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.040 | Acc: 35.922,55.396,70.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.039 | Acc: 35.998,55.352,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.039 | Acc: 36.137,55.466,70.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.044 | Acc: 36.206,55.387,70.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.046 | Acc: 36.141,55.301,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.088 | Acc: 27.344,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.058 | Acc: 28.497,47.359,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.052 | Acc: 27.401,46.608,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.067 | Acc: 27.075,46.299,57.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 2.953 | Acc: 32.031,50.000,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 35.863,55.506,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.931 | Acc: 35.747,55.983,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.916 | Acc: 35.938,56.468,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.928 | Acc: 36.487,56.771,72.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.923 | Acc: 36.812,57.178,72.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.939 | Acc: 36.519,57.018,72.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.949 | Acc: 36.270,56.799,72.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.954 | Acc: 36.423,56.924,72.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.970 | Acc: 36.261,56.608,71.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.981 | Acc: 36.116,56.588,71.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.982 | Acc: 36.150,56.497,71.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.982 | Acc: 36.184,56.461,71.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.988 | Acc: 36.117,56.373,71.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.996 | Acc: 36.065,56.253,71.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.003 | Acc: 36.080,56.193,71.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.010 | Acc: 36.006,56.094,71.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.008 | Acc: 36.100,56.099,71.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.014 | Acc: 36.059,56.075,71.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.020 | Acc: 35.987,55.992,71.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.155 | Acc: 18.750,51.562,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.413 | Acc: 21.763,44.940,57.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.434 | Acc: 20.979,44.684,57.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.462 | Acc: 20.645,44.185,57.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 3.197 | Acc: 27.344,50.781,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.989 | Acc: 34.859,55.915,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.984 | Acc: 36.300,56.402,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.976 | Acc: 36.360,56.148,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.996 | Acc: 35.986,55.961,71.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.008 | Acc: 35.667,55.879,71.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.009 | Acc: 36.009,56.237,71.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.004 | Acc: 36.093,56.300,71.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.001 | Acc: 36.185,56.318,71.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.007 | Acc: 36.015,56.190,71.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.003 | Acc: 36.101,56.079,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.998 | Acc: 36.181,56.162,71.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.004 | Acc: 36.265,56.130,71.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.008 | Acc: 36.087,56.014,71.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.012 | Acc: 36.057,55.997,71.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.015 | Acc: 36.111,55.858,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.015 | Acc: 36.113,55.963,71.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.015 | Acc: 36.050,56.000,71.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.020 | Acc: 36.041,55.964,70.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.021 | Acc: 36.061,55.914,70.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 28.125,37.500,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.088 | Acc: 28.460,43.936,58.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.137 | Acc: 27.706,43.426,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.145 | Acc: 27.702,43.430,57.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 2.981 | Acc: 39.062,50.000,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.853 | Acc: 36.979,57.738,73.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.910 | Acc: 36.719,56.517,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.921 | Acc: 37.077,56.058,72.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.930 | Acc: 36.892,56.472,72.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.929 | Acc: 36.796,56.575,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.952 | Acc: 36.635,56.437,72.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.956 | Acc: 36.558,56.521,72.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.964 | Acc: 36.675,56.396,72.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.966 | Acc: 36.667,56.444,72.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.965 | Acc: 36.758,56.425,72.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.972 | Acc: 36.768,56.324,71.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.965 | Acc: 36.660,56.347,71.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.973 | Acc: 36.626,56.241,71.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.976 | Acc: 36.557,56.217,71.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.982 | Acc: 36.560,56.211,71.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.984 | Acc: 36.502,56.296,71.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.988 | Acc: 36.458,56.248,71.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.992 | Acc: 36.505,56.226,71.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.996 | Acc: 36.518,56.213,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.156 | Acc: 29.688,37.500,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.110 | Acc: 29.874,42.374,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.133 | Acc: 29.992,42.530,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.133 | Acc: 29.649,42.841,57.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 2.929 | Acc: 36.719,55.469,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.987 | Acc: 36.496,56.138,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.989 | Acc: 36.547,55.793,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 36.335,56.148,71.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.949 | Acc: 36.728,56.308,72.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.948 | Acc: 36.518,56.366,72.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.951 | Acc: 36.422,56.670,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.964 | Acc: 36.348,56.455,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.967 | Acc: 36.471,56.497,72.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.964 | Acc: 36.335,56.621,72.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.964 | Acc: 36.264,56.596,72.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.956 | Acc: 36.471,56.702,72.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.960 | Acc: 36.339,56.636,72.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.966 | Acc: 36.309,56.579,71.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.967 | Acc: 36.388,56.598,71.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.968 | Acc: 36.433,56.561,71.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.976 | Acc: 36.405,56.520,71.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.979 | Acc: 36.432,56.454,71.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.982 | Acc: 36.487,56.421,71.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.996 | Acc: 36.382,56.205,71.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.914 | Acc: 32.031,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.044 | Acc: 29.241,46.689,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.032 | Acc: 29.230,46.608,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.054 | Acc: 28.727,45.940,57.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 3.043 | Acc: 28.906,51.562,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 36.049,55.692,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.904 | Acc: 36.471,56.498,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.901 | Acc: 36.744,57.018,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.919 | Acc: 36.429,56.713,73.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.937 | Acc: 36.347,56.327,72.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.951 | Acc: 36.318,56.030,72.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.955 | Acc: 36.348,56.056,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.965 | Acc: 36.374,56.119,72.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.967 | Acc: 36.486,56.194,72.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.971 | Acc: 36.423,56.145,72.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.972 | Acc: 36.454,56.201,71.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.971 | Acc: 36.427,56.312,71.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.976 | Acc: 36.318,56.268,71.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.982 | Acc: 36.291,56.144,71.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.985 | Acc: 36.363,56.146,71.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.990 | Acc: 36.390,56.072,71.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.993 | Acc: 36.366,56.135,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.995 | Acc: 36.370,56.120,71.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.997 | Acc: 36.432,56.215,71.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.077 | Acc: 25.000,43.750,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.959 | Acc: 29.129,46.391,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.004 | Acc: 28.525,45.122,58.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.020 | Acc: 28.394,45.172,58.017,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 2.760 | Acc: 38.281,57.031,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.887 | Acc: 37.984,58.519,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.907 | Acc: 36.547,57.489,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.914 | Acc: 36.642,57.185,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.933 | Acc: 36.429,56.713,72.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.936 | Acc: 36.154,56.869,72.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.935 | Acc: 36.209,56.599,72.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.934 | Acc: 36.375,56.549,72.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.944 | Acc: 36.432,56.308,72.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.948 | Acc: 36.477,56.254,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.957 | Acc: 36.361,56.122,72.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.958 | Acc: 36.383,56.211,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.965 | Acc: 36.437,56.244,72.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.970 | Acc: 36.428,56.196,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.965 | Acc: 36.480,56.300,72.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.970 | Acc: 36.451,56.221,71.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.973 | Acc: 36.502,56.240,71.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.972 | Acc: 36.556,56.266,71.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.975 | Acc: 36.576,56.267,71.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.979 | Acc: 36.624,56.246,71.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.084 | Acc: 26.562,40.625,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 21.949,41.927,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 21.799,41.768,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 21.247,41.611,54.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 3.026 | Acc: 40.625,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.850 | Acc: 38.058,58.110,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.869 | Acc: 37.329,57.755,73.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.880 | Acc: 36.988,57.441,73.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.880 | Acc: 37.240,57.002,73.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.906 | Acc: 37.175,56.668,72.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.910 | Acc: 37.248,56.805,72.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.917 | Acc: 37.101,56.776,72.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.920 | Acc: 37.146,56.789,72.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.935 | Acc: 36.913,56.492,72.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.939 | Acc: 36.878,56.549,72.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.949 | Acc: 36.690,56.501,71.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.958 | Acc: 36.803,56.539,71.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.966 | Acc: 36.662,56.480,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.967 | Acc: 36.697,56.503,71.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.973 | Acc: 36.703,56.455,71.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.968 | Acc: 36.801,56.501,71.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.967 | Acc: 36.868,56.578,71.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.969 | Acc: 36.890,56.544,71.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.970 | Acc: 36.922,56.523,71.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.879 | Acc: 32.812,43.750,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.934 | Acc: 29.985,46.987,60.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.957 | Acc: 29.192,46.913,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.973 | Acc: 28.804,46.235,59.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 2.658 | Acc: 41.406,62.500,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.958 | Acc: 35.938,55.246,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.937 | Acc: 36.814,55.945,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.931 | Acc: 37.398,56.365,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.912 | Acc: 37.519,56.780,73.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.909 | Acc: 37.384,56.938,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.920 | Acc: 37.539,56.818,72.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.925 | Acc: 37.472,56.859,72.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.931 | Acc: 37.291,56.876,72.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.945 | Acc: 37.008,56.699,72.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.938 | Acc: 36.894,56.790,72.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.943 | Acc: 37.093,56.840,72.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.941 | Acc: 37.092,56.736,72.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.947 | Acc: 37.054,56.636,72.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.946 | Acc: 37.116,56.659,72.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.953 | Acc: 37.131,56.517,72.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.958 | Acc: 37.081,56.401,71.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.960 | Acc: 37.067,56.353,71.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.962 | Acc: 37.054,56.373,71.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.964 | Acc: 37.080,56.389,71.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.906 | Acc: 29.688,50.781,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.018 | Acc: 27.344,47.173,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.061 | Acc: 26.410,46.665,58.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.096 | Acc: 26.409,46.235,58.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 3.057 | Acc: 35.156,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.863 | Acc: 37.091,58.185,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.841 | Acc: 38.262,58.479,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.826 | Acc: 38.281,58.504,74.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.846 | Acc: 38.175,57.909,73.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.872 | Acc: 37.763,57.495,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.878 | Acc: 37.610,57.716,73.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.885 | Acc: 37.522,57.635,73.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.901 | Acc: 37.384,57.254,73.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.900 | Acc: 37.409,57.342,72.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.912 | Acc: 37.345,57.303,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.911 | Acc: 37.256,57.250,72.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.917 | Acc: 37.092,57.210,72.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.920 | Acc: 37.024,57.199,72.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.927 | Acc: 36.952,57.140,72.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.933 | Acc: 36.952,57.057,72.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.936 | Acc: 36.943,57.026,72.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.938 | Acc: 36.971,57.006,72.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.944 | Acc: 36.998,56.994,72.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.949 | Acc: 36.928,56.964,72.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.588 | Acc: 32.031,49.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.913 | Acc: 29.799,46.689,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.910 | Acc: 29.249,46.151,59.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.915 | Acc: 29.316,45.786,59.375,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 2.951 | Acc: 35.938,57.031,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.922 | Acc: 36.235,57.143,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.895 | Acc: 37.271,57.698,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.911 | Acc: 36.924,57.492,72.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.922 | Acc: 36.806,57.301,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.910 | Acc: 36.974,57.480,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.929 | Acc: 36.577,57.296,72.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.927 | Acc: 36.525,57.358,72.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.938 | Acc: 36.413,57.109,72.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.934 | Acc: 36.537,57.221,72.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.931 | Acc: 36.633,57.156,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.932 | Acc: 36.751,57.166,72.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.934 | Acc: 36.654,57.012,72.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.934 | Acc: 36.608,56.974,72.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.936 | Acc: 36.552,56.948,72.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.941 | Acc: 36.542,56.896,72.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.942 | Acc: 36.548,56.902,72.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.947 | Acc: 36.538,56.846,72.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.949 | Acc: 36.580,56.882,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.950 | Acc: 36.643,56.843,72.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.135 | Acc: 35.938,41.406,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.235 | Acc: 30.878,40.737,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 30.431,40.206,55.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.325 | Acc: 30.085,39.831,54.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 2.943 | Acc: 36.719,60.938,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.912 | Acc: 37.463,57.440,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.902 | Acc: 36.300,57.241,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.906 | Acc: 36.770,56.929,73.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.904 | Acc: 36.806,57.224,73.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.891 | Acc: 37.237,57.666,73.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.900 | Acc: 37.293,57.432,73.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.901 | Acc: 37.478,57.502,73.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.905 | Acc: 37.393,57.516,72.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.901 | Acc: 37.418,57.454,72.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.911 | Acc: 37.212,57.261,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.915 | Acc: 37.260,57.222,72.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.925 | Acc: 37.247,57.151,72.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.934 | Acc: 37.296,57.070,72.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.936 | Acc: 37.197,57.079,72.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.933 | Acc: 37.196,57.158,72.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.931 | Acc: 37.162,57.231,72.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.932 | Acc: 37.136,57.215,72.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.932 | Acc: 37.132,57.161,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.936 | Acc: 37.090,57.158,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.773 | Acc: 35.156,46.094,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.871 | Acc: 31.808,46.875,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.901 | Acc: 31.212,45.732,58.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.911 | Acc: 30.482,45.927,58.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 2.752 | Acc: 35.156,58.594,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.865 | Acc: 37.649,57.217,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.879 | Acc: 37.329,57.450,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.887 | Acc: 36.949,57.428,73.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.899 | Acc: 36.777,57.311,73.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.908 | Acc: 36.626,56.915,73.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.893 | Acc: 36.880,57.231,73.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.889 | Acc: 37.051,57.353,73.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.883 | Acc: 37.097,57.643,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.892 | Acc: 37.185,57.571,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.893 | Acc: 37.096,57.591,72.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.899 | Acc: 37.139,57.498,72.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.905 | Acc: 37.211,57.472,72.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.906 | Acc: 37.210,57.393,72.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.907 | Acc: 37.208,57.351,72.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.917 | Acc: 37.103,57.184,72.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.917 | Acc: 37.057,57.226,72.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.921 | Acc: 37.053,57.194,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.922 | Acc: 37.078,57.146,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.929 | Acc: 37.096,57.066,72.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.566 | Acc: 34.375,53.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.850 | Acc: 30.283,48.177,61.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.907 | Acc: 29.173,46.570,60.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.913 | Acc: 28.509,46.516,60.310,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 2.936 | Acc: 32.031,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.752 | Acc: 37.760,59.115,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.781 | Acc: 38.415,59.051,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.797 | Acc: 38.358,59.029,74.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.829 | Acc: 38.301,58.652,74.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.838 | Acc: 38.250,58.439,73.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.850 | Acc: 38.107,58.490,73.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.857 | Acc: 37.827,58.261,73.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.864 | Acc: 37.801,58.113,73.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.875 | Acc: 37.690,57.929,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.884 | Acc: 37.597,57.855,73.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 37.595,57.763,73.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.898 | Acc: 37.435,57.637,73.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.908 | Acc: 37.392,57.534,72.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.911 | Acc: 37.389,57.473,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.916 | Acc: 37.259,57.410,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.917 | Acc: 37.269,57.474,72.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.919 | Acc: 37.218,57.483,72.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.920 | Acc: 37.193,57.393,72.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.923 | Acc: 37.207,57.331,72.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.828 | Acc: 32.812,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.938 | Acc: 29.539,46.615,59.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.964 | Acc: 29.592,45.713,58.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.985 | Acc: 29.201,45.069,58.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 2.720 | Acc: 32.812,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.803 | Acc: 39.174,58.482,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.832 | Acc: 38.300,58.803,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.822 | Acc: 38.128,58.799,74.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.827 | Acc: 37.973,58.729,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.833 | Acc: 37.902,58.470,74.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.836 | Acc: 37.791,58.071,74.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.841 | Acc: 37.760,57.968,73.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.839 | Acc: 37.937,57.977,74.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.851 | Acc: 37.781,57.769,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.856 | Acc: 37.784,57.661,73.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.861 | Acc: 37.712,57.643,73.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.869 | Acc: 37.468,57.485,73.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.875 | Acc: 37.389,57.441,73.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.876 | Acc: 37.428,57.473,73.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.882 | Acc: 37.495,57.410,73.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.884 | Acc: 37.495,57.462,73.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.889 | Acc: 37.532,57.489,72.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.899 | Acc: 37.400,57.442,72.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.903 | Acc: 37.330,57.378,72.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.109 | Acc: 27.344,45.312,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.183 | Acc: 29.874,42.039,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.210 | Acc: 28.544,42.092,55.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.239 | Acc: 28.279,41.803,55.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 3.200 | Acc: 29.688,51.562,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.836 | Acc: 36.942,57.626,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.864 | Acc: 37.309,57.431,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.844 | Acc: 37.410,58.222,73.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.844 | Acc: 37.442,58.131,73.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.845 | Acc: 37.531,58.331,73.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.863 | Acc: 37.248,57.922,73.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.858 | Acc: 37.262,58.051,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.861 | Acc: 37.257,57.919,73.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.868 | Acc: 37.306,57.769,73.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.873 | Acc: 37.380,57.708,73.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.876 | Acc: 37.408,57.689,73.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.882 | Acc: 37.250,57.693,73.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.881 | Acc: 37.305,57.756,73.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.889 | Acc: 37.266,57.637,72.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 37.256,57.532,72.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.898 | Acc: 37.254,57.503,72.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.895 | Acc: 37.415,57.618,72.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.897 | Acc: 37.413,57.551,72.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.903 | Acc: 37.377,57.489,72.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.920 | Acc: 32.812,47.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.974 | Acc: 29.911,47.098,58.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.038 | Acc: 28.773,45.789,57.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.017 | Acc: 28.868,45.428,57.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 2.855 | Acc: 35.938,57.812,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.800 | Acc: 38.244,58.966,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.822 | Acc: 38.205,57.908,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.842 | Acc: 37.743,57.710,74.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.856 | Acc: 37.731,57.523,74.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.853 | Acc: 37.430,57.735,74.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.861 | Acc: 37.442,57.593,74.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 37.483,57.563,74.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.870 | Acc: 37.388,57.614,73.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 37.483,57.588,73.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.874 | Acc: 37.422,57.478,73.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.875 | Acc: 37.288,57.473,73.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.873 | Acc: 37.348,57.654,73.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.874 | Acc: 37.467,57.597,73.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.879 | Acc: 37.464,57.587,73.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.880 | Acc: 37.407,57.587,73.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.883 | Acc: 37.468,57.564,73.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.886 | Acc: 37.461,57.618,73.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.889 | Acc: 37.455,57.544,73.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.892 | Acc: 37.459,57.511,73.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.525 | Acc: 28.125,40.625,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.668 | Acc: 24.070,39.137,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.708 | Acc: 23.914,38.415,53.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.766 | Acc: 23.706,37.743,52.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.784 | Acc: 35.938,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.811 | Acc: 38.802,58.185,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.831 | Acc: 38.434,58.289,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.848 | Acc: 37.820,57.953,73.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.827 | Acc: 38.002,58.189,74.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.832 | Acc: 37.515,58.331,74.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.827 | Acc: 37.810,58.329,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.834 | Acc: 37.810,58.311,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.848 | Acc: 37.699,58.230,74.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.858 | Acc: 37.724,58.046,73.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.861 | Acc: 37.687,57.980,73.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.867 | Acc: 37.546,57.855,73.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.877 | Acc: 37.474,57.644,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.884 | Acc: 37.506,57.615,73.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.890 | Acc: 37.475,57.482,73.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 37.531,57.475,73.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.888 | Acc: 37.585,57.477,73.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 37.589,57.574,73.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.890 | Acc: 37.509,57.557,73.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.890 | Acc: 37.482,57.538,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.118 | Acc: 22.656,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.031 | Acc: 26.042,47.359,58.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.080 | Acc: 26.086,46.951,58.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.105 | Acc: 25.640,46.606,57.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 2.631 | Acc: 35.938,61.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.791 | Acc: 38.430,58.854,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.823 | Acc: 37.729,58.194,73.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.824 | Acc: 37.961,58.427,73.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.837 | Acc: 38.050,58.073,73.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.850 | Acc: 37.763,58.068,73.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.844 | Acc: 37.991,58.277,73.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.848 | Acc: 37.949,58.328,73.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.846 | Acc: 37.878,58.201,73.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 37.716,58.128,73.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.853 | Acc: 37.710,58.135,73.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.858 | Acc: 37.610,58.117,73.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.866 | Acc: 37.510,57.932,73.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.863 | Acc: 37.530,58.031,73.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.861 | Acc: 37.747,58.063,73.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 37.749,58.002,73.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.873 | Acc: 37.736,57.912,73.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.876 | Acc: 37.777,57.890,72.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.879 | Acc: 37.799,57.856,72.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.880 | Acc: 37.816,57.878,72.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.890 | Acc: 32.031,45.312,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.954 | Acc: 28.274,47.135,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.956 | Acc: 27.725,46.894,60.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.954 | Acc: 27.613,47.016,60.067,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 3.066 | Acc: 43.750,53.906,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.821 | Acc: 38.095,58.668,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.807 | Acc: 37.843,59.375,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.822 | Acc: 37.859,59.401,73.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.849 | Acc: 37.326,58.565,74.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.867 | Acc: 37.106,58.192,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.869 | Acc: 37.274,57.903,73.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.861 | Acc: 37.533,58.018,73.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.864 | Acc: 37.641,58.016,73.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.863 | Acc: 37.798,57.968,73.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.867 | Acc: 37.776,57.785,73.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.870 | Acc: 37.818,57.710,73.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 37.840,57.832,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.875 | Acc: 37.796,57.774,73.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.871 | Acc: 37.834,57.810,73.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.871 | Acc: 37.856,57.833,73.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.873 | Acc: 37.943,57.812,73.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.879 | Acc: 37.846,57.712,72.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.878 | Acc: 37.846,57.791,72.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.880 | Acc: 37.738,57.761,72.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.380 | Acc: 25.781,42.188,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.708 | Acc: 20.126,42.001,55.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.769 | Acc: 19.950,41.482,54.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.797 | Acc: 19.570,41.189,54.457,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 2.772 | Acc: 38.281,58.594,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.761 | Acc: 38.244,59.040,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.812 | Acc: 37.767,57.965,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.788 | Acc: 38.115,58.607,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.778 | Acc: 38.117,58.787,74.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.787 | Acc: 38.041,58.864,74.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.809 | Acc: 37.842,58.478,74.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.815 | Acc: 37.783,58.477,74.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.816 | Acc: 37.762,58.550,74.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.820 | Acc: 37.759,58.348,74.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.820 | Acc: 37.780,58.349,74.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.822 | Acc: 37.730,58.410,74.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.826 | Acc: 37.733,58.253,74.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.830 | Acc: 37.736,58.238,73.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 37.753,58.113,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.843 | Acc: 37.726,58.028,73.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.851 | Acc: 37.763,57.917,73.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.860 | Acc: 37.605,57.780,73.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.867 | Acc: 37.532,57.704,73.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.868 | Acc: 37.555,57.669,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.682 | Acc: 33.594,48.438,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.884 | Acc: 32.180,46.763,59.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.898 | Acc: 31.098,46.723,59.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.938 | Acc: 30.674,46.504,59.119,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 2.855 | Acc: 39.062,60.938,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.808 | Acc: 37.165,59.152,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.791 | Acc: 37.329,59.204,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.781 | Acc: 37.346,59.004,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.798 | Acc: 37.471,58.806,74.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.805 | Acc: 37.554,58.779,74.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.810 | Acc: 37.545,58.568,74.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.816 | Acc: 37.533,58.538,74.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.818 | Acc: 37.364,58.351,74.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.821 | Acc: 37.625,58.287,74.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.828 | Acc: 37.414,58.131,74.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.837 | Acc: 37.475,58.003,73.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.839 | Acc: 37.468,58.036,73.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.846 | Acc: 37.524,57.878,73.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.848 | Acc: 37.558,57.932,73.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.851 | Acc: 37.547,57.870,73.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.855 | Acc: 37.602,57.851,73.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.864 | Acc: 37.610,57.774,73.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.871 | Acc: 37.636,57.696,73.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.873 | Acc: 37.592,57.718,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.153 | Acc: 35.938,44.531,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.150 | Acc: 28.534,44.345,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.177 | Acc: 27.744,44.150,56.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.182 | Acc: 27.664,44.032,56.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.785 | Acc: 36.719,60.156,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.686 | Acc: 39.323,62.016,76.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.674 | Acc: 39.539,60.766,76.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.715 | Acc: 38.947,59.849,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.736 | Acc: 38.638,59.510,75.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.775 | Acc: 37.964,58.965,75.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.781 | Acc: 38.133,58.800,74.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.794 | Acc: 37.927,58.705,74.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 38.043,58.642,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 38.182,58.663,74.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 38.254,58.691,74.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 38.147,58.611,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 38.220,58.568,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.819 | Acc: 38.221,58.354,74.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.825 | Acc: 38.181,58.324,73.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.829 | Acc: 38.107,58.202,73.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.836 | Acc: 38.087,58.131,73.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.843 | Acc: 38.098,58.007,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.843 | Acc: 38.186,58.046,73.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.844 | Acc: 38.195,58.054,73.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.851 | Acc: 35.156,46.094,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.879 | Acc: 32.403,48.438,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.909 | Acc: 31.002,48.114,58.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.949 | Acc: 30.968,47.951,57.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.868 | Acc: 37.500,58.594,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.780 | Acc: 38.170,57.664,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.798 | Acc: 37.938,57.546,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.802 | Acc: 38.243,58.350,75.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.804 | Acc: 38.214,58.410,74.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.797 | Acc: 38.165,58.663,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.787 | Acc: 38.204,58.710,74.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.785 | Acc: 38.237,58.610,74.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.796 | Acc: 38.082,58.438,74.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.801 | Acc: 38.147,58.253,74.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.800 | Acc: 38.176,58.388,74.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.814 | Acc: 38.235,58.198,74.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.817 | Acc: 38.226,58.192,74.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.817 | Acc: 38.242,58.276,74.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.822 | Acc: 38.223,58.232,73.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.824 | Acc: 38.235,58.254,73.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.824 | Acc: 38.164,58.224,73.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 38.176,58.218,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.830 | Acc: 38.128,58.187,73.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.839 | Acc: 38.009,58.050,73.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.159 | Acc: 28.125,45.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.168 | Acc: 28.051,46.280,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.209 | Acc: 27.915,44.931,56.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.237 | Acc: 27.472,44.403,56.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 2.982 | Acc: 36.719,53.125,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.730 | Acc: 38.988,59.375,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.719 | Acc: 38.681,59.184,76.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.770 | Acc: 38.397,58.619,75.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.765 | Acc: 38.783,59.086,74.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.772 | Acc: 38.660,58.973,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.773 | Acc: 38.701,58.910,74.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.784 | Acc: 38.564,58.826,74.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.782 | Acc: 38.728,58.764,74.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.792 | Acc: 38.553,58.533,74.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.799 | Acc: 38.433,58.423,74.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.808 | Acc: 38.419,58.392,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 38.375,58.386,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.813 | Acc: 38.407,58.390,73.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.817 | Acc: 38.384,58.327,73.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.823 | Acc: 38.237,58.249,73.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.820 | Acc: 38.269,58.272,73.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.824 | Acc: 38.318,58.305,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.828 | Acc: 38.303,58.265,73.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.832 | Acc: 38.195,58.274,73.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.190 | Acc: 27.344,42.969,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.445 | Acc: 28.013,43.304,56.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.451 | Acc: 28.316,42.264,56.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.461 | Acc: 28.253,42.021,55.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 2.854 | Acc: 37.500,53.906,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.840 | Acc: 37.016,57.738,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.809 | Acc: 37.652,58.060,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.791 | Acc: 37.833,58.299,74.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.787 | Acc: 37.654,58.497,74.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.784 | Acc: 37.717,58.648,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.788 | Acc: 37.526,58.652,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.797 | Acc: 37.661,58.538,74.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.801 | Acc: 37.626,58.424,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.804 | Acc: 37.677,58.477,74.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.817 | Acc: 37.807,58.372,74.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.825 | Acc: 37.899,58.332,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.828 | Acc: 38.019,58.467,73.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.830 | Acc: 37.952,58.372,73.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.833 | Acc: 38.031,58.371,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 37.952,58.324,73.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 37.923,58.246,73.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 37.961,58.275,73.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.842 | Acc: 37.894,58.286,73.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.840 | Acc: 37.978,58.362,73.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.840 | Acc: 32.031,44.531,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.941 | Acc: 32.143,45.052,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.978 | Acc: 31.307,44.646,57.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.996 | Acc: 30.725,44.711,57.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 2.773 | Acc: 40.625,51.562,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.838 | Acc: 37.835,57.626,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.811 | Acc: 38.453,58.232,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.794 | Acc: 38.794,58.517,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.789 | Acc: 38.513,58.536,74.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.789 | Acc: 38.506,58.694,74.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.789 | Acc: 38.565,58.742,74.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.812 | Acc: 38.292,58.566,74.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.808 | Acc: 38.432,58.856,74.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.806 | Acc: 38.415,58.831,74.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.808 | Acc: 38.402,58.905,74.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.812 | Acc: 38.345,58.877,74.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.816 | Acc: 38.304,58.801,74.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.816 | Acc: 38.275,58.860,74.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.817 | Acc: 38.153,58.777,74.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.819 | Acc: 38.149,58.705,74.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.825 | Acc: 38.233,58.586,73.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.827 | Acc: 38.158,58.594,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.831 | Acc: 38.115,58.475,73.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.835 | Acc: 38.062,58.444,73.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.976 | Acc: 29.688,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.159 | Acc: 26.786,47.024,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.156 | Acc: 26.296,46.380,58.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.179 | Acc: 25.986,46.196,58.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 2.693 | Acc: 35.156,58.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.654 | Acc: 39.397,60.119,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.685 | Acc: 38.548,60.099,76.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 38.665,60.131,76.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.747 | Acc: 38.291,59.423,75.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.758 | Acc: 38.235,59.375,75.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.757 | Acc: 38.262,59.646,75.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.764 | Acc: 38.303,59.530,75.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.774 | Acc: 38.320,59.254,75.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.782 | Acc: 38.299,59.129,75.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 38.258,59.150,74.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.786 | Acc: 38.479,59.287,74.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.789 | Acc: 38.547,59.223,74.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.795 | Acc: 38.470,59.064,74.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 38.454,58.950,74.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 38.447,58.996,74.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.811 | Acc: 38.306,58.910,74.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.815 | Acc: 38.297,58.807,74.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.819 | Acc: 38.249,58.728,74.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.825 | Acc: 38.261,58.602,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.227 | Acc: 27.344,42.969,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.759 | Acc: 22.061,40.402,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.699 | Acc: 22.027,40.511,57.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.721 | Acc: 21.709,40.766,57.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.687 | Acc: 35.938,58.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.807 | Acc: 38.244,57.292,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.752 | Acc: 38.167,58.556,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.776 | Acc: 38.409,58.466,75.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.757 | Acc: 38.426,58.767,75.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.761 | Acc: 38.660,58.547,75.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.757 | Acc: 38.669,58.658,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.770 | Acc: 38.514,58.245,75.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.769 | Acc: 38.679,58.477,75.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.775 | Acc: 38.562,58.365,74.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.780 | Acc: 38.526,58.442,74.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.784 | Acc: 38.462,58.413,74.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.798 | Acc: 38.314,58.328,74.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.801 | Acc: 38.284,58.369,74.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.808 | Acc: 38.170,58.193,74.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.821 | Acc: 38.063,58.054,74.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.820 | Acc: 38.057,58.068,74.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 38.015,57.989,73.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.827 | Acc: 38.110,58.048,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.823 | Acc: 38.191,58.143,73.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.063 | Acc: 28.906,46.875,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.058 | Acc: 26.749,47.359,60.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.112 | Acc: 26.982,46.151,59.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.156 | Acc: 26.588,45.761,58.786,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 2.703 | Acc: 39.062,59.375,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.799 | Acc: 37.016,57.887,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.803 | Acc: 37.652,58.460,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.782 | Acc: 38.012,58.824,74.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.758 | Acc: 38.339,59.250,75.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 38.320,59.035,74.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.779 | Acc: 38.171,58.581,74.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.786 | Acc: 38.071,58.605,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.782 | Acc: 38.199,58.802,74.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.790 | Acc: 38.139,58.702,74.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.784 | Acc: 38.363,58.909,74.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.795 | Acc: 38.320,58.845,74.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.795 | Acc: 38.190,58.756,74.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.799 | Acc: 38.248,58.669,74.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.802 | Acc: 38.212,58.655,74.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.807 | Acc: 38.170,58.576,74.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.808 | Acc: 38.203,58.548,74.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.806 | Acc: 38.251,58.603,74.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.804 | Acc: 38.253,58.661,74.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.806 | Acc: 38.281,58.653,74.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.872 | Acc: 26.562,42.969,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.099 | Acc: 27.679,45.759,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.116 | Acc: 27.839,45.903,57.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.133 | Acc: 27.228,45.722,57.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 3.117 | Acc: 32.812,55.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.724 | Acc: 38.951,59.598,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.746 | Acc: 38.891,58.651,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.751 | Acc: 39.447,59.209,75.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 39.265,59.250,75.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.759 | Acc: 39.148,59.460,75.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.770 | Acc: 38.694,59.252,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.784 | Acc: 38.592,58.982,74.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.783 | Acc: 38.606,59.026,74.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.786 | Acc: 38.549,58.978,74.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.793 | Acc: 38.491,58.955,74.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.789 | Acc: 38.638,59.075,74.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 38.758,59.041,74.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.796 | Acc: 38.655,58.980,74.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 38.476,58.944,74.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.804 | Acc: 38.354,58.820,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.802 | Acc: 38.425,58.798,74.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.806 | Acc: 38.368,58.807,74.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.809 | Acc: 38.363,58.767,74.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.810 | Acc: 38.298,58.688,74.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.900 | Acc: 31.250,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.929 | Acc: 30.692,47.024,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.931 | Acc: 30.011,46.208,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.968 | Acc: 29.752,46.350,58.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 2.915 | Acc: 36.719,57.812,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.724 | Acc: 38.393,59.673,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.714 | Acc: 38.624,60.194,75.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.737 | Acc: 38.614,59.836,75.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.744 | Acc: 38.387,59.375,75.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.748 | Acc: 38.281,59.290,75.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.757 | Acc: 38.378,59.084,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.748 | Acc: 38.431,59.270,75.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.753 | Acc: 38.286,59.283,75.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.765 | Acc: 38.268,59.267,74.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.775 | Acc: 38.122,59.099,74.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.773 | Acc: 38.334,59.138,74.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.775 | Acc: 38.430,59.200,74.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.778 | Acc: 38.485,59.142,74.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.783 | Acc: 38.404,59.119,74.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.793 | Acc: 38.424,58.978,74.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.797 | Acc: 38.439,58.952,74.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.800 | Acc: 38.545,58.924,74.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.804 | Acc: 38.478,58.908,74.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.812 | Acc: 38.378,58.768,73.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.157 | Acc: 31.250,43.750,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.210 | Acc: 26.525,43.862,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.192 | Acc: 26.353,44.550,58.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.192 | Acc: 25.628,44.403,57.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 2.590 | Acc: 38.281,64.844,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 38.839,60.268,76.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 38.186,60.023,76.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 38.473,59.631,76.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.722 | Acc: 38.358,59.558,75.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.751 | Acc: 38.335,59.344,75.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.746 | Acc: 38.630,59.407,75.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.766 | Acc: 38.697,59.253,75.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.777 | Acc: 38.611,58.904,74.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.782 | Acc: 38.540,58.861,74.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.788 | Acc: 38.549,58.598,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.791 | Acc: 38.543,58.647,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 38.469,58.766,74.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.798 | Acc: 38.497,58.713,74.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.799 | Acc: 38.601,58.736,74.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.801 | Acc: 38.619,58.783,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.801 | Acc: 38.588,58.757,74.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.804 | Acc: 38.531,58.699,74.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.807 | Acc: 38.461,58.607,74.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.810 | Acc: 38.404,58.549,73.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.870 | Acc: 31.250,50.000,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.964 | Acc: 28.348,48.251,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.008 | Acc: 27.820,47.142,59.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.011 | Acc: 26.998,47.285,59.298,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 3.175 | Acc: 31.250,49.219,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.752 | Acc: 38.318,60.007,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.777 | Acc: 38.243,59.337,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.761 | Acc: 39.024,59.618,74.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.759 | Acc: 38.648,59.568,74.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.767 | Acc: 38.761,59.189,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.759 | Acc: 38.662,59.414,74.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.770 | Acc: 38.398,59.214,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.762 | Acc: 38.495,59.234,74.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.771 | Acc: 38.437,59.271,74.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.768 | Acc: 38.375,59.266,74.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.772 | Acc: 38.430,59.181,74.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.771 | Acc: 38.385,59.197,74.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.777 | Acc: 38.434,59.198,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.781 | Acc: 38.317,59.144,74.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.789 | Acc: 38.325,59.102,74.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.791 | Acc: 38.240,59.095,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.788 | Acc: 38.371,59.150,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.788 | Acc: 38.426,59.152,74.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.794 | Acc: 38.417,59.096,74.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.716 | Acc: 34.375,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.765 | Acc: 31.287,48.624,60.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.820 | Acc: 30.316,48.323,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.847 | Acc: 30.213,48.105,59.144,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 2.758 | Acc: 37.500,62.500,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.756 | Acc: 38.914,59.189,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.762 | Acc: 38.815,59.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.765 | Acc: 38.922,59.503,75.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.767 | Acc: 38.609,59.144,75.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.773 | Acc: 38.653,58.981,75.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.773 | Acc: 38.533,59.091,75.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.771 | Acc: 38.564,58.915,75.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.775 | Acc: 38.519,58.822,75.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.782 | Acc: 38.229,58.840,74.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.786 | Acc: 38.169,58.792,74.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.784 | Acc: 38.387,58.862,74.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.787 | Acc: 38.440,58.963,74.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.786 | Acc: 38.488,59.061,74.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.783 | Acc: 38.520,59.078,74.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.781 | Acc: 38.603,59.064,74.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.784 | Acc: 38.454,59.061,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.789 | Acc: 38.501,59.043,74.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.793 | Acc: 38.437,59.009,74.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.792 | Acc: 38.486,59.028,74.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.755 | Acc: 31.250,50.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.891 | Acc: 29.315,50.074,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.876 | Acc: 28.735,49.238,60.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.854 | Acc: 28.535,49.270,60.681,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 2.751 | Acc: 35.938,65.625,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.736 | Acc: 38.356,59.970,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.701 | Acc: 38.643,60.290,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 38.794,60.310,75.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.712 | Acc: 38.841,60.397,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.735 | Acc: 38.691,60.071,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.755 | Acc: 38.397,59.749,75.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.757 | Acc: 38.298,59.696,75.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.768 | Acc: 38.354,59.593,74.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.770 | Acc: 38.536,59.479,74.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.771 | Acc: 38.643,59.573,74.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.769 | Acc: 38.656,59.690,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.771 | Acc: 38.699,59.644,74.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.767 | Acc: 38.808,59.531,74.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.776 | Acc: 38.721,59.447,74.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.779 | Acc: 38.754,59.455,74.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.785 | Acc: 38.712,59.353,74.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.786 | Acc: 38.772,59.325,74.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.790 | Acc: 38.731,59.247,74.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.792 | Acc: 38.673,59.172,74.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.888 | Acc: 35.156,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.206 | Acc: 31.882,45.387,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.207 | Acc: 30.850,44.722,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.219 | Acc: 30.584,44.531,55.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.411 | Acc: 41.406,57.812,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.661 | Acc: 40.216,61.012,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.694 | Acc: 39.539,60.347,76.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.687 | Acc: 39.972,60.195,76.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.709 | Acc: 39.632,59.896,75.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.712 | Acc: 39.279,59.793,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.710 | Acc: 38.798,59.627,75.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.706 | Acc: 39.079,59.852,75.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.706 | Acc: 38.980,59.715,75.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.705 | Acc: 39.110,59.824,75.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.709 | Acc: 39.082,59.674,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.714 | Acc: 38.974,59.718,75.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.722 | Acc: 39.085,59.728,75.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.737 | Acc: 38.970,59.570,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.748 | Acc: 38.821,59.425,75.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.755 | Acc: 38.808,59.359,74.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.761 | Acc: 38.800,59.309,74.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.765 | Acc: 38.804,59.244,74.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.773 | Acc: 38.736,59.104,74.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.776 | Acc: 38.724,59.102,74.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.856 | Acc: 28.906,47.656,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 28.832,48.475,58.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.070 | Acc: 27.611,48.418,59.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.080 | Acc: 27.024,48.284,59.119,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 2.726 | Acc: 36.719,58.594,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.662 | Acc: 38.765,60.156,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.677 | Acc: 38.948,59.966,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.699 | Acc: 38.704,59.541,75.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.693 | Acc: 39.014,59.838,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.700 | Acc: 38.970,59.530,75.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.712 | Acc: 38.849,59.614,75.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.717 | Acc: 38.725,59.514,75.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.730 | Acc: 38.752,59.317,75.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.739 | Acc: 38.730,59.254,75.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.744 | Acc: 38.825,59.134,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.744 | Acc: 38.840,59.124,75.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.743 | Acc: 38.839,59.184,75.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.749 | Acc: 38.832,59.177,74.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.753 | Acc: 38.840,59.155,74.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.758 | Acc: 38.769,59.079,74.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.763 | Acc: 38.766,59.078,74.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.768 | Acc: 38.694,58.986,74.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.771 | Acc: 38.723,59.007,74.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.776 | Acc: 38.691,58.977,74.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.812 | Acc: 35.938,46.875,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.142 | Acc: 31.882,43.936,56.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.212 | Acc: 30.888,43.426,55.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.227 | Acc: 30.686,42.610,54.867,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 2.574 | Acc: 42.969,61.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.818 | Acc: 36.830,57.440,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.751 | Acc: 38.034,58.899,75.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.713 | Acc: 38.409,59.631,75.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.690 | Acc: 38.995,59.983,75.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.691 | Acc: 38.738,59.893,75.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.697 | Acc: 38.849,59.950,75.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.696 | Acc: 38.918,59.984,75.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.711 | Acc: 38.674,59.923,75.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.715 | Acc: 38.713,59.953,75.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.722 | Acc: 38.584,59.803,75.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.731 | Acc: 38.490,59.732,75.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.738 | Acc: 38.395,59.676,75.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.737 | Acc: 38.500,59.731,75.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.743 | Acc: 38.509,59.606,75.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.748 | Acc: 38.497,59.583,74.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.751 | Acc: 38.515,59.575,74.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.755 | Acc: 38.444,59.453,74.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.758 | Acc: 38.446,59.455,74.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.759 | Acc: 38.538,59.445,74.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.459 | Acc: 30.469,39.062,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.537 | Acc: 25.372,42.336,55.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.550 | Acc: 25.953,42.149,54.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.542 | Acc: 25.935,42.252,54.521,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.978 | Acc: 34.375,56.250,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.716 | Acc: 39.993,59.338,76.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 39.501,59.604,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 39.754,60.092,75.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.713 | Acc: 39.612,60.185,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.706 | Acc: 39.372,60.350,75.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.703 | Acc: 39.069,60.105,75.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.709 | Acc: 39.284,60.079,75.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.715 | Acc: 39.480,60.016,75.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.732 | Acc: 39.334,59.949,75.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.732 | Acc: 39.405,59.989,75.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.739 | Acc: 39.296,59.930,75.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.743 | Acc: 39.150,59.806,75.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.742 | Acc: 39.104,59.779,75.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.749 | Acc: 39.096,59.742,74.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.752 | Acc: 39.003,59.762,74.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.758 | Acc: 38.907,59.635,74.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.764 | Acc: 38.955,59.512,74.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.766 | Acc: 38.972,59.511,74.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.767 | Acc: 39.032,59.471,74.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.094 | Acc: 26.562,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.272 | Acc: 24.219,47.507,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.312 | Acc: 23.628,46.589,59.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.315 | Acc: 23.514,46.670,59.798,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.676 | Acc: 39.844,54.688,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.781 | Acc: 38.839,59.784,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 39.196,60.556,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.701 | Acc: 39.319,60.118,75.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.704 | Acc: 38.899,60.108,75.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.692 | Acc: 38.939,60.326,75.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.685 | Acc: 39.243,60.305,75.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.697 | Acc: 39.062,60.023,75.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.699 | Acc: 39.067,59.928,75.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.707 | Acc: 39.071,59.833,75.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.716 | Acc: 38.942,59.655,75.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.711 | Acc: 39.077,59.665,75.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.715 | Acc: 39.131,59.748,75.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.726 | Acc: 39.054,59.597,75.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.740 | Acc: 38.890,59.561,75.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.743 | Acc: 38.850,59.541,74.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.749 | Acc: 38.812,59.431,74.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.750 | Acc: 38.886,59.519,74.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.753 | Acc: 38.876,59.455,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.757 | Acc: 38.794,59.422,74.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.909 | Acc: 32.031,44.531,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.946 | Acc: 29.725,47.061,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.932 | Acc: 29.440,46.932,60.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.944 | Acc: 29.201,46.888,60.092,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 2.684 | Acc: 39.844,64.062,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.659 | Acc: 38.095,60.342,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.668 | Acc: 39.253,59.699,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.667 | Acc: 39.395,60.195,76.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.654 | Acc: 39.468,60.667,76.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.649 | Acc: 39.279,60.442,76.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.662 | Acc: 39.237,60.363,76.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.666 | Acc: 39.351,60.395,76.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.678 | Acc: 39.232,60.200,76.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.685 | Acc: 39.097,60.087,76.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.693 | Acc: 39.179,60.090,75.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.704 | Acc: 39.038,59.863,75.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.711 | Acc: 39.134,59.800,75.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.714 | Acc: 39.125,59.836,75.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.722 | Acc: 39.082,59.745,75.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.727 | Acc: 39.008,59.661,75.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.734 | Acc: 38.909,59.601,75.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.740 | Acc: 38.875,59.556,75.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.746 | Acc: 38.840,59.520,74.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.752 | Acc: 38.782,59.424,74.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.049 | Acc: 28.125,50.781,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.152 | Acc: 23.772,45.312,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.157 | Acc: 24.295,45.389,60.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.175 | Acc: 24.103,44.980,59.900,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 2.620 | Acc: 33.594,63.281,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 38.616,58.854,76.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.670 | Acc: 39.444,60.366,76.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.688 | Acc: 39.203,60.387,76.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.697 | Acc: 38.821,60.484,76.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.697 | Acc: 39.155,60.427,76.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.700 | Acc: 39.250,60.440,76.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.705 | Acc: 39.251,60.350,75.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.714 | Acc: 39.043,60.214,75.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.720 | Acc: 38.868,60.191,75.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.717 | Acc: 39.020,60.257,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.724 | Acc: 39.080,60.064,75.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.729 | Acc: 39.056,59.920,75.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.730 | Acc: 38.964,60.001,75.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.727 | Acc: 39.026,60.056,75.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.734 | Acc: 38.943,60.008,75.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.734 | Acc: 38.936,59.983,75.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.737 | Acc: 38.936,59.888,75.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.744 | Acc: 38.870,59.901,75.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.748 | Acc: 38.862,59.873,75.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.101 | Acc: 28.906,50.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.065 | Acc: 28.311,47.359,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.092 | Acc: 27.325,46.913,59.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.107 | Acc: 26.870,46.145,59.042,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 2.738 | Acc: 36.719,52.344,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 39.844,59.970,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.666 | Acc: 39.177,59.870,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.673 | Acc: 38.998,60.067,76.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.673 | Acc: 38.879,60.397,76.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.676 | Acc: 38.560,60.504,76.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.697 | Acc: 38.540,60.266,75.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.703 | Acc: 38.459,59.957,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.711 | Acc: 38.446,59.909,75.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.718 | Acc: 38.523,59.889,75.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.724 | Acc: 38.456,59.779,75.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.722 | Acc: 38.635,59.782,75.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.732 | Acc: 38.599,59.741,75.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.736 | Acc: 38.554,59.689,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.732 | Acc: 38.737,59.792,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.738 | Acc: 38.717,59.749,75.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.741 | Acc: 38.763,59.757,74.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.744 | Acc: 38.838,59.758,74.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.743 | Acc: 38.848,59.782,74.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.744 | Acc: 38.835,59.693,74.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 28.906,44.531,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.093 | Acc: 26.711,46.205,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.181 | Acc: 25.305,45.332,57.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.201 | Acc: 25.141,45.095,57.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 2.401 | Acc: 39.062,65.625,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.663 | Acc: 38.616,60.938,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.639 | Acc: 39.539,61.147,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.662 | Acc: 39.050,60.207,76.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.684 | Acc: 39.014,59.838,76.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.683 | Acc: 39.055,59.661,76.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.691 | Acc: 39.056,59.756,76.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.695 | Acc: 39.024,59.912,76.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.715 | Acc: 38.907,59.758,75.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.729 | Acc: 38.782,59.660,75.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.734 | Acc: 38.822,59.783,75.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.734 | Acc: 38.857,59.831,75.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.741 | Acc: 38.865,59.910,75.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.735 | Acc: 38.985,60.048,75.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.733 | Acc: 39.071,60.092,75.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.733 | Acc: 39.101,60.060,75.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.736 | Acc: 39.111,60.003,74.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.738 | Acc: 39.095,59.966,74.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.740 | Acc: 39.045,59.918,74.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.744 | Acc: 38.999,59.892,74.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.752 | Acc: 32.031,42.969,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.690 | Acc: 31.362,48.400,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.714 | Acc: 30.831,48.399,62.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.741 | Acc: 30.815,48.233,62.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 2.501 | Acc: 32.031,60.156,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.642 | Acc: 38.504,61.533,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.636 | Acc: 38.338,60.918,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.625 | Acc: 39.062,61.245,77.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.642 | Acc: 39.053,60.909,77.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.647 | Acc: 39.155,60.829,76.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.657 | Acc: 39.282,60.718,76.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.661 | Acc: 39.312,60.672,76.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.679 | Acc: 39.087,60.418,76.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.687 | Acc: 38.886,60.277,76.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.699 | Acc: 38.806,60.172,75.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.707 | Acc: 38.730,60.011,75.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.711 | Acc: 38.771,59.997,75.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.718 | Acc: 38.808,60.016,75.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.726 | Acc: 38.648,59.914,75.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.728 | Acc: 38.712,59.904,75.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.727 | Acc: 38.795,59.881,75.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.733 | Acc: 38.739,59.746,75.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.735 | Acc: 38.770,59.756,75.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.737 | Acc: 38.771,59.666,74.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.676 | Acc: 32.812,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.789 | Acc: 29.911,48.177,62.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.781 | Acc: 30.107,48.114,61.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.796 | Acc: 29.649,48.002,61.450,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.501 | Acc: 37.500,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.701 | Acc: 38.132,60.379,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.665 | Acc: 39.310,61.719,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.674 | Acc: 39.511,61.347,76.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.657 | Acc: 39.632,61.613,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.662 | Acc: 39.658,61.324,76.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.679 | Acc: 39.418,61.009,76.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.675 | Acc: 39.578,61.048,76.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.674 | Acc: 39.752,60.850,76.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.678 | Acc: 39.917,60.782,76.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.685 | Acc: 39.933,60.697,75.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.690 | Acc: 39.773,60.531,75.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.702 | Acc: 39.562,60.296,75.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.712 | Acc: 39.553,60.189,75.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.713 | Acc: 39.530,60.156,75.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.717 | Acc: 39.486,60.130,75.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.721 | Acc: 39.449,60.144,75.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.723 | Acc: 39.418,60.143,75.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.726 | Acc: 39.420,60.074,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.727 | Acc: 39.473,60.062,75.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.858 | Acc: 29.688,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.947 | Acc: 30.134,47.359,59.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.970 | Acc: 29.554,46.361,59.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.987 | Acc: 29.431,46.337,59.144,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 2.577 | Acc: 33.594,64.844,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.729 | Acc: 38.244,60.268,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.706 | Acc: 38.377,60.728,76.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 38.806,60.284,76.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.703 | Acc: 38.850,60.224,76.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.728 | Acc: 38.467,60.087,75.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.721 | Acc: 38.443,60.085,75.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.720 | Acc: 38.370,59.973,75.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.725 | Acc: 38.398,59.894,75.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.730 | Acc: 38.480,59.815,75.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.730 | Acc: 38.546,59.861,75.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.732 | Acc: 38.589,59.852,75.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.733 | Acc: 38.628,59.819,75.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.737 | Acc: 38.658,59.806,75.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.738 | Acc: 38.698,59.811,75.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.739 | Acc: 38.715,59.829,75.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.735 | Acc: 38.904,59.913,75.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.737 | Acc: 38.863,59.858,75.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.738 | Acc: 38.833,59.855,75.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.740 | Acc: 38.864,59.888,74.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.748 | Acc: 32.812,53.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.849 | Acc: 28.683,50.409,61.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.894 | Acc: 27.839,49.466,60.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.919 | Acc: 27.357,49.565,60.156,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 2.668 | Acc: 34.375,54.688,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.621 | Acc: 39.732,61.086,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.632 | Acc: 39.425,60.880,76.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.650 | Acc: 39.472,60.643,76.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.658 | Acc: 39.140,60.802,76.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.653 | Acc: 39.364,61.239,76.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.657 | Acc: 39.372,60.912,76.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.665 | Acc: 39.439,60.899,76.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.663 | Acc: 39.412,60.816,76.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.663 | Acc: 39.360,60.748,76.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.668 | Acc: 39.420,60.755,76.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.673 | Acc: 39.363,60.697,76.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.683 | Acc: 39.335,60.646,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.686 | Acc: 39.410,60.551,75.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.696 | Acc: 39.352,60.393,75.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.701 | Acc: 39.265,60.325,75.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.709 | Acc: 39.211,60.246,75.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.710 | Acc: 39.161,60.216,75.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.718 | Acc: 39.062,60.139,75.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.723 | Acc: 39.040,60.078,75.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.891 | Acc: 33.594,45.312,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.965 | Acc: 30.134,47.098,59.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.002 | Acc: 30.126,46.532,59.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.985 | Acc: 29.854,46.849,59.631,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.667 | Acc: 34.375,65.625,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 39.732,60.342,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.688 | Acc: 39.196,60.290,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.686 | Acc: 39.062,60.669,76.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.672 | Acc: 39.381,60.802,76.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.669 | Acc: 39.395,60.984,76.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.661 | Acc: 39.585,61.086,76.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.653 | Acc: 39.955,61.309,76.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.670 | Acc: 39.805,61.136,76.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.664 | Acc: 39.891,61.076,76.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.672 | Acc: 39.960,61.035,76.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.684 | Acc: 39.692,60.867,75.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.696 | Acc: 39.513,60.711,75.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.698 | Acc: 39.446,60.680,75.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.703 | Acc: 39.352,60.587,75.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.706 | Acc: 39.364,60.572,75.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.709 | Acc: 39.372,60.514,75.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.715 | Acc: 39.397,60.401,75.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.718 | Acc: 39.424,60.299,75.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.722 | Acc: 39.374,60.146,75.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.524 | Acc: 25.781,41.406,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.278 | Acc: 25.112,45.796,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.340 | Acc: 24.981,44.512,58.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.408 | Acc: 24.718,44.147,58.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.876 | Acc: 42.969,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.655 | Acc: 39.769,60.826,76.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.640 | Acc: 39.120,60.690,77.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.638 | Acc: 39.191,61.104,77.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.648 | Acc: 39.323,60.870,76.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.656 | Acc: 39.411,60.659,76.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.662 | Acc: 39.301,60.673,76.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.663 | Acc: 39.284,60.638,76.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.662 | Acc: 39.397,60.748,76.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.668 | Acc: 39.373,60.704,76.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.677 | Acc: 39.389,60.634,76.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.684 | Acc: 39.363,60.552,76.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.686 | Acc: 39.406,60.497,75.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.685 | Acc: 39.386,60.468,75.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.691 | Acc: 39.354,60.431,75.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.702 | Acc: 39.156,60.203,75.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.703 | Acc: 39.062,60.176,75.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.705 | Acc: 39.012,60.126,75.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.715 | Acc: 38.952,60.048,75.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.718 | Acc: 38.978,59.951,75.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.598 | Acc: 37.500,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.819 | Acc: 33.259,51.004,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.853 | Acc: 32.107,49.943,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.869 | Acc: 31.545,49.603,58.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 2.840 | Acc: 39.844,63.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.736 | Acc: 37.426,60.417,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.715 | Acc: 38.014,60.309,75.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 38.742,60.323,75.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.679 | Acc: 39.014,60.802,76.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.679 | Acc: 39.086,60.651,76.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.667 | Acc: 39.463,60.686,76.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.669 | Acc: 39.389,60.644,76.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.675 | Acc: 39.227,60.510,76.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.672 | Acc: 39.391,60.549,76.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.675 | Acc: 39.552,60.599,76.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.675 | Acc: 39.533,60.559,76.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.685 | Acc: 39.403,60.335,75.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.686 | Acc: 39.482,60.366,75.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.686 | Acc: 39.543,60.420,75.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.692 | Acc: 39.441,60.335,75.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.697 | Acc: 39.408,60.273,75.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.694 | Acc: 39.491,60.356,75.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.697 | Acc: 39.452,60.312,75.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.705 | Acc: 39.427,60.230,75.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.307 | Acc: 32.812,46.094,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.255 | Acc: 28.906,44.829,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.262 | Acc: 28.697,44.379,56.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.247 | Acc: 28.560,44.160,56.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.761 | Acc: 35.156,61.719,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.650 | Acc: 38.542,60.789,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.647 | Acc: 39.901,60.747,77.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.678 | Acc: 39.191,60.387,76.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.664 | Acc: 39.014,60.523,76.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.654 | Acc: 39.310,60.566,76.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.664 | Acc: 39.495,60.569,76.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.666 | Acc: 39.561,60.694,76.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.674 | Acc: 39.596,60.680,76.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.682 | Acc: 39.429,60.601,76.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.687 | Acc: 39.280,60.288,76.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.693 | Acc: 39.190,60.294,76.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.693 | Acc: 39.192,60.263,76.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.696 | Acc: 39.158,60.216,75.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.699 | Acc: 39.285,60.229,75.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.707 | Acc: 39.213,60.125,75.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.712 | Acc: 39.218,60.098,75.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.715 | Acc: 39.168,60.090,75.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.719 | Acc: 39.147,60.070,75.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.724 | Acc: 39.093,60.046,75.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.858 | Acc: 30.469,48.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.817 | Acc: 28.906,49.368,60.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.853 | Acc: 28.354,48.285,60.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.869 | Acc: 28.189,48.514,59.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.448 | Acc: 36.719,64.062,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.601 | Acc: 39.137,60.640,78.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.608 | Acc: 39.024,61.223,78.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.638 | Acc: 39.216,61.040,77.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.644 | Acc: 39.284,60.841,76.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.646 | Acc: 39.442,60.999,76.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.657 | Acc: 39.469,60.963,76.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.671 | Acc: 39.245,60.888,76.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.669 | Acc: 39.155,60.884,76.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.676 | Acc: 39.175,60.709,76.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.676 | Acc: 39.331,60.619,76.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.674 | Acc: 39.427,60.704,76.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.680 | Acc: 39.419,60.711,76.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.679 | Acc: 39.437,60.731,75.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.679 | Acc: 39.457,60.735,76.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.681 | Acc: 39.478,60.784,76.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.681 | Acc: 39.486,60.867,76.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.687 | Acc: 39.560,60.809,75.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.691 | Acc: 39.549,60.743,75.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.694 | Acc: 39.505,60.755,75.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.965 | Acc: 25.000,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.107 | Acc: 25.000,48.586,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.159 | Acc: 24.466,47.370,61.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.196 | Acc: 23.591,46.926,60.733,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 2.852 | Acc: 32.031,55.469,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.608 | Acc: 40.030,61.161,78.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.635 | Acc: 40.053,60.499,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.649 | Acc: 39.754,60.489,77.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.658 | Acc: 39.400,60.503,77.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.680 | Acc: 39.295,60.450,76.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.673 | Acc: 39.314,60.531,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.682 | Acc: 39.256,60.478,76.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.685 | Acc: 39.223,60.404,76.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.685 | Acc: 39.153,60.333,75.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.683 | Acc: 39.269,60.487,75.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.681 | Acc: 39.359,60.471,75.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.683 | Acc: 39.403,60.458,75.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.686 | Acc: 39.386,60.375,75.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.689 | Acc: 39.379,60.376,75.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.694 | Acc: 39.306,60.390,75.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.698 | Acc: 39.250,60.307,75.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.703 | Acc: 39.195,60.220,75.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.705 | Acc: 39.190,60.163,75.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.710 | Acc: 39.122,60.039,75.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.989 | Acc: 28.906,53.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.136 | Acc: 28.348,45.908,59.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.114 | Acc: 28.182,45.846,59.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.119 | Acc: 27.818,45.633,58.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 2.497 | Acc: 39.844,67.188,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.665 | Acc: 37.798,61.570,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.637 | Acc: 38.777,61.814,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.651 | Acc: 38.998,61.232,77.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.649 | Acc: 38.956,60.909,76.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.637 | Acc: 39.558,61.239,76.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.653 | Acc: 39.276,60.802,76.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.658 | Acc: 39.179,60.810,76.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.665 | Acc: 39.184,60.821,76.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.667 | Acc: 39.218,60.851,76.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.675 | Acc: 39.156,60.794,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.677 | Acc: 39.084,60.740,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.678 | Acc: 39.150,60.724,76.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.689 | Acc: 39.104,60.539,75.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.695 | Acc: 39.076,60.512,75.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.696 | Acc: 39.184,60.470,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.697 | Acc: 39.189,60.551,75.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.701 | Acc: 39.282,60.521,75.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.705 | Acc: 39.259,60.492,75.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.705 | Acc: 39.366,60.480,75.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.372 | Acc: 39.844,56.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.670 | Acc: 36.458,51.079,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.718 | Acc: 35.518,49.981,59.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.750 | Acc: 34.964,50.115,58.363,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 2.486 | Acc: 39.062,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.568 | Acc: 39.435,62.798,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.617 | Acc: 38.624,61.509,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.630 | Acc: 38.589,61.219,77.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.645 | Acc: 38.966,61.159,76.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.659 | Acc: 38.753,61.139,76.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.667 | Acc: 38.875,60.899,76.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.669 | Acc: 39.040,60.943,76.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.675 | Acc: 39.116,60.656,76.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.674 | Acc: 39.218,60.666,76.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.684 | Acc: 39.160,60.522,75.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.686 | Acc: 39.243,60.616,75.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.694 | Acc: 39.150,60.587,75.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.700 | Acc: 39.134,60.486,75.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.700 | Acc: 39.140,60.518,75.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.703 | Acc: 39.184,60.507,75.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.708 | Acc: 39.228,60.412,75.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.710 | Acc: 39.136,60.383,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.710 | Acc: 39.138,60.388,75.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.710 | Acc: 39.106,60.392,75.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.152 | Acc: 21.094,46.875,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.179 | Acc: 23.400,46.466,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.231 | Acc: 24.028,45.293,59.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.246 | Acc: 23.681,45.044,58.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.481 | Acc: 44.531,64.844,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.692 | Acc: 38.876,60.119,76.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.683 | Acc: 38.357,60.042,76.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.670 | Acc: 38.986,60.758,76.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.672 | Acc: 39.091,60.976,76.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.675 | Acc: 39.341,61.046,76.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.681 | Acc: 39.282,60.996,76.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.684 | Acc: 39.212,60.827,76.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.670 | Acc: 39.407,61.161,76.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.668 | Acc: 39.239,61.162,76.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.668 | Acc: 39.315,61.140,76.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.673 | Acc: 39.211,61.090,75.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.676 | Acc: 39.192,60.938,75.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.677 | Acc: 39.146,60.902,75.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.678 | Acc: 39.196,60.865,75.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.676 | Acc: 39.294,60.870,75.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.678 | Acc: 39.306,60.845,75.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.683 | Acc: 39.303,60.743,75.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.687 | Acc: 39.329,60.712,75.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.688 | Acc: 39.362,60.747,75.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.889 | Acc: 28.906,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.027 | Acc: 26.972,50.260,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.085 | Acc: 26.162,49.257,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.082 | Acc: 25.807,48.911,59.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 2.593 | Acc: 40.625,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.512 | Acc: 40.774,63.021,79.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.570 | Acc: 39.729,62.329,78.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.572 | Acc: 39.703,62.449,78.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.566 | Acc: 39.940,62.461,78.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.585 | Acc: 39.658,62.183,78.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.597 | Acc: 39.773,62.009,77.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.606 | Acc: 39.678,61.785,77.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.619 | Acc: 39.616,61.627,76.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.632 | Acc: 39.498,61.520,76.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.633 | Acc: 39.537,61.462,76.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.643 | Acc: 39.412,61.206,76.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.640 | Acc: 39.484,61.210,76.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.643 | Acc: 39.535,61.222,76.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.650 | Acc: 39.549,61.196,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.660 | Acc: 39.325,60.995,76.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.665 | Acc: 39.277,60.962,76.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.672 | Acc: 39.285,60.883,76.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.680 | Acc: 39.275,60.760,75.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.685 | Acc: 39.284,60.640,75.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.864 | Acc: 39.844,50.781,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.763 | Acc: 33.966,49.554,60.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.758 | Acc: 33.479,49.390,60.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.751 | Acc: 33.568,49.257,60.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 2.618 | Acc: 37.500,63.281,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.606 | Acc: 37.798,61.570,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.649 | Acc: 37.976,60.404,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.617 | Acc: 38.781,61.002,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.622 | Acc: 39.043,61.073,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.609 | Acc: 39.573,61.309,77.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.615 | Acc: 39.669,61.364,77.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.621 | Acc: 39.539,61.453,77.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.624 | Acc: 39.494,61.403,76.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.624 | Acc: 39.542,61.369,76.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.634 | Acc: 39.482,61.287,76.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.639 | Acc: 39.416,61.164,76.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.641 | Acc: 39.445,61.187,76.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.646 | Acc: 39.470,61.111,76.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.651 | Acc: 39.432,61.021,76.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.651 | Acc: 39.486,60.982,76.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.654 | Acc: 39.522,60.891,76.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.662 | Acc: 39.560,60.901,76.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.671 | Acc: 39.510,60.777,76.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.676 | Acc: 39.458,60.759,75.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 35.156,41.406,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 28.051,43.676,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.359 | Acc: 27.763,42.759,55.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.346 | Acc: 27.690,42.725,55.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.537 | Acc: 45.312,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 40.030,61.235,76.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.672 | Acc: 39.329,60.918,76.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.665 | Acc: 39.600,60.579,76.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.673 | Acc: 39.323,60.561,76.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.669 | Acc: 39.318,60.558,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.663 | Acc: 39.250,60.434,76.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.669 | Acc: 39.295,60.411,76.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.669 | Acc: 39.354,60.675,76.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.661 | Acc: 39.378,60.782,76.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.662 | Acc: 39.490,60.875,76.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.662 | Acc: 39.497,60.856,76.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.668 | Acc: 39.510,60.727,76.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.674 | Acc: 39.503,60.536,75.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.669 | Acc: 39.580,60.568,75.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.671 | Acc: 39.504,60.621,75.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.673 | Acc: 39.464,60.575,75.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.679 | Acc: 39.496,60.466,75.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.684 | Acc: 39.424,60.429,75.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.692 | Acc: 39.358,60.367,75.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.617 | Acc: 26.562,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 23.400,45.461,57.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.559 | Acc: 23.704,44.131,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 23.348,44.083,57.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 2.371 | Acc: 41.406,61.719,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.553 | Acc: 41.071,62.128,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.605 | Acc: 39.425,61.261,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.621 | Acc: 38.858,61.539,77.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.604 | Acc: 39.477,61.613,77.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.606 | Acc: 39.403,61.549,77.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.602 | Acc: 39.560,61.486,77.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.614 | Acc: 39.738,61.309,77.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.622 | Acc: 39.810,61.301,76.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.634 | Acc: 39.796,61.110,76.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.639 | Acc: 39.844,61.213,76.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.654 | Acc: 39.706,60.998,76.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.661 | Acc: 39.698,60.921,76.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.663 | Acc: 39.655,60.839,76.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.667 | Acc: 39.527,60.765,76.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.671 | Acc: 39.509,60.657,76.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.673 | Acc: 39.525,60.699,76.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.678 | Acc: 39.493,60.592,75.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.679 | Acc: 39.571,60.526,75.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.683 | Acc: 39.524,60.478,75.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.820 | Acc: 28.125,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.937 | Acc: 29.129,47.768,58.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.985 | Acc: 29.287,47.237,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.004 | Acc: 29.649,47.016,58.440,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.853 | Acc: 35.156,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.707 | Acc: 37.835,59.152,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.641 | Acc: 38.643,60.194,76.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.640 | Acc: 38.998,60.361,76.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.651 | Acc: 38.956,60.774,76.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.655 | Acc: 38.807,60.644,76.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.649 | Acc: 39.121,60.808,76.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.644 | Acc: 39.489,61.054,76.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.636 | Acc: 39.752,61.272,76.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.638 | Acc: 39.831,61.166,76.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.639 | Acc: 39.688,61.046,76.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.640 | Acc: 39.794,61.111,76.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.642 | Acc: 39.789,61.074,76.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.642 | Acc: 39.829,61.144,76.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.648 | Acc: 39.719,61.074,76.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.654 | Acc: 39.623,60.995,76.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.656 | Acc: 39.656,60.993,76.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.665 | Acc: 39.544,60.850,76.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.665 | Acc: 39.627,60.853,76.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.667 | Acc: 39.633,60.864,76.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.989 | Acc: 35.938,46.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.772 | Acc: 34.338,49.702,62.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.817 | Acc: 33.003,48.266,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.809 | Acc: 32.569,48.450,60.784,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 2.562 | Acc: 40.625,58.594,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.644 | Acc: 39.583,60.565,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.617 | Acc: 40.434,61.014,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.626 | Acc: 40.100,60.899,77.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.641 | Acc: 39.931,60.677,77.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.637 | Acc: 39.844,60.528,76.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.640 | Acc: 39.592,60.602,76.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.633 | Acc: 39.473,60.771,76.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.628 | Acc: 39.591,60.797,77.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.637 | Acc: 39.447,60.683,76.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.646 | Acc: 39.401,60.459,76.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.646 | Acc: 39.402,60.605,76.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.653 | Acc: 39.299,60.558,76.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.651 | Acc: 39.440,60.605,76.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.657 | Acc: 39.488,60.543,76.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.664 | Acc: 39.460,60.356,76.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.670 | Acc: 39.367,60.310,76.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.673 | Acc: 39.413,60.342,76.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.673 | Acc: 39.437,60.392,76.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.675 | Acc: 39.419,60.372,76.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.103 | Acc: 26.562,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.258 | Acc: 24.963,46.540,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.256 | Acc: 24.848,46.189,58.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 24.398,45.543,58.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.423 | Acc: 37.500,64.844,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.639 | Acc: 40.365,60.379,76.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.618 | Acc: 39.748,60.785,76.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.652 | Acc: 39.370,60.720,76.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.632 | Acc: 39.014,61.140,76.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.631 | Acc: 39.233,61.270,77.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.635 | Acc: 39.185,61.176,76.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.632 | Acc: 39.367,61.093,76.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.638 | Acc: 39.480,61.001,76.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.638 | Acc: 39.645,61.084,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.640 | Acc: 39.564,61.058,76.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.643 | Acc: 39.667,60.916,76.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.645 | Acc: 39.821,60.983,76.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.654 | Acc: 39.820,60.845,76.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.658 | Acc: 39.908,60.746,76.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.662 | Acc: 39.852,60.735,76.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.666 | Acc: 39.749,60.794,76.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.665 | Acc: 39.807,60.786,76.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.669 | Acc: 39.833,60.710,75.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.675 | Acc: 39.774,60.689,75.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.834 | Acc: 29.688,39.062,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.730 | Acc: 23.512,41.815,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.754 | Acc: 22.675,41.711,55.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.735 | Acc: 22.400,41.842,54.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.580 | Acc: 36.719,63.281,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.566 | Acc: 40.885,61.384,78.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.586 | Acc: 39.539,61.585,78.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.582 | Acc: 39.921,61.719,78.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.601 | Acc: 39.651,61.478,77.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.600 | Acc: 39.565,61.487,77.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.605 | Acc: 39.702,61.564,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.616 | Acc: 39.788,61.353,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.613 | Acc: 40.072,61.369,77.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.620 | Acc: 39.960,61.378,77.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.623 | Acc: 40.100,61.260,77.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.638 | Acc: 39.932,61.054,77.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.649 | Acc: 39.795,60.840,76.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.653 | Acc: 39.778,60.680,76.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.656 | Acc: 39.802,60.684,76.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.657 | Acc: 39.797,60.670,76.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.659 | Acc: 39.737,60.706,76.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.661 | Acc: 39.695,60.672,76.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.665 | Acc: 39.608,60.585,76.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.668 | Acc: 39.678,60.570,76.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.710 | Acc: 35.156,44.531,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.040 | Acc: 30.618,46.280,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.058 | Acc: 29.707,45.694,59.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.074 | Acc: 29.598,45.594,58.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.801 | Acc: 39.062,54.688,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.636 | Acc: 39.249,60.342,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.611 | Acc: 39.520,61.090,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.620 | Acc: 39.549,61.053,76.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.616 | Acc: 39.525,61.285,76.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.617 | Acc: 39.681,61.603,76.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.604 | Acc: 39.882,61.951,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.608 | Acc: 39.844,61.674,76.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.610 | Acc: 39.815,61.661,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.620 | Acc: 39.680,61.304,76.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.628 | Acc: 39.607,61.178,76.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.629 | Acc: 39.398,61.107,76.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.632 | Acc: 39.507,61.116,76.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.643 | Acc: 39.455,60.946,76.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.650 | Acc: 39.480,60.929,76.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.657 | Acc: 39.428,60.891,75.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.661 | Acc: 39.432,60.779,75.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.664 | Acc: 39.505,60.795,75.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.667 | Acc: 39.482,60.749,75.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.667 | Acc: 39.516,60.730,75.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.343 | Acc: 25.000,42.188,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.353 | Acc: 24.554,44.829,61.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.430 | Acc: 24.409,44.112,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.446 | Acc: 23.847,44.262,59.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 2.500 | Acc: 39.062,59.375,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.606 | Acc: 40.811,61.756,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.619 | Acc: 40.130,60.918,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.592 | Acc: 40.164,61.347,77.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.593 | Acc: 40.287,61.526,77.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.596 | Acc: 40.362,61.634,77.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.609 | Acc: 40.199,61.331,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.617 | Acc: 40.254,61.264,77.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.619 | Acc: 40.130,61.030,76.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.621 | Acc: 40.060,61.058,76.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.630 | Acc: 40.065,61.011,76.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.635 | Acc: 40.095,60.980,76.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.640 | Acc: 39.980,60.963,76.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.640 | Acc: 39.880,60.967,76.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.648 | Acc: 39.788,60.954,76.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.648 | Acc: 39.724,60.943,76.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.653 | Acc: 39.651,60.918,76.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.657 | Acc: 39.649,60.908,76.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.658 | Acc: 39.712,60.909,76.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.665 | Acc: 39.614,60.825,75.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.744 | Acc: 39.062,52.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.659 | Acc: 35.417,52.083,63.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.714 | Acc: 33.994,51.429,61.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.745 | Acc: 33.274,51.076,61.668,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 2.725 | Acc: 37.500,64.844,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.606 | Acc: 39.583,62.054,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.619 | Acc: 39.234,61.338,76.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.615 | Acc: 39.383,61.232,76.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.612 | Acc: 39.497,61.343,77.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.632 | Acc: 39.558,61.278,76.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.641 | Acc: 39.502,60.854,76.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.650 | Acc: 39.622,60.782,76.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.653 | Acc: 39.703,60.836,76.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.654 | Acc: 39.693,60.916,76.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.659 | Acc: 39.587,60.844,76.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.656 | Acc: 39.727,60.796,76.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.660 | Acc: 39.824,60.753,76.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.659 | Acc: 39.829,60.779,76.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.659 | Acc: 39.744,60.790,76.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.664 | Acc: 39.602,60.740,76.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.665 | Acc: 39.642,60.706,76.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.665 | Acc: 39.626,60.727,76.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.670 | Acc: 39.647,60.702,75.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.674 | Acc: 39.635,60.702,75.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.979 | Acc: 35.938,46.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.838 | Acc: 31.436,49.814,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.888 | Acc: 31.250,49.238,60.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.891 | Acc: 30.891,49.488,60.387,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 2.689 | Acc: 37.500,64.062,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.575 | Acc: 40.141,62.537,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.582 | Acc: 39.939,61.871,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.600 | Acc: 39.780,61.591,77.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.592 | Acc: 39.921,61.603,78.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.586 | Acc: 40.068,61.974,77.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.596 | Acc: 39.734,61.990,77.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.595 | Acc: 39.849,61.985,77.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.602 | Acc: 39.693,61.908,77.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.607 | Acc: 39.611,61.831,77.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.610 | Acc: 39.910,61.727,77.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.612 | Acc: 40.021,61.659,77.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.620 | Acc: 40.090,61.596,76.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.623 | Acc: 40.101,61.554,76.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.631 | Acc: 39.955,61.388,76.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.638 | Acc: 39.924,61.246,76.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.645 | Acc: 39.844,61.144,76.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.652 | Acc: 39.764,61.116,76.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.656 | Acc: 39.733,61.009,76.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.658 | Acc: 39.682,60.995,76.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.090 | Acc: 34.375,43.750,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.703 | Acc: 33.296,50.223,61.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.752 | Acc: 32.565,49.447,60.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.750 | Acc: 31.954,49.565,60.617,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 2.570 | Acc: 39.844,62.500,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.629 | Acc: 39.955,59.970,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.625 | Acc: 40.091,60.575,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.609 | Acc: 40.369,60.938,77.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.616 | Acc: 40.384,61.362,77.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.610 | Acc: 40.633,61.456,77.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.615 | Acc: 40.560,61.590,77.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.629 | Acc: 40.270,61.364,77.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.630 | Acc: 40.285,61.578,76.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.634 | Acc: 40.085,61.546,76.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.631 | Acc: 40.131,61.622,76.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.635 | Acc: 40.021,61.538,76.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.634 | Acc: 40.126,61.527,76.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.641 | Acc: 40.077,61.363,76.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.648 | Acc: 40.016,61.293,76.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.648 | Acc: 39.974,61.207,76.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.651 | Acc: 39.980,61.220,76.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.656 | Acc: 40.022,61.132,76.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.661 | Acc: 39.980,61.076,76.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.666 | Acc: 39.965,61.028,76.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.640 | Acc: 32.812,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.678 | Acc: 32.515,51.414,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.689 | Acc: 31.688,50.514,61.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.718 | Acc: 31.288,50.525,61.514,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 2.529 | Acc: 41.406,60.938,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.594 | Acc: 39.360,61.682,77.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.604 | Acc: 39.501,61.109,78.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.620 | Acc: 39.575,61.155,77.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.624 | Acc: 39.448,61.323,77.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.622 | Acc: 39.480,61.425,77.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.626 | Acc: 39.824,61.325,77.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.632 | Acc: 39.894,61.220,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.632 | Acc: 39.795,61.025,76.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.642 | Acc: 39.550,60.855,76.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.645 | Acc: 39.560,60.961,76.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.642 | Acc: 39.678,61.008,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.647 | Acc: 39.789,60.915,76.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.652 | Acc: 39.808,60.866,76.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.648 | Acc: 39.922,60.932,76.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.652 | Acc: 39.880,60.834,76.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.653 | Acc: 39.907,60.813,76.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.654 | Acc: 39.867,60.850,76.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.658 | Acc: 39.816,60.862,76.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.657 | Acc: 39.868,60.919,76.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.868 | Acc: 32.031,55.469,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.134 | Acc: 27.344,47.917,60.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.196 | Acc: 26.048,47.389,59.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.225 | Acc: 25.986,46.875,59.004,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 2.542 | Acc: 42.969,57.031,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.609 | Acc: 39.435,60.603,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.584 | Acc: 39.748,61.681,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.580 | Acc: 40.049,61.488,77.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.576 | Acc: 40.432,61.998,77.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.591 | Acc: 40.416,61.742,77.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.603 | Acc: 40.251,61.609,77.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.605 | Acc: 40.198,61.553,77.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.617 | Acc: 40.183,61.462,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.624 | Acc: 40.120,61.417,76.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.627 | Acc: 39.964,61.404,76.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.630 | Acc: 39.840,61.390,76.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.632 | Acc: 39.899,61.310,76.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.631 | Acc: 40.044,61.255,76.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.636 | Acc: 39.958,61.127,76.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.642 | Acc: 39.865,61.096,76.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.650 | Acc: 39.717,60.979,76.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.651 | Acc: 39.741,60.997,76.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.654 | Acc: 39.768,60.994,76.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.655 | Acc: 39.797,61.024,76.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.509 | Acc: 33.594,56.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.699 | Acc: 34.040,52.009,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.730 | Acc: 32.793,51.467,60.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.779 | Acc: 32.364,50.858,60.387,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.455 | Acc: 43.750,63.281,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.534 | Acc: 43.155,62.984,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.590 | Acc: 41.349,62.386,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.613 | Acc: 40.817,61.360,76.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.609 | Acc: 40.673,61.728,77.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.605 | Acc: 40.710,61.765,77.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.606 | Acc: 40.702,61.880,76.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.599 | Acc: 40.808,61.863,77.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.603 | Acc: 40.567,61.903,77.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.610 | Acc: 40.388,61.658,77.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.614 | Acc: 40.314,61.587,76.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.623 | Acc: 40.116,61.408,76.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.623 | Acc: 40.181,61.482,76.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.625 | Acc: 40.185,61.321,76.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.630 | Acc: 40.250,61.149,76.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.633 | Acc: 40.181,61.075,76.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.636 | Acc: 40.099,61.105,76.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.640 | Acc: 40.075,61.086,76.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.644 | Acc: 40.034,61.011,76.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.645 | Acc: 40.065,61.026,76.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.219 | Acc: 28.125,50.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.131 | Acc: 28.609,49.740,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.088 | Acc: 28.792,49.352,60.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.092 | Acc: 28.420,48.860,60.220,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 2.668 | Acc: 38.281,57.031,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.565 | Acc: 40.997,62.054,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.563 | Acc: 39.634,61.890,78.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.596 | Acc: 38.986,61.514,77.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.629 | Acc: 39.024,60.957,77.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.625 | Acc: 39.356,60.922,77.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.637 | Acc: 39.282,61.034,76.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.644 | Acc: 39.190,60.899,76.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.636 | Acc: 39.315,60.923,76.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.633 | Acc: 39.347,60.942,76.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.632 | Acc: 39.381,60.961,76.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.630 | Acc: 39.437,61.051,76.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.637 | Acc: 39.497,60.970,76.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.641 | Acc: 39.410,60.908,76.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.642 | Acc: 39.468,60.893,76.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.646 | Acc: 39.475,60.901,76.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.646 | Acc: 39.498,60.857,76.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.649 | Acc: 39.541,60.763,76.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.651 | Acc: 39.521,60.821,76.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.657 | Acc: 39.458,60.751,75.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.824 | Acc: 34.375,45.312,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.070 | Acc: 29.315,47.247,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.078 | Acc: 29.040,46.989,58.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.111 | Acc: 28.996,46.683,58.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 2.442 | Acc: 47.656,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.563 | Acc: 40.699,62.500,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.568 | Acc: 39.939,61.890,78.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.579 | Acc: 40.023,61.424,77.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.571 | Acc: 40.210,61.690,77.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.578 | Acc: 40.207,61.835,77.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.579 | Acc: 40.528,61.938,77.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.589 | Acc: 40.414,61.963,77.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.595 | Acc: 40.397,61.981,77.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.603 | Acc: 40.323,61.758,77.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.607 | Acc: 40.190,61.703,77.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.611 | Acc: 40.109,61.588,77.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.615 | Acc: 40.304,61.534,76.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.624 | Acc: 40.248,61.437,76.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.624 | Acc: 40.252,61.427,76.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.627 | Acc: 40.207,61.376,76.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.626 | Acc: 40.172,61.339,76.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.634 | Acc: 40.121,61.371,76.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.632 | Acc: 40.155,61.437,76.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.640 | Acc: 40.082,61.311,76.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.484 | Acc: 26.562,40.625,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 25.893,40.885,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 24.657,40.415,53.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 24.232,39.857,53.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 2.436 | Acc: 48.438,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.606 | Acc: 39.435,60.826,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.598 | Acc: 40.587,60.995,77.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.603 | Acc: 40.676,61.014,77.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.605 | Acc: 40.509,61.208,77.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.612 | Acc: 40.347,61.108,77.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.611 | Acc: 40.476,61.299,77.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.615 | Acc: 40.270,61.303,76.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.614 | Acc: 40.276,61.423,76.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.615 | Acc: 40.228,61.365,76.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.611 | Acc: 40.209,61.287,76.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.615 | Acc: 40.208,61.351,76.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.616 | Acc: 40.278,61.424,76.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.611 | Acc: 40.245,61.548,76.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.617 | Acc: 40.236,61.441,76.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.622 | Acc: 40.210,61.402,76.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.626 | Acc: 40.141,61.317,76.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.632 | Acc: 40.034,61.245,76.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.639 | Acc: 40.000,61.152,76.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.641 | Acc: 40.045,61.184,76.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.215 | Acc: 32.812,43.750,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.087 | Acc: 29.501,47.545,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.128 | Acc: 29.268,46.532,58.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.163 | Acc: 28.778,45.799,57.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 2.414 | Acc: 51.562,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.601 | Acc: 40.811,62.909,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.575 | Acc: 40.720,62.557,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.589 | Acc: 40.523,62.154,77.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.610 | Acc: 39.940,61.622,77.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.614 | Acc: 39.735,61.556,77.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.614 | Acc: 39.657,61.538,77.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.611 | Acc: 39.694,61.503,77.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.618 | Acc: 39.766,61.471,77.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.618 | Acc: 39.943,61.512,77.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.626 | Acc: 39.762,61.373,77.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.619 | Acc: 39.957,61.432,77.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.617 | Acc: 40.080,61.388,77.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.612 | Acc: 40.308,61.569,77.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.618 | Acc: 40.186,61.521,76.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.623 | Acc: 40.124,61.485,76.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.625 | Acc: 40.000,61.397,76.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.626 | Acc: 39.993,61.343,76.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.630 | Acc: 39.967,61.336,76.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.637 | Acc: 39.995,61.259,76.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.949 | Acc: 25.781,44.531,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.898 | Acc: 28.311,47.619,62.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.934 | Acc: 27.934,47.161,61.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.962 | Acc: 27.882,47.426,61.066,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 2.317 | Acc: 42.969,61.719,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.543 | Acc: 40.513,61.607,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.586 | Acc: 39.101,61.814,78.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.570 | Acc: 39.165,61.962,77.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.573 | Acc: 39.352,61.651,77.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.574 | Acc: 39.519,61.572,77.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.571 | Acc: 39.534,62.022,77.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.572 | Acc: 39.711,61.974,77.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.579 | Acc: 39.892,61.884,77.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.582 | Acc: 39.848,61.701,77.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.587 | Acc: 39.762,61.625,77.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.591 | Acc: 39.840,61.439,77.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.594 | Acc: 39.902,61.369,77.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.602 | Acc: 39.990,61.345,77.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.606 | Acc: 40.019,61.282,76.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.611 | Acc: 40.002,61.259,76.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.617 | Acc: 39.805,61.132,76.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.627 | Acc: 39.702,61.061,76.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.630 | Acc: 39.684,61.000,76.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.635 | Acc: 39.639,60.958,76.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.954 | Acc: 26.562,54.688,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.856 | Acc: 28.757,50.037,60.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.868 | Acc: 27.763,49.752,60.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.876 | Acc: 27.395,49.449,60.617,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 2.887 | Acc: 33.594,53.125,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.559 | Acc: 40.365,61.570,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.553 | Acc: 40.320,62.005,78.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.568 | Acc: 40.138,61.373,77.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.573 | Acc: 39.641,61.285,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.591 | Acc: 39.627,61.301,77.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.589 | Acc: 40.115,61.622,77.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.586 | Acc: 40.160,61.503,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.589 | Acc: 40.106,61.607,77.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.597 | Acc: 40.116,61.408,77.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.599 | Acc: 40.213,61.396,77.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.600 | Acc: 40.222,61.461,77.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.609 | Acc: 40.093,61.242,76.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.612 | Acc: 40.113,61.294,76.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.618 | Acc: 39.977,61.246,76.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.619 | Acc: 39.999,61.171,76.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.625 | Acc: 39.963,61.152,76.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.633 | Acc: 39.899,61.059,76.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.636 | Acc: 39.809,61.050,76.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.637 | Acc: 39.825,61.177,76.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.084 | Acc: 35.156,46.875,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.935 | Acc: 30.580,49.628,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.970 | Acc: 30.278,48.133,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.973 | Acc: 30.046,47.720,59.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.274 | Acc: 45.312,70.312,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.479 | Acc: 39.993,63.170,79.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.515 | Acc: 40.130,62.538,78.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.565 | Acc: 39.549,61.847,77.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.553 | Acc: 39.747,62.066,78.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.575 | Acc: 39.496,61.688,77.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.578 | Acc: 39.560,61.699,77.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.584 | Acc: 39.561,61.613,77.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.601 | Acc: 39.456,61.394,77.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.603 | Acc: 39.473,61.291,77.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.598 | Acc: 39.696,61.423,77.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.603 | Acc: 39.681,61.432,77.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.617 | Acc: 39.620,61.346,76.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.613 | Acc: 39.682,61.381,76.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.614 | Acc: 39.752,61.466,76.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.616 | Acc: 39.867,61.436,76.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.615 | Acc: 39.944,61.497,76.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.620 | Acc: 39.977,61.460,76.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.621 | Acc: 39.958,61.401,76.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.629 | Acc: 40.010,61.290,76.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.980 | Acc: 22.656,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.972 | Acc: 28.199,48.289,60.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.962 | Acc: 27.973,47.885,60.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.987 | Acc: 27.920,47.246,60.067,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 2.654 | Acc: 34.375,58.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.532 | Acc: 40.513,61.756,79.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.516 | Acc: 40.625,62.481,78.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.564 | Acc: 39.639,61.911,78.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.558 | Acc: 40.017,62.153,78.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.555 | Acc: 39.875,62.020,78.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.573 | Acc: 39.592,61.867,77.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.582 | Acc: 39.860,61.807,77.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.589 | Acc: 39.878,61.942,77.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.589 | Acc: 39.934,61.809,77.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.593 | Acc: 39.988,61.816,77.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.595 | Acc: 40.084,61.867,77.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.601 | Acc: 40.061,61.816,77.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.609 | Acc: 40.053,61.680,76.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.614 | Acc: 40.075,61.594,76.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.617 | Acc: 39.968,61.612,76.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.626 | Acc: 39.924,61.432,76.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.633 | Acc: 39.844,61.309,76.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.638 | Acc: 39.822,61.288,76.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.647 | Acc: 39.797,61.190,76.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.055 | Acc: 29.688,47.656,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.968 | Acc: 27.753,49.665,61.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.984 | Acc: 27.248,49.600,60.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.020 | Acc: 27.177,49.103,60.246,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.405 | Acc: 46.094,63.281,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.569 | Acc: 41.295,62.314,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.530 | Acc: 41.139,62.176,78.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.532 | Acc: 40.599,62.205,78.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.537 | Acc: 40.461,62.018,78.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.548 | Acc: 40.849,62.175,78.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.556 | Acc: 40.877,62.403,78.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.563 | Acc: 40.786,62.334,78.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.572 | Acc: 40.518,62.175,77.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.574 | Acc: 40.517,62.038,77.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.587 | Acc: 40.415,61.839,77.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.600 | Acc: 40.296,61.634,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.601 | Acc: 40.236,61.625,77.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.603 | Acc: 40.128,61.695,77.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.599 | Acc: 40.152,61.836,77.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.599 | Acc: 40.114,61.836,77.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.608 | Acc: 40.085,61.724,77.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.614 | Acc: 39.972,61.648,76.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.620 | Acc: 39.924,61.563,76.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.626 | Acc: 39.905,61.481,76.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.258 | Acc: 28.125,42.188,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.417 | Acc: 27.232,43.192,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.450 | Acc: 26.829,43.045,57.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.470 | Acc: 26.025,42.354,57.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.531 | Acc: 40.625,61.719,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.634 | Acc: 39.509,61.830,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.613 | Acc: 39.405,62.252,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.588 | Acc: 40.049,62.935,77.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.579 | Acc: 40.085,63.030,77.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.570 | Acc: 39.991,62.864,77.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.586 | Acc: 39.882,62.500,77.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.587 | Acc: 40.032,62.373,77.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.585 | Acc: 40.159,62.311,77.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.591 | Acc: 40.107,62.297,77.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.597 | Acc: 40.073,62.205,76.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.597 | Acc: 40.158,62.161,76.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.601 | Acc: 40.148,62.033,76.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.604 | Acc: 40.206,61.853,76.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.605 | Acc: 40.250,61.874,76.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.616 | Acc: 40.049,61.656,76.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.617 | Acc: 40.021,61.699,76.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.618 | Acc: 40.022,61.648,76.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.620 | Acc: 40.071,61.678,76.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.624 | Acc: 40.104,61.643,76.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.900 | Acc: 33.594,48.438,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.010 | Acc: 30.283,49.070,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.081 | Acc: 28.563,47.809,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.120 | Acc: 28.112,47.720,57.979,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 2.503 | Acc: 33.594,60.938,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.551 | Acc: 40.179,61.533,78.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.552 | Acc: 40.263,61.700,77.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.588 | Acc: 40.087,61.424,77.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.595 | Acc: 39.892,61.343,77.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.592 | Acc: 40.022,61.324,77.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.585 | Acc: 40.386,61.667,77.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.588 | Acc: 40.475,61.641,77.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.585 | Acc: 40.528,61.855,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.598 | Acc: 40.245,61.719,76.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.603 | Acc: 40.283,61.808,76.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.601 | Acc: 40.370,61.878,76.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.612 | Acc: 40.265,61.716,76.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.614 | Acc: 40.293,61.728,76.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.617 | Acc: 40.308,61.655,76.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.622 | Acc: 40.199,61.537,76.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.629 | Acc: 40.111,61.407,76.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.632 | Acc: 40.169,61.405,76.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.634 | Acc: 40.075,61.420,76.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.637 | Acc: 40.030,61.399,76.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.851 | Acc: 26.562,53.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.056 | Acc: 24.777,48.140,59.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.100 | Acc: 24.143,47.218,58.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.115 | Acc: 24.065,46.580,58.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.692 | Acc: 39.844,60.156,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.641 | Acc: 39.211,60.231,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.592 | Acc: 40.206,61.395,76.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.576 | Acc: 40.548,62.026,77.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.565 | Acc: 40.519,61.921,77.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.562 | Acc: 40.818,61.966,77.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.563 | Acc: 40.489,61.874,77.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.569 | Acc: 40.459,61.763,77.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.579 | Acc: 40.382,61.578,77.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.580 | Acc: 40.193,61.585,77.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.580 | Acc: 40.217,61.692,77.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.584 | Acc: 40.250,61.666,77.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.591 | Acc: 40.278,61.722,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.594 | Acc: 40.263,61.602,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.599 | Acc: 40.133,61.569,77.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.605 | Acc: 39.981,61.485,77.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.604 | Acc: 40.065,61.468,77.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.606 | Acc: 40.087,61.478,76.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.615 | Acc: 39.954,61.329,76.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.620 | Acc: 39.954,61.321,76.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.095 | Acc: 32.812,48.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.084 | Acc: 26.637,47.805,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.088 | Acc: 26.029,47.104,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.091 | Acc: 25.717,47.144,59.093,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 2.600 | Acc: 40.625,64.844,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.578 | Acc: 39.137,61.235,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.590 | Acc: 39.253,61.833,77.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.574 | Acc: 39.101,62.013,78.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.568 | Acc: 39.632,62.240,78.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.583 | Acc: 39.650,61.796,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.573 | Acc: 39.682,61.964,78.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.577 | Acc: 39.750,61.763,78.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.590 | Acc: 39.839,61.690,77.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.602 | Acc: 39.826,61.425,77.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.606 | Acc: 39.832,61.353,77.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.618 | Acc: 39.713,61.224,77.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.611 | Acc: 39.789,61.427,77.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.611 | Acc: 39.966,61.452,77.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.611 | Acc: 40.055,61.463,77.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.617 | Acc: 40.072,61.361,76.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.619 | Acc: 40.092,61.376,76.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.622 | Acc: 40.098,61.419,76.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.623 | Acc: 40.088,61.476,76.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.623 | Acc: 40.127,61.530,76.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.025 | Acc: 38.281,39.062,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.202 | Acc: 29.539,44.085,57.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.230 | Acc: 28.792,43.636,57.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.227 | Acc: 28.586,43.430,57.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 2.359 | Acc: 34.375,65.625,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.549 | Acc: 40.476,62.760,78.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.553 | Acc: 39.691,62.005,78.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.553 | Acc: 40.190,62.602,78.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.565 | Acc: 40.230,62.625,78.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.558 | Acc: 40.153,62.577,78.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.555 | Acc: 40.483,62.500,78.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.551 | Acc: 40.525,62.450,78.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.563 | Acc: 40.455,62.136,78.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.562 | Acc: 40.569,62.206,78.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.569 | Acc: 40.442,62.076,77.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.580 | Acc: 40.353,61.846,77.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.589 | Acc: 40.340,61.754,77.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.599 | Acc: 40.230,61.581,77.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.603 | Acc: 40.088,61.405,77.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.603 | Acc: 40.140,61.537,77.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.603 | Acc: 40.231,61.597,77.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.606 | Acc: 40.206,61.625,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.609 | Acc: 40.162,61.617,76.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.611 | Acc: 40.221,61.602,76.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.502 | Acc: 41.406,53.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.560 | Acc: 36.496,51.823,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.573 | Acc: 34.889,51.029,61.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.573 | Acc: 34.682,50.909,61.578,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.547 | Acc: 36.719,53.125,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.553 | Acc: 40.625,60.751,78.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.522 | Acc: 40.530,61.738,79.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.525 | Acc: 40.241,61.616,79.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.516 | Acc: 40.586,61.931,79.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.534 | Acc: 40.176,61.734,78.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.540 | Acc: 40.405,61.958,78.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.542 | Acc: 40.370,62.118,78.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.555 | Acc: 40.509,61.903,78.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.566 | Acc: 40.344,61.779,78.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.573 | Acc: 40.252,61.680,77.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.575 | Acc: 40.328,61.779,77.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.583 | Acc: 40.239,61.677,77.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.588 | Acc: 40.341,61.713,77.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.595 | Acc: 40.286,61.719,77.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.601 | Acc: 40.329,61.675,77.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.602 | Acc: 40.352,61.758,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.603 | Acc: 40.304,61.710,77.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.607 | Acc: 40.333,61.688,76.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.610 | Acc: 40.198,61.667,76.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.892 | Acc: 21.875,40.625,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.020 | Acc: 19.978,39.881,54.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.061 | Acc: 20.141,39.710,53.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.094 | Acc: 19.237,39.357,53.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 2.677 | Acc: 33.594,59.375,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.537 | Acc: 40.513,61.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.449 | Acc: 40.739,63.510,79.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.391 | Acc: 41.496,64.485,81.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.366 | Acc: 41.599,64.718,81.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.328 | Acc: 41.932,65.377,82.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.304 | Acc: 42.142,65.780,82.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.281 | Acc: 42.658,66.096,82.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.260 | Acc: 43.080,66.479,83.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.249 | Acc: 43.085,66.695,83.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.240 | Acc: 43.186,66.822,83.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.227 | Acc: 43.177,67.018,83.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.220 | Acc: 43.238,67.162,83.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.218 | Acc: 43.229,67.149,83.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.212 | Acc: 43.275,67.249,83.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.203 | Acc: 43.454,67.426,84.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.199 | Acc: 43.643,67.501,84.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.196 | Acc: 43.661,67.488,84.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.193 | Acc: 43.670,67.562,84.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.188 | Acc: 43.688,67.639,84.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.860 | Acc: 49.219,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.822 | Acc: 42.262,61.607,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 41.368,60.899,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.836 | Acc: 41.086,61.040,71.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.889 | Acc: 43.750,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.018 | Acc: 45.089,69.196,88.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.064 | Acc: 44.188,69.264,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.085 | Acc: 43.865,68.776,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.076 | Acc: 44.184,69.165,87.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.068 | Acc: 44.291,69.106,86.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.061 | Acc: 44.525,69.292,87.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.054 | Acc: 44.537,69.404,87.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.054 | Acc: 44.599,69.439,87.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.057 | Acc: 44.553,69.389,86.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.050 | Acc: 44.675,69.492,87.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.048 | Acc: 44.708,69.496,87.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.050 | Acc: 44.616,69.567,87.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.053 | Acc: 44.585,69.501,86.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.053 | Acc: 44.640,69.434,86.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.053 | Acc: 44.619,69.401,86.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.056 | Acc: 44.604,69.375,86.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.055 | Acc: 44.687,69.378,86.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.056 | Acc: 44.676,69.349,86.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.057 | Acc: 44.609,69.293,86.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.799 | Acc: 50.000,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.816 | Acc: 42.522,63.132,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.824 | Acc: 41.711,62.005,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.830 | Acc: 41.329,61.655,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 2.074 | Acc: 41.406,69.531,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.031 | Acc: 44.643,69.643,87.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.007 | Acc: 44.607,70.465,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.017 | Acc: 44.647,70.530,88.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.011 | Acc: 44.782,70.409,87.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.005 | Acc: 44.910,70.382,88.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.003 | Acc: 45.061,70.345,88.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.003 | Acc: 45.124,70.246,88.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.007 | Acc: 45.177,70.143,87.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.005 | Acc: 45.200,70.110,88.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.012 | Acc: 44.955,69.947,87.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.011 | Acc: 44.952,69.924,87.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.011 | Acc: 45.008,69.927,87.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.010 | Acc: 45.076,69.950,87.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.006 | Acc: 45.140,70.023,87.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.007 | Acc: 45.149,69.975,88.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.008 | Acc: 45.086,69.986,88.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.006 | Acc: 45.129,70.090,87.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.009 | Acc: 45.116,69.968,87.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.011 | Acc: 45.081,69.919,87.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.896 | Acc: 45.312,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.837 | Acc: 42.150,61.979,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.850 | Acc: 41.178,61.471,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.854 | Acc: 40.753,61.424,71.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 2.056 | Acc: 50.781,67.969,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 45.945,70.275,88.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.992 | Acc: 45.446,69.950,88.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.992 | Acc: 45.133,69.787,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.971 | Acc: 45.428,70.216,88.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.978 | Acc: 45.065,70.243,88.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.975 | Acc: 45.009,70.229,88.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.980 | Acc: 45.102,70.069,88.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.981 | Acc: 44.968,70.012,88.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.985 | Acc: 44.868,69.915,88.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.983 | Acc: 44.947,70.021,88.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.987 | Acc: 44.980,70.005,88.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.992 | Acc: 44.813,69.855,88.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.994 | Acc: 44.744,69.861,88.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.993 | Acc: 44.740,69.948,88.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.989 | Acc: 44.900,70.079,88.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.988 | Acc: 44.911,70.188,88.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.985 | Acc: 44.925,70.287,88.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.986 | Acc: 44.923,70.315,88.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.987 | Acc: 44.923,70.345,88.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.807 | Acc: 46.875,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.804 | Acc: 43.266,62.946,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.816 | Acc: 42.111,62.271,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.826 | Acc: 41.598,62.154,71.171,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.993 | Acc: 42.969,70.312,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.936 | Acc: 46.019,70.945,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.924 | Acc: 45.846,71.132,89.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.940 | Acc: 45.453,70.876,89.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.943 | Acc: 44.850,70.785,89.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.948 | Acc: 44.848,70.661,89.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.950 | Acc: 44.835,70.500,89.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.945 | Acc: 45.024,70.739,89.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.946 | Acc: 45.012,70.812,89.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.953 | Acc: 45.023,70.520,89.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.956 | Acc: 44.982,70.371,89.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.957 | Acc: 45.051,70.514,89.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.958 | Acc: 45.076,70.513,89.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.957 | Acc: 45.097,70.558,89.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.957 | Acc: 45.085,70.649,89.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.958 | Acc: 44.960,70.715,89.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.960 | Acc: 44.955,70.629,89.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.962 | Acc: 44.877,70.562,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.963 | Acc: 44.862,70.518,89.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.959 | Acc: 44.974,70.598,89.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.781 | Acc: 49.219,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.833 | Acc: 42.597,63.579,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.839 | Acc: 41.883,62.424,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.847 | Acc: 41.304,62.334,71.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.875 | Acc: 45.312,77.344,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.908 | Acc: 45.536,72.693,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.920 | Acc: 45.941,72.180,89.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.911 | Acc: 46.068,72.221,90.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.924 | Acc: 46.007,71.692,89.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.924 | Acc: 45.970,71.736,89.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.922 | Acc: 45.913,71.533,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.926 | Acc: 45.673,71.476,89.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.931 | Acc: 45.463,71.453,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.930 | Acc: 45.425,71.361,89.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.931 | Acc: 45.449,71.137,89.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.931 | Acc: 45.394,70.981,89.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.935 | Acc: 45.325,70.886,89.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.936 | Acc: 45.312,70.911,89.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.933 | Acc: 45.365,70.983,89.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.932 | Acc: 45.388,71.068,89.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.930 | Acc: 45.519,71.130,89.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.932 | Acc: 45.558,71.053,89.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.934 | Acc: 45.464,71.027,89.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.935 | Acc: 45.464,70.983,89.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.962 | Acc: 46.094,56.250,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.807 | Acc: 43.006,63.021,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.817 | Acc: 42.054,62.271,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.826 | Acc: 41.534,62.282,71.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 2.022 | Acc: 42.188,67.188,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.895 | Acc: 45.350,71.057,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.921 | Acc: 44.893,71.094,90.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.895 | Acc: 45.402,71.427,90.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.898 | Acc: 45.033,71.576,90.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.915 | Acc: 44.856,71.318,90.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.919 | Acc: 44.977,71.191,89.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.917 | Acc: 45.157,71.398,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.914 | Acc: 45.380,71.390,89.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.914 | Acc: 45.464,71.392,89.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.915 | Acc: 45.417,71.265,89.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.918 | Acc: 45.429,71.271,89.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.920 | Acc: 45.387,71.256,89.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.919 | Acc: 45.399,71.264,89.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.919 | Acc: 45.326,71.238,89.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.919 | Acc: 45.310,71.299,89.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.920 | Acc: 45.371,71.252,89.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.920 | Acc: 45.349,71.240,89.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.921 | Acc: 45.354,71.224,89.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.923 | Acc: 45.378,71.248,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.854 | Acc: 46.875,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.818 | Acc: 42.820,63.021,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.828 | Acc: 42.226,62.443,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.838 | Acc: 41.688,62.590,71.324,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.656 | Acc: 54.688,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.910 | Acc: 44.978,70.982,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.905 | Acc: 45.351,70.655,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.893 | Acc: 45.325,71.119,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.897 | Acc: 45.775,70.814,90.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.901 | Acc: 45.599,70.699,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.908 | Acc: 45.377,70.538,90.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.900 | Acc: 45.484,70.988,90.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.909 | Acc: 45.279,70.885,90.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.906 | Acc: 45.351,71.012,90.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.907 | Acc: 45.499,71.012,90.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.911 | Acc: 45.327,70.984,90.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.914 | Acc: 45.264,70.912,90.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.914 | Acc: 45.399,70.998,90.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.915 | Acc: 45.340,70.996,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.912 | Acc: 45.338,71.006,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.908 | Acc: 45.441,71.140,90.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.905 | Acc: 45.500,71.238,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.902 | Acc: 45.503,71.282,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.903 | Acc: 45.479,71.334,90.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.793 | Acc: 46.094,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 43.527,62.798,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.821 | Acc: 42.721,62.500,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.837 | Acc: 42.188,62.039,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.717 | Acc: 51.562,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.863 | Acc: 45.908,73.289,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.896 | Acc: 44.798,71.742,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.880 | Acc: 44.903,72.054,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.884 | Acc: 45.187,71.856,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.878 | Acc: 45.490,71.774,91.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.881 | Acc: 45.364,71.604,91.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.888 | Acc: 45.274,71.581,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.892 | Acc: 45.332,71.390,91.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.890 | Acc: 45.386,71.603,90.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.886 | Acc: 45.530,71.716,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.885 | Acc: 45.415,71.674,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.889 | Acc: 45.306,71.577,90.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.885 | Acc: 45.447,71.636,90.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.882 | Acc: 45.468,71.586,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.883 | Acc: 45.538,71.517,90.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.883 | Acc: 45.546,71.498,90.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.884 | Acc: 45.599,71.513,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.882 | Acc: 45.667,71.507,90.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.883 | Acc: 45.667,71.537,90.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.870 | Acc: 46.094,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.823 | Acc: 43.601,63.207,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.844 | Acc: 42.340,62.538,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.855 | Acc: 42.059,62.423,71.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 2.133 | Acc: 37.500,71.094,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.901 | Acc: 43.862,71.540,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.893 | Acc: 44.531,70.922,90.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.880 | Acc: 44.685,71.452,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.873 | Acc: 44.608,71.644,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.881 | Acc: 44.415,71.403,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.885 | Acc: 44.667,71.132,90.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.884 | Acc: 44.864,71.193,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.881 | Acc: 45.075,71.244,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.884 | Acc: 44.972,71.305,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.886 | Acc: 45.114,71.257,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.887 | Acc: 45.157,71.334,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.884 | Acc: 45.128,71.363,90.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 45.307,71.429,90.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.883 | Acc: 45.299,71.433,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.882 | Acc: 45.320,71.447,90.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.883 | Acc: 45.337,71.444,90.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.883 | Acc: 45.340,71.382,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.881 | Acc: 45.367,71.410,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.882 | Acc: 45.335,71.412,90.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.942 | Acc: 48.438,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.857 | Acc: 42.634,62.872,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.875 | Acc: 41.940,61.852,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.888 | Acc: 41.662,62.116,70.863,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.794 | Acc: 51.562,71.094,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.811 | Acc: 46.726,74.070,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.831 | Acc: 45.922,73.037,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.845 | Acc: 45.594,72.605,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.832 | Acc: 45.775,72.541,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.842 | Acc: 45.792,72.277,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.844 | Acc: 45.777,72.056,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.847 | Acc: 45.783,71.980,91.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.853 | Acc: 45.807,71.991,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.856 | Acc: 45.843,71.888,91.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.854 | Acc: 45.962,71.957,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.854 | Acc: 45.896,71.889,91.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.853 | Acc: 45.896,71.956,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.858 | Acc: 45.788,71.821,91.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.856 | Acc: 45.819,71.805,91.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.854 | Acc: 45.845,71.870,91.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.857 | Acc: 45.816,71.758,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.856 | Acc: 45.780,71.802,91.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.858 | Acc: 45.776,71.732,91.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.861 | Acc: 45.749,71.688,91.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.880 | Acc: 48.438,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.856 | Acc: 43.118,62.426,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.864 | Acc: 42.226,62.081,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.878 | Acc: 41.688,62.180,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 2.014 | Acc: 41.406,69.531,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.916 | Acc: 43.118,71.615,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.893 | Acc: 44.912,71.037,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.886 | Acc: 45.581,71.004,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.882 | Acc: 45.679,71.277,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.875 | Acc: 45.916,71.597,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.874 | Acc: 45.848,71.694,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.865 | Acc: 45.844,71.759,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.868 | Acc: 45.691,71.671,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.859 | Acc: 45.787,71.698,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.858 | Acc: 45.783,71.747,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.854 | Acc: 45.878,71.843,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.858 | Acc: 45.886,71.804,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.855 | Acc: 45.920,72.004,91.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.854 | Acc: 45.907,72.020,91.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.856 | Acc: 45.852,71.930,91.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.856 | Acc: 45.909,71.921,91.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.855 | Acc: 45.910,71.987,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.856 | Acc: 45.886,71.962,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.858 | Acc: 45.772,71.854,91.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.870 | Acc: 44.531,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.844 | Acc: 42.969,62.835,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.856 | Acc: 42.264,62.176,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.869 | Acc: 41.662,62.090,70.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.612 | Acc: 44.531,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.862 | Acc: 44.494,71.615,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.830 | Acc: 45.084,72.580,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.823 | Acc: 45.825,72.759,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.823 | Acc: 46.132,72.637,91.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.831 | Acc: 46.287,72.486,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.832 | Acc: 46.262,72.443,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.836 | Acc: 46.149,72.335,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.829 | Acc: 46.137,72.486,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.833 | Acc: 46.012,72.436,91.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.833 | Acc: 46.129,72.446,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.833 | Acc: 46.182,72.540,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.833 | Acc: 46.113,72.449,91.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.835 | Acc: 46.085,72.498,91.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.840 | Acc: 46.030,72.320,91.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.841 | Acc: 45.941,72.275,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.845 | Acc: 45.836,72.172,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.844 | Acc: 45.794,72.155,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.845 | Acc: 45.810,72.098,91.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.847 | Acc: 45.864,72.066,91.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.907 | Acc: 46.875,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.845 | Acc: 43.601,63.318,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.863 | Acc: 42.378,62.691,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.881 | Acc: 41.803,62.436,71.171,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.771 | Acc: 46.094,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.806 | Acc: 46.094,73.400,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.816 | Acc: 46.075,73.114,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.820 | Acc: 46.209,72.733,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.808 | Acc: 46.171,72.820,92.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.813 | Acc: 46.341,72.687,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.811 | Acc: 46.462,72.488,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.810 | Acc: 46.133,72.407,92.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.813 | Acc: 46.069,72.355,92.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.811 | Acc: 46.146,72.272,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.812 | Acc: 46.125,72.330,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.816 | Acc: 46.065,72.225,92.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.820 | Acc: 45.831,72.225,92.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.822 | Acc: 45.824,72.216,92.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.822 | Acc: 45.932,72.217,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.822 | Acc: 45.855,72.285,92.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.824 | Acc: 45.833,72.199,92.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.825 | Acc: 45.844,72.109,92.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.827 | Acc: 45.944,72.070,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.826 | Acc: 45.989,72.152,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.984 | Acc: 46.875,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.856 | Acc: 43.824,63.839,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.872 | Acc: 42.130,62.691,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.888 | Acc: 41.816,62.602,70.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.775 | Acc: 43.750,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.788 | Acc: 46.577,73.847,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.777 | Acc: 47.428,73.228,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.790 | Acc: 46.683,72.759,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.789 | Acc: 46.267,72.685,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.797 | Acc: 46.218,72.672,92.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.798 | Acc: 45.919,72.701,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.808 | Acc: 45.745,72.357,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.810 | Acc: 45.754,72.326,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.809 | Acc: 45.671,72.376,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.812 | Acc: 45.717,72.376,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.818 | Acc: 45.673,72.225,91.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.818 | Acc: 45.633,72.189,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.817 | Acc: 45.714,72.279,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.820 | Acc: 45.777,72.261,91.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.822 | Acc: 45.767,72.215,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.820 | Acc: 45.811,72.262,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.821 | Acc: 45.862,72.262,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.825 | Acc: 45.815,72.161,91.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.829 | Acc: 45.839,72.090,91.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.891 | Acc: 48.438,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.886 | Acc: 44.085,62.314,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.889 | Acc: 42.702,61.757,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.897 | Acc: 42.431,62.001,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.684 | Acc: 48.438,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.823 | Acc: 46.615,71.949,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.799 | Acc: 47.085,72.237,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.815 | Acc: 46.427,71.965,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.809 | Acc: 46.499,72.377,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.801 | Acc: 46.643,72.532,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.803 | Acc: 46.468,72.379,92.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.811 | Acc: 46.271,72.174,92.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.808 | Acc: 46.341,72.331,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.810 | Acc: 46.141,72.263,92.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.810 | Acc: 46.171,72.303,92.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.820 | Acc: 45.981,72.137,92.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.821 | Acc: 45.980,72.144,92.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.820 | Acc: 46.037,72.222,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.819 | Acc: 45.963,72.292,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.816 | Acc: 45.938,72.415,92.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.819 | Acc: 45.919,72.362,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.819 | Acc: 45.993,72.274,92.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.823 | Acc: 45.973,72.210,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.823 | Acc: 45.932,72.156,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.993 | Acc: 47.656,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.866 | Acc: 43.527,62.946,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.879 | Acc: 41.978,62.024,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.890 | Acc: 41.637,62.013,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.980 | Acc: 40.625,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.749 | Acc: 46.912,73.624,93.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.768 | Acc: 46.589,72.752,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.780 | Acc: 46.401,72.682,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.785 | Acc: 46.518,72.569,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.779 | Acc: 46.581,72.710,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.790 | Acc: 46.100,72.392,92.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.793 | Acc: 46.133,72.324,92.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.799 | Acc: 46.084,72.268,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.796 | Acc: 46.012,72.376,92.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.801 | Acc: 45.985,72.357,92.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.800 | Acc: 46.005,72.306,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.803 | Acc: 46.097,72.329,92.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.806 | Acc: 45.971,72.318,92.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.805 | Acc: 45.871,72.387,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.805 | Acc: 45.850,72.329,92.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.808 | Acc: 45.797,72.335,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.811 | Acc: 45.741,72.248,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.813 | Acc: 45.739,72.154,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.814 | Acc: 45.723,72.088,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.921 | Acc: 50.000,56.250,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.891 | Acc: 43.601,62.500,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.892 | Acc: 42.607,62.367,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.895 | Acc: 42.200,62.295,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.779 | Acc: 46.094,69.531,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.830 | Acc: 43.973,71.652,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.795 | Acc: 45.846,72.142,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 46.222,72.579,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.801 | Acc: 46.084,72.328,92.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.791 | Acc: 46.063,72.424,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.806 | Acc: 45.622,71.940,92.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.803 | Acc: 45.806,72.008,92.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.800 | Acc: 45.968,72.113,92.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.801 | Acc: 45.956,72.143,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.800 | Acc: 46.000,72.244,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.799 | Acc: 46.115,72.278,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.801 | Acc: 46.110,72.232,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.799 | Acc: 46.216,72.216,92.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.802 | Acc: 46.091,72.200,92.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.802 | Acc: 46.026,72.298,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.803 | Acc: 46.052,72.289,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.803 | Acc: 46.048,72.299,92.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.805 | Acc: 46.131,72.314,92.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.805 | Acc: 46.174,72.279,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.947 | Acc: 47.656,56.250,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.923 | Acc: 43.750,62.537,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.923 | Acc: 42.511,62.233,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 42.072,62.103,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.685 | Acc: 46.094,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.816 | Acc: 46.726,72.582,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.801 | Acc: 46.608,72.428,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.800 | Acc: 45.620,72.349,92.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.786 | Acc: 45.853,72.608,93.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.787 | Acc: 45.962,72.734,93.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.795 | Acc: 45.868,72.534,92.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.799 | Acc: 45.844,72.534,92.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.801 | Acc: 45.968,72.491,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.797 | Acc: 45.878,72.475,92.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.798 | Acc: 45.896,72.481,92.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.795 | Acc: 45.995,72.571,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.794 | Acc: 46.045,72.429,92.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.797 | Acc: 46.106,72.417,92.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.799 | Acc: 45.983,72.364,92.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.798 | Acc: 46.000,72.407,92.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.802 | Acc: 45.989,72.313,92.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.803 | Acc: 46.071,72.297,92.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.802 | Acc: 46.122,72.271,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.802 | Acc: 46.163,72.269,92.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.976 | Acc: 45.312,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.898 | Acc: 42.969,62.984,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 41.787,62.100,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.928 | Acc: 41.650,61.898,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.952 | Acc: 45.312,71.875,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.768 | Acc: 45.982,72.247,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.769 | Acc: 46.989,72.008,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.771 | Acc: 47.272,72.234,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.764 | Acc: 47.039,72.483,92.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.766 | Acc: 46.767,72.509,92.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.770 | Acc: 46.701,72.553,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.767 | Acc: 46.681,72.773,93.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.773 | Acc: 46.336,72.690,93.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.773 | Acc: 46.353,72.661,93.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.772 | Acc: 46.218,72.695,93.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.773 | Acc: 46.186,72.624,92.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.774 | Acc: 46.142,72.663,93.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.775 | Acc: 46.246,72.596,92.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.773 | Acc: 46.322,72.617,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.776 | Acc: 46.299,72.641,92.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.777 | Acc: 46.281,72.612,92.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.778 | Acc: 46.204,72.574,92.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.780 | Acc: 46.161,72.520,92.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.782 | Acc: 46.100,72.464,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.930 | Acc: 48.438,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.912 | Acc: 43.229,63.058,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.927 | Acc: 42.188,62.024,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 41.688,61.860,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 2.010 | Acc: 38.281,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.787 | Acc: 45.796,72.656,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.760 | Acc: 45.846,72.980,92.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.773 | Acc: 45.774,72.477,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.775 | Acc: 45.756,72.512,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.774 | Acc: 45.699,72.587,92.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.777 | Acc: 45.629,72.566,92.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.780 | Acc: 45.889,72.551,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.780 | Acc: 46.074,72.452,92.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.780 | Acc: 46.180,72.419,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.786 | Acc: 46.175,72.229,92.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.787 | Acc: 46.101,72.094,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.788 | Acc: 46.116,72.154,92.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.788 | Acc: 46.228,72.207,92.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.790 | Acc: 46.177,72.278,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.790 | Acc: 46.089,72.329,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.788 | Acc: 46.142,72.391,92.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.784 | Acc: 46.192,72.457,92.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.787 | Acc: 46.148,72.412,92.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.785 | Acc: 46.211,72.488,92.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.871 | Acc: 46.094,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.927 | Acc: 43.527,62.128,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 42.111,61.776,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.937 | Acc: 42.111,61.808,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.754 | Acc: 46.094,71.094,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.749 | Acc: 45.647,73.698,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.756 | Acc: 46.341,72.923,93.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.743 | Acc: 46.785,73.399,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.737 | Acc: 46.904,73.727,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.752 | Acc: 46.496,73.631,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.751 | Acc: 46.559,73.580,93.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.752 | Acc: 46.509,73.432,93.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.756 | Acc: 46.370,73.205,93.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.754 | Acc: 46.348,73.299,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.753 | Acc: 46.455,73.344,93.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.755 | Acc: 46.352,73.307,93.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.760 | Acc: 46.217,73.201,93.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.759 | Acc: 46.261,73.228,93.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.758 | Acc: 46.291,73.246,93.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.761 | Acc: 46.270,73.165,93.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.765 | Acc: 46.189,73.019,93.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.766 | Acc: 46.124,73.018,93.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.769 | Acc: 46.059,72.873,93.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.769 | Acc: 46.161,72.894,93.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.891 | Acc: 44.531,58.594,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.889 | Acc: 43.638,63.095,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.907 | Acc: 42.664,62.290,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.915 | Acc: 42.508,62.334,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.720 | Acc: 44.531,67.969,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.767 | Acc: 47.768,72.619,93.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.743 | Acc: 46.646,73.323,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.745 | Acc: 46.388,73.322,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.752 | Acc: 46.470,72.917,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.757 | Acc: 46.550,72.881,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.767 | Acc: 46.378,72.424,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.773 | Acc: 46.398,72.146,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.773 | Acc: 46.467,72.355,92.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.773 | Acc: 46.275,72.458,92.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.770 | Acc: 46.238,72.621,93.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.775 | Acc: 46.048,72.465,93.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.770 | Acc: 46.168,72.494,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.771 | Acc: 46.303,72.557,93.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.771 | Acc: 46.352,72.662,92.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.771 | Acc: 46.226,72.744,92.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.770 | Acc: 46.232,72.793,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.772 | Acc: 46.277,72.798,92.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.773 | Acc: 46.243,72.734,92.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.774 | Acc: 46.200,72.753,92.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.904 | Acc: 46.094,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.917 | Acc: 43.787,62.760,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.924 | Acc: 42.416,62.081,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.934 | Acc: 42.111,61.911,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.767 | Acc: 39.062,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.764 | Acc: 45.164,73.065,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.745 | Acc: 45.865,72.961,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.743 | Acc: 46.299,73.079,93.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.739 | Acc: 46.393,73.245,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.733 | Acc: 46.612,73.561,93.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.742 | Acc: 46.546,73.276,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.744 | Acc: 46.471,73.343,93.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.747 | Acc: 46.463,73.370,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.751 | Acc: 46.374,73.222,93.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.747 | Acc: 46.381,73.344,93.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.752 | Acc: 46.232,73.254,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.753 | Acc: 46.295,73.168,93.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.757 | Acc: 46.276,73.075,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.758 | Acc: 46.147,73.062,93.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.759 | Acc: 46.086,72.950,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.759 | Acc: 46.121,72.999,93.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.758 | Acc: 46.117,73.037,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.760 | Acc: 46.128,72.994,93.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.763 | Acc: 46.108,72.941,93.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.970 | Acc: 47.656,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.953 | Acc: 43.192,62.388,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.963 | Acc: 41.787,62.348,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.968 | Acc: 41.470,62.129,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.720 | Acc: 49.219,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.731 | Acc: 46.912,73.103,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.734 | Acc: 46.627,72.637,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.734 | Acc: 46.721,73.092,93.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.731 | Acc: 47.078,73.003,93.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.731 | Acc: 46.937,73.213,93.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.735 | Acc: 47.133,73.431,93.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.743 | Acc: 47.030,73.244,93.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.747 | Acc: 46.991,73.340,93.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.745 | Acc: 46.940,73.243,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.746 | Acc: 46.739,73.208,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.749 | Acc: 46.536,73.211,93.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.754 | Acc: 46.492,73.113,93.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.755 | Acc: 46.501,73.087,93.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.756 | Acc: 46.397,73.065,93.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.757 | Acc: 46.366,72.973,93.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.757 | Acc: 46.417,72.897,93.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.756 | Acc: 46.401,72.885,93.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.757 | Acc: 46.388,72.866,93.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.758 | Acc: 46.366,72.849,93.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.984 | Acc: 46.094,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.929 | Acc: 43.378,63.616,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.949 | Acc: 42.359,62.500,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.964 | Acc: 41.970,62.436,69.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.882 | Acc: 43.750,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.732 | Acc: 46.949,73.475,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.749 | Acc: 46.608,72.885,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.755 | Acc: 46.376,72.810,93.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.752 | Acc: 46.267,73.090,93.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.746 | Acc: 46.457,73.244,93.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.740 | Acc: 46.623,73.224,93.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.745 | Acc: 46.398,73.127,93.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.744 | Acc: 46.429,73.069,93.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.745 | Acc: 46.474,73.153,93.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.749 | Acc: 46.397,73.107,93.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.752 | Acc: 46.362,73.049,93.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.753 | Acc: 46.415,72.987,93.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.755 | Acc: 46.336,72.920,93.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.753 | Acc: 46.316,72.982,93.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.752 | Acc: 46.288,73.033,93.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.754 | Acc: 46.250,72.968,93.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.757 | Acc: 46.256,72.860,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.756 | Acc: 46.237,72.933,93.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.757 | Acc: 46.225,72.863,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.865 | Acc: 50.000,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.937 | Acc: 43.564,63.058,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.963 | Acc: 42.168,62.157,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 41.829,62.052,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.708 | Acc: 43.750,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.749 | Acc: 46.205,72.693,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.759 | Acc: 45.655,72.618,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.737 | Acc: 46.299,72.746,93.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.738 | Acc: 46.026,72.791,93.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.732 | Acc: 46.156,73.051,93.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.733 | Acc: 46.475,73.199,93.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.739 | Acc: 46.504,73.105,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.739 | Acc: 46.671,73.112,93.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.734 | Acc: 46.625,73.200,93.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.735 | Acc: 46.595,73.158,93.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.736 | Acc: 46.730,73.141,93.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.739 | Acc: 46.632,72.971,93.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.742 | Acc: 46.525,72.944,93.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.746 | Acc: 46.425,72.920,93.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.748 | Acc: 46.374,72.833,93.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.748 | Acc: 46.344,72.758,93.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.749 | Acc: 46.341,72.764,93.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.749 | Acc: 46.330,72.788,93.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.748 | Acc: 46.309,72.828,93.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.987 | Acc: 46.875,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.933 | Acc: 43.601,62.760,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.950 | Acc: 42.683,62.367,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.960 | Acc: 42.469,62.218,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.569 | Acc: 44.531,75.781,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.758 | Acc: 45.387,72.024,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.728 | Acc: 45.713,73.075,93.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.732 | Acc: 46.055,72.592,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.737 | Acc: 46.296,73.032,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.743 | Acc: 46.101,72.935,93.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.739 | Acc: 46.132,72.953,93.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.738 | Acc: 46.155,73.050,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.739 | Acc: 46.157,73.234,93.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.737 | Acc: 46.340,73.187,93.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.737 | Acc: 46.269,73.197,93.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.735 | Acc: 46.373,73.296,93.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.736 | Acc: 46.467,73.259,93.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.736 | Acc: 46.492,73.276,93.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.738 | Acc: 46.461,73.424,93.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.739 | Acc: 46.512,73.461,93.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.739 | Acc: 46.573,73.408,93.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.738 | Acc: 46.591,73.362,93.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.745 | Acc: 46.531,73.165,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.746 | Acc: 46.551,73.159,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.996 | Acc: 50.781,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.946 | Acc: 43.936,62.798,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.967 | Acc: 42.645,62.309,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 42.264,62.167,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.734 | Acc: 44.531,70.312,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.719 | Acc: 47.061,73.028,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.714 | Acc: 47.027,73.075,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.730 | Acc: 46.055,73.105,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.732 | Acc: 46.277,73.023,93.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.731 | Acc: 46.488,72.997,93.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.736 | Acc: 46.442,72.837,93.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.737 | Acc: 46.509,73.033,93.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.738 | Acc: 46.404,73.006,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.739 | Acc: 46.189,72.876,93.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.739 | Acc: 46.377,72.858,93.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.735 | Acc: 46.536,72.960,93.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.736 | Acc: 46.729,73.000,93.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.735 | Acc: 46.633,73.054,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.739 | Acc: 46.519,72.979,93.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.737 | Acc: 46.543,72.960,93.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.737 | Acc: 46.525,73.019,93.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.737 | Acc: 46.536,73.078,93.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.739 | Acc: 46.492,73.085,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.737 | Acc: 46.533,73.140,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.014 | Acc: 46.094,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.954 | Acc: 43.155,62.612,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.972 | Acc: 42.035,61.986,69.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.987 | Acc: 41.650,61.924,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.729 | Acc: 45.312,71.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.669 | Acc: 48.400,74.033,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.704 | Acc: 47.370,73.228,94.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.731 | Acc: 46.773,72.797,93.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.741 | Acc: 46.373,72.926,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.740 | Acc: 46.403,73.105,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.741 | Acc: 46.378,73.153,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.738 | Acc: 46.465,73.299,93.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.738 | Acc: 46.584,73.263,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.733 | Acc: 46.569,73.239,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.739 | Acc: 46.428,73.119,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.737 | Acc: 46.461,73.112,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.738 | Acc: 46.428,73.139,93.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.736 | Acc: 46.363,73.213,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.735 | Acc: 46.391,73.240,93.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.736 | Acc: 46.366,73.230,93.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.739 | Acc: 46.310,73.211,93.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.736 | Acc: 46.405,73.192,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.740 | Acc: 46.280,73.096,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.738 | Acc: 46.348,73.101,93.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.083 | Acc: 46.094,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.964 | Acc: 43.452,63.281,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.969 | Acc: 42.302,62.481,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.988 | Acc: 41.919,62.167,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.769 | Acc: 56.250,67.969,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.692 | Acc: 47.619,74.293,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.690 | Acc: 47.370,74.619,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.685 | Acc: 47.387,74.808,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.704 | Acc: 46.807,74.074,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.708 | Acc: 46.643,74.165,93.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.703 | Acc: 46.901,74.154,94.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.707 | Acc: 46.847,73.986,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.709 | Acc: 46.802,73.981,94.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.716 | Acc: 46.569,73.852,93.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.713 | Acc: 46.541,73.846,93.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.716 | Acc: 46.578,73.738,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.716 | Acc: 46.668,73.720,94.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.720 | Acc: 46.513,73.605,93.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.720 | Acc: 46.614,73.610,93.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.722 | Acc: 46.605,73.531,93.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.725 | Acc: 46.529,73.520,93.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.727 | Acc: 46.508,73.472,93.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.730 | Acc: 46.494,73.444,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.730 | Acc: 46.526,73.454,93.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.043 | Acc: 46.094,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 43.601,62.835,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 42.245,61.604,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 41.790,61.821,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.948 | Acc: 42.969,71.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.677 | Acc: 47.433,74.144,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.689 | Acc: 46.818,73.609,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.685 | Acc: 47.298,73.950,94.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.684 | Acc: 47.242,74.084,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.702 | Acc: 46.968,73.917,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.704 | Acc: 47.088,73.683,93.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.713 | Acc: 46.770,73.559,93.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.710 | Acc: 46.933,73.787,93.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.714 | Acc: 46.793,73.679,93.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.715 | Acc: 46.836,73.815,93.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.712 | Acc: 46.985,73.805,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.717 | Acc: 46.872,73.619,93.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.724 | Acc: 46.656,73.440,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.726 | Acc: 46.697,73.454,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.725 | Acc: 46.649,73.440,93.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.725 | Acc: 46.636,73.438,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.726 | Acc: 46.568,73.403,93.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.726 | Acc: 46.520,73.366,93.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.729 | Acc: 46.500,73.282,93.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.909 | Acc: 46.875,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.917 | Acc: 43.973,63.393,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.940 | Acc: 42.797,63.014,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.953 | Acc: 42.316,62.820,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 1.816 | Acc: 39.062,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.758 | Acc: 46.429,74.144,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.733 | Acc: 46.951,73.819,93.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.713 | Acc: 47.387,74.321,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.715 | Acc: 47.251,74.363,93.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.715 | Acc: 47.045,74.165,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.719 | Acc: 46.798,73.954,94.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.720 | Acc: 46.648,73.659,94.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.723 | Acc: 46.681,73.505,94.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.725 | Acc: 46.620,73.377,94.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.726 | Acc: 46.525,73.270,93.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.719 | Acc: 46.610,73.360,94.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.721 | Acc: 46.574,73.305,94.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.721 | Acc: 46.618,73.285,93.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.720 | Acc: 46.803,73.301,93.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.717 | Acc: 46.919,73.404,93.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.717 | Acc: 46.931,73.423,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.719 | Acc: 46.923,73.394,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.722 | Acc: 46.903,73.392,93.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.724 | Acc: 46.799,73.308,93.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.069 | Acc: 40.625,57.812,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.949 | Acc: 43.527,63.132,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.953 | Acc: 42.492,62.462,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.974 | Acc: 42.162,62.385,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.635 | Acc: 39.844,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.667 | Acc: 47.470,74.740,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.650 | Acc: 48.838,74.314,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.682 | Acc: 47.772,73.783,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.678 | Acc: 47.791,74.074,94.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 47.610,74.226,94.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.682 | Acc: 47.450,74.032,94.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.689 | Acc: 47.241,73.947,94.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.693 | Acc: 47.234,73.908,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.702 | Acc: 46.996,73.778,94.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.710 | Acc: 46.898,73.581,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.707 | Acc: 46.963,73.653,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.712 | Acc: 46.943,73.554,93.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.717 | Acc: 46.884,73.545,93.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.717 | Acc: 46.919,73.535,93.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.719 | Acc: 46.870,73.495,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.720 | Acc: 46.831,73.452,93.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.718 | Acc: 46.795,73.449,93.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.719 | Acc: 46.674,73.435,93.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.718 | Acc: 46.693,73.438,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.962 | Acc: 46.094,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 43.750,63.095,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 42.702,62.043,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.979 | Acc: 42.252,62.013,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.743 | Acc: 43.750,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.709 | Acc: 46.726,73.661,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.699 | Acc: 47.046,73.552,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.695 | Acc: 47.490,73.694,94.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.706 | Acc: 46.769,73.187,94.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.708 | Acc: 46.713,73.337,94.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.709 | Acc: 46.597,73.580,94.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.712 | Acc: 46.531,73.554,94.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.714 | Acc: 46.598,73.501,93.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.718 | Acc: 46.534,73.390,94.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.714 | Acc: 46.813,73.511,94.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.712 | Acc: 46.794,73.487,94.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.712 | Acc: 46.852,73.548,94.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.713 | Acc: 46.866,73.542,93.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.714 | Acc: 46.814,73.485,93.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.715 | Acc: 46.782,73.453,93.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.715 | Acc: 46.831,73.457,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.713 | Acc: 46.827,73.460,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.716 | Acc: 46.799,73.412,93.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.717 | Acc: 46.785,73.440,93.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.012 | Acc: 43.750,56.250,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.936 | Acc: 43.824,63.728,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.964 | Acc: 42.683,62.767,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 42.290,62.500,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.841 | Acc: 39.844,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.687 | Acc: 46.317,74.665,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.693 | Acc: 46.627,74.581,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.694 | Acc: 46.734,74.232,94.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.687 | Acc: 46.672,74.354,94.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.700 | Acc: 46.364,74.002,94.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.700 | Acc: 46.417,74.032,94.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.700 | Acc: 46.432,73.969,94.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.699 | Acc: 46.453,74.030,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.700 | Acc: 46.469,73.990,94.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.702 | Acc: 46.486,73.892,94.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.704 | Acc: 46.592,73.894,93.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.708 | Acc: 46.515,73.839,93.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.708 | Acc: 46.606,73.848,93.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.710 | Acc: 46.630,73.832,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.715 | Acc: 46.597,73.702,93.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.717 | Acc: 46.551,73.622,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.716 | Acc: 46.527,73.637,93.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.719 | Acc: 46.388,73.615,93.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.718 | Acc: 46.410,73.645,93.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.008 | Acc: 45.312,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.918 | Acc: 43.155,64.100,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.933 | Acc: 43.007,63.091,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.952 | Acc: 42.636,62.871,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.669 | Acc: 42.969,75.000,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 45.536,72.507,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.724 | Acc: 45.351,72.752,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.713 | Acc: 45.799,73.169,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.711 | Acc: 46.209,73.235,94.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.705 | Acc: 46.666,73.422,94.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.702 | Acc: 47.178,73.515,94.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.698 | Acc: 47.119,73.570,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.698 | Acc: 47.166,73.617,94.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.697 | Acc: 47.289,73.783,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.699 | Acc: 47.236,73.717,94.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.701 | Acc: 47.137,73.713,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 47.154,73.707,94.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.702 | Acc: 47.201,73.791,94.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.705 | Acc: 47.225,73.768,94.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.708 | Acc: 47.013,73.663,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.709 | Acc: 46.980,73.671,94.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.711 | Acc: 46.944,73.598,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.713 | Acc: 46.888,73.502,94.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.712 | Acc: 46.932,73.513,94.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.073 | Acc: 46.875,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.009 | Acc: 42.783,62.500,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.027 | Acc: 41.997,61.890,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.026 | Acc: 41.560,61.949,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.593 | Acc: 42.188,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.650 | Acc: 46.875,74.516,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.660 | Acc: 47.409,74.390,94.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.661 | Acc: 47.144,74.552,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.668 | Acc: 46.856,74.508,94.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 46.844,74.544,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.678 | Acc: 46.894,74.445,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 46.620,74.274,94.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.692 | Acc: 46.564,74.078,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.698 | Acc: 46.616,73.968,94.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.696 | Acc: 46.642,73.986,94.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.698 | Acc: 46.681,73.918,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.697 | Acc: 46.706,73.898,94.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.698 | Acc: 46.689,73.884,94.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.703 | Acc: 46.630,73.779,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.701 | Acc: 46.743,73.803,94.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.700 | Acc: 46.829,73.783,94.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.701 | Acc: 46.772,73.827,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.704 | Acc: 46.691,73.808,94.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.706 | Acc: 46.680,73.825,94.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.052 | Acc: 46.094,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.982 | Acc: 42.969,62.760,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.001 | Acc: 42.321,62.062,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.011 | Acc: 42.008,61.936,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.710 | Acc: 47.656,69.531,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.702 | Acc: 47.061,73.289,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 47.332,73.800,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.688 | Acc: 47.157,74.360,94.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.703 | Acc: 46.856,73.987,94.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.690 | Acc: 47.254,74.219,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.700 | Acc: 46.830,73.754,94.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.702 | Acc: 46.676,73.698,94.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.699 | Acc: 46.841,73.607,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.707 | Acc: 46.694,73.485,94.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.710 | Acc: 46.634,73.453,94.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.714 | Acc: 46.635,73.476,94.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.713 | Acc: 46.671,73.506,94.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.719 | Acc: 46.432,73.414,93.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.717 | Acc: 46.533,73.471,93.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.720 | Acc: 46.397,73.445,93.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.721 | Acc: 46.391,73.479,93.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.719 | Acc: 46.424,73.536,93.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.717 | Acc: 46.481,73.626,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.718 | Acc: 46.471,73.534,93.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.021 | Acc: 42.969,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.986 | Acc: 42.708,63.876,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.020 | Acc: 41.444,62.443,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.028 | Acc: 41.099,62.269,69.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.555 | Acc: 46.875,71.875,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.689 | Acc: 46.615,73.772,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.693 | Acc: 46.399,74.276,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.688 | Acc: 46.657,74.155,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.690 | Acc: 47.222,73.698,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.691 | Acc: 47.200,73.716,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.686 | Acc: 47.346,73.825,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.693 | Acc: 47.274,73.703,94.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.695 | Acc: 47.205,73.675,94.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.695 | Acc: 47.186,73.636,94.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.698 | Acc: 47.085,73.574,94.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.700 | Acc: 47.066,73.515,94.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.699 | Acc: 47.047,73.726,94.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.694 | Acc: 47.117,73.815,94.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.699 | Acc: 47.125,73.718,94.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.696 | Acc: 47.194,73.778,94.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.697 | Acc: 47.150,73.759,94.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.696 | Acc: 47.127,73.779,94.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.698 | Acc: 47.100,73.727,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.700 | Acc: 47.090,73.665,94.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.075 | Acc: 44.531,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.971 | Acc: 43.266,62.686,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.999 | Acc: 42.264,61.833,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.004 | Acc: 41.957,61.962,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.807 | Acc: 46.875,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.718 | Acc: 45.722,73.363,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.708 | Acc: 46.532,73.342,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.705 | Acc: 46.542,73.220,94.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.697 | Acc: 46.402,73.331,94.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.689 | Acc: 46.519,73.685,94.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.690 | Acc: 46.468,73.844,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.693 | Acc: 46.526,73.892,94.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.690 | Acc: 46.589,73.869,94.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.690 | Acc: 46.750,73.930,94.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.688 | Acc: 46.906,74.021,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.691 | Acc: 46.822,73.950,94.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.689 | Acc: 46.917,73.985,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.690 | Acc: 46.872,73.925,94.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.694 | Acc: 46.794,73.752,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.697 | Acc: 46.709,73.562,94.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.698 | Acc: 46.639,73.569,94.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.701 | Acc: 46.600,73.586,94.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.698 | Acc: 46.641,73.619,94.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.702 | Acc: 46.565,73.497,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.110 | Acc: 44.531,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.012 | Acc: 43.118,62.500,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.039 | Acc: 42.511,62.043,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.047 | Acc: 42.239,61.898,69.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.742 | Acc: 41.406,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.707 | Acc: 45.312,73.289,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 45.541,73.247,94.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.685 | Acc: 46.324,73.745,94.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.668 | Acc: 47.135,74.228,94.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.667 | Acc: 47.084,74.335,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.674 | Acc: 46.991,74.322,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.675 | Acc: 47.135,74.141,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.679 | Acc: 46.904,74.093,94.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.684 | Acc: 46.685,73.960,94.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.688 | Acc: 46.735,73.881,94.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 46.716,73.929,94.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.689 | Acc: 46.787,73.882,94.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.692 | Acc: 46.728,73.746,94.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.695 | Acc: 46.730,73.657,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.695 | Acc: 46.833,73.666,94.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.692 | Acc: 46.933,73.688,94.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.690 | Acc: 46.999,73.694,94.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.691 | Acc: 46.942,73.725,94.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.693 | Acc: 46.916,73.684,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.951 | Acc: 49.219,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.973 | Acc: 44.196,62.723,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.995 | Acc: 42.511,62.233,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.995 | Acc: 42.367,62.282,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.761 | Acc: 43.750,67.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.707 | Acc: 46.391,73.698,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.698 | Acc: 46.989,73.876,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.710 | Acc: 46.593,73.566,94.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.699 | Acc: 46.431,73.823,94.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.698 | Acc: 46.341,73.786,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.693 | Acc: 46.597,73.786,94.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.692 | Acc: 46.709,73.770,94.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.690 | Acc: 46.793,73.826,94.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.696 | Acc: 46.638,73.632,94.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.695 | Acc: 46.700,73.682,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.696 | Acc: 46.698,73.734,94.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 46.700,73.710,94.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.694 | Acc: 46.668,73.689,94.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.693 | Acc: 46.608,73.668,94.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.693 | Acc: 46.665,73.733,94.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.693 | Acc: 46.717,73.632,94.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.693 | Acc: 46.774,73.605,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.695 | Acc: 46.654,73.608,94.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.697 | Acc: 46.660,73.583,94.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.956 | Acc: 46.875,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.018 | Acc: 43.229,62.835,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.045 | Acc: 41.768,61.928,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.055 | Acc: 41.150,61.962,69.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.486 | Acc: 47.656,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.655 | Acc: 47.359,74.516,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 46.856,74.219,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.691 | Acc: 47.285,74.270,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 47.232,74.508,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.682 | Acc: 47.138,74.366,94.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.693 | Acc: 47.217,73.993,94.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 47.202,73.986,94.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.689 | Acc: 47.127,73.923,94.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.691 | Acc: 47.013,73.925,94.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.690 | Acc: 47.050,73.958,94.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.687 | Acc: 47.115,73.982,94.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.685 | Acc: 47.018,73.930,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.689 | Acc: 46.896,73.872,94.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.691 | Acc: 46.878,73.799,94.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.691 | Acc: 46.919,73.866,94.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 46.926,73.907,94.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.693 | Acc: 46.866,73.866,94.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.692 | Acc: 46.845,73.927,94.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.692 | Acc: 46.852,73.944,94.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.205 | Acc: 45.312,57.031,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.028 | Acc: 43.452,62.835,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.045 | Acc: 42.302,62.481,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.063 | Acc: 41.701,62.615,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.631 | Acc: 49.219,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.660 | Acc: 45.908,74.442,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.660 | Acc: 47.085,74.771,94.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.660 | Acc: 47.695,75.000,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.678 | Acc: 47.309,74.691,94.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.675 | Acc: 47.285,74.706,94.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.684 | Acc: 47.017,74.316,94.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.681 | Acc: 46.897,74.330,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.675 | Acc: 46.928,74.481,94.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 46.832,74.443,94.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.678 | Acc: 46.774,74.421,94.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.679 | Acc: 46.645,74.350,94.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.681 | Acc: 46.674,74.241,94.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.683 | Acc: 46.704,74.180,94.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.686 | Acc: 46.694,74.169,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.687 | Acc: 46.569,74.193,94.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 46.566,74.053,94.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.692 | Acc: 46.431,74.097,94.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.695 | Acc: 46.488,73.979,94.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.693 | Acc: 46.535,74.020,94.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.062 | Acc: 43.750,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.967 | Acc: 43.638,63.318,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.993 | Acc: 42.950,62.348,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.015 | Acc: 42.636,62.231,69.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.772 | Acc: 44.531,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.611 | Acc: 48.996,74.665,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.629 | Acc: 48.819,74.657,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.638 | Acc: 48.245,74.347,94.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.654 | Acc: 47.676,73.775,94.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.658 | Acc: 47.115,74.033,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.659 | Acc: 46.907,74.148,94.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.663 | Acc: 46.664,74.019,94.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.665 | Acc: 46.661,74.025,94.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.669 | Acc: 46.603,73.912,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.668 | Acc: 46.751,73.912,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.669 | Acc: 46.818,73.978,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.674 | Acc: 46.755,73.856,94.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.674 | Acc: 46.737,73.881,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.674 | Acc: 46.633,73.824,94.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.677 | Acc: 46.662,73.832,94.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.679 | Acc: 46.622,73.871,94.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.680 | Acc: 46.644,73.861,94.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 46.685,73.803,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.683 | Acc: 46.742,73.790,94.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.958 | Acc: 46.094,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.965 | Acc: 44.122,63.467,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.997 | Acc: 43.045,62.557,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 42.610,62.231,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.546 | Acc: 53.906,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.650 | Acc: 47.284,75.000,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.659 | Acc: 46.818,74.486,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.657 | Acc: 46.939,74.475,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.657 | Acc: 46.991,74.576,95.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.666 | Acc: 46.550,74.459,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.672 | Acc: 46.468,74.406,94.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.675 | Acc: 46.565,74.368,94.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.681 | Acc: 46.579,74.224,94.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 46.672,74.245,94.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.677 | Acc: 46.739,74.320,94.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.676 | Acc: 46.783,74.293,94.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.675 | Acc: 46.914,74.303,94.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.675 | Acc: 46.941,74.282,94.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.677 | Acc: 46.911,74.266,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.678 | Acc: 46.870,74.203,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.680 | Acc: 46.841,74.202,94.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.681 | Acc: 46.868,74.200,94.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 46.765,74.141,94.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.684 | Acc: 46.781,74.061,94.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.029 | Acc: 39.844,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.028 | Acc: 42.820,62.500,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.030 | Acc: 41.444,62.309,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.050 | Acc: 40.920,62.039,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.502 | Acc: 59.375,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.686 | Acc: 46.801,73.735,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.669 | Acc: 47.409,74.066,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 47.170,73.642,94.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.671 | Acc: 47.039,73.794,94.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.670 | Acc: 47.192,73.933,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.663 | Acc: 47.404,74.167,94.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.665 | Acc: 47.158,74.069,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.667 | Acc: 47.050,74.107,94.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.668 | Acc: 47.095,74.111,94.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.664 | Acc: 47.225,74.133,94.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.667 | Acc: 47.161,74.014,94.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.665 | Acc: 47.151,74.096,94.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.667 | Acc: 47.111,74.093,94.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.666 | Acc: 47.117,74.130,94.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.666 | Acc: 47.057,74.154,94.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.670 | Acc: 47.058,74.095,94.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.673 | Acc: 47.086,74.031,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.675 | Acc: 47.018,74.005,94.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.677 | Acc: 46.965,74.010,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.036 | Acc: 46.875,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.006 | Acc: 44.382,63.170,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.039 | Acc: 42.854,62.176,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.058 | Acc: 42.444,61.885,69.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.776 | Acc: 43.750,69.531,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.674 | Acc: 46.429,74.516,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.663 | Acc: 46.380,74.371,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.650 | Acc: 47.349,74.667,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.661 | Acc: 47.164,74.547,95.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.668 | Acc: 47.014,74.513,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 47.030,74.535,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.665 | Acc: 46.881,74.463,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.668 | Acc: 46.919,74.393,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.670 | Acc: 46.927,74.396,94.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.673 | Acc: 46.856,74.335,94.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.671 | Acc: 47.034,74.364,94.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.668 | Acc: 47.115,74.423,94.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.670 | Acc: 47.085,74.344,94.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.672 | Acc: 47.067,74.386,94.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.671 | Acc: 47.059,74.406,94.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.670 | Acc: 47.019,74.389,94.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.671 | Acc: 47.072,74.283,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.673 | Acc: 47.120,74.275,94.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.675 | Acc: 47.137,74.225,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.129 | Acc: 45.312,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.028 | Acc: 43.862,62.612,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.030 | Acc: 43.064,62.119,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.060 | Acc: 42.802,62.282,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.589 | Acc: 45.312,71.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.646 | Acc: 46.391,74.851,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.668 | Acc: 46.761,74.486,95.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 46.158,74.398,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.672 | Acc: 46.586,74.556,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.667 | Acc: 46.875,74.683,94.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.667 | Acc: 46.694,74.354,94.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.663 | Acc: 46.814,74.324,94.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 46.841,74.165,94.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.667 | Acc: 47.039,74.236,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.665 | Acc: 47.089,74.320,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.668 | Acc: 46.974,74.254,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.668 | Acc: 47.086,74.261,94.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.668 | Acc: 47.132,74.222,94.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.672 | Acc: 46.986,74.046,94.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.675 | Acc: 46.828,74.042,94.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.679 | Acc: 46.785,73.978,94.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.676 | Acc: 46.854,74.042,94.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.676 | Acc: 46.810,74.072,94.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.675 | Acc: 46.816,74.149,94.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.044 | Acc: 44.531,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.980 | Acc: 43.824,63.244,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.006 | Acc: 42.778,62.710,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.035 | Acc: 42.469,62.718,69.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.570 | Acc: 50.781,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.668 | Acc: 47.954,74.591,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.651 | Acc: 46.970,74.428,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.668 | Acc: 46.414,74.488,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 46.373,73.852,95.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.680 | Acc: 46.450,73.793,95.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.674 | Acc: 46.688,74.025,95.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.673 | Acc: 46.664,73.964,94.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.672 | Acc: 46.661,73.918,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.671 | Acc: 46.620,74.016,94.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.670 | Acc: 46.529,74.075,94.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.673 | Acc: 46.507,74.031,94.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.672 | Acc: 46.616,74.112,94.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.676 | Acc: 46.594,74.129,94.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.676 | Acc: 46.650,74.099,94.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.677 | Acc: 46.678,74.009,94.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.676 | Acc: 46.744,73.932,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 46.614,73.914,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 46.607,73.896,94.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.682 | Acc: 46.654,73.913,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.996 | Acc: 46.094,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.983 | Acc: 44.048,63.504,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.016 | Acc: 43.007,62.710,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.042 | Acc: 42.623,62.385,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.647 | Acc: 50.000,72.656,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.677 | Acc: 46.577,73.847,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.671 | Acc: 47.027,74.028,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.677 | Acc: 46.939,74.091,94.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.676 | Acc: 46.508,73.939,94.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.669 | Acc: 46.852,74.149,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.679 | Acc: 46.655,74.251,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.676 | Acc: 46.869,74.208,94.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.676 | Acc: 46.812,74.175,94.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 46.758,74.085,94.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.674 | Acc: 46.743,74.207,94.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.678 | Acc: 46.681,74.208,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.679 | Acc: 46.632,74.180,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.680 | Acc: 46.642,74.246,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.682 | Acc: 46.564,74.202,94.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.685 | Acc: 46.548,74.180,94.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.686 | Acc: 46.563,74.109,94.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.687 | Acc: 46.515,74.077,94.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.687 | Acc: 46.583,74.072,94.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.686 | Acc: 46.547,74.055,94.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.129 | Acc: 43.750,57.031,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.040 | Acc: 42.783,62.463,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.053 | Acc: 42.168,62.271,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.074 | Acc: 41.970,62.218,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.989 | Acc: 42.969,62.500,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.660 | Acc: 46.057,73.698,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.663 | Acc: 46.818,74.028,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.664 | Acc: 46.644,74.232,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.663 | Acc: 46.952,74.219,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.658 | Acc: 47.177,74.358,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.657 | Acc: 47.159,74.316,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 47.002,74.158,94.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.670 | Acc: 46.865,74.093,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.671 | Acc: 46.905,74.197,94.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.674 | Acc: 46.848,74.067,94.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.674 | Acc: 46.854,74.137,94.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.672 | Acc: 46.849,74.128,94.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.669 | Acc: 46.887,74.132,94.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.667 | Acc: 46.953,74.166,94.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.671 | Acc: 46.942,74.120,94.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.668 | Acc: 47.060,74.126,94.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.668 | Acc: 47.090,74.129,94.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.671 | Acc: 47.089,74.087,94.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.672 | Acc: 47.043,74.096,94.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.146 | Acc: 45.312,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.995 | Acc: 44.159,62.574,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.029 | Acc: 42.912,62.195,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.047 | Acc: 42.469,62.193,68.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.524 | Acc: 51.562,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.672 | Acc: 45.759,74.926,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.641 | Acc: 47.428,74.848,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.642 | Acc: 47.234,74.898,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.648 | Acc: 47.280,74.479,95.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.653 | Acc: 47.146,74.474,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.656 | Acc: 47.030,74.471,94.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.656 | Acc: 46.930,74.440,94.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.660 | Acc: 46.875,74.350,94.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.660 | Acc: 46.996,74.366,94.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.659 | Acc: 47.128,74.250,94.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 47.140,74.229,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 47.248,74.274,94.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.663 | Acc: 47.085,74.285,94.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.665 | Acc: 47.156,74.202,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.666 | Acc: 47.124,74.177,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.672 | Acc: 47.011,74.078,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.672 | Acc: 46.992,74.097,94.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.675 | Acc: 46.957,74.030,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.674 | Acc: 46.965,74.081,94.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.113 | Acc: 46.875,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.995 | Acc: 43.527,62.574,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.029 | Acc: 42.264,62.005,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.045 | Acc: 41.893,62.116,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.796 | Acc: 48.438,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.625 | Acc: 49.516,75.409,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.648 | Acc: 48.095,74.695,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 47.067,74.705,94.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.655 | Acc: 47.000,74.479,94.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.652 | Acc: 47.285,74.474,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.655 | Acc: 47.056,74.419,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.656 | Acc: 47.130,74.363,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.658 | Acc: 47.084,74.457,94.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.658 | Acc: 47.043,74.473,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.660 | Acc: 46.968,74.335,94.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 46.960,74.427,94.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.659 | Acc: 47.057,74.530,94.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.658 | Acc: 47.091,74.479,94.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.661 | Acc: 47.070,74.430,94.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.662 | Acc: 47.005,74.445,94.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 46.938,74.353,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.664 | Acc: 46.941,74.345,94.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.665 | Acc: 46.964,74.323,94.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.667 | Acc: 46.873,74.262,94.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.206 | Acc: 46.094,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.053 | Acc: 42.485,61.756,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.099 | Acc: 41.787,61.242,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.118 | Acc: 41.342,61.347,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.682 | Acc: 43.750,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.631 | Acc: 46.615,75.707,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.643 | Acc: 46.894,76.124,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.637 | Acc: 47.310,75.781,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.646 | Acc: 47.097,75.289,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.641 | Acc: 47.169,75.302,95.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.638 | Acc: 47.366,75.161,95.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.636 | Acc: 47.462,75.078,95.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.637 | Acc: 47.472,74.888,95.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.645 | Acc: 47.259,74.642,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.647 | Acc: 47.221,74.607,94.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.654 | Acc: 47.073,74.452,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.659 | Acc: 47.024,74.433,94.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.661 | Acc: 46.920,74.389,94.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.659 | Acc: 46.956,74.391,94.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.661 | Acc: 46.906,74.442,94.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 46.890,74.413,94.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.666 | Acc: 46.799,74.308,94.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.666 | Acc: 46.888,74.301,94.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.668 | Acc: 46.875,74.239,94.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.943 | Acc: 50.781,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.017 | Acc: 43.452,62.537,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.033 | Acc: 43.083,62.195,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.051 | Acc: 42.264,61.975,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.642 | Acc: 42.969,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.635 | Acc: 46.057,74.256,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.647 | Acc: 46.265,74.047,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.648 | Acc: 46.555,74.360,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.645 | Acc: 47.058,74.190,95.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.653 | Acc: 46.968,74.165,95.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.655 | Acc: 47.275,74.238,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.662 | Acc: 47.063,74.019,94.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.661 | Acc: 46.957,73.971,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.659 | Acc: 46.961,74.111,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.655 | Acc: 47.050,74.273,94.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.657 | Acc: 47.130,74.261,94.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.658 | Acc: 47.053,74.225,94.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.659 | Acc: 47.031,74.303,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.662 | Acc: 46.886,74.249,94.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.663 | Acc: 46.833,74.211,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.664 | Acc: 46.836,74.233,94.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.666 | Acc: 46.749,74.232,94.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.666 | Acc: 46.799,74.301,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.666 | Acc: 46.898,74.250,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.950 | Acc: 41.406,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.098 | Acc: 42.039,61.793,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.110 | Acc: 41.673,61.414,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.138 | Acc: 41.509,61.527,68.622,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.787 | Acc: 47.656,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.634 | Acc: 48.884,75.335,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.650 | Acc: 47.447,74.104,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 47.182,74.155,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.645 | Acc: 47.116,74.334,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.652 | Acc: 47.115,74.250,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.660 | Acc: 46.927,74.154,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.661 | Acc: 46.892,74.086,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.658 | Acc: 46.953,74.311,95.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.656 | Acc: 47.138,74.296,95.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.658 | Acc: 47.170,74.273,95.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.662 | Acc: 46.949,74.155,94.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.659 | Acc: 47.034,74.335,94.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.661 | Acc: 47.001,74.374,94.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.660 | Acc: 47.122,74.383,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.660 | Acc: 47.158,74.460,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.664 | Acc: 47.135,74.375,94.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.665 | Acc: 47.093,74.379,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.665 | Acc: 47.096,74.381,94.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.664 | Acc: 47.092,74.436,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.992 | Acc: 47.656,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.041 | Acc: 43.341,62.351,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.062 | Acc: 42.588,62.024,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.071 | Acc: 42.264,61.757,69.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.705 | Acc: 52.344,71.875,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.628 | Acc: 46.875,74.926,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.650 | Acc: 46.627,74.238,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.640 | Acc: 46.862,74.257,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.645 | Acc: 46.981,74.016,95.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.647 | Acc: 47.231,74.257,95.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.647 | Acc: 47.443,74.122,95.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.650 | Acc: 47.352,74.136,94.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.649 | Acc: 47.375,74.141,94.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.651 | Acc: 47.328,74.020,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.653 | Acc: 47.271,74.207,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.655 | Acc: 47.260,74.159,94.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.656 | Acc: 47.254,74.141,94.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.659 | Acc: 47.108,74.168,94.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.662 | Acc: 47.053,74.077,94.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.663 | Acc: 46.968,74.081,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 47.050,74.126,94.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.664 | Acc: 47.010,74.129,94.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.663 | Acc: 47.011,74.208,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.663 | Acc: 47.055,74.213,94.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.024 | Acc: 45.312,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.037 | Acc: 43.713,63.281,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.057 | Acc: 43.140,62.595,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.076 | Acc: 42.777,62.385,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.700 | Acc: 43.750,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.634 | Acc: 45.982,75.409,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.620 | Acc: 47.123,75.629,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.621 | Acc: 47.093,75.717,95.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.620 | Acc: 47.309,75.791,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.630 | Acc: 47.045,75.480,95.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.636 | Acc: 46.927,75.316,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.634 | Acc: 47.047,75.161,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.636 | Acc: 47.006,75.189,95.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.641 | Acc: 46.979,75.108,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.643 | Acc: 47.015,75.101,95.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.637 | Acc: 47.218,75.166,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.642 | Acc: 47.183,75.078,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.646 | Acc: 47.049,74.979,95.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.645 | Acc: 47.014,74.997,95.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.650 | Acc: 47.026,74.795,95.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.654 | Acc: 46.933,74.628,95.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.653 | Acc: 47.063,74.659,95.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.656 | Acc: 46.920,74.636,94.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 46.908,74.600,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.067 | Acc: 46.875,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.067 | Acc: 43.266,62.351,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.107 | Acc: 41.940,61.928,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.123 | Acc: 41.522,61.783,68.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.368 | Acc: 56.250,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 47.396,74.963,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.656 | Acc: 47.104,74.771,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.650 | Acc: 47.106,74.577,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.651 | Acc: 47.232,74.257,95.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.646 | Acc: 47.587,74.288,95.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.650 | Acc: 47.630,74.257,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.654 | Acc: 47.540,74.147,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.645 | Acc: 47.748,74.379,95.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.649 | Acc: 47.397,74.413,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.646 | Acc: 47.427,74.401,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.644 | Acc: 47.405,74.498,95.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.643 | Acc: 47.416,74.514,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.647 | Acc: 47.450,74.482,95.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.652 | Acc: 47.339,74.419,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.658 | Acc: 47.129,74.307,94.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.659 | Acc: 47.133,74.345,94.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.658 | Acc: 47.159,74.423,94.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.658 | Acc: 47.135,74.470,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.659 | Acc: 47.070,74.430,94.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.133 | Acc: 46.094,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.058 | Acc: 43.378,61.830,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.068 | Acc: 42.759,61.395,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.089 | Acc: 42.316,61.309,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.794 | Acc: 48.438,70.312,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.657 | Acc: 48.140,74.740,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.644 | Acc: 47.542,74.924,94.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.641 | Acc: 47.797,74.705,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.637 | Acc: 47.888,75.193,95.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.648 | Acc: 47.386,75.054,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.653 | Acc: 47.321,75.013,95.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.649 | Acc: 47.352,74.956,95.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.649 | Acc: 47.399,74.811,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.654 | Acc: 47.169,74.655,94.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.653 | Acc: 47.178,74.693,94.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.654 | Acc: 47.161,74.601,94.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.654 | Acc: 47.209,74.605,94.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.653 | Acc: 47.285,74.638,94.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.659 | Acc: 47.072,74.513,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.658 | Acc: 47.111,74.491,94.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 47.104,74.496,94.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 46.994,74.466,94.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.659 | Acc: 47.083,74.424,94.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.661 | Acc: 47.055,74.395,94.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.216 | Acc: 43.750,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.078 | Acc: 43.341,61.868,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.086 | Acc: 42.721,61.204,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.106 | Acc: 41.893,61.245,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.499 | Acc: 52.344,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 48.884,75.074,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.623 | Acc: 48.133,75.171,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.628 | Acc: 47.631,75.282,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.629 | Acc: 47.637,75.058,95.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.624 | Acc: 47.571,75.294,95.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.621 | Acc: 47.618,75.200,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.623 | Acc: 47.379,74.989,95.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.625 | Acc: 47.287,74.981,95.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.634 | Acc: 47.143,74.914,95.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.638 | Acc: 47.151,74.778,95.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.641 | Acc: 47.055,74.714,95.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.644 | Acc: 47.160,74.601,95.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.650 | Acc: 47.141,74.437,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.649 | Acc: 47.206,74.533,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.652 | Acc: 47.140,74.447,94.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.654 | Acc: 47.099,74.499,94.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.652 | Acc: 47.173,74.560,94.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.652 | Acc: 47.120,74.572,94.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.654 | Acc: 47.055,74.582,94.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.050 | Acc: 44.531,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.057 | Acc: 43.378,62.612,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.067 | Acc: 42.359,61.852,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.083 | Acc: 41.995,61.936,68.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.410 | Acc: 50.000,76.562,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.633 | Acc: 46.391,74.702,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.631 | Acc: 47.142,74.867,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.624 | Acc: 47.170,75.192,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.628 | Acc: 47.454,74.797,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.626 | Acc: 47.386,74.861,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.635 | Acc: 46.978,74.483,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.640 | Acc: 46.892,74.446,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.641 | Acc: 46.996,74.427,95.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.642 | Acc: 47.039,74.391,95.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.647 | Acc: 46.782,74.250,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.654 | Acc: 46.709,74.031,94.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 46.567,73.917,94.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.661 | Acc: 46.594,73.884,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.659 | Acc: 46.767,73.941,94.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.657 | Acc: 46.911,73.954,94.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 46.846,73.934,94.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.655 | Acc: 46.935,74.042,94.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.656 | Acc: 46.949,74.020,94.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 46.932,74.065,94.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.238 | Acc: 44.531,57.812,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.145 | Acc: 42.411,62.240,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.166 | Acc: 41.178,61.681,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.203 | Acc: 40.689,61.373,68.404,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.465 | Acc: 48.438,76.562,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.618 | Acc: 47.507,75.446,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.622 | Acc: 47.256,74.733,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.632 | Acc: 47.246,74.821,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.635 | Acc: 47.444,74.749,95.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.642 | Acc: 47.246,74.722,95.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.637 | Acc: 47.256,74.780,95.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.636 | Acc: 47.241,74.828,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.635 | Acc: 47.423,74.864,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.639 | Acc: 47.225,74.767,95.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.641 | Acc: 47.100,74.712,95.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.645 | Acc: 47.101,74.597,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.644 | Acc: 47.196,74.536,95.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.644 | Acc: 47.324,74.533,95.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.645 | Acc: 47.328,74.488,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.647 | Acc: 47.254,74.476,94.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.651 | Acc: 47.221,74.413,94.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.651 | Acc: 47.161,74.430,94.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.652 | Acc: 47.167,74.448,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.655 | Acc: 47.107,74.393,94.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.958 | Acc: 45.312,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.063 | Acc: 44.048,62.612,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.069 | Acc: 43.159,62.290,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.091 | Acc: 42.713,62.167,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.549 | Acc: 47.656,73.438,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.649 | Acc: 47.173,74.554,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.628 | Acc: 47.008,74.619,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.627 | Acc: 47.080,74.846,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.634 | Acc: 47.270,74.489,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.636 | Acc: 47.092,74.428,95.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.640 | Acc: 47.017,74.438,95.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.638 | Acc: 47.086,74.618,95.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.637 | Acc: 47.181,74.641,95.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.643 | Acc: 47.212,74.560,94.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.645 | Acc: 47.217,74.541,94.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.642 | Acc: 47.377,74.615,94.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.643 | Acc: 47.332,74.682,94.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.645 | Acc: 47.342,74.575,94.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.647 | Acc: 47.292,74.552,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.648 | Acc: 47.282,74.533,94.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.650 | Acc: 47.323,74.528,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.647 | Acc: 47.317,74.478,94.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.646 | Acc: 47.440,74.457,94.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.648 | Acc: 47.381,74.420,94.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.249 | Acc: 49.219,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.104 | Acc: 43.973,62.128,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.112 | Acc: 43.331,61.509,68.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.122 | Acc: 42.456,61.732,68.801,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.594 | Acc: 46.094,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.652 | Acc: 46.429,75.744,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.665 | Acc: 46.799,74.829,94.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.643 | Acc: 47.272,74.718,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.650 | Acc: 47.049,74.354,94.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.642 | Acc: 47.409,74.838,95.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.642 | Acc: 47.333,74.768,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.639 | Acc: 47.446,74.812,95.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.637 | Acc: 47.545,74.762,95.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.635 | Acc: 47.350,74.840,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.635 | Acc: 47.458,74.755,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.638 | Acc: 47.391,74.689,95.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.641 | Acc: 47.436,74.786,95.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.642 | Acc: 47.354,74.701,95.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.646 | Acc: 47.250,74.572,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.647 | Acc: 47.189,74.548,94.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.649 | Acc: 47.184,74.521,94.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.651 | Acc: 47.175,74.551,94.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.651 | Acc: 47.256,74.533,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.652 | Acc: 47.299,74.612,94.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.106 | Acc: 43.750,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.082 | Acc: 42.969,62.426,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.092 | Acc: 41.845,61.928,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.099 | Acc: 41.598,61.988,68.840,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.868 | Acc: 45.312,61.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.618 | Acc: 47.396,75.149,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.608 | Acc: 47.466,75.705,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.614 | Acc: 47.170,75.781,95.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.626 | Acc: 47.174,75.502,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.632 | Acc: 46.875,75.240,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.633 | Acc: 47.082,75.297,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.632 | Acc: 47.230,75.177,95.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.632 | Acc: 47.341,75.121,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.638 | Acc: 47.315,75.004,95.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.643 | Acc: 47.244,74.724,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.644 | Acc: 47.229,74.703,94.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.643 | Acc: 47.345,74.676,94.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.647 | Acc: 47.330,74.593,94.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.646 | Acc: 47.389,74.655,94.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.646 | Acc: 47.355,74.678,94.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.646 | Acc: 47.413,74.620,94.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.648 | Acc: 47.445,74.572,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.651 | Acc: 47.271,74.485,94.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.652 | Acc: 47.211,74.459,94.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.152 | Acc: 45.312,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.105 | Acc: 42.560,61.570,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.130 | Acc: 41.692,61.471,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.149 | Acc: 41.163,61.181,68.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.649 | Acc: 46.094,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.640 | Acc: 46.652,74.963,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.630 | Acc: 46.570,75.229,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.637 | Acc: 46.260,75.026,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.632 | Acc: 46.624,75.048,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.638 | Acc: 46.798,74.660,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.641 | Acc: 46.965,74.697,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.640 | Acc: 47.069,74.734,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.639 | Acc: 47.181,74.612,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.638 | Acc: 47.333,74.599,95.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.640 | Acc: 47.174,74.596,95.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.641 | Acc: 47.168,74.608,95.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.640 | Acc: 47.186,74.673,95.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.638 | Acc: 47.231,74.695,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.637 | Acc: 47.278,74.708,95.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.638 | Acc: 47.207,74.647,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.638 | Acc: 47.274,74.696,95.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.638 | Acc: 47.274,74.684,95.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.641 | Acc: 47.163,74.546,95.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.641 | Acc: 47.176,74.541,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.272 | Acc: 46.094,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.233 | Acc: 41.034,61.421,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.203 | Acc: 40.187,60.918,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.225 | Acc: 40.087,60.925,68.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.919 | Acc: 43.750,67.969,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.641 | Acc: 47.247,73.847,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.623 | Acc: 47.104,74.733,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.639 | Acc: 46.773,74.757,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.633 | Acc: 47.348,74.894,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.633 | Acc: 47.200,74.822,95.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.638 | Acc: 47.153,74.832,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.633 | Acc: 47.440,75.006,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.639 | Acc: 47.346,74.801,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.636 | Acc: 47.389,74.819,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.635 | Acc: 47.369,74.856,95.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.639 | Acc: 47.327,74.781,95.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.642 | Acc: 47.329,74.660,95.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.645 | Acc: 47.264,74.560,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.647 | Acc: 47.248,74.505,95.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.645 | Acc: 47.332,74.533,95.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.648 | Acc: 47.235,74.448,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.646 | Acc: 47.313,74.553,94.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.647 | Acc: 47.332,74.597,94.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.649 | Acc: 47.334,74.553,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.116 | Acc: 48.438,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.155 | Acc: 42.560,61.644,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.160 | Acc: 41.044,61.433,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.173 | Acc: 40.587,61.219,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.695 | Acc: 51.562,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.654 | Acc: 47.173,74.256,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.637 | Acc: 47.828,74.657,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.646 | Acc: 47.515,74.232,94.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.635 | Acc: 47.733,74.797,94.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.640 | Acc: 47.215,74.745,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.652 | Acc: 46.972,74.574,94.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.650 | Acc: 47.036,74.629,94.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.655 | Acc: 46.885,74.670,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.650 | Acc: 46.897,74.827,94.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.650 | Acc: 47.089,74.767,94.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.650 | Acc: 47.084,74.714,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.649 | Acc: 47.147,74.705,94.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.651 | Acc: 47.046,74.665,94.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.650 | Acc: 47.053,74.705,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.652 | Acc: 47.093,74.616,94.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.653 | Acc: 46.989,74.586,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.656 | Acc: 46.854,74.578,94.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.653 | Acc: 46.897,74.667,94.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.652 | Acc: 46.951,74.688,94.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.954 | Acc: 46.094,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.091 | Acc: 44.606,61.868,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.104 | Acc: 42.797,61.014,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.118 | Acc: 42.239,60.835,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.764 | Acc: 40.625,67.969,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.663 | Acc: 47.582,73.847,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.657 | Acc: 47.561,73.800,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.652 | Acc: 47.362,73.860,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.629 | Acc: 48.216,74.653,95.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.628 | Acc: 47.935,74.869,95.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.632 | Acc: 47.618,74.787,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.639 | Acc: 47.268,74.640,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.638 | Acc: 47.312,74.714,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.637 | Acc: 47.415,74.676,95.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.633 | Acc: 47.450,74.841,95.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.635 | Acc: 47.317,74.852,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.636 | Acc: 47.196,74.822,95.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.636 | Acc: 47.276,74.820,95.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.637 | Acc: 47.275,74.769,95.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.638 | Acc: 47.205,74.727,95.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.641 | Acc: 47.114,74.654,95.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.642 | Acc: 47.113,74.620,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.643 | Acc: 47.046,74.628,95.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.645 | Acc: 47.039,74.559,95.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.215 | Acc: 44.531,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.193 | Acc: 41.369,60.789,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.203 | Acc: 40.263,60.442,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.229 | Acc: 39.921,60.451,68.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.707 | Acc: 38.281,65.625,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.599 | Acc: 46.540,74.368,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.617 | Acc: 46.723,75.038,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.618 | Acc: 46.670,75.282,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.624 | Acc: 47.010,75.058,95.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.629 | Acc: 46.898,74.861,95.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.628 | Acc: 46.927,74.800,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.626 | Acc: 47.285,74.961,95.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.623 | Acc: 47.321,75.082,95.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.627 | Acc: 47.415,74.953,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.630 | Acc: 47.450,74.880,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.631 | Acc: 47.479,74.844,95.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.631 | Acc: 47.465,74.838,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.629 | Acc: 47.596,74.811,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.632 | Acc: 47.528,74.772,95.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.635 | Acc: 47.545,74.665,95.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.637 | Acc: 47.510,74.606,95.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.637 | Acc: 47.478,74.583,95.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.637 | Acc: 47.487,74.604,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.638 | Acc: 47.408,74.588,95.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.964 | Acc: 49.219,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.061 | Acc: 43.936,62.128,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.068 | Acc: 42.854,61.623,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.086 | Acc: 42.367,61.668,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.723 | Acc: 49.219,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.643 | Acc: 47.470,75.521,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.636 | Acc: 47.485,74.886,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.632 | Acc: 47.682,74.795,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.631 | Acc: 47.656,74.797,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.622 | Acc: 47.649,74.876,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.630 | Acc: 47.333,74.793,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.631 | Acc: 47.285,74.867,94.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.636 | Acc: 47.059,74.854,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.634 | Acc: 47.333,74.862,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.638 | Acc: 47.236,74.786,94.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.644 | Acc: 47.055,74.636,94.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.643 | Acc: 47.112,74.715,94.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.644 | Acc: 47.094,74.638,94.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.644 | Acc: 47.086,74.619,94.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.645 | Acc: 47.103,74.613,94.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.648 | Acc: 47.070,74.611,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.651 | Acc: 47.045,74.572,94.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.652 | Acc: 47.001,74.565,94.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.652 | Acc: 47.039,74.530,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.055 | Acc: 48.438,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.136 | Acc: 43.899,62.054,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.140 | Acc: 41.978,61.128,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.172 | Acc: 41.381,61.053,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.685 | Acc: 44.531,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.621 | Acc: 46.726,75.372,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.625 | Acc: 46.570,75.610,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.626 | Acc: 46.606,75.346,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.633 | Acc: 46.914,75.154,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.632 | Acc: 47.061,75.162,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.630 | Acc: 47.314,75.187,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.632 | Acc: 47.407,75.116,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.636 | Acc: 47.103,75.126,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.636 | Acc: 47.220,75.155,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.637 | Acc: 47.132,75.089,95.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.636 | Acc: 47.183,75.081,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.636 | Acc: 47.277,75.055,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.636 | Acc: 47.258,75.033,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.639 | Acc: 47.236,75.025,95.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.640 | Acc: 47.184,74.948,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.641 | Acc: 47.138,74.886,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.644 | Acc: 47.212,74.890,94.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.646 | Acc: 47.107,74.851,94.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.646 | Acc: 47.168,74.865,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.088 | Acc: 45.312,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.133 | Acc: 42.448,62.872,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.162 | Acc: 41.711,61.566,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.174 | Acc: 41.342,61.258,68.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.579 | Acc: 53.125,75.000,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.604 | Acc: 48.214,75.856,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.637 | Acc: 47.085,75.762,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.606 | Acc: 47.707,76.268,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.592 | Acc: 47.598,76.186,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.592 | Acc: 47.339,76.122,95.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.590 | Acc: 47.256,76.007,95.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.589 | Acc: 47.307,75.909,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.583 | Acc: 47.574,76.034,95.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.585 | Acc: 47.587,76.010,95.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.581 | Acc: 47.648,76.096,95.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.580 | Acc: 47.660,76.160,95.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.579 | Acc: 47.630,76.089,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.578 | Acc: 47.647,76.039,96.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.579 | Acc: 47.748,75.962,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.579 | Acc: 47.783,75.976,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.579 | Acc: 47.814,75.910,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.578 | Acc: 47.830,75.928,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.576 | Acc: 47.870,76.015,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.575 | Acc: 47.890,76.013,96.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.018 | Acc: 47.656,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.934 | Acc: 45.461,64.472,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.950 | Acc: 44.074,63.567,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.971 | Acc: 43.814,63.371,70.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.332 | Acc: 46.094,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.538 | Acc: 49.033,76.786,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.543 | Acc: 49.409,76.181,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.533 | Acc: 49.372,76.409,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.541 | Acc: 49.122,76.399,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.547 | Acc: 49.095,76.214,96.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.542 | Acc: 49.083,76.472,96.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.542 | Acc: 48.886,76.585,96.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.543 | Acc: 48.913,76.533,96.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.543 | Acc: 48.921,76.545,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.537 | Acc: 48.962,76.784,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.536 | Acc: 48.939,76.768,96.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.535 | Acc: 48.820,76.734,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.536 | Acc: 48.812,76.691,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.536 | Acc: 48.721,76.696,96.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.536 | Acc: 48.806,76.716,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.538 | Acc: 48.681,76.657,96.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.541 | Acc: 48.591,76.640,96.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.541 | Acc: 48.557,76.643,96.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.543 | Acc: 48.495,76.642,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.001 | Acc: 46.875,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.932 | Acc: 45.424,64.062,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.945 | Acc: 44.112,63.377,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.965 | Acc: 44.045,63.179,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.396 | Acc: 55.469,77.344,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.533 | Acc: 47.359,77.121,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.534 | Acc: 47.351,77.001,97.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.548 | Acc: 47.592,76.511,97.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.542 | Acc: 47.946,76.620,97.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.544 | Acc: 48.144,76.431,96.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.542 | Acc: 48.089,76.498,96.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.540 | Acc: 48.050,76.612,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.536 | Acc: 48.234,76.669,96.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.538 | Acc: 48.230,76.537,96.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.537 | Acc: 48.165,76.597,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.539 | Acc: 48.155,76.580,96.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.541 | Acc: 48.061,76.537,96.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.540 | Acc: 48.081,76.554,96.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.539 | Acc: 48.112,76.601,96.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.540 | Acc: 48.035,76.573,96.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.541 | Acc: 48.009,76.545,96.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.540 | Acc: 47.993,76.567,96.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.541 | Acc: 48.044,76.617,96.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.539 | Acc: 48.058,76.601,96.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.005 | Acc: 48.438,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 45.685,64.174,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.954 | Acc: 44.131,63.529,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.975 | Acc: 43.737,63.332,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.611 | Acc: 42.188,71.875,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.535 | Acc: 48.549,75.856,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.536 | Acc: 48.571,76.524,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.524 | Acc: 48.399,76.870,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.524 | Acc: 48.573,76.688,97.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.532 | Acc: 48.329,76.617,97.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.534 | Acc: 48.373,76.627,97.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.532 | Acc: 48.144,76.684,97.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.533 | Acc: 48.399,76.650,97.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.534 | Acc: 48.299,76.692,97.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.535 | Acc: 48.333,76.636,97.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.536 | Acc: 48.187,76.661,97.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.539 | Acc: 48.188,76.588,97.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.538 | Acc: 48.141,76.622,97.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.536 | Acc: 48.207,76.635,97.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.532 | Acc: 48.341,76.700,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.531 | Acc: 48.355,76.765,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.532 | Acc: 48.314,76.773,97.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.533 | Acc: 48.223,76.757,97.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.532 | Acc: 48.292,76.827,97.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.002 | Acc: 46.875,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.957 | Acc: 45.573,64.397,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.968 | Acc: 44.150,63.624,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.993 | Acc: 43.776,63.461,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.498 | Acc: 50.000,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.519 | Acc: 49.628,76.562,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.537 | Acc: 48.152,77.039,97.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.527 | Acc: 48.502,77.075,97.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.529 | Acc: 48.409,76.890,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.534 | Acc: 48.167,76.771,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.533 | Acc: 48.160,76.898,97.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.534 | Acc: 48.160,76.840,97.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.531 | Acc: 48.268,76.834,97.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.532 | Acc: 48.213,76.903,97.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.534 | Acc: 48.259,76.877,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.528 | Acc: 48.388,76.965,97.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 48.457,77.000,97.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.529 | Acc: 48.354,77.006,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.529 | Acc: 48.210,76.980,97.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.526 | Acc: 48.217,77.025,97.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.529 | Acc: 48.192,76.911,97.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.528 | Acc: 48.213,76.929,97.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.528 | Acc: 48.234,76.930,97.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.530 | Acc: 48.120,76.845,97.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.967 | Acc: 48.438,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.942 | Acc: 45.536,64.323,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.954 | Acc: 44.131,63.453,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.975 | Acc: 43.852,63.217,70.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.437 | Acc: 50.781,73.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.530 | Acc: 49.368,76.079,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.532 | Acc: 48.323,76.391,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.525 | Acc: 48.502,77.100,97.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.528 | Acc: 48.360,77.160,97.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.532 | Acc: 47.803,77.011,97.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 47.721,77.286,97.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.529 | Acc: 47.773,77.244,97.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.531 | Acc: 47.802,77.169,97.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.531 | Acc: 47.794,76.985,97.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.530 | Acc: 47.905,77.021,97.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.532 | Acc: 47.978,76.934,97.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.530 | Acc: 48.130,76.964,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.528 | Acc: 48.087,76.973,97.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.528 | Acc: 48.040,77.002,97.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.529 | Acc: 48.087,76.993,97.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.530 | Acc: 48.058,76.918,97.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.529 | Acc: 48.062,76.984,97.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.529 | Acc: 48.096,77.010,97.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.528 | Acc: 48.089,77.042,97.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.976 | Acc: 46.875,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.941 | Acc: 45.499,65.030,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.955 | Acc: 44.169,64.101,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.970 | Acc: 43.968,63.717,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.337 | Acc: 48.438,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.555 | Acc: 49.144,75.967,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.542 | Acc: 48.704,76.220,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.538 | Acc: 48.578,76.819,96.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.530 | Acc: 48.312,76.852,96.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.524 | Acc: 48.306,76.864,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.528 | Acc: 48.205,76.717,97.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.529 | Acc: 48.227,76.729,97.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.527 | Acc: 48.525,76.849,97.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.525 | Acc: 48.597,76.990,97.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.526 | Acc: 48.488,76.893,97.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.526 | Acc: 48.445,76.962,97.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 48.506,76.893,97.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.529 | Acc: 48.420,76.814,96.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.529 | Acc: 48.432,76.866,96.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.529 | Acc: 48.388,76.928,97.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.529 | Acc: 48.274,76.923,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.530 | Acc: 48.250,76.963,97.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.526 | Acc: 48.280,77.028,97.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.525 | Acc: 48.257,77.053,97.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.007 | Acc: 47.656,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 45.499,64.546,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.959 | Acc: 44.169,63.624,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.979 | Acc: 43.891,63.397,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.438 | Acc: 49.219,75.000,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.511 | Acc: 48.958,77.641,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.524 | Acc: 48.476,77.229,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.520 | Acc: 48.438,77.267,96.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.523 | Acc: 48.274,77.103,96.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.525 | Acc: 48.113,77.058,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.520 | Acc: 48.354,77.331,97.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.517 | Acc: 48.587,77.316,97.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.521 | Acc: 48.384,77.213,97.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.527 | Acc: 48.204,76.938,97.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.523 | Acc: 48.301,77.021,97.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.521 | Acc: 48.278,77.160,97.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.523 | Acc: 48.211,77.208,97.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.520 | Acc: 48.267,77.281,97.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.518 | Acc: 48.343,77.302,97.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.519 | Acc: 48.393,77.271,97.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.521 | Acc: 48.287,77.173,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.521 | Acc: 48.325,77.170,97.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.521 | Acc: 48.347,77.130,97.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.523 | Acc: 48.269,77.083,97.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.980 | Acc: 47.656,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.943 | Acc: 45.126,64.621,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.959 | Acc: 43.998,63.681,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.979 | Acc: 43.635,63.384,70.415,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.510 | Acc: 48.438,77.344,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.527 | Acc: 47.545,76.562,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.541 | Acc: 47.542,76.677,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.535 | Acc: 47.925,76.972,96.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.537 | Acc: 47.753,76.688,96.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.537 | Acc: 47.973,76.485,96.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 48.257,76.763,97.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.523 | Acc: 48.188,76.856,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.526 | Acc: 48.239,76.747,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.524 | Acc: 48.179,76.787,97.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.524 | Acc: 48.092,76.776,97.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.524 | Acc: 48.133,76.831,97.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.524 | Acc: 48.133,76.990,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.525 | Acc: 48.072,77.026,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.521 | Acc: 48.157,77.116,97.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.520 | Acc: 48.282,77.185,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.519 | Acc: 48.311,77.227,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.520 | Acc: 48.254,77.238,97.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.519 | Acc: 48.301,77.236,97.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.519 | Acc: 48.382,77.256,97.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.009 | Acc: 46.875,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.947 | Acc: 45.424,64.360,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.966 | Acc: 43.979,63.662,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.988 | Acc: 43.558,63.576,70.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.662 | Acc: 36.719,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.524 | Acc: 46.912,76.637,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.514 | Acc: 47.466,77.001,97.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.501 | Acc: 48.553,77.241,97.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.504 | Acc: 48.409,77.324,97.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.510 | Acc: 48.229,77.197,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.514 | Acc: 48.502,77.195,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.512 | Acc: 48.377,77.150,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 48.394,77.125,97.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.513 | Acc: 48.381,77.059,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.510 | Acc: 48.406,77.126,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.511 | Acc: 48.512,77.082,97.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.510 | Acc: 48.651,77.221,97.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.514 | Acc: 48.515,77.212,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.517 | Acc: 48.429,77.124,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.517 | Acc: 48.404,77.126,97.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.516 | Acc: 48.355,77.271,97.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.517 | Acc: 48.293,77.218,97.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.520 | Acc: 48.210,77.110,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.519 | Acc: 48.239,77.114,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.974 | Acc: 49.219,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 45.164,64.807,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.958 | Acc: 43.731,63.567,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 43.532,63.461,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.443 | Acc: 49.219,79.688,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.493 | Acc: 49.777,76.860,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.479 | Acc: 50.038,77.725,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 49.129,77.357,97.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.506 | Acc: 48.823,76.852,97.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.514 | Acc: 48.592,76.609,97.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.513 | Acc: 48.444,76.892,97.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.509 | Acc: 48.498,76.978,97.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.511 | Acc: 48.549,77.043,97.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 48.472,76.994,97.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 48.457,76.947,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.517 | Acc: 48.363,76.891,97.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.518 | Acc: 48.343,76.900,97.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.521 | Acc: 48.303,76.844,97.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.520 | Acc: 48.298,76.824,97.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.518 | Acc: 48.214,76.939,97.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.519 | Acc: 48.248,76.949,97.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.517 | Acc: 48.385,77.028,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.514 | Acc: 48.459,77.140,97.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.514 | Acc: 48.558,77.069,97.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.030 | Acc: 49.219,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 45.461,64.472,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.968 | Acc: 44.245,63.491,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.987 | Acc: 43.929,63.332,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.450 | Acc: 51.562,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.506 | Acc: 47.693,77.418,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.519 | Acc: 48.018,77.687,97.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.522 | Acc: 48.361,77.536,97.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.515 | Acc: 48.351,77.730,97.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.520 | Acc: 48.399,77.653,97.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.525 | Acc: 48.302,77.447,97.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.527 | Acc: 48.022,77.338,97.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.532 | Acc: 47.996,77.150,97.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.530 | Acc: 48.049,77.111,97.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.532 | Acc: 47.905,77.060,97.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.529 | Acc: 47.950,77.213,97.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 48.107,77.272,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.527 | Acc: 48.090,77.185,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.522 | Acc: 48.132,77.305,97.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.519 | Acc: 48.321,77.393,97.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.519 | Acc: 48.328,77.390,97.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.520 | Acc: 48.243,77.351,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.517 | Acc: 48.321,77.326,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.516 | Acc: 48.339,77.377,97.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.999 | Acc: 46.875,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.955 | Acc: 45.015,64.174,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.969 | Acc: 43.807,63.357,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 43.558,63.204,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.474 | Acc: 53.125,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.544 | Acc: 48.438,77.158,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.530 | Acc: 48.438,77.515,97.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.513 | Acc: 48.758,77.818,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.518 | Acc: 48.447,77.556,97.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.514 | Acc: 48.561,77.475,97.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.516 | Acc: 48.592,77.331,97.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 48.227,77.028,97.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.522 | Acc: 48.185,76.946,97.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 48.109,76.929,97.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.520 | Acc: 48.185,76.905,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.519 | Acc: 48.155,76.962,97.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.521 | Acc: 48.204,77.071,97.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.518 | Acc: 48.267,77.221,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.515 | Acc: 48.332,77.374,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.518 | Acc: 48.245,77.289,97.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.517 | Acc: 48.231,77.254,97.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.515 | Acc: 48.273,77.307,97.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.513 | Acc: 48.357,77.357,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.515 | Acc: 48.296,77.284,97.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.017 | Acc: 49.219,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 45.461,64.807,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.972 | Acc: 44.112,63.472,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.988 | Acc: 43.801,63.320,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.668 | Acc: 40.625,69.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.505 | Acc: 48.624,77.344,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.505 | Acc: 48.323,77.611,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.502 | Acc: 48.092,77.741,97.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 48.139,77.951,97.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.510 | Acc: 47.904,77.638,97.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.516 | Acc: 48.031,77.563,97.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.514 | Acc: 48.155,77.427,97.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.516 | Acc: 48.277,77.271,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.512 | Acc: 48.321,77.223,97.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.510 | Acc: 48.305,77.243,97.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.513 | Acc: 48.183,77.110,97.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.511 | Acc: 48.243,77.152,97.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.512 | Acc: 48.321,77.161,97.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.513 | Acc: 48.396,77.141,97.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.512 | Acc: 48.469,77.087,97.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.512 | Acc: 48.493,77.166,97.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.512 | Acc: 48.438,77.231,97.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.513 | Acc: 48.412,77.218,97.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.511 | Acc: 48.526,77.264,97.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.050 | Acc: 49.219,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 45.461,64.062,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.973 | Acc: 44.112,63.396,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.992 | Acc: 43.865,63.294,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.562 | Acc: 39.062,82.031,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.508 | Acc: 48.140,78.199,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.499 | Acc: 48.685,78.468,97.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.505 | Acc: 48.245,77.830,97.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.511 | Acc: 47.859,77.643,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.509 | Acc: 47.950,77.522,97.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.506 | Acc: 48.173,77.518,97.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.509 | Acc: 48.122,77.455,97.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.506 | Acc: 48.321,77.446,97.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.509 | Acc: 48.183,77.378,97.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 48.278,77.414,97.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.508 | Acc: 48.324,77.361,97.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.507 | Acc: 48.463,77.331,97.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 48.390,77.233,97.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 48.318,77.213,97.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.509 | Acc: 48.212,77.243,97.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.510 | Acc: 48.211,77.271,97.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.509 | Acc: 48.222,77.289,97.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.510 | Acc: 48.232,77.279,97.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 48.196,77.268,97.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.977 | Acc: 48.438,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.946 | Acc: 45.350,64.472,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 44.245,63.510,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.991 | Acc: 43.840,63.409,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.554 | Acc: 44.531,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.506 | Acc: 47.954,78.646,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.532 | Acc: 47.428,77.687,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.517 | Acc: 47.925,77.702,97.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.498 | Acc: 48.708,77.758,97.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.502 | Acc: 48.708,77.568,97.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 48.612,77.492,97.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.506 | Acc: 48.393,77.360,97.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.511 | Acc: 48.316,77.271,97.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 48.286,77.352,97.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 48.169,77.243,97.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.516 | Acc: 48.137,77.209,97.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.517 | Acc: 47.980,77.234,97.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.514 | Acc: 48.108,77.293,97.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.514 | Acc: 48.073,77.296,97.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.509 | Acc: 48.227,77.372,97.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.511 | Acc: 48.199,77.285,97.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.510 | Acc: 48.247,77.385,97.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.511 | Acc: 48.247,77.339,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.512 | Acc: 48.136,77.284,97.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.988 | Acc: 49.219,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.950 | Acc: 45.387,64.844,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 44.284,63.720,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.990 | Acc: 43.776,63.576,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.573 | Acc: 39.844,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.515 | Acc: 46.577,77.121,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.506 | Acc: 47.599,77.877,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.509 | Acc: 47.707,77.702,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.501 | Acc: 48.110,77.768,97.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.515 | Acc: 47.656,77.630,97.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.515 | Acc: 47.482,77.447,97.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.517 | Acc: 47.285,77.360,97.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.514 | Acc: 47.530,77.421,97.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.518 | Acc: 47.600,77.421,97.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 47.613,77.348,97.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.517 | Acc: 47.685,77.287,97.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.516 | Acc: 47.802,77.285,97.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.517 | Acc: 47.830,77.296,97.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.513 | Acc: 47.970,77.366,97.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.514 | Acc: 48.056,77.354,97.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.512 | Acc: 48.114,77.400,97.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.513 | Acc: 48.183,77.332,97.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.514 | Acc: 48.256,77.337,97.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.512 | Acc: 48.257,77.381,97.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.056 | Acc: 47.656,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 45.871,64.323,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 44.303,63.262,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.005 | Acc: 43.776,63.294,69.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.438 | Acc: 53.125,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.489 | Acc: 47.470,78.571,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.508 | Acc: 48.018,77.649,97.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.509 | Acc: 48.169,77.357,97.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.510 | Acc: 48.380,77.296,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.506 | Acc: 48.352,77.282,97.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 48.308,77.305,97.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.507 | Acc: 48.327,77.255,97.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 48.137,77.087,97.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.506 | Acc: 48.148,77.124,97.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.507 | Acc: 48.107,77.126,97.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.508 | Acc: 48.112,77.089,97.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.506 | Acc: 48.249,77.159,97.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.512 | Acc: 48.081,77.032,97.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.513 | Acc: 48.134,77.077,97.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.510 | Acc: 48.152,77.206,97.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.511 | Acc: 48.180,77.210,97.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.508 | Acc: 48.305,77.234,97.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.507 | Acc: 48.308,77.246,97.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.508 | Acc: 48.251,77.251,97.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.050 | Acc: 49.219,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.947 | Acc: 45.685,64.323,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.964 | Acc: 44.474,63.338,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.987 | Acc: 44.147,63.204,70.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.512 | Acc: 48.438,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.494 | Acc: 48.698,77.641,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.484 | Acc: 48.857,77.458,97.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.479 | Acc: 49.052,77.587,97.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.485 | Acc: 48.872,77.739,97.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.493 | Acc: 48.608,77.460,97.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.497 | Acc: 48.696,77.460,97.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.500 | Acc: 48.504,77.366,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 48.200,77.266,97.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 48.252,77.262,97.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.509 | Acc: 48.309,77.262,97.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 48.406,77.287,97.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.508 | Acc: 48.382,77.217,97.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.509 | Acc: 48.330,77.164,97.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.506 | Acc: 48.465,77.271,97.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.506 | Acc: 48.534,77.284,97.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 48.635,77.341,97.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 48.696,77.390,97.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.505 | Acc: 48.676,77.378,97.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 48.684,77.372,97.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.045 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 45.610,64.546,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.978 | Acc: 44.360,63.605,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.997 | Acc: 43.712,63.397,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.414 | Acc: 52.344,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.502 | Acc: 48.214,78.162,97.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.516 | Acc: 47.752,76.753,97.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.507 | Acc: 48.079,77.088,97.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.500 | Acc: 47.984,77.305,97.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.501 | Acc: 48.198,77.375,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 48.115,77.479,97.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 47.961,77.322,97.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.503 | Acc: 48.064,77.421,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.505 | Acc: 48.002,77.426,97.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.503 | Acc: 47.936,77.519,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.502 | Acc: 48.006,77.531,97.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 48.068,77.532,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 48.135,77.487,97.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.506 | Acc: 48.109,77.444,97.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.506 | Acc: 48.186,77.453,97.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 48.335,77.492,97.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.504 | Acc: 48.318,77.467,97.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.505 | Acc: 48.290,77.497,97.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 48.278,77.512,97.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.031 | Acc: 49.219,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.948 | Acc: 45.573,64.807,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 44.360,63.872,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.989 | Acc: 44.121,63.781,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.507 | Acc: 46.875,75.781,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.505 | Acc: 47.879,76.562,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.504 | Acc: 48.438,77.134,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.506 | Acc: 48.732,76.960,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.497 | Acc: 48.920,77.054,97.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.502 | Acc: 48.530,76.856,97.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 48.528,76.924,97.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 48.504,77.006,97.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.502 | Acc: 48.709,77.082,97.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.502 | Acc: 48.645,77.232,97.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.500 | Acc: 48.752,77.328,97.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.502 | Acc: 48.688,77.333,97.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.504 | Acc: 48.664,77.250,97.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.505 | Acc: 48.629,77.341,97.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 48.657,77.377,97.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 48.643,77.372,97.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 48.579,77.302,97.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.506 | Acc: 48.538,77.231,97.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.506 | Acc: 48.582,77.238,97.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.505 | Acc: 48.610,77.303,97.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.081 | Acc: 46.094,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 45.089,64.174,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.980 | Acc: 44.055,63.205,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.005 | Acc: 43.609,63.230,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.472 | Acc: 54.688,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.469 | Acc: 50.149,79.315,97.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.483 | Acc: 48.914,79.059,97.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.488 | Acc: 48.604,78.522,97.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.490 | Acc: 48.785,78.549,97.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.502 | Acc: 48.484,78.280,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.502 | Acc: 48.573,78.093,97.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.499 | Acc: 48.709,78.097,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.500 | Acc: 48.666,78.062,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.498 | Acc: 48.709,77.948,97.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.503 | Acc: 48.647,77.857,97.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.505 | Acc: 48.558,77.839,97.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.506 | Acc: 48.544,77.736,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.508 | Acc: 48.476,77.661,97.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.507 | Acc: 48.638,77.577,97.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.506 | Acc: 48.731,77.549,97.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 48.756,77.514,97.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.505 | Acc: 48.742,77.520,97.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 48.719,77.560,97.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 48.686,77.506,97.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.037 | Acc: 49.219,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 45.536,64.509,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.977 | Acc: 44.474,63.586,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.998 | Acc: 43.993,63.550,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.585 | Acc: 44.531,74.219,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.524 | Acc: 47.842,77.344,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.519 | Acc: 48.323,77.001,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.501 | Acc: 48.527,77.523,97.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 48.293,77.209,97.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.509 | Acc: 48.391,77.150,97.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 48.670,77.331,97.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.500 | Acc: 48.969,77.582,97.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.505 | Acc: 48.743,77.480,97.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.504 | Acc: 48.627,77.443,97.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.502 | Acc: 48.737,77.445,97.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.502 | Acc: 48.717,77.588,97.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 48.758,77.593,97.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 48.581,77.508,97.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 48.574,77.438,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.508 | Acc: 48.687,77.429,97.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.510 | Acc: 48.574,77.385,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.509 | Acc: 48.566,77.390,97.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.507 | Acc: 48.580,77.445,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.506 | Acc: 48.634,77.446,97.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.079 | Acc: 47.656,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 45.722,64.955,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.978 | Acc: 44.627,64.024,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 44.045,63.909,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.460 | Acc: 52.344,77.344,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.507 | Acc: 49.070,77.158,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.527 | Acc: 47.942,77.115,97.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.523 | Acc: 48.194,76.793,97.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.523 | Acc: 48.187,76.919,97.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.522 | Acc: 47.726,77.058,97.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.518 | Acc: 47.869,77.073,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.509 | Acc: 48.044,77.277,97.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 48.287,77.378,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.504 | Acc: 48.412,77.344,97.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.503 | Acc: 48.546,77.344,97.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 48.526,77.354,97.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.504 | Acc: 48.450,77.305,97.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 48.488,77.344,97.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.503 | Acc: 48.451,77.424,97.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 48.565,77.424,97.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.501 | Acc: 48.591,77.366,97.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 48.527,77.314,97.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.502 | Acc: 48.494,77.279,97.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 48.438,77.301,97.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.073 | Acc: 47.656,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 45.238,64.621,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.974 | Acc: 44.188,63.453,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.996 | Acc: 43.814,63.371,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.487 | Acc: 44.531,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.501 | Acc: 47.805,77.344,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 47.580,77.420,97.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 48.322,77.267,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.496 | Acc: 48.302,77.112,97.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.499 | Acc: 48.205,77.088,97.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 48.024,77.279,97.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 48.205,77.144,97.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.503 | Acc: 48.093,77.203,97.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.502 | Acc: 48.161,77.326,97.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.501 | Acc: 48.298,77.398,97.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.502 | Acc: 48.243,77.326,97.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 48.311,77.366,97.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 48.390,77.428,97.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 48.493,77.441,97.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 48.526,77.435,97.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.500 | Acc: 48.433,77.446,97.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.499 | Acc: 48.504,77.465,97.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 48.483,77.471,97.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.499 | Acc: 48.456,77.465,97.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.053 | Acc: 49.219,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 45.238,64.583,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.988 | Acc: 44.188,63.548,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.010 | Acc: 43.865,63.384,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.592 | Acc: 45.312,76.562,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.494 | Acc: 48.028,78.609,97.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 47.999,78.258,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.498 | Acc: 48.181,77.933,97.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.498 | Acc: 48.312,77.826,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.509 | Acc: 47.997,77.545,97.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.506 | Acc: 48.115,77.531,97.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.507 | Acc: 48.210,77.499,97.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 48.384,77.407,97.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.505 | Acc: 48.446,77.279,97.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.506 | Acc: 48.383,77.177,97.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.504 | Acc: 48.462,77.248,97.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.504 | Acc: 48.493,77.302,97.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 48.506,77.233,97.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 48.474,77.224,97.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.503 | Acc: 48.453,77.292,97.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 48.523,77.310,97.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.507 | Acc: 48.412,77.222,97.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.507 | Acc: 48.407,77.262,97.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.506 | Acc: 48.491,77.278,97.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.075 | Acc: 47.656,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.958 | Acc: 45.499,64.472,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.982 | Acc: 43.998,63.624,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.004 | Acc: 43.737,63.589,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.478 | Acc: 46.094,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.534 | Acc: 47.433,77.269,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.501 | Acc: 48.323,77.973,97.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.506 | Acc: 48.194,77.766,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 48.139,77.758,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.512 | Acc: 48.368,77.622,97.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.516 | Acc: 48.302,77.382,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.511 | Acc: 48.310,77.504,97.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 48.394,77.664,97.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 48.433,77.465,97.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.507 | Acc: 48.589,77.499,97.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.504 | Acc: 48.575,77.648,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.504 | Acc: 48.635,77.616,97.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.501 | Acc: 48.638,77.643,97.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.501 | Acc: 48.618,77.577,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 48.575,77.523,97.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 48.584,77.446,97.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.501 | Acc: 48.621,77.577,97.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.500 | Acc: 48.621,77.662,97.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 48.618,77.629,97.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.017 | Acc: 48.438,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.957 | Acc: 45.871,64.323,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.978 | Acc: 44.531,63.529,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.999 | Acc: 43.968,63.320,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.460 | Acc: 45.312,81.250,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.494 | Acc: 48.214,77.753,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.521 | Acc: 47.656,76.810,97.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.513 | Acc: 47.836,76.678,97.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.521 | Acc: 47.598,76.640,97.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.518 | Acc: 47.517,76.934,97.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.509 | Acc: 47.856,76.989,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.509 | Acc: 47.584,77.039,97.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.505 | Acc: 47.763,77.111,97.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.504 | Acc: 47.820,77.206,97.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.500 | Acc: 48.006,77.309,97.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 48.172,77.337,97.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.497 | Acc: 48.275,77.409,97.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.498 | Acc: 48.321,77.440,97.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 48.343,77.461,97.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.498 | Acc: 48.370,77.544,97.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.498 | Acc: 48.374,77.536,97.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.497 | Acc: 48.353,77.571,97.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.497 | Acc: 48.388,77.595,97.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.499 | Acc: 48.405,77.561,97.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.057 | Acc: 47.656,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.970 | Acc: 45.610,64.100,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.982 | Acc: 44.360,63.377,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.007 | Acc: 44.032,63.409,70.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.595 | Acc: 46.094,72.656,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.492 | Acc: 49.033,77.418,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 48.552,77.706,97.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.504 | Acc: 48.194,77.357,97.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.506 | Acc: 48.206,77.450,97.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.505 | Acc: 48.345,77.452,97.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.508 | Acc: 48.063,77.415,97.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 48.260,77.416,97.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.506 | Acc: 48.273,77.567,97.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.506 | Acc: 48.381,77.421,97.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.504 | Acc: 48.387,77.433,97.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.500 | Acc: 48.505,77.506,97.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 48.483,77.363,97.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 48.479,77.356,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 48.538,77.358,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 48.572,77.375,97.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.501 | Acc: 48.581,77.424,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 48.543,77.399,97.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.502 | Acc: 48.606,77.385,97.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 48.620,77.303,97.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.085 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.958 | Acc: 45.945,64.769,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.980 | Acc: 44.417,63.662,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.003 | Acc: 44.083,63.537,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.392 | Acc: 46.875,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.488 | Acc: 48.065,77.939,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.479 | Acc: 48.704,78.125,97.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.485 | Acc: 48.591,77.843,97.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.495 | Acc: 48.428,77.845,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 48.035,77.731,97.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 48.212,77.544,97.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 48.410,77.443,97.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 48.554,77.319,97.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.503 | Acc: 48.412,77.430,97.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.502 | Acc: 48.391,77.511,97.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 48.498,77.588,97.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.497 | Acc: 48.483,77.593,97.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.497 | Acc: 48.533,77.652,97.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.496 | Acc: 48.604,77.641,97.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.497 | Acc: 48.606,77.570,97.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.496 | Acc: 48.666,77.633,97.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.498 | Acc: 48.591,77.582,97.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.498 | Acc: 48.576,77.595,97.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.500 | Acc: 48.479,77.563,97.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.038 | Acc: 46.875,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 45.796,64.509,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.978 | Acc: 44.417,63.624,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 44.057,63.397,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.522 | Acc: 39.844,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.467 | Acc: 48.735,79.055,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.463 | Acc: 49.143,78.411,97.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 48.732,77.395,97.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.496 | Acc: 48.302,77.170,97.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.487 | Acc: 48.708,77.684,97.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 48.922,77.815,97.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.493 | Acc: 48.903,77.648,97.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.496 | Acc: 48.801,77.567,97.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.496 | Acc: 48.636,77.568,97.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.493 | Acc: 48.772,77.507,97.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 48.635,77.439,97.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 48.655,77.503,97.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.494 | Acc: 48.623,77.532,97.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.497 | Acc: 48.482,77.508,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.498 | Acc: 48.476,77.564,97.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.497 | Acc: 48.571,77.573,97.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.499 | Acc: 48.557,77.513,97.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.502 | Acc: 48.357,77.448,97.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.503 | Acc: 48.327,77.375,97.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.041 | Acc: 48.438,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 45.722,64.360,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.982 | Acc: 44.493,63.491,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.005 | Acc: 44.147,63.422,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.517 | Acc: 43.750,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.489 | Acc: 48.810,77.158,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.507 | Acc: 48.571,76.582,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.493 | Acc: 49.014,77.254,97.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 48.862,77.382,97.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.499 | Acc: 48.700,77.282,97.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.498 | Acc: 48.812,77.344,97.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.493 | Acc: 49.119,77.316,97.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.493 | Acc: 49.005,77.412,97.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.495 | Acc: 48.856,77.413,97.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.497 | Acc: 48.772,77.441,97.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.497 | Acc: 48.713,77.482,97.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.497 | Acc: 48.713,77.525,97.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.497 | Acc: 48.734,77.463,97.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 48.599,77.399,97.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.499 | Acc: 48.653,77.352,97.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.498 | Acc: 48.622,77.324,97.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 48.648,77.312,97.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.500 | Acc: 48.613,77.324,97.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.499 | Acc: 48.653,77.350,97.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.062 | Acc: 48.438,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.964 | Acc: 45.089,64.360,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.987 | Acc: 43.921,63.415,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.008 | Acc: 43.673,63.320,69.736,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.279 | Acc: 53.906,78.125,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.507 | Acc: 49.107,76.749,97.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.522 | Acc: 48.952,76.353,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.515 | Acc: 48.873,76.550,97.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.514 | Acc: 48.717,76.640,97.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.509 | Acc: 48.793,76.818,97.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.499 | Acc: 48.831,77.163,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.494 | Acc: 48.748,77.449,97.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.495 | Acc: 48.772,77.460,97.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 48.783,77.521,97.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.495 | Acc: 48.605,77.507,97.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 48.551,77.503,97.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.495 | Acc: 48.454,77.697,97.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.497 | Acc: 48.551,77.643,97.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 48.474,77.555,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 48.406,77.466,97.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.501 | Acc: 48.433,77.480,97.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 48.511,77.504,97.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 48.585,77.500,97.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.500 | Acc: 48.602,77.547,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.975 | Acc: 47.656,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 45.722,64.472,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.979 | Acc: 44.379,63.643,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.007 | Acc: 43.955,63.473,70.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.601 | Acc: 47.656,74.219,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 49.368,77.493,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 48.990,77.439,97.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 48.770,77.728,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.490 | Acc: 48.438,77.894,97.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.487 | Acc: 48.670,78.195,97.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.490 | Acc: 48.754,78.028,97.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.496 | Acc: 48.620,77.820,97.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.497 | Acc: 48.539,77.780,97.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 48.632,77.685,97.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 48.690,77.729,97.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.488 | Acc: 48.759,77.814,97.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.487 | Acc: 48.716,77.801,97.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 48.794,77.841,97.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.488 | Acc: 48.818,77.758,97.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.492 | Acc: 48.718,77.673,97.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.490 | Acc: 48.727,77.714,97.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.492 | Acc: 48.664,77.681,97.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.493 | Acc: 48.660,77.684,97.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.493 | Acc: 48.632,77.637,97.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.033 | Acc: 49.219,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.975 | Acc: 45.685,64.360,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.992 | Acc: 44.531,63.510,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 44.160,63.448,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.572 | Acc: 46.875,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.517 | Acc: 47.507,76.414,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.492 | Acc: 48.171,77.210,97.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 47.938,77.369,97.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 48.013,77.276,97.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.508 | Acc: 48.136,77.158,97.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 48.212,77.066,97.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 48.155,77.238,97.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.498 | Acc: 48.234,77.378,97.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 48.217,77.439,97.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.497 | Acc: 48.154,77.488,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 48.218,77.588,97.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 48.185,77.503,97.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.496 | Acc: 48.282,77.565,97.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.497 | Acc: 48.285,77.516,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.498 | Acc: 48.339,77.484,97.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.500 | Acc: 48.228,77.390,97.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.501 | Acc: 48.215,77.380,97.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.500 | Acc: 48.171,77.355,97.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.498 | Acc: 48.204,77.385,97.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.039 | Acc: 47.656,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.993 | Acc: 45.573,64.583,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.007 | Acc: 44.512,63.605,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.028 | Acc: 44.019,63.614,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.447 | Acc: 53.125,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.495 | Acc: 49.182,77.790,97.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.499 | Acc: 48.685,77.344,97.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.505 | Acc: 48.809,77.357,97.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.503 | Acc: 48.630,77.450,97.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.512 | Acc: 48.499,77.290,97.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.506 | Acc: 48.509,77.628,97.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 48.582,77.621,97.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.499 | Acc: 48.607,77.717,97.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.500 | Acc: 48.658,77.814,97.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.496 | Acc: 48.741,77.849,97.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.495 | Acc: 48.706,77.853,97.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 48.732,77.824,97.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.493 | Acc: 48.785,77.880,97.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.492 | Acc: 48.838,77.930,97.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.493 | Acc: 48.840,77.855,97.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.489 | Acc: 48.859,77.906,97.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.494 | Acc: 48.708,77.811,97.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.494 | Acc: 48.715,77.759,97.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.495 | Acc: 48.653,77.733,97.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.013 | Acc: 47.656,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.973 | Acc: 45.424,64.546,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.993 | Acc: 44.455,63.453,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 43.981,63.384,70.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.314 | Acc: 58.594,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.460 | Acc: 49.665,78.125,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.479 | Acc: 49.371,77.839,97.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.478 | Acc: 48.924,78.125,97.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.476 | Acc: 49.064,78.318,97.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.476 | Acc: 48.963,78.388,97.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 48.612,78.073,97.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.481 | Acc: 48.709,78.053,97.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 48.641,78.115,97.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 48.515,77.892,97.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.485 | Acc: 48.612,77.970,97.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 48.618,77.987,97.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.489 | Acc: 48.515,77.918,97.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 48.509,77.895,97.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.490 | Acc: 48.524,77.819,97.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.491 | Acc: 48.580,77.707,97.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.492 | Acc: 48.423,77.670,97.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.492 | Acc: 48.415,77.733,97.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.494 | Acc: 48.422,77.664,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.493 | Acc: 48.464,77.649,97.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.100 | Acc: 48.438,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.979 | Acc: 45.275,64.509,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.998 | Acc: 43.807,63.510,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.024 | Acc: 43.584,63.256,70.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.514 | Acc: 44.531,80.469,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.471 | Acc: 47.991,78.571,97.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 48.323,78.068,97.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 48.463,78.227,97.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.491 | Acc: 48.119,78.202,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.494 | Acc: 48.267,78.171,97.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.492 | Acc: 48.354,78.002,97.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.483 | Acc: 48.659,78.230,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.488 | Acc: 48.578,78.052,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.482 | Acc: 48.632,78.289,97.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.483 | Acc: 48.605,78.257,97.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.480 | Acc: 48.759,78.344,97.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.483 | Acc: 48.619,78.261,97.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 48.587,78.089,97.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.485 | Acc: 48.590,78.030,97.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.487 | Acc: 48.528,77.985,97.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.490 | Acc: 48.452,77.908,97.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.489 | Acc: 48.497,77.864,97.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.489 | Acc: 48.567,77.841,97.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.489 | Acc: 48.567,77.848,97.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.031 | Acc: 50.000,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 45.945,64.769,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.979 | Acc: 44.760,63.681,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.001 | Acc: 44.262,63.512,70.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.376 | Acc: 49.219,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.470 | Acc: 49.777,77.455,97.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.487 | Acc: 48.742,77.611,97.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.485 | Acc: 48.694,77.626,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.490 | Acc: 48.814,77.556,97.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.486 | Acc: 48.956,77.591,97.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.484 | Acc: 48.747,77.570,97.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 48.709,77.593,97.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.482 | Acc: 48.806,77.649,97.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.479 | Acc: 48.860,77.702,97.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.479 | Acc: 49.048,77.748,97.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.482 | Acc: 48.844,77.694,97.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.481 | Acc: 48.927,77.674,97.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.479 | Acc: 48.922,77.778,97.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.481 | Acc: 48.924,77.672,97.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.482 | Acc: 48.861,77.679,97.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 48.798,77.643,97.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.486 | Acc: 48.751,77.536,97.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 48.736,77.541,97.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 48.729,77.536,97.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.067 | Acc: 50.000,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.968 | Acc: 45.424,64.472,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.985 | Acc: 44.055,63.510,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.012 | Acc: 43.827,63.397,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.383 | Acc: 55.469,79.688,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.467 | Acc: 50.112,78.869,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.471 | Acc: 50.286,78.354,97.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.473 | Acc: 49.744,78.279,97.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 49.171,78.115,97.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.498 | Acc: 48.654,77.932,97.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.499 | Acc: 48.709,77.931,97.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.499 | Acc: 48.504,77.709,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.499 | Acc: 48.423,77.683,97.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.497 | Acc: 48.403,77.732,97.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.496 | Acc: 48.395,77.678,97.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.495 | Acc: 48.466,77.694,97.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.497 | Acc: 48.402,77.684,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.495 | Acc: 48.440,77.718,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.494 | Acc: 48.463,77.733,97.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.494 | Acc: 48.536,77.658,97.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.492 | Acc: 48.459,77.694,97.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.490 | Acc: 48.451,77.722,97.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.489 | Acc: 48.487,77.731,97.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 48.550,77.678,97.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.046 | Acc: 48.438,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 45.759,64.435,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 44.284,63.567,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.008 | Acc: 43.929,63.525,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.411 | Acc: 48.438,81.250,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.477 | Acc: 48.661,78.571,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.490 | Acc: 48.476,78.182,97.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.492 | Acc: 48.668,77.946,97.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.500 | Acc: 48.196,77.498,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.502 | Acc: 48.113,77.251,97.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.498 | Acc: 48.373,77.531,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 48.299,77.427,97.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.499 | Acc: 48.374,77.310,97.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.498 | Acc: 48.459,77.374,97.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.493 | Acc: 48.570,77.499,97.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.489 | Acc: 48.621,77.623,97.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 48.687,77.768,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.490 | Acc: 48.617,77.661,97.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.490 | Acc: 48.540,77.747,97.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.490 | Acc: 48.637,77.738,97.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.488 | Acc: 48.705,77.772,97.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.489 | Acc: 48.687,77.738,97.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 48.797,77.746,97.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 48.784,77.789,97.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.057 | Acc: 48.438,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.969 | Acc: 45.461,63.988,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.989 | Acc: 44.036,63.167,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 43.788,63.243,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.366 | Acc: 50.000,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.459 | Acc: 49.851,77.865,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.481 | Acc: 48.990,77.973,97.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.488 | Acc: 48.591,77.728,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.492 | Acc: 48.582,77.768,97.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.495 | Acc: 48.438,77.738,97.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.491 | Acc: 48.612,78.002,97.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.497 | Acc: 48.576,77.665,97.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.496 | Acc: 48.695,77.955,97.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.496 | Acc: 48.735,77.978,97.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.494 | Acc: 48.713,77.977,97.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 48.681,78.026,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.490 | Acc: 48.788,78.170,97.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 48.761,78.110,97.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.488 | Acc: 48.768,78.108,97.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.488 | Acc: 48.713,78.096,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.486 | Acc: 48.683,78.149,97.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.488 | Acc: 48.660,78.088,97.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 48.771,78.086,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.485 | Acc: 48.835,78.178,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.064 | Acc: 50.000,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 45.461,64.472,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.981 | Acc: 44.322,63.472,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.008 | Acc: 43.929,63.281,70.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.497 | Acc: 45.312,84.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.534 | Acc: 47.210,77.716,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.509 | Acc: 47.847,77.649,97.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.500 | Acc: 47.976,77.574,97.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.505 | Acc: 47.907,77.228,97.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.496 | Acc: 48.028,77.437,97.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.487 | Acc: 48.392,77.893,97.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.490 | Acc: 48.388,77.842,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.485 | Acc: 48.535,77.955,97.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 48.468,78.008,97.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.485 | Acc: 48.558,78.141,97.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 48.434,78.001,97.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 48.519,77.927,97.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 48.548,77.924,97.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 48.568,77.994,97.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.485 | Acc: 48.666,77.993,97.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.486 | Acc: 48.603,77.923,97.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.486 | Acc: 48.527,77.939,97.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.485 | Acc: 48.593,77.922,97.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.486 | Acc: 48.558,77.891,97.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.045 | Acc: 47.656,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.968 | Acc: 45.126,64.621,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.986 | Acc: 44.036,63.491,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.010 | Acc: 43.801,63.320,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.428 | Acc: 51.562,78.125,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.467 | Acc: 49.368,78.683,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.486 | Acc: 48.800,77.934,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 48.758,77.971,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.483 | Acc: 48.910,77.990,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.489 | Acc: 48.584,77.723,97.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 48.689,77.776,97.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.489 | Acc: 48.615,77.715,97.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.486 | Acc: 48.622,77.941,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 48.498,77.875,97.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.486 | Acc: 48.577,77.888,97.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 48.625,78.001,97.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.486 | Acc: 48.635,77.869,97.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.485 | Acc: 48.677,77.874,97.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.483 | Acc: 48.724,77.858,97.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.483 | Acc: 48.679,77.865,97.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 48.635,77.872,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.484 | Acc: 48.632,77.850,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 48.634,77.863,97.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 48.655,77.856,97.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.073 | Acc: 49.219,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.972 | Acc: 45.499,64.509,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.989 | Acc: 44.245,63.510,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 43.878,63.435,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.525 | Acc: 52.344,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.491 | Acc: 48.586,77.567,97.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 48.361,78.011,98.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.493 | Acc: 48.053,77.638,97.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.503 | Acc: 47.994,77.324,97.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 48.368,76.934,97.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.497 | Acc: 48.366,77.221,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 48.737,77.355,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 48.801,77.582,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.486 | Acc: 48.899,77.607,97.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.487 | Acc: 48.830,77.624,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.486 | Acc: 48.766,77.701,97.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.485 | Acc: 48.765,77.752,97.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.483 | Acc: 48.749,77.769,97.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 48.632,77.702,97.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.487 | Acc: 48.609,77.694,97.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 48.722,77.638,97.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.489 | Acc: 48.692,77.644,97.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.490 | Acc: 48.699,77.699,97.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.487 | Acc: 48.753,77.776,97.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.046 | Acc: 47.656,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.968 | Acc: 45.647,64.323,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.987 | Acc: 44.417,63.319,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.012 | Acc: 44.006,63.358,70.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.589 | Acc: 49.219,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.507 | Acc: 49.256,76.637,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.511 | Acc: 48.647,76.829,97.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.510 | Acc: 48.386,76.691,97.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 48.611,77.025,97.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.493 | Acc: 49.087,77.181,97.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.493 | Acc: 49.128,77.195,97.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.495 | Acc: 49.230,77.194,97.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 49.355,77.431,97.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.489 | Acc: 49.361,77.460,97.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 49.176,77.530,97.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.491 | Acc: 49.067,77.563,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.493 | Acc: 48.927,77.519,97.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.492 | Acc: 48.931,77.550,97.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.491 | Acc: 48.916,77.569,97.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.490 | Acc: 48.887,77.505,97.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 48.868,77.560,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.488 | Acc: 48.841,77.603,97.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.486 | Acc: 48.862,77.684,97.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.487 | Acc: 48.839,77.664,97.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.046 | Acc: 48.438,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.969 | Acc: 45.722,64.062,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.988 | Acc: 44.417,63.510,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.008 | Acc: 44.032,63.448,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.405 | Acc: 53.125,78.125,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.486 | Acc: 49.256,77.269,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.471 | Acc: 49.257,77.877,98.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.482 | Acc: 48.694,77.600,98.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 48.688,77.440,98.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.480 | Acc: 48.963,77.498,97.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.475 | Acc: 49.257,77.576,97.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 49.091,77.593,97.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.483 | Acc: 49.199,77.606,97.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 49.206,77.590,97.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.483 | Acc: 49.207,77.678,97.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 49.120,77.704,97.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.485 | Acc: 49.005,77.632,97.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 48.809,77.646,97.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.489 | Acc: 48.777,77.705,97.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.489 | Acc: 48.767,77.736,97.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.488 | Acc: 48.812,77.811,97.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.490 | Acc: 48.692,77.692,97.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.490 | Acc: 48.732,77.796,97.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.486 | Acc: 48.841,77.826,97.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.069 | Acc: 49.219,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 46.057,64.583,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.987 | Acc: 44.607,63.586,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.008 | Acc: 44.262,63.550,70.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.514 | Acc: 46.875,78.906,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 49.628,77.232,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.477 | Acc: 48.742,76.829,97.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.474 | Acc: 48.809,77.177,97.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.486 | Acc: 48.495,76.958,97.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.489 | Acc: 48.716,77.088,97.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.493 | Acc: 48.599,77.098,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.493 | Acc: 48.493,77.166,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.492 | Acc: 48.467,77.184,97.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 48.502,77.279,97.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.493 | Acc: 48.301,77.254,97.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.490 | Acc: 48.289,77.351,97.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.489 | Acc: 48.347,77.571,97.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.487 | Acc: 48.378,77.637,97.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.489 | Acc: 48.315,77.538,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.486 | Acc: 48.440,77.593,97.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.485 | Acc: 48.479,77.616,97.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.489 | Acc: 48.426,77.598,97.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.488 | Acc: 48.373,77.647,97.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 48.407,77.625,97.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.037 | Acc: 48.438,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.955 | Acc: 45.833,64.435,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.981 | Acc: 44.493,63.529,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.007 | Acc: 44.211,63.409,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.534 | Acc: 47.656,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.472 | Acc: 49.926,77.865,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.461 | Acc: 50.191,78.316,97.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.482 | Acc: 49.244,78.023,97.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.472 | Acc: 49.479,78.250,97.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.478 | Acc: 49.118,78.233,97.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.471 | Acc: 49.135,78.325,97.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.478 | Acc: 48.748,78.236,97.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.479 | Acc: 48.763,78.305,97.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.478 | Acc: 48.722,78.285,97.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.476 | Acc: 48.888,78.265,97.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.475 | Acc: 48.932,78.118,97.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.476 | Acc: 48.956,78.086,97.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.480 | Acc: 48.860,77.930,97.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.476 | Acc: 48.944,78.125,97.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 48.887,78.174,97.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.478 | Acc: 48.829,78.132,97.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 48.761,78.056,97.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.481 | Acc: 48.818,77.982,97.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 48.737,77.953,97.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.074 | Acc: 49.219,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 45.461,64.509,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 44.360,63.777,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.007 | Acc: 44.083,63.691,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.510 | Acc: 42.188,78.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.517 | Acc: 47.024,76.860,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.497 | Acc: 47.885,77.363,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.498 | Acc: 48.028,77.318,97.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.498 | Acc: 48.283,77.392,97.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.491 | Acc: 48.461,77.568,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.490 | Acc: 48.554,77.537,97.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 48.537,77.704,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.489 | Acc: 48.549,77.611,97.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 48.584,77.737,97.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 48.574,77.725,97.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 48.720,77.846,97.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.490 | Acc: 48.697,77.762,97.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.490 | Acc: 48.635,77.814,97.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.491 | Acc: 48.640,77.769,97.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.489 | Acc: 48.733,77.795,97.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.488 | Acc: 48.781,77.833,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.488 | Acc: 48.742,77.809,97.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.486 | Acc: 48.792,77.867,97.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.486 | Acc: 48.792,77.863,97.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.044 | Acc: 48.438,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.965 | Acc: 45.647,64.472,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 44.360,63.586,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 44.057,63.537,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.319 | Acc: 50.000,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.478 | Acc: 48.177,78.571,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.468 | Acc: 48.628,78.601,98.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.484 | Acc: 48.258,78.189,97.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 48.312,78.231,97.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.480 | Acc: 48.515,78.318,97.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.480 | Acc: 48.702,78.209,97.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.474 | Acc: 48.753,78.441,97.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.477 | Acc: 48.646,78.426,97.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.478 | Acc: 48.692,78.427,97.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.481 | Acc: 48.678,78.366,97.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.481 | Acc: 48.688,78.319,97.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.484 | Acc: 48.583,78.180,97.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.484 | Acc: 48.653,78.149,97.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.483 | Acc: 48.691,78.078,97.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.483 | Acc: 48.752,78.042,97.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 48.686,77.981,97.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.483 | Acc: 48.731,78.040,97.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 48.751,78.056,97.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 48.700,78.055,97.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.064 | Acc: 48.438,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 45.610,64.211,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 44.303,63.357,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.006 | Acc: 44.032,63.371,70.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.275 | Acc: 55.469,85.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 49.405,77.418,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.474 | Acc: 49.371,77.954,98.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.476 | Acc: 49.834,77.843,97.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.476 | Acc: 49.605,78.029,97.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 49.319,77.738,97.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.481 | Acc: 49.161,77.951,97.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 49.030,78.025,97.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.485 | Acc: 48.884,77.844,97.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.489 | Acc: 48.632,77.888,97.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.486 | Acc: 48.737,77.888,98.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 48.657,77.878,98.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.485 | Acc: 48.664,77.950,98.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 48.677,77.895,97.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 48.668,77.889,97.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.487 | Acc: 48.640,77.806,97.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.488 | Acc: 48.695,77.760,97.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.487 | Acc: 48.664,77.827,97.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 48.721,77.811,97.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.487 | Acc: 48.712,77.858,97.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.025 | Acc: 49.219,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 45.796,64.211,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 44.512,63.453,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 44.185,63.332,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.400 | Acc: 45.312,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.480 | Acc: 49.256,76.972,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 48.571,77.534,97.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.494 | Acc: 48.425,77.369,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.501 | Acc: 48.158,77.228,97.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.495 | Acc: 48.345,77.498,97.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.496 | Acc: 48.295,77.389,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.490 | Acc: 48.188,77.466,97.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 48.205,77.606,97.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 48.174,77.780,97.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.487 | Acc: 48.266,77.938,97.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.488 | Acc: 48.328,77.817,97.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.491 | Acc: 48.246,77.798,97.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 48.312,77.924,97.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.490 | Acc: 48.207,77.905,97.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.489 | Acc: 48.336,77.834,97.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.489 | Acc: 48.333,77.748,97.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.488 | Acc: 48.314,77.788,97.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.489 | Acc: 48.360,77.707,97.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.489 | Acc: 48.435,77.688,97.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.055 | Acc: 48.438,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.971 | Acc: 45.424,64.583,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.991 | Acc: 44.131,63.510,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.017 | Acc: 43.878,63.371,70.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.496 | Acc: 47.656,78.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.484 | Acc: 48.289,78.125,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 48.495,77.553,97.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.489 | Acc: 48.399,78.253,97.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.493 | Acc: 48.573,77.971,97.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.498 | Acc: 48.291,77.792,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.493 | Acc: 48.450,77.712,97.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 48.703,77.715,97.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.493 | Acc: 48.612,77.766,97.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.494 | Acc: 48.675,77.715,97.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.494 | Acc: 48.593,77.631,97.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.497 | Acc: 48.544,77.627,97.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 48.600,77.691,97.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.490 | Acc: 48.701,77.823,97.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.491 | Acc: 48.785,77.750,97.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.491 | Acc: 48.790,77.694,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.491 | Acc: 48.649,77.760,97.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.491 | Acc: 48.676,77.690,97.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.493 | Acc: 48.645,77.651,97.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.492 | Acc: 48.651,77.692,97.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.050 | Acc: 46.875,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.968 | Acc: 44.829,64.100,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.994 | Acc: 43.998,63.319,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 43.712,63.243,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.626 | Acc: 39.844,71.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.494 | Acc: 49.033,78.162,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.486 | Acc: 49.085,78.011,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.488 | Acc: 48.578,78.291,97.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.484 | Acc: 48.476,78.492,97.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.488 | Acc: 48.499,78.202,97.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 48.528,77.976,97.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.484 | Acc: 48.604,78.191,97.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.486 | Acc: 48.612,78.130,97.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 48.614,78.116,97.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.487 | Acc: 48.457,77.989,97.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 48.519,78.012,97.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.487 | Acc: 48.499,77.982,97.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.487 | Acc: 48.536,77.951,97.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.485 | Acc: 48.485,77.980,97.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.484 | Acc: 48.495,77.936,97.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.481 | Acc: 48.622,77.981,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.481 | Acc: 48.731,77.898,97.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 48.697,77.878,97.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 48.628,77.893,97.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.046 | Acc: 49.219,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 45.424,64.546,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.988 | Acc: 44.188,63.529,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.011 | Acc: 43.763,63.550,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.693 | Acc: 43.750,71.094,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 48.921,78.497,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.464 | Acc: 48.399,78.030,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.455 | Acc: 49.052,78.215,98.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.442 | Acc: 49.460,78.752,98.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.452 | Acc: 49.304,78.543,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.459 | Acc: 49.077,78.538,97.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.466 | Acc: 48.892,78.491,97.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.464 | Acc: 48.971,78.557,97.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.469 | Acc: 48.921,78.267,97.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.470 | Acc: 48.970,78.168,98.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.474 | Acc: 48.961,78.104,97.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.475 | Acc: 48.862,78.060,97.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.479 | Acc: 48.662,77.883,97.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.477 | Acc: 48.691,77.925,97.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.480 | Acc: 48.604,77.912,97.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.480 | Acc: 48.545,78.013,97.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.480 | Acc: 48.625,77.994,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.481 | Acc: 48.656,78.010,97.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.482 | Acc: 48.614,77.951,97.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.088 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 45.350,64.546,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.987 | Acc: 44.207,63.453,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.008 | Acc: 43.929,63.422,70.415,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.438 | Acc: 51.562,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.472 | Acc: 48.586,78.199,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.469 | Acc: 49.314,77.820,97.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.481 | Acc: 49.014,77.626,97.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 48.717,77.623,97.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 49.033,77.645,97.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 49.083,77.550,97.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 48.892,77.338,97.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.485 | Acc: 49.190,77.640,97.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.485 | Acc: 49.081,77.616,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.487 | Acc: 48.947,77.705,97.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 48.904,77.662,97.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.486 | Acc: 48.885,77.636,97.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.485 | Acc: 48.889,77.703,97.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 48.985,77.658,97.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.487 | Acc: 48.944,77.684,97.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.486 | Acc: 48.963,77.740,97.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.487 | Acc: 48.925,77.717,97.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.488 | Acc: 48.818,77.664,97.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 48.825,77.660,97.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.048 | Acc: 48.438,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.970 | Acc: 45.945,64.323,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 44.493,63.434,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.011 | Acc: 43.929,63.435,70.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.338 | Acc: 50.000,80.469,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.495 | Acc: 49.479,78.237,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.493 | Acc: 48.133,78.011,97.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.498 | Acc: 47.733,77.549,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.496 | Acc: 47.868,77.604,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.495 | Acc: 47.888,77.816,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.492 | Acc: 47.960,77.822,97.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.493 | Acc: 48.077,77.881,97.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 48.239,78.052,97.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 48.334,78.056,97.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 48.235,77.938,97.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.489 | Acc: 48.232,77.948,97.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.489 | Acc: 48.159,77.908,97.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.488 | Acc: 48.246,77.835,97.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.488 | Acc: 48.307,77.769,97.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.485 | Acc: 48.425,77.925,97.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 48.384,77.908,97.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.487 | Acc: 48.380,77.928,97.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.486 | Acc: 48.412,77.971,97.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.484 | Acc: 48.507,77.973,97.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.037 | Acc: 48.438,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.969 | Acc: 45.275,64.435,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.997 | Acc: 44.017,63.453,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.017 | Acc: 43.699,63.320,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.666 | Acc: 40.625,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.508 | Acc: 47.842,76.600,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.491 | Acc: 47.885,77.611,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.512 | Acc: 47.784,77.241,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.501 | Acc: 48.351,77.402,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.501 | Acc: 48.244,77.545,97.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.496 | Acc: 48.483,77.660,97.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.493 | Acc: 48.715,77.793,97.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 48.821,77.887,97.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 48.968,77.965,97.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.488 | Acc: 48.822,77.993,97.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.486 | Acc: 48.918,77.938,97.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 48.810,77.901,97.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 48.626,77.939,97.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.489 | Acc: 48.546,77.955,97.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.488 | Acc: 48.585,77.933,97.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.488 | Acc: 48.537,77.908,97.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.485 | Acc: 48.534,77.978,97.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 48.578,78.023,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.484 | Acc: 48.616,78.037,97.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.076 | Acc: 50.000,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.969 | Acc: 45.647,63.988,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 44.569,63.243,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.017 | Acc: 44.185,63.153,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.662 | Acc: 46.875,70.312,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.536 | Acc: 47.693,75.707,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.519 | Acc: 47.351,76.658,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.514 | Acc: 47.759,76.716,97.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.500 | Acc: 47.984,77.238,97.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.488 | Acc: 48.352,77.591,97.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.487 | Acc: 48.263,77.583,97.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 48.449,77.732,97.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 48.578,77.543,97.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 48.800,77.749,97.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.486 | Acc: 48.745,77.670,97.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 48.738,77.687,97.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.484 | Acc: 48.778,77.824,97.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.487 | Acc: 48.674,77.712,97.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.488 | Acc: 48.677,77.714,97.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.484 | Acc: 48.850,77.816,97.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.483 | Acc: 48.871,77.787,97.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.483 | Acc: 48.783,77.772,97.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 48.818,77.768,97.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.485 | Acc: 48.772,77.811,97.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.067 | Acc: 48.438,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 45.871,64.397,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.982 | Acc: 44.398,63.529,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.004 | Acc: 44.160,63.486,70.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.456 | Acc: 47.656,78.125,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.493 | Acc: 47.842,76.860,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.497 | Acc: 47.561,76.791,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.505 | Acc: 47.810,76.767,98.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.492 | Acc: 48.380,77.411,98.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.493 | Acc: 48.229,77.560,98.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.494 | Acc: 47.986,77.537,98.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 48.000,77.665,98.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 48.127,77.683,98.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.489 | Acc: 48.377,77.624,97.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.486 | Acc: 48.492,77.635,97.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 48.597,77.662,98.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 48.457,77.584,97.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.487 | Acc: 48.420,77.583,97.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 48.443,77.613,97.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.488 | Acc: 48.367,77.627,97.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 48.479,77.687,97.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.483 | Acc: 48.591,77.797,97.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 48.639,77.785,97.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 48.606,77.789,97.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.043 | Acc: 49.219,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 45.312,64.583,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.985 | Acc: 44.284,63.529,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.010 | Acc: 43.942,63.461,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.452 | Acc: 50.781,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.475 | Acc: 50.149,77.530,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.478 | Acc: 49.219,77.611,98.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.475 | Acc: 49.270,78.151,97.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.486 | Acc: 48.833,77.681,97.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.486 | Acc: 48.662,77.452,97.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.485 | Acc: 48.631,77.434,97.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.488 | Acc: 48.582,77.449,97.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.489 | Acc: 48.772,77.484,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.489 | Acc: 48.658,77.542,97.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.486 | Acc: 48.589,77.596,97.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.484 | Acc: 48.713,77.711,97.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.485 | Acc: 48.661,77.674,97.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.485 | Acc: 48.737,77.616,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 48.785,77.680,97.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.485 | Acc: 48.723,77.733,97.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 48.698,77.721,97.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 48.733,77.795,97.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 48.621,77.759,97.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.485 | Acc: 48.641,77.766,97.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.056 | Acc: 48.438,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 45.796,64.695,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.982 | Acc: 44.417,63.624,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 43.942,63.486,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.727 | Acc: 45.312,67.969,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.483 | Acc: 48.549,77.493,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 49.104,77.344,97.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 48.655,77.587,97.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.493 | Acc: 48.708,77.459,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.489 | Acc: 48.786,77.715,97.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.482 | Acc: 49.115,77.705,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.483 | Acc: 49.003,77.682,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.483 | Acc: 48.850,77.863,97.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.478 | Acc: 48.994,77.974,97.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.474 | Acc: 49.184,78.012,97.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.478 | Acc: 49.077,77.870,97.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.483 | Acc: 48.885,77.788,97.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.484 | Acc: 48.815,77.676,97.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 48.832,77.733,97.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.481 | Acc: 48.884,77.884,97.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.482 | Acc: 48.880,77.838,97.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 48.774,77.868,97.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 48.808,77.911,97.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 48.807,77.947,97.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.032 | Acc: 48.438,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.965 | Acc: 45.424,64.100,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.991 | Acc: 44.245,63.281,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.018 | Acc: 43.968,63.345,70.044,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.322 | Acc: 60.938,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.463 | Acc: 48.921,77.195,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.485 | Acc: 48.438,77.763,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.483 | Acc: 48.079,77.382,97.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.474 | Acc: 48.370,77.720,97.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 48.445,77.475,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.484 | Acc: 48.392,77.673,97.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.481 | Acc: 48.515,77.643,97.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.484 | Acc: 48.690,77.518,97.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 48.835,77.551,97.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.486 | Acc: 48.815,77.565,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 48.844,77.655,97.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 48.755,77.610,97.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.492 | Acc: 48.623,77.505,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.489 | Acc: 48.571,77.558,97.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.488 | Acc: 48.544,77.606,97.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.486 | Acc: 48.610,77.682,97.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.486 | Acc: 48.637,77.685,97.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 48.570,77.681,97.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.486 | Acc: 48.528,77.703,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.048 | Acc: 48.438,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.972 | Acc: 45.536,64.435,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.993 | Acc: 44.226,63.586,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.018 | Acc: 43.929,63.461,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.269 | Acc: 50.781,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.419 | Acc: 50.446,78.497,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.455 | Acc: 49.581,77.630,98.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.465 | Acc: 49.193,77.164,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.464 | Acc: 49.161,77.720,98.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.467 | Acc: 49.157,77.738,98.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.476 | Acc: 48.973,77.473,98.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.474 | Acc: 49.186,77.632,97.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.469 | Acc: 49.292,77.999,97.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.472 | Acc: 49.154,77.853,97.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.475 | Acc: 49.048,77.853,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.474 | Acc: 48.968,77.913,97.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.475 | Acc: 48.921,77.979,97.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.475 | Acc: 48.854,77.945,97.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.476 | Acc: 48.866,77.839,97.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.475 | Acc: 48.842,77.904,97.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.476 | Acc: 48.776,77.957,97.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.477 | Acc: 48.683,77.898,97.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.480 | Acc: 48.645,77.850,97.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 48.552,77.832,97.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.040 | Acc: 48.438,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 45.461,64.360,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.981 | Acc: 44.284,63.624,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.006 | Acc: 43.929,63.473,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.688 | Acc: 37.500,67.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.505 | Acc: 47.396,77.083,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.499 | Acc: 48.533,77.325,97.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.507 | Acc: 48.156,77.331,97.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.505 | Acc: 48.274,77.276,97.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.500 | Acc: 48.345,77.197,97.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 48.212,77.350,97.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.498 | Acc: 48.371,77.410,97.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.498 | Acc: 48.423,77.421,97.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.495 | Acc: 48.450,77.577,97.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 48.542,77.732,97.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 48.384,77.669,97.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.490 | Acc: 48.506,77.593,97.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.488 | Acc: 48.554,77.640,97.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 48.635,77.663,97.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.487 | Acc: 48.674,77.637,97.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 48.703,77.699,97.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.485 | Acc: 48.735,77.804,97.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 48.736,77.779,97.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.485 | Acc: 48.788,77.828,97.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.024 | Acc: 50.000,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.971 | Acc: 45.796,63.951,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.988 | Acc: 44.322,63.262,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.012 | Acc: 43.916,63.217,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.583 | Acc: 49.219,75.000,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.491 | Acc: 48.996,77.716,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 49.390,77.001,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.493 | Acc: 48.899,76.870,97.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.491 | Acc: 49.238,76.890,97.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.487 | Acc: 49.234,77.228,97.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 48.973,77.098,97.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.488 | Acc: 48.864,77.033,97.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.488 | Acc: 48.908,77.135,97.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 48.731,77.232,97.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.487 | Acc: 48.904,77.390,97.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 48.915,77.340,97.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 48.888,77.324,97.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.488 | Acc: 48.761,77.434,97.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 48.813,77.488,97.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.488 | Acc: 48.746,77.481,97.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.489 | Acc: 48.610,77.519,97.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.487 | Acc: 48.646,77.518,97.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.485 | Acc: 48.730,77.580,97.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.484 | Acc: 48.725,77.586,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.063 | Acc: 49.219,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 45.424,64.472,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.980 | Acc: 44.360,63.720,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.008 | Acc: 43.993,63.614,69.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.337 | Acc: 53.125,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.454 | Acc: 49.479,78.943,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.468 | Acc: 48.666,78.201,97.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.471 | Acc: 48.694,78.240,97.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.464 | Acc: 48.804,78.434,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.473 | Acc: 49.025,78.210,97.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 48.735,77.854,97.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.478 | Acc: 48.814,77.793,97.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.480 | Acc: 48.763,77.717,97.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.481 | Acc: 48.865,77.775,97.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.479 | Acc: 48.830,77.915,97.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 48.720,77.853,97.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.482 | Acc: 48.775,77.892,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.482 | Acc: 48.842,77.921,97.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.481 | Acc: 48.899,77.964,97.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.480 | Acc: 48.920,78.019,97.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.482 | Acc: 48.820,78.035,97.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.481 | Acc: 48.832,78.031,97.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.481 | Acc: 48.825,78.069,97.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.480 | Acc: 48.926,78.125,97.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.059 | Acc: 49.219,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.969 | Acc: 45.722,64.844,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.991 | Acc: 44.360,63.739,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 43.981,63.640,70.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.426 | Acc: 48.438,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.431 | Acc: 51.228,80.394,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.459 | Acc: 49.829,78.944,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.463 | Acc: 49.629,78.957,97.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.464 | Acc: 49.402,78.762,97.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.470 | Acc: 49.373,78.589,97.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.474 | Acc: 49.219,78.713,97.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.477 | Acc: 49.152,78.518,97.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.482 | Acc: 48.962,78.343,97.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 48.964,78.216,97.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.483 | Acc: 48.822,78.168,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.478 | Acc: 48.964,78.242,97.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.478 | Acc: 49.044,78.258,97.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.483 | Acc: 49.009,78.125,97.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.482 | Acc: 49.016,78.094,97.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.479 | Acc: 49.040,78.122,97.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.478 | Acc: 49.073,78.118,97.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.480 | Acc: 49.029,78.072,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 48.924,77.991,97.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.482 | Acc: 48.872,77.951,97.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.052 | Acc: 48.438,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.974 | Acc: 45.685,64.062,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.995 | Acc: 44.284,63.262,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.019 | Acc: 43.916,63.307,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.389 | Acc: 50.781,81.250,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.442 | Acc: 49.070,78.497,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.473 | Acc: 49.200,78.011,97.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.478 | Acc: 48.988,78.227,97.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.484 | Acc: 48.708,78.115,97.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 48.886,77.978,97.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.485 | Acc: 48.909,78.028,97.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.478 | Acc: 49.097,78.142,97.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.485 | Acc: 48.758,77.999,97.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.486 | Acc: 48.822,78.082,97.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.488 | Acc: 48.764,77.876,97.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.486 | Acc: 48.752,77.920,97.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.486 | Acc: 48.710,77.892,97.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.487 | Acc: 48.725,77.933,97.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 48.766,77.903,97.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.486 | Acc: 48.829,77.871,97.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 48.907,77.950,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.485 | Acc: 48.861,77.896,97.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.486 | Acc: 48.797,77.846,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.487 | Acc: 48.768,77.776,97.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.070 | Acc: 48.438,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.974 | Acc: 45.350,64.100,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.988 | Acc: 44.055,63.453,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 43.776,63.499,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.391 | Acc: 45.312,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.505 | Acc: 47.768,77.381,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.493 | Acc: 48.647,77.611,97.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.488 | Acc: 48.770,77.305,97.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.494 | Acc: 48.486,77.228,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.487 | Acc: 48.700,77.429,97.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.482 | Acc: 48.676,77.596,97.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 48.770,77.560,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.486 | Acc: 48.753,77.446,97.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 48.830,77.491,97.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.488 | Acc: 48.741,77.441,97.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.486 | Acc: 48.727,77.574,97.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.483 | Acc: 48.778,77.691,97.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 48.599,77.664,97.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 48.596,77.697,97.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.485 | Acc: 48.611,77.852,97.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.485 | Acc: 48.618,77.794,97.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.485 | Acc: 48.690,77.784,97.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.483 | Acc: 48.784,77.796,97.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.482 | Acc: 48.825,77.787,97.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.056 | Acc: 48.438,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.968 | Acc: 45.796,64.211,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.993 | Acc: 44.512,63.243,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.019 | Acc: 44.032,63.217,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.434 | Acc: 52.344,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.493 | Acc: 48.512,77.381,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 48.152,77.611,98.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.494 | Acc: 48.361,77.677,97.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.491 | Acc: 48.312,78.038,97.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.487 | Acc: 48.236,78.048,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.495 | Acc: 48.140,77.893,97.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.489 | Acc: 48.515,77.842,97.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 48.607,77.814,97.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 48.545,77.814,97.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.487 | Acc: 48.690,77.954,97.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 48.561,77.941,97.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.491 | Acc: 48.412,77.849,97.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.488 | Acc: 48.488,77.933,97.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.489 | Acc: 48.499,77.855,97.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.490 | Acc: 48.508,77.842,97.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.490 | Acc: 48.554,77.813,97.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.488 | Acc: 48.657,77.875,97.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 48.717,77.945,97.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 48.669,77.904,97.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.061 | Acc: 48.438,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 45.685,64.397,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 44.207,63.529,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.009 | Acc: 44.083,63.486,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.353 | Acc: 55.469,82.031,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.459 | Acc: 48.735,78.869,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.443 | Acc: 49.752,79.021,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.453 | Acc: 49.052,78.919,98.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.461 | Acc: 48.727,78.655,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 48.817,78.280,98.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.466 | Acc: 48.741,78.254,98.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.466 | Acc: 48.748,78.236,97.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.466 | Acc: 48.840,78.072,97.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.473 | Acc: 48.489,77.914,97.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.476 | Acc: 48.461,77.787,97.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.479 | Acc: 48.498,77.736,97.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 48.493,77.704,97.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.481 | Acc: 48.551,77.670,97.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.481 | Acc: 48.588,77.672,97.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.483 | Acc: 48.508,77.608,97.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 48.442,77.626,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 48.596,77.614,97.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 48.585,77.569,97.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.484 | Acc: 48.530,77.606,97.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.063 | Acc: 50.000,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.971 | Acc: 45.424,64.397,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.992 | Acc: 44.207,63.567,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 43.878,63.448,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.332 | Acc: 57.812,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.475 | Acc: 48.996,77.790,97.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.459 | Acc: 49.162,78.258,97.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.475 | Acc: 48.694,77.549,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.481 | Acc: 48.621,77.681,97.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.487 | Acc: 48.554,77.452,97.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 48.786,77.686,97.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.480 | Acc: 48.836,77.748,97.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.478 | Acc: 48.787,77.955,97.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.478 | Acc: 48.852,78.034,97.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.477 | Acc: 48.919,77.985,97.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.476 | Acc: 49.081,77.973,97.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.477 | Acc: 49.002,77.986,97.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.477 | Acc: 49.090,78.029,97.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.478 | Acc: 49.044,77.950,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.481 | Acc: 48.946,77.902,97.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.477 | Acc: 48.961,77.981,97.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.477 | Acc: 48.948,77.992,97.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.478 | Acc: 48.983,77.945,97.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.480 | Acc: 48.932,77.908,97.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.044 | Acc: 49.219,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.974 | Acc: 45.573,64.397,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 44.398,63.281,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.020 | Acc: 44.057,63.397,70.044,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
main.py:244: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  confidence, idx = torch.topk(F.softmax(outputs[j][i]), k=1)
Batch: 0 | Loss: 1.520 | Acc: 51.562,76.562,96.875,% | Adaptive Acc: 91.406% | clf_exit: 0.297 0.352 0.352
Batch: 20 | Loss: 1.511 | Acc: 48.289,77.790,97.545,% | Adaptive Acc: 89.509% | clf_exit: 0.258 0.447 0.295
Batch: 40 | Loss: 1.498 | Acc: 47.847,77.077,97.885,% | Adaptive Acc: 89.768% | clf_exit: 0.262 0.442 0.296
Batch: 60 | Loss: 1.484 | Acc: 48.207,77.267,97.887,% | Adaptive Acc: 89.844% | clf_exit: 0.262 0.449 0.289
Batch: 80 | Loss: 1.490 | Acc: 48.225,77.382,97.917,% | Adaptive Acc: 89.882% | clf_exit: 0.263 0.446 0.291
Batch: 100 | Loss: 1.491 | Acc: 48.120,77.506,97.834,% | Adaptive Acc: 89.882% | clf_exit: 0.262 0.447 0.292
Batch: 120 | Loss: 1.490 | Acc: 48.315,77.589,97.863,% | Adaptive Acc: 89.895% | clf_exit: 0.263 0.444 0.293
Batch: 140 | Loss: 1.489 | Acc: 48.227,77.610,97.883,% | Adaptive Acc: 89.910% | clf_exit: 0.262 0.444 0.295
Batch: 160 | Loss: 1.490 | Acc: 48.389,77.465,97.850,% | Adaptive Acc: 89.761% | clf_exit: 0.262 0.443 0.295
Batch: 180 | Loss: 1.492 | Acc: 48.386,77.430,97.838,% | Adaptive Acc: 89.870% | clf_exit: 0.262 0.442 0.296
Batch: 200 | Loss: 1.494 | Acc: 48.449,77.421,97.819,% | Adaptive Acc: 89.918% | clf_exit: 0.262 0.441 0.297
Batch: 220 | Loss: 1.498 | Acc: 48.342,77.400,97.730,% | Adaptive Acc: 89.812% | clf_exit: 0.261 0.442 0.297
Batch: 240 | Loss: 1.496 | Acc: 48.369,77.464,97.734,% | Adaptive Acc: 89.805% | clf_exit: 0.262 0.441 0.297
Batch: 260 | Loss: 1.495 | Acc: 48.282,77.466,97.755,% | Adaptive Acc: 89.796% | clf_exit: 0.263 0.441 0.297
Batch: 280 | Loss: 1.493 | Acc: 48.285,77.491,97.790,% | Adaptive Acc: 89.791% | clf_exit: 0.262 0.442 0.296
Batch: 300 | Loss: 1.492 | Acc: 48.297,77.499,97.807,% | Adaptive Acc: 89.818% | clf_exit: 0.262 0.442 0.295
Batch: 320 | Loss: 1.488 | Acc: 48.384,77.658,97.856,% | Adaptive Acc: 89.917% | clf_exit: 0.262 0.442 0.295
Batch: 340 | Loss: 1.486 | Acc: 48.481,77.738,97.853,% | Adaptive Acc: 89.972% | clf_exit: 0.263 0.442 0.294
Batch: 360 | Loss: 1.482 | Acc: 48.561,77.818,97.853,% | Adaptive Acc: 90.004% | clf_exit: 0.264 0.443 0.294
Batch: 380 | Loss: 1.482 | Acc: 48.528,77.805,97.847,% | Adaptive Acc: 89.989% | clf_exit: 0.263 0.443 0.293
main.py:344: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  confidence, idx = torch.topk(F.softmax(outputs[j][i]), k=1)
Batch: 0 | Loss: 3.063 | Acc: 48.438,64.062,71.094,% | Adaptive Acc: 67.188% | clf_exit: 0.367 0.367 0.266
Batch: 20 | Loss: 2.963 | Acc: 45.722,64.286,70.722,% | Adaptive Acc: 66.481% | clf_exit: 0.343 0.361 0.296
Batch: 40 | Loss: 2.987 | Acc: 44.360,63.434,70.427,% | Adaptive Acc: 65.911% | clf_exit: 0.335 0.366 0.299
Batch: 60 | Loss: 3.012 | Acc: 44.096,63.332,70.146,% | Adaptive Acc: 65.727% | clf_exit: 0.331 0.371 0.298
model is save as models/resnet56_2con3_att3_cifar100_adaptive0_circles2_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 5.436 | Acc: 48.438,12.500,46.875,% | Adaptive Acc: 50.000% | clf_exit: 0.367 0.039 0.594
Batch: 20 | Loss: 5.504 | Acc: 45.722,14.100,44.531,% | Adaptive Acc: 49.144% | clf_exit: 0.343 0.031 0.626
Batch: 40 | Loss: 5.537 | Acc: 44.360,14.158,44.722,% | Adaptive Acc: 48.590% | clf_exit: 0.335 0.031 0.634
Batch: 60 | Loss: 5.553 | Acc: 44.096,14.139,44.224,% | Adaptive Acc: 48.143% | clf_exit: 0.331 0.032 0.637
Batch: 0 | Loss: 3.965 | Acc: 48.438,44.531,64.844,% | Adaptive Acc: 60.156% | clf_exit: 0.367 0.133 0.500
Batch: 20 | Loss: 3.936 | Acc: 45.722,42.001,65.513,% | Adaptive Acc: 61.793% | clf_exit: 0.343 0.113 0.544
Batch: 40 | Loss: 3.954 | Acc: 44.360,41.330,64.825,% | Adaptive Acc: 61.166% | clf_exit: 0.335 0.107 0.558
Batch: 60 | Loss: 3.980 | Acc: 44.096,41.009,64.408,% | Adaptive Acc: 60.745% | clf_exit: 0.331 0.112 0.557
Batch: 0 | Loss: 3.063 | Acc: 48.438,64.062,71.094,% | Adaptive Acc: 67.188% | clf_exit: 0.367 0.367 0.266
Batch: 20 | Loss: 2.963 | Acc: 45.722,64.286,70.722,% | Adaptive Acc: 66.481% | clf_exit: 0.343 0.361 0.296
Batch: 40 | Loss: 2.987 | Acc: 44.360,63.434,70.427,% | Adaptive Acc: 65.911% | clf_exit: 0.335 0.366 0.299
Batch: 60 | Loss: 3.012 | Acc: 44.096,63.332,70.146,% | Adaptive Acc: 65.727% | clf_exit: 0.331 0.371 0.298







Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 9.049 |  Acc: 2.296,2.360,4.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 8.546 |  Acc: 3.320,3.370,7.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 8.225 |  Acc: 4.004,5.636,11.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 8.010 |  Acc: 3.930,7.090,13.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 7.777 |  Acc: 4.680,8.664,16.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 7.524 |  Acc: 5.210,9.830,19.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 7.415 |  Acc: 5.528,11.272,19.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 7.272 |  Acc: 5.430,11.470,20.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 7.067 |  Acc: 6.400,13.778,23.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 7.013 |  Acc: 6.370,13.490,23.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 6.749 |  Acc: 7.638,16.076,26.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 6.670 |  Acc: 7.160,16.400,27.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 6.462 |  Acc: 9.432,18.410,29.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 6.524 |  Acc: 9.680,17.050,28.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 6.186 |  Acc: 11.454,20.590,32.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 6.173 |  Acc: 10.370,19.880,31.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 5.921 |  Acc: 13.372,22.532,35.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 6.042 |  Acc: 12.430,19.540,34.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 5.686 |  Acc: 15.392,24.516,37.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 5.701 |  Acc: 15.090,23.650,36.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 5.481 |  Acc: 17.122,26.224,39.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 5.742 |  Acc: 15.060,22.160,37.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.284 |  Acc: 18.690,28.208,42.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 5.727 |  Acc: 15.460,23.590,35.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.136 |  Acc: 19.888,29.444,43.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 5.610 |  Acc: 15.180,26.220,38.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 4.978 |  Acc: 20.862,30.894,45.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 5.209 |  Acc: 20.230,27.360,42.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 4.851 |  Acc: 21.888,32.436,47.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 5.205 |  Acc: 19.500,28.680,42.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 4.735 |  Acc: 22.556,33.586,48.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 5.073 |  Acc: 20.590,31.000,43.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 4.627 |  Acc: 23.610,34.634,50.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 5.168 |  Acc: 20.300,28.510,43.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 4.521 |  Acc: 24.478,35.928,51.172,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 5.015 |  Acc: 22.140,31.790,45.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.420 |  Acc: 25.412,37.140,52.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 4.818 |  Acc: 23.510,34.460,45.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.324 |  Acc: 25.870,38.036,53.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 5.130 |  Acc: 18.650,30.950,45.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.267 |  Acc: 26.358,39.252,54.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 4.636 |  Acc: 24.610,33.340,49.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.176 |  Acc: 27.146,40.218,55.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 4.865 |  Acc: 21.740,33.220,48.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.111 |  Acc: 27.792,41.016,56.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 4.630 |  Acc: 24.340,35.310,49.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.032 |  Acc: 28.254,41.902,57.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 4.578 |  Acc: 23.210,36.360,50.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 3.985 |  Acc: 28.648,42.662,57.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 4.372 |  Acc: 25.370,37.900,52.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 3.912 |  Acc: 29.102,43.666,58.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 5.079 |  Acc: 22.400,30.310,47.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 3.880 |  Acc: 29.248,43.832,59.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 4.570 |  Acc: 23.280,38.320,50.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 3.818 |  Acc: 29.936,44.942,59.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 4.153 |  Acc: 26.030,41.080,56.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 3.777 |  Acc: 30.258,45.094,60.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 4.325 |  Acc: 25.690,39.320,54.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 3.718 |  Acc: 30.404,45.930,61.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 5.102 |  Acc: 22.250,30.370,46.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 3.670 |  Acc: 30.744,46.426,62.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 4.827 |  Acc: 22.190,34.230,49.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 3.640 |  Acc: 31.102,47.074,62.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 4.726 |  Acc: 23.090,34.310,51.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 3.601 |  Acc: 31.484,47.444,63.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 4.365 |  Acc: 25.570,40.260,52.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 3.568 |  Acc: 31.878,48.110,63.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 4.217 |  Acc: 26.850,40.640,54.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 3.548 |  Acc: 31.864,48.456,63.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 4.516 |  Acc: 24.190,36.160,53.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.518 |  Acc: 32.290,48.668,64.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 4.384 |  Acc: 23.920,38.370,55.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.483 |  Acc: 32.270,49.422,64.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 4.224 |  Acc: 24.650,41.340,55.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.449 |  Acc: 32.554,49.862,65.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 4.380 |  Acc: 24.040,41.420,55.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.427 |  Acc: 32.738,50.136,65.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 4.442 |  Acc: 22.670,39.550,54.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.396 |  Acc: 33.008,50.180,65.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 4.193 |  Acc: 26.100,43.190,55.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.377 |  Acc: 33.518,50.698,66.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 4.232 |  Acc: 28.410,42.170,56.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.354 |  Acc: 33.390,51.164,66.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 4.386 |  Acc: 25.440,39.610,54.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.332 |  Acc: 33.476,51.424,66.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 4.753 |  Acc: 21.960,37.300,50.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.320 |  Acc: 33.746,51.708,66.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 4.544 |  Acc: 23.540,39.210,52.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.282 |  Acc: 33.800,52.270,67.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 4.130 |  Acc: 28.190,42.980,56.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.274 |  Acc: 33.934,52.130,67.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 4.025 |  Acc: 27.070,46.230,58.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.249 |  Acc: 34.144,52.540,67.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 4.107 |  Acc: 25.840,44.080,58.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.229 |  Acc: 34.294,53.082,68.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 4.077 |  Acc: 27.000,42.930,57.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.224 |  Acc: 34.388,52.926,68.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 4.322 |  Acc: 22.730,42.590,55.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.206 |  Acc: 34.634,53.234,68.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 3.935 |  Acc: 28.500,44.140,59.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.184 |  Acc: 34.898,53.346,68.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 3.975 |  Acc: 29.870,45.790,57.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.166 |  Acc: 34.722,53.700,69.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 4.208 |  Acc: 24.760,42.730,56.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.148 |  Acc: 35.336,54.202,69.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 4.336 |  Acc: 26.650,41.750,55.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.147 |  Acc: 35.148,53.996,69.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 3.992 |  Acc: 31.290,43.800,56.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.123 |  Acc: 35.626,54.466,69.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 4.146 |  Acc: 24.920,44.850,58.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.136 |  Acc: 34.994,54.274,69.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 4.808 |  Acc: 21.830,39.150,51.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.097 |  Acc: 35.574,54.756,70.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 3.981 |  Acc: 31.600,45.150,57.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.075 |  Acc: 35.800,54.928,70.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 4.391 |  Acc: 24.100,42.200,55.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.079 |  Acc: 35.798,55.224,70.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 4.029 |  Acc: 29.740,45.160,57.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.061 |  Acc: 36.012,55.092,70.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 3.803 |  Acc: 31.700,48.570,59.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.058 |  Acc: 35.974,55.220,70.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 4.134 |  Acc: 28.460,44.940,56.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.045 |  Acc: 36.226,55.364,70.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 4.046 |  Acc: 26.940,46.130,57.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.023 |  Acc: 35.972,55.988,71.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 4.457 |  Acc: 20.780,44.200,57.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.021 |  Acc: 36.078,55.926,70.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 4.124 |  Acc: 27.860,43.590,57.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 2.998 |  Acc: 36.516,56.144,71.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 4.115 |  Acc: 29.690,42.980,57.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 2.996 |  Acc: 36.324,56.188,71.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 4.050 |  Acc: 28.840,45.640,58.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 2.995 |  Acc: 36.420,56.232,71.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 3.998 |  Acc: 28.310,45.370,58.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 2.979 |  Acc: 36.600,56.304,71.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 4.522 |  Acc: 21.470,41.780,55.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 2.976 |  Acc: 36.896,56.464,71.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 3.947 |  Acc: 29.150,46.160,59.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 2.963 |  Acc: 37.074,56.406,71.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 4.106 |  Acc: 26.420,46.120,57.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 2.952 |  Acc: 36.946,56.916,72.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 3.904 |  Acc: 29.520,45.770,59.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 2.949 |  Acc: 36.714,56.864,72.090,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 4.277 |  Acc: 30.100,40.220,55.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 2.937 |  Acc: 37.084,57.156,72.140,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 3.885 |  Acc: 30.480,45.700,58.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 2.928 |  Acc: 37.084,57.082,72.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 3.895 |  Acc: 28.680,46.520,60.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 2.925 |  Acc: 37.182,57.276,72.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 3.962 |  Acc: 29.200,45.070,58.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 2.907 |  Acc: 37.320,57.328,72.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 4.219 |  Acc: 28.370,41.710,55.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 2.906 |  Acc: 37.386,57.448,72.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 3.990 |  Acc: 29.090,45.470,57.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 2.892 |  Acc: 37.500,57.542,73.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 4.784 |  Acc: 23.730,37.780,52.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 2.894 |  Acc: 37.532,57.476,73.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 4.066 |  Acc: 25.510,46.750,58.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 2.880 |  Acc: 37.806,57.894,72.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 3.924 |  Acc: 27.970,47.190,60.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 2.881 |  Acc: 37.700,57.764,72.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 4.786 |  Acc: 19.760,41.260,54.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 2.871 |  Acc: 37.498,57.654,73.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 3.918 |  Acc: 30.570,46.620,59.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 2.872 |  Acc: 37.598,57.682,73.154,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 4.157 |  Acc: 28.030,44.130,56.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 2.845 |  Acc: 38.144,58.006,73.554,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 3.954 |  Acc: 30.790,47.910,57.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 2.841 |  Acc: 37.956,58.064,73.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 4.203 |  Acc: 27.680,44.670,56.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 2.838 |  Acc: 38.196,58.202,73.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 4.459 |  Acc: 28.190,42.210,56.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 2.841 |  Acc: 37.974,58.356,73.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 3.960 |  Acc: 31.210,45.010,57.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 2.837 |  Acc: 38.006,58.416,73.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 4.145 |  Acc: 26.360,46.290,58.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 2.825 |  Acc: 38.298,58.662,74.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 4.723 |  Acc: 21.970,40.720,57.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 2.822 |  Acc: 38.178,58.154,73.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 4.164 |  Acc: 26.420,45.700,59.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 2.808 |  Acc: 38.292,58.614,73.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 4.120 |  Acc: 27.220,45.720,57.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 2.811 |  Acc: 38.284,58.696,74.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 3.953 |  Acc: 30.120,46.630,58.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 2.811 |  Acc: 38.398,58.760,74.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 4.166 |  Acc: 25.950,44.720,58.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 2.814 |  Acc: 38.352,58.502,73.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 3.989 |  Acc: 27.260,47.460,59.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 2.796 |  Acc: 38.426,59.036,73.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 3.819 |  Acc: 30.480,48.410,59.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 2.793 |  Acc: 38.500,59.056,74.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 3.819 |  Acc: 28.570,49.380,60.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 2.794 |  Acc: 38.702,59.132,74.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 4.205 |  Acc: 30.580,44.330,55.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 2.778 |  Acc: 38.696,59.072,74.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 4.043 |  Acc: 27.260,48.550,59.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 2.777 |  Acc: 38.658,58.946,74.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 4.213 |  Acc: 31.050,42.870,54.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 2.761 |  Acc: 38.566,59.460,74.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 4.554 |  Acc: 25.950,41.980,54.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 2.767 |  Acc: 38.956,59.480,74.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 4.294 |  Acc: 23.670,46.660,60.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 2.759 |  Acc: 38.852,59.394,74.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 3.922 |  Acc: 29.170,47.300,60.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 2.752 |  Acc: 38.820,59.454,74.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 4.149 |  Acc: 24.270,45.290,60.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.750 |  Acc: 38.860,59.808,74.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 4.094 |  Acc: 27.090,46.470,59.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.745 |  Acc: 38.828,59.716,74.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 4.170 |  Acc: 25.510,45.510,57.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.747 |  Acc: 39.002,59.854,74.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 3.714 |  Acc: 31.080,48.670,62.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.737 |  Acc: 38.780,59.660,74.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 3.769 |  Acc: 29.940,48.120,61.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.727 |  Acc: 39.448,60.016,75.140,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 3.959 |  Acc: 29.250,46.470,59.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.744 |  Acc: 38.802,59.780,74.886,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 3.888 |  Acc: 27.790,49.840,60.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.722 |  Acc: 39.038,60.078,75.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 3.966 |  Acc: 29.950,47.350,59.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.723 |  Acc: 39.380,60.142,75.256,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 4.406 |  Acc: 24.810,44.380,58.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 2.725 |  Acc: 38.952,59.900,75.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 3.856 |  Acc: 31.600,49.520,58.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.705 |  Acc: 39.416,60.196,75.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 4.237 |  Acc: 28.870,44.170,57.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.724 |  Acc: 39.094,60.072,75.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 3.856 |  Acc: 28.560,48.620,59.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.699 |  Acc: 39.444,60.622,75.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 4.185 |  Acc: 23.760,46.950,60.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.711 |  Acc: 39.124,60.014,75.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 4.086 |  Acc: 28.110,45.780,58.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 2.709 |  Acc: 39.322,60.436,75.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 3.730 |  Acc: 34.770,50.410,58.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 2.712 |  Acc: 39.074,60.334,75.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 4.226 |  Acc: 23.820,45.300,58.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 2.686 |  Acc: 39.414,60.818,75.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 4.078 |  Acc: 25.710,49.090,59.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 2.684 |  Acc: 39.334,60.652,75.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 3.738 |  Acc: 33.460,49.420,60.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 2.681 |  Acc: 39.400,60.662,75.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 4.298 |  Acc: 28.100,43.160,56.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 2.692 |  Acc: 39.362,60.380,75.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 4.605 |  Acc: 23.490,43.820,56.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 2.687 |  Acc: 39.492,60.450,75.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 3.971 |  Acc: 29.830,47.060,58.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 2.669 |  Acc: 39.590,60.810,76.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 3.801 |  Acc: 32.820,48.670,60.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 2.677 |  Acc: 39.458,60.360,76.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 4.282 |  Acc: 24.660,45.580,58.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 2.679 |  Acc: 39.752,60.690,75.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 4.685 |  Acc: 22.560,42.360,55.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 2.671 |  Acc: 39.632,60.560,76.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 4.055 |  Acc: 29.700,45.810,59.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 2.666 |  Acc: 39.446,60.692,75.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 4.417 |  Acc: 24.190,44.390,60.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 2.668 |  Acc: 39.614,60.796,75.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 3.730 |  Acc: 33.190,51.360,62.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 2.677 |  Acc: 39.662,60.736,75.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 3.872 |  Acc: 30.730,49.650,60.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 2.661 |  Acc: 39.654,60.948,76.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 3.740 |  Acc: 32.060,49.740,61.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 2.667 |  Acc: 40.010,61.058,76.080,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 3.681 |  Acc: 31.420,50.840,61.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 2.657 |  Acc: 39.882,60.922,76.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 4.211 |  Acc: 26.000,46.990,59.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 2.655 |  Acc: 39.776,60.984,76.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 3.756 |  Acc: 32.710,50.900,60.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 2.647 |  Acc: 40.044,60.998,76.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 4.083 |  Acc: 28.390,48.990,60.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 2.658 |  Acc: 39.446,60.744,75.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 4.090 |  Acc: 29.090,46.920,58.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 2.644 |  Acc: 40.046,61.240,76.256,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 4.569 |  Acc: 24.580,40.240,54.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 2.644 |  Acc: 39.990,61.094,76.270,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 4.120 |  Acc: 29.010,46.580,57.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 2.638 |  Acc: 39.988,61.216,76.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 3.930 |  Acc: 28.000,47.760,61.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 2.638 |  Acc: 39.706,60.958,76.270,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 3.826 |  Acc: 27.520,49.800,61.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 2.639 |  Acc: 39.850,61.166,76.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 3.967 |  Acc: 29.940,48.050,59.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 2.628 |  Acc: 40.044,61.298,76.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 3.969 |  Acc: 28.130,47.420,60.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 2.648 |  Acc: 39.844,61.172,76.146,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 4.005 |  Acc: 26.970,49.130,60.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 2.631 |  Acc: 39.862,61.402,76.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 4.465 |  Acc: 26.150,42.520,58.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 2.624 |  Acc: 40.124,61.688,76.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 4.109 |  Acc: 28.460,47.800,58.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 2.640 |  Acc: 39.988,61.338,76.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 4.089 |  Acc: 24.260,46.940,58.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 2.619 |  Acc: 40.020,61.386,76.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 4.063 |  Acc: 25.690,47.310,59.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 2.627 |  Acc: 40.074,61.498,76.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 4.175 |  Acc: 28.990,44.130,58.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 2.613 |  Acc: 40.260,61.536,76.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 3.570 |  Acc: 35.020,51.050,61.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 2.611 |  Acc: 40.162,61.628,76.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 5.096 |  Acc: 19.300,39.360,53.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.189 |  Acc: 43.672,67.612,84.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 2.817 |  Acc: 41.190,61.580,71.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.058 |  Acc: 44.616,69.316,86.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 2.811 |  Acc: 41.690,61.960,71.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 2.011 |  Acc: 45.112,69.928,87.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 2.832 |  Acc: 40.850,61.590,71.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.987 |  Acc: 44.942,70.388,88.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 2.811 |  Acc: 41.740,62.360,71.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.960 |  Acc: 44.940,70.570,89.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 2.833 |  Acc: 41.470,62.530,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.935 |  Acc: 45.448,70.968,89.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 2.808 |  Acc: 41.820,62.560,71.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.923 |  Acc: 45.338,71.202,89.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 2.823 |  Acc: 41.930,62.740,71.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.902 |  Acc: 45.468,71.328,90.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 2.818 |  Acc: 42.410,62.560,71.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.885 |  Acc: 45.650,71.524,90.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 2.834 |  Acc: 42.240,62.700,71.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.883 |  Acc: 45.356,71.410,90.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 2.875 |  Acc: 41.950,62.330,71.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.862 |  Acc: 45.704,71.656,91.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 2.860 |  Acc: 42.000,62.560,71.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.858 |  Acc: 45.818,71.844,91.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 2.854 |  Acc: 41.990,62.510,71.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.846 |  Acc: 45.834,72.074,91.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 2.867 |  Acc: 42.050,62.720,71.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.826 |  Acc: 45.962,72.190,91.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 2.872 |  Acc: 42.030,62.790,71.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.829 |  Acc: 45.890,72.082,91.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 2.882 |  Acc: 42.660,62.340,71.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.822 |  Acc: 45.940,72.182,91.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 2.873 |  Acc: 41.920,62.310,71.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.813 |  Acc: 45.784,72.106,92.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 2.875 |  Acc: 42.550,62.690,71.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.805 |  Acc: 46.136,72.306,92.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 2.913 |  Acc: 42.310,62.310,70.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.801 |  Acc: 46.216,72.280,92.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 2.905 |  Acc: 42.130,62.440,70.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.784 |  Acc: 46.132,72.416,92.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 2.916 |  Acc: 42.220,62.140,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.784 |  Acc: 46.206,72.514,92.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 2.917 |  Acc: 42.550,62.170,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.769 |  Acc: 46.184,72.864,93.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 2.900 |  Acc: 42.900,62.680,70.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.775 |  Acc: 46.226,72.742,92.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 2.925 |  Acc: 42.350,62.320,70.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.766 |  Acc: 46.088,72.902,93.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 2.943 |  Acc: 41.810,62.500,70.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.759 |  Acc: 46.394,72.834,93.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 2.942 |  Acc: 42.150,62.710,70.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.755 |  Acc: 46.250,72.916,93.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 2.965 |  Acc: 42.050,62.590,70.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.748 |  Acc: 46.336,72.850,93.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 2.942 |  Acc: 42.910,62.720,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.745 |  Acc: 46.570,73.122,93.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 2.968 |  Acc: 42.510,62.570,70.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.738 |  Acc: 46.508,73.102,93.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 2.967 |  Acc: 42.070,62.330,70.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.738 |  Acc: 46.364,73.062,93.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 2.975 |  Acc: 42.130,62.540,70.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.731 |  Acc: 46.510,73.432,93.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 2.988 |  Acc: 42.080,62.190,69.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.729 |  Acc: 46.536,73.296,93.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 2.939 |  Acc: 42.800,63.100,70.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.725 |  Acc: 46.786,73.308,93.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 2.955 |  Acc: 42.410,62.730,70.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.719 |  Acc: 46.694,73.442,93.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 2.961 |  Acc: 42.600,62.380,70.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.716 |  Acc: 46.854,73.450,93.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 2.964 |  Acc: 42.670,62.750,70.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.719 |  Acc: 46.440,73.634,93.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 2.938 |  Acc: 42.810,63.000,70.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.714 |  Acc: 46.896,73.516,94.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 3.008 |  Acc: 41.730,62.340,69.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.706 |  Acc: 46.698,73.852,94.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 2.986 |  Acc: 42.290,62.410,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.718 |  Acc: 46.496,73.522,93.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 3.006 |  Acc: 41.510,62.580,69.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.699 |  Acc: 47.094,73.692,94.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 2.985 |  Acc: 42.530,62.220,70.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.703 |  Acc: 46.612,73.504,94.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 3.027 |  Acc: 42.530,62.340,69.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.695 |  Acc: 46.904,73.688,94.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 2.974 |  Acc: 42.560,62.720,70.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.696 |  Acc: 46.692,73.622,94.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 3.042 |  Acc: 41.320,62.370,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.692 |  Acc: 46.872,73.966,94.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 3.048 |  Acc: 42.010,62.770,69.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.694 |  Acc: 46.534,73.954,94.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 2.997 |  Acc: 42.970,62.410,70.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.683 |  Acc: 46.754,73.794,94.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 3.004 |  Acc: 42.840,62.420,70.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.683 |  Acc: 46.762,74.082,94.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 3.037 |  Acc: 41.250,62.330,69.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.677 |  Acc: 46.940,74.000,94.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 3.037 |  Acc: 42.770,62.260,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.678 |  Acc: 47.098,74.160,94.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 3.042 |  Acc: 42.990,62.640,69.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.676 |  Acc: 46.802,74.148,94.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 3.014 |  Acc: 42.750,63.020,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.682 |  Acc: 46.648,73.930,94.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 3.028 |  Acc: 42.580,62.810,69.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.684 |  Acc: 46.600,74.066,94.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 3.053 |  Acc: 42.070,62.590,69.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.672 |  Acc: 47.036,74.148,94.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 3.027 |  Acc: 42.820,62.450,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.675 |  Acc: 46.896,74.068,94.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 3.028 |  Acc: 42.170,62.280,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.670 |  Acc: 46.800,74.206,94.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 3.099 |  Acc: 41.570,61.600,69.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.668 |  Acc: 46.902,74.234,94.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 3.030 |  Acc: 42.840,62.550,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.665 |  Acc: 46.880,74.294,94.608,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 3.114 |  Acc: 41.790,61.760,68.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.664 |  Acc: 47.096,74.444,94.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 3.044 |  Acc: 42.530,62.160,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.663 |  Acc: 47.084,74.206,94.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 3.041 |  Acc: 43.170,62.670,69.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.657 |  Acc: 46.908,74.634,94.940,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 3.092 |  Acc: 41.830,62.000,68.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.660 |  Acc: 47.010,74.392,94.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 3.066 |  Acc: 42.790,61.610,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.661 |  Acc: 47.026,74.436,94.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 3.086 |  Acc: 42.360,61.830,69.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.657 |  Acc: 47.034,74.530,94.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 3.068 |  Acc: 42.450,62.310,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.659 |  Acc: 46.944,74.066,94.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 3.172 |  Acc: 40.920,61.690,68.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.655 |  Acc: 47.114,74.412,94.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 3.070 |  Acc: 42.990,62.640,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.649 |  Acc: 47.336,74.426,94.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 3.089 |  Acc: 42.810,62.090,68.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.652 |  Acc: 47.358,74.590,94.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 3.079 |  Acc: 41.830,62.130,69.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.651 |  Acc: 47.274,74.492,94.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 3.132 |  Acc: 41.270,61.630,68.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.644 |  Acc: 47.116,74.470,95.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 3.208 |  Acc: 40.410,61.020,68.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.650 |  Acc: 47.330,74.552,94.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 3.153 |  Acc: 40.800,61.750,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.652 |  Acc: 46.950,74.700,94.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 3.079 |  Acc: 42.870,61.270,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.645 |  Acc: 47.032,74.584,95.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 3.191 |  Acc: 40.400,60.970,68.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.638 |  Acc: 47.412,74.566,95.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 3.058 |  Acc: 42.660,61.840,69.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.654 |  Acc: 47.016,74.512,94.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 3.153 |  Acc: 41.520,61.210,68.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.647 |  Acc: 47.150,74.804,94.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 3.154 |  Acc: 41.540,61.620,68.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.575 |  Acc: 47.942,76.042,96.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 2.948 |  Acc: 44.040,63.720,70.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.543 |  Acc: 48.478,76.668,96.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 2.940 |  Acc: 44.250,63.550,70.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.538 |  Acc: 48.066,76.630,96.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 2.951 |  Acc: 44.100,63.670,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.532 |  Acc: 48.288,76.790,97.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 2.971 |  Acc: 43.990,63.810,70.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.530 |  Acc: 48.110,76.844,97.104,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 2.952 |  Acc: 44.080,63.670,70.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.527 |  Acc: 48.162,77.064,97.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 2.945 |  Acc: 44.230,63.980,70.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.526 |  Acc: 48.240,77.036,97.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 2.956 |  Acc: 44.210,63.780,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.522 |  Acc: 48.300,77.076,97.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 2.956 |  Acc: 44.000,63.790,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.521 |  Acc: 48.310,77.200,97.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 2.963 |  Acc: 43.920,63.960,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.520 |  Acc: 48.192,77.088,97.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 2.956 |  Acc: 43.950,63.910,70.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.514 |  Acc: 48.560,77.044,97.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 2.965 |  Acc: 44.230,63.670,70.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.516 |  Acc: 48.340,77.358,97.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 2.964 |  Acc: 43.850,63.610,70.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.513 |  Acc: 48.348,77.302,97.308,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 2.968 |  Acc: 44.030,63.720,70.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.511 |  Acc: 48.534,77.290,97.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 2.969 |  Acc: 44.170,63.650,70.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.509 |  Acc: 48.184,77.312,97.440,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 2.969 |  Acc: 44.160,63.770,70.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.512 |  Acc: 48.130,77.302,97.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 2.967 |  Acc: 44.160,63.970,70.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.512 |  Acc: 48.242,77.370,97.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 2.984 |  Acc: 44.090,63.660,70.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.508 |  Acc: 48.222,77.250,97.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 2.964 |  Acc: 44.400,63.620,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.505 |  Acc: 48.674,77.330,97.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 2.973 |  Acc: 44.040,63.900,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.506 |  Acc: 48.260,77.462,97.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 2.965 |  Acc: 44.480,64.210,70.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.506 |  Acc: 48.560,77.270,97.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 2.983 |  Acc: 43.920,63.590,70.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.504 |  Acc: 48.708,77.518,97.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 2.976 |  Acc: 44.310,63.900,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.506 |  Acc: 48.634,77.402,97.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 2.981 |  Acc: 44.300,64.240,70.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.503 |  Acc: 48.416,77.280,97.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 2.974 |  Acc: 44.080,63.800,70.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.500 |  Acc: 48.436,77.404,97.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 2.984 |  Acc: 44.180,63.830,70.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.506 |  Acc: 48.480,77.238,97.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 2.981 |  Acc: 44.040,63.920,70.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.502 |  Acc: 48.648,77.632,97.554,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 2.976 |  Acc: 44.280,63.670,70.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.498 |  Acc: 48.394,77.588,97.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 2.984 |  Acc: 44.390,63.780,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.503 |  Acc: 48.620,77.352,97.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 2.978 |  Acc: 44.430,63.950,70.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.501 |  Acc: 48.430,77.566,97.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 2.981 |  Acc: 44.400,63.880,70.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.502 |  Acc: 48.412,77.372,97.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 2.982 |  Acc: 44.320,63.760,70.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.500 |  Acc: 48.676,77.332,97.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 2.982 |  Acc: 44.050,63.740,70.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.498 |  Acc: 48.670,77.540,97.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 2.983 |  Acc: 44.250,63.850,70.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.494 |  Acc: 48.608,77.616,97.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 2.988 |  Acc: 44.420,63.810,70.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.498 |  Acc: 48.246,77.376,97.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 3.001 |  Acc: 44.270,63.990,70.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.495 |  Acc: 48.674,77.688,97.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 2.995 |  Acc: 44.240,63.800,70.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.493 |  Acc: 48.412,77.620,97.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 3.002 |  Acc: 43.940,63.660,70.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.489 |  Acc: 48.564,77.852,97.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 2.981 |  Acc: 44.540,63.960,70.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.486 |  Acc: 48.788,77.586,97.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 2.992 |  Acc: 44.180,63.770,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.488 |  Acc: 48.594,77.668,97.778,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 2.983 |  Acc: 44.310,63.990,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.487 |  Acc: 48.810,77.818,97.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 2.993 |  Acc: 44.130,63.610,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.486 |  Acc: 48.828,78.152,97.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 2.987 |  Acc: 44.210,63.770,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.487 |  Acc: 48.552,77.874,97.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 2.990 |  Acc: 44.110,63.760,70.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.483 |  Acc: 48.664,77.858,97.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 2.987 |  Acc: 44.130,63.880,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.488 |  Acc: 48.760,77.768,97.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 2.987 |  Acc: 44.240,63.660,70.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.487 |  Acc: 48.834,77.656,97.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 2.983 |  Acc: 44.380,63.890,70.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.486 |  Acc: 48.862,77.876,97.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 2.983 |  Acc: 44.470,63.910,70.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.487 |  Acc: 48.470,77.678,97.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 2.984 |  Acc: 44.440,63.820,70.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.483 |  Acc: 48.738,77.910,97.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 2.982 |  Acc: 44.360,64.020,70.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.486 |  Acc: 48.788,77.896,97.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 2.990 |  Acc: 44.350,63.980,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.484 |  Acc: 48.712,78.016,97.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 2.980 |  Acc: 44.350,63.810,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.486 |  Acc: 48.716,77.892,97.950,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 2.989 |  Acc: 44.510,63.720,70.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.488 |  Acc: 48.470,77.696,97.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 2.993 |  Acc: 44.150,63.850,70.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.492 |  Acc: 48.634,77.690,97.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 2.992 |  Acc: 44.080,63.740,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.484 |  Acc: 48.618,77.902,97.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 2.988 |  Acc: 44.070,63.970,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.482 |  Acc: 48.582,77.930,97.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 2.985 |  Acc: 44.170,63.800,70.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.488 |  Acc: 48.814,77.658,97.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 2.988 |  Acc: 44.190,63.840,70.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.484 |  Acc: 48.462,77.982,97.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 2.991 |  Acc: 44.060,63.730,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.486 |  Acc: 48.574,77.990,97.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 2.993 |  Acc: 44.430,63.530,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.485 |  Acc: 48.784,77.830,97.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 2.979 |  Acc: 44.550,63.870,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.483 |  Acc: 48.646,77.814,97.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 2.986 |  Acc: 44.170,63.860,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.484 |  Acc: 48.644,77.748,97.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 2.978 |  Acc: 44.330,63.850,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.480 |  Acc: 48.890,77.952,97.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 2.997 |  Acc: 44.320,63.740,70.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.485 |  Acc: 48.528,77.722,97.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 2.994 |  Acc: 44.120,63.830,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.481 |  Acc: 48.584,77.810,97.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 2.984 |  Acc: 44.280,63.840,70.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.484 |  Acc: 48.758,77.856,97.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 2.988 |  Acc: 44.340,63.720,70.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.485 |  Acc: 48.696,77.578,97.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 2.983 |  Acc: 44.270,63.970,70.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.481 |  Acc: 48.854,78.100,97.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 2.988 |  Acc: 44.260,64.090,70.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.482 |  Acc: 48.886,77.932,97.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 2.998 |  Acc: 44.260,63.720,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.487 |  Acc: 48.722,77.770,97.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 2.990 |  Acc: 44.060,63.900,70.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.483 |  Acc: 48.788,77.758,97.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 2.994 |  Acc: 44.330,63.690,70.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.488 |  Acc: 48.674,77.930,97.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 2.987 |  Acc: 44.400,63.930,70.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.483 |  Acc: 48.588,77.606,97.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 2.993 |  Acc: 44.200,63.860,70.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.480 |  Acc: 48.900,77.858,97.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 2.996 |  Acc: 44.400,63.890,70.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='scan', backend='resnet56_2con3_att3', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.483 |  Acc: 48.508,77.808,97.870,% | Adaptive Acc:89.996% | clf_exit: 0.263 0.443 0.294
Testing: Epoch=299 | Loss: 2.988 |  Acc: 44.440,63.800,70.340,% | Adaptive Acc:66.090% | clf_exit: 0.330 0.372 0.297

circles: 0
Testing: Epoch=299 | Loss: 5.537 |  Acc: 44.440,14.180,44.220,% | Adaptive Acc:48.080% | clf_exit: 0.330 0.033 0.636
circles: 1
Testing: Epoch=299 | Loss: 3.955 |  Acc: 44.440,41.320,64.780,% | Adaptive Acc:61.150% | clf_exit: 0.330 0.112 0.558
circles: 2
Testing: Epoch=299 | Loss: 2.988 |  Acc: 44.440,63.800,70.340,% | Adaptive Acc:66.090% | clf_exit: 0.330 0.372 0.297

