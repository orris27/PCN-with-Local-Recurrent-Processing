==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=16, out_features=16, bias=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (BN1d): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=48, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=48, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=96, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=96, out_features=100, bias=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.314 | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.572 | Acc: 1.079,1.190,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.266 | Acc: 1.048,1.353,1.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.094 | Acc: 1.370,1.870,2.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.990 | Acc: 1.640,2.170,2.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.923 | Acc: 1.686,2.158,2.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.868 | Acc: 1.801,2.292,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.807 | Acc: 1.995,2.521,3.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.761 | Acc: 2.014,2.645,3.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.727 | Acc: 2.072,2.732,3.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.687 | Acc: 2.130,2.837,3.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.649 | Acc: 2.195,3.001,3.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.611 | Acc: 2.269,3.073,4.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.572 | Acc: 2.341,3.212,4.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.536 | Acc: 2.452,3.278,4.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.504 | Acc: 2.538,3.322,4.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.471 | Acc: 2.597,3.441,4.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.440 | Acc: 2.658,3.510,5.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.403 | Acc: 2.684,3.595,5.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.371 | Acc: 2.760,3.709,5.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.712 | Acc: 3.125,4.688,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.753 | Acc: 4.874,5.990,8.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.763 | Acc: 4.554,5.621,8.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.768 | Acc: 4.022,5.802,8.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 12.765 | Acc: 1.562,6.250,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.716 | Acc: 4.129,5.618,9.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.636 | Acc: 4.211,6.155,9.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.611 | Acc: 4.290,6.570,9.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.600 | Acc: 4.225,6.790,9.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.576 | Acc: 4.401,6.869,10.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.562 | Acc: 4.274,6.915,10.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.541 | Acc: 4.305,7.053,10.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.518 | Acc: 4.362,7.133,10.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.489 | Acc: 4.381,7.238,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.480 | Acc: 4.412,7.299,10.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.461 | Acc: 4.475,7.300,11.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.439 | Acc: 4.506,7.423,11.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.420 | Acc: 4.526,7.486,11.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.391 | Acc: 4.599,7.612,11.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.371 | Acc: 4.659,7.761,11.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.351 | Acc: 4.690,7.834,11.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.330 | Acc: 4.692,7.945,11.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.309 | Acc: 4.690,8.003,11.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.285 | Acc: 4.774,8.112,11.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.957 | Acc: 6.250,7.031,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.976 | Acc: 5.915,9.226,12.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.970 | Acc: 5.697,9.108,12.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.986 | Acc: 5.635,9.401,13.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 11.791 | Acc: 7.812,7.812,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.934 | Acc: 5.990,9.115,13.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.906 | Acc: 5.964,9.699,14.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.850 | Acc: 6.212,10.028,14.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.797 | Acc: 6.385,10.378,15.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.785 | Acc: 6.521,10.396,15.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.795 | Acc: 6.508,10.343,15.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.774 | Acc: 6.566,10.483,15.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.752 | Acc: 6.672,10.549,15.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.734 | Acc: 6.708,10.510,15.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.724 | Acc: 6.709,10.568,15.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.710 | Acc: 6.664,10.552,15.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.689 | Acc: 6.756,10.620,15.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.672 | Acc: 6.828,10.641,15.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.657 | Acc: 6.862,10.762,15.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.636 | Acc: 6.901,10.852,15.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.623 | Acc: 6.978,10.889,15.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.609 | Acc: 7.029,10.926,15.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.595 | Acc: 7.005,10.931,15.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.579 | Acc: 7.070,11.022,15.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.218 | Acc: 9.375,14.844,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.389 | Acc: 8.259,12.016,16.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.385 | Acc: 8.289,11.738,16.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.395 | Acc: 8.069,11.770,16.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 11.718 | Acc: 7.031,4.688,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.210 | Acc: 8.891,13.318,18.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.174 | Acc: 8.689,13.434,19.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.185 | Acc: 8.581,13.064,18.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.153 | Acc: 8.661,13.243,18.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.162 | Acc: 8.594,13.065,18.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.134 | Acc: 8.762,13.210,18.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.125 | Acc: 8.721,13.270,18.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.108 | Acc: 8.788,13.281,18.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.084 | Acc: 8.827,13.376,18.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.065 | Acc: 8.858,13.495,18.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.048 | Acc: 8.898,13.479,18.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.024 | Acc: 8.973,13.518,19.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.015 | Acc: 9.046,13.551,19.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.999 | Acc: 9.086,13.607,19.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.983 | Acc: 9.102,13.663,19.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.966 | Acc: 9.202,13.729,19.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.956 | Acc: 9.217,13.797,19.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.942 | Acc: 9.381,13.896,19.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.930 | Acc: 9.363,13.956,19.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.466 | Acc: 12.500,17.188,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.764 | Acc: 10.789,15.737,21.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.746 | Acc: 10.213,14.768,21.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.764 | Acc: 10.156,14.395,21.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 10.267 | Acc: 10.938,20.312,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.546 | Acc: 10.342,16.406,22.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.540 | Acc: 10.423,15.720,21.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.475 | Acc: 11.040,16.176,21.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.488 | Acc: 11.063,16.127,21.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.482 | Acc: 11.162,16.112,22.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.467 | Acc: 11.435,16.264,22.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.449 | Acc: 11.486,16.246,22.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.449 | Acc: 11.496,16.110,22.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.427 | Acc: 11.473,16.173,22.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.419 | Acc: 11.579,16.227,22.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.409 | Acc: 11.595,16.336,22.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.393 | Acc: 11.725,16.448,22.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.382 | Acc: 11.862,16.565,22.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.381 | Acc: 11.855,16.637,22.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.364 | Acc: 11.945,16.705,22.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.355 | Acc: 11.935,16.730,22.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.333 | Acc: 12.033,16.839,22.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.327 | Acc: 12.054,16.863,22.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.312 | Acc: 12.205,16.993,23.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.420 | Acc: 13.281,14.062,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.589 | Acc: 11.235,15.253,21.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.539 | Acc: 11.052,15.663,21.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.538 | Acc: 11.411,15.638,21.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 9.675 | Acc: 17.969,25.781,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.025 | Acc: 13.765,18.564,24.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.996 | Acc: 13.681,18.331,24.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.962 | Acc: 13.832,18.840,25.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.945 | Acc: 13.947,18.789,25.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.921 | Acc: 14.186,18.912,25.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.903 | Acc: 14.224,19.066,25.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.893 | Acc: 14.223,19.088,25.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.900 | Acc: 14.101,19.056,25.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.875 | Acc: 14.352,19.225,25.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.872 | Acc: 14.373,19.193,25.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.852 | Acc: 14.480,19.397,25.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.838 | Acc: 14.477,19.470,25.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.817 | Acc: 14.577,19.492,26.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.813 | Acc: 14.621,19.520,26.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.803 | Acc: 14.672,19.586,26.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.791 | Acc: 14.734,19.697,26.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.789 | Acc: 14.741,19.653,26.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.776 | Acc: 14.770,19.694,26.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.770 | Acc: 14.807,19.761,26.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.901 | Acc: 15.625,22.656,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.966 | Acc: 13.504,18.266,26.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.953 | Acc: 14.291,18.197,25.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.934 | Acc: 14.114,18.033,25.756,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 8.719 | Acc: 28.125,30.469,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.461 | Acc: 16.332,20.945,27.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.426 | Acc: 15.911,20.617,27.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.451 | Acc: 15.804,20.236,27.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.428 | Acc: 16.011,20.534,27.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.433 | Acc: 16.182,20.908,27.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.401 | Acc: 16.368,21.158,28.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.401 | Acc: 16.456,21.188,28.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.382 | Acc: 16.629,21.409,28.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.383 | Acc: 16.756,21.569,28.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.387 | Acc: 16.717,21.657,28.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.372 | Acc: 16.802,21.836,28.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.363 | Acc: 16.847,21.856,28.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.338 | Acc: 17.053,21.971,28.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.323 | Acc: 17.093,22.025,29.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.318 | Acc: 17.200,22.132,29.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.317 | Acc: 17.224,22.114,29.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.308 | Acc: 17.229,22.173,29.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.303 | Acc: 17.281,22.226,29.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.291 | Acc: 17.321,22.263,29.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.390 | Acc: 17.188,24.219,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.404 | Acc: 16.332,21.466,27.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.398 | Acc: 16.997,20.675,28.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.409 | Acc: 16.739,20.607,27.805,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 8.705 | Acc: 22.656,30.469,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.975 | Acc: 18.341,24.963,32.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.917 | Acc: 18.998,25.400,32.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.959 | Acc: 18.699,25.038,32.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.960 | Acc: 18.837,24.778,32.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.980 | Acc: 18.711,24.691,32.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.972 | Acc: 18.866,24.593,32.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.977 | Acc: 18.706,24.551,32.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.967 | Acc: 18.881,24.685,32.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.967 | Acc: 18.875,24.603,32.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.961 | Acc: 18.890,24.604,32.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.961 | Acc: 18.948,24.601,32.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.958 | Acc: 19.019,24.598,32.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.948 | Acc: 19.007,24.563,32.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.931 | Acc: 19.053,24.550,32.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.918 | Acc: 19.054,24.626,32.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.905 | Acc: 19.127,24.623,32.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.901 | Acc: 19.197,24.688,32.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.885 | Acc: 19.341,24.851,32.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.875 | Acc: 19.388,24.887,32.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.918 | Acc: 19.531,27.344,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.968 | Acc: 18.750,24.665,33.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.924 | Acc: 18.674,24.009,33.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.941 | Acc: 18.327,23.745,32.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 8.565 | Acc: 21.875,25.781,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.617 | Acc: 19.829,25.074,35.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.588 | Acc: 20.351,26.220,34.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.578 | Acc: 20.761,26.614,34.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.611 | Acc: 20.515,26.350,34.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.574 | Acc: 20.777,26.593,34.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.561 | Acc: 20.693,26.601,34.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.556 | Acc: 20.678,26.662,34.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.555 | Acc: 20.803,26.752,34.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.541 | Acc: 20.826,26.675,34.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.532 | Acc: 20.872,26.718,34.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.529 | Acc: 20.959,26.852,34.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.528 | Acc: 21.078,26.926,34.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.529 | Acc: 21.088,26.829,34.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.523 | Acc: 21.133,26.932,34.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.526 | Acc: 21.151,26.928,34.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.523 | Acc: 21.213,26.928,34.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.516 | Acc: 21.236,26.918,34.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.516 | Acc: 21.219,26.876,34.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.503 | Acc: 21.334,26.964,35.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.047 | Acc: 17.969,27.344,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.464 | Acc: 17.671,23.698,30.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.475 | Acc: 18.102,23.438,29.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.476 | Acc: 18.007,23.169,29.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 7.757 | Acc: 32.031,35.938,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.239 | Acc: 22.879,29.315,36.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.287 | Acc: 22.351,28.601,36.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.300 | Acc: 22.054,28.548,36.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.281 | Acc: 22.184,28.434,37.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.273 | Acc: 22.208,28.473,37.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.265 | Acc: 22.392,28.396,37.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.255 | Acc: 22.640,28.496,37.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.249 | Acc: 22.647,28.537,37.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.266 | Acc: 22.527,28.470,37.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.263 | Acc: 22.551,28.440,37.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.262 | Acc: 22.423,28.411,37.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.256 | Acc: 22.413,28.508,37.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.241 | Acc: 22.444,28.595,37.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.240 | Acc: 22.492,28.614,37.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.230 | Acc: 22.539,28.670,37.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.223 | Acc: 22.586,28.714,37.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.214 | Acc: 22.675,28.801,37.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.205 | Acc: 22.819,28.947,37.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.194 | Acc: 22.861,29.019,37.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.334 | Acc: 25.000,28.906,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.545 | Acc: 20.126,28.162,35.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.516 | Acc: 20.103,27.630,34.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.530 | Acc: 19.992,27.536,35.028,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 8.520 | Acc: 25.000,29.688,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.888 | Acc: 24.219,31.659,40.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.859 | Acc: 24.123,31.174,41.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.900 | Acc: 24.219,30.968,40.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.917 | Acc: 24.257,30.999,40.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.941 | Acc: 24.172,30.770,40.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.947 | Acc: 24.406,30.772,40.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.959 | Acc: 24.374,30.812,39.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.940 | Acc: 24.520,30.944,40.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.938 | Acc: 24.482,31.026,40.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.935 | Acc: 24.549,31.071,40.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.924 | Acc: 24.636,31.098,40.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.928 | Acc: 24.614,31.004,40.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.929 | Acc: 24.605,31.011,40.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.936 | Acc: 24.533,30.880,40.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.939 | Acc: 24.533,30.892,39.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.935 | Acc: 24.535,30.817,39.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.934 | Acc: 24.558,30.792,39.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.929 | Acc: 24.567,30.774,39.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.923 | Acc: 24.584,30.807,39.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.957 | Acc: 20.312,25.000,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.325 | Acc: 18.341,23.326,31.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.336 | Acc: 18.521,23.152,31.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.333 | Acc: 18.430,23.066,31.801,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 8.428 | Acc: 25.000,30.469,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.744 | Acc: 24.702,32.515,41.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.708 | Acc: 25.991,32.393,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.709 | Acc: 26.101,32.505,41.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.703 | Acc: 26.186,32.504,41.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.707 | Acc: 25.890,32.271,41.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.684 | Acc: 25.981,32.670,42.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.670 | Acc: 25.992,32.862,41.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.678 | Acc: 25.888,32.725,41.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.679 | Acc: 25.950,32.800,41.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.684 | Acc: 25.933,32.785,41.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.675 | Acc: 25.891,32.738,41.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.681 | Acc: 25.804,32.722,41.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.681 | Acc: 25.766,32.621,41.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.680 | Acc: 25.723,32.687,41.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.682 | Acc: 25.724,32.678,41.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.679 | Acc: 25.757,32.676,41.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.687 | Acc: 25.690,32.517,41.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.686 | Acc: 25.675,32.529,41.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.677 | Acc: 25.742,32.581,41.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.663 | Acc: 25.781,33.594,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.258 | Acc: 22.917,29.129,41.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.233 | Acc: 22.066,29.154,40.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.229 | Acc: 21.901,28.906,40.471,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 7.005 | Acc: 28.125,41.406,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.357 | Acc: 27.790,34.859,43.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.436 | Acc: 26.753,34.318,43.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.445 | Acc: 26.985,34.541,43.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.449 | Acc: 27.016,34.597,43.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.478 | Acc: 26.779,34.236,43.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.522 | Acc: 26.640,33.878,43.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.520 | Acc: 26.590,33.799,43.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.506 | Acc: 26.664,33.929,43.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.497 | Acc: 26.873,34.047,43.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.493 | Acc: 26.823,34.080,43.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.479 | Acc: 26.941,34.131,43.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.472 | Acc: 26.990,34.174,43.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.471 | Acc: 26.988,34.270,43.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.461 | Acc: 27.088,34.314,43.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.463 | Acc: 27.102,34.359,43.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.468 | Acc: 27.096,34.319,43.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.471 | Acc: 27.000,34.302,43.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.465 | Acc: 27.049,34.327,43.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.461 | Acc: 27.126,34.313,43.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.892 | Acc: 27.344,35.156,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.904 | Acc: 24.926,30.580,42.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.926 | Acc: 24.047,30.030,41.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.940 | Acc: 24.116,30.136,41.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 7.546 | Acc: 21.875,30.469,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.310 | Acc: 27.827,35.417,44.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.300 | Acc: 27.649,35.328,43.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.305 | Acc: 27.318,35.361,44.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.296 | Acc: 27.286,35.320,44.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.318 | Acc: 27.135,35.172,44.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.312 | Acc: 27.260,35.363,44.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.317 | Acc: 27.183,35.228,44.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.327 | Acc: 27.096,35.210,44.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.324 | Acc: 27.223,35.260,44.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.319 | Acc: 27.375,35.354,44.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.299 | Acc: 27.542,35.425,44.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.303 | Acc: 27.493,35.373,44.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.290 | Acc: 27.550,35.381,44.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.291 | Acc: 27.502,35.345,44.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.284 | Acc: 27.531,35.418,44.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.284 | Acc: 27.643,35.407,44.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.287 | Acc: 27.697,35.340,44.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.278 | Acc: 27.718,35.425,44.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.272 | Acc: 27.750,35.447,44.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.158 | Acc: 24.219,32.031,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.146 | Acc: 23.698,29.315,41.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.138 | Acc: 23.228,29.002,40.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.162 | Acc: 23.348,28.804,39.946,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 7.597 | Acc: 23.438,32.812,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.332 | Acc: 26.637,34.412,44.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.229 | Acc: 27.344,35.137,45.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.177 | Acc: 27.421,36.002,46.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.216 | Acc: 27.151,35.812,45.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.201 | Acc: 27.591,36.115,45.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.185 | Acc: 27.802,36.441,46.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.195 | Acc: 27.715,36.436,45.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.187 | Acc: 27.814,36.534,46.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.164 | Acc: 27.944,36.671,46.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.155 | Acc: 28.144,36.746,46.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.132 | Acc: 28.309,36.825,46.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.129 | Acc: 28.388,36.916,46.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.127 | Acc: 28.385,36.868,46.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.115 | Acc: 28.481,36.958,46.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.118 | Acc: 28.462,36.986,46.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.114 | Acc: 28.551,36.984,46.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.108 | Acc: 28.650,37.044,46.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.104 | Acc: 28.772,37.134,46.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.102 | Acc: 28.720,37.117,46.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.762 | Acc: 21.875,33.594,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.802 | Acc: 19.680,28.981,39.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.830 | Acc: 19.512,28.068,38.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.862 | Acc: 19.416,27.741,37.718,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 6.904 | Acc: 32.031,41.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.039 | Acc: 29.501,37.909,47.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.004 | Acc: 29.402,37.919,48.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.938 | Acc: 29.726,38.653,48.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.921 | Acc: 29.900,38.320,48.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.930 | Acc: 29.695,38.119,48.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.937 | Acc: 29.739,38.236,48.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.937 | Acc: 29.593,38.176,48.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.940 | Acc: 29.600,38.034,48.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.943 | Acc: 29.688,38.052,48.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.954 | Acc: 29.781,38.060,48.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.958 | Acc: 29.794,37.952,47.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.956 | Acc: 29.811,37.967,47.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.951 | Acc: 29.939,38.051,47.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.961 | Acc: 29.774,37.992,47.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.952 | Acc: 29.864,38.100,47.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.948 | Acc: 30.011,38.172,47.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.957 | Acc: 29.898,38.077,47.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.947 | Acc: 29.897,38.244,47.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.951 | Acc: 29.833,38.224,47.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.210 | Acc: 18.750,25.000,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.674 | Acc: 18.118,22.507,32.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.665 | Acc: 17.988,22.275,32.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.656 | Acc: 17.764,22.182,32.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 6.953 | Acc: 27.344,34.375,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.795 | Acc: 29.762,39.807,49.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.815 | Acc: 29.726,39.482,49.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.796 | Acc: 30.661,39.818,49.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.774 | Acc: 30.855,39.921,49.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.773 | Acc: 30.507,39.728,49.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.785 | Acc: 30.501,39.637,48.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.790 | Acc: 30.413,39.617,48.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.800 | Acc: 30.323,39.519,48.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.791 | Acc: 30.542,39.598,48.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.807 | Acc: 30.477,39.595,48.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.810 | Acc: 30.469,39.501,48.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.809 | Acc: 30.543,39.575,48.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.825 | Acc: 30.379,39.407,48.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.824 | Acc: 30.435,39.418,48.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.817 | Acc: 30.513,39.449,48.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.813 | Acc: 30.515,39.457,48.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.809 | Acc: 30.521,39.514,49.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.800 | Acc: 30.555,39.642,49.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.796 | Acc: 30.565,39.678,49.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.819 | Acc: 25.000,29.688,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.148 | Acc: 23.810,31.808,42.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.093 | Acc: 23.152,31.707,42.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.036 | Acc: 23.207,32.006,42.969,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 6.080 | Acc: 34.375,48.438,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.628 | Acc: 31.399,41.295,50.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.736 | Acc: 30.354,40.454,50.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.684 | Acc: 30.943,40.612,50.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.666 | Acc: 30.797,40.548,50.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.656 | Acc: 31.064,40.656,50.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.664 | Acc: 31.101,40.522,50.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.674 | Acc: 31.089,40.553,49.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.681 | Acc: 30.973,40.455,49.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.687 | Acc: 30.969,40.357,49.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.693 | Acc: 30.943,40.326,49.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.694 | Acc: 30.985,40.363,49.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.681 | Acc: 31.130,40.528,49.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.678 | Acc: 31.208,40.430,49.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.691 | Acc: 31.078,40.328,49.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.694 | Acc: 30.962,40.306,49.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.692 | Acc: 30.943,40.340,49.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.683 | Acc: 31.090,40.417,49.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.683 | Acc: 31.027,40.391,49.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.686 | Acc: 31.041,40.420,49.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.276 | Acc: 21.094,31.250,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.527 | Acc: 19.494,29.985,41.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.566 | Acc: 19.588,29.573,41.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.589 | Acc: 19.147,29.175,40.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 6.518 | Acc: 32.031,41.406,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.424 | Acc: 32.552,43.378,51.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.406 | Acc: 32.603,42.740,51.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.410 | Acc: 32.582,42.725,52.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.454 | Acc: 32.186,42.245,51.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.489 | Acc: 32.170,42.118,51.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.515 | Acc: 32.018,42.020,51.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.525 | Acc: 32.015,42.043,51.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.532 | Acc: 31.905,41.794,51.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.543 | Acc: 31.889,41.600,51.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.533 | Acc: 31.907,41.713,51.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.543 | Acc: 31.999,41.686,51.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.556 | Acc: 31.821,41.585,51.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.561 | Acc: 31.771,41.577,51.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.560 | Acc: 31.870,41.654,51.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.560 | Acc: 31.805,41.642,51.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.559 | Acc: 31.768,41.555,51.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.558 | Acc: 31.795,41.578,51.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.562 | Acc: 31.717,41.499,51.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.557 | Acc: 31.781,41.572,51.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.943 | Acc: 23.438,32.812,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.487 | Acc: 22.731,29.055,40.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.575 | Acc: 21.818,28.716,40.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.618 | Acc: 21.901,28.855,39.780,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 6.131 | Acc: 28.125,43.750,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.392 | Acc: 32.626,41.629,52.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.436 | Acc: 32.355,42.530,52.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.411 | Acc: 32.941,42.700,52.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.434 | Acc: 32.620,42.400,52.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.445 | Acc: 32.364,42.497,52.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.460 | Acc: 32.361,42.446,51.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.471 | Acc: 32.064,42.470,51.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.492 | Acc: 31.944,42.255,51.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.477 | Acc: 32.031,42.347,51.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.472 | Acc: 32.078,42.514,51.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.463 | Acc: 32.187,42.658,51.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.447 | Acc: 32.245,42.842,51.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.443 | Acc: 32.313,42.909,51.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.438 | Acc: 32.332,42.933,51.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.441 | Acc: 32.322,42.803,52.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.440 | Acc: 32.348,42.835,51.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.440 | Acc: 32.405,42.799,52.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.451 | Acc: 32.373,42.759,51.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.452 | Acc: 32.382,42.772,51.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.576 | Acc: 26.562,29.688,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.863 | Acc: 25.818,34.189,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.949 | Acc: 24.809,33.803,43.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.992 | Acc: 24.283,33.696,43.238,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 6.395 | Acc: 30.469,40.625,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.391 | Acc: 31.324,41.927,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.353 | Acc: 32.146,43.159,52.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.354 | Acc: 32.018,43.046,52.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.333 | Acc: 32.243,43.210,52.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.308 | Acc: 32.650,43.789,53.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.305 | Acc: 32.716,43.769,53.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.316 | Acc: 32.729,43.744,53.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.317 | Acc: 32.783,43.842,53.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.330 | Acc: 32.769,43.694,53.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.346 | Acc: 32.591,43.602,53.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.362 | Acc: 32.374,43.421,52.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.359 | Acc: 32.287,43.455,52.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.361 | Acc: 32.375,43.499,52.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.362 | Acc: 32.309,43.466,52.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.359 | Acc: 32.418,43.467,52.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.352 | Acc: 32.474,43.497,52.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.348 | Acc: 32.629,43.551,52.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.342 | Acc: 32.691,43.640,52.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.347 | Acc: 32.702,43.551,52.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.750 | Acc: 20.312,32.031,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.828 | Acc: 19.940,33.036,39.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.923 | Acc: 19.798,32.069,38.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.927 | Acc: 19.736,31.711,38.512,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 6.205 | Acc: 32.031,42.188,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.238 | Acc: 31.287,44.122,54.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.224 | Acc: 32.508,43.483,54.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.253 | Acc: 32.825,43.737,53.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.245 | Acc: 33.092,44.088,54.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.238 | Acc: 33.277,44.137,54.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.254 | Acc: 33.181,44.215,53.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.244 | Acc: 33.306,44.276,54.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.234 | Acc: 33.332,44.308,54.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.244 | Acc: 33.283,44.294,54.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.254 | Acc: 33.236,44.248,53.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.256 | Acc: 33.071,44.234,53.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.253 | Acc: 33.146,44.272,53.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.253 | Acc: 33.211,44.271,53.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.255 | Acc: 33.113,44.253,53.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.257 | Acc: 33.171,44.230,53.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.252 | Acc: 33.226,44.212,53.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.253 | Acc: 33.268,44.270,53.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.255 | Acc: 33.243,44.308,53.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.261 | Acc: 33.210,44.228,53.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.440 | Acc: 32.812,45.312,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.521 | Acc: 25.893,37.165,45.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.550 | Acc: 26.162,36.643,45.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.538 | Acc: 26.345,36.668,45.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 6.719 | Acc: 29.688,43.750,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.000 | Acc: 33.743,47.619,55.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.066 | Acc: 33.708,46.284,55.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.080 | Acc: 33.901,46.465,55.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.087 | Acc: 34.057,46.335,55.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.086 | Acc: 34.097,46.504,55.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.092 | Acc: 34.110,46.501,55.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.102 | Acc: 33.871,46.155,55.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.095 | Acc: 33.914,46.036,55.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.102 | Acc: 33.999,45.977,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.105 | Acc: 34.060,45.919,55.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.115 | Acc: 33.993,45.793,55.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.121 | Acc: 33.963,45.825,54.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.126 | Acc: 33.932,45.705,54.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.126 | Acc: 33.913,45.782,55.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.135 | Acc: 33.814,45.738,54.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.141 | Acc: 33.896,45.724,54.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.144 | Acc: 33.857,45.658,54.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.148 | Acc: 33.808,45.568,54.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.152 | Acc: 33.807,45.534,54.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.549 | Acc: 28.906,32.031,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.420 | Acc: 26.079,35.342,47.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.364 | Acc: 26.448,35.842,47.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.375 | Acc: 26.486,35.809,47.041,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 5.947 | Acc: 32.031,46.875,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.095 | Acc: 32.738,45.908,56.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.946 | Acc: 34.032,47.447,57.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.960 | Acc: 33.517,46.913,56.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.978 | Acc: 33.565,46.943,56.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.010 | Acc: 33.594,46.434,55.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.016 | Acc: 33.510,46.462,55.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.031 | Acc: 33.472,46.343,55.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.025 | Acc: 33.536,46.399,55.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.038 | Acc: 33.559,46.301,55.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.043 | Acc: 33.524,46.319,55.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.050 | Acc: 33.569,46.232,55.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.061 | Acc: 33.542,46.123,55.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.072 | Acc: 33.549,46.133,55.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.075 | Acc: 33.577,46.147,55.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.083 | Acc: 33.615,46.044,55.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.069 | Acc: 33.713,46.284,55.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.061 | Acc: 33.834,46.309,55.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.070 | Acc: 33.765,46.250,55.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.069 | Acc: 33.825,46.254,55.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.137 | Acc: 25.781,40.625,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.733 | Acc: 24.628,37.240,46.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.828 | Acc: 24.219,36.414,45.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.896 | Acc: 24.180,36.130,45.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 6.134 | Acc: 30.469,43.750,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.868 | Acc: 34.896,48.214,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.937 | Acc: 35.194,47.961,56.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.954 | Acc: 35.169,47.528,56.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.967 | Acc: 34.944,46.981,56.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.998 | Acc: 34.321,46.751,56.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.998 | Acc: 34.401,46.772,55.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.010 | Acc: 34.469,46.598,55.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.037 | Acc: 34.467,46.302,55.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.030 | Acc: 34.267,46.361,55.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.020 | Acc: 34.293,46.409,55.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.021 | Acc: 34.205,46.444,55.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.024 | Acc: 34.145,46.548,55.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.024 | Acc: 34.130,46.486,55.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.020 | Acc: 34.211,46.475,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.022 | Acc: 34.134,46.457,55.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.026 | Acc: 34.005,46.427,55.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.026 | Acc: 34.098,46.362,55.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.028 | Acc: 34.083,46.384,55.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.026 | Acc: 34.135,46.442,55.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.725 | Acc: 32.031,46.094,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.888 | Acc: 29.204,40.327,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.906 | Acc: 28.144,40.454,50.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.908 | Acc: 28.381,40.356,50.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 6.360 | Acc: 28.906,43.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.945 | Acc: 34.598,46.391,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.981 | Acc: 34.184,46.151,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.942 | Acc: 34.746,46.785,57.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.936 | Acc: 34.722,46.788,56.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.919 | Acc: 34.708,47.061,56.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.897 | Acc: 34.924,47.424,57.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.910 | Acc: 34.990,47.412,56.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.914 | Acc: 35.088,47.283,56.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.919 | Acc: 34.850,47.134,56.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.927 | Acc: 34.779,47.058,56.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.928 | Acc: 34.679,47.052,56.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.920 | Acc: 34.741,47.134,56.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.903 | Acc: 35.040,47.366,56.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.906 | Acc: 35.101,47.409,56.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.908 | Acc: 35.115,47.428,56.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.923 | Acc: 35.032,47.374,56.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.928 | Acc: 35.042,47.381,56.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.938 | Acc: 34.983,47.308,56.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.944 | Acc: 34.918,47.306,56.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.291 | Acc: 28.906,39.062,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.277 | Acc: 26.786,38.914,48.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.262 | Acc: 26.982,38.662,48.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.258 | Acc: 26.908,39.203,48.143,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 5.326 | Acc: 32.031,53.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.762 | Acc: 35.789,48.698,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.745 | Acc: 35.499,48.571,59.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.745 | Acc: 35.361,48.783,59.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.751 | Acc: 35.301,48.978,59.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.796 | Acc: 34.955,48.468,58.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.808 | Acc: 34.898,48.651,58.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.808 | Acc: 34.984,48.487,58.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.812 | Acc: 34.899,48.588,57.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.820 | Acc: 34.828,48.554,57.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.846 | Acc: 34.783,48.294,57.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.858 | Acc: 34.690,48.190,57.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.868 | Acc: 34.751,48.172,57.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.871 | Acc: 34.947,48.240,57.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.877 | Acc: 34.873,48.115,57.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.874 | Acc: 34.860,48.144,57.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.875 | Acc: 34.871,48.148,57.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.877 | Acc: 34.797,48.133,57.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.883 | Acc: 34.784,48.096,57.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.890 | Acc: 34.722,48.031,57.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.425 | Acc: 30.469,43.750,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.397 | Acc: 25.298,38.728,48.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.353 | Acc: 25.038,38.529,48.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.327 | Acc: 25.013,38.256,48.335,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 5.631 | Acc: 38.281,49.219,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.682 | Acc: 37.054,50.409,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.705 | Acc: 36.452,49.924,58.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.737 | Acc: 36.360,49.193,58.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.736 | Acc: 36.159,49.122,58.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.764 | Acc: 35.837,49.080,58.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.764 | Acc: 36.060,49.096,58.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.752 | Acc: 36.093,49.169,58.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.749 | Acc: 36.064,49.204,58.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.760 | Acc: 35.933,49.214,58.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.760 | Acc: 35.934,49.071,58.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.782 | Acc: 35.817,48.950,58.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.787 | Acc: 35.746,48.878,58.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.782 | Acc: 35.677,48.886,58.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.792 | Acc: 35.640,48.813,57.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.796 | Acc: 35.662,48.848,57.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.802 | Acc: 35.602,48.786,57.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.804 | Acc: 35.626,48.827,57.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.799 | Acc: 35.615,48.795,57.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.801 | Acc: 35.583,48.725,57.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.683 | Acc: 30.469,43.750,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.813 | Acc: 30.320,42.225,50.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.824 | Acc: 29.916,41.921,50.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.853 | Acc: 29.956,41.790,49.962,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 5.974 | Acc: 36.719,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.729 | Acc: 36.235,50.893,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.718 | Acc: 36.452,50.171,59.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.704 | Acc: 36.642,49.910,58.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.700 | Acc: 36.275,49.865,59.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.723 | Acc: 35.783,49.466,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.767 | Acc: 35.324,49.128,58.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.771 | Acc: 35.250,49.197,58.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.770 | Acc: 35.331,49.180,58.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.757 | Acc: 35.424,49.366,58.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.758 | Acc: 35.409,49.413,58.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.760 | Acc: 35.421,49.342,58.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.761 | Acc: 35.425,49.316,58.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.741 | Acc: 35.644,49.428,58.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.751 | Acc: 35.604,49.341,58.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.751 | Acc: 35.572,49.273,58.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.751 | Acc: 35.619,49.306,58.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.755 | Acc: 35.585,49.281,58.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.755 | Acc: 35.570,49.264,58.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.752 | Acc: 35.593,49.284,58.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.751 | Acc: 21.094,28.906,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.649 | Acc: 17.708,31.399,44.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.745 | Acc: 17.416,31.193,43.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.763 | Acc: 16.970,31.199,42.956,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 5.357 | Acc: 40.625,48.438,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.594 | Acc: 35.417,50.595,60.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.643 | Acc: 35.880,50.191,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.670 | Acc: 35.809,50.307,59.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.686 | Acc: 35.629,50.482,59.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.695 | Acc: 35.504,50.325,59.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.697 | Acc: 35.492,50.239,59.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.703 | Acc: 35.450,50.050,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.698 | Acc: 35.622,50.116,59.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.687 | Acc: 35.769,50.181,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.688 | Acc: 35.568,50.218,59.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.683 | Acc: 35.637,50.177,59.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.678 | Acc: 35.662,50.243,59.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.678 | Acc: 35.713,50.227,59.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.683 | Acc: 35.654,50.153,59.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.694 | Acc: 35.559,49.992,59.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.693 | Acc: 35.548,49.959,59.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.700 | Acc: 35.534,49.883,59.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.705 | Acc: 35.574,49.922,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.706 | Acc: 35.599,49.881,58.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.829 | Acc: 29.688,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.540 | Acc: 32.478,44.420,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.558 | Acc: 31.421,43.960,53.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.589 | Acc: 31.301,43.635,52.894,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 6.621 | Acc: 24.219,40.625,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.578 | Acc: 35.863,51.190,61.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.557 | Acc: 36.109,51.067,60.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.550 | Acc: 36.168,50.973,60.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.561 | Acc: 36.333,50.810,60.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.552 | Acc: 36.672,50.866,60.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.563 | Acc: 36.486,50.730,60.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.574 | Acc: 36.564,50.803,60.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.587 | Acc: 36.355,50.699,60.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.580 | Acc: 36.365,50.717,60.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.588 | Acc: 36.287,50.688,60.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.599 | Acc: 36.174,50.463,59.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.617 | Acc: 36.116,50.292,59.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.622 | Acc: 36.027,50.204,59.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.623 | Acc: 36.051,50.156,59.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.619 | Acc: 36.132,50.366,59.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.625 | Acc: 36.149,50.299,59.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.637 | Acc: 36.052,50.103,59.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.652 | Acc: 35.953,49.916,59.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.660 | Acc: 35.899,49.863,59.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.816 | Acc: 26.562,45.312,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.770 | Acc: 29.836,44.643,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.742 | Acc: 29.535,43.826,51.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.787 | Acc: 29.098,43.263,50.589,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 5.621 | Acc: 33.594,54.688,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.604 | Acc: 36.421,50.409,61.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.627 | Acc: 37.252,50.724,59.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.612 | Acc: 36.911,50.499,60.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.588 | Acc: 36.941,50.511,60.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.597 | Acc: 36.889,50.387,60.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.612 | Acc: 36.428,50.136,60.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.598 | Acc: 36.320,50.377,60.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.593 | Acc: 36.389,50.592,60.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.588 | Acc: 36.412,50.639,60.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.592 | Acc: 36.377,50.591,60.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.580 | Acc: 36.439,50.686,60.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.585 | Acc: 36.427,50.678,60.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.593 | Acc: 36.437,50.682,60.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.598 | Acc: 36.430,50.653,59.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.595 | Acc: 36.446,50.763,60.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.591 | Acc: 36.439,50.796,60.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.596 | Acc: 36.371,50.882,60.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.598 | Acc: 36.431,50.898,59.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.604 | Acc: 36.284,50.833,59.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.783 | Acc: 35.156,44.531,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.844 | Acc: 29.985,43.304,50.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.840 | Acc: 29.611,43.102,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.820 | Acc: 29.419,42.841,51.050,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 5.656 | Acc: 35.156,54.688,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.565 | Acc: 37.016,50.223,60.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.533 | Acc: 36.700,50.838,60.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.497 | Acc: 36.578,51.627,61.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.487 | Acc: 37.047,51.572,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.510 | Acc: 36.812,51.454,60.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.519 | Acc: 36.628,51.233,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.523 | Acc: 36.530,51.274,60.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.521 | Acc: 36.597,51.228,60.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.533 | Acc: 36.386,51.092,60.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.539 | Acc: 36.396,51.096,60.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.530 | Acc: 36.482,51.230,60.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.541 | Acc: 36.492,51.096,60.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.563 | Acc: 36.360,51.009,60.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.562 | Acc: 36.299,50.915,60.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.565 | Acc: 36.319,50.888,60.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.560 | Acc: 36.332,50.981,60.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.565 | Acc: 36.283,50.912,60.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.564 | Acc: 36.316,50.887,60.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.559 | Acc: 36.464,50.992,60.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.583 | Acc: 34.375,48.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.890 | Acc: 29.353,43.006,49.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.854 | Acc: 29.992,42.492,48.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.837 | Acc: 30.379,42.713,49.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 5.713 | Acc: 28.906,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.606 | Acc: 34.784,51.562,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.519 | Acc: 35.880,51.867,60.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.493 | Acc: 36.680,51.883,60.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.481 | Acc: 36.748,52.122,61.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.469 | Acc: 36.812,52.235,61.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.465 | Acc: 37.016,52.247,61.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.455 | Acc: 37.262,52.366,61.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.451 | Acc: 37.374,52.470,61.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.445 | Acc: 37.465,52.417,61.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.454 | Acc: 37.399,52.344,61.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.465 | Acc: 37.182,52.248,61.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.472 | Acc: 37.059,52.084,61.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.468 | Acc: 37.063,52.056,61.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.471 | Acc: 36.983,52.060,61.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.473 | Acc: 36.945,52.074,61.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.486 | Acc: 36.860,51.903,61.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.493 | Acc: 36.845,51.771,60.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.498 | Acc: 36.814,51.640,60.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.497 | Acc: 36.815,51.657,60.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.371 | Acc: 30.469,44.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.596 | Acc: 29.836,44.196,53.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.611 | Acc: 29.383,44.112,52.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.635 | Acc: 29.982,43.955,52.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.563 | Acc: 39.062,49.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.431 | Acc: 36.644,51.488,62.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.396 | Acc: 36.795,52.229,62.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.372 | Acc: 36.988,52.779,62.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.389 | Acc: 37.162,52.797,62.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.414 | Acc: 37.082,52.614,61.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.422 | Acc: 37.106,52.305,61.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.419 | Acc: 37.007,52.371,61.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.451 | Acc: 36.743,52.028,61.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.441 | Acc: 36.887,52.197,61.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.444 | Acc: 36.886,52.266,61.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.446 | Acc: 36.853,52.372,61.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.458 | Acc: 36.826,52.253,61.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.462 | Acc: 36.776,52.185,61.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.472 | Acc: 36.719,52.082,61.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.480 | Acc: 36.615,52.006,61.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.483 | Acc: 36.590,51.932,61.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.481 | Acc: 36.636,51.922,61.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.482 | Acc: 36.660,51.902,61.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.481 | Acc: 36.610,51.921,61.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.083 | Acc: 30.469,42.969,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.444 | Acc: 27.827,38.393,47.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.511 | Acc: 28.106,38.205,47.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.567 | Acc: 27.523,37.871,47.592,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 5.425 | Acc: 33.594,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.454 | Acc: 36.384,52.121,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.380 | Acc: 36.604,51.963,62.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.358 | Acc: 36.642,52.318,62.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.389 | Acc: 36.815,52.267,61.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.399 | Acc: 37.020,52.344,61.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.421 | Acc: 36.983,52.105,61.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.430 | Acc: 36.957,52.144,61.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.407 | Acc: 37.131,52.329,61.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.424 | Acc: 36.939,52.132,61.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.424 | Acc: 36.921,52.134,61.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.422 | Acc: 36.864,52.135,61.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.420 | Acc: 36.936,52.143,61.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.419 | Acc: 36.961,52.173,61.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.425 | Acc: 36.913,52.163,61.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.433 | Acc: 36.843,52.115,61.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.427 | Acc: 36.867,52.205,61.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.428 | Acc: 36.897,52.289,61.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.435 | Acc: 36.868,52.290,61.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.440 | Acc: 36.827,52.186,61.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.165 | Acc: 30.469,42.188,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.791 | Acc: 28.981,43.787,52.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.848 | Acc: 28.887,43.045,52.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.860 | Acc: 28.970,43.058,52.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 5.240 | Acc: 37.500,53.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.419 | Acc: 36.533,52.418,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.332 | Acc: 37.367,53.335,63.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.345 | Acc: 36.821,52.959,63.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.304 | Acc: 37.722,53.520,63.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.332 | Acc: 37.585,53.411,62.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.304 | Acc: 37.797,53.738,62.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.301 | Acc: 37.827,53.707,63.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.307 | Acc: 37.859,53.605,62.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.320 | Acc: 37.703,53.440,62.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.317 | Acc: 37.663,53.459,62.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.331 | Acc: 37.613,53.390,62.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.337 | Acc: 37.730,53.345,62.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.350 | Acc: 37.614,53.224,62.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.360 | Acc: 37.492,53.119,62.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.364 | Acc: 37.492,53.133,62.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.369 | Acc: 37.412,53.045,62.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.378 | Acc: 37.296,52.887,62.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.380 | Acc: 37.249,52.885,61.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.387 | Acc: 37.213,52.834,61.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.300 | Acc: 27.344,42.969,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.530 | Acc: 29.501,44.568,53.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.554 | Acc: 29.002,44.550,53.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.561 | Acc: 29.047,44.275,53.343,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 5.467 | Acc: 32.031,47.656,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.228 | Acc: 38.504,54.427,63.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.259 | Acc: 37.519,53.659,63.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.278 | Acc: 37.602,53.560,63.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.294 | Acc: 37.703,53.463,63.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.308 | Acc: 37.709,53.287,63.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.310 | Acc: 37.771,53.474,62.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.314 | Acc: 37.744,53.585,63.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.321 | Acc: 37.597,53.465,63.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.321 | Acc: 37.746,53.406,63.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.318 | Acc: 37.772,53.401,62.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.316 | Acc: 37.889,53.447,62.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.317 | Acc: 37.704,53.401,62.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.324 | Acc: 37.784,53.400,62.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.330 | Acc: 37.764,53.350,62.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.342 | Acc: 37.599,53.260,62.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.344 | Acc: 37.573,53.164,62.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.345 | Acc: 37.587,53.155,62.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.347 | Acc: 37.576,53.106,62.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.347 | Acc: 37.521,53.098,62.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.708 | Acc: 27.344,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.994 | Acc: 28.832,42.560,50.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.931 | Acc: 28.792,42.797,50.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.943 | Acc: 28.740,42.418,50.717,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 5.385 | Acc: 37.500,53.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.395 | Acc: 35.938,52.344,62.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.325 | Acc: 36.566,52.572,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.282 | Acc: 36.898,52.766,63.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.278 | Acc: 37.259,53.164,63.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.287 | Acc: 37.345,52.994,63.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.316 | Acc: 37.306,52.847,63.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.306 | Acc: 37.345,53.186,63.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.293 | Acc: 37.461,53.295,63.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.293 | Acc: 37.586,53.397,63.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.288 | Acc: 37.554,53.467,63.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.287 | Acc: 37.557,53.443,63.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.284 | Acc: 37.575,53.439,63.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.292 | Acc: 37.581,53.314,62.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.300 | Acc: 37.531,53.220,62.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.309 | Acc: 37.497,53.224,62.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.311 | Acc: 37.515,53.169,62.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.312 | Acc: 37.541,53.194,62.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.320 | Acc: 37.491,53.196,62.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.316 | Acc: 37.562,53.242,62.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.531 | Acc: 22.656,44.531,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.538 | Acc: 25.335,41.183,50.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.568 | Acc: 25.152,40.949,50.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.596 | Acc: 24.898,40.920,49.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 5.080 | Acc: 42.188,56.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.260 | Acc: 36.979,53.906,63.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.185 | Acc: 37.538,53.963,64.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.246 | Acc: 37.513,53.701,63.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.279 | Acc: 37.143,53.019,63.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.302 | Acc: 36.982,52.754,62.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.306 | Acc: 37.042,52.679,62.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.303 | Acc: 37.101,52.787,63.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.296 | Acc: 37.131,52.839,63.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.288 | Acc: 37.332,53.047,63.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.281 | Acc: 37.356,53.160,63.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.274 | Acc: 37.433,53.337,63.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.282 | Acc: 37.484,53.290,63.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.298 | Acc: 37.332,53.227,63.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.305 | Acc: 37.408,53.161,63.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.307 | Acc: 37.492,53.091,63.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.304 | Acc: 37.522,53.130,63.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.302 | Acc: 37.530,53.132,62.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.303 | Acc: 37.526,53.168,62.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.306 | Acc: 37.467,53.148,62.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.057 | Acc: 31.250,44.531,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.956 | Acc: 30.543,42.894,52.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.938 | Acc: 31.002,42.416,52.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.954 | Acc: 30.648,42.559,52.062,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 5.094 | Acc: 39.062,55.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.036 | Acc: 37.835,55.097,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.105 | Acc: 38.434,54.440,65.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.127 | Acc: 38.384,54.918,65.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.156 | Acc: 38.233,55.015,64.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.181 | Acc: 38.366,54.865,64.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.182 | Acc: 38.159,54.681,64.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.200 | Acc: 38.132,54.538,64.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.208 | Acc: 38.247,54.498,63.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.200 | Acc: 38.299,54.437,63.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.211 | Acc: 38.130,54.384,63.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.227 | Acc: 38.034,54.338,63.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.238 | Acc: 37.931,54.224,63.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.254 | Acc: 37.877,54.065,63.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.258 | Acc: 37.864,54.015,63.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.259 | Acc: 37.933,53.974,63.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.261 | Acc: 37.972,53.960,63.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.268 | Acc: 37.922,53.909,63.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.278 | Acc: 37.864,53.846,62.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.274 | Acc: 37.853,53.820,62.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.801 | Acc: 18.750,42.188,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.790 | Acc: 20.275,40.216,50.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.807 | Acc: 19.893,39.348,50.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.818 | Acc: 19.877,39.524,50.384,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 4.973 | Acc: 47.656,56.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.162 | Acc: 38.988,53.720,65.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.202 | Acc: 37.881,54.325,64.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.216 | Acc: 37.974,54.252,64.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.213 | Acc: 37.934,54.437,64.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.195 | Acc: 37.871,54.525,64.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.201 | Acc: 38.184,54.584,64.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.196 | Acc: 38.370,54.560,64.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.193 | Acc: 38.330,54.576,63.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.193 | Acc: 38.428,54.614,63.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.212 | Acc: 38.246,54.380,63.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.221 | Acc: 38.136,54.345,63.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.218 | Acc: 37.954,54.341,63.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.215 | Acc: 38.039,54.331,63.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.215 | Acc: 38.048,54.321,63.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.225 | Acc: 37.991,54.119,63.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.222 | Acc: 38.031,54.142,63.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.224 | Acc: 38.025,54.193,63.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.228 | Acc: 37.931,54.101,63.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.225 | Acc: 37.980,54.097,63.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.161 | Acc: 24.219,42.188,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.231 | Acc: 25.930,41.778,53.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.282 | Acc: 25.953,40.987,51.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.282 | Acc: 25.871,41.368,51.562,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 5.526 | Acc: 38.281,51.562,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.220 | Acc: 38.132,54.315,63.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.060 | Acc: 38.910,55.564,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.078 | Acc: 38.550,55.225,65.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.087 | Acc: 38.609,55.257,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.080 | Acc: 38.769,55.291,65.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.101 | Acc: 38.656,54.894,65.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.101 | Acc: 38.531,54.904,64.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.099 | Acc: 38.645,54.959,64.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.125 | Acc: 38.609,54.692,64.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.130 | Acc: 38.639,54.618,64.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.144 | Acc: 38.437,54.557,64.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.165 | Acc: 38.220,54.454,64.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.181 | Acc: 38.179,54.280,64.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.186 | Acc: 38.106,54.257,64.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.185 | Acc: 38.126,54.316,64.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.191 | Acc: 38.116,54.283,64.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.193 | Acc: 38.112,54.222,64.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.194 | Acc: 38.134,54.237,64.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.197 | Acc: 38.029,54.204,63.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.120 | Acc: 26.562,41.406,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.221 | Acc: 26.674,40.662,50.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.268 | Acc: 26.658,40.111,50.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.344 | Acc: 26.601,39.626,50.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 4.745 | Acc: 36.719,59.375,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.027 | Acc: 38.430,55.990,64.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.997 | Acc: 38.910,56.612,65.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.001 | Acc: 39.011,56.429,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.033 | Acc: 38.966,56.096,65.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.036 | Acc: 38.900,56.281,64.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.044 | Acc: 38.830,56.069,64.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.058 | Acc: 38.725,55.834,64.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.075 | Acc: 38.383,55.784,64.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.090 | Acc: 38.316,55.555,64.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.107 | Acc: 38.293,55.282,64.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.113 | Acc: 38.257,55.278,64.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.129 | Acc: 38.165,55.209,64.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.144 | Acc: 38.051,55.041,64.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.148 | Acc: 38.059,55.007,64.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.158 | Acc: 38.081,54.970,64.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.165 | Acc: 38.077,54.902,64.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.169 | Acc: 38.098,54.850,63.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.172 | Acc: 38.154,54.817,63.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.172 | Acc: 38.175,54.874,63.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.897 | Acc: 41.406,51.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.314 | Acc: 32.999,47.842,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.339 | Acc: 32.889,47.523,54.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.358 | Acc: 32.339,47.323,54.636,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 4.656 | Acc: 43.750,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.195 | Acc: 37.054,54.501,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.076 | Acc: 37.576,55.507,65.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.069 | Acc: 37.705,55.379,65.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.107 | Acc: 37.876,54.996,65.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.094 | Acc: 38.459,55.113,65.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.104 | Acc: 38.552,54.939,65.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.092 | Acc: 38.857,54.953,65.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.101 | Acc: 38.684,54.906,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.112 | Acc: 38.760,54.873,64.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.112 | Acc: 38.825,54.792,64.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.116 | Acc: 38.723,54.769,64.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.119 | Acc: 38.729,54.668,64.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.120 | Acc: 38.736,54.702,64.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.124 | Acc: 38.709,54.746,64.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.133 | Acc: 38.702,54.695,64.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.142 | Acc: 38.629,54.680,64.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.138 | Acc: 38.652,54.752,64.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.135 | Acc: 38.697,54.809,64.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.139 | Acc: 38.626,54.815,64.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.467 | Acc: 27.344,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.530 | Acc: 28.534,44.978,56.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.503 | Acc: 28.678,45.217,56.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.495 | Acc: 28.650,44.992,56.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 4.389 | Acc: 40.625,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.985 | Acc: 39.062,56.138,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.977 | Acc: 39.291,56.421,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.003 | Acc: 39.139,56.173,66.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.017 | Acc: 39.091,56.038,66.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.032 | Acc: 38.730,55.902,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.034 | Acc: 39.043,55.940,65.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.044 | Acc: 39.090,55.862,65.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.065 | Acc: 38.781,55.653,65.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.080 | Acc: 38.786,55.628,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.091 | Acc: 38.790,55.438,64.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.090 | Acc: 38.964,55.462,64.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.105 | Acc: 38.810,55.359,64.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.107 | Acc: 38.787,55.388,64.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.107 | Acc: 38.809,55.321,64.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.118 | Acc: 38.761,55.196,64.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.118 | Acc: 38.717,55.264,64.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.122 | Acc: 38.625,55.153,64.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.127 | Acc: 38.615,55.185,64.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.131 | Acc: 38.560,55.143,64.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.539 | Acc: 23.438,42.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.501 | Acc: 30.692,44.234,55.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.559 | Acc: 30.755,43.921,54.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.568 | Acc: 30.123,44.314,54.214,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 4.815 | Acc: 46.094,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.054 | Acc: 38.653,55.060,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.994 | Acc: 39.196,56.174,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.958 | Acc: 39.498,56.596,66.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.975 | Acc: 39.593,56.588,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.011 | Acc: 38.931,56.142,65.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.033 | Acc: 38.849,55.947,65.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.026 | Acc: 39.040,55.873,65.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.037 | Acc: 38.733,55.828,65.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.045 | Acc: 38.640,55.641,65.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.050 | Acc: 38.635,55.616,65.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.055 | Acc: 38.543,55.557,65.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.077 | Acc: 38.460,55.307,64.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.082 | Acc: 38.461,55.337,64.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.092 | Acc: 38.434,55.182,64.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.099 | Acc: 38.372,55.129,64.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.108 | Acc: 38.386,55.050,64.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.115 | Acc: 38.254,55.040,64.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.112 | Acc: 38.333,55.172,64.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.118 | Acc: 38.341,55.155,64.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.314 | Acc: 26.562,38.281,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.491 | Acc: 26.116,38.802,50.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.474 | Acc: 25.629,38.529,49.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.494 | Acc: 25.628,38.422,49.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 5.009 | Acc: 39.062,53.906,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.895 | Acc: 39.881,57.887,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.993 | Acc: 39.501,57.431,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.023 | Acc: 38.947,57.082,67.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.017 | Acc: 39.101,56.848,66.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.052 | Acc: 38.660,56.258,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.062 | Acc: 38.572,56.127,66.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.053 | Acc: 38.664,56.111,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.035 | Acc: 38.922,56.163,66.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.033 | Acc: 38.972,56.142,66.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.048 | Acc: 38.814,56.021,66.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.056 | Acc: 38.886,56.010,65.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.056 | Acc: 38.894,55.974,65.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.059 | Acc: 38.916,55.951,65.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.063 | Acc: 38.901,55.936,65.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.071 | Acc: 38.728,55.879,65.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.079 | Acc: 38.651,55.768,65.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.091 | Acc: 38.707,55.748,65.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.098 | Acc: 38.573,55.627,65.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.095 | Acc: 38.593,55.643,65.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.482 | Acc: 29.688,50.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.506 | Acc: 30.394,47.061,55.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.498 | Acc: 30.259,46.665,55.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.474 | Acc: 30.482,46.888,55.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 4.958 | Acc: 39.062,56.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.922 | Acc: 39.732,56.622,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.991 | Acc: 39.425,55.812,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.049 | Acc: 38.922,55.315,65.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.020 | Acc: 38.735,55.478,65.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.010 | Acc: 38.645,55.739,65.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.017 | Acc: 38.849,55.804,65.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.022 | Acc: 38.896,55.879,65.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.020 | Acc: 39.194,55.964,65.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.016 | Acc: 39.132,55.969,65.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.022 | Acc: 38.923,55.920,65.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.025 | Acc: 38.939,55.826,65.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.036 | Acc: 38.917,55.757,65.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.045 | Acc: 38.916,55.687,65.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.049 | Acc: 38.818,55.663,65.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.060 | Acc: 38.748,55.658,65.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.067 | Acc: 38.712,55.583,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.069 | Acc: 38.694,55.567,65.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.066 | Acc: 38.705,55.640,65.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.072 | Acc: 38.708,55.631,65.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.379 | Acc: 33.594,47.656,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.556 | Acc: 28.757,45.685,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.541 | Acc: 29.268,45.389,55.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.542 | Acc: 28.765,45.210,55.840,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 5.535 | Acc: 32.812,50.000,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.971 | Acc: 38.802,56.287,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.945 | Acc: 38.567,56.650,66.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.962 | Acc: 38.384,56.199,66.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.975 | Acc: 38.474,56.240,66.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.982 | Acc: 38.923,56.265,66.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.976 | Acc: 39.030,56.360,66.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.972 | Acc: 39.301,56.555,66.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.970 | Acc: 39.392,56.546,66.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.980 | Acc: 39.175,56.556,66.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.991 | Acc: 39.249,56.510,66.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.991 | Acc: 39.186,56.490,66.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.998 | Acc: 39.241,56.470,66.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.007 | Acc: 39.030,56.367,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.011 | Acc: 39.124,56.375,65.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.024 | Acc: 39.039,56.258,65.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.035 | Acc: 38.921,56.136,65.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.038 | Acc: 38.975,56.147,65.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.042 | Acc: 38.980,56.081,65.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.039 | Acc: 39.044,56.131,65.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.140 | Acc: 31.250,44.531,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.591 | Acc: 28.051,39.881,50.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.507 | Acc: 27.915,39.958,50.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.541 | Acc: 27.421,39.498,50.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 4.460 | Acc: 42.188,57.812,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.995 | Acc: 37.240,56.696,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.946 | Acc: 38.872,57.012,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.944 | Acc: 38.422,56.673,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.961 | Acc: 38.349,56.655,66.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.980 | Acc: 38.235,56.451,66.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.993 | Acc: 38.191,56.521,66.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.989 | Acc: 38.132,56.438,66.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.996 | Acc: 38.301,56.289,66.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.986 | Acc: 38.601,56.414,66.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.982 | Acc: 38.619,56.518,66.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.994 | Acc: 38.525,56.314,66.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.998 | Acc: 38.498,56.240,66.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.012 | Acc: 38.473,56.127,66.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.013 | Acc: 38.618,56.236,66.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.018 | Acc: 38.554,56.172,65.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.013 | Acc: 38.658,56.209,65.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.011 | Acc: 38.719,56.184,65.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.021 | Acc: 38.638,56.118,65.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.029 | Acc: 38.579,56.051,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.702 | Acc: 27.344,43.750,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.332 | Acc: 28.274,46.987,57.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.414 | Acc: 27.954,46.475,56.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.488 | Acc: 27.536,45.786,55.815,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.796 | Acc: 39.062,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.987 | Acc: 38.504,56.250,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.934 | Acc: 39.367,57.127,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.911 | Acc: 39.882,57.415,67.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.906 | Acc: 39.651,57.485,67.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.910 | Acc: 39.782,57.449,67.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.924 | Acc: 39.831,57.361,67.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.942 | Acc: 39.744,57.175,67.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.963 | Acc: 39.655,56.900,66.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.967 | Acc: 39.740,56.846,66.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.971 | Acc: 39.684,56.744,66.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.985 | Acc: 39.462,56.621,66.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.984 | Acc: 39.510,56.668,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.981 | Acc: 39.529,56.720,66.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.988 | Acc: 39.488,56.706,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.994 | Acc: 39.447,56.543,66.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.997 | Acc: 39.406,56.535,66.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.997 | Acc: 39.422,56.546,66.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.996 | Acc: 39.433,56.527,66.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.005 | Acc: 39.325,56.461,66.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.159 | Acc: 32.812,53.125,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.386 | Acc: 27.790,47.433,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.453 | Acc: 27.553,46.913,57.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.439 | Acc: 27.920,47.515,57.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 5.062 | Acc: 37.500,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.917 | Acc: 38.988,57.366,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.870 | Acc: 40.130,57.470,67.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.884 | Acc: 39.908,57.620,67.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.884 | Acc: 39.998,57.311,67.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.870 | Acc: 40.091,57.372,67.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.882 | Acc: 39.966,57.380,67.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.914 | Acc: 39.733,56.998,67.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.915 | Acc: 39.562,57.080,67.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.918 | Acc: 39.447,57.061,67.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.924 | Acc: 39.424,57.078,66.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.934 | Acc: 39.335,56.989,66.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.952 | Acc: 39.234,56.788,66.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.945 | Acc: 39.296,56.938,66.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.945 | Acc: 39.288,56.965,66.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.947 | Acc: 39.262,57.003,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.963 | Acc: 39.170,56.878,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.972 | Acc: 39.062,56.825,66.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.981 | Acc: 39.060,56.730,66.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.985 | Acc: 39.071,56.703,66.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.191 | Acc: 29.688,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.301 | Acc: 31.027,48.810,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.292 | Acc: 31.498,48.171,55.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.318 | Acc: 31.314,48.156,55.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 4.689 | Acc: 39.844,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.870 | Acc: 39.583,58.147,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.848 | Acc: 39.615,58.003,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.845 | Acc: 39.600,57.608,68.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.882 | Acc: 39.651,57.378,68.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.869 | Acc: 39.952,57.418,68.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.867 | Acc: 40.025,57.193,68.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.880 | Acc: 39.738,57.153,67.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.884 | Acc: 39.577,57.167,67.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.895 | Acc: 39.520,57.131,67.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.902 | Acc: 39.482,57.012,67.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.907 | Acc: 39.515,56.929,67.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.918 | Acc: 39.533,56.856,67.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.915 | Acc: 39.589,56.909,67.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.932 | Acc: 39.591,56.839,67.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.931 | Acc: 39.592,56.883,67.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.935 | Acc: 39.581,56.822,67.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.939 | Acc: 39.596,56.820,66.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.940 | Acc: 39.487,56.785,66.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.951 | Acc: 39.512,56.697,66.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.230 | Acc: 40.625,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.589 | Acc: 30.990,44.792,53.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.629 | Acc: 29.897,45.065,53.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.607 | Acc: 30.033,45.479,53.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 4.500 | Acc: 47.656,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.789 | Acc: 41.406,58.110,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.799 | Acc: 40.606,57.736,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.875 | Acc: 40.023,57.364,67.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.892 | Acc: 39.786,57.311,67.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.890 | Acc: 39.759,57.186,67.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.894 | Acc: 39.740,57.244,67.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.889 | Acc: 39.999,57.558,67.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.906 | Acc: 39.912,57.371,67.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.920 | Acc: 39.801,57.113,66.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.931 | Acc: 39.735,57.132,66.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.936 | Acc: 39.557,57.137,66.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.939 | Acc: 39.464,57.154,66.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.933 | Acc: 39.476,57.223,66.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.940 | Acc: 39.399,57.120,66.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.943 | Acc: 39.408,57.018,66.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.940 | Acc: 39.452,56.975,66.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.951 | Acc: 39.335,56.869,66.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.949 | Acc: 39.355,56.854,66.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.958 | Acc: 39.358,56.763,66.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.229 | Acc: 27.344,38.281,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.351 | Acc: 28.943,40.104,50.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.345 | Acc: 28.506,39.444,50.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.390 | Acc: 28.291,38.998,50.384,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 4.964 | Acc: 40.625,54.688,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.960 | Acc: 38.207,55.543,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.855 | Acc: 38.815,56.441,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.832 | Acc: 38.909,57.082,68.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.819 | Acc: 39.371,57.504,68.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.818 | Acc: 39.380,57.449,68.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.817 | Acc: 39.514,57.645,68.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.845 | Acc: 39.495,57.508,68.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.847 | Acc: 39.611,57.706,67.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.858 | Acc: 39.580,57.618,67.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.846 | Acc: 39.809,57.778,67.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.854 | Acc: 39.773,57.678,67.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.853 | Acc: 39.737,57.650,67.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.872 | Acc: 39.565,57.543,67.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.878 | Acc: 39.560,57.568,67.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.889 | Acc: 39.499,57.454,67.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.890 | Acc: 39.561,57.438,67.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.900 | Acc: 39.550,57.439,67.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.911 | Acc: 39.448,57.323,66.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.911 | Acc: 39.378,57.298,66.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.470 | Acc: 28.906,39.062,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.568 | Acc: 28.274,39.100,50.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.621 | Acc: 27.344,38.338,50.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.603 | Acc: 27.113,38.435,49.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 4.878 | Acc: 40.625,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.816 | Acc: 40.923,57.887,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.836 | Acc: 40.720,57.450,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.813 | Acc: 40.420,57.262,67.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.816 | Acc: 40.336,57.330,68.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.818 | Acc: 40.130,57.596,68.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.845 | Acc: 39.902,57.335,67.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.866 | Acc: 39.772,57.087,67.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.861 | Acc: 39.839,57.109,67.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.868 | Acc: 39.714,57.195,67.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.877 | Acc: 39.614,57.358,67.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.878 | Acc: 39.473,57.480,67.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.882 | Acc: 39.403,57.492,67.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.890 | Acc: 39.338,57.435,67.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.885 | Acc: 39.457,57.409,67.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.901 | Acc: 39.286,57.241,66.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.909 | Acc: 39.187,57.219,66.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.910 | Acc: 39.202,57.219,66.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.920 | Acc: 39.240,57.129,66.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.923 | Acc: 39.290,57.085,66.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.029 | Acc: 26.562,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.454 | Acc: 30.060,47.433,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.532 | Acc: 29.345,46.341,54.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.535 | Acc: 29.175,46.286,54.585,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.896 | Acc: 47.656,61.719,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.841 | Acc: 40.439,57.589,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.798 | Acc: 39.863,58.098,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.808 | Acc: 39.690,57.992,68.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.813 | Acc: 39.767,58.005,68.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.812 | Acc: 39.720,57.913,68.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.814 | Acc: 39.592,58.064,68.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.819 | Acc: 39.694,57.984,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.838 | Acc: 39.679,57.953,68.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.866 | Acc: 39.732,57.769,67.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.874 | Acc: 39.700,57.715,67.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.876 | Acc: 39.872,57.767,67.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.877 | Acc: 39.857,57.738,67.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.880 | Acc: 39.778,57.654,67.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.877 | Acc: 39.766,57.629,67.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.878 | Acc: 39.794,57.714,67.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.885 | Acc: 39.717,57.676,67.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.890 | Acc: 39.745,57.620,67.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.891 | Acc: 39.729,57.544,67.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.895 | Acc: 39.674,57.489,67.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.650 | Acc: 32.031,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.824 | Acc: 27.195,46.429,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.858 | Acc: 26.982,46.151,56.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.885 | Acc: 26.665,46.363,56.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 4.563 | Acc: 39.062,61.719,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.729 | Acc: 40.327,59.859,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.693 | Acc: 40.511,59.089,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.714 | Acc: 40.356,58.747,68.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.751 | Acc: 39.988,58.073,68.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.752 | Acc: 40.068,58.168,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.781 | Acc: 39.831,57.980,68.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.778 | Acc: 40.137,58.056,68.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.794 | Acc: 40.014,57.910,68.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.821 | Acc: 39.662,57.808,67.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.814 | Acc: 39.758,57.941,67.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.819 | Acc: 39.886,57.975,67.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.818 | Acc: 39.915,57.968,67.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.826 | Acc: 39.940,57.878,67.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.829 | Acc: 39.891,57.851,67.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.839 | Acc: 39.722,57.662,67.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.849 | Acc: 39.771,57.508,67.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.856 | Acc: 39.743,57.473,67.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.868 | Acc: 39.666,57.432,67.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.873 | Acc: 39.661,57.429,67.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.341 | Acc: 36.719,49.219,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.100 | Acc: 31.585,50.446,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.148 | Acc: 30.888,50.000,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.179 | Acc: 30.853,49.859,56.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 5.330 | Acc: 31.250,53.125,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.813 | Acc: 41.034,57.031,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.807 | Acc: 40.358,57.946,68.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.851 | Acc: 39.498,57.812,68.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.877 | Acc: 39.487,57.591,67.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.870 | Acc: 39.844,57.557,67.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.880 | Acc: 39.740,57.451,67.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.860 | Acc: 39.838,57.613,67.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.848 | Acc: 40.018,57.672,67.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.856 | Acc: 39.857,57.502,67.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.863 | Acc: 39.774,57.432,67.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.865 | Acc: 39.720,57.427,67.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.856 | Acc: 39.795,57.466,67.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.855 | Acc: 39.805,57.513,67.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.861 | Acc: 39.669,57.426,67.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.860 | Acc: 39.719,57.470,67.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.865 | Acc: 39.727,57.467,67.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.868 | Acc: 39.706,57.542,67.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.873 | Acc: 39.675,57.529,67.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.869 | Acc: 39.743,57.534,67.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.888 | Acc: 21.875,45.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.997 | Acc: 25.186,45.908,52.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.997 | Acc: 25.534,45.560,51.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.006 | Acc: 25.589,45.658,51.434,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 4.857 | Acc: 39.844,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.747 | Acc: 40.588,58.371,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.750 | Acc: 40.816,58.136,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.743 | Acc: 40.663,58.030,68.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.771 | Acc: 40.567,58.083,68.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.802 | Acc: 40.292,58.153,68.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.811 | Acc: 40.412,58.142,68.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.820 | Acc: 40.304,58.117,68.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.815 | Acc: 40.048,58.167,68.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.825 | Acc: 39.913,57.972,68.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.835 | Acc: 39.809,57.914,68.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.834 | Acc: 39.879,57.979,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.843 | Acc: 39.717,57.936,68.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.841 | Acc: 39.745,57.908,68.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.834 | Acc: 39.858,57.999,68.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.833 | Acc: 39.880,58.031,68.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.832 | Acc: 39.948,58.088,68.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.838 | Acc: 39.862,57.977,68.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.840 | Acc: 39.829,58.018,68.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.841 | Acc: 39.833,58.065,68.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.437 | Acc: 32.031,40.625,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.062 | Acc: 31.585,39.955,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.142 | Acc: 30.755,39.806,51.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.115 | Acc: 30.507,40.087,51.755,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 4.847 | Acc: 38.281,56.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.620 | Acc: 41.518,59.933,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.751 | Acc: 39.882,58.403,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.719 | Acc: 40.804,58.696,69.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.761 | Acc: 40.143,58.382,68.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.768 | Acc: 40.099,58.323,68.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.774 | Acc: 39.960,58.161,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.782 | Acc: 39.838,58.162,68.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.796 | Acc: 39.795,58.104,68.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.797 | Acc: 39.826,58.175,68.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.800 | Acc: 39.824,58.123,68.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.805 | Acc: 39.808,58.170,68.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.807 | Acc: 39.899,58.117,68.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.810 | Acc: 39.853,58.136,68.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.815 | Acc: 39.794,58.085,68.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.819 | Acc: 39.745,58.012,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.817 | Acc: 39.839,58.019,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.814 | Acc: 39.961,58.076,67.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.819 | Acc: 39.961,58.025,67.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.820 | Acc: 39.971,57.999,67.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.039 | Acc: 19.531,39.844,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.854 | Acc: 24.033,41.220,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.802 | Acc: 24.447,41.273,47.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.775 | Acc: 24.308,41.406,48.207,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 4.748 | Acc: 39.844,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.627 | Acc: 41.778,60.751,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 41.197,60.213,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.672 | Acc: 40.971,59.362,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.696 | Acc: 40.779,59.028,70.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.716 | Acc: 40.780,58.772,69.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.737 | Acc: 40.567,58.775,69.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.756 | Acc: 40.509,58.666,69.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.750 | Acc: 40.402,58.817,69.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.759 | Acc: 40.275,58.611,69.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.778 | Acc: 40.085,58.368,68.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.790 | Acc: 39.992,58.159,68.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.792 | Acc: 40.016,58.240,68.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.798 | Acc: 40.035,58.229,68.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.799 | Acc: 40.113,58.316,68.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.806 | Acc: 40.028,58.238,68.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.812 | Acc: 39.968,58.226,68.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.817 | Acc: 40.002,58.181,68.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.815 | Acc: 40.049,58.144,68.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.819 | Acc: 40.028,58.048,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.288 | Acc: 35.156,46.875,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.211 | Acc: 33.371,48.251,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.245 | Acc: 32.374,48.133,55.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.241 | Acc: 32.185,48.502,56.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.646 | Acc: 41.406,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.689 | Acc: 40.327,59.784,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.654 | Acc: 41.006,60.023,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.699 | Acc: 41.022,59.196,70.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.693 | Acc: 41.011,59.336,69.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.692 | Acc: 40.919,59.197,70.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.715 | Acc: 40.857,58.891,69.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.722 | Acc: 40.758,58.854,69.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.724 | Acc: 40.644,58.822,69.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.722 | Acc: 40.685,58.987,69.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.728 | Acc: 40.590,59.033,69.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.734 | Acc: 40.636,58.944,69.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.741 | Acc: 40.560,58.814,68.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.756 | Acc: 40.454,58.648,68.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.765 | Acc: 40.444,58.588,68.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.772 | Acc: 40.386,58.607,68.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.771 | Acc: 40.394,58.594,68.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.774 | Acc: 40.364,58.555,68.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.781 | Acc: 40.216,58.462,68.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.788 | Acc: 40.155,58.424,68.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.841 | Acc: 33.594,44.531,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.121 | Acc: 27.418,41.778,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.089 | Acc: 26.982,42.264,52.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.098 | Acc: 27.421,42.303,52.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 4.837 | Acc: 39.062,48.438,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.620 | Acc: 41.146,59.003,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 40.663,59.794,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.669 | Acc: 40.407,59.337,70.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.675 | Acc: 40.731,59.327,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.683 | Acc: 40.555,59.228,70.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.719 | Acc: 40.263,58.929,69.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.736 | Acc: 40.082,58.860,69.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.762 | Acc: 39.917,58.730,69.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.751 | Acc: 39.991,58.848,69.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.758 | Acc: 39.875,58.745,68.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.769 | Acc: 39.755,58.668,68.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.780 | Acc: 39.730,58.623,68.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.775 | Acc: 39.856,58.785,68.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.776 | Acc: 39.791,58.736,68.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.776 | Acc: 39.841,58.760,68.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.775 | Acc: 39.914,58.730,68.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.776 | Acc: 39.938,58.649,68.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.785 | Acc: 39.950,58.520,68.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.795 | Acc: 40.010,58.454,68.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.780 | Acc: 25.781,44.531,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.172 | Acc: 25.856,43.266,54.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.211 | Acc: 25.629,42.988,54.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.264 | Acc: 25.282,42.520,53.215,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 4.060 | Acc: 38.281,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 40.997,60.491,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 40.644,60.042,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.638 | Acc: 40.407,59.926,70.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.665 | Acc: 40.461,59.655,70.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.705 | Acc: 40.331,59.151,69.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.725 | Acc: 40.154,58.871,69.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.719 | Acc: 40.326,58.865,69.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.705 | Acc: 40.455,58.958,69.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.697 | Acc: 40.491,59.077,69.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.709 | Acc: 40.267,58.986,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.717 | Acc: 40.385,58.940,69.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.720 | Acc: 40.379,58.840,69.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.731 | Acc: 40.430,58.737,69.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.739 | Acc: 40.383,58.747,68.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.745 | Acc: 40.371,58.679,68.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.752 | Acc: 40.323,58.616,68.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.760 | Acc: 40.341,58.575,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.766 | Acc: 40.313,58.466,68.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.771 | Acc: 40.225,58.409,68.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.276 | Acc: 30.469,50.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.425 | Acc: 30.394,46.466,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.378 | Acc: 30.793,47.123,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.431 | Acc: 30.418,46.901,54.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 4.941 | Acc: 37.500,54.688,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.732 | Acc: 39.993,58.073,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.684 | Acc: 39.939,58.498,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.700 | Acc: 40.138,58.478,69.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.693 | Acc: 40.355,58.652,69.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.698 | Acc: 40.610,58.888,69.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.713 | Acc: 40.664,58.671,69.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.709 | Acc: 40.642,58.810,69.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.732 | Acc: 40.387,58.555,69.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.728 | Acc: 40.508,58.650,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.726 | Acc: 40.516,58.691,69.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.727 | Acc: 40.533,58.756,69.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.739 | Acc: 40.320,58.584,68.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.755 | Acc: 40.224,58.414,68.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.758 | Acc: 40.308,58.377,68.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.767 | Acc: 40.306,58.277,68.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.778 | Acc: 40.146,58.294,68.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.782 | Acc: 40.148,58.349,68.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.785 | Acc: 40.136,58.377,68.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.782 | Acc: 40.137,58.430,68.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.382 | Acc: 28.906,43.750,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.425 | Acc: 29.278,46.243,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.547 | Acc: 28.830,45.141,56.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.559 | Acc: 28.778,44.762,56.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 4.317 | Acc: 50.781,64.062,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.726 | Acc: 40.625,59.152,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.687 | Acc: 40.911,59.566,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.688 | Acc: 40.599,59.529,70.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.687 | Acc: 40.519,59.520,70.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.679 | Acc: 40.958,59.390,70.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.698 | Acc: 40.580,59.007,69.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.687 | Acc: 40.514,59.109,69.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.698 | Acc: 40.504,59.137,69.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.700 | Acc: 40.547,59.250,69.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.709 | Acc: 40.438,59.204,69.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.702 | Acc: 40.561,59.269,69.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.709 | Acc: 40.528,59.252,69.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.709 | Acc: 40.556,59.213,69.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.729 | Acc: 40.330,59.033,69.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.727 | Acc: 40.342,59.064,69.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.724 | Acc: 40.399,59.119,69.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.727 | Acc: 40.355,59.061,69.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.727 | Acc: 40.374,59.091,69.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.731 | Acc: 40.317,59.033,69.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.376 | Acc: 32.031,42.188,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.539 | Acc: 29.390,41.295,50.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.490 | Acc: 29.249,41.692,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.480 | Acc: 29.111,41.470,50.999,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 4.534 | Acc: 48.438,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.620 | Acc: 40.402,58.445,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 41.711,59.756,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.581 | Acc: 41.073,59.874,70.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.615 | Acc: 40.799,59.664,70.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.632 | Acc: 40.509,59.530,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.640 | Acc: 40.651,59.194,70.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.669 | Acc: 40.370,58.932,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.668 | Acc: 40.504,58.972,69.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.665 | Acc: 40.340,59.090,69.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.674 | Acc: 40.372,59.033,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.690 | Acc: 40.243,58.951,69.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.695 | Acc: 40.288,58.996,69.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.703 | Acc: 40.245,58.968,69.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.713 | Acc: 40.227,58.930,69.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.716 | Acc: 40.236,58.874,69.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.728 | Acc: 40.102,58.891,68.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.737 | Acc: 40.098,58.784,68.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.742 | Acc: 40.088,58.737,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.746 | Acc: 40.051,58.715,68.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.282 | Acc: 21.875,39.844,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.323 | Acc: 24.628,42.597,51.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.357 | Acc: 24.371,42.283,50.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.337 | Acc: 24.270,42.725,50.807,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 4.088 | Acc: 39.844,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 41.369,61.086,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 40.968,59.928,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 40.881,59.029,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.658 | Acc: 40.934,59.336,69.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.662 | Acc: 40.664,59.166,69.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.686 | Acc: 40.425,59.136,69.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.697 | Acc: 40.442,59.131,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.700 | Acc: 40.543,59.336,69.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.705 | Acc: 40.629,59.280,69.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.710 | Acc: 40.606,59.348,69.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.711 | Acc: 40.583,59.375,69.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.709 | Acc: 40.674,59.430,69.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.708 | Acc: 40.688,59.474,69.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.707 | Acc: 40.686,59.372,69.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.718 | Acc: 40.617,59.320,69.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.721 | Acc: 40.496,59.312,68.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.718 | Acc: 40.504,59.306,68.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.726 | Acc: 40.428,59.228,68.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.733 | Acc: 40.412,59.154,68.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.983 | Acc: 32.812,47.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.109 | Acc: 28.385,42.113,52.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.067 | Acc: 28.201,43.102,52.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.085 | Acc: 28.394,43.353,53.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 5.111 | Acc: 35.938,49.219,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.678 | Acc: 40.923,59.263,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.630 | Acc: 40.339,59.966,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 40.843,60.169,70.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.631 | Acc: 40.721,59.905,70.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.647 | Acc: 40.254,59.723,70.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.638 | Acc: 40.438,59.833,70.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.667 | Acc: 40.403,59.674,69.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.687 | Acc: 40.314,59.540,69.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.691 | Acc: 40.202,59.453,69.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.701 | Acc: 40.194,59.293,69.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.720 | Acc: 40.187,59.089,69.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.727 | Acc: 40.191,59.109,69.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.728 | Acc: 40.287,59.136,69.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.725 | Acc: 40.236,59.091,69.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.724 | Acc: 40.280,59.032,69.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.720 | Acc: 40.316,59.063,69.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.719 | Acc: 40.339,59.091,69.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.717 | Acc: 40.300,59.139,69.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.726 | Acc: 40.203,59.037,69.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.855 | Acc: 35.938,53.125,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.210 | Acc: 30.246,47.656,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.280 | Acc: 29.935,47.447,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.315 | Acc: 30.085,47.246,58.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.522 | Acc: 40.625,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.786 | Acc: 39.137,57.999,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.732 | Acc: 40.511,59.394,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.679 | Acc: 40.625,59.273,70.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.678 | Acc: 40.210,59.520,70.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.669 | Acc: 40.114,59.514,70.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.661 | Acc: 40.096,59.459,70.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.651 | Acc: 40.287,59.525,70.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.660 | Acc: 40.373,59.443,70.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.671 | Acc: 40.344,59.379,70.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.697 | Acc: 40.248,59.188,69.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.714 | Acc: 40.346,59.043,69.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.705 | Acc: 40.353,59.112,69.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.710 | Acc: 40.604,59.153,69.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.719 | Acc: 40.536,59.128,69.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.722 | Acc: 40.521,59.115,69.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.730 | Acc: 40.494,58.995,69.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.731 | Acc: 40.529,58.997,69.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.722 | Acc: 40.554,59.102,69.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.726 | Acc: 40.561,59.092,69.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.705 | Acc: 25.781,40.625,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.593 | Acc: 24.591,43.601,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.595 | Acc: 24.085,43.617,52.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.585 | Acc: 24.411,43.558,52.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.812 | Acc: 42.188,54.688,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.709 | Acc: 38.653,59.412,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.676 | Acc: 39.520,59.413,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.648 | Acc: 40.241,59.362,70.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.609 | Acc: 40.741,60.311,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.622 | Acc: 40.780,59.978,70.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.612 | Acc: 40.567,60.150,70.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.637 | Acc: 40.481,59.929,70.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.643 | Acc: 40.615,59.700,69.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.651 | Acc: 40.586,59.487,69.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.649 | Acc: 40.648,59.495,69.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.647 | Acc: 40.618,59.495,69.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.651 | Acc: 40.654,59.466,69.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.660 | Acc: 40.619,59.468,69.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.669 | Acc: 40.606,59.406,69.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.669 | Acc: 40.558,59.424,69.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.677 | Acc: 40.552,59.360,69.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.685 | Acc: 40.446,59.309,69.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.696 | Acc: 40.335,59.221,69.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.702 | Acc: 40.332,59.180,69.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.941 | Acc: 35.156,40.625,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.964 | Acc: 30.283,42.522,52.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.020 | Acc: 30.545,42.416,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.044 | Acc: 30.546,42.610,52.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 4.763 | Acc: 39.062,55.469,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 40.588,60.826,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 40.339,60.042,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.570 | Acc: 40.330,60.284,71.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.582 | Acc: 40.673,60.098,70.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.577 | Acc: 40.981,60.241,70.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.591 | Acc: 41.193,60.221,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.612 | Acc: 40.941,59.946,70.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.615 | Acc: 40.955,59.957,70.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.621 | Acc: 41.156,59.867,70.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.626 | Acc: 41.196,59.888,70.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.634 | Acc: 41.049,59.757,70.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.633 | Acc: 41.082,59.855,70.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.634 | Acc: 40.957,59.830,70.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.642 | Acc: 40.950,59.742,69.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.653 | Acc: 40.882,59.653,69.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.667 | Acc: 40.842,59.497,69.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.677 | Acc: 40.707,59.366,69.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.680 | Acc: 40.666,59.280,69.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.687 | Acc: 40.600,59.203,69.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.131 | Acc: 28.125,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.957 | Acc: 28.162,45.015,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.932 | Acc: 28.258,45.370,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.950 | Acc: 28.279,45.389,55.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 4.505 | Acc: 43.750,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.662 | Acc: 39.769,61.235,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.564 | Acc: 40.701,61.909,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.617 | Acc: 39.921,60.809,70.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.593 | Acc: 39.979,60.938,70.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.628 | Acc: 39.828,60.319,70.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.615 | Acc: 40.025,60.447,70.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.615 | Acc: 40.187,60.322,70.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.631 | Acc: 40.203,60.268,70.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.648 | Acc: 40.370,60.066,70.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.659 | Acc: 40.267,59.942,69.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.666 | Acc: 40.275,59.774,69.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.677 | Acc: 40.187,59.738,69.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.670 | Acc: 40.278,59.749,69.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.669 | Acc: 40.239,59.650,69.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.668 | Acc: 40.285,59.627,69.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.669 | Acc: 40.447,59.567,69.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.666 | Acc: 40.476,59.675,69.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.668 | Acc: 40.452,59.671,69.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.667 | Acc: 40.481,59.685,69.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.249 | Acc: 30.469,45.312,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.456 | Acc: 31.176,47.061,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.467 | Acc: 30.488,46.970,52.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.501 | Acc: 30.315,46.926,52.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.305 | Acc: 42.969,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.659 | Acc: 40.811,58.185,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.662 | Acc: 40.796,58.689,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.640 | Acc: 41.137,59.144,70.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.620 | Acc: 41.618,59.394,70.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.624 | Acc: 41.337,59.460,70.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.634 | Acc: 40.948,59.433,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.659 | Acc: 40.747,59.253,70.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.664 | Acc: 40.678,59.205,70.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.662 | Acc: 40.785,59.388,70.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.654 | Acc: 40.784,59.461,70.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.663 | Acc: 40.671,59.396,70.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.667 | Acc: 40.680,59.385,70.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.678 | Acc: 40.640,59.279,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.666 | Acc: 40.708,59.378,69.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.665 | Acc: 40.661,59.419,69.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.664 | Acc: 40.664,59.485,69.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.671 | Acc: 40.643,59.425,69.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.673 | Acc: 40.599,59.390,69.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.664 | Acc: 40.615,59.488,69.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.866 | Acc: 39.844,48.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.203 | Acc: 33.743,49.740,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.250 | Acc: 32.965,48.704,56.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.282 | Acc: 32.697,48.527,56.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.983 | Acc: 35.156,53.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.522 | Acc: 41.183,59.970,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 40.835,60.499,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 40.587,60.784,71.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.570 | Acc: 40.847,60.957,70.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.585 | Acc: 40.741,60.651,70.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.611 | Acc: 40.438,60.337,70.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.623 | Acc: 40.498,60.228,70.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.612 | Acc: 40.683,60.282,70.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.616 | Acc: 40.569,60.096,70.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.616 | Acc: 40.777,59.981,70.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.610 | Acc: 40.841,59.990,70.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.613 | Acc: 40.907,60.001,70.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.620 | Acc: 40.835,59.854,70.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.613 | Acc: 40.800,59.939,70.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.618 | Acc: 40.799,59.871,69.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.622 | Acc: 40.769,59.835,69.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.632 | Acc: 40.685,59.714,69.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.646 | Acc: 40.510,59.594,69.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.653 | Acc: 40.582,59.551,69.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.733 | Acc: 38.281,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.974 | Acc: 34.635,48.735,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.028 | Acc: 34.604,48.876,56.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.064 | Acc: 34.606,48.450,56.148,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 4.894 | Acc: 36.719,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 40.402,59.970,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.579 | Acc: 40.072,59.699,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.587 | Acc: 40.177,59.465,70.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.613 | Acc: 40.451,59.192,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.622 | Acc: 40.377,59.437,70.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.611 | Acc: 40.722,59.498,70.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.597 | Acc: 40.985,59.652,70.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.591 | Acc: 41.091,59.894,70.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.586 | Acc: 41.061,60.022,70.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.593 | Acc: 40.994,59.946,70.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.592 | Acc: 41.088,59.997,70.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.599 | Acc: 41.102,59.871,70.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.610 | Acc: 41.080,59.737,70.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.626 | Acc: 41.017,59.545,70.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.631 | Acc: 40.942,59.487,70.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.643 | Acc: 40.905,59.438,70.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.650 | Acc: 40.987,59.364,70.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.660 | Acc: 40.872,59.282,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.659 | Acc: 40.820,59.258,69.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.679 | Acc: 28.125,58.594,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.009 | Acc: 33.668,51.302,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.978 | Acc: 33.384,50.229,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.988 | Acc: 33.504,50.717,58.222,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 3.909 | Acc: 43.750,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.473 | Acc: 41.629,61.198,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 41.044,60.385,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.567 | Acc: 41.124,60.284,71.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.521 | Acc: 42.207,60.783,71.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.513 | Acc: 42.311,60.636,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.507 | Acc: 42.510,60.776,71.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.494 | Acc: 42.420,61.004,71.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.523 | Acc: 42.217,60.598,71.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.546 | Acc: 41.946,60.372,71.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.559 | Acc: 41.950,60.354,71.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.581 | Acc: 41.579,60.153,70.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.585 | Acc: 41.510,60.117,70.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.603 | Acc: 41.385,59.923,70.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.608 | Acc: 41.359,59.948,70.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.627 | Acc: 41.167,59.736,70.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.634 | Acc: 41.073,59.648,70.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.631 | Acc: 41.040,59.627,70.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.631 | Acc: 41.045,59.539,70.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.633 | Acc: 41.015,59.478,70.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.400 | Acc: 32.031,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.210 | Acc: 33.371,47.917,56.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.160 | Acc: 32.984,47.999,57.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.178 | Acc: 32.889,48.309,57.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 5.201 | Acc: 35.156,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 41.890,61.161,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.537 | Acc: 41.902,61.261,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.522 | Acc: 41.637,61.437,71.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.534 | Acc: 41.705,61.101,71.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.574 | Acc: 41.646,60.767,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.589 | Acc: 41.587,60.492,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.596 | Acc: 41.401,60.483,70.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.599 | Acc: 41.348,60.379,70.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.602 | Acc: 41.475,60.411,70.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.599 | Acc: 41.332,60.319,70.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.614 | Acc: 41.265,60.132,70.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.610 | Acc: 41.367,60.211,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.607 | Acc: 41.313,60.183,70.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.600 | Acc: 41.376,60.256,70.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.614 | Acc: 41.305,60.117,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.613 | Acc: 41.304,60.115,70.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.624 | Acc: 41.200,60.014,70.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.629 | Acc: 41.153,59.959,70.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.635 | Acc: 41.099,59.931,69.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.135 | Acc: 31.250,42.969,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.868 | Acc: 32.775,41.146,53.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.863 | Acc: 32.660,41.082,53.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.909 | Acc: 32.531,41.201,53.266,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 4.684 | Acc: 46.875,57.812,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.599 | Acc: 40.848,60.789,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 40.568,60.309,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 41.099,60.207,71.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.561 | Acc: 40.818,60.282,71.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.561 | Acc: 40.996,60.187,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.565 | Acc: 41.038,60.427,71.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.590 | Acc: 40.908,60.212,70.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.603 | Acc: 40.882,59.986,70.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.589 | Acc: 40.949,60.079,70.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.584 | Acc: 40.990,60.102,70.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.587 | Acc: 40.964,60.114,70.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.590 | Acc: 40.868,59.936,70.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.603 | Acc: 40.867,59.812,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.605 | Acc: 40.822,59.770,70.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.605 | Acc: 40.859,59.777,70.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.612 | Acc: 40.873,59.750,70.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.615 | Acc: 40.923,59.794,70.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.620 | Acc: 40.828,59.771,70.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.623 | Acc: 40.801,59.732,70.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.371 | Acc: 29.688,47.656,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.621 | Acc: 28.869,48.140,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.644 | Acc: 28.887,46.894,56.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.652 | Acc: 28.881,46.593,56.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.587 | Acc: 40.625,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.414 | Acc: 42.708,62.574,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.488 | Acc: 42.207,61.719,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.508 | Acc: 41.803,61.283,71.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.496 | Acc: 41.937,61.294,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.496 | Acc: 41.901,61.262,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.495 | Acc: 42.207,61.235,72.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.493 | Acc: 42.104,61.109,71.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.505 | Acc: 41.916,60.933,71.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.517 | Acc: 41.877,60.821,71.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.535 | Acc: 41.671,60.801,71.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.558 | Acc: 41.456,60.467,71.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.569 | Acc: 41.387,60.451,71.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.571 | Acc: 41.334,60.390,71.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.581 | Acc: 41.303,60.384,70.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.587 | Acc: 41.238,60.255,70.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.592 | Acc: 41.253,60.220,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.594 | Acc: 41.239,60.186,70.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.599 | Acc: 41.224,60.130,70.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.604 | Acc: 41.214,60.087,70.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.062 | Acc: 35.938,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.395 | Acc: 33.519,48.400,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.379 | Acc: 33.365,47.409,56.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.379 | Acc: 33.197,47.810,56.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 4.317 | Acc: 43.750,63.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.571 | Acc: 41.629,60.491,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.563 | Acc: 41.502,60.499,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 41.048,60.131,70.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.573 | Acc: 40.789,60.282,70.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.549 | Acc: 40.826,60.558,71.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.553 | Acc: 40.748,60.569,71.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.560 | Acc: 40.891,60.550,71.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.577 | Acc: 40.707,60.462,71.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.577 | Acc: 40.815,60.420,70.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.572 | Acc: 40.936,60.467,70.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.582 | Acc: 40.954,60.361,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.573 | Acc: 41.056,60.399,70.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.579 | Acc: 41.002,60.273,70.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.582 | Acc: 41.070,60.337,70.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.596 | Acc: 40.968,60.232,70.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.600 | Acc: 41.000,60.154,70.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.604 | Acc: 40.918,60.129,70.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.609 | Acc: 40.950,60.128,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.615 | Acc: 40.924,60.058,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.099 | Acc: 38.281,53.906,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.066 | Acc: 35.677,49.516,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.072 | Acc: 35.080,49.771,57.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.080 | Acc: 34.785,49.449,57.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 4.544 | Acc: 40.625,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 40.253,60.789,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.557 | Acc: 40.568,60.499,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.521 | Acc: 41.124,60.873,72.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.517 | Acc: 41.049,61.227,71.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.507 | Acc: 41.313,61.255,71.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.530 | Acc: 41.271,60.918,71.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.539 | Acc: 41.196,60.777,71.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.535 | Acc: 41.411,60.836,71.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.556 | Acc: 41.354,60.562,71.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.554 | Acc: 41.523,60.603,71.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.561 | Acc: 41.417,60.372,71.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.567 | Acc: 41.390,60.305,70.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.572 | Acc: 41.364,60.228,70.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.573 | Acc: 41.331,60.237,70.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.575 | Acc: 41.347,60.304,70.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.580 | Acc: 41.360,60.278,70.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.583 | Acc: 41.296,60.241,70.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.581 | Acc: 41.279,60.273,70.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.588 | Acc: 41.234,60.232,70.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.871 | Acc: 29.688,46.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.550 | Acc: 33.891,45.685,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.498 | Acc: 33.327,45.636,55.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.554 | Acc: 33.645,45.505,54.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 4.866 | Acc: 44.531,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.433 | Acc: 42.820,62.909,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.445 | Acc: 42.111,62.748,71.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.488 | Acc: 41.765,62.039,71.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.504 | Acc: 41.667,61.391,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.501 | Acc: 41.600,61.417,70.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.533 | Acc: 41.355,61.073,70.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.532 | Acc: 41.445,61.026,70.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.532 | Acc: 41.372,60.913,70.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.536 | Acc: 41.242,60.735,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.543 | Acc: 41.181,60.693,70.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.554 | Acc: 41.286,60.538,70.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.557 | Acc: 41.270,60.493,70.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.566 | Acc: 41.209,60.393,70.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.568 | Acc: 41.281,60.334,70.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.570 | Acc: 41.292,60.333,70.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.573 | Acc: 41.324,60.327,70.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.577 | Acc: 41.264,60.273,70.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.573 | Acc: 41.257,60.280,70.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.574 | Acc: 41.279,60.312,70.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.279 | Acc: 31.250,51.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.149 | Acc: 31.176,50.856,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.140 | Acc: 30.831,51.010,58.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.170 | Acc: 30.430,51.319,57.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 4.502 | Acc: 39.844,61.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.455 | Acc: 40.960,62.016,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.480 | Acc: 41.749,61.681,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.510 | Acc: 41.739,61.360,71.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.489 | Acc: 41.676,61.478,71.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.494 | Acc: 41.584,61.510,71.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.511 | Acc: 41.574,61.028,71.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.508 | Acc: 41.755,61.192,71.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.503 | Acc: 41.809,61.093,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.515 | Acc: 41.644,60.959,71.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.516 | Acc: 41.601,60.957,71.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.514 | Acc: 41.632,60.934,71.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.527 | Acc: 41.656,60.808,71.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.530 | Acc: 41.670,60.803,70.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.540 | Acc: 41.529,60.732,70.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.548 | Acc: 41.476,60.722,70.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.559 | Acc: 41.409,60.577,70.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.559 | Acc: 41.349,60.569,70.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.567 | Acc: 41.289,60.537,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.583 | Acc: 41.090,60.345,70.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.705 | Acc: 30.469,45.312,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.550 | Acc: 29.985,46.949,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.615 | Acc: 29.497,46.513,54.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.674 | Acc: 28.945,46.311,54.547,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 4.532 | Acc: 46.094,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.457 | Acc: 41.481,61.756,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.411 | Acc: 41.368,61.395,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.408 | Acc: 41.752,61.539,72.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.451 | Acc: 41.493,60.928,71.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.468 | Acc: 41.708,60.767,71.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.483 | Acc: 41.426,60.828,71.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.504 | Acc: 41.190,60.583,71.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.504 | Acc: 41.319,60.690,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.518 | Acc: 41.277,60.571,71.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.517 | Acc: 41.243,60.693,71.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.533 | Acc: 41.166,60.510,71.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.545 | Acc: 41.257,60.422,71.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.543 | Acc: 41.293,60.563,71.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.557 | Acc: 41.145,60.398,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.554 | Acc: 41.214,60.460,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.551 | Acc: 41.292,60.580,71.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.553 | Acc: 41.278,60.461,70.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.560 | Acc: 41.224,60.483,70.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.565 | Acc: 41.238,60.546,70.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.131 | Acc: 32.812,52.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.679 | Acc: 30.506,47.507,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.711 | Acc: 30.393,46.018,55.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.758 | Acc: 29.956,45.850,56.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 4.260 | Acc: 39.844,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 40.476,58.966,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.483 | Acc: 40.968,60.747,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.494 | Acc: 40.958,60.592,72.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.466 | Acc: 41.387,60.754,72.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.452 | Acc: 41.716,61.038,72.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.484 | Acc: 41.542,60.692,72.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.507 | Acc: 41.390,60.389,71.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.504 | Acc: 41.455,60.379,71.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.516 | Acc: 41.350,60.238,71.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.518 | Acc: 41.371,60.211,71.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.517 | Acc: 41.374,60.294,71.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.517 | Acc: 41.439,60.331,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.531 | Acc: 41.307,60.255,71.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.543 | Acc: 41.156,60.170,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.551 | Acc: 41.077,60.172,71.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.549 | Acc: 41.129,60.195,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.549 | Acc: 41.193,60.259,71.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.557 | Acc: 41.114,60.247,71.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.562 | Acc: 41.072,60.201,70.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.851 | Acc: 32.031,46.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.191 | Acc: 29.874,50.670,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.226 | Acc: 29.402,49.619,58.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.186 | Acc: 29.688,50.102,58.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 4.539 | Acc: 43.750,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.471 | Acc: 42.076,60.268,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.461 | Acc: 41.120,60.537,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.456 | Acc: 41.611,60.579,72.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.432 | Acc: 41.975,60.909,72.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.457 | Acc: 41.963,60.961,72.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.488 | Acc: 41.561,60.770,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.496 | Acc: 41.539,60.827,72.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.497 | Acc: 41.532,60.845,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.497 | Acc: 41.596,60.808,72.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.506 | Acc: 41.503,60.743,72.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.520 | Acc: 41.495,60.747,72.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.526 | Acc: 41.367,60.591,71.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.535 | Acc: 41.358,60.524,71.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.535 | Acc: 41.387,60.559,71.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.539 | Acc: 41.308,60.460,71.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.553 | Acc: 41.100,60.346,71.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.553 | Acc: 41.200,60.365,71.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.554 | Acc: 41.201,60.303,71.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.558 | Acc: 41.136,60.318,71.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.163 | Acc: 26.562,53.906,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.551 | Acc: 23.996,44.159,52.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.507 | Acc: 24.638,44.150,51.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.536 | Acc: 25.205,43.891,51.729,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 4.298 | Acc: 49.219,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 40.476,61.086,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.484 | Acc: 41.292,61.947,71.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.436 | Acc: 41.714,62.346,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.458 | Acc: 41.541,62.172,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.451 | Acc: 41.375,61.989,72.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.462 | Acc: 41.574,61.919,72.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.461 | Acc: 41.711,61.879,72.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.468 | Acc: 41.838,61.835,72.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.485 | Acc: 41.777,61.771,72.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.489 | Acc: 41.733,61.524,71.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.494 | Acc: 41.721,61.432,71.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.503 | Acc: 41.643,61.378,71.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.522 | Acc: 41.544,61.180,71.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.531 | Acc: 41.534,61.035,71.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.536 | Acc: 41.448,61.002,71.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.540 | Acc: 41.445,60.969,70.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.544 | Acc: 41.342,60.901,70.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.551 | Acc: 41.274,60.855,70.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.555 | Acc: 41.287,60.763,70.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.845 | Acc: 26.562,49.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.157 | Acc: 23.140,47.433,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.219 | Acc: 23.018,47.066,55.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.244 | Acc: 23.233,47.041,55.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 4.762 | Acc: 35.156,56.250,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.394 | Acc: 42.001,60.938,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.413 | Acc: 42.264,61.662,72.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.423 | Acc: 42.085,61.668,72.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.414 | Acc: 42.062,61.738,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.436 | Acc: 41.793,61.347,72.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.457 | Acc: 41.748,61.228,72.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.467 | Acc: 41.584,61.131,72.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.468 | Acc: 41.595,61.156,72.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.480 | Acc: 41.527,61.149,71.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.496 | Acc: 41.348,61.097,71.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.500 | Acc: 41.350,61.079,71.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.502 | Acc: 41.306,61.051,71.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.512 | Acc: 41.245,60.887,71.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.513 | Acc: 41.320,60.915,71.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.520 | Acc: 41.263,60.803,71.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.530 | Acc: 41.204,60.718,71.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.537 | Acc: 41.234,60.704,71.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.544 | Acc: 41.229,60.719,71.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.545 | Acc: 41.232,60.798,71.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.592 | Acc: 28.906,52.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.955 | Acc: 26.897,43.862,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.997 | Acc: 26.239,42.607,55.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.004 | Acc: 25.679,42.431,55.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 4.700 | Acc: 39.844,57.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.341 | Acc: 42.485,62.649,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 41.673,62.424,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.329 | Acc: 41.726,62.910,73.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.387 | Acc: 41.850,62.326,73.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.411 | Acc: 41.739,61.843,72.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.437 | Acc: 41.522,61.499,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.439 | Acc: 41.523,61.242,72.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.447 | Acc: 41.377,61.190,72.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.451 | Acc: 41.303,61.244,72.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.474 | Acc: 41.406,61.252,72.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.478 | Acc: 41.445,61.273,71.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.485 | Acc: 41.539,61.281,71.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.496 | Acc: 41.475,61.123,71.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.501 | Acc: 41.520,61.165,71.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.513 | Acc: 41.549,61.085,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.526 | Acc: 41.452,60.998,71.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.533 | Acc: 41.351,60.869,71.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.530 | Acc: 41.430,60.935,71.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.527 | Acc: 41.447,60.919,71.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.015 | Acc: 32.812,49.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.212 | Acc: 32.217,48.996,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.220 | Acc: 32.260,48.895,57.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.230 | Acc: 31.993,49.052,57.838,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 4.914 | Acc: 46.875,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 41.481,60.603,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.429 | Acc: 41.806,60.995,72.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.426 | Acc: 41.829,61.027,72.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.399 | Acc: 41.811,61.265,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.397 | Acc: 42.180,61.317,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.413 | Acc: 42.207,61.370,72.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.434 | Acc: 41.949,61.248,71.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.445 | Acc: 41.867,61.107,71.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.455 | Acc: 41.726,61.145,71.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.462 | Acc: 41.682,61.093,71.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.473 | Acc: 41.710,60.991,71.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.476 | Acc: 41.636,61.048,71.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.476 | Acc: 41.619,61.015,71.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.483 | Acc: 41.540,60.890,71.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.490 | Acc: 41.578,60.808,71.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.497 | Acc: 41.550,60.750,71.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.516 | Acc: 41.415,60.598,71.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.526 | Acc: 41.469,60.557,70.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.530 | Acc: 41.419,60.484,70.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.139 | Acc: 26.562,44.531,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.107 | Acc: 28.720,40.811,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.134 | Acc: 28.563,40.758,54.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.141 | Acc: 28.138,40.702,53.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 3.688 | Acc: 47.656,64.062,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.417 | Acc: 42.374,62.835,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 41.578,62.043,72.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.470 | Acc: 41.073,61.475,71.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.456 | Acc: 41.599,61.719,72.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.477 | Acc: 41.754,61.564,71.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.475 | Acc: 41.729,61.512,71.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.463 | Acc: 42.121,61.608,71.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.470 | Acc: 42.081,61.578,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.470 | Acc: 42.088,61.417,71.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.463 | Acc: 42.075,61.412,71.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.468 | Acc: 41.990,61.390,71.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.473 | Acc: 41.915,61.294,71.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.482 | Acc: 41.771,61.174,71.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.495 | Acc: 41.809,60.965,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.504 | Acc: 41.775,60.950,71.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.514 | Acc: 41.654,60.828,71.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.522 | Acc: 41.562,60.718,71.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.529 | Acc: 41.540,60.702,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.536 | Acc: 41.490,60.632,71.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.906 | Acc: 29.688,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.052 | Acc: 30.246,52.083,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.053 | Acc: 30.412,51.277,58.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.065 | Acc: 30.622,51.486,58.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 4.178 | Acc: 47.656,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 41.369,60.268,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.497 | Acc: 41.292,60.537,72.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.511 | Acc: 40.779,60.669,72.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.502 | Acc: 40.943,61.015,72.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.514 | Acc: 40.834,60.845,72.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.507 | Acc: 41.154,60.925,72.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.496 | Acc: 41.373,61.143,72.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.498 | Acc: 41.280,61.190,72.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.500 | Acc: 41.367,61.171,72.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.487 | Acc: 41.363,61.171,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.485 | Acc: 41.537,61.217,72.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.488 | Acc: 41.465,61.200,72.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.485 | Acc: 41.511,61.210,72.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.488 | Acc: 41.579,61.074,71.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.507 | Acc: 41.437,60.976,71.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.522 | Acc: 41.233,60.828,71.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.530 | Acc: 41.244,60.738,71.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.527 | Acc: 41.311,60.771,71.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.526 | Acc: 41.363,60.792,71.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.034 | Acc: 33.594,46.875,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.931 | Acc: 34.524,50.000,59.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.948 | Acc: 33.975,49.295,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.984 | Acc: 33.863,49.180,58.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 4.678 | Acc: 40.625,63.281,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.469 | Acc: 41.964,61.198,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.435 | Acc: 42.188,61.757,72.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.435 | Acc: 41.650,61.450,72.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.428 | Acc: 41.599,61.516,72.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.448 | Acc: 41.491,61.463,72.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.470 | Acc: 41.484,61.241,72.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.472 | Acc: 41.561,61.137,71.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.463 | Acc: 41.794,61.263,71.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.459 | Acc: 41.773,61.330,71.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.471 | Acc: 41.752,61.225,71.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.471 | Acc: 41.731,61.323,71.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.473 | Acc: 41.740,61.288,71.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.481 | Acc: 41.580,61.219,71.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.494 | Acc: 41.526,61.082,71.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.492 | Acc: 41.578,61.122,71.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.491 | Acc: 41.672,61.157,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.491 | Acc: 41.757,61.176,71.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.502 | Acc: 41.709,60.979,71.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.507 | Acc: 41.661,60.985,71.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.051 | Acc: 31.250,45.312,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.682 | Acc: 29.278,45.722,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.732 | Acc: 29.287,45.427,55.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.746 | Acc: 29.393,45.530,55.712,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 4.327 | Acc: 38.281,63.281,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.360 | Acc: 40.960,62.723,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 42.302,63.300,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.405 | Acc: 42.162,62.449,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.404 | Acc: 42.197,62.085,73.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.423 | Acc: 41.839,61.959,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.433 | Acc: 41.645,61.822,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.451 | Acc: 41.512,61.602,72.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.451 | Acc: 41.615,61.680,72.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.450 | Acc: 41.566,61.645,72.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.446 | Acc: 41.775,61.641,72.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.450 | Acc: 41.795,61.673,72.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.453 | Acc: 41.756,61.596,72.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.457 | Acc: 41.750,61.578,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.457 | Acc: 41.748,61.655,72.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.465 | Acc: 41.710,61.498,71.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.473 | Acc: 41.659,61.439,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.475 | Acc: 41.596,61.407,71.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.482 | Acc: 41.538,61.275,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.495 | Acc: 41.492,61.186,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.737 | Acc: 32.812,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.346 | Acc: 28.088,43.229,52.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.297 | Acc: 27.858,42.854,52.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.305 | Acc: 27.805,42.751,52.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 4.925 | Acc: 40.625,54.688,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 40.960,60.193,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.427 | Acc: 41.864,61.338,72.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.402 | Acc: 42.508,61.565,72.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.406 | Acc: 42.438,61.651,72.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.411 | Acc: 42.164,61.688,72.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.423 | Acc: 42.252,61.803,72.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.424 | Acc: 42.110,61.802,72.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.436 | Acc: 41.935,61.617,72.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.448 | Acc: 41.752,61.658,72.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.440 | Acc: 41.741,61.719,72.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.444 | Acc: 41.689,61.690,72.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.452 | Acc: 41.747,61.511,72.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.462 | Acc: 41.619,61.416,72.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.481 | Acc: 41.451,61.279,71.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.487 | Acc: 41.404,61.215,71.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.490 | Acc: 41.438,61.254,71.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.498 | Acc: 41.399,61.178,71.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.501 | Acc: 41.354,61.169,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.504 | Acc: 41.427,61.165,71.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.034 | Acc: 31.250,49.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.166 | Acc: 33.743,49.516,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.236 | Acc: 33.251,48.209,56.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.259 | Acc: 32.684,48.309,56.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 4.203 | Acc: 42.969,60.938,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.406 | Acc: 42.783,61.830,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.419 | Acc: 42.359,61.604,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.420 | Acc: 42.264,61.245,72.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.453 | Acc: 41.937,61.246,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.438 | Acc: 42.164,61.580,72.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.443 | Acc: 41.981,61.570,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.438 | Acc: 42.099,61.541,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.455 | Acc: 41.828,61.331,72.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.443 | Acc: 41.890,61.391,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.444 | Acc: 41.923,61.466,72.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.440 | Acc: 41.990,61.468,72.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.460 | Acc: 41.896,61.294,71.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.451 | Acc: 41.879,61.378,72.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.459 | Acc: 41.848,61.352,71.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.467 | Acc: 41.809,61.280,71.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.473 | Acc: 41.759,61.281,71.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.477 | Acc: 41.704,61.238,71.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.484 | Acc: 41.714,61.171,71.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.489 | Acc: 41.704,61.095,71.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.776 | Acc: 28.906,48.438,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.902 | Acc: 28.832,45.871,54.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.959 | Acc: 28.144,45.027,54.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.964 | Acc: 27.971,44.992,54.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 4.302 | Acc: 49.219,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.368 | Acc: 42.634,61.458,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.501 | Acc: 41.139,60.823,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.488 | Acc: 40.932,60.784,71.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.472 | Acc: 40.895,61.275,72.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.454 | Acc: 41.213,61.115,72.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.441 | Acc: 41.380,61.532,72.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.447 | Acc: 41.528,61.597,71.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.459 | Acc: 41.479,61.554,71.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.460 | Acc: 41.406,61.546,71.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.462 | Acc: 41.410,61.443,71.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.472 | Acc: 41.399,61.319,71.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.471 | Acc: 41.552,61.249,71.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.467 | Acc: 41.535,61.246,71.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.473 | Acc: 41.598,61.191,71.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.472 | Acc: 41.653,61.236,71.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.475 | Acc: 41.625,61.178,71.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.484 | Acc: 41.603,61.118,71.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.496 | Acc: 41.534,61.002,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.495 | Acc: 41.578,60.972,71.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.896 | Acc: 37.500,50.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.227 | Acc: 32.440,47.917,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.264 | Acc: 32.527,47.389,58.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.261 | Acc: 32.492,47.759,58.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.304 | Acc: 40.625,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 42.039,63.430,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.372 | Acc: 41.959,62.157,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.390 | Acc: 42.597,61.898,72.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.387 | Acc: 42.776,61.748,73.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.388 | Acc: 42.590,61.765,73.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.382 | Acc: 42.594,61.867,73.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.401 | Acc: 42.309,61.630,72.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.401 | Acc: 42.362,61.743,72.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.401 | Acc: 42.326,61.831,72.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.405 | Acc: 42.289,61.742,72.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.403 | Acc: 42.276,61.747,72.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.405 | Acc: 42.278,61.673,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.414 | Acc: 42.149,61.647,72.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.428 | Acc: 42.118,61.499,72.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.437 | Acc: 42.068,61.498,72.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.454 | Acc: 42.010,61.303,72.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.463 | Acc: 41.940,61.265,71.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.472 | Acc: 41.906,61.158,71.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.474 | Acc: 41.913,61.118,71.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.280 | Acc: 36.719,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.221 | Acc: 33.259,49.107,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.299 | Acc: 32.812,48.895,56.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.262 | Acc: 32.941,48.988,57.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 4.170 | Acc: 42.188,62.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.316 | Acc: 42.188,60.975,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.384 | Acc: 41.730,61.071,73.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.378 | Acc: 41.957,61.411,72.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.386 | Acc: 41.541,61.507,72.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.409 | Acc: 41.700,61.502,72.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.415 | Acc: 41.819,61.370,72.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.399 | Acc: 41.888,61.746,72.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.394 | Acc: 41.877,61.767,72.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.407 | Acc: 41.911,61.637,72.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.428 | Acc: 41.729,61.443,72.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.421 | Acc: 41.926,61.542,72.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.426 | Acc: 41.941,61.446,72.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.426 | Acc: 41.918,61.381,72.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.431 | Acc: 41.843,61.366,72.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.439 | Acc: 41.910,61.353,72.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.449 | Acc: 41.818,61.305,72.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.453 | Acc: 41.901,61.306,71.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.459 | Acc: 41.824,61.225,71.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.463 | Acc: 41.798,61.204,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.144 | Acc: 29.688,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.159 | Acc: 32.850,50.037,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.230 | Acc: 31.650,49.200,57.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.258 | Acc: 31.647,48.950,57.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 4.449 | Acc: 40.625,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.262 | Acc: 44.159,64.286,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.303 | Acc: 43.140,62.938,72.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.294 | Acc: 43.046,63.179,73.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.301 | Acc: 43.007,63.079,73.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.312 | Acc: 42.698,62.794,73.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.344 | Acc: 42.517,62.519,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.369 | Acc: 42.365,62.284,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.374 | Acc: 42.513,62.272,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.385 | Acc: 42.429,62.021,72.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.401 | Acc: 42.254,61.808,72.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.407 | Acc: 42.195,61.857,72.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.417 | Acc: 42.168,61.751,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.424 | Acc: 42.110,61.692,72.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.439 | Acc: 41.985,61.505,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.437 | Acc: 42.014,61.555,72.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.441 | Acc: 41.949,61.526,72.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.446 | Acc: 41.924,61.462,71.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.457 | Acc: 41.880,61.357,71.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.467 | Acc: 41.794,61.276,71.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.521 | Acc: 28.906,48.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.505 | Acc: 28.795,49.740,55.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.513 | Acc: 28.773,49.143,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.495 | Acc: 28.484,49.577,56.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 4.353 | Acc: 42.188,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.300 | Acc: 42.336,62.686,73.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.340 | Acc: 42.130,61.719,73.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.359 | Acc: 43.058,61.783,73.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.372 | Acc: 43.277,61.796,73.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.372 | Acc: 43.131,61.858,73.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.384 | Acc: 42.678,61.816,72.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.380 | Acc: 42.670,61.802,72.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.396 | Acc: 42.721,61.670,72.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.413 | Acc: 42.239,61.533,72.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.410 | Acc: 42.273,61.575,72.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.411 | Acc: 42.202,61.567,72.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.415 | Acc: 42.152,61.576,72.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.420 | Acc: 42.017,61.551,72.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.432 | Acc: 41.973,61.399,72.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.437 | Acc: 41.982,61.384,72.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.443 | Acc: 41.934,61.373,72.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.453 | Acc: 41.915,61.304,72.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.459 | Acc: 41.926,61.312,71.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.469 | Acc: 41.820,61.251,71.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.688 | Acc: 23.438,43.750,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.498 | Acc: 24.219,41.295,54.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.554 | Acc: 24.352,41.673,54.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.523 | Acc: 24.334,42.290,54.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 4.641 | Acc: 40.625,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.437 | Acc: 40.551,62.351,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.403 | Acc: 41.559,62.043,73.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.391 | Acc: 41.509,62.065,73.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.405 | Acc: 41.300,61.748,73.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.395 | Acc: 41.429,62.020,73.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.401 | Acc: 41.477,62.132,73.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.406 | Acc: 41.500,62.051,72.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.415 | Acc: 41.435,61.961,72.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.414 | Acc: 41.458,62.030,72.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.409 | Acc: 41.562,62.022,72.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.418 | Acc: 41.541,62.002,72.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.418 | Acc: 41.617,61.952,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.424 | Acc: 41.697,61.943,72.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.425 | Acc: 41.690,61.897,72.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.424 | Acc: 41.824,61.989,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.430 | Acc: 41.801,61.940,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.435 | Acc: 41.828,61.939,72.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.436 | Acc: 41.854,61.937,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.442 | Acc: 41.876,61.893,72.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.056 | Acc: 30.469,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.321 | Acc: 30.022,49.963,58.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.350 | Acc: 29.611,48.990,58.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.370 | Acc: 29.265,49.168,57.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 4.514 | Acc: 44.531,63.281,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.338 | Acc: 41.220,63.988,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.288 | Acc: 41.578,63.720,75.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.333 | Acc: 41.445,62.974,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.342 | Acc: 41.580,62.510,74.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.358 | Acc: 41.832,62.067,73.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.355 | Acc: 41.897,62.274,73.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.356 | Acc: 42.165,62.184,73.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.365 | Acc: 42.192,61.995,73.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.372 | Acc: 42.282,61.965,73.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.380 | Acc: 42.234,61.843,73.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.383 | Acc: 42.279,61.804,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.407 | Acc: 42.132,61.602,72.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.423 | Acc: 42.032,61.560,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.431 | Acc: 42.126,61.432,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.433 | Acc: 42.156,61.480,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.435 | Acc: 42.127,61.390,72.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.435 | Acc: 42.158,61.387,72.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.443 | Acc: 42.123,61.381,72.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.457 | Acc: 41.995,61.237,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.657 | Acc: 34.375,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.658 | Acc: 34.710,51.451,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.747 | Acc: 33.822,50.629,61.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.779 | Acc: 34.439,50.359,61.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 4.252 | Acc: 44.531,60.156,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.394 | Acc: 40.923,62.760,73.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.296 | Acc: 42.835,63.262,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.397 | Acc: 42.162,62.321,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.399 | Acc: 42.149,62.461,73.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.413 | Acc: 41.994,62.020,72.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.405 | Acc: 41.981,62.042,73.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.408 | Acc: 42.182,61.907,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.406 | Acc: 42.129,61.879,72.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.437 | Acc: 41.933,61.503,72.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.449 | Acc: 41.834,61.419,72.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.435 | Acc: 41.975,61.616,72.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.433 | Acc: 41.918,61.706,72.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.440 | Acc: 41.915,61.695,72.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.444 | Acc: 41.940,61.724,72.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.443 | Acc: 41.899,61.745,72.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.446 | Acc: 41.925,61.765,72.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.450 | Acc: 41.906,61.634,72.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.455 | Acc: 41.893,61.626,72.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.453 | Acc: 41.907,61.655,72.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.378 | Acc: 28.906,49.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.660 | Acc: 28.981,46.949,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.659 | Acc: 28.887,46.837,55.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.668 | Acc: 28.560,46.811,55.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 4.201 | Acc: 41.406,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.270 | Acc: 42.671,63.728,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.360 | Acc: 42.245,62.252,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.366 | Acc: 42.188,62.257,73.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.349 | Acc: 42.110,62.105,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.365 | Acc: 42.118,61.997,73.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.379 | Acc: 42.271,61.841,72.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.394 | Acc: 42.049,61.741,72.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.382 | Acc: 42.139,61.889,72.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.388 | Acc: 42.114,61.948,72.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.388 | Acc: 42.176,61.979,72.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.392 | Acc: 42.191,61.959,72.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.395 | Acc: 42.282,61.923,72.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.408 | Acc: 42.173,61.794,72.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.409 | Acc: 42.160,61.847,72.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.414 | Acc: 42.195,61.823,72.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.417 | Acc: 42.141,61.665,72.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.426 | Acc: 42.002,61.547,72.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.429 | Acc: 41.859,61.576,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.442 | Acc: 41.825,61.505,72.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.502 | Acc: 33.594,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.521 | Acc: 32.292,46.987,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.560 | Acc: 32.107,46.589,55.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.544 | Acc: 32.070,46.875,55.277,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 4.377 | Acc: 39.844,57.812,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.462 | Acc: 40.923,61.979,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.412 | Acc: 41.025,62.729,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.407 | Acc: 41.842,62.026,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.405 | Acc: 41.454,62.201,72.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.385 | Acc: 41.414,62.392,73.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.386 | Acc: 41.464,62.248,73.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.395 | Acc: 41.578,62.107,73.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.401 | Acc: 41.634,62.058,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.411 | Acc: 41.799,61.965,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.416 | Acc: 41.842,61.956,72.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.420 | Acc: 41.961,61.920,72.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.421 | Acc: 42.045,61.975,72.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.429 | Acc: 41.936,61.904,72.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.431 | Acc: 41.871,61.902,72.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.424 | Acc: 41.931,61.973,72.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.425 | Acc: 41.988,61.921,72.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.428 | Acc: 42.013,61.863,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.437 | Acc: 41.988,61.751,72.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.441 | Acc: 41.931,61.696,72.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.571 | Acc: 36.719,53.906,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.067 | Acc: 34.710,49.479,58.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.100 | Acc: 34.108,49.409,58.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.127 | Acc: 34.183,48.783,57.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 4.491 | Acc: 35.156,57.812,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.392 | Acc: 40.774,61.719,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.343 | Acc: 41.883,62.271,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.332 | Acc: 42.213,62.385,73.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 42.033,62.355,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.361 | Acc: 42.234,62.206,73.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.362 | Acc: 42.575,62.100,73.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.363 | Acc: 42.448,62.068,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.364 | Acc: 42.454,62.010,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.379 | Acc: 42.317,61.861,73.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.373 | Acc: 42.390,61.940,73.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.388 | Acc: 42.357,61.860,72.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.398 | Acc: 42.243,61.835,72.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.408 | Acc: 42.083,61.749,72.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.412 | Acc: 41.965,61.671,72.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.414 | Acc: 41.995,61.649,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.419 | Acc: 41.949,61.646,72.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.424 | Acc: 41.892,61.655,72.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.428 | Acc: 41.913,61.699,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.437 | Acc: 41.788,61.618,72.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.978 | Acc: 35.156,52.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.301 | Acc: 31.622,48.735,58.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.320 | Acc: 31.174,48.952,58.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.341 | Acc: 30.430,48.783,58.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 4.272 | Acc: 42.969,63.281,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.335 | Acc: 42.894,61.458,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 42.149,61.776,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.372 | Acc: 42.943,62.052,73.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.366 | Acc: 42.554,62.355,73.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.368 | Acc: 42.628,62.299,73.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.358 | Acc: 42.639,62.261,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.358 | Acc: 42.692,62.212,73.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.361 | Acc: 42.687,62.296,73.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.361 | Acc: 42.654,62.314,73.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.375 | Acc: 42.553,62.220,73.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.384 | Acc: 42.325,62.076,72.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.403 | Acc: 42.188,61.897,72.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.405 | Acc: 42.107,61.940,72.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.410 | Acc: 42.085,61.922,72.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.405 | Acc: 42.086,61.874,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.409 | Acc: 42.032,61.809,72.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.420 | Acc: 41.915,61.735,72.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.419 | Acc: 41.958,61.743,72.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.423 | Acc: 41.941,61.711,72.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.302 | Acc: 36.719,52.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.590 | Acc: 34.449,45.796,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.641 | Acc: 33.765,45.846,54.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.668 | Acc: 33.248,45.863,54.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 4.273 | Acc: 39.844,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.323 | Acc: 42.039,62.202,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.371 | Acc: 41.959,61.986,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.310 | Acc: 42.789,62.833,73.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.311 | Acc: 42.998,62.809,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.346 | Acc: 42.845,62.206,73.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.367 | Acc: 42.394,61.958,73.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.381 | Acc: 42.315,61.940,72.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.381 | Acc: 42.139,61.986,72.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.369 | Acc: 42.321,62.107,72.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.371 | Acc: 42.257,62.150,72.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.384 | Acc: 42.251,62.182,72.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.381 | Acc: 42.405,62.224,72.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.388 | Acc: 42.280,62.123,72.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.401 | Acc: 42.229,61.980,72.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.405 | Acc: 42.247,61.945,72.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.410 | Acc: 42.278,61.943,72.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.413 | Acc: 42.304,61.895,72.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.415 | Acc: 42.320,61.901,72.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.420 | Acc: 42.300,61.819,72.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.337 | Acc: 32.812,59.375,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.848 | Acc: 31.771,52.009,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.865 | Acc: 32.470,51.677,60.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.879 | Acc: 32.313,51.703,60.489,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 4.752 | Acc: 37.500,51.562,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.427 | Acc: 40.551,60.938,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.313 | Acc: 42.740,62.862,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.294 | Acc: 42.789,63.358,74.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.296 | Acc: 42.458,63.166,74.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.321 | Acc: 42.358,62.701,74.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.357 | Acc: 42.013,61.983,73.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.359 | Acc: 42.032,62.151,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.361 | Acc: 42.032,62.233,73.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.367 | Acc: 42.140,62.224,73.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.369 | Acc: 42.090,62.115,73.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.392 | Acc: 41.975,61.934,72.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.403 | Acc: 41.990,61.790,72.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.392 | Acc: 42.137,61.827,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.394 | Acc: 42.101,61.855,72.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.398 | Acc: 42.029,61.825,72.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.400 | Acc: 42.039,61.775,72.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.404 | Acc: 42.013,61.742,72.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.407 | Acc: 42.010,61.673,72.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.410 | Acc: 42.081,61.694,72.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.145 | Acc: 22.656,43.750,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.235 | Acc: 23.512,44.420,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.291 | Acc: 23.742,43.312,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.341 | Acc: 23.233,42.636,56.609,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 4.401 | Acc: 41.406,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.360 | Acc: 43.229,62.054,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.344 | Acc: 42.550,62.805,73.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.388 | Acc: 42.982,62.282,72.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.387 | Acc: 42.988,62.153,72.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.372 | Acc: 43.085,62.245,72.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.377 | Acc: 42.710,62.332,72.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.390 | Acc: 42.387,62.212,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.387 | Acc: 42.551,62.097,72.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.381 | Acc: 42.503,62.112,72.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.383 | Acc: 42.592,62.034,72.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.379 | Acc: 42.566,62.132,72.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.389 | Acc: 42.463,62.017,72.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.388 | Acc: 42.574,62.018,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.397 | Acc: 42.516,61.933,72.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.402 | Acc: 42.486,61.828,72.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.413 | Acc: 42.399,61.765,72.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.417 | Acc: 42.302,61.730,72.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.419 | Acc: 42.296,61.708,72.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.413 | Acc: 42.304,61.770,72.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.124 | Acc: 26.562,46.094,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.791 | Acc: 28.162,46.689,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.839 | Acc: 27.382,45.732,56.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.881 | Acc: 27.113,45.799,56.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 3.864 | Acc: 42.969,65.625,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.340 | Acc: 41.629,61.496,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 42.340,62.195,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.278 | Acc: 42.520,62.628,74.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.279 | Acc: 42.728,62.847,74.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.295 | Acc: 42.876,62.554,74.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.305 | Acc: 42.691,62.700,74.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.305 | Acc: 42.714,62.783,74.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.323 | Acc: 42.634,62.534,73.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.320 | Acc: 42.654,62.565,73.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.332 | Acc: 42.611,62.453,73.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.336 | Acc: 42.693,62.504,73.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.347 | Acc: 42.661,62.448,73.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.361 | Acc: 42.562,62.308,73.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.382 | Acc: 42.415,62.133,73.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.388 | Acc: 42.374,62.048,73.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.390 | Acc: 42.414,61.982,72.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.394 | Acc: 42.407,62.019,72.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.397 | Acc: 42.352,62.007,72.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.409 | Acc: 42.247,61.901,72.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.137 | Acc: 25.781,40.625,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.593 | Acc: 21.689,40.327,51.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.579 | Acc: 21.189,40.473,51.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.540 | Acc: 21.183,40.318,52.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 4.273 | Acc: 42.188,61.719,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.384 | Acc: 40.402,61.124,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.360 | Acc: 40.835,62.157,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.345 | Acc: 41.009,62.628,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.318 | Acc: 41.426,62.876,74.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.328 | Acc: 41.592,62.717,74.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.347 | Acc: 41.316,62.577,73.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.335 | Acc: 41.628,62.666,73.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.340 | Acc: 41.634,62.670,73.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.355 | Acc: 41.544,62.595,73.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.371 | Acc: 41.577,62.414,73.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.372 | Acc: 41.700,62.323,73.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.378 | Acc: 41.763,62.296,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.379 | Acc: 41.777,62.377,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.381 | Acc: 41.848,62.303,73.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.386 | Acc: 41.733,62.269,72.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.386 | Acc: 41.684,62.201,72.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.387 | Acc: 41.654,62.241,72.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.389 | Acc: 41.644,62.245,72.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.389 | Acc: 41.714,62.223,72.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.805 | Acc: 35.156,46.094,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.036 | Acc: 35.491,49.405,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.065 | Acc: 34.947,48.780,57.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.058 | Acc: 34.823,48.899,57.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 4.269 | Acc: 46.875,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.268 | Acc: 44.531,64.472,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 43.216,63.720,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.356 | Acc: 42.469,62.846,73.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.344 | Acc: 42.506,62.606,73.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.356 | Acc: 42.265,62.214,73.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.362 | Acc: 42.239,62.016,73.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.360 | Acc: 42.226,62.084,73.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.362 | Acc: 42.382,62.243,73.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.375 | Acc: 42.188,62.206,73.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.376 | Acc: 42.184,62.197,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.383 | Acc: 42.286,62.235,73.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.388 | Acc: 42.294,62.085,72.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.405 | Acc: 42.128,61.970,72.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.402 | Acc: 42.160,61.936,72.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.411 | Acc: 41.975,61.794,72.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.405 | Acc: 42.054,61.884,72.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.413 | Acc: 42.071,61.831,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.417 | Acc: 41.975,61.812,72.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.423 | Acc: 41.956,61.680,72.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.730 | Acc: 41.406,54.688,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.873 | Acc: 36.905,50.967,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.820 | Acc: 37.119,51.410,57.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.821 | Acc: 36.680,51.217,57.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 4.085 | Acc: 42.969,62.500,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.264 | Acc: 42.634,62.798,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.343 | Acc: 42.035,62.367,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.336 | Acc: 42.059,62.129,73.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.330 | Acc: 42.236,62.037,73.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.338 | Acc: 42.342,61.889,73.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.326 | Acc: 42.581,62.171,73.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.318 | Acc: 42.537,62.345,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.325 | Acc: 42.328,62.364,73.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.348 | Acc: 42.248,62.215,73.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.359 | Acc: 42.118,62.166,73.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.366 | Acc: 42.071,62.051,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.359 | Acc: 42.168,62.160,73.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.365 | Acc: 42.214,62.201,73.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.371 | Acc: 42.188,62.144,73.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.370 | Acc: 42.164,62.043,73.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.375 | Acc: 42.112,61.984,72.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.382 | Acc: 42.144,61.941,72.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.380 | Acc: 42.235,62.011,72.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.389 | Acc: 42.261,61.983,72.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.500 | Acc: 28.906,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.708 | Acc: 29.874,45.461,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.757 | Acc: 29.192,44.398,55.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.782 | Acc: 28.778,44.518,55.699,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 4.341 | Acc: 40.625,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.222 | Acc: 42.746,63.988,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.213 | Acc: 43.197,63.739,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.245 | Acc: 42.879,63.038,74.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.244 | Acc: 43.200,63.252,74.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.238 | Acc: 43.263,63.420,74.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.260 | Acc: 43.001,63.088,74.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.271 | Acc: 42.747,62.921,74.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.280 | Acc: 42.673,62.971,74.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.274 | Acc: 42.701,63.074,73.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.299 | Acc: 42.463,63.079,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.311 | Acc: 42.414,63.002,73.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.322 | Acc: 42.217,63.077,73.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.327 | Acc: 42.196,62.934,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.324 | Acc: 42.290,62.981,73.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.327 | Acc: 42.203,62.952,73.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.344 | Acc: 42.044,62.707,73.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.358 | Acc: 42.016,62.553,72.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.364 | Acc: 41.995,62.474,72.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.372 | Acc: 41.937,62.379,72.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.869 | Acc: 38.281,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.380 | Acc: 31.808,45.982,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.430 | Acc: 32.012,45.713,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.459 | Acc: 31.647,45.274,56.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 4.553 | Acc: 42.188,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.372 | Acc: 42.076,62.574,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.382 | Acc: 42.092,61.795,72.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.366 | Acc: 42.277,62.013,73.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 42.197,61.748,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.352 | Acc: 42.296,62.005,73.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.337 | Acc: 42.388,62.287,73.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.343 | Acc: 42.453,62.184,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.365 | Acc: 42.348,62.029,73.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.389 | Acc: 42.326,61.814,73.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.400 | Acc: 42.265,61.637,72.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.400 | Acc: 42.315,61.655,72.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.396 | Acc: 42.301,61.644,72.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.384 | Acc: 42.412,61.809,72.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.381 | Acc: 42.340,61.866,72.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.379 | Acc: 42.359,61.924,72.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.383 | Acc: 42.316,61.862,72.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.390 | Acc: 42.247,61.836,72.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.391 | Acc: 42.307,61.911,72.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.400 | Acc: 42.196,61.766,72.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.986 | Acc: 30.469,46.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.872 | Acc: 27.232,45.908,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.986 | Acc: 26.067,46.094,56.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.992 | Acc: 26.114,45.710,55.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 3.718 | Acc: 53.125,71.094,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.219 | Acc: 42.969,63.690,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.286 | Acc: 42.588,62.881,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.347 | Acc: 42.034,62.141,73.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.360 | Acc: 41.908,62.153,73.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.343 | Acc: 42.064,62.539,73.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.352 | Acc: 42.000,62.519,73.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.356 | Acc: 42.193,62.544,73.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.357 | Acc: 42.090,62.612,73.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.362 | Acc: 42.131,62.504,73.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.368 | Acc: 42.141,62.380,73.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.369 | Acc: 42.184,62.253,73.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.373 | Acc: 42.155,62.199,73.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.370 | Acc: 42.244,62.293,73.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.380 | Acc: 42.174,62.158,73.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.383 | Acc: 42.190,62.155,73.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.380 | Acc: 42.207,62.171,73.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.385 | Acc: 42.139,62.078,72.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.391 | Acc: 42.166,62.056,72.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.390 | Acc: 42.208,62.037,72.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.036 | Acc: 36.719,52.344,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.315 | Acc: 30.134,49.442,61.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.378 | Acc: 30.107,48.780,60.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.420 | Acc: 29.995,48.745,60.156,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 4.609 | Acc: 35.938,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.172 | Acc: 42.932,63.579,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.161 | Acc: 43.445,64.291,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.194 | Acc: 42.892,63.755,74.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.217 | Acc: 42.718,63.744,74.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.235 | Acc: 42.597,63.521,74.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.259 | Acc: 42.355,63.243,73.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.268 | Acc: 42.393,63.193,74.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.298 | Acc: 42.411,62.801,73.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.310 | Acc: 42.503,62.668,73.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.322 | Acc: 42.436,62.690,73.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.330 | Acc: 42.484,62.638,73.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.342 | Acc: 42.486,62.448,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.351 | Acc: 42.427,62.365,73.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.362 | Acc: 42.274,62.300,73.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.370 | Acc: 42.237,62.170,72.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.379 | Acc: 42.093,62.142,72.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.380 | Acc: 42.050,62.120,72.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.374 | Acc: 42.133,62.175,72.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.376 | Acc: 42.075,62.174,72.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.486 | Acc: 28.906,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.204 | Acc: 33.147,47.917,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.227 | Acc: 32.851,48.114,58.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.256 | Acc: 32.812,47.823,58.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 4.017 | Acc: 47.656,62.500,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.324 | Acc: 41.295,61.979,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.241 | Acc: 42.721,62.595,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.241 | Acc: 43.020,62.974,75.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.226 | Acc: 43.374,63.262,74.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.255 | Acc: 43.239,63.041,74.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.262 | Acc: 43.188,62.616,74.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.276 | Acc: 42.891,62.533,74.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.294 | Acc: 42.721,62.277,74.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.308 | Acc: 42.779,62.194,74.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.307 | Acc: 42.771,62.298,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.309 | Acc: 42.831,62.376,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.315 | Acc: 42.722,62.280,73.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.323 | Acc: 42.636,62.249,73.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.331 | Acc: 42.635,62.200,73.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.337 | Acc: 42.548,62.266,73.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.336 | Acc: 42.645,62.264,73.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.342 | Acc: 42.575,62.188,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.349 | Acc: 42.547,62.160,73.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.358 | Acc: 42.487,62.073,73.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.347 | Acc: 31.250,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.330 | Acc: 29.874,49.256,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.383 | Acc: 28.659,48.780,59.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.370 | Acc: 29.162,48.425,59.337,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 4.748 | Acc: 39.062,58.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.350 | Acc: 42.448,62.314,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.329 | Acc: 42.873,63.281,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.321 | Acc: 42.892,62.884,74.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.295 | Acc: 43.027,63.185,74.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.291 | Acc: 42.922,63.227,74.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.279 | Acc: 42.930,63.307,74.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.289 | Acc: 42.697,62.993,74.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.301 | Acc: 42.542,62.684,74.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.314 | Acc: 42.330,62.578,74.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 42.460,62.512,74.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.321 | Acc: 42.431,62.486,74.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.333 | Acc: 42.398,62.494,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.343 | Acc: 42.406,62.440,73.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.349 | Acc: 42.452,62.322,73.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.358 | Acc: 42.429,62.303,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.359 | Acc: 42.372,62.335,73.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.359 | Acc: 42.368,62.310,73.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.362 | Acc: 42.291,62.275,73.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.367 | Acc: 42.274,62.256,73.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.452 | Acc: 28.125,48.438,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.427 | Acc: 32.143,48.289,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.434 | Acc: 31.307,47.923,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.455 | Acc: 31.429,47.643,57.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 4.160 | Acc: 40.625,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.212 | Acc: 43.229,63.988,73.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.291 | Acc: 42.188,62.862,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 42.264,63.128,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.260 | Acc: 42.622,63.609,74.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.236 | Acc: 43.077,64.155,74.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.250 | Acc: 42.743,64.030,74.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.266 | Acc: 42.758,63.763,74.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.282 | Acc: 42.590,63.548,74.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.291 | Acc: 42.511,63.359,74.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.296 | Acc: 42.572,63.281,74.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.300 | Acc: 42.481,63.179,74.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.299 | Acc: 42.450,63.223,73.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.312 | Acc: 42.454,63.108,73.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.322 | Acc: 42.438,63.025,73.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.332 | Acc: 42.450,62.910,73.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.339 | Acc: 42.419,62.802,73.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.358 | Acc: 42.215,62.589,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.361 | Acc: 42.116,62.591,73.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.361 | Acc: 42.159,62.566,73.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.003 | Acc: 24.219,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.425 | Acc: 28.348,49.070,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.368 | Acc: 28.239,48.780,58.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.401 | Acc: 27.690,48.745,58.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 4.583 | Acc: 39.844,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.247 | Acc: 42.708,63.653,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.221 | Acc: 42.359,64.158,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.237 | Acc: 42.264,63.781,74.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.253 | Acc: 42.814,63.532,74.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.234 | Acc: 43.015,63.482,74.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.231 | Acc: 43.188,63.540,74.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.251 | Acc: 43.118,63.314,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.259 | Acc: 43.003,63.252,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.260 | Acc: 43.172,63.147,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.277 | Acc: 42.977,63.025,73.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.288 | Acc: 42.993,62.981,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.305 | Acc: 42.726,62.850,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.316 | Acc: 42.663,62.730,73.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.328 | Acc: 42.499,62.595,73.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.335 | Acc: 42.387,62.479,73.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.336 | Acc: 42.273,62.446,73.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.335 | Acc: 42.341,62.438,73.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.337 | Acc: 42.328,62.465,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.346 | Acc: 42.274,62.391,73.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.179 | Acc: 29.688,43.750,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.426 | Acc: 25.818,42.708,54.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.594 | Acc: 25.610,42.492,53.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.597 | Acc: 24.885,42.123,53.714,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 4.779 | Acc: 38.281,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.349 | Acc: 42.113,61.198,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.292 | Acc: 42.702,61.966,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.241 | Acc: 43.046,62.846,74.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.246 | Acc: 42.901,63.252,74.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.247 | Acc: 43.108,63.250,74.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.247 | Acc: 43.079,63.139,74.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.252 | Acc: 42.825,62.938,74.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.271 | Acc: 42.804,62.990,74.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.282 | Acc: 42.844,62.958,73.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.295 | Acc: 42.530,62.768,73.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.293 | Acc: 42.612,62.899,73.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.295 | Acc: 42.580,62.944,73.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.301 | Acc: 42.478,63.012,73.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.308 | Acc: 42.543,62.920,73.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.319 | Acc: 42.553,62.861,73.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.326 | Acc: 42.533,62.760,73.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.323 | Acc: 42.591,62.745,73.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.324 | Acc: 42.729,62.699,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.328 | Acc: 42.692,62.650,73.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.969 | Acc: 33.594,50.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.980 | Acc: 34.561,50.037,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.006 | Acc: 34.051,49.333,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.962 | Acc: 33.709,49.769,59.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 4.085 | Acc: 43.750,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.300 | Acc: 42.076,64.062,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.267 | Acc: 42.778,63.300,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.236 | Acc: 42.853,63.409,75.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.239 | Acc: 43.499,63.175,74.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.288 | Acc: 43.170,62.894,74.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.281 | Acc: 43.156,62.920,74.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.302 | Acc: 43.146,62.882,74.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.310 | Acc: 43.037,62.791,73.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.317 | Acc: 43.038,62.703,73.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.329 | Acc: 42.926,62.652,73.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.325 | Acc: 43.142,62.726,73.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.337 | Acc: 42.956,62.588,73.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.351 | Acc: 42.747,62.443,73.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.342 | Acc: 42.813,62.500,73.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.343 | Acc: 42.751,62.474,73.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.338 | Acc: 42.786,62.512,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.346 | Acc: 42.694,62.475,73.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.353 | Acc: 42.670,62.444,73.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.368 | Acc: 42.491,62.233,72.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.726 | Acc: 38.281,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.477 | Acc: 31.510,47.098,55.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.474 | Acc: 30.716,46.932,56.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.494 | Acc: 30.866,46.977,56.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 4.676 | Acc: 35.156,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.177 | Acc: 43.006,64.137,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.259 | Acc: 42.854,63.758,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.271 | Acc: 42.585,63.307,74.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.241 | Acc: 43.383,63.484,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.238 | Acc: 43.386,63.374,74.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.246 | Acc: 43.376,63.255,74.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.258 | Acc: 43.035,63.198,73.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.272 | Acc: 42.867,63.014,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.275 | Acc: 42.813,62.923,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.283 | Acc: 42.837,62.873,73.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.288 | Acc: 42.880,62.921,73.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.290 | Acc: 42.855,62.899,73.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.288 | Acc: 42.921,62.997,73.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.304 | Acc: 42.782,62.936,73.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.310 | Acc: 42.756,62.863,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.322 | Acc: 42.640,62.709,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.330 | Acc: 42.515,62.582,73.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.342 | Acc: 42.458,62.519,73.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.344 | Acc: 42.448,62.473,73.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.299 | Acc: 25.781,50.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.224 | Acc: 31.436,48.735,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.332 | Acc: 30.278,48.037,58.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.326 | Acc: 30.725,48.758,59.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 4.146 | Acc: 48.438,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.202 | Acc: 43.192,63.542,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.256 | Acc: 42.530,63.186,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.256 | Acc: 42.930,63.525,74.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.277 | Acc: 42.641,62.847,73.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.303 | Acc: 42.420,62.686,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.289 | Acc: 42.530,62.829,74.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.287 | Acc: 42.609,62.771,74.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.302 | Acc: 42.605,62.660,74.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.304 | Acc: 42.464,62.556,73.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.330 | Acc: 42.211,62.403,73.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.340 | Acc: 42.011,62.348,73.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.341 | Acc: 42.009,62.387,73.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.338 | Acc: 42.017,62.395,73.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.335 | Acc: 42.062,62.333,73.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.340 | Acc: 42.076,62.266,73.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.338 | Acc: 42.144,62.249,73.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.337 | Acc: 42.153,62.308,73.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.343 | Acc: 42.188,62.232,73.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.348 | Acc: 42.202,62.164,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.596 | Acc: 25.000,45.312,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.537 | Acc: 25.558,48.921,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.627 | Acc: 26.029,49.047,58.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.701 | Acc: 25.461,48.630,57.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 4.711 | Acc: 36.719,55.469,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.211 | Acc: 42.746,63.914,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.364 | Acc: 41.235,61.566,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.310 | Acc: 41.778,62.257,74.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.297 | Acc: 42.110,62.731,74.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.306 | Acc: 42.064,62.709,74.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.308 | Acc: 42.013,62.500,74.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.305 | Acc: 42.154,62.672,73.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.302 | Acc: 42.197,62.636,73.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.300 | Acc: 42.412,62.651,73.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 42.316,62.652,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.312 | Acc: 42.357,62.673,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.322 | Acc: 42.256,62.565,73.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.321 | Acc: 42.232,62.566,73.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.322 | Acc: 42.240,62.586,73.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.331 | Acc: 42.180,62.609,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.327 | Acc: 42.243,62.658,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.334 | Acc: 42.236,62.569,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.331 | Acc: 42.294,62.608,73.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.328 | Acc: 42.319,62.654,73.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.841 | Acc: 32.031,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.729 | Acc: 31.659,43.601,52.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.851 | Acc: 31.155,43.255,51.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.901 | Acc: 30.738,43.417,51.998,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 4.560 | Acc: 39.062,64.062,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.271 | Acc: 42.783,62.872,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.301 | Acc: 41.902,62.214,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.330 | Acc: 41.842,61.975,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.317 | Acc: 42.149,62.269,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.329 | Acc: 41.816,62.268,74.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.313 | Acc: 42.084,62.487,74.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.316 | Acc: 42.287,62.517,73.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.326 | Acc: 42.236,62.500,73.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.338 | Acc: 42.205,62.414,73.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.338 | Acc: 42.238,62.411,73.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.338 | Acc: 42.276,62.472,73.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.338 | Acc: 42.346,62.481,73.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.338 | Acc: 42.439,62.494,73.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.327 | Acc: 42.518,62.586,73.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.328 | Acc: 42.533,62.596,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.324 | Acc: 42.494,62.612,73.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.334 | Acc: 42.387,62.477,73.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.341 | Acc: 42.345,62.411,73.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.343 | Acc: 42.413,62.359,73.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.468 | Acc: 28.125,50.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.107 | Acc: 34.821,49.405,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.166 | Acc: 33.746,49.600,58.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.164 | Acc: 33.376,49.795,58.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 4.003 | Acc: 48.438,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.267 | Acc: 43.118,62.760,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.330 | Acc: 42.092,62.081,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.285 | Acc: 42.738,62.436,73.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.255 | Acc: 43.287,62.847,74.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.250 | Acc: 43.185,62.778,74.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.273 | Acc: 43.059,62.571,74.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.257 | Acc: 43.174,62.650,74.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.285 | Acc: 43.022,62.393,73.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.295 | Acc: 42.809,62.293,73.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.313 | Acc: 42.603,62.181,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.320 | Acc: 42.548,62.238,73.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.314 | Acc: 42.602,62.341,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.314 | Acc: 42.759,62.371,73.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.317 | Acc: 42.782,62.389,73.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.319 | Acc: 42.766,62.443,73.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.327 | Acc: 42.674,62.410,73.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.334 | Acc: 42.653,62.383,72.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.328 | Acc: 42.707,62.426,72.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.327 | Acc: 42.721,62.445,73.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.586 | Acc: 29.688,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.855 | Acc: 28.348,46.615,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.889 | Acc: 28.201,47.008,57.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.870 | Acc: 28.291,47.439,57.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 3.972 | Acc: 39.844,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.261 | Acc: 42.262,63.467,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.229 | Acc: 43.121,63.262,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.291 | Acc: 42.533,63.089,74.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.275 | Acc: 42.988,62.876,74.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.269 | Acc: 42.992,62.925,74.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.264 | Acc: 43.020,63.210,74.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.272 | Acc: 43.118,62.910,74.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.275 | Acc: 43.250,62.922,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.287 | Acc: 43.236,62.914,74.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.285 | Acc: 43.241,62.994,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.275 | Acc: 43.421,63.182,74.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.289 | Acc: 43.202,62.908,74.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.289 | Acc: 43.301,62.952,74.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.293 | Acc: 43.272,62.834,73.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.296 | Acc: 43.226,62.786,73.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.296 | Acc: 43.212,62.824,73.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.300 | Acc: 43.189,62.793,73.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.297 | Acc: 43.189,62.851,73.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.308 | Acc: 43.092,62.771,73.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.649 | Acc: 33.594,55.469,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.201 | Acc: 32.403,49.442,58.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.202 | Acc: 32.069,49.466,57.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.217 | Acc: 31.826,49.705,58.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 4.275 | Acc: 41.406,60.156,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.233 | Acc: 42.150,63.728,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.199 | Acc: 42.950,64.177,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.211 | Acc: 42.725,63.601,75.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.234 | Acc: 42.641,63.493,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.265 | Acc: 42.528,63.181,74.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.290 | Acc: 42.278,63.133,74.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.272 | Acc: 42.409,63.065,74.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.281 | Acc: 42.532,63.150,74.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.291 | Acc: 42.408,62.949,73.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.297 | Acc: 42.483,62.900,73.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.306 | Acc: 42.343,62.783,73.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.316 | Acc: 42.314,62.633,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.315 | Acc: 42.310,62.671,73.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.319 | Acc: 42.357,62.706,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.323 | Acc: 42.291,62.671,73.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.322 | Acc: 42.292,62.687,73.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.324 | Acc: 42.311,62.674,73.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.324 | Acc: 42.309,62.608,73.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.325 | Acc: 42.331,62.660,73.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.556 | Acc: 33.594,55.469,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.776 | Acc: 35.826,52.046,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.772 | Acc: 36.033,51.524,60.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.768 | Acc: 35.989,51.511,60.476,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 4.104 | Acc: 45.312,62.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.363 | Acc: 42.150,62.202,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.281 | Acc: 43.407,63.034,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.284 | Acc: 43.084,63.089,74.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.271 | Acc: 43.133,63.291,74.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.279 | Acc: 42.992,63.034,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.280 | Acc: 43.001,63.146,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.279 | Acc: 43.091,63.220,74.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.273 | Acc: 43.008,63.281,74.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.273 | Acc: 43.068,63.165,74.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.274 | Acc: 43.066,63.157,74.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.268 | Acc: 43.213,63.257,74.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.267 | Acc: 43.170,63.210,74.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.282 | Acc: 42.963,63.081,73.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.281 | Acc: 43.083,63.067,73.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.297 | Acc: 42.927,62.941,73.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.301 | Acc: 42.862,62.880,73.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.307 | Acc: 42.861,62.828,73.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.307 | Acc: 42.923,62.825,73.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.313 | Acc: 42.842,62.801,73.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.407 | Acc: 31.250,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.245 | Acc: 32.031,51.562,58.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.265 | Acc: 31.593,50.553,57.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.266 | Acc: 31.685,50.666,58.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 4.041 | Acc: 43.750,60.156,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.145 | Acc: 43.862,63.876,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.164 | Acc: 43.483,64.158,75.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.171 | Acc: 43.340,64.062,75.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.193 | Acc: 43.027,63.850,75.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.231 | Acc: 42.721,63.614,74.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.223 | Acc: 42.975,63.656,74.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.243 | Acc: 42.836,63.508,74.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.251 | Acc: 42.847,63.398,74.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.260 | Acc: 42.775,63.333,74.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.272 | Acc: 42.743,63.184,73.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.281 | Acc: 42.686,63.083,74.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.277 | Acc: 42.690,63.087,73.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.276 | Acc: 42.756,63.138,73.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.271 | Acc: 42.819,63.137,74.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.283 | Acc: 42.701,63.027,73.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.296 | Acc: 42.650,62.870,73.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.298 | Acc: 42.664,62.860,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.311 | Acc: 42.534,62.736,73.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.315 | Acc: 42.596,62.674,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.263 | Acc: 39.062,53.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.725 | Acc: 36.012,51.637,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.786 | Acc: 35.366,51.010,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.810 | Acc: 35.412,50.884,58.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 4.254 | Acc: 40.625,57.031,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.324 | Acc: 42.113,63.170,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.274 | Acc: 42.816,63.567,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.211 | Acc: 43.161,64.165,74.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.225 | Acc: 42.602,63.831,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.239 | Acc: 42.721,63.506,74.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.243 | Acc: 42.885,63.436,74.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.260 | Acc: 42.875,63.292,74.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.247 | Acc: 42.765,63.383,74.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.265 | Acc: 42.658,63.186,74.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.268 | Acc: 42.693,63.064,74.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.273 | Acc: 42.778,62.917,74.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.274 | Acc: 42.755,62.941,73.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.281 | Acc: 42.750,62.907,73.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.284 | Acc: 42.702,62.764,73.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.298 | Acc: 42.553,62.710,73.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.306 | Acc: 42.463,62.661,73.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.312 | Acc: 42.492,62.621,73.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.315 | Acc: 42.527,62.619,73.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.320 | Acc: 42.507,62.576,73.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.426 | Acc: 35.938,57.812,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.195 | Acc: 32.254,49.702,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.164 | Acc: 31.745,49.352,59.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.184 | Acc: 31.519,49.270,59.926,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 3.932 | Acc: 45.312,64.844,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.216 | Acc: 42.448,63.021,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.227 | Acc: 42.588,63.167,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.243 | Acc: 42.546,63.358,74.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.238 | Acc: 42.901,63.310,74.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.252 | Acc: 43.209,63.219,74.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.240 | Acc: 43.414,63.281,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.255 | Acc: 43.218,62.993,73.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.268 | Acc: 42.954,62.878,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.277 | Acc: 42.865,62.668,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.279 | Acc: 42.813,62.741,73.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.276 | Acc: 42.824,62.797,73.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.274 | Acc: 42.901,62.873,73.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.285 | Acc: 42.795,62.826,73.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.289 | Acc: 42.885,62.792,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.293 | Acc: 42.797,62.798,73.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.297 | Acc: 42.784,62.899,73.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.296 | Acc: 42.847,62.935,73.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.301 | Acc: 42.822,62.844,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.310 | Acc: 42.690,62.767,73.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.510 | Acc: 42.188,60.938,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.017 | Acc: 33.333,51.116,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.138 | Acc: 32.984,50.896,58.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.154 | Acc: 32.441,50.333,58.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 4.425 | Acc: 41.406,57.812,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.268 | Acc: 42.188,63.095,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.250 | Acc: 42.340,63.834,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 42.482,63.102,74.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.265 | Acc: 42.892,63.146,75.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.257 | Acc: 42.922,63.219,75.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.260 | Acc: 43.001,63.255,75.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.278 | Acc: 42.886,63.004,74.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.276 | Acc: 42.862,63.107,74.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.278 | Acc: 42.693,63.083,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.289 | Acc: 42.638,62.830,74.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.300 | Acc: 42.675,62.712,74.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.306 | Acc: 42.541,62.701,74.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.309 | Acc: 42.553,62.632,73.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.306 | Acc: 42.596,62.608,73.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.301 | Acc: 42.694,62.734,73.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.299 | Acc: 42.747,62.724,73.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.295 | Acc: 42.836,62.777,73.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.296 | Acc: 42.802,62.755,73.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.301 | Acc: 42.688,62.750,73.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.616 | Acc: 31.250,53.125,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.721 | Acc: 26.376,47.842,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.734 | Acc: 27.134,47.313,55.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.763 | Acc: 26.627,47.182,55.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 3.766 | Acc: 43.750,66.406,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.162 | Acc: 42.783,64.062,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.243 | Acc: 42.130,62.519,75.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.237 | Acc: 42.303,62.679,75.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.214 | Acc: 42.892,63.050,75.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.202 | Acc: 42.830,63.312,75.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.203 | Acc: 42.788,63.527,75.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.230 | Acc: 42.681,63.281,74.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.251 | Acc: 42.605,63.208,74.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.261 | Acc: 42.654,63.130,74.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.275 | Acc: 42.572,62.970,74.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.273 | Acc: 42.707,62.935,74.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.286 | Acc: 42.534,62.853,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.283 | Acc: 42.574,62.877,74.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.293 | Acc: 42.535,62.770,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.295 | Acc: 42.592,62.749,74.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.306 | Acc: 42.635,62.670,73.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.305 | Acc: 42.591,62.695,73.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.307 | Acc: 42.562,62.688,73.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.313 | Acc: 42.569,62.666,73.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.089 | Acc: 28.125,54.688,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.888 | Acc: 27.493,50.112,57.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.931 | Acc: 27.077,49.314,57.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.932 | Acc: 27.344,49.385,57.902,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 3.825 | Acc: 47.656,67.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.241 | Acc: 42.150,63.802,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.284 | Acc: 42.721,62.957,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.276 | Acc: 42.482,62.756,74.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.289 | Acc: 42.014,62.722,74.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.305 | Acc: 41.940,62.500,73.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.301 | Acc: 42.194,62.545,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.299 | Acc: 42.232,62.561,73.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.284 | Acc: 42.503,62.898,74.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.270 | Acc: 42.792,63.044,74.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.273 | Acc: 42.926,63.048,74.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.279 | Acc: 42.788,62.928,74.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.286 | Acc: 42.761,62.879,73.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.298 | Acc: 42.789,62.790,73.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.301 | Acc: 42.771,62.778,73.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.303 | Acc: 42.779,62.705,73.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.304 | Acc: 42.879,62.748,73.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.308 | Acc: 42.751,62.711,73.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.306 | Acc: 42.752,62.688,73.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.305 | Acc: 42.708,62.666,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.270 | Acc: 17.969,37.500,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.215 | Acc: 21.205,37.946,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.336 | Acc: 20.655,37.481,51.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.382 | Acc: 20.594,37.410,51.652,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 4.602 | Acc: 36.719,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.170 | Acc: 42.969,64.062,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.205 | Acc: 42.378,64.120,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.204 | Acc: 42.725,63.960,75.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.208 | Acc: 43.191,64.198,75.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.206 | Acc: 43.379,64.240,75.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.196 | Acc: 43.369,64.211,75.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.210 | Acc: 43.196,63.896,74.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.216 | Acc: 43.134,63.859,74.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.229 | Acc: 42.990,63.825,74.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.246 | Acc: 43.008,63.584,74.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.267 | Acc: 42.930,63.366,73.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.266 | Acc: 42.927,63.382,73.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.271 | Acc: 42.915,63.317,73.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.276 | Acc: 42.972,63.201,73.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.292 | Acc: 42.919,63.105,73.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.294 | Acc: 42.993,63.099,73.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.302 | Acc: 42.928,62.972,73.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.309 | Acc: 42.787,62.896,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.307 | Acc: 42.846,62.920,73.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.426 | Acc: 33.594,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.446 | Acc: 32.924,48.214,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.382 | Acc: 32.984,48.952,57.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.401 | Acc: 32.800,48.963,57.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 3.871 | Acc: 51.562,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.160 | Acc: 43.899,62.798,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.231 | Acc: 42.530,63.110,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.221 | Acc: 42.520,63.307,75.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.237 | Acc: 42.737,63.146,74.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.221 | Acc: 42.752,63.598,74.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.223 | Acc: 42.678,63.404,74.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.219 | Acc: 42.758,63.481,74.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.224 | Acc: 42.896,63.373,74.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.243 | Acc: 42.835,63.169,74.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.252 | Acc: 42.802,63.060,74.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.261 | Acc: 42.827,63.094,74.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.273 | Acc: 42.891,63.054,73.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.269 | Acc: 42.954,63.051,73.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.275 | Acc: 42.846,62.956,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.281 | Acc: 42.870,62.884,73.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.291 | Acc: 42.764,62.804,73.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.296 | Acc: 42.714,62.750,73.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.300 | Acc: 42.726,62.708,73.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.303 | Acc: 42.690,62.685,73.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.520 | Acc: 32.031,50.781,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.744 | Acc: 33.854,52.381,61.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.796 | Acc: 33.651,52.268,61.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.843 | Acc: 33.133,51.998,60.771,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.175 | Acc: 39.062,65.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.140 | Acc: 42.485,64.918,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.135 | Acc: 43.293,64.863,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.129 | Acc: 43.455,64.536,76.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.158 | Acc: 43.644,64.400,75.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.185 | Acc: 43.704,64.001,75.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.185 | Acc: 43.524,64.024,75.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.185 | Acc: 43.667,63.869,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.193 | Acc: 43.677,63.810,74.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.211 | Acc: 43.383,63.678,74.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.210 | Acc: 43.501,63.790,74.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.220 | Acc: 43.347,63.660,74.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.234 | Acc: 43.299,63.479,74.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.241 | Acc: 43.301,63.335,74.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.245 | Acc: 43.241,63.367,74.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.246 | Acc: 43.236,63.372,74.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.260 | Acc: 43.178,63.281,74.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.264 | Acc: 43.120,63.270,73.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.279 | Acc: 43.027,63.078,73.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.288 | Acc: 42.901,62.961,73.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.143 | Acc: 27.344,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.254 | Acc: 31.845,50.409,60.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.233 | Acc: 31.460,50.438,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.289 | Acc: 30.879,49.898,59.362,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 4.418 | Acc: 42.188,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.267 | Acc: 42.820,64.100,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.195 | Acc: 43.636,64.939,76.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.142 | Acc: 44.045,65.074,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.149 | Acc: 43.866,64.728,75.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.158 | Acc: 43.526,64.341,75.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.190 | Acc: 43.298,64.095,75.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.197 | Acc: 43.262,63.830,75.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.217 | Acc: 42.877,63.495,74.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.220 | Acc: 42.926,63.583,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.239 | Acc: 42.763,63.375,74.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.248 | Acc: 42.661,63.363,74.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.257 | Acc: 42.583,63.288,74.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.260 | Acc: 42.636,63.239,74.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.255 | Acc: 42.835,63.281,74.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.261 | Acc: 42.810,63.159,74.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.267 | Acc: 42.730,63.143,74.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.275 | Acc: 42.687,63.107,73.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.273 | Acc: 42.776,63.167,73.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.278 | Acc: 42.809,63.101,73.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.294 | Acc: 31.250,55.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.604 | Acc: 28.720,47.954,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.578 | Acc: 29.421,48.228,57.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.583 | Acc: 29.162,48.105,57.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 4.349 | Acc: 46.875,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.169 | Acc: 43.936,63.914,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.138 | Acc: 44.169,64.482,76.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.159 | Acc: 43.981,64.498,75.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.185 | Acc: 43.798,64.159,75.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.219 | Acc: 43.332,63.583,74.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.254 | Acc: 42.936,63.133,74.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.253 | Acc: 42.803,63.154,74.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.253 | Acc: 42.741,63.218,74.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.258 | Acc: 42.818,63.117,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.260 | Acc: 42.891,63.067,74.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.261 | Acc: 42.831,63.090,74.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.260 | Acc: 42.907,63.168,74.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.266 | Acc: 42.867,63.108,73.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.259 | Acc: 42.938,63.192,74.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.265 | Acc: 42.899,63.138,73.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.265 | Acc: 42.954,63.147,73.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.267 | Acc: 42.992,63.167,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.278 | Acc: 42.980,63.065,73.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.293 | Acc: 42.848,62.968,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.388 | Acc: 25.781,48.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.293 | Acc: 30.952,49.033,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.353 | Acc: 30.945,48.323,57.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.373 | Acc: 30.866,48.040,57.415,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 4.097 | Acc: 39.844,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.131 | Acc: 43.006,63.318,76.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.166 | Acc: 42.702,64.082,75.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.170 | Acc: 42.764,64.075,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.210 | Acc: 42.631,63.696,75.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.219 | Acc: 42.783,63.629,75.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.236 | Acc: 42.678,63.559,75.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.231 | Acc: 42.764,63.725,75.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.226 | Acc: 42.896,63.766,75.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.231 | Acc: 42.857,63.898,74.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.237 | Acc: 42.899,63.783,74.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.254 | Acc: 42.863,63.663,74.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.260 | Acc: 42.884,63.544,74.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.259 | Acc: 42.891,63.476,74.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.263 | Acc: 42.905,63.495,74.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.277 | Acc: 42.808,63.344,74.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.285 | Acc: 42.774,63.237,73.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.295 | Acc: 42.717,63.089,73.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.298 | Acc: 42.767,63.128,73.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.296 | Acc: 42.831,63.109,73.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.929 | Acc: 35.156,53.906,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.404 | Acc: 31.622,47.247,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.513 | Acc: 30.621,46.875,57.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.498 | Acc: 30.149,47.554,57.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 4.156 | Acc: 44.531,65.625,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.210 | Acc: 43.750,62.463,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.216 | Acc: 43.064,62.729,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.227 | Acc: 42.687,62.999,74.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.238 | Acc: 42.679,63.021,74.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.256 | Acc: 42.597,63.142,74.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.251 | Acc: 42.730,63.346,74.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.228 | Acc: 43.046,63.564,74.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.247 | Acc: 42.935,63.145,74.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.261 | Acc: 42.857,62.871,74.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.283 | Acc: 42.650,62.605,73.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.292 | Acc: 42.605,62.408,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.291 | Acc: 42.615,62.588,73.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.294 | Acc: 42.544,62.581,73.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.295 | Acc: 42.605,62.633,73.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.301 | Acc: 42.530,62.547,73.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.294 | Acc: 42.669,62.695,73.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.298 | Acc: 42.694,62.674,73.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.299 | Acc: 42.767,62.719,73.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.297 | Acc: 42.751,62.752,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.579 | Acc: 28.125,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.796 | Acc: 29.018,45.275,56.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.718 | Acc: 30.183,45.732,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.734 | Acc: 29.713,45.697,55.635,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 4.236 | Acc: 41.406,63.281,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.129 | Acc: 43.824,64.100,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.142 | Acc: 43.883,63.910,75.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.126 | Acc: 43.878,64.139,75.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.155 | Acc: 43.798,64.034,75.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.175 | Acc: 43.595,63.977,75.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.186 | Acc: 43.304,63.933,75.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.200 | Acc: 43.196,63.857,75.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.215 | Acc: 43.274,63.665,75.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.226 | Acc: 43.202,63.596,74.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.237 | Acc: 43.113,63.503,74.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.244 | Acc: 43.004,63.405,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.252 | Acc: 42.985,63.366,74.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.259 | Acc: 42.972,63.150,74.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.261 | Acc: 42.838,63.156,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.267 | Acc: 42.805,63.079,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.274 | Acc: 42.752,62.868,73.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.273 | Acc: 42.769,62.857,73.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.275 | Acc: 42.865,62.883,73.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.275 | Acc: 42.897,62.951,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.201 | Acc: 25.781,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.988 | Acc: 25.186,44.754,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.977 | Acc: 25.514,44.531,56.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.046 | Acc: 25.128,43.993,56.545,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 4.322 | Acc: 35.156,59.375,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.122 | Acc: 43.601,64.732,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.958 | Acc: 44.741,66.044,77.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.924 | Acc: 44.941,66.726,78.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.859 | Acc: 45.409,67.564,78.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.797 | Acc: 45.815,68.518,79.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.778 | Acc: 45.771,68.937,79.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.728 | Acc: 46.022,69.520,80.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.705 | Acc: 46.390,69.973,80.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.686 | Acc: 46.612,70.045,80.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.668 | Acc: 46.727,70.169,80.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.668 | Acc: 46.645,70.153,80.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.667 | Acc: 46.577,70.235,80.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.656 | Acc: 46.710,70.298,81.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.650 | Acc: 46.655,70.332,81.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.639 | Acc: 46.691,70.471,81.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.628 | Acc: 46.724,70.556,81.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.622 | Acc: 46.802,70.613,81.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.616 | Acc: 46.866,70.704,81.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.614 | Acc: 46.934,70.649,81.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.114 | Acc: 45.312,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.399 | Acc: 44.234,62.240,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.400 | Acc: 44.093,62.633,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.413 | Acc: 44.185,62.756,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.308 | Acc: 52.344,71.875,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.423 | Acc: 47.693,72.582,84.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.412 | Acc: 47.732,72.618,84.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.435 | Acc: 47.656,72.170,84.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.442 | Acc: 47.724,72.290,84.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.417 | Acc: 48.043,72.269,84.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.415 | Acc: 48.037,72.224,84.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.414 | Acc: 47.878,72.146,84.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.418 | Acc: 47.909,72.025,84.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.421 | Acc: 47.838,72.048,84.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.424 | Acc: 47.823,71.926,84.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.436 | Acc: 47.748,71.719,84.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.434 | Acc: 47.750,71.729,84.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.429 | Acc: 47.848,71.818,84.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.424 | Acc: 47.965,71.883,84.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.426 | Acc: 47.991,71.904,84.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.427 | Acc: 48.038,71.924,84.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.418 | Acc: 48.066,72.072,84.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.424 | Acc: 47.964,72.059,84.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.422 | Acc: 48.029,72.152,84.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.066 | Acc: 47.656,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.333 | Acc: 45.871,62.574,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.348 | Acc: 45.217,62.995,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.371 | Acc: 44.903,63.166,70.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.454 | Acc: 42.188,71.094,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.407 | Acc: 46.726,72.247,84.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.342 | Acc: 48.571,72.409,85.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.330 | Acc: 48.642,72.823,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.327 | Acc: 48.659,73.139,85.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.341 | Acc: 48.507,73.058,85.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.353 | Acc: 48.431,72.921,85.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.352 | Acc: 48.393,72.856,85.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.354 | Acc: 48.282,72.826,85.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.351 | Acc: 48.325,72.855,85.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.358 | Acc: 48.150,72.785,85.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.351 | Acc: 48.187,72.819,85.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.347 | Acc: 48.194,72.828,85.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.350 | Acc: 48.177,72.860,85.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.351 | Acc: 48.179,72.809,85.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.355 | Acc: 48.129,72.757,85.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.350 | Acc: 48.141,72.780,85.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.353 | Acc: 48.128,72.697,85.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.354 | Acc: 48.083,72.704,85.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.353 | Acc: 48.058,72.728,85.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.976 | Acc: 48.438,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 45.201,63.690,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.339 | Acc: 44.798,63.624,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.349 | Acc: 44.915,63.627,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 3.213 | Acc: 50.000,73.438,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.283 | Acc: 49.479,74.033,85.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.308 | Acc: 48.761,73.037,85.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.296 | Acc: 48.514,73.194,85.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.291 | Acc: 48.640,73.167,85.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.296 | Acc: 48.708,73.051,85.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.297 | Acc: 48.599,72.960,85.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.296 | Acc: 48.537,73.133,85.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.297 | Acc: 48.530,73.040,85.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.303 | Acc: 48.377,73.006,85.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.305 | Acc: 48.189,72.983,85.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.303 | Acc: 48.123,73.063,85.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.303 | Acc: 48.168,73.074,85.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.304 | Acc: 48.165,73.030,85.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.308 | Acc: 48.115,72.970,85.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.314 | Acc: 48.118,72.944,85.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.312 | Acc: 48.138,72.982,85.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.316 | Acc: 48.179,72.966,85.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.312 | Acc: 48.182,73.015,85.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.309 | Acc: 48.152,73.052,85.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.059 | Acc: 48.438,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.317 | Acc: 46.019,63.876,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.345 | Acc: 45.198,63.853,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.355 | Acc: 45.248,63.653,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.833 | Acc: 51.562,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.285 | Acc: 49.628,73.438,86.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.290 | Acc: 49.943,72.580,86.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.265 | Acc: 49.846,73.476,86.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.243 | Acc: 49.691,73.939,86.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.232 | Acc: 49.675,73.933,86.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.242 | Acc: 49.438,73.709,86.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.248 | Acc: 49.341,73.559,86.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.249 | Acc: 49.141,73.510,86.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.251 | Acc: 49.059,73.420,86.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.255 | Acc: 48.970,73.364,86.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.254 | Acc: 49.010,73.413,86.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.250 | Acc: 49.096,73.470,86.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.259 | Acc: 48.958,73.420,86.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.260 | Acc: 48.927,73.476,86.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.265 | Acc: 48.845,73.450,86.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.273 | Acc: 48.768,73.318,86.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.268 | Acc: 48.827,73.410,86.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.263 | Acc: 48.892,73.470,86.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.265 | Acc: 48.794,73.450,86.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.076 | Acc: 45.312,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.368 | Acc: 44.978,63.393,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.393 | Acc: 44.970,63.681,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.411 | Acc: 44.839,63.730,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.464 | Acc: 48.438,68.750,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.187 | Acc: 48.661,73.512,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.222 | Acc: 48.895,73.742,86.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.214 | Acc: 49.052,73.553,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.235 | Acc: 48.630,73.476,87.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.251 | Acc: 48.383,73.399,86.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.244 | Acc: 48.373,73.528,87.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.250 | Acc: 48.310,73.449,86.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.243 | Acc: 48.554,73.598,87.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.237 | Acc: 48.627,73.718,86.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.236 | Acc: 48.675,73.830,87.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.239 | Acc: 48.635,73.802,86.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.239 | Acc: 48.632,73.758,86.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.233 | Acc: 48.689,73.836,86.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.235 | Acc: 48.757,73.743,87.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.234 | Acc: 48.733,73.728,87.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.235 | Acc: 48.815,73.747,86.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.232 | Acc: 48.848,73.724,86.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.233 | Acc: 48.818,73.658,86.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.236 | Acc: 48.782,73.612,86.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.120 | Acc: 47.656,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.315 | Acc: 45.722,63.244,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.355 | Acc: 45.503,63.567,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.364 | Acc: 45.428,63.781,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 3.013 | Acc: 47.656,76.562,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.162 | Acc: 50.372,74.851,87.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.191 | Acc: 49.428,74.314,87.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.181 | Acc: 49.206,74.103,87.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.186 | Acc: 49.363,74.161,87.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.193 | Acc: 49.196,73.979,87.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.204 | Acc: 49.199,73.967,86.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.219 | Acc: 49.008,73.787,86.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.215 | Acc: 49.117,73.777,86.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.220 | Acc: 49.033,73.714,86.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.216 | Acc: 49.044,73.799,86.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.219 | Acc: 49.000,73.738,86.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.214 | Acc: 49.024,73.872,86.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.221 | Acc: 48.943,73.913,86.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.222 | Acc: 48.832,73.946,86.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.222 | Acc: 48.827,73.964,86.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.219 | Acc: 48.837,73.944,86.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.219 | Acc: 48.939,73.932,86.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.213 | Acc: 48.957,74.048,87.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.213 | Acc: 48.967,74.034,87.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.188 | Acc: 49.219,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.348 | Acc: 45.685,63.802,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.388 | Acc: 44.989,63.986,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.390 | Acc: 44.864,63.717,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.319 | Acc: 46.875,73.438,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.115 | Acc: 49.368,75.632,87.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.168 | Acc: 48.933,74.771,87.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.162 | Acc: 49.014,74.654,87.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.157 | Acc: 49.132,74.373,87.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.166 | Acc: 49.118,74.149,87.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.169 | Acc: 49.070,74.335,87.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.174 | Acc: 49.174,74.346,87.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.170 | Acc: 49.141,74.408,87.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.168 | Acc: 49.094,74.486,87.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.168 | Acc: 49.176,74.499,87.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.176 | Acc: 49.095,74.509,87.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.178 | Acc: 49.102,74.465,87.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.175 | Acc: 49.153,74.575,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.185 | Acc: 48.999,74.436,87.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.182 | Acc: 49.055,74.406,87.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.182 | Acc: 49.068,74.375,87.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.176 | Acc: 49.148,74.402,87.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.181 | Acc: 49.080,74.316,87.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.183 | Acc: 49.040,74.317,87.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.040 | Acc: 48.438,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.342 | Acc: 44.792,64.323,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.388 | Acc: 44.912,64.501,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.395 | Acc: 44.928,64.139,70.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 2.501 | Acc: 58.594,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.143 | Acc: 48.475,73.921,88.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.144 | Acc: 49.085,74.295,88.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.167 | Acc: 48.361,74.065,87.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.168 | Acc: 48.302,73.968,87.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.139 | Acc: 48.925,74.474,88.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.165 | Acc: 48.864,74.303,87.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.161 | Acc: 48.936,74.440,87.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.173 | Acc: 48.816,74.316,87.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.176 | Acc: 48.787,74.189,88.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.173 | Acc: 48.896,74.192,88.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.175 | Acc: 48.798,74.169,88.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.167 | Acc: 48.872,74.258,87.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.169 | Acc: 48.937,74.234,87.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.171 | Acc: 48.874,74.188,87.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.170 | Acc: 48.905,74.240,87.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.162 | Acc: 48.983,74.294,87.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.170 | Acc: 48.964,74.262,87.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.170 | Acc: 48.929,74.301,87.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.168 | Acc: 48.928,74.250,87.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.053 | Acc: 48.438,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.362 | Acc: 44.643,63.281,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.402 | Acc: 44.760,63.243,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.413 | Acc: 44.839,63.358,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 2.791 | Acc: 53.906,77.344,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.025 | Acc: 50.037,75.037,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.070 | Acc: 50.362,74.752,88.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.098 | Acc: 50.000,74.641,88.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.106 | Acc: 49.614,74.788,88.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.119 | Acc: 49.242,74.745,88.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.123 | Acc: 49.477,74.651,88.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.141 | Acc: 49.307,74.474,88.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.142 | Acc: 49.093,74.457,88.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.161 | Acc: 48.930,74.348,88.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.177 | Acc: 48.842,74.164,87.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.175 | Acc: 48.837,74.183,87.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.170 | Acc: 48.901,74.180,87.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.165 | Acc: 48.964,74.252,87.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.155 | Acc: 49.035,74.447,87.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.158 | Acc: 48.933,74.437,87.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.158 | Acc: 48.980,74.486,87.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.160 | Acc: 48.937,74.462,87.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.161 | Acc: 48.953,74.474,87.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.162 | Acc: 49.001,74.395,87.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.037 | Acc: 49.219,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.310 | Acc: 45.424,63.728,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.359 | Acc: 45.065,63.529,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.374 | Acc: 45.018,63.614,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 2.810 | Acc: 54.688,80.469,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.091 | Acc: 49.516,74.628,88.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.126 | Acc: 48.666,74.276,88.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.110 | Acc: 48.796,74.398,88.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.103 | Acc: 48.852,74.556,88.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.113 | Acc: 48.801,74.652,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.126 | Acc: 48.657,74.380,88.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.122 | Acc: 48.609,74.407,88.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.126 | Acc: 48.510,74.447,88.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.123 | Acc: 48.507,74.538,88.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.118 | Acc: 48.780,74.592,88.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.116 | Acc: 48.894,74.608,88.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.117 | Acc: 48.856,74.592,88.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.119 | Acc: 48.973,74.578,88.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.123 | Acc: 48.974,74.508,88.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.123 | Acc: 49.006,74.496,88.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.126 | Acc: 49.068,74.472,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.129 | Acc: 49.065,74.446,88.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.131 | Acc: 49.089,74.433,88.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.130 | Acc: 49.098,74.444,88.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.196 | Acc: 44.531,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.376 | Acc: 44.531,63.281,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.429 | Acc: 44.588,62.919,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.441 | Acc: 44.390,63.268,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 3.144 | Acc: 47.656,75.781,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.178 | Acc: 49.330,73.549,87.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.146 | Acc: 48.914,74.314,88.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.155 | Acc: 48.758,74.283,88.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.122 | Acc: 49.035,74.547,88.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.104 | Acc: 49.528,74.783,88.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.106 | Acc: 49.626,74.864,88.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.107 | Acc: 49.357,74.856,88.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.093 | Acc: 49.505,75.058,88.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.093 | Acc: 49.521,75.043,88.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.099 | Acc: 49.460,75.008,88.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.097 | Acc: 49.449,74.922,88.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.103 | Acc: 49.472,74.922,88.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.104 | Acc: 49.524,74.862,88.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.108 | Acc: 49.361,74.755,88.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.108 | Acc: 49.336,74.764,88.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.111 | Acc: 49.394,74.664,88.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.115 | Acc: 49.384,74.675,88.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.117 | Acc: 49.357,74.684,88.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.123 | Acc: 49.317,74.619,88.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.161 | Acc: 42.188,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.365 | Acc: 44.866,64.360,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.407 | Acc: 44.722,64.196,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.426 | Acc: 44.647,63.858,70.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 3.263 | Acc: 49.219,69.531,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.040 | Acc: 50.298,74.777,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.073 | Acc: 49.581,75.152,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.085 | Acc: 49.232,75.077,88.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.077 | Acc: 48.978,75.019,88.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.070 | Acc: 49.211,75.085,88.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.082 | Acc: 49.064,74.981,88.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.076 | Acc: 49.202,75.055,88.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.087 | Acc: 49.161,74.719,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.083 | Acc: 49.409,74.806,88.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.078 | Acc: 49.499,74.895,88.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.089 | Acc: 49.399,74.816,88.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.092 | Acc: 49.429,74.793,88.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.097 | Acc: 49.350,74.767,88.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.097 | Acc: 49.372,74.778,88.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.099 | Acc: 49.411,74.673,88.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.099 | Acc: 49.465,74.589,88.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.093 | Acc: 49.496,74.686,88.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.097 | Acc: 49.427,74.649,88.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.099 | Acc: 49.356,74.582,88.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.123 | Acc: 43.750,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.357 | Acc: 45.685,63.728,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.387 | Acc: 45.484,63.872,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.403 | Acc: 45.338,63.934,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 3.100 | Acc: 49.219,77.344,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.046 | Acc: 49.851,75.372,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.040 | Acc: 49.657,75.343,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.051 | Acc: 49.654,75.218,89.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.062 | Acc: 49.701,75.145,89.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.072 | Acc: 49.613,75.093,89.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.058 | Acc: 49.619,75.174,89.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.059 | Acc: 49.612,75.100,89.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.064 | Acc: 49.539,74.932,89.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.074 | Acc: 49.253,74.840,89.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.074 | Acc: 49.254,74.689,89.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.082 | Acc: 49.251,74.742,89.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.086 | Acc: 49.209,74.822,89.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.084 | Acc: 49.210,74.811,89.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.087 | Acc: 49.110,74.800,89.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.088 | Acc: 49.120,74.779,89.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.086 | Acc: 49.126,74.766,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.091 | Acc: 49.070,74.746,89.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.092 | Acc: 49.115,74.729,89.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.090 | Acc: 49.098,74.699,89.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.170 | Acc: 50.000,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.383 | Acc: 45.089,63.839,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.440 | Acc: 44.874,63.491,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.462 | Acc: 44.659,63.576,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 2.834 | Acc: 44.531,76.562,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.981 | Acc: 49.293,75.521,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.058 | Acc: 48.704,74.600,89.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.065 | Acc: 48.540,74.872,89.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.068 | Acc: 49.045,74.875,89.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.063 | Acc: 48.994,75.000,89.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.069 | Acc: 48.889,75.058,89.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.051 | Acc: 49.064,75.321,89.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.077 | Acc: 48.937,75.136,89.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.075 | Acc: 48.994,75.065,89.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.078 | Acc: 48.962,75.016,89.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.081 | Acc: 49.010,74.975,89.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.081 | Acc: 49.073,74.968,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.079 | Acc: 49.117,75.012,89.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.071 | Acc: 49.288,75.131,89.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.072 | Acc: 49.341,75.125,89.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.074 | Acc: 49.396,75.083,89.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.077 | Acc: 49.322,75.025,89.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.078 | Acc: 49.364,75.063,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.077 | Acc: 49.405,75.084,89.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.197 | Acc: 48.438,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.344 | Acc: 45.499,63.988,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.400 | Acc: 45.446,64.120,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.417 | Acc: 45.120,64.011,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 3.160 | Acc: 48.438,75.000,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.998 | Acc: 49.628,75.484,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.014 | Acc: 49.752,75.343,89.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.021 | Acc: 49.846,75.192,89.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.042 | Acc: 49.383,75.058,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.041 | Acc: 49.559,75.263,89.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.046 | Acc: 49.451,75.090,89.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.048 | Acc: 49.346,74.994,89.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.050 | Acc: 49.287,75.073,89.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.059 | Acc: 49.279,75.000,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.058 | Acc: 49.359,74.918,89.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.063 | Acc: 49.243,74.972,89.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.069 | Acc: 49.219,74.903,89.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.073 | Acc: 49.189,74.841,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.077 | Acc: 49.197,74.808,89.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.076 | Acc: 49.286,74.795,89.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.080 | Acc: 49.211,74.713,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.077 | Acc: 49.299,74.785,89.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.077 | Acc: 49.271,74.816,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.072 | Acc: 49.309,74.844,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.078 | Acc: 50.000,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.423 | Acc: 45.126,63.951,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.456 | Acc: 44.874,63.910,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.466 | Acc: 44.890,63.870,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 2.747 | Acc: 52.344,73.438,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.089 | Acc: 49.182,75.074,89.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.086 | Acc: 49.600,74.466,89.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.060 | Acc: 49.616,74.603,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.045 | Acc: 49.421,75.135,89.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.051 | Acc: 49.559,74.977,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.066 | Acc: 49.509,74.845,89.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.060 | Acc: 49.535,74.939,89.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.059 | Acc: 49.481,75.019,89.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.059 | Acc: 49.335,75.043,89.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.052 | Acc: 49.351,75.117,89.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.046 | Acc: 49.491,75.117,89.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.046 | Acc: 49.559,75.075,89.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.052 | Acc: 49.575,75.021,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.057 | Acc: 49.483,74.961,89.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.064 | Acc: 49.471,74.886,89.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.059 | Acc: 49.572,74.905,89.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.060 | Acc: 49.597,74.915,89.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.058 | Acc: 49.550,74.965,89.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.058 | Acc: 49.561,75.008,89.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.059 | Acc: 46.875,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.360 | Acc: 45.610,63.839,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.392 | Acc: 45.332,63.986,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.409 | Acc: 45.159,64.050,69.813,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 2.848 | Acc: 42.969,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.030 | Acc: 50.298,74.740,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.047 | Acc: 50.229,75.343,89.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.059 | Acc: 49.769,74.987,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.049 | Acc: 49.740,74.875,89.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.056 | Acc: 49.443,74.954,89.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.059 | Acc: 49.206,74.955,89.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.062 | Acc: 49.180,74.762,89.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.055 | Acc: 49.248,74.888,89.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.067 | Acc: 49.327,74.737,89.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.051 | Acc: 49.545,74.938,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.042 | Acc: 49.685,75.074,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.040 | Acc: 49.789,75.136,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.048 | Acc: 49.614,75.000,89.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.049 | Acc: 49.611,74.983,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.057 | Acc: 49.509,74.969,89.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.052 | Acc: 49.586,75.029,89.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.052 | Acc: 49.599,74.977,89.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.053 | Acc: 49.511,74.916,89.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.051 | Acc: 49.543,74.975,89.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.156 | Acc: 46.875,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.389 | Acc: 45.647,63.914,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.446 | Acc: 45.293,63.948,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.475 | Acc: 44.928,63.806,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.861 | Acc: 49.219,77.344,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.904 | Acc: 51.749,76.972,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.964 | Acc: 50.877,76.200,90.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.982 | Acc: 50.269,76.140,90.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.995 | Acc: 50.405,76.042,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.014 | Acc: 50.155,75.704,89.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.015 | Acc: 50.013,75.723,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.024 | Acc: 49.906,75.604,89.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.026 | Acc: 49.825,75.456,89.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.028 | Acc: 49.810,75.341,89.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.028 | Acc: 49.724,75.470,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.027 | Acc: 49.710,75.615,89.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.033 | Acc: 49.605,75.577,89.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.035 | Acc: 49.446,75.578,89.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.034 | Acc: 49.491,75.581,89.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.037 | Acc: 49.515,75.488,89.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.039 | Acc: 49.482,75.492,89.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.039 | Acc: 49.489,75.470,89.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.039 | Acc: 49.500,75.478,89.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.042 | Acc: 49.498,75.470,89.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.106 | Acc: 48.438,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.425 | Acc: 45.126,63.430,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.503 | Acc: 44.531,63.396,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.515 | Acc: 44.403,63.384,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 2.756 | Acc: 53.906,78.906,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.939 | Acc: 49.405,77.009,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.948 | Acc: 50.762,77.153,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.964 | Acc: 50.359,76.780,90.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.923 | Acc: 50.395,77.344,90.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.944 | Acc: 50.209,76.818,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.957 | Acc: 50.084,76.627,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.965 | Acc: 50.000,76.452,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.962 | Acc: 50.029,76.475,90.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.967 | Acc: 50.009,76.442,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.979 | Acc: 49.837,76.158,90.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.984 | Acc: 49.820,76.011,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.993 | Acc: 49.812,75.869,90.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.995 | Acc: 49.814,75.790,90.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.995 | Acc: 49.839,75.756,90.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.990 | Acc: 49.927,75.807,90.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.996 | Acc: 49.847,75.730,90.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.001 | Acc: 49.803,75.738,90.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.009 | Acc: 49.704,75.615,89.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.012 | Acc: 49.735,75.574,89.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.240 | Acc: 48.438,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.428 | Acc: 45.052,63.430,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.479 | Acc: 44.703,63.396,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.487 | Acc: 45.210,63.358,69.390,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 2.764 | Acc: 55.469,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.964 | Acc: 50.595,76.674,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.986 | Acc: 49.848,76.124,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 50.051,75.679,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.972 | Acc: 49.904,75.955,90.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.975 | Acc: 50.077,76.098,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.993 | Acc: 49.884,75.846,90.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.995 | Acc: 49.928,75.898,90.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.001 | Acc: 49.903,75.873,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.999 | Acc: 49.961,75.876,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.004 | Acc: 49.833,75.723,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.013 | Acc: 49.646,75.619,90.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.020 | Acc: 49.523,75.564,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.011 | Acc: 49.719,75.644,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.007 | Acc: 49.853,75.709,90.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.010 | Acc: 49.761,75.620,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.007 | Acc: 49.747,75.669,90.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.010 | Acc: 49.803,75.603,89.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.010 | Acc: 49.868,75.636,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.012 | Acc: 49.826,75.543,89.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.126 | Acc: 50.781,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.380 | Acc: 46.466,64.249,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.446 | Acc: 45.789,63.872,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.459 | Acc: 45.825,63.768,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 2.739 | Acc: 53.906,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.890 | Acc: 50.521,76.897,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.002 | Acc: 49.009,76.067,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.991 | Acc: 49.424,76.511,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.982 | Acc: 49.498,76.437,90.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.999 | Acc: 49.412,75.913,90.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.994 | Acc: 49.580,75.988,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.997 | Acc: 49.596,75.848,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.001 | Acc: 49.670,75.694,90.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.007 | Acc: 49.594,75.587,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.006 | Acc: 49.526,75.525,90.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.013 | Acc: 49.523,75.484,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.009 | Acc: 49.595,75.486,90.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.016 | Acc: 49.536,75.434,90.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.014 | Acc: 49.513,75.428,90.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.014 | Acc: 49.520,75.498,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.002 | Acc: 49.688,75.655,90.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.000 | Acc: 49.670,75.655,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.004 | Acc: 49.623,75.586,90.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.006 | Acc: 49.565,75.580,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.226 | Acc: 45.312,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.460 | Acc: 44.940,64.435,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.500 | Acc: 44.874,63.910,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.511 | Acc: 44.749,63.665,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 2.890 | Acc: 51.562,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.893 | Acc: 49.554,75.149,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.981 | Acc: 49.352,75.572,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.965 | Acc: 50.038,75.897,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.983 | Acc: 49.778,75.704,91.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.993 | Acc: 49.706,75.719,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.996 | Acc: 49.671,75.846,90.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.991 | Acc: 49.629,75.826,90.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.990 | Acc: 49.520,75.733,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.997 | Acc: 49.366,75.561,90.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.994 | Acc: 49.452,75.622,90.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.003 | Acc: 49.427,75.551,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.001 | Acc: 49.507,75.561,90.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.998 | Acc: 49.608,75.650,90.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.001 | Acc: 49.547,75.670,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.999 | Acc: 49.613,75.631,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.996 | Acc: 49.667,75.694,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.998 | Acc: 49.700,75.740,90.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.999 | Acc: 49.623,75.645,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.000 | Acc: 49.594,75.668,90.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.187 | Acc: 44.531,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 45.052,63.281,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.565 | Acc: 44.912,63.548,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 44.621,63.409,69.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.695 | Acc: 51.562,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.974 | Acc: 49.256,76.116,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.979 | Acc: 49.581,75.877,90.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.967 | Acc: 49.372,76.063,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.966 | Acc: 49.325,76.128,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.960 | Acc: 49.513,76.153,90.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.981 | Acc: 49.464,76.027,90.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.987 | Acc: 49.374,75.887,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.991 | Acc: 49.408,75.941,90.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.998 | Acc: 49.340,75.799,90.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.987 | Acc: 49.526,75.976,90.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.986 | Acc: 49.498,75.951,90.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.987 | Acc: 49.533,75.872,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.986 | Acc: 49.686,75.847,90.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.979 | Acc: 49.736,75.895,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.979 | Acc: 49.759,75.880,90.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.988 | Acc: 49.725,75.832,90.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.985 | Acc: 49.762,75.880,90.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.991 | Acc: 49.675,75.829,90.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.996 | Acc: 49.625,75.843,90.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.493 | Acc: 38.281,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.516 | Acc: 44.978,63.802,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.553 | Acc: 44.970,64.139,68.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 44.698,64.075,68.596,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 3.065 | Acc: 46.875,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.063 | Acc: 48.810,75.000,89.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.991 | Acc: 49.333,76.067,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.974 | Acc: 49.808,76.358,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.960 | Acc: 50.154,76.379,90.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.950 | Acc: 50.131,76.516,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.961 | Acc: 50.006,76.304,90.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.959 | Acc: 50.061,76.330,90.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.973 | Acc: 49.767,76.034,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.979 | Acc: 49.789,75.997,90.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.982 | Acc: 49.705,75.812,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.976 | Acc: 49.760,75.838,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.983 | Acc: 49.741,75.775,90.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.986 | Acc: 49.695,75.754,90.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.979 | Acc: 49.833,75.820,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.980 | Acc: 49.818,75.779,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.975 | Acc: 49.922,75.801,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.978 | Acc: 49.911,75.777,90.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.972 | Acc: 50.080,75.881,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.976 | Acc: 49.957,75.855,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 42.969,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.634 | Acc: 43.564,62.798,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.676 | Acc: 43.159,63.224,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.707 | Acc: 42.687,63.102,68.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 2.965 | Acc: 56.250,69.531,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.032 | Acc: 48.326,74.107,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 48.857,74.809,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.007 | Acc: 48.809,74.987,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.991 | Acc: 49.363,75.260,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.980 | Acc: 49.590,75.193,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.972 | Acc: 49.735,75.420,90.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.948 | Acc: 50.044,75.770,90.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.949 | Acc: 50.112,75.873,90.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.957 | Acc: 50.134,75.764,90.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.951 | Acc: 50.288,75.878,90.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.956 | Acc: 50.237,75.855,90.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.954 | Acc: 50.266,75.963,90.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.955 | Acc: 50.242,75.958,90.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.963 | Acc: 50.225,75.873,90.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.967 | Acc: 50.158,75.831,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.967 | Acc: 50.165,75.837,90.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.968 | Acc: 50.160,75.777,90.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.970 | Acc: 50.054,75.781,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.975 | Acc: 49.932,75.730,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.172 | Acc: 50.781,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.468 | Acc: 45.126,64.286,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.513 | Acc: 45.084,64.177,68.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.532 | Acc: 45.159,63.986,68.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 2.865 | Acc: 53.125,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.978 | Acc: 48.958,75.893,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.915 | Acc: 49.924,76.753,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.933 | Acc: 49.629,76.703,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.925 | Acc: 50.058,76.852,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.925 | Acc: 49.706,76.864,90.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.935 | Acc: 49.638,76.653,90.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.946 | Acc: 49.551,76.485,90.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.938 | Acc: 49.612,76.398,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.945 | Acc: 49.469,76.338,90.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.948 | Acc: 49.475,76.306,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.951 | Acc: 49.523,76.227,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.954 | Acc: 49.605,76.157,90.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.953 | Acc: 49.817,76.149,90.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.961 | Acc: 49.683,76.079,90.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.967 | Acc: 49.668,76.064,90.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.964 | Acc: 49.725,76.110,90.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.970 | Acc: 49.711,76.026,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.969 | Acc: 49.736,76.037,90.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.971 | Acc: 49.772,75.995,90.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.123 | Acc: 50.000,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.441 | Acc: 46.168,64.509,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.475 | Acc: 45.255,64.272,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.505 | Acc: 45.056,64.075,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.874 | Acc: 51.562,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.969 | Acc: 47.545,76.339,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.954 | Acc: 49.447,76.505,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.924 | Acc: 50.038,76.895,90.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.945 | Acc: 50.212,76.389,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.935 | Acc: 50.379,76.207,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.942 | Acc: 50.226,76.162,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.946 | Acc: 50.166,76.241,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.944 | Acc: 50.024,76.213,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.943 | Acc: 50.047,76.092,90.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.950 | Acc: 50.023,76.011,90.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.951 | Acc: 50.004,75.962,90.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.960 | Acc: 49.870,75.985,90.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.960 | Acc: 49.847,75.952,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.964 | Acc: 49.819,75.904,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.958 | Acc: 49.847,75.997,90.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.959 | Acc: 49.839,76.029,90.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.964 | Acc: 49.732,75.937,90.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.968 | Acc: 49.742,75.922,90.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.966 | Acc: 49.774,75.933,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.161 | Acc: 46.094,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 45.089,63.653,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 44.779,63.548,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.592 | Acc: 44.544,63.153,69.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 3.309 | Acc: 46.094,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.014 | Acc: 49.442,75.112,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 48.704,75.819,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.987 | Acc: 49.065,75.922,91.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.988 | Acc: 49.093,75.762,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.975 | Acc: 49.288,75.874,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.969 | Acc: 49.361,75.839,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.949 | Acc: 49.656,75.881,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.950 | Acc: 49.588,75.898,91.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.953 | Acc: 49.724,75.881,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.950 | Acc: 49.720,76.081,90.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.956 | Acc: 49.753,76.029,90.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.952 | Acc: 49.942,76.044,90.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.953 | Acc: 49.895,76.051,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.951 | Acc: 49.872,76.168,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.953 | Acc: 49.847,76.147,90.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.953 | Acc: 49.837,76.168,90.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.951 | Acc: 49.851,76.168,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.951 | Acc: 49.868,76.156,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.946 | Acc: 49.967,76.226,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.439 | Acc: 48.438,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.571 | Acc: 44.234,63.988,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 44.131,63.891,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 44.198,63.704,68.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 3.223 | Acc: 45.312,73.438,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.977 | Acc: 49.628,76.414,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.944 | Acc: 49.371,76.963,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.951 | Acc: 48.975,76.524,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.953 | Acc: 49.199,76.370,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.958 | Acc: 49.319,76.160,91.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.944 | Acc: 49.632,76.246,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.943 | Acc: 49.457,76.208,91.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.945 | Acc: 49.311,76.266,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.947 | Acc: 49.275,76.135,91.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.934 | Acc: 49.417,76.244,91.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.935 | Acc: 49.523,76.343,91.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.937 | Acc: 49.530,76.381,91.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.947 | Acc: 49.473,76.293,91.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.941 | Acc: 49.572,76.312,91.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.939 | Acc: 49.699,76.394,91.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.937 | Acc: 49.803,76.397,91.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.939 | Acc: 49.918,76.317,90.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.944 | Acc: 49.892,76.153,90.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.948 | Acc: 49.883,76.107,90.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.339 | Acc: 46.875,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 45.350,63.244,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 44.627,62.881,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 44.647,63.243,68.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 2.553 | Acc: 49.219,87.500,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.884 | Acc: 48.847,76.562,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.904 | Acc: 49.066,76.715,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.905 | Acc: 49.846,76.306,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.934 | Acc: 49.595,76.157,90.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.920 | Acc: 50.070,76.354,90.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.925 | Acc: 49.910,76.369,90.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.923 | Acc: 50.083,76.446,90.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.924 | Acc: 50.078,76.412,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.929 | Acc: 49.922,76.273,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.930 | Acc: 49.926,76.213,90.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.928 | Acc: 49.993,76.213,90.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.921 | Acc: 50.006,76.212,90.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.924 | Acc: 49.874,76.090,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.929 | Acc: 49.872,76.043,91.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.928 | Acc: 49.883,76.093,91.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.933 | Acc: 49.842,76.105,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.934 | Acc: 49.780,76.102,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.941 | Acc: 49.708,76.004,90.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.946 | Acc: 49.713,75.915,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.372 | Acc: 50.000,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 45.126,63.504,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.558 | Acc: 45.370,63.720,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 45.146,63.832,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 2.764 | Acc: 49.219,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.794 | Acc: 50.037,79.092,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.852 | Acc: 50.133,77.877,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.878 | Acc: 50.346,77.280,91.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.910 | Acc: 50.000,76.823,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.896 | Acc: 50.209,76.880,91.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.895 | Acc: 50.220,77.008,91.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.907 | Acc: 50.305,76.840,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.909 | Acc: 50.408,76.718,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.914 | Acc: 50.384,76.506,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.918 | Acc: 50.241,76.508,91.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.918 | Acc: 50.269,76.492,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.916 | Acc: 50.324,76.475,91.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.921 | Acc: 50.204,76.413,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.928 | Acc: 50.075,76.257,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.930 | Acc: 50.112,76.259,91.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.929 | Acc: 50.073,76.246,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.932 | Acc: 50.064,76.198,91.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.931 | Acc: 50.076,76.212,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.933 | Acc: 50.111,76.198,91.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.175 | Acc: 46.875,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 43.229,62.574,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.646 | Acc: 42.759,62.957,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.654 | Acc: 42.738,63.012,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.834 | Acc: 50.781,75.781,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.930 | Acc: 49.963,76.525,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.952 | Acc: 49.962,76.162,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.913 | Acc: 50.102,76.434,90.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.929 | Acc: 49.759,76.302,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.928 | Acc: 49.861,76.446,91.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.937 | Acc: 49.877,76.401,91.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.952 | Acc: 49.612,76.136,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.955 | Acc: 49.442,76.072,91.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.952 | Acc: 49.288,76.196,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.949 | Acc: 49.347,76.197,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.943 | Acc: 49.625,76.198,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.939 | Acc: 49.630,76.248,91.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.939 | Acc: 49.686,76.164,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.936 | Acc: 49.880,76.165,91.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.934 | Acc: 49.951,76.155,91.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.936 | Acc: 49.905,76.100,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.939 | Acc: 49.840,76.065,90.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.942 | Acc: 49.777,76.071,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.939 | Acc: 49.861,76.109,90.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.327 | Acc: 46.875,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 45.089,63.356,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 45.274,63.739,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.567 | Acc: 44.980,63.537,68.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 2.875 | Acc: 50.000,76.562,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 51.228,75.967,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.907 | Acc: 51.220,76.124,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.911 | Acc: 50.679,76.294,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.905 | Acc: 50.656,76.128,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.913 | Acc: 50.325,76.176,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.910 | Acc: 50.381,76.375,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.905 | Acc: 50.283,76.607,91.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.913 | Acc: 50.165,76.431,91.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.903 | Acc: 50.138,76.606,91.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.898 | Acc: 50.229,76.652,91.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.913 | Acc: 50.117,76.520,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.922 | Acc: 50.045,76.310,91.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.920 | Acc: 50.135,76.227,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.930 | Acc: 50.028,76.073,90.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.930 | Acc: 50.021,76.030,91.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 50.097,76.127,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.932 | Acc: 50.050,76.109,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.930 | Acc: 49.944,76.147,91.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.931 | Acc: 49.863,76.175,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.510 | Acc: 48.438,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.649 | Acc: 44.866,62.240,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.659 | Acc: 44.722,62.786,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.667 | Acc: 44.634,62.807,68.609,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 3.005 | Acc: 48.438,73.438,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.850 | Acc: 51.562,76.600,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.890 | Acc: 51.296,75.896,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.893 | Acc: 50.935,76.101,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.890 | Acc: 50.868,75.936,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.884 | Acc: 50.735,76.145,91.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.892 | Acc: 50.374,76.143,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.891 | Acc: 50.421,76.213,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.893 | Acc: 50.354,76.199,91.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.895 | Acc: 50.449,76.191,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.901 | Acc: 50.237,76.213,91.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.904 | Acc: 50.113,76.312,91.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.904 | Acc: 50.075,76.404,91.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.912 | Acc: 49.931,76.263,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.910 | Acc: 49.978,76.346,91.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.920 | Acc: 49.925,76.215,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.923 | Acc: 49.852,76.193,91.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.923 | Acc: 49.789,76.281,91.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.921 | Acc: 49.803,76.264,91.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.922 | Acc: 49.783,76.300,91.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.429 | Acc: 50.000,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 45.275,63.876,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 45.027,64.196,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 44.915,64.075,69.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 3.000 | Acc: 45.312,77.344,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.903 | Acc: 50.112,76.228,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.857 | Acc: 51.353,76.543,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.847 | Acc: 50.807,76.831,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.857 | Acc: 50.530,76.620,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.869 | Acc: 50.201,76.702,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.873 | Acc: 50.368,76.724,91.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.880 | Acc: 50.233,76.734,91.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.889 | Acc: 50.184,76.509,91.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.895 | Acc: 50.108,76.437,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.905 | Acc: 49.988,76.345,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.896 | Acc: 50.106,76.467,91.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.897 | Acc: 50.088,76.449,91.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.895 | Acc: 50.063,76.536,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.898 | Acc: 50.064,76.457,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.894 | Acc: 50.184,76.537,91.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.901 | Acc: 50.095,76.468,91.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 50.151,76.418,91.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.906 | Acc: 50.167,76.344,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.907 | Acc: 50.168,76.372,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.489 | Acc: 47.656,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.632 | Acc: 44.494,63.542,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.662 | Acc: 44.131,62.995,67.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.665 | Acc: 44.314,63.115,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.737 | Acc: 51.562,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.804 | Acc: 50.223,77.865,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.846 | Acc: 50.457,77.058,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.857 | Acc: 50.000,76.998,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.861 | Acc: 50.203,76.968,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.876 | Acc: 50.131,76.709,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.882 | Acc: 50.265,76.653,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.894 | Acc: 50.283,76.590,91.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.904 | Acc: 50.107,76.490,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.913 | Acc: 50.039,76.390,91.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.912 | Acc: 50.035,76.236,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.908 | Acc: 50.025,76.361,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.905 | Acc: 49.958,76.371,91.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.906 | Acc: 49.895,76.338,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.905 | Acc: 49.880,76.421,91.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.902 | Acc: 49.948,76.446,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.904 | Acc: 49.968,76.404,91.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.903 | Acc: 50.030,76.464,91.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.905 | Acc: 50.028,76.374,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.908 | Acc: 50.025,76.355,91.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.216 | Acc: 50.000,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 44.606,63.244,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 44.703,63.472,68.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.587 | Acc: 44.698,63.166,68.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 3.139 | Acc: 42.188,77.344,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.863 | Acc: 49.888,77.158,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.834 | Acc: 50.133,77.420,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.821 | Acc: 50.359,77.574,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.849 | Acc: 50.386,77.305,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.831 | Acc: 50.758,77.537,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.846 | Acc: 50.568,77.189,91.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.852 | Acc: 50.593,77.133,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.856 | Acc: 50.500,76.888,91.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.867 | Acc: 50.440,76.787,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.870 | Acc: 50.350,76.761,91.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.868 | Acc: 50.336,76.838,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 50.282,76.705,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.875 | Acc: 50.156,76.745,91.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.880 | Acc: 50.175,76.635,91.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 50.078,76.477,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.896 | Acc: 50.002,76.414,91.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 49.975,76.379,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.898 | Acc: 50.026,76.418,91.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.907 | Acc: 49.979,76.382,91.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.464 | Acc: 52.344,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.623 | Acc: 45.126,62.798,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.691 | Acc: 44.245,62.938,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.711 | Acc: 43.904,62.910,68.417,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 2.840 | Acc: 59.375,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.859 | Acc: 50.223,76.339,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.824 | Acc: 50.152,77.363,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.818 | Acc: 50.256,77.600,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.824 | Acc: 50.212,77.286,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.850 | Acc: 50.077,77.027,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 49.858,76.872,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.860 | Acc: 50.050,76.984,91.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.876 | Acc: 49.879,76.752,91.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.889 | Acc: 49.840,76.636,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.901 | Acc: 49.689,76.403,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.902 | Acc: 49.696,76.403,91.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.893 | Acc: 49.909,76.569,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.892 | Acc: 49.895,76.506,91.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 49.911,76.537,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.896 | Acc: 49.824,76.537,91.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.898 | Acc: 49.908,76.507,91.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.898 | Acc: 50.030,76.455,91.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.898 | Acc: 50.056,76.428,91.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.897 | Acc: 50.049,76.472,91.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 46.094,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.658 | Acc: 44.866,62.946,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.691 | Acc: 44.474,63.034,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.706 | Acc: 44.160,63.064,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 2.910 | Acc: 47.656,71.875,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.868 | Acc: 49.740,77.567,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.839 | Acc: 50.762,77.306,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.834 | Acc: 51.140,77.459,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.822 | Acc: 50.965,77.739,92.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.829 | Acc: 51.052,77.444,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.825 | Acc: 50.975,77.596,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.835 | Acc: 50.853,77.416,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.843 | Acc: 50.772,77.256,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.851 | Acc: 50.591,77.111,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.855 | Acc: 50.564,77.013,92.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.854 | Acc: 50.576,76.997,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.860 | Acc: 50.431,76.802,91.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.873 | Acc: 50.332,76.640,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.883 | Acc: 50.222,76.532,91.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.883 | Acc: 50.189,76.498,91.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.888 | Acc: 50.110,76.390,91.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 50.073,76.409,91.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.895 | Acc: 50.022,76.318,91.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.891 | Acc: 50.066,76.398,91.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.357 | Acc: 47.656,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.640 | Acc: 45.238,63.021,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.645 | Acc: 44.912,63.357,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.649 | Acc: 44.851,63.537,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 3.011 | Acc: 54.688,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.873 | Acc: 50.037,77.046,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.792 | Acc: 51.524,77.649,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.853 | Acc: 50.359,77.293,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.879 | Acc: 50.106,76.948,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.877 | Acc: 50.093,76.717,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.882 | Acc: 50.006,76.627,91.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.873 | Acc: 50.017,76.662,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.873 | Acc: 50.044,76.674,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.879 | Acc: 49.905,76.649,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.878 | Acc: 49.876,76.543,91.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.881 | Acc: 49.852,76.534,91.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.881 | Acc: 49.922,76.475,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.886 | Acc: 49.913,76.509,91.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.887 | Acc: 50.011,76.499,91.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.889 | Acc: 49.961,76.495,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.894 | Acc: 49.951,76.460,91.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.891 | Acc: 50.076,76.491,91.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.889 | Acc: 50.084,76.461,91.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.891 | Acc: 50.111,76.394,91.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.372 | Acc: 49.219,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.593 | Acc: 44.531,63.542,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.632 | Acc: 44.417,63.662,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.650 | Acc: 44.608,63.435,68.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 2.500 | Acc: 52.344,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.771 | Acc: 51.042,78.311,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 51.296,77.496,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.795 | Acc: 51.140,77.651,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 50.926,77.701,92.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.819 | Acc: 50.650,77.437,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.843 | Acc: 50.639,77.182,91.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.849 | Acc: 50.349,77.299,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.851 | Acc: 50.286,77.227,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.843 | Acc: 50.496,77.240,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.843 | Acc: 50.463,77.204,91.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.849 | Acc: 50.516,77.121,91.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.847 | Acc: 50.548,77.136,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.855 | Acc: 50.464,76.976,91.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.859 | Acc: 50.431,76.929,91.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.866 | Acc: 50.358,76.871,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.870 | Acc: 50.270,76.838,91.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.873 | Acc: 50.300,76.760,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.872 | Acc: 50.387,76.796,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.875 | Acc: 50.287,76.807,91.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 46.875,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.613 | Acc: 45.238,64.211,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.616 | Acc: 44.874,63.453,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.613 | Acc: 44.864,63.742,68.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.473 | Acc: 57.031,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.859 | Acc: 51.562,76.451,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.876 | Acc: 50.591,76.982,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.850 | Acc: 50.371,77.075,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.871 | Acc: 50.193,77.141,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.852 | Acc: 50.518,77.127,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.849 | Acc: 50.613,76.963,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.853 | Acc: 50.560,76.889,92.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.856 | Acc: 50.510,76.907,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 50.514,77.024,92.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.854 | Acc: 50.447,77.002,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.851 | Acc: 50.573,77.008,92.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.851 | Acc: 50.499,77.084,91.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.858 | Acc: 50.320,77.035,91.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.860 | Acc: 50.242,77.041,91.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.863 | Acc: 50.293,76.986,91.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.863 | Acc: 50.292,76.979,91.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.863 | Acc: 50.389,76.906,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.868 | Acc: 50.398,76.848,91.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.871 | Acc: 50.375,76.868,91.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.661 | Acc: 48.438,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.749 | Acc: 43.824,62.016,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.781 | Acc: 43.140,62.786,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.792 | Acc: 42.982,62.692,67.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 3.076 | Acc: 49.219,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.848 | Acc: 51.265,78.088,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.854 | Acc: 50.076,77.630,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.861 | Acc: 50.346,77.536,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.832 | Acc: 51.148,77.595,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.834 | Acc: 50.998,77.553,92.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.834 | Acc: 50.788,77.299,92.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.841 | Acc: 50.632,77.349,92.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.835 | Acc: 50.806,77.392,92.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.844 | Acc: 50.794,77.288,92.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.840 | Acc: 50.840,77.301,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 50.827,77.354,92.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.832 | Acc: 50.869,77.366,92.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.841 | Acc: 50.679,77.218,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.851 | Acc: 50.617,77.096,92.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.860 | Acc: 50.478,76.986,91.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.869 | Acc: 50.338,76.918,91.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.866 | Acc: 50.389,77.016,91.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.868 | Acc: 50.353,76.989,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.870 | Acc: 50.369,76.921,91.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.421 | Acc: 46.875,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.586 | Acc: 45.052,63.058,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.638 | Acc: 44.665,62.938,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.656 | Acc: 44.787,63.179,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 3.177 | Acc: 46.875,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.757 | Acc: 52.046,77.307,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.819 | Acc: 51.334,77.001,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.823 | Acc: 51.089,77.280,92.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.835 | Acc: 50.916,77.228,92.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.848 | Acc: 50.541,77.135,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.848 | Acc: 50.807,77.027,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.845 | Acc: 50.809,77.017,92.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.854 | Acc: 50.704,76.941,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.852 | Acc: 50.669,76.852,92.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.853 | Acc: 50.564,76.769,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.855 | Acc: 50.495,76.718,92.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.855 | Acc: 50.545,76.819,92.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.859 | Acc: 50.395,76.790,91.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.859 | Acc: 50.445,76.771,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.863 | Acc: 50.480,76.659,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.863 | Acc: 50.368,76.657,91.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.860 | Acc: 50.399,76.661,91.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.865 | Acc: 50.392,76.638,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.864 | Acc: 50.361,76.688,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.552 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.697 | Acc: 44.420,61.496,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.728 | Acc: 44.150,62.043,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.747 | Acc: 44.211,61.783,67.853,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 3.251 | Acc: 44.531,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.889 | Acc: 49.888,76.525,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.895 | Acc: 48.990,77.001,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.868 | Acc: 49.270,77.293,92.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.853 | Acc: 49.778,77.421,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.856 | Acc: 49.899,77.359,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.849 | Acc: 50.123,77.182,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.849 | Acc: 50.127,77.244,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.848 | Acc: 50.170,77.106,92.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 50.181,77.124,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.849 | Acc: 50.307,77.052,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.855 | Acc: 50.371,76.884,91.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.856 | Acc: 50.457,76.916,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.856 | Acc: 50.533,76.967,91.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.858 | Acc: 50.475,76.932,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.856 | Acc: 50.496,76.975,91.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.856 | Acc: 50.565,76.942,91.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.859 | Acc: 50.548,76.954,91.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.863 | Acc: 50.480,76.865,91.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.865 | Acc: 50.457,76.782,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.592 | Acc: 45.312,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.708 | Acc: 44.308,62.314,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.722 | Acc: 43.655,62.290,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.734 | Acc: 43.558,62.666,68.007,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.575 | Acc: 49.219,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.748 | Acc: 51.786,78.162,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.783 | Acc: 51.010,78.049,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.827 | Acc: 50.538,77.626,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.818 | Acc: 50.656,77.421,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 50.642,77.282,91.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.846 | Acc: 50.846,77.344,91.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.845 | Acc: 51.003,77.155,91.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.847 | Acc: 50.883,77.082,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.842 | Acc: 50.742,77.150,91.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.844 | Acc: 50.657,77.118,91.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.848 | Acc: 50.530,77.135,91.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.843 | Acc: 50.532,77.195,91.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.847 | Acc: 50.479,77.206,91.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.853 | Acc: 50.403,77.157,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.857 | Acc: 50.433,77.084,91.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.860 | Acc: 50.377,77.047,91.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.863 | Acc: 50.360,76.927,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.862 | Acc: 50.327,76.961,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.864 | Acc: 50.359,76.942,91.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.342 | Acc: 48.438,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.613 | Acc: 45.089,62.946,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.634 | Acc: 44.874,62.595,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.641 | Acc: 44.557,62.935,67.815,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.539 | Acc: 56.250,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.751 | Acc: 50.930,77.493,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.817 | Acc: 50.248,77.611,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.805 | Acc: 50.961,77.318,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.820 | Acc: 50.897,77.160,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.802 | Acc: 50.990,77.305,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.823 | Acc: 50.923,76.898,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.831 | Acc: 50.748,76.834,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.837 | Acc: 50.699,76.815,92.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.842 | Acc: 50.604,76.761,92.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.841 | Acc: 50.579,76.675,92.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.837 | Acc: 50.594,76.644,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.840 | Acc: 50.512,76.692,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.837 | Acc: 50.521,76.739,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.846 | Acc: 50.442,76.668,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.845 | Acc: 50.504,76.656,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.850 | Acc: 50.397,76.638,91.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.850 | Acc: 50.367,76.698,91.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.857 | Acc: 50.238,76.671,91.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.860 | Acc: 50.176,76.669,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.582 | Acc: 45.312,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.776 | Acc: 43.155,61.905,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.821 | Acc: 42.721,62.081,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.844 | Acc: 42.918,62.193,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 2.637 | Acc: 56.250,74.219,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.800 | Acc: 50.521,76.562,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.797 | Acc: 50.248,76.734,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.829 | Acc: 50.384,76.550,92.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.852 | Acc: 50.010,76.505,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.848 | Acc: 50.201,76.671,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.857 | Acc: 50.077,76.556,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.863 | Acc: 50.072,76.596,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 50.136,76.630,92.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 50.259,76.714,92.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.857 | Acc: 50.120,76.679,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.859 | Acc: 50.113,76.690,92.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.865 | Acc: 50.052,76.634,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.865 | Acc: 50.117,76.610,91.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.868 | Acc: 50.100,76.629,91.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.871 | Acc: 49.956,76.591,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.868 | Acc: 50.017,76.614,91.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.864 | Acc: 50.110,76.702,91.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.865 | Acc: 50.106,76.703,91.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.863 | Acc: 50.201,76.747,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.503 | Acc: 46.875,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.796 | Acc: 44.122,61.942,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.784 | Acc: 43.445,62.691,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.805 | Acc: 43.366,62.846,67.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.595 | Acc: 54.688,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.852 | Acc: 50.335,77.418,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.857 | Acc: 50.686,77.268,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.847 | Acc: 50.525,77.011,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.857 | Acc: 50.405,76.997,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.858 | Acc: 50.456,77.058,91.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.865 | Acc: 50.413,76.918,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.873 | Acc: 50.227,76.917,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.868 | Acc: 50.286,76.844,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.863 | Acc: 50.324,76.925,91.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.863 | Acc: 50.463,76.967,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.864 | Acc: 50.463,76.912,91.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.859 | Acc: 50.528,77.033,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.856 | Acc: 50.518,77.014,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.860 | Acc: 50.420,77.038,91.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.856 | Acc: 50.470,77.105,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.863 | Acc: 50.365,76.971,91.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.863 | Acc: 50.353,76.941,91.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.867 | Acc: 50.307,76.883,91.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.871 | Acc: 50.238,76.884,91.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.439 | Acc: 51.562,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.667 | Acc: 46.094,62.612,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.676 | Acc: 45.675,62.843,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 45.338,63.115,68.033,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 2.772 | Acc: 50.781,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.759 | Acc: 49.256,78.646,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.765 | Acc: 49.657,78.601,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.797 | Acc: 49.859,78.291,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 50.125,78.289,92.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.807 | Acc: 50.309,77.939,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.814 | Acc: 50.116,77.608,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.817 | Acc: 50.028,77.682,92.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.817 | Acc: 50.044,77.615,92.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.822 | Acc: 50.039,77.603,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.818 | Acc: 50.280,77.596,92.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 50.382,77.612,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.823 | Acc: 50.311,77.428,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.833 | Acc: 50.171,77.380,92.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.827 | Acc: 50.348,77.349,92.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.832 | Acc: 50.423,77.235,92.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.834 | Acc: 50.399,77.259,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.837 | Acc: 50.373,77.188,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.838 | Acc: 50.377,77.192,92.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.843 | Acc: 50.326,77.124,92.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.414 | Acc: 50.781,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 45.275,63.318,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.617 | Acc: 45.312,63.053,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 45.338,63.217,68.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 2.805 | Acc: 43.750,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.822 | Acc: 50.037,77.493,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.825 | Acc: 49.447,77.001,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.824 | Acc: 50.179,76.755,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.829 | Acc: 49.981,76.775,92.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.816 | Acc: 50.549,77.166,92.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.830 | Acc: 50.278,77.047,92.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.822 | Acc: 50.427,77.161,92.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.823 | Acc: 50.408,77.125,92.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.830 | Acc: 50.233,77.033,92.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.835 | Acc: 50.210,76.967,92.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 50.170,77.001,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.844 | Acc: 50.130,76.926,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.846 | Acc: 50.132,76.946,92.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.846 | Acc: 50.195,76.924,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.845 | Acc: 50.156,76.944,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 50.187,77.015,92.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.847 | Acc: 50.206,76.963,92.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.850 | Acc: 50.190,76.969,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.855 | Acc: 50.139,76.927,92.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.459 | Acc: 48.438,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.739 | Acc: 43.936,62.016,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.771 | Acc: 43.540,62.443,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.797 | Acc: 43.084,62.244,67.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.862 | Acc: 50.000,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.781 | Acc: 50.186,77.939,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 50.038,77.896,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.801 | Acc: 50.307,77.894,92.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.812 | Acc: 50.174,77.681,92.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.807 | Acc: 50.294,77.761,92.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.802 | Acc: 50.517,77.757,92.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.815 | Acc: 50.166,77.510,92.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.816 | Acc: 50.218,77.582,92.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 50.211,77.672,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.813 | Acc: 50.284,77.639,92.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.820 | Acc: 50.159,77.475,92.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.828 | Acc: 50.211,77.405,92.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.827 | Acc: 50.299,77.371,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 50.303,77.277,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 50.423,77.204,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.840 | Acc: 50.380,77.132,92.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.840 | Acc: 50.399,77.089,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.844 | Acc: 50.366,77.052,92.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 50.299,77.038,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.399 | Acc: 48.438,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.851 | Acc: 43.006,62.091,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.841 | Acc: 42.969,62.062,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.848 | Acc: 42.918,62.205,67.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.839 | Acc: 46.875,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.915 | Acc: 49.182,77.009,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.858 | Acc: 50.324,77.172,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.835 | Acc: 50.743,77.267,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.841 | Acc: 50.260,77.257,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.832 | Acc: 50.162,77.174,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.840 | Acc: 49.981,77.073,92.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.828 | Acc: 50.105,77.056,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.835 | Acc: 49.888,76.999,92.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.841 | Acc: 49.845,76.878,92.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.840 | Acc: 50.016,77.017,92.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.834 | Acc: 50.110,77.061,92.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.835 | Acc: 50.175,77.097,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.832 | Acc: 50.210,77.224,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.839 | Acc: 50.150,77.110,92.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.840 | Acc: 50.174,77.079,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.837 | Acc: 50.341,77.159,92.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.838 | Acc: 50.353,77.131,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.839 | Acc: 50.262,77.138,92.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.844 | Acc: 50.182,77.083,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.435 | Acc: 52.344,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.697 | Acc: 44.829,62.500,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.763 | Acc: 43.807,62.405,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.768 | Acc: 43.878,62.423,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.462 | Acc: 54.688,78.906,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.878 | Acc: 49.777,77.269,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.868 | Acc: 50.095,76.982,92.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.840 | Acc: 50.397,77.433,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.829 | Acc: 50.357,77.296,92.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.833 | Acc: 50.085,77.127,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 49.903,77.079,92.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.842 | Acc: 49.994,77.183,92.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.844 | Acc: 50.058,77.227,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.841 | Acc: 50.026,77.244,92.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.844 | Acc: 50.070,77.095,92.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.834 | Acc: 50.237,77.245,92.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.838 | Acc: 50.201,77.162,92.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.842 | Acc: 50.192,77.086,92.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 50.170,77.094,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.845 | Acc: 50.174,77.097,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.849 | Acc: 50.173,76.976,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.847 | Acc: 50.229,77.021,92.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.850 | Acc: 50.260,76.915,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.852 | Acc: 50.246,76.909,92.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.638 | Acc: 43.750,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.715 | Acc: 44.048,62.388,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.754 | Acc: 43.807,62.119,67.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.759 | Acc: 43.801,62.269,67.943,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 2.486 | Acc: 46.875,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.750 | Acc: 51.786,77.939,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.785 | Acc: 50.819,78.296,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.787 | Acc: 50.410,78.112,92.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.821 | Acc: 50.000,77.315,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.827 | Acc: 50.023,77.568,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.805 | Acc: 50.065,77.834,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.809 | Acc: 50.133,77.654,92.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.817 | Acc: 50.155,77.465,92.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.822 | Acc: 50.039,77.348,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.820 | Acc: 50.105,77.375,92.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.824 | Acc: 50.067,77.319,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.830 | Acc: 49.987,77.272,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.828 | Acc: 49.964,77.332,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.828 | Acc: 49.967,77.349,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.834 | Acc: 49.901,77.206,92.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.834 | Acc: 49.966,77.242,92.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 50.076,77.188,92.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.838 | Acc: 50.074,77.177,92.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.839 | Acc: 50.064,77.215,92.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.455 | Acc: 46.875,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.616 | Acc: 45.722,61.868,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.657 | Acc: 45.541,62.500,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.668 | Acc: 45.236,62.782,67.994,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 3.116 | Acc: 39.844,71.875,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.804 | Acc: 49.963,77.567,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.801 | Acc: 50.553,77.706,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.781 | Acc: 50.525,77.818,93.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.804 | Acc: 50.588,77.720,93.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.800 | Acc: 50.882,77.661,93.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.799 | Acc: 51.085,77.589,93.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.810 | Acc: 50.842,77.610,92.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.815 | Acc: 50.422,77.465,92.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.817 | Acc: 50.380,77.478,92.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.821 | Acc: 50.455,77.429,92.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.822 | Acc: 50.559,77.453,92.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.827 | Acc: 50.515,77.415,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.831 | Acc: 50.539,77.344,92.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 50.495,77.369,92.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 50.527,77.341,92.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 50.411,77.283,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.842 | Acc: 50.357,77.234,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.842 | Acc: 50.348,77.223,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.840 | Acc: 50.470,77.262,92.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.536 | Acc: 46.875,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.790 | Acc: 44.568,61.235,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.827 | Acc: 44.379,61.490,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.833 | Acc: 44.121,61.860,67.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.647 | Acc: 46.094,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.725 | Acc: 51.674,78.683,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 51.200,78.316,92.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.796 | Acc: 50.961,77.920,92.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 51.119,78.019,92.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.799 | Acc: 50.828,77.692,92.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.812 | Acc: 50.568,77.512,92.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.809 | Acc: 50.687,77.405,92.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.809 | Acc: 50.621,77.412,92.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.813 | Acc: 50.470,77.460,92.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.812 | Acc: 50.486,77.332,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.810 | Acc: 50.608,77.315,92.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 50.584,77.331,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.810 | Acc: 50.635,77.350,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.812 | Acc: 50.592,77.271,92.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 50.605,77.183,92.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 50.601,77.232,92.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.820 | Acc: 50.635,77.188,92.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.820 | Acc: 50.558,77.259,92.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.824 | Acc: 50.574,77.235,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.574 | Acc: 46.094,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.772 | Acc: 43.452,62.760,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.794 | Acc: 43.274,62.957,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.809 | Acc: 43.263,62.782,67.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 3.155 | Acc: 44.531,71.094,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.689 | Acc: 52.195,79.985,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 51.696,79.173,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.737 | Acc: 51.550,78.881,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.754 | Acc: 51.408,78.453,93.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.767 | Acc: 51.245,78.133,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.764 | Acc: 51.304,77.957,93.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.764 | Acc: 51.302,78.047,93.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.777 | Acc: 51.165,77.911,93.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.780 | Acc: 51.075,77.840,92.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.781 | Acc: 51.007,77.744,92.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.789 | Acc: 50.965,77.708,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.799 | Acc: 50.879,77.629,92.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.793 | Acc: 51.021,77.652,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.798 | Acc: 50.948,77.524,92.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.801 | Acc: 50.979,77.520,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.805 | Acc: 50.898,77.431,92.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.809 | Acc: 50.719,77.401,92.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.811 | Acc: 50.643,77.333,92.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.814 | Acc: 50.613,77.323,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.650 | Acc: 43.750,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.688 | Acc: 45.089,62.909,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.732 | Acc: 44.341,62.652,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.750 | Acc: 44.352,62.628,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 2.770 | Acc: 47.656,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.864 | Acc: 50.149,77.455,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.785 | Acc: 51.601,77.934,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.803 | Acc: 51.127,77.754,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.814 | Acc: 50.945,77.720,92.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.829 | Acc: 50.642,77.514,92.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.835 | Acc: 50.394,77.447,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.832 | Acc: 50.410,77.410,92.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.820 | Acc: 50.674,77.567,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.806 | Acc: 50.764,77.711,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.812 | Acc: 50.735,77.608,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 50.767,77.577,92.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.814 | Acc: 50.759,77.454,92.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.821 | Acc: 50.548,77.329,92.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.817 | Acc: 50.626,77.344,92.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.814 | Acc: 50.675,77.365,92.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.820 | Acc: 50.594,77.263,92.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 50.580,77.186,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.823 | Acc: 50.606,77.266,92.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.820 | Acc: 50.662,77.340,92.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.612 | Acc: 43.750,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.775 | Acc: 44.271,63.021,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.783 | Acc: 44.398,62.976,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.821 | Acc: 43.904,62.769,67.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 3.272 | Acc: 50.781,69.531,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.793 | Acc: 51.004,78.646,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.784 | Acc: 50.534,78.487,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.779 | Acc: 50.743,78.074,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.813 | Acc: 50.289,77.836,92.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.796 | Acc: 50.449,77.754,92.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.785 | Acc: 50.607,77.667,92.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.787 | Acc: 50.693,77.604,92.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.784 | Acc: 50.922,77.562,92.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.786 | Acc: 50.988,77.568,92.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 50.766,77.468,92.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.814 | Acc: 50.650,77.326,92.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.816 | Acc: 50.665,77.292,92.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.813 | Acc: 50.721,77.278,92.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.813 | Acc: 50.659,77.405,92.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.817 | Acc: 50.613,77.292,92.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 50.667,77.334,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.816 | Acc: 50.717,77.321,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.814 | Acc: 50.716,77.285,92.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.819 | Acc: 50.605,77.215,92.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.717 | Acc: 47.656,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.779 | Acc: 44.159,62.016,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.813 | Acc: 43.559,62.671,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.823 | Acc: 43.494,62.743,67.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 2.461 | Acc: 53.906,75.781,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.754 | Acc: 50.818,78.013,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.791 | Acc: 50.591,77.191,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.784 | Acc: 50.295,77.395,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.803 | Acc: 49.846,77.315,92.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.811 | Acc: 49.791,77.181,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.815 | Acc: 49.942,77.137,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.815 | Acc: 50.033,77.128,92.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.815 | Acc: 50.243,77.140,92.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.815 | Acc: 50.328,77.102,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.814 | Acc: 50.260,77.173,92.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.818 | Acc: 50.276,77.149,92.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.823 | Acc: 50.347,77.039,92.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.818 | Acc: 50.479,77.053,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.821 | Acc: 50.553,77.021,92.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.819 | Acc: 50.623,77.139,92.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.827 | Acc: 50.562,77.030,92.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.829 | Acc: 50.612,77.083,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.828 | Acc: 50.548,77.047,92.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.828 | Acc: 50.515,77.065,92.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.488 | Acc: 50.000,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.645 | Acc: 45.908,63.207,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.675 | Acc: 45.675,62.919,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 45.274,62.999,67.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.943 | Acc: 42.969,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.782 | Acc: 49.591,78.757,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.783 | Acc: 50.419,78.049,93.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.783 | Acc: 50.525,78.535,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.783 | Acc: 50.936,78.385,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.784 | Acc: 50.464,78.187,92.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.787 | Acc: 50.407,77.912,92.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.783 | Acc: 50.493,77.848,92.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.786 | Acc: 50.514,77.688,92.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.790 | Acc: 50.522,77.672,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.796 | Acc: 50.478,77.581,92.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.802 | Acc: 50.392,77.503,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.805 | Acc: 50.421,77.418,92.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.805 | Acc: 50.407,77.422,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.813 | Acc: 50.300,77.277,92.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.819 | Acc: 50.234,77.258,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 50.246,77.217,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 50.225,77.181,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.831 | Acc: 50.238,77.117,92.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.828 | Acc: 50.340,77.112,92.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.629 | Acc: 46.875,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.810 | Acc: 44.085,62.463,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.845 | Acc: 43.826,62.424,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.875 | Acc: 43.545,62.359,66.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 3.078 | Acc: 46.094,76.562,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.800 | Acc: 50.484,76.972,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.745 | Acc: 50.991,77.973,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.760 | Acc: 50.666,77.497,92.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.773 | Acc: 50.685,77.411,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.785 | Acc: 50.549,77.228,92.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.800 | Acc: 50.568,77.021,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.805 | Acc: 50.549,76.967,92.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.797 | Acc: 50.611,77.193,92.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.809 | Acc: 50.475,76.990,92.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.805 | Acc: 50.532,77.095,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.804 | Acc: 50.431,77.142,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.807 | Acc: 50.464,77.227,92.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.808 | Acc: 50.506,77.137,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.808 | Acc: 50.478,77.163,92.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.813 | Acc: 50.374,77.110,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.819 | Acc: 50.341,77.093,92.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.817 | Acc: 50.447,77.096,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.814 | Acc: 50.470,77.155,92.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.812 | Acc: 50.496,77.186,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.432 | Acc: 49.219,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.730 | Acc: 44.940,62.723,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.768 | Acc: 44.398,62.881,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.804 | Acc: 44.045,62.743,67.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 2.763 | Acc: 51.562,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.865 | Acc: 50.744,77.046,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.806 | Acc: 50.819,78.525,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.755 | Acc: 50.922,78.496,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 50.965,78.154,93.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.777 | Acc: 50.828,78.024,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.774 | Acc: 50.704,78.067,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.769 | Acc: 50.720,78.036,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.772 | Acc: 50.767,77.989,92.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.775 | Acc: 50.876,77.978,92.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.778 | Acc: 50.944,77.970,92.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.782 | Acc: 50.795,77.846,92.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.788 | Acc: 50.729,77.723,92.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.796 | Acc: 50.614,77.682,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.796 | Acc: 50.695,77.677,92.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 50.579,77.629,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.810 | Acc: 50.499,77.529,92.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.808 | Acc: 50.415,77.566,92.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.811 | Acc: 50.439,77.493,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.812 | Acc: 50.437,77.422,92.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.481 | Acc: 50.781,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.782 | Acc: 43.862,61.384,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.779 | Acc: 43.255,61.986,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.790 | Acc: 43.353,62.231,67.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 3.132 | Acc: 46.875,78.906,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.791 | Acc: 51.153,76.786,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.843 | Acc: 50.343,76.925,93.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.833 | Acc: 50.243,77.062,93.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.826 | Acc: 50.135,77.122,93.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.811 | Acc: 50.557,77.367,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.802 | Acc: 50.600,77.505,93.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.800 | Acc: 50.637,77.560,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.803 | Acc: 50.626,77.407,93.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.804 | Acc: 50.660,77.434,93.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.809 | Acc: 50.505,77.340,93.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 50.442,77.319,93.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 50.376,77.217,92.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.804 | Acc: 50.533,77.299,92.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.810 | Acc: 50.436,77.260,92.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.814 | Acc: 50.441,77.240,92.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 50.389,77.142,92.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.817 | Acc: 50.369,77.144,92.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.817 | Acc: 50.379,77.136,92.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.817 | Acc: 50.410,77.145,92.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.569 | Acc: 47.656,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.749 | Acc: 45.982,62.314,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.768 | Acc: 45.484,62.214,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.786 | Acc: 44.928,61.924,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.953 | Acc: 50.781,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.815 | Acc: 49.851,78.125,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.808 | Acc: 50.743,77.591,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.797 | Acc: 50.961,77.241,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.763 | Acc: 51.196,77.315,92.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.765 | Acc: 51.207,77.514,92.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.785 | Acc: 50.846,77.583,92.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.785 | Acc: 50.765,77.626,92.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.798 | Acc: 50.645,77.387,92.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.802 | Acc: 50.501,77.434,92.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 50.435,77.406,92.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 50.463,77.354,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.806 | Acc: 50.428,77.441,92.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.806 | Acc: 50.422,77.460,92.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.806 | Acc: 50.445,77.461,92.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.809 | Acc: 50.436,77.432,92.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.808 | Acc: 50.392,77.485,92.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.804 | Acc: 50.369,77.502,92.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.809 | Acc: 50.422,77.422,92.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.809 | Acc: 50.459,77.420,92.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.415 | Acc: 51.562,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.803 | Acc: 44.457,62.202,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.831 | Acc: 44.417,61.662,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.848 | Acc: 43.955,61.706,67.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 2.708 | Acc: 46.875,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.730 | Acc: 50.000,78.534,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.688 | Acc: 50.857,78.925,92.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.741 | Acc: 50.038,78.253,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.764 | Acc: 50.212,77.855,92.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.778 | Acc: 50.070,77.707,92.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.794 | Acc: 50.194,77.589,92.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.790 | Acc: 50.371,77.709,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.798 | Acc: 50.160,77.523,92.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.795 | Acc: 50.207,77.499,92.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 50.350,77.620,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.797 | Acc: 50.279,77.485,92.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.806 | Acc: 50.169,77.415,92.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.809 | Acc: 50.195,77.353,92.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.806 | Acc: 50.264,77.399,92.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.800 | Acc: 50.363,77.492,92.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.798 | Acc: 50.428,77.568,92.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.803 | Acc: 50.396,77.520,92.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.805 | Acc: 50.403,77.430,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.807 | Acc: 50.424,77.342,92.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.444 | Acc: 43.750,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.830 | Acc: 43.638,61.979,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.860 | Acc: 43.426,61.852,67.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.885 | Acc: 43.212,61.796,67.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 2.633 | Acc: 52.344,75.000,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.697 | Acc: 51.339,78.385,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.760 | Acc: 50.648,77.572,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.720 | Acc: 51.255,77.946,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.719 | Acc: 51.582,78.067,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.745 | Acc: 51.037,77.970,92.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.743 | Acc: 51.007,78.028,92.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.761 | Acc: 50.898,77.898,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.764 | Acc: 50.747,77.824,92.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.762 | Acc: 50.816,78.043,92.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.771 | Acc: 50.742,77.966,92.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.771 | Acc: 50.686,77.948,92.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.779 | Acc: 50.554,77.892,92.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.778 | Acc: 50.682,77.856,92.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.781 | Acc: 50.667,77.758,92.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.784 | Acc: 50.574,77.645,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.790 | Acc: 50.501,77.551,92.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.795 | Acc: 50.495,77.495,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.796 | Acc: 50.524,77.493,92.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.802 | Acc: 50.404,77.393,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.797 | Acc: 43.750,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.923 | Acc: 44.568,61.644,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.933 | Acc: 44.150,61.776,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.936 | Acc: 43.763,62.065,66.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 2.912 | Acc: 46.094,77.344,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.732 | Acc: 50.260,78.757,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.745 | Acc: 50.800,78.487,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.776 | Acc: 50.717,77.856,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.783 | Acc: 50.473,77.768,92.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.789 | Acc: 50.271,77.607,92.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.788 | Acc: 50.220,77.867,92.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.797 | Acc: 50.355,77.787,92.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.785 | Acc: 50.442,77.936,92.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.784 | Acc: 50.393,77.827,92.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.787 | Acc: 50.330,77.791,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.781 | Acc: 50.477,77.814,92.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.784 | Acc: 50.425,77.817,92.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.783 | Acc: 50.497,77.862,92.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.786 | Acc: 50.473,77.841,92.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.787 | Acc: 50.407,77.829,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.791 | Acc: 50.290,77.736,92.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.794 | Acc: 50.263,77.676,92.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.798 | Acc: 50.281,77.608,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.802 | Acc: 50.310,77.543,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.696 | Acc: 45.312,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.863 | Acc: 44.048,61.905,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.895 | Acc: 44.131,61.966,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.896 | Acc: 43.968,62.129,66.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.411 | Acc: 47.656,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.743 | Acc: 52.083,77.679,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.758 | Acc: 51.334,77.858,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.789 | Acc: 50.935,77.331,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.797 | Acc: 50.704,77.373,92.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.805 | Acc: 50.441,77.143,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.803 | Acc: 50.355,77.337,92.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.816 | Acc: 50.161,77.205,92.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.813 | Acc: 50.243,77.237,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.802 | Acc: 50.354,77.305,92.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.802 | Acc: 50.396,77.247,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.801 | Acc: 50.336,77.291,92.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.793 | Acc: 50.412,77.334,92.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.794 | Acc: 50.482,77.296,92.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.794 | Acc: 50.436,77.283,92.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.798 | Acc: 50.459,77.367,92.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.799 | Acc: 50.448,77.285,92.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.803 | Acc: 50.406,77.293,92.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.801 | Acc: 50.426,77.346,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.804 | Acc: 50.330,77.301,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.816 | Acc: 44.531,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.966 | Acc: 42.969,60.900,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.942 | Acc: 43.026,61.395,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.956 | Acc: 42.815,61.796,66.650,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.568 | Acc: 53.125,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.797 | Acc: 50.595,77.939,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.765 | Acc: 51.315,77.611,93.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.773 | Acc: 50.922,77.856,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.773 | Acc: 50.965,77.797,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.781 | Acc: 50.797,77.506,92.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.801 | Acc: 50.355,77.331,92.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.813 | Acc: 50.194,77.377,92.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.802 | Acc: 50.408,77.397,92.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.794 | Acc: 50.453,77.495,92.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.795 | Acc: 50.389,77.445,92.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.801 | Acc: 50.286,77.365,92.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.800 | Acc: 50.353,77.308,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.789 | Acc: 50.377,77.449,92.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.794 | Acc: 50.286,77.333,92.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.796 | Acc: 50.161,77.313,92.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.797 | Acc: 50.153,77.310,92.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.797 | Acc: 50.144,77.266,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.801 | Acc: 50.201,77.253,92.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.799 | Acc: 50.273,77.274,92.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.671 | Acc: 42.188,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.862 | Acc: 44.196,60.900,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.900 | Acc: 43.598,61.357,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.925 | Acc: 43.327,61.578,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.642 | Acc: 58.594,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.705 | Acc: 51.339,79.129,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.667 | Acc: 52.115,79.306,93.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.699 | Acc: 51.883,79.214,93.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.721 | Acc: 51.476,78.675,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.760 | Acc: 50.874,78.179,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.757 | Acc: 50.781,78.131,92.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.751 | Acc: 50.803,78.153,92.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.758 | Acc: 50.655,78.193,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.759 | Acc: 50.777,78.177,92.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.769 | Acc: 50.719,78.043,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.767 | Acc: 50.707,78.079,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.772 | Acc: 50.726,78.067,92.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.776 | Acc: 50.718,77.978,92.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.776 | Acc: 50.706,77.983,92.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.782 | Acc: 50.631,77.863,92.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.791 | Acc: 50.552,77.748,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.793 | Acc: 50.534,77.697,92.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.796 | Acc: 50.519,77.614,92.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.803 | Acc: 50.461,77.506,92.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.766 | Acc: 47.656,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.028 | Acc: 42.746,60.119,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.060 | Acc: 42.569,61.071,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.070 | Acc: 42.367,60.733,66.035,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 2.915 | Acc: 50.781,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.803 | Acc: 49.814,76.525,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.781 | Acc: 50.362,77.477,92.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.769 | Acc: 50.371,77.497,92.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.766 | Acc: 50.550,77.633,92.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.773 | Acc: 50.387,77.607,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.783 | Acc: 50.239,77.583,92.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.781 | Acc: 50.360,77.571,92.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.782 | Acc: 50.228,77.489,92.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.784 | Acc: 50.272,77.620,92.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.788 | Acc: 50.338,77.616,92.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.779 | Acc: 50.460,77.743,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.777 | Acc: 50.493,77.814,92.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.780 | Acc: 50.515,77.724,92.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.784 | Acc: 50.512,77.672,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.786 | Acc: 50.480,77.702,92.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.795 | Acc: 50.458,77.553,92.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.797 | Acc: 50.461,77.575,92.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.799 | Acc: 50.424,77.552,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.797 | Acc: 50.424,77.493,92.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.969 | Acc: 43.750,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.908 | Acc: 43.043,62.798,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.938 | Acc: 43.350,62.481,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.949 | Acc: 43.276,62.218,66.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.541 | Acc: 51.562,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.770 | Acc: 50.558,77.307,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.773 | Acc: 50.534,77.420,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.733 | Acc: 50.986,77.754,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.748 | Acc: 50.916,77.488,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.760 | Acc: 50.712,77.491,92.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.763 | Acc: 50.510,77.563,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.769 | Acc: 50.327,77.455,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.768 | Acc: 50.422,77.523,92.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.780 | Acc: 50.350,77.465,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.784 | Acc: 50.509,77.441,92.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.789 | Acc: 50.470,77.404,92.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.792 | Acc: 50.395,77.418,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.790 | Acc: 50.470,77.484,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.792 | Acc: 50.498,77.435,92.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.793 | Acc: 50.470,77.406,92.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.787 | Acc: 50.589,77.451,92.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.790 | Acc: 50.532,77.438,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.793 | Acc: 50.623,77.368,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.798 | Acc: 50.537,77.290,92.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.722 | Acc: 42.969,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.891 | Acc: 43.266,62.016,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.896 | Acc: 43.178,61.776,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.907 | Acc: 43.238,61.898,66.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.679 | Acc: 50.781,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.746 | Acc: 49.814,77.865,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 49.714,78.163,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.726 | Acc: 50.000,78.394,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.718 | Acc: 50.010,78.501,93.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.723 | Acc: 50.116,78.442,93.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.713 | Acc: 50.478,78.499,93.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.707 | Acc: 50.560,78.668,93.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.702 | Acc: 50.611,78.659,93.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.697 | Acc: 50.928,78.759,93.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.689 | Acc: 51.038,78.988,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.687 | Acc: 51.103,78.998,93.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.681 | Acc: 51.235,79.065,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.682 | Acc: 51.212,79.122,93.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.677 | Acc: 51.201,79.143,93.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.674 | Acc: 51.210,79.161,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.666 | Acc: 51.358,79.286,93.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.662 | Acc: 51.418,79.399,93.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.663 | Acc: 51.418,79.395,93.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.662 | Acc: 51.452,79.407,94.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.404 | Acc: 51.562,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 46.652,65.104,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 46.341,64.710,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 45.991,64.780,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.698 | Acc: 47.656,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.600 | Acc: 50.521,79.948,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.571 | Acc: 51.296,80.011,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.585 | Acc: 51.255,79.854,95.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.605 | Acc: 51.119,79.909,94.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.596 | Acc: 51.307,80.036,94.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.612 | Acc: 51.111,79.920,94.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.608 | Acc: 51.446,79.848,94.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.606 | Acc: 51.504,79.765,94.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.608 | Acc: 51.368,79.817,94.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.608 | Acc: 51.450,79.769,94.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.607 | Acc: 51.478,79.783,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.605 | Acc: 51.530,79.882,95.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.606 | Acc: 51.464,79.876,95.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.606 | Acc: 51.485,79.988,95.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.601 | Acc: 51.604,80.085,95.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.601 | Acc: 51.650,80.099,95.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.601 | Acc: 51.716,80.061,95.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.605 | Acc: 51.664,80.025,95.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.604 | Acc: 51.716,80.042,95.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.419 | Acc: 50.781,67.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 47.098,64.844,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.527 | Acc: 46.551,64.367,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 46.196,64.293,68.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.441 | Acc: 49.219,79.688,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.644 | Acc: 50.000,80.171,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.652 | Acc: 49.809,80.030,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.620 | Acc: 51.114,79.995,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.603 | Acc: 51.350,80.189,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.609 | Acc: 51.323,80.190,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.604 | Acc: 51.517,80.365,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.607 | Acc: 51.346,80.242,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.597 | Acc: 51.514,80.309,95.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.595 | Acc: 51.562,80.352,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.589 | Acc: 51.617,80.337,95.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.583 | Acc: 51.760,80.380,95.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.580 | Acc: 51.887,80.346,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.579 | Acc: 51.922,80.352,95.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.579 | Acc: 51.904,80.391,95.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.578 | Acc: 51.903,80.438,95.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.578 | Acc: 51.920,80.393,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.578 | Acc: 51.895,80.373,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.577 | Acc: 52.006,80.382,95.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.578 | Acc: 51.923,80.387,95.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.381 | Acc: 50.000,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 47.173,65.104,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.523 | Acc: 46.742,64.577,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 46.580,64.703,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.889 | Acc: 43.750,78.125,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.540 | Acc: 49.888,80.804,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.550 | Acc: 51.562,80.812,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 52.113,80.930,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.553 | Acc: 52.238,80.652,95.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.541 | Acc: 52.584,80.871,95.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.550 | Acc: 52.466,80.759,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.556 | Acc: 52.255,80.408,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.555 | Acc: 52.227,80.478,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.566 | Acc: 52.227,80.378,95.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.567 | Acc: 52.227,80.348,95.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.567 | Acc: 52.142,80.433,95.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.567 | Acc: 52.169,80.410,95.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.564 | Acc: 52.221,80.460,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.567 | Acc: 52.138,80.444,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.572 | Acc: 52.115,80.391,95.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.575 | Acc: 52.057,80.325,95.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.576 | Acc: 52.032,80.299,95.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.579 | Acc: 51.930,80.289,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.579 | Acc: 51.938,80.290,95.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.351 | Acc: 50.781,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 46.280,64.993,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 46.094,64.596,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.557 | Acc: 46.043,64.664,68.750,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 3.037 | Acc: 43.750,71.094,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.557 | Acc: 52.865,80.841,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.564 | Acc: 52.630,81.288,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.562 | Acc: 52.421,80.751,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.579 | Acc: 52.160,80.228,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.588 | Acc: 51.864,80.183,95.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.587 | Acc: 51.931,80.185,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.585 | Acc: 51.961,80.208,95.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.585 | Acc: 51.956,80.236,95.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.585 | Acc: 51.860,80.145,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.583 | Acc: 51.827,80.181,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.584 | Acc: 51.905,80.112,95.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.578 | Acc: 52.000,80.122,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.573 | Acc: 52.014,80.307,95.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.573 | Acc: 52.080,80.341,95.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.574 | Acc: 51.949,80.375,95.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.573 | Acc: 51.962,80.401,95.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.566 | Acc: 52.050,80.480,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.567 | Acc: 51.982,80.477,95.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.566 | Acc: 52.061,80.557,95.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.427 | Acc: 52.344,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 46.838,64.509,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.536 | Acc: 46.551,64.425,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.551 | Acc: 46.350,64.575,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.518 | Acc: 51.562,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.496 | Acc: 53.720,82.106,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.526 | Acc: 52.954,81.231,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 52.651,81.224,95.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.565 | Acc: 52.238,81.019,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.562 | Acc: 52.065,80.995,95.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.547 | Acc: 52.273,81.005,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.546 | Acc: 52.089,80.984,95.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.552 | Acc: 52.014,80.954,95.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.551 | Acc: 51.929,80.939,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.553 | Acc: 51.835,80.912,95.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.556 | Acc: 51.799,80.893,95.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.554 | Acc: 51.857,80.958,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.557 | Acc: 51.868,80.861,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.558 | Acc: 51.879,80.811,95.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.558 | Acc: 51.915,80.861,95.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.554 | Acc: 52.081,80.870,95.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.554 | Acc: 51.977,80.858,95.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.556 | Acc: 52.004,80.852,95.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.556 | Acc: 52.102,80.821,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.378 | Acc: 51.562,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 46.949,64.807,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.546 | Acc: 46.513,64.348,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 46.350,64.549,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.616 | Acc: 56.250,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.557 | Acc: 51.935,81.027,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.586 | Acc: 52.191,80.621,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.588 | Acc: 51.947,80.520,95.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.576 | Acc: 52.016,80.257,95.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.555 | Acc: 52.274,80.670,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.541 | Acc: 52.641,80.837,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.552 | Acc: 52.493,80.602,95.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.545 | Acc: 52.349,80.726,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.545 | Acc: 52.361,80.758,95.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.556 | Acc: 52.301,80.550,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.560 | Acc: 52.125,80.490,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.554 | Acc: 52.178,80.582,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.562 | Acc: 52.164,80.511,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.560 | Acc: 52.169,80.513,95.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.557 | Acc: 52.178,80.544,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.562 | Acc: 52.042,80.488,95.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.566 | Acc: 51.904,80.418,95.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.564 | Acc: 51.857,80.449,95.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.566 | Acc: 51.804,80.473,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.320 | Acc: 48.438,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.522 | Acc: 46.912,64.695,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.547 | Acc: 46.227,64.253,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 46.107,64.408,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.435 | Acc: 51.562,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.470 | Acc: 54.911,81.548,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.530 | Acc: 53.201,80.316,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.545 | Acc: 52.818,80.289,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.564 | Acc: 52.189,80.382,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.561 | Acc: 51.849,80.384,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.548 | Acc: 52.098,80.759,95.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.545 | Acc: 52.305,80.746,95.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.548 | Acc: 52.101,80.716,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.545 | Acc: 52.180,80.659,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.557 | Acc: 51.928,80.492,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.563 | Acc: 52.015,80.455,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.559 | Acc: 52.117,80.482,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.557 | Acc: 52.188,80.538,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.557 | Acc: 52.116,80.541,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.555 | Acc: 52.108,80.583,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.555 | Acc: 52.108,80.615,95.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.555 | Acc: 52.142,80.618,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.561 | Acc: 52.036,80.601,95.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.562 | Acc: 52.094,80.563,95.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.399 | Acc: 51.562,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.525 | Acc: 46.875,64.955,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.550 | Acc: 46.570,64.615,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.564 | Acc: 46.388,64.780,68.801,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.364 | Acc: 58.594,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 52.790,81.436,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.565 | Acc: 51.886,80.564,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.555 | Acc: 51.691,80.725,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.524 | Acc: 51.958,81.269,95.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.528 | Acc: 51.810,81.134,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 51.808,81.276,95.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.528 | Acc: 51.779,81.172,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.530 | Acc: 51.834,81.226,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.534 | Acc: 51.752,81.293,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.536 | Acc: 51.726,81.242,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.534 | Acc: 51.760,81.172,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.540 | Acc: 51.692,81.120,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.542 | Acc: 51.802,81.008,95.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.538 | Acc: 51.866,81.158,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.539 | Acc: 51.913,81.102,95.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.542 | Acc: 51.816,81.102,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.543 | Acc: 51.842,81.058,95.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.549 | Acc: 51.814,80.919,95.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.552 | Acc: 51.780,80.889,95.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.356 | Acc: 51.562,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.534 | Acc: 46.801,64.844,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 46.399,64.348,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 46.235,64.575,68.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.684 | Acc: 50.000,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.664 | Acc: 51.190,79.539,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.576 | Acc: 52.630,80.373,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.568 | Acc: 52.433,80.264,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.572 | Acc: 52.112,80.411,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.560 | Acc: 52.189,80.608,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.571 | Acc: 51.976,80.475,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.564 | Acc: 52.172,80.629,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.563 | Acc: 52.033,80.493,95.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.555 | Acc: 52.167,80.698,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.559 | Acc: 52.169,80.570,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.556 | Acc: 52.149,80.589,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.553 | Acc: 52.149,80.634,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.554 | Acc: 52.047,80.600,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.556 | Acc: 52.116,80.661,95.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.554 | Acc: 52.136,80.669,95.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.548 | Acc: 52.154,80.702,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 52.144,80.739,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.549 | Acc: 52.138,80.664,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.551 | Acc: 52.102,80.641,95.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.306 | Acc: 50.781,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.518 | Acc: 46.987,64.732,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.553 | Acc: 46.589,64.577,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 46.555,64.664,68.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.273 | Acc: 53.906,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.536 | Acc: 52.121,80.655,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.560 | Acc: 52.153,80.354,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.575 | Acc: 51.716,80.020,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.550 | Acc: 51.977,80.382,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.542 | Acc: 52.189,80.562,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.545 | Acc: 52.040,80.746,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.546 | Acc: 52.122,80.751,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.554 | Acc: 52.014,80.653,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.555 | Acc: 52.007,80.572,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.548 | Acc: 52.056,80.694,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.547 | Acc: 52.096,80.677,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.544 | Acc: 52.117,80.705,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.544 | Acc: 52.176,80.681,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.544 | Acc: 52.202,80.769,95.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.546 | Acc: 52.209,80.754,95.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.547 | Acc: 52.207,80.758,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 52.124,80.767,95.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.552 | Acc: 52.021,80.661,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.550 | Acc: 52.055,80.744,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.350 | Acc: 51.562,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.520 | Acc: 46.949,64.769,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 46.665,64.596,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.553 | Acc: 46.491,64.690,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.632 | Acc: 51.562,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 50.521,80.469,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.599 | Acc: 50.724,80.678,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.601 | Acc: 51.050,80.341,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.592 | Acc: 51.148,80.285,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.584 | Acc: 51.454,80.229,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.582 | Acc: 51.511,80.307,95.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.573 | Acc: 51.518,80.441,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.570 | Acc: 51.669,80.614,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.562 | Acc: 51.735,80.723,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.558 | Acc: 51.753,80.811,95.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.552 | Acc: 51.828,80.882,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.548 | Acc: 51.848,80.887,95.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.549 | Acc: 51.868,80.903,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.550 | Acc: 51.874,80.839,95.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.555 | Acc: 51.806,80.817,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.552 | Acc: 51.901,80.732,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.547 | Acc: 52.055,80.771,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.551 | Acc: 51.889,80.726,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.554 | Acc: 51.942,80.631,95.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.385 | Acc: 50.781,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 46.987,64.955,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 46.627,64.520,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.565 | Acc: 46.388,64.754,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.267 | Acc: 56.250,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.578 | Acc: 51.116,81.287,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.566 | Acc: 50.896,80.964,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.555 | Acc: 51.383,80.968,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.553 | Acc: 51.620,81.105,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.547 | Acc: 51.748,81.080,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.533 | Acc: 52.098,81.153,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.531 | Acc: 52.111,81.200,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.534 | Acc: 52.213,81.143,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.526 | Acc: 52.400,81.220,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.530 | Acc: 52.235,81.196,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 52.167,81.137,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.533 | Acc: 52.152,81.172,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.534 | Acc: 52.131,81.136,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.533 | Acc: 52.149,81.111,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.535 | Acc: 52.159,81.006,96.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.538 | Acc: 52.093,80.938,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.540 | Acc: 52.101,80.904,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.539 | Acc: 52.123,80.943,95.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.541 | Acc: 52.130,80.916,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.377 | Acc: 50.781,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 46.391,64.732,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 46.170,64.215,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.579 | Acc: 46.132,64.408,68.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.808 | Acc: 50.000,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.578 | Acc: 51.637,80.990,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.614 | Acc: 50.877,79.954,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.588 | Acc: 51.217,80.213,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.571 | Acc: 51.572,80.488,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.566 | Acc: 51.733,80.415,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.561 | Acc: 51.834,80.456,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.564 | Acc: 51.684,80.463,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.557 | Acc: 51.805,80.493,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.553 | Acc: 51.830,80.525,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.544 | Acc: 52.017,80.679,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.534 | Acc: 52.224,80.808,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.544 | Acc: 52.084,80.751,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.545 | Acc: 52.047,80.837,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.545 | Acc: 51.971,80.836,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.543 | Acc: 51.908,80.915,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.538 | Acc: 51.984,80.953,95.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.543 | Acc: 51.957,80.844,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.543 | Acc: 51.922,80.865,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.540 | Acc: 52.026,80.891,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.398 | Acc: 49.219,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 46.726,64.583,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 46.437,64.425,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 46.235,64.447,68.622,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.405 | Acc: 53.125,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.430 | Acc: 53.757,81.845,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.491 | Acc: 52.134,81.174,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.535 | Acc: 51.998,80.763,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 52.296,81.047,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.520 | Acc: 52.359,81.412,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.533 | Acc: 51.976,81.089,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.539 | Acc: 51.878,80.979,95.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.545 | Acc: 51.820,81.017,95.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.547 | Acc: 51.951,80.995,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.547 | Acc: 52.076,80.986,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.544 | Acc: 52.227,80.964,95.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.542 | Acc: 52.068,80.939,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.542 | Acc: 52.092,80.915,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.541 | Acc: 52.196,80.900,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.541 | Acc: 52.185,80.928,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.542 | Acc: 52.263,80.943,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.541 | Acc: 52.261,80.904,95.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.543 | Acc: 52.220,80.884,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.546 | Acc: 52.206,80.889,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.463 | Acc: 50.781,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 47.098,65.253,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 46.513,64.672,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 46.337,64.562,68.904,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.657 | Acc: 52.344,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.654 | Acc: 51.525,79.613,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.580 | Acc: 52.744,80.640,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.551 | Acc: 52.882,80.776,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.539 | Acc: 52.913,80.980,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.536 | Acc: 52.769,81.095,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.540 | Acc: 52.518,81.024,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.561 | Acc: 51.889,80.757,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.566 | Acc: 51.795,80.736,95.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.556 | Acc: 51.903,80.741,95.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.547 | Acc: 51.916,80.885,95.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.553 | Acc: 51.813,80.918,95.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.557 | Acc: 51.799,80.793,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.557 | Acc: 51.745,80.801,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.548 | Acc: 51.846,80.964,95.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.553 | Acc: 51.799,80.892,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.550 | Acc: 51.840,80.946,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.545 | Acc: 51.952,81.009,95.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.544 | Acc: 51.950,80.988,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.542 | Acc: 51.952,80.963,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.405 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.540 | Acc: 47.284,65.179,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 46.799,64.748,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 46.516,64.639,68.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.568 | Acc: 47.656,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.519 | Acc: 52.716,81.362,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.516 | Acc: 52.687,81.002,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 52.690,80.981,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.513 | Acc: 52.652,80.903,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.518 | Acc: 52.498,80.794,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.516 | Acc: 52.486,80.830,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.522 | Acc: 52.632,80.624,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.522 | Acc: 52.552,80.639,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.521 | Acc: 52.516,80.646,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.531 | Acc: 52.468,80.624,95.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.533 | Acc: 52.333,80.670,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.535 | Acc: 52.308,80.738,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.536 | Acc: 52.140,80.825,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.538 | Acc: 52.119,80.747,96.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.536 | Acc: 52.219,80.658,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.536 | Acc: 52.149,80.727,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 52.186,80.735,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.533 | Acc: 52.205,80.789,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.529 | Acc: 52.204,80.813,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.331 | Acc: 50.000,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 47.247,64.546,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 46.799,64.177,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 46.427,64.357,68.801,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 2.460 | Acc: 56.250,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.433 | Acc: 53.646,82.106,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.456 | Acc: 53.125,81.955,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.494 | Acc: 52.216,81.596,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.498 | Acc: 52.083,81.568,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.502 | Acc: 52.073,81.443,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.511 | Acc: 52.202,81.450,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.516 | Acc: 52.244,81.377,96.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 52.261,81.299,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.523 | Acc: 52.210,81.289,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 52.394,81.308,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 52.351,81.236,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 52.305,81.101,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.523 | Acc: 52.359,81.103,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 52.341,81.030,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 52.333,81.102,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.527 | Acc: 52.280,81.011,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.527 | Acc: 52.243,81.005,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.528 | Acc: 52.257,80.962,95.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.527 | Acc: 52.229,80.992,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.407 | Acc: 51.562,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 47.098,64.881,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 46.551,64.348,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 46.478,64.319,68.417,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.697 | Acc: 46.094,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.566 | Acc: 51.488,82.031,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.522 | Acc: 51.696,81.574,95.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.512 | Acc: 51.870,81.442,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.497 | Acc: 52.305,81.732,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 52.483,81.443,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.511 | Acc: 52.363,81.450,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.505 | Acc: 52.394,81.411,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.506 | Acc: 52.441,81.269,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 52.352,81.185,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 52.313,81.095,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.523 | Acc: 52.277,81.087,95.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 52.240,81.059,95.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.528 | Acc: 52.197,81.011,96.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.530 | Acc: 52.069,80.955,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.535 | Acc: 52.032,80.897,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.537 | Acc: 51.996,80.919,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.540 | Acc: 51.986,80.856,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.539 | Acc: 52.000,80.845,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.536 | Acc: 51.995,80.834,95.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.383 | Acc: 50.781,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 47.470,64.993,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.577 | Acc: 46.856,64.253,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.587 | Acc: 46.580,64.460,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.374 | Acc: 53.906,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.559 | Acc: 51.116,81.771,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.573 | Acc: 51.620,80.640,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.559 | Acc: 52.177,80.674,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 52.267,80.874,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.551 | Acc: 52.019,80.639,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.540 | Acc: 52.008,80.863,96.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.532 | Acc: 52.022,81.023,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.524 | Acc: 52.252,81.163,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.522 | Acc: 52.275,81.099,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.526 | Acc: 52.254,80.955,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.530 | Acc: 52.252,80.886,96.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.532 | Acc: 52.146,80.848,96.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.528 | Acc: 52.269,80.903,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 52.249,80.891,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.526 | Acc: 52.344,80.876,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.530 | Acc: 52.224,80.831,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.527 | Acc: 52.190,80.943,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.528 | Acc: 52.147,80.969,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.528 | Acc: 52.155,80.949,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.386 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 46.726,64.993,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 46.380,64.539,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 46.414,64.613,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.857 | Acc: 49.219,76.562,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.544 | Acc: 52.158,80.990,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.535 | Acc: 52.591,80.850,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.536 | Acc: 52.344,80.955,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 52.296,81.163,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.536 | Acc: 52.212,81.219,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.525 | Acc: 52.176,81.334,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.534 | Acc: 52.155,81.294,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.537 | Acc: 52.033,81.265,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.536 | Acc: 52.033,81.259,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 51.959,81.106,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.534 | Acc: 51.948,81.126,96.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.530 | Acc: 51.994,81.166,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.537 | Acc: 51.943,81.094,96.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.533 | Acc: 51.971,81.178,96.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.531 | Acc: 51.988,81.198,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.531 | Acc: 51.945,81.252,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.533 | Acc: 51.934,81.239,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.530 | Acc: 52.013,81.254,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.533 | Acc: 52.030,81.197,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.388 | Acc: 50.781,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 46.689,64.695,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 46.723,64.101,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 46.542,64.408,68.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.461 | Acc: 49.219,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.605 | Acc: 51.042,79.985,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.557 | Acc: 52.096,80.659,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.566 | Acc: 51.550,80.418,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.547 | Acc: 52.025,80.768,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.550 | Acc: 51.779,80.832,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.551 | Acc: 51.872,80.927,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.547 | Acc: 51.984,80.951,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.533 | Acc: 52.082,81.114,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.528 | Acc: 52.076,81.168,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.537 | Acc: 52.021,81.098,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.534 | Acc: 52.079,81.003,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.529 | Acc: 52.065,81.091,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.532 | Acc: 52.125,81.091,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.536 | Acc: 52.038,81.083,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.539 | Acc: 52.006,81.024,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.537 | Acc: 52.025,81.016,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.536 | Acc: 51.984,81.074,96.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.537 | Acc: 52.010,81.025,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.538 | Acc: 52.012,80.990,95.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.404 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 47.321,64.732,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 46.704,64.253,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 46.516,64.536,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 2.506 | Acc: 56.250,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.534 | Acc: 53.981,80.804,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.466 | Acc: 54.573,81.993,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.500 | Acc: 53.215,81.532,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 53.115,81.443,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.485 | Acc: 52.963,81.544,96.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 52.602,81.515,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.493 | Acc: 52.488,81.555,96.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.494 | Acc: 52.387,81.381,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.505 | Acc: 52.145,81.267,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.504 | Acc: 52.235,81.332,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.504 | Acc: 52.326,81.349,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.508 | Acc: 52.246,81.334,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.515 | Acc: 52.068,81.268,96.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 52.094,81.203,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 52.121,81.198,96.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.515 | Acc: 52.161,81.274,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.517 | Acc: 52.158,81.257,96.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.522 | Acc: 52.140,81.153,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 52.194,81.188,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.370 | Acc: 50.781,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 47.135,64.807,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 46.799,64.405,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 46.465,64.408,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.272 | Acc: 52.344,88.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.516 | Acc: 51.674,81.138,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.533 | Acc: 51.543,81.098,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.520 | Acc: 52.293,81.391,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.507 | Acc: 52.431,81.645,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.510 | Acc: 52.491,81.451,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.515 | Acc: 52.169,81.411,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.515 | Acc: 52.200,81.305,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 52.072,81.206,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.523 | Acc: 51.934,81.215,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.523 | Acc: 51.881,81.215,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.522 | Acc: 51.856,81.197,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.529 | Acc: 51.754,81.140,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.532 | Acc: 51.736,81.037,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.533 | Acc: 51.790,80.997,96.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.534 | Acc: 51.819,80.996,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.533 | Acc: 51.937,81.024,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.527 | Acc: 52.007,81.064,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.529 | Acc: 51.965,81.036,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.527 | Acc: 52.010,81.053,96.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.390 | Acc: 51.562,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 47.098,64.955,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 46.780,64.558,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 46.644,64.690,68.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 3.025 | Acc: 44.531,74.219,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.542 | Acc: 52.381,81.585,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 52.572,81.421,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.554 | Acc: 52.305,81.122,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.542 | Acc: 52.064,81.163,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.546 | Acc: 52.019,81.258,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.543 | Acc: 52.014,81.185,96.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.541 | Acc: 52.072,81.139,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.539 | Acc: 52.198,81.187,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.531 | Acc: 52.206,81.181,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.531 | Acc: 52.219,81.184,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.525 | Acc: 52.220,81.275,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 52.318,81.308,96.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 52.242,81.271,96.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 52.299,81.222,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.523 | Acc: 52.170,81.203,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 52.159,81.248,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 52.117,81.202,96.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.524 | Acc: 52.127,81.127,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.526 | Acc: 52.104,81.094,96.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.306 | Acc: 51.562,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 47.210,64.583,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 46.723,64.253,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 46.580,64.472,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.631 | Acc: 47.656,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.511 | Acc: 50.744,80.841,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.492 | Acc: 51.429,81.402,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.518 | Acc: 51.511,80.802,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.532 | Acc: 51.157,80.739,96.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 51.439,80.948,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.520 | Acc: 51.653,81.056,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.520 | Acc: 51.734,81.095,96.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.516 | Acc: 51.956,81.119,96.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.517 | Acc: 51.990,81.008,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 51.943,80.970,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.521 | Acc: 51.845,81.034,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 51.773,81.091,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 51.853,81.046,96.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 51.813,81.139,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.523 | Acc: 51.817,81.058,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 51.816,81.111,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.523 | Acc: 51.794,81.122,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.522 | Acc: 51.738,81.133,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 51.780,81.131,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.367 | Acc: 50.000,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 47.247,64.174,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 46.684,63.777,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 46.452,63.998,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.243 | Acc: 64.062,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.538 | Acc: 51.190,81.957,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.498 | Acc: 52.039,82.069,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.501 | Acc: 52.369,81.839,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.499 | Acc: 52.595,81.607,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 52.800,81.544,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.495 | Acc: 52.647,81.392,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.491 | Acc: 52.682,81.289,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.497 | Acc: 52.611,81.313,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.496 | Acc: 52.534,81.349,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.497 | Acc: 52.530,81.289,96.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.504 | Acc: 52.400,81.147,96.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.508 | Acc: 52.370,81.166,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.507 | Acc: 52.389,81.169,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.505 | Acc: 52.324,81.203,96.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.507 | Acc: 52.263,81.120,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 52.278,81.138,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.512 | Acc: 52.252,81.069,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.514 | Acc: 52.216,81.079,96.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.516 | Acc: 52.130,81.135,96.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.346 | Acc: 50.781,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.534 | Acc: 47.396,64.621,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 46.932,64.482,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 46.862,64.626,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.547 | Acc: 54.688,83.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.486 | Acc: 52.083,81.585,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.481 | Acc: 51.772,81.402,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.481 | Acc: 51.934,81.160,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 51.649,81.173,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.501 | Acc: 51.740,81.119,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.501 | Acc: 52.034,81.005,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 52.061,81.067,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.518 | Acc: 51.990,81.051,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 52.102,80.991,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.519 | Acc: 51.928,81.001,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.517 | Acc: 51.916,81.020,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 51.832,80.968,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.516 | Acc: 51.868,81.037,96.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 52.018,80.994,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.525 | Acc: 51.988,80.926,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.517 | Acc: 52.113,81.043,96.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.521 | Acc: 52.071,80.897,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.517 | Acc: 52.179,80.941,96.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.518 | Acc: 52.237,80.957,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.383 | Acc: 50.000,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.545 | Acc: 47.396,65.699,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 47.008,65.072,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.592 | Acc: 46.747,64.857,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.457 | Acc: 54.688,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.526 | Acc: 52.418,80.952,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.510 | Acc: 52.515,81.288,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.537 | Acc: 52.318,80.827,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.538 | Acc: 52.064,80.758,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 52.243,80.894,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.524 | Acc: 52.247,81.108,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.532 | Acc: 52.133,80.984,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.529 | Acc: 52.271,80.988,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.531 | Acc: 52.283,80.922,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.526 | Acc: 52.313,81.013,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.527 | Acc: 52.365,80.981,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.516 | Acc: 52.519,81.107,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.515 | Acc: 52.577,81.020,96.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.515 | Acc: 52.563,81.000,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.513 | Acc: 52.525,81.042,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.512 | Acc: 52.534,81.080,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.514 | Acc: 52.415,81.042,96.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.514 | Acc: 52.404,81.014,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.521 | Acc: 52.260,80.936,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.342 | Acc: 51.562,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.539 | Acc: 46.838,64.583,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 46.723,64.196,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 46.683,64.331,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.814 | Acc: 49.219,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.469 | Acc: 52.827,81.882,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.497 | Acc: 52.649,81.726,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.511 | Acc: 51.921,81.506,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.502 | Acc: 52.286,81.607,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 52.305,81.846,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.507 | Acc: 52.034,81.528,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.508 | Acc: 52.111,81.294,96.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 52.043,81.206,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.529 | Acc: 51.899,81.043,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.538 | Acc: 51.757,81.009,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 51.835,81.073,96.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.530 | Acc: 51.806,81.094,96.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.530 | Acc: 51.856,81.121,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.526 | Acc: 52.013,81.175,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.526 | Acc: 51.965,81.180,96.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 51.928,81.121,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.528 | Acc: 51.870,81.126,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.528 | Acc: 51.894,81.135,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.525 | Acc: 51.936,81.166,96.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.400 | Acc: 51.562,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 46.987,64.695,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 46.608,64.539,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.597 | Acc: 46.504,64.447,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.579 | Acc: 47.656,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.547 | Acc: 52.009,81.734,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.529 | Acc: 51.886,81.631,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.536 | Acc: 52.049,81.455,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.522 | Acc: 52.257,81.134,95.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.527 | Acc: 52.174,81.072,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.532 | Acc: 52.040,80.914,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.525 | Acc: 52.083,81.222,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.521 | Acc: 52.145,81.226,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.516 | Acc: 52.253,81.267,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 52.208,81.227,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.519 | Acc: 52.082,81.193,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 52.107,81.143,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.518 | Acc: 52.188,81.166,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 52.069,81.161,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.519 | Acc: 52.076,81.157,96.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 52.081,81.033,96.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.523 | Acc: 52.046,80.966,96.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.522 | Acc: 52.041,80.966,96.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.518 | Acc: 52.046,81.024,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.349 | Acc: 50.781,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 46.987,64.918,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 46.646,64.672,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 46.644,64.588,68.622,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.898 | Acc: 46.094,78.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.478 | Acc: 52.455,81.510,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.433 | Acc: 53.068,81.993,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.470 | Acc: 52.177,81.814,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.460 | Acc: 52.238,82.089,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.474 | Acc: 52.282,81.931,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.488 | Acc: 52.169,81.754,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 52.338,81.732,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.492 | Acc: 52.373,81.473,96.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.501 | Acc: 52.400,81.272,96.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.494 | Acc: 52.453,81.398,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.501 | Acc: 52.446,81.239,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.499 | Acc: 52.428,81.247,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.503 | Acc: 52.446,81.196,96.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.505 | Acc: 52.377,81.150,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.501 | Acc: 52.466,81.172,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.501 | Acc: 52.412,81.233,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.507 | Acc: 52.298,81.200,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 52.318,81.150,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.511 | Acc: 52.274,81.154,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.366 | Acc: 53.125,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 46.838,65.104,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 46.284,64.615,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 46.273,64.626,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.677 | Acc: 46.875,89.062,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.537 | Acc: 50.670,82.292,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.489 | Acc: 52.229,82.603,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 52.203,81.878,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.506 | Acc: 52.257,81.366,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 52.212,81.397,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.513 | Acc: 51.898,81.295,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.514 | Acc: 51.950,81.095,96.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.510 | Acc: 52.053,81.114,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.517 | Acc: 51.973,81.103,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 52.181,81.114,96.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 52.128,81.250,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.507 | Acc: 52.230,81.263,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 52.263,81.352,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.502 | Acc: 52.283,81.353,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.505 | Acc: 52.141,81.323,96.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.508 | Acc: 52.147,81.272,96.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.508 | Acc: 52.119,81.296,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 52.101,81.278,96.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.511 | Acc: 52.085,81.289,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.363 | Acc: 50.781,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 47.247,64.918,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 46.665,64.367,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 46.414,64.524,68.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.362 | Acc: 50.000,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.509 | Acc: 51.451,81.734,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.454 | Acc: 52.591,82.146,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 52.164,81.762,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.492 | Acc: 52.218,81.723,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.492 | Acc: 52.127,81.567,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.499 | Acc: 52.060,81.586,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.494 | Acc: 52.039,81.627,96.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 52.082,81.454,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.506 | Acc: 52.119,81.315,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.509 | Acc: 52.025,81.250,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.512 | Acc: 51.965,81.204,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.511 | Acc: 51.952,81.295,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.511 | Acc: 52.035,81.292,96.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 52.088,81.342,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 52.110,81.351,96.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.514 | Acc: 52.061,81.355,96.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.515 | Acc: 52.092,81.298,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.516 | Acc: 52.084,81.291,96.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.519 | Acc: 52.069,81.291,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.450 | Acc: 50.000,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.594 | Acc: 47.284,64.546,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.626 | Acc: 46.684,64.234,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.635 | Acc: 46.555,64.421,68.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.470 | Acc: 53.906,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.495 | Acc: 52.530,81.696,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.507 | Acc: 52.496,81.479,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.502 | Acc: 52.549,81.532,96.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.499 | Acc: 52.459,81.838,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 52.475,81.923,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 52.763,81.844,96.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.485 | Acc: 52.887,81.715,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.501 | Acc: 52.679,81.536,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.497 | Acc: 52.793,81.470,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.502 | Acc: 52.701,81.409,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.506 | Acc: 52.489,81.338,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.504 | Acc: 52.496,81.292,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.505 | Acc: 52.425,81.265,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.508 | Acc: 52.313,81.269,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.505 | Acc: 52.279,81.273,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.508 | Acc: 52.244,81.287,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.513 | Acc: 52.218,81.211,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.513 | Acc: 52.214,81.183,96.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.511 | Acc: 52.256,81.254,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.417 | Acc: 50.000,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 47.247,64.881,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 46.894,64.653,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.598 | Acc: 46.670,64.613,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.541 | Acc: 52.344,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.446 | Acc: 52.865,82.254,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 52.763,81.555,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 52.690,81.903,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.478 | Acc: 52.778,81.809,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 52.630,81.513,96.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 52.421,81.605,96.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.494 | Acc: 52.266,81.400,96.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 52.373,81.386,96.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.510 | Acc: 52.253,81.319,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 52.433,81.526,96.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.505 | Acc: 52.393,81.398,96.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.511 | Acc: 52.383,81.315,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.510 | Acc: 52.335,81.331,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.513 | Acc: 52.344,81.264,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 52.377,81.320,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.508 | Acc: 52.373,81.308,96.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.506 | Acc: 52.362,81.337,96.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.508 | Acc: 52.298,81.352,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.509 | Acc: 52.219,81.324,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.372 | Acc: 50.781,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 47.210,64.844,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 46.856,64.596,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 46.670,64.600,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.698 | Acc: 46.094,78.125,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.597 | Acc: 51.004,80.432,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.549 | Acc: 51.391,80.983,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.539 | Acc: 51.498,80.789,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.532 | Acc: 51.476,80.922,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.542 | Acc: 51.423,80.647,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.524 | Acc: 51.737,80.856,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.512 | Acc: 51.906,81.139,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.518 | Acc: 51.960,81.100,96.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.517 | Acc: 52.093,81.133,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.514 | Acc: 52.013,81.227,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.512 | Acc: 52.103,81.303,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.503 | Acc: 52.230,81.376,96.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 52.236,81.274,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.503 | Acc: 52.330,81.342,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.504 | Acc: 52.331,81.312,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.507 | Acc: 52.317,81.357,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.510 | Acc: 52.289,81.351,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.514 | Acc: 52.262,81.319,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.515 | Acc: 52.256,81.318,96.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.384 | Acc: 50.781,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.570 | Acc: 47.210,64.546,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.590 | Acc: 46.723,64.310,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.598 | Acc: 46.593,64.408,68.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.262 | Acc: 61.719,87.500,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.467 | Acc: 53.237,81.473,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.504 | Acc: 52.363,80.907,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.516 | Acc: 52.369,80.827,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.512 | Acc: 52.344,80.999,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 52.065,80.964,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.515 | Acc: 52.176,80.966,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.515 | Acc: 52.178,80.962,96.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.518 | Acc: 52.082,81.041,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.516 | Acc: 52.016,81.177,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.518 | Acc: 51.990,81.137,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 52.008,81.246,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 52.055,81.192,96.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.511 | Acc: 52.074,81.268,96.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.512 | Acc: 51.996,81.208,96.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.508 | Acc: 52.141,81.208,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.503 | Acc: 52.188,81.216,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 52.177,81.248,96.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 52.236,81.345,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 52.297,81.332,96.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.350 | Acc: 50.000,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.571 | Acc: 47.024,65.067,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 46.894,64.634,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 46.606,64.600,68.660,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.812 | Acc: 45.312,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.477 | Acc: 51.935,82.143,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.461 | Acc: 52.229,82.431,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.478 | Acc: 51.985,82.147,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 52.353,81.645,96.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.503 | Acc: 52.065,81.498,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.495 | Acc: 52.202,81.631,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.488 | Acc: 52.233,81.566,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.482 | Acc: 52.203,81.716,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 52.210,81.673,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.496 | Acc: 52.002,81.448,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 52.022,81.469,96.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 52.133,81.571,96.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.487 | Acc: 52.191,81.612,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 52.119,81.600,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 52.082,81.676,96.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 52.108,81.627,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 52.119,81.598,96.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.071,81.605,96.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.057,81.623,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 50.781,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 46.689,64.658,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 46.761,64.367,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 46.619,64.460,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.594 | Acc: 42.188,74.219,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.464 | Acc: 51.935,80.804,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.467 | Acc: 52.287,81.364,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 52.446,81.557,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 52.228,81.453,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 51.957,81.335,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.520 | Acc: 51.866,81.405,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.522 | Acc: 51.923,81.438,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.512 | Acc: 52.004,81.493,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 52.145,81.531,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 52.103,81.464,96.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.516 | Acc: 52.079,81.413,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.512 | Acc: 52.071,81.467,96.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.505 | Acc: 52.185,81.537,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.502 | Acc: 52.324,81.506,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.499 | Acc: 52.352,81.517,96.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.499 | Acc: 52.341,81.574,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.500 | Acc: 52.291,81.578,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 52.307,81.568,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 52.321,81.523,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.327 | Acc: 50.781,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 47.247,64.844,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 46.989,64.329,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.592 | Acc: 46.811,64.485,68.724,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.650 | Acc: 48.438,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.427 | Acc: 51.265,82.254,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 51.829,82.031,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.478 | Acc: 51.460,81.954,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.483 | Acc: 51.534,82.041,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 51.470,81.714,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 51.724,81.612,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.480 | Acc: 51.856,81.577,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.480 | Acc: 51.980,81.677,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 51.912,81.561,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.492 | Acc: 51.963,81.479,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 51.969,81.480,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 52.127,81.493,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.485 | Acc: 52.206,81.600,96.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 52.157,81.600,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 52.071,81.624,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 52.066,81.486,96.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 52.062,81.479,96.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 52.047,81.458,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 52.032,81.482,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.406 | Acc: 50.000,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 46.726,65.067,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 46.761,64.520,68.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 46.516,64.562,68.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.529 | Acc: 56.250,77.344,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.521 | Acc: 53.720,79.911,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.499 | Acc: 52.839,81.021,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.494 | Acc: 52.549,81.160,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 52.498,81.327,96.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.492 | Acc: 52.468,81.389,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 52.447,81.508,96.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.506 | Acc: 52.504,81.483,96.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.497 | Acc: 52.460,81.662,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.502 | Acc: 52.408,81.682,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.500 | Acc: 52.394,81.693,96.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.497 | Acc: 52.453,81.695,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.491 | Acc: 52.477,81.704,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 52.490,81.675,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.490 | Acc: 52.441,81.642,96.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 52.268,81.561,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 52.458,81.610,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.419,81.507,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.494 | Acc: 52.426,81.430,96.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.492 | Acc: 52.397,81.449,96.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.364 | Acc: 50.781,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 47.433,65.141,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.579 | Acc: 46.951,64.634,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.590 | Acc: 46.837,64.664,68.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.157 | Acc: 56.250,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.411 | Acc: 53.497,82.366,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.462 | Acc: 52.858,81.936,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.442 | Acc: 52.830,82.172,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.440 | Acc: 52.845,82.234,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.447 | Acc: 52.839,81.985,96.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.458 | Acc: 52.583,82.012,96.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.462 | Acc: 52.527,81.765,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.463 | Acc: 52.533,81.779,96.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.464 | Acc: 52.547,81.777,96.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.466 | Acc: 52.581,81.771,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 52.485,81.550,96.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 52.422,81.600,96.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 52.317,81.552,96.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 52.269,81.553,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.482 | Acc: 52.367,81.595,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 52.319,81.574,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 52.321,81.523,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 52.264,81.479,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.350,81.543,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.351 | Acc: 50.781,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.569 | Acc: 46.875,64.658,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 46.684,64.386,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 46.580,64.472,68.750,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.159 | Acc: 59.375,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.415 | Acc: 52.046,82.217,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.461 | Acc: 51.524,81.822,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.471 | Acc: 51.691,81.570,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.475 | Acc: 51.890,81.559,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.479 | Acc: 51.957,81.467,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.463 | Acc: 52.163,81.773,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.470 | Acc: 52.067,81.754,96.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.480 | Acc: 52.067,81.658,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 52.042,81.556,96.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.481 | Acc: 52.157,81.588,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 52.121,81.462,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.485 | Acc: 52.253,81.461,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.487 | Acc: 52.221,81.492,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.482 | Acc: 52.360,81.511,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 52.333,81.476,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 52.244,81.435,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.485 | Acc: 52.291,81.491,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.300,81.449,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.491 | Acc: 52.319,81.451,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.388 | Acc: 49.219,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 46.689,65.067,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 46.646,64.634,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 46.555,64.741,68.724,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.122 | Acc: 57.031,87.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.511 | Acc: 52.195,80.469,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.524 | Acc: 51.867,80.145,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 51.755,80.315,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.508 | Acc: 51.881,80.700,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.502 | Acc: 52.112,80.948,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.498 | Acc: 52.221,81.153,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 52.438,81.389,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.485 | Acc: 52.518,81.439,96.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.482 | Acc: 52.503,81.496,96.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.489 | Acc: 52.402,81.475,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 52.471,81.593,96.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.498 | Acc: 52.347,81.432,96.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.317,81.427,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.494 | Acc: 52.316,81.428,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.493 | Acc: 52.313,81.476,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 52.261,81.474,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.496 | Acc: 52.250,81.477,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.225,81.544,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.492 | Acc: 52.278,81.545,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.352 | Acc: 51.562,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.554 | Acc: 47.210,64.844,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 46.856,64.748,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.595 | Acc: 46.593,64.754,68.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.253 | Acc: 57.031,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.496 | Acc: 52.753,81.734,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 52.534,81.612,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.518 | Acc: 52.113,81.122,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.488 | Acc: 52.324,81.433,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.490 | Acc: 52.444,81.389,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.481 | Acc: 52.441,81.586,96.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.480 | Acc: 52.366,81.577,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.488 | Acc: 52.334,81.405,96.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.486 | Acc: 52.326,81.297,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.483 | Acc: 52.301,81.390,96.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.484 | Acc: 52.259,81.402,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.485 | Acc: 52.396,81.402,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 52.496,81.460,96.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.488 | Acc: 52.405,81.431,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 52.435,81.497,96.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 52.383,81.554,96.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.305,81.429,96.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.281,81.471,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.487 | Acc: 52.303,81.529,96.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.583 | Acc: 46.912,64.993,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 46.589,64.444,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.619 | Acc: 46.452,64.575,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.554 | Acc: 46.875,77.344,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.510 | Acc: 52.083,79.501,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.493 | Acc: 52.344,80.697,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.471 | Acc: 52.382,81.058,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.476 | Acc: 52.344,81.260,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.480 | Acc: 52.344,81.188,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 52.124,81.256,96.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 52.200,81.366,96.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 52.252,81.342,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.490 | Acc: 52.365,81.319,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 52.060,81.320,96.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 52.100,81.473,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 52.007,81.380,96.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 52.023,81.385,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 52.166,81.322,96.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.493 | Acc: 52.152,81.343,96.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 52.200,81.420,96.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 52.156,81.378,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.236,81.391,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.483 | Acc: 52.290,81.432,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.349 | Acc: 50.000,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.549 | Acc: 46.838,64.881,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 46.665,64.653,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.590 | Acc: 46.504,64.780,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.317 | Acc: 49.219,88.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 53.237,82.924,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.459 | Acc: 52.649,82.660,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.484 | Acc: 52.036,82.070,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.476 | Acc: 52.093,82.128,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.483 | Acc: 52.251,81.931,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.474 | Acc: 52.163,81.954,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.472 | Acc: 52.200,82.026,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.466 | Acc: 52.358,82.094,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.471 | Acc: 52.326,82.031,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.480 | Acc: 52.138,81.814,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.483 | Acc: 52.057,81.738,96.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.485 | Acc: 52.130,81.697,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.486 | Acc: 52.158,81.711,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 52.035,81.700,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.486 | Acc: 51.970,81.647,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.484 | Acc: 52.086,81.642,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.487 | Acc: 52.078,81.656,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.483 | Acc: 52.121,81.661,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.485 | Acc: 52.089,81.607,96.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.399 | Acc: 50.000,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.587 | Acc: 47.470,64.286,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 46.780,64.291,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.620 | Acc: 46.632,64.306,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.300 | Acc: 53.906,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.533 | Acc: 52.530,80.357,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.521 | Acc: 52.591,80.774,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.514 | Acc: 52.702,81.263,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 52.951,81.481,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.488 | Acc: 52.901,81.467,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.494 | Acc: 52.647,81.482,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 52.610,81.704,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.478 | Acc: 52.620,81.701,96.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.476 | Acc: 52.594,81.716,96.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.472 | Acc: 52.534,81.779,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 52.489,81.727,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.484 | Acc: 52.418,81.665,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.481 | Acc: 52.434,81.636,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.482 | Acc: 52.333,81.634,96.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.482 | Acc: 52.377,81.603,96.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 52.324,81.569,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.486 | Acc: 52.355,81.509,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.487 | Acc: 52.309,81.497,96.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.344,81.461,96.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.329 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 47.396,65.253,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 47.008,64.748,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.581 | Acc: 46.785,64.793,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.298 | Acc: 55.469,85.938,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.522 | Acc: 51.600,81.101,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.502 | Acc: 52.268,81.136,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.486 | Acc: 52.485,81.237,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 52.209,80.951,96.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.512 | Acc: 51.864,80.979,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 51.898,81.011,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 52.139,81.294,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.484 | Acc: 52.169,81.434,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.487 | Acc: 52.106,81.509,96.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.489 | Acc: 52.181,81.561,96.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.486 | Acc: 52.273,81.554,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 52.246,81.610,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 52.203,81.579,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.489 | Acc: 52.313,81.606,96.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.492 | Acc: 52.276,81.585,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 52.334,81.639,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.491 | Acc: 52.328,81.658,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.491 | Acc: 52.355,81.674,96.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.446,81.670,96.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.340 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 46.987,64.844,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 46.970,64.463,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 46.734,64.485,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.203 | Acc: 53.125,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.451 | Acc: 53.199,81.622,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.500 | Acc: 52.534,81.288,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.501 | Acc: 52.280,81.365,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 52.151,81.626,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 52.003,81.575,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 52.131,81.560,96.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.498 | Acc: 52.017,81.366,96.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.501 | Acc: 51.994,81.294,96.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.499 | Acc: 51.891,81.384,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.501 | Acc: 51.807,81.266,96.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.501 | Acc: 51.874,81.292,96.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.498 | Acc: 51.916,81.325,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 51.967,81.313,96.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.494 | Acc: 52.074,81.328,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.500 | Acc: 52.056,81.234,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.498 | Acc: 52.078,81.328,96.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.504 | Acc: 51.986,81.280,96.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.503 | Acc: 51.959,81.311,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 52.048,81.334,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.373 | Acc: 50.000,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 47.135,64.955,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 46.761,64.558,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 46.644,64.498,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.475 | Acc: 50.000,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.600 | Acc: 50.484,80.655,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.553 | Acc: 51.639,81.364,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.540 | Acc: 51.639,81.711,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.525 | Acc: 52.103,81.790,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.512 | Acc: 52.274,82.008,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.498 | Acc: 52.447,81.993,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.488 | Acc: 52.743,81.992,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.487 | Acc: 52.814,82.031,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.490 | Acc: 52.560,81.962,96.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.482 | Acc: 52.581,81.895,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.483 | Acc: 52.496,81.830,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.484 | Acc: 52.587,81.769,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 52.395,81.759,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.488 | Acc: 52.474,81.709,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.489 | Acc: 52.515,81.657,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 52.538,81.620,96.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 52.543,81.626,96.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 52.409,81.585,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 52.485,81.629,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.409 | Acc: 50.000,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 46.949,64.807,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 46.704,64.367,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 46.593,64.370,68.865,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.503 | Acc: 55.469,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.464 | Acc: 53.385,82.217,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.457 | Acc: 53.373,82.546,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.461 | Acc: 53.432,82.659,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.466 | Acc: 53.405,82.610,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.474 | Acc: 53.295,82.488,96.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.476 | Acc: 52.976,82.503,96.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.476 | Acc: 52.898,82.425,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.482 | Acc: 52.810,82.162,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 52.633,82.087,96.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.487 | Acc: 52.690,81.950,96.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.482 | Acc: 52.708,81.897,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.486 | Acc: 52.564,81.830,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 52.475,81.753,96.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 52.355,81.731,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 52.346,81.735,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 52.414,81.698,96.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.500 | Acc: 52.374,81.607,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.496 | Acc: 52.445,81.601,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.492 | Acc: 52.479,81.623,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.360 | Acc: 50.000,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.581 | Acc: 47.507,64.881,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 46.989,64.539,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 46.644,64.408,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.503 | Acc: 57.812,75.781,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.499 | Acc: 52.641,80.766,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.486 | Acc: 52.382,81.936,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.507 | Acc: 51.883,81.826,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.491 | Acc: 52.296,81.858,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.486 | Acc: 52.584,81.791,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.481 | Acc: 52.621,81.644,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 52.726,81.793,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.481 | Acc: 52.480,81.760,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.490 | Acc: 52.421,81.802,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.493 | Acc: 52.309,81.821,96.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.492 | Acc: 52.259,81.830,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 52.259,81.827,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.500 | Acc: 52.272,81.744,96.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.500 | Acc: 52.377,81.709,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.499 | Acc: 52.401,81.647,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.497 | Acc: 52.507,81.622,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 52.548,81.674,96.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.491 | Acc: 52.510,81.691,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.561,81.705,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.355 | Acc: 50.000,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 46.987,64.881,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 46.970,64.615,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 46.785,64.600,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.096 | Acc: 59.375,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.369 | Acc: 54.167,81.882,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.426 | Acc: 52.706,81.936,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.458 | Acc: 52.190,81.519,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.456 | Acc: 52.373,81.771,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.453 | Acc: 52.700,81.838,96.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.453 | Acc: 52.738,81.889,96.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.461 | Acc: 52.831,81.760,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.461 | Acc: 52.878,81.784,96.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.465 | Acc: 52.745,81.837,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.461 | Acc: 52.849,81.895,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.467 | Acc: 52.803,81.900,96.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.467 | Acc: 52.820,81.850,96.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.464 | Acc: 52.850,81.950,96.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.467 | Acc: 52.800,81.956,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.476 | Acc: 52.647,81.863,96.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.479 | Acc: 52.546,81.839,96.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 52.426,81.688,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.483 | Acc: 52.443,81.741,96.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 52.420,81.722,96.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.384 | Acc: 50.000,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.571 | Acc: 46.689,64.695,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 46.513,64.558,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 46.427,64.549,68.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 2.419 | Acc: 62.500,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.542 | Acc: 53.199,82.217,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.529 | Acc: 52.420,81.593,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.493 | Acc: 52.766,82.070,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 52.681,81.780,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.488 | Acc: 52.653,81.730,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.495 | Acc: 52.447,81.528,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.498 | Acc: 52.355,81.538,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 52.179,81.415,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.491 | Acc: 52.270,81.544,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.493 | Acc: 52.243,81.456,96.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.500 | Acc: 52.185,81.349,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.494 | Acc: 52.243,81.402,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.215,81.370,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 52.266,81.422,96.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.489 | Acc: 52.284,81.541,96.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.492 | Acc: 52.210,81.513,96.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.177,81.523,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.188,81.501,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.210,81.490,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 50.781,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 47.284,64.918,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 46.818,64.520,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 46.657,64.600,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.345 | Acc: 57.812,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.456 | Acc: 52.827,81.064,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.448 | Acc: 52.915,81.593,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.462 | Acc: 52.677,81.621,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.467 | Acc: 52.566,81.752,96.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.480 | Acc: 52.243,81.621,96.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.480 | Acc: 52.479,81.670,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.476 | Acc: 52.399,81.738,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.478 | Acc: 52.499,81.692,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.478 | Acc: 52.503,81.673,96.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.479 | Acc: 52.635,81.643,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.490 | Acc: 52.425,81.649,96.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 52.454,81.681,96.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.488 | Acc: 52.466,81.570,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.485 | Acc: 52.419,81.631,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 52.390,81.616,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 52.344,81.583,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.487 | Acc: 52.314,81.534,96.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.484 | Acc: 52.374,81.616,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 52.475,81.674,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.318 | Acc: 50.781,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.554 | Acc: 47.433,65.290,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 46.894,64.672,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.592 | Acc: 46.734,64.677,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.928 | Acc: 48.438,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.472 | Acc: 52.939,82.403,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.475 | Acc: 52.077,82.165,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.470 | Acc: 52.152,82.108,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.481 | Acc: 52.170,81.858,96.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.477 | Acc: 52.266,81.985,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.469 | Acc: 52.357,82.005,96.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.480 | Acc: 52.344,81.882,96.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.476 | Acc: 52.446,81.866,96.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.495,82.005,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.469 | Acc: 52.631,81.926,96.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.471 | Acc: 52.630,81.911,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.474 | Acc: 52.464,81.840,96.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.475 | Acc: 52.550,81.861,96.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.481 | Acc: 52.427,81.795,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 52.416,81.730,96.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.484 | Acc: 52.341,81.673,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.487 | Acc: 52.339,81.685,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.296,81.644,96.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.486 | Acc: 52.352,81.640,96.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.314 | Acc: 49.219,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.554 | Acc: 47.359,64.993,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 47.027,64.634,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.595 | Acc: 46.747,64.639,68.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.290 | Acc: 53.906,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.441 | Acc: 54.241,81.771,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.458 | Acc: 53.163,81.383,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.455 | Acc: 53.138,81.685,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.463 | Acc: 53.048,81.703,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.461 | Acc: 52.870,81.714,96.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.470 | Acc: 52.763,81.644,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.469 | Acc: 52.715,81.677,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 52.465,81.400,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.495 | Acc: 52.206,81.401,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.494 | Acc: 52.270,81.437,96.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.496 | Acc: 52.273,81.448,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.493 | Acc: 52.392,81.483,96.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 52.380,81.525,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 52.255,81.539,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.489 | Acc: 52.344,81.569,96.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 52.207,81.530,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.266,81.594,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.331,81.611,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.491 | Acc: 52.321,81.535,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.354 | Acc: 50.000,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 46.763,64.881,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 46.704,64.482,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 46.491,64.434,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.600 | Acc: 52.344,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.493 | Acc: 54.688,80.580,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.504 | Acc: 53.354,80.545,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.501 | Acc: 53.138,81.045,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.489 | Acc: 52.971,81.578,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.485 | Acc: 53.001,81.420,96.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 52.860,81.457,96.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 52.798,81.300,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.487 | Acc: 52.810,81.357,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.491 | Acc: 52.560,81.405,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.490 | Acc: 52.612,81.456,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.491 | Acc: 52.475,81.459,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 52.435,81.545,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 52.377,81.531,96.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 52.383,81.531,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 52.307,81.561,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.492 | Acc: 52.280,81.583,96.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.270,81.589,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.357,81.605,96.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.416,81.623,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.340 | Acc: 49.219,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.561 | Acc: 47.247,65.253,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 46.894,64.729,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 46.734,64.780,68.840,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.542 | Acc: 53.906,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.477 | Acc: 52.381,81.399,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.501 | Acc: 51.810,81.726,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.531 | Acc: 51.409,81.288,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.525 | Acc: 51.765,81.202,96.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.518 | Acc: 51.903,81.327,96.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 52.234,81.528,96.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.499 | Acc: 52.105,81.555,96.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 52.412,81.633,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.482 | Acc: 52.676,81.651,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.487 | Acc: 52.655,81.596,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.483 | Acc: 52.598,81.685,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.493 | Acc: 52.444,81.574,96.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 52.368,81.639,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 52.397,81.625,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 52.287,81.603,96.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 52.319,81.688,96.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 52.266,81.578,96.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.374,81.624,96.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.389,81.640,96.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.350 | Acc: 50.781,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 47.433,64.769,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 46.799,64.482,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 46.657,64.485,68.865,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.335 | Acc: 60.156,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.513 | Acc: 50.744,81.324,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.527 | Acc: 51.505,80.850,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 51.652,81.378,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.499 | Acc: 52.083,81.202,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.498 | Acc: 52.205,81.235,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.488 | Acc: 52.473,81.450,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.490 | Acc: 52.432,81.588,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 52.499,81.517,96.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.491 | Acc: 52.387,81.500,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.501 | Acc: 52.157,81.324,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 52.209,81.455,96.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.498 | Acc: 52.127,81.448,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 52.167,81.525,96.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 52.238,81.545,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 52.313,81.533,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 52.322,81.474,96.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 52.371,81.484,96.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.487 | Acc: 52.331,81.501,96.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.303,81.469,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.385 | Acc: 50.000,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 46.503,64.844,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 46.513,64.425,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 46.414,64.408,68.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.542 | Acc: 53.125,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.475 | Acc: 52.716,82.068,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 52.706,82.298,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 52.485,82.095,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 52.189,81.848,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.469 | Acc: 52.924,81.977,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 52.576,81.792,96.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.508 | Acc: 52.178,81.527,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 52.310,81.502,96.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.503 | Acc: 52.201,81.526,96.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.501 | Acc: 52.184,81.538,96.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.497 | Acc: 52.308,81.579,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 52.431,81.636,96.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 52.287,81.585,96.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.489 | Acc: 52.288,81.586,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 52.237,81.554,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.481 | Acc: 52.327,81.664,96.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.486 | Acc: 52.341,81.619,96.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 52.316,81.488,96.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.486 | Acc: 52.340,81.492,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.362 | Acc: 50.000,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.561 | Acc: 47.135,64.807,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 46.684,64.501,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 46.568,64.536,68.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.593 | Acc: 54.688,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.403 | Acc: 53.534,83.110,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.425 | Acc: 53.106,82.755,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 52.677,82.377,96.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.454 | Acc: 52.894,82.272,97.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.451 | Acc: 53.001,82.348,96.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.465 | Acc: 52.686,82.238,96.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.470 | Acc: 52.698,82.020,96.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.474 | Acc: 52.664,81.968,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 52.568,81.790,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.471 | Acc: 52.732,81.872,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.472 | Acc: 52.743,81.819,96.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 52.661,81.730,96.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.480 | Acc: 52.619,81.663,96.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.481 | Acc: 52.552,81.706,96.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.480 | Acc: 52.621,81.754,96.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.478 | Acc: 52.580,81.751,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.480 | Acc: 52.543,81.756,96.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.486 | Acc: 52.454,81.683,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.467,81.656,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.356 | Acc: 50.781,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 46.987,64.881,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 46.684,64.634,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.612 | Acc: 46.542,64.549,68.712,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 2.509 | Acc: 55.469,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.431 | Acc: 51.637,82.217,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.447 | Acc: 51.791,81.974,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.439 | Acc: 52.344,82.031,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.441 | Acc: 52.344,82.205,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.456 | Acc: 52.058,82.217,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.456 | Acc: 52.021,82.147,96.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.464 | Acc: 52.178,82.109,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.467 | Acc: 52.222,82.080,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.210,81.992,96.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.473 | Acc: 52.196,81.985,96.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 52.096,81.922,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 52.020,81.872,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.483 | Acc: 51.991,81.777,96.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.483 | Acc: 52.094,81.723,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.481 | Acc: 52.095,81.650,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 52.022,81.598,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 52.126,81.603,96.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 52.244,81.644,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.480 | Acc: 52.245,81.648,96.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.328 | Acc: 50.781,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 47.247,64.695,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 47.085,64.348,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.595 | Acc: 46.875,64.447,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.687 | Acc: 53.125,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.542 | Acc: 51.525,81.138,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.535 | Acc: 50.934,80.583,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.527 | Acc: 51.383,80.558,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.522 | Acc: 51.669,80.748,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.508 | Acc: 51.748,80.902,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.498 | Acc: 51.989,81.011,96.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.493 | Acc: 52.261,81.189,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.496 | Acc: 52.096,81.148,96.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.488 | Acc: 52.167,81.190,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.496 | Acc: 51.877,81.122,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.485 | Acc: 52.004,81.264,96.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.483 | Acc: 52.068,81.289,96.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 52.044,81.265,96.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.483 | Acc: 52.105,81.297,96.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 52.040,81.349,96.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.477 | Acc: 52.263,81.450,96.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.474 | Acc: 52.314,81.523,96.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.476 | Acc: 52.305,81.523,96.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.475 | Acc: 52.305,81.498,96.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 50.781,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 47.545,64.881,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 47.085,64.577,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.615 | Acc: 46.824,64.498,68.660,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.312 | Acc: 50.781,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.562 | Acc: 50.856,79.836,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.510 | Acc: 51.601,80.907,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.508 | Acc: 51.729,81.045,96.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.505 | Acc: 51.861,81.173,96.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 52.181,81.103,96.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.512 | Acc: 51.943,81.063,96.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.510 | Acc: 51.917,81.195,96.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.506 | Acc: 52.121,81.308,96.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.500 | Acc: 52.072,81.336,96.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.501 | Acc: 52.033,81.254,96.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 52.050,81.246,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.497 | Acc: 52.084,81.360,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 52.074,81.259,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.496 | Acc: 52.035,81.347,96.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.489 | Acc: 52.276,81.356,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 52.263,81.435,96.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 52.266,81.429,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.262,81.475,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.485 | Acc: 52.295,81.478,96.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.348 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.559 | Acc: 46.987,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 46.723,64.577,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.597 | Acc: 46.568,64.639,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.319 | Acc: 56.250,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.477 | Acc: 52.083,82.329,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.500 | Acc: 51.886,81.841,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.487 | Acc: 52.305,81.890,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.489 | Acc: 52.238,81.626,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 51.988,81.343,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.514 | Acc: 52.073,81.405,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.513 | Acc: 52.117,81.267,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.508 | Acc: 52.116,81.415,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.516 | Acc: 52.076,81.418,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.504 | Acc: 52.161,81.538,96.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.504 | Acc: 52.174,81.632,96.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.502 | Acc: 52.071,81.600,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 52.104,81.621,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.498 | Acc: 52.057,81.617,96.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 52.066,81.652,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 52.035,81.620,96.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.491 | Acc: 52.158,81.662,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 52.199,81.618,96.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.172,81.597,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.388 | Acc: 50.000,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 47.173,64.807,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 46.818,64.520,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 46.619,64.472,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.611 | Acc: 50.000,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.451 | Acc: 53.423,81.957,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.467 | Acc: 52.572,81.517,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 53.304,81.301,96.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.476 | Acc: 52.787,81.530,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.477 | Acc: 52.614,81.459,96.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.479 | Acc: 52.415,81.586,96.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.475 | Acc: 52.399,81.727,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.480 | Acc: 52.334,81.701,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.475 | Acc: 52.318,81.764,96.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.483 | Acc: 52.258,81.619,96.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.482 | Acc: 52.224,81.710,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.483 | Acc: 52.159,81.830,96.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.492 | Acc: 52.086,81.684,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.489 | Acc: 52.119,81.706,96.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.487 | Acc: 52.263,81.645,96.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.487 | Acc: 52.283,81.586,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 52.390,81.660,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.490 | Acc: 52.329,81.534,96.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.377,81.586,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.373 | Acc: 50.000,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 47.098,64.807,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 46.627,64.444,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.614 | Acc: 46.504,64.421,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.165 | Acc: 54.688,78.125,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.492 | Acc: 52.679,81.845,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.497 | Acc: 52.630,81.307,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 52.549,81.250,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.497 | Acc: 52.373,81.539,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.495 | Acc: 52.506,81.776,96.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 52.563,81.909,96.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.487 | Acc: 52.521,81.909,96.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.486 | Acc: 52.538,81.847,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 52.456,81.837,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.494 | Acc: 52.305,81.670,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.489 | Acc: 52.467,81.787,96.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.485 | Acc: 52.499,81.717,96.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.485 | Acc: 52.598,81.744,96.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.484 | Acc: 52.586,81.709,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 52.562,81.720,96.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.480 | Acc: 52.602,81.781,96.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.487 | Acc: 52.582,81.665,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.487 | Acc: 52.547,81.637,96.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.486 | Acc: 52.649,81.709,96.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.401 | Acc: 51.562,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 47.173,64.993,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 46.742,64.615,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 46.555,64.639,69.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.774 | Acc: 49.219,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.465 | Acc: 52.269,81.138,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.454 | Acc: 52.687,81.822,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 52.574,81.685,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.476 | Acc: 52.768,81.655,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.464 | Acc: 52.986,81.784,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.467 | Acc: 52.996,81.812,96.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.483 | Acc: 52.798,81.577,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.484 | Acc: 52.892,81.454,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.481 | Acc: 52.879,81.535,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.480 | Acc: 52.841,81.534,96.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.481 | Acc: 52.779,81.543,96.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.482 | Acc: 52.713,81.487,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.480 | Acc: 52.652,81.588,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.478 | Acc: 52.686,81.600,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.477 | Acc: 52.606,81.624,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.478 | Acc: 52.531,81.632,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.479 | Acc: 52.488,81.626,96.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.480 | Acc: 52.469,81.581,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 52.428,81.582,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.351 | Acc: 50.781,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 47.396,64.993,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 47.180,64.615,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 46.939,64.600,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.529 | Acc: 48.438,89.062,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.509 | Acc: 50.744,82.292,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.475 | Acc: 51.353,82.450,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.453 | Acc: 52.075,82.646,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.477 | Acc: 52.315,82.079,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.466 | Acc: 52.483,82.240,96.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.471 | Acc: 52.525,82.025,96.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.469 | Acc: 52.327,82.120,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.477 | Acc: 52.237,82.031,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.477 | Acc: 52.292,81.910,96.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.485 | Acc: 52.243,81.907,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.478 | Acc: 52.460,81.865,96.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.484 | Acc: 52.292,81.785,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.482 | Acc: 52.329,81.861,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.477 | Acc: 52.452,81.870,96.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.476 | Acc: 52.466,81.855,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.479 | Acc: 52.475,81.766,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.481 | Acc: 52.429,81.802,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 52.424,81.746,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 52.448,81.699,96.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 49.219,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 47.135,64.844,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 46.665,64.539,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.609 | Acc: 46.529,64.498,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.548 | Acc: 45.312,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.480 | Acc: 52.641,80.990,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.448 | Acc: 53.316,81.898,97.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.457 | Acc: 53.176,81.929,97.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.460 | Acc: 53.029,81.858,96.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.466 | Acc: 52.955,81.714,96.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.470 | Acc: 52.815,81.657,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.494 | Acc: 52.471,81.377,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.496 | Acc: 52.421,81.323,96.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.503 | Acc: 52.214,81.336,96.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.500 | Acc: 52.219,81.332,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.495 | Acc: 52.291,81.409,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 52.169,81.350,96.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 52.158,81.337,96.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 52.219,81.297,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 52.204,81.385,96.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 52.156,81.406,96.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 52.149,81.456,96.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.486 | Acc: 52.292,81.490,96.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.262,81.498,96.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.419 | Acc: 50.000,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 47.024,64.621,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 46.704,64.405,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 46.696,64.498,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 2.255 | Acc: 53.906,87.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.366 | Acc: 53.460,82.999,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.443 | Acc: 52.877,82.165,97.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 52.536,82.070,96.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.454 | Acc: 52.537,82.224,97.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.457 | Acc: 52.452,82.194,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.467 | Acc: 52.357,82.141,97.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.469 | Acc: 52.449,81.920,96.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.474 | Acc: 52.538,81.789,96.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.680,81.733,96.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.472 | Acc: 52.639,81.759,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.467 | Acc: 52.736,81.794,96.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.463 | Acc: 52.862,81.785,96.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.467 | Acc: 52.778,81.735,96.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.470 | Acc: 52.697,81.686,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.473 | Acc: 52.624,81.652,96.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.476 | Acc: 52.548,81.598,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.477 | Acc: 52.520,81.568,96.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 52.502,81.538,96.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.484 | Acc: 52.506,81.500,96.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.370 | Acc: 50.000,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 47.210,64.993,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 46.684,64.405,68.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 46.529,64.434,68.660,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.261 | Acc: 57.812,85.156,98.438,% | Adaptive Acc: 90.625% | clf_exit: 0.398 0.422 0.180
Batch: 20 | Loss: 2.545 | Acc: 50.967,80.878,96.540,% | Adaptive Acc: 86.570% | clf_exit: 0.357 0.437 0.206
Batch: 40 | Loss: 2.527 | Acc: 52.325,80.926,96.456,% | Adaptive Acc: 86.947% | clf_exit: 0.363 0.433 0.204
Batch: 60 | Loss: 2.495 | Acc: 52.779,80.943,96.516,% | Adaptive Acc: 87.026% | clf_exit: 0.359 0.439 0.202
Batch: 80 | Loss: 2.485 | Acc: 52.730,81.221,96.644,% | Adaptive Acc: 87.278% | clf_exit: 0.365 0.435 0.200
Batch: 100 | Loss: 2.480 | Acc: 52.661,81.389,96.682,% | Adaptive Acc: 87.090% | clf_exit: 0.365 0.437 0.198
Batch: 120 | Loss: 2.484 | Acc: 52.660,81.386,96.623,% | Adaptive Acc: 87.035% | clf_exit: 0.364 0.438 0.199
Batch: 140 | Loss: 2.474 | Acc: 52.804,81.555,96.604,% | Adaptive Acc: 87.051% | clf_exit: 0.365 0.438 0.198
Batch: 160 | Loss: 2.473 | Acc: 52.814,81.628,96.618,% | Adaptive Acc: 87.122% | clf_exit: 0.366 0.437 0.198
Batch: 180 | Loss: 2.481 | Acc: 52.663,81.548,96.599,% | Adaptive Acc: 87.086% | clf_exit: 0.366 0.437 0.197
Batch: 200 | Loss: 2.491 | Acc: 52.519,81.518,96.552,% | Adaptive Acc: 87.002% | clf_exit: 0.366 0.437 0.197
Batch: 220 | Loss: 2.493 | Acc: 52.471,81.508,96.553,% | Adaptive Acc: 86.888% | clf_exit: 0.365 0.439 0.196
Batch: 240 | Loss: 2.499 | Acc: 52.328,81.451,96.512,% | Adaptive Acc: 86.829% | clf_exit: 0.364 0.439 0.197
Batch: 260 | Loss: 2.500 | Acc: 52.383,81.382,96.501,% | Adaptive Acc: 86.877% | clf_exit: 0.364 0.438 0.198
Batch: 280 | Loss: 2.500 | Acc: 52.327,81.486,96.464,% | Adaptive Acc: 86.877% | clf_exit: 0.364 0.438 0.197
Batch: 300 | Loss: 2.498 | Acc: 52.365,81.502,96.491,% | Adaptive Acc: 86.836% | clf_exit: 0.364 0.439 0.196
Batch: 320 | Loss: 2.498 | Acc: 52.336,81.423,96.476,% | Adaptive Acc: 86.838% | clf_exit: 0.364 0.440 0.197
Batch: 340 | Loss: 2.494 | Acc: 52.417,81.433,96.502,% | Adaptive Acc: 86.847% | clf_exit: 0.364 0.440 0.197
Batch: 360 | Loss: 2.495 | Acc: 52.283,81.414,96.533,% | Adaptive Acc: 86.803% | clf_exit: 0.363 0.440 0.197
Batch: 380 | Loss: 2.495 | Acc: 52.327,81.461,96.516,% | Adaptive Acc: 86.805% | clf_exit: 0.363 0.440 0.196
Batch: 0 | Loss: 4.397 | Acc: 50.781,68.750,72.656,% | Adaptive Acc: 67.188% | clf_exit: 0.414 0.453 0.133
Batch: 20 | Loss: 4.585 | Acc: 46.912,64.993,69.680,% | Adaptive Acc: 63.393% | clf_exit: 0.431 0.359 0.210
Batch: 40 | Loss: 4.612 | Acc: 46.513,64.367,69.036,% | Adaptive Acc: 63.110% | clf_exit: 0.425 0.368 0.208
Batch: 60 | Loss: 4.628 | Acc: 46.376,64.293,68.699,% | Adaptive Acc: 63.140% | clf_exit: 0.420 0.372 0.208
model is save as models/resnet56_2con3_att_cifar100_adaptive0_circles2_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 7.215 | Acc: 50.781,37.500,35.156,% | Adaptive Acc: 48.438% | clf_exit: 0.414 0.109 0.477
Batch: 20 | Loss: 7.718 | Acc: 46.912,34.115,28.757,% | Adaptive Acc: 44.010% | clf_exit: 0.431 0.140 0.429
Batch: 40 | Loss: 7.729 | Acc: 46.513,33.422,27.934,% | Adaptive Acc: 44.017% | clf_exit: 0.425 0.139 0.437
Batch: 60 | Loss: 7.721 | Acc: 46.376,33.325,28.266,% | Adaptive Acc: 44.096% | clf_exit: 0.420 0.137 0.442
Batch: 0 | Loss: 4.667 | Acc: 50.781,63.281,68.750,% | Adaptive Acc: 66.406% | clf_exit: 0.414 0.320 0.266
Batch: 20 | Loss: 4.894 | Acc: 46.912,61.793,64.062,% | Adaptive Acc: 60.900% | clf_exit: 0.431 0.265 0.304
Batch: 40 | Loss: 4.909 | Acc: 46.513,61.261,63.377,% | Adaptive Acc: 60.709% | clf_exit: 0.425 0.273 0.302
Batch: 60 | Loss: 4.909 | Acc: 46.376,61.565,63.563,% | Adaptive Acc: 60.873% | clf_exit: 0.420 0.275 0.305
Batch: 0 | Loss: 4.397 | Acc: 50.781,68.750,72.656,% | Adaptive Acc: 67.188% | clf_exit: 0.414 0.453 0.133
Batch: 20 | Loss: 4.585 | Acc: 46.912,64.993,69.680,% | Adaptive Acc: 63.393% | clf_exit: 0.431 0.359 0.210
Batch: 40 | Loss: 4.612 | Acc: 46.513,64.367,69.036,% | Adaptive Acc: 63.110% | clf_exit: 0.425 0.368 0.208
Batch: 60 | Loss: 4.628 | Acc: 46.376,64.293,68.699,% | Adaptive Acc: 63.140% | clf_exit: 0.420 0.372 0.208







Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.354 |  Acc: 2.790,3.786,5.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 12.748 |  Acc: 4.100,5.830,8.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 12.275 |  Acc: 4.816,8.162,12.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 11.975 |  Acc: 5.730,9.470,13.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 11.567 |  Acc: 7.080,11.062,15.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 11.384 |  Acc: 8.130,11.750,16.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 10.919 |  Acc: 9.384,13.986,19.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 10.757 |  Acc: 10.260,14.380,21.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 10.301 |  Acc: 12.262,17.068,23.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 10.513 |  Acc: 11.610,15.800,21.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 9.762 |  Acc: 14.846,19.808,26.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 9.917 |  Acc: 14.390,18.180,25.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 9.288 |  Acc: 17.330,22.306,29.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 9.378 |  Acc: 16.660,20.780,28.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 8.871 |  Acc: 19.410,24.890,32.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 8.914 |  Acc: 18.180,24.020,32.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 8.503 |  Acc: 21.328,26.952,35.036,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 9.450 |  Acc: 18.270,23.490,29.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 8.193 |  Acc: 22.870,29.066,37.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 8.500 |  Acc: 20.240,27.560,35.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 7.920 |  Acc: 24.584,30.798,39.914,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 9.276 |  Acc: 18.440,22.850,31.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 7.675 |  Acc: 25.784,32.580,41.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 8.225 |  Acc: 21.910,28.910,40.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 7.462 |  Acc: 27.076,34.280,43.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 7.917 |  Acc: 24.210,30.450,41.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 7.274 |  Acc: 27.738,35.408,44.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 8.142 |  Acc: 23.180,29.240,40.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 7.100 |  Acc: 28.748,37.098,46.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 8.845 |  Acc: 19.680,27.740,37.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 6.950 |  Acc: 29.870,38.200,47.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 9.636 |  Acc: 17.830,22.130,32.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 6.801 |  Acc: 30.512,39.666,48.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 8.014 |  Acc: 23.090,31.950,42.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 6.690 |  Acc: 31.018,40.424,49.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 8.500 |  Acc: 19.780,29.600,40.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 6.561 |  Acc: 31.786,41.534,51.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 8.625 |  Acc: 21.790,28.920,39.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 6.449 |  Acc: 32.352,42.782,51.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 7.987 |  Acc: 24.560,33.580,43.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 6.347 |  Acc: 32.698,43.504,52.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 8.954 |  Acc: 19.580,31.430,38.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 6.259 |  Acc: 33.228,44.306,53.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 7.513 |  Acc: 26.660,36.850,45.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 6.157 |  Acc: 33.742,45.436,54.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 7.322 |  Acc: 26.440,35.990,47.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 6.069 |  Acc: 33.808,46.276,55.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 7.849 |  Acc: 24.490,36.500,45.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 6.021 |  Acc: 34.154,46.516,55.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 6.869 |  Acc: 28.680,40.460,50.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 5.944 |  Acc: 34.908,47.266,56.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 7.187 |  Acc: 27.380,39.550,48.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 5.889 |  Acc: 34.736,48.022,57.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 7.277 |  Acc: 25.190,38.520,48.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 5.806 |  Acc: 35.558,48.738,57.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 6.844 |  Acc: 29.710,41.770,49.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 5.748 |  Acc: 35.602,49.312,58.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 9.717 |  Acc: 17.270,31.290,43.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 5.706 |  Acc: 35.612,49.884,58.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 6.538 |  Acc: 31.450,43.870,53.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 5.659 |  Acc: 35.906,49.882,59.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 6.754 |  Acc: 29.530,43.040,51.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 5.605 |  Acc: 36.286,50.824,59.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 6.775 |  Acc: 29.830,43.200,51.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 5.560 |  Acc: 36.464,50.982,60.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 6.798 |  Acc: 30.710,42.840,49.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 5.499 |  Acc: 36.828,51.664,60.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 6.609 |  Acc: 30.100,44.000,53.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 5.485 |  Acc: 36.550,51.910,61.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 7.548 |  Acc: 27.220,38.060,47.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.445 |  Acc: 36.840,52.126,61.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 6.808 |  Acc: 29.100,43.520,52.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.391 |  Acc: 37.212,52.808,61.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 6.524 |  Acc: 29.030,44.510,53.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.353 |  Acc: 37.524,53.052,62.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 6.919 |  Acc: 28.780,42.410,50.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.318 |  Acc: 37.560,53.204,62.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 7.575 |  Acc: 24.940,41.160,50.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.304 |  Acc: 37.488,53.162,62.954,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 6.912 |  Acc: 30.560,43.010,52.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.278 |  Acc: 37.788,53.792,62.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 7.763 |  Acc: 19.810,40.090,50.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.226 |  Acc: 37.958,54.100,63.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 7.222 |  Acc: 26.090,41.580,51.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.198 |  Acc: 38.036,54.226,63.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 7.321 |  Acc: 26.610,39.530,50.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.176 |  Acc: 38.124,54.826,63.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 6.354 |  Acc: 32.440,47.310,54.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.142 |  Acc: 38.648,54.784,64.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 6.460 |  Acc: 28.870,44.990,56.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 5.137 |  Acc: 38.498,55.068,64.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 6.533 |  Acc: 29.940,44.270,54.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 5.119 |  Acc: 38.324,55.176,64.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 7.458 |  Acc: 25.900,38.490,49.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 5.092 |  Acc: 38.634,55.672,65.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 6.462 |  Acc: 30.110,47.040,55.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 5.067 |  Acc: 38.762,55.728,65.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 6.511 |  Acc: 29.080,45.350,55.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 5.038 |  Acc: 39.090,56.186,65.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 7.573 |  Acc: 27.160,39.390,50.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 5.024 |  Acc: 38.640,56.126,65.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 6.464 |  Acc: 27.540,45.950,55.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 5.006 |  Acc: 39.278,56.444,66.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 6.441 |  Acc: 27.760,47.300,57.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 4.984 |  Acc: 39.066,56.720,66.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 6.301 |  Acc: 31.350,48.260,55.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 4.952 |  Acc: 39.524,56.738,66.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 6.583 |  Acc: 29.880,45.730,53.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 4.959 |  Acc: 39.328,56.728,66.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 7.355 |  Acc: 28.280,39.160,50.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 4.914 |  Acc: 39.446,57.290,66.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 7.596 |  Acc: 26.860,38.630,50.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 4.926 |  Acc: 39.254,57.034,66.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 6.539 |  Acc: 28.840,46.380,54.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 4.897 |  Acc: 39.674,57.458,67.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.803 |  Acc: 27.040,46.590,56.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 4.873 |  Acc: 39.670,57.418,67.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 6.141 |  Acc: 30.970,49.830,56.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 4.871 |  Acc: 39.822,57.538,67.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 6.975 |  Acc: 25.960,45.780,51.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 4.844 |  Acc: 39.828,58.040,67.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 7.091 |  Acc: 30.530,40.160,51.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.824 |  Acc: 39.964,57.992,67.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 7.752 |  Acc: 24.020,41.820,48.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.825 |  Acc: 39.982,58.012,67.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 6.207 |  Acc: 32.440,48.690,56.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.792 |  Acc: 40.154,58.410,68.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 7.109 |  Acc: 27.080,42.270,52.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.799 |  Acc: 39.984,58.418,68.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 7.238 |  Acc: 25.330,42.780,53.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.774 |  Acc: 40.190,58.458,68.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 6.385 |  Acc: 30.880,46.990,55.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.785 |  Acc: 40.082,58.384,68.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 6.556 |  Acc: 28.810,44.680,56.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.740 |  Acc: 40.268,58.952,68.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 7.480 |  Acc: 28.980,41.650,51.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.749 |  Acc: 40.000,58.730,68.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 7.321 |  Acc: 24.110,42.670,51.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.740 |  Acc: 40.382,59.070,68.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 7.092 |  Acc: 28.660,43.610,53.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.724 |  Acc: 40.222,59.058,69.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 6.255 |  Acc: 30.050,47.670,58.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.730 |  Acc: 40.518,59.054,68.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 7.558 |  Acc: 24.350,43.800,53.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.707 |  Acc: 40.314,59.154,69.274,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 6.994 |  Acc: 30.570,43.080,52.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.692 |  Acc: 40.576,59.180,69.308,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.926 |  Acc: 28.110,45.390,55.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.667 |  Acc: 40.472,59.688,69.586,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 6.473 |  Acc: 30.560,47.300,53.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.671 |  Acc: 40.598,59.412,69.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 6.271 |  Acc: 32.800,48.560,56.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.657 |  Acc: 40.584,59.554,69.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 6.033 |  Acc: 34.690,48.780,56.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.662 |  Acc: 40.810,59.298,69.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 5.944 |  Acc: 33.750,50.900,58.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.637 |  Acc: 40.996,59.430,70.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 6.144 |  Acc: 32.790,48.410,57.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.641 |  Acc: 41.042,59.846,69.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 6.871 |  Acc: 32.550,41.360,53.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.621 |  Acc: 40.792,59.678,70.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 6.632 |  Acc: 29.090,46.830,56.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.605 |  Acc: 41.238,60.066,70.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.350 |  Acc: 33.110,48.110,57.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.615 |  Acc: 40.894,60.062,70.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 6.065 |  Acc: 34.800,49.620,57.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.588 |  Acc: 41.230,60.196,70.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 6.539 |  Acc: 33.510,45.910,55.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.576 |  Acc: 41.272,60.304,70.474,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 6.131 |  Acc: 30.400,51.460,58.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.591 |  Acc: 40.996,60.252,70.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 6.663 |  Acc: 28.950,46.360,54.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.572 |  Acc: 41.198,60.482,70.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 6.753 |  Acc: 29.970,45.680,56.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.560 |  Acc: 41.084,60.218,70.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 6.173 |  Acc: 30.160,49.970,59.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.564 |  Acc: 41.072,60.250,71.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 7.482 |  Acc: 25.200,44.040,51.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.559 |  Acc: 41.254,60.746,70.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 7.220 |  Acc: 23.340,47.240,55.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.544 |  Acc: 41.242,60.806,71.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 6.979 |  Acc: 25.830,42.650,55.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.527 |  Acc: 41.484,60.878,71.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 6.194 |  Acc: 32.210,49.170,58.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.531 |  Acc: 41.412,60.508,70.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 7.124 |  Acc: 28.270,40.590,54.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.535 |  Acc: 41.522,60.664,71.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 6.039 |  Acc: 30.630,51.740,58.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.524 |  Acc: 41.386,60.820,71.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 5.968 |  Acc: 33.800,49.350,58.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.510 |  Acc: 41.662,60.948,71.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 6.725 |  Acc: 29.410,45.860,55.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.499 |  Acc: 41.512,61.138,71.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 7.331 |  Acc: 27.610,42.810,52.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.506 |  Acc: 41.372,61.108,71.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 6.232 |  Acc: 32.850,48.530,57.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.494 |  Acc: 41.680,61.044,71.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 6.963 |  Acc: 28.010,44.820,54.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.495 |  Acc: 41.594,60.976,71.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 6.256 |  Acc: 32.550,47.730,58.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.478 |  Acc: 41.908,61.080,71.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 6.222 |  Acc: 33.010,49.410,57.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.467 |  Acc: 41.756,61.176,71.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 6.219 |  Acc: 31.800,49.140,57.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.474 |  Acc: 41.716,61.198,71.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.462 |  Acc: 28.340,49.710,56.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.466 |  Acc: 41.818,61.280,71.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 7.475 |  Acc: 24.700,42.900,55.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.446 |  Acc: 41.844,61.834,72.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 6.342 |  Acc: 29.470,49.250,57.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.464 |  Acc: 41.924,61.142,71.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 5.769 |  Acc: 34.160,50.690,61.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.456 |  Acc: 41.832,61.596,72.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 6.664 |  Acc: 28.590,46.760,55.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.443 |  Acc: 41.824,61.502,72.060,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 6.500 |  Acc: 32.250,47.070,55.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.443 |  Acc: 41.920,61.660,72.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 6.094 |  Acc: 34.410,48.910,58.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.439 |  Acc: 41.784,61.564,72.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 6.294 |  Acc: 30.890,48.900,58.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.431 |  Acc: 41.902,61.634,72.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 6.636 |  Acc: 33.400,46.050,54.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.418 |  Acc: 42.310,61.812,72.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 5.870 |  Acc: 32.500,51.660,60.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.418 |  Acc: 42.032,61.614,72.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 7.341 |  Acc: 23.230,42.670,56.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.419 |  Acc: 42.308,61.750,72.128,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 6.845 |  Acc: 27.020,46.040,56.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.410 |  Acc: 42.278,61.860,72.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 8.471 |  Acc: 21.590,40.530,52.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.394 |  Acc: 41.690,62.214,72.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.036 |  Acc: 34.660,49.270,57.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.427 |  Acc: 41.876,61.604,72.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 5.827 |  Acc: 36.710,51.230,57.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.395 |  Acc: 42.216,61.926,72.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 6.761 |  Acc: 28.730,44.940,55.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.377 |  Acc: 41.942,62.362,72.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 6.459 |  Acc: 32.000,45.180,56.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.402 |  Acc: 42.202,61.736,72.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 6.958 |  Acc: 26.730,45.830,56.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.396 |  Acc: 42.138,61.970,72.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 6.422 |  Acc: 30.050,48.770,60.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.374 |  Acc: 42.096,62.176,72.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 6.201 |  Acc: 32.880,48.330,58.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.363 |  Acc: 42.460,62.060,73.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 6.377 |  Acc: 29.100,48.840,59.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.366 |  Acc: 42.288,62.252,73.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 6.464 |  Acc: 31.550,47.940,57.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.366 |  Acc: 42.200,62.508,72.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 6.388 |  Acc: 27.900,48.690,58.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.351 |  Acc: 42.262,62.378,73.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 7.555 |  Acc: 25.270,42.220,54.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.332 |  Acc: 42.686,62.626,73.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 5.935 |  Acc: 33.820,50.180,59.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.368 |  Acc: 42.522,62.268,72.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 6.469 |  Acc: 30.690,46.950,56.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.341 |  Acc: 42.488,62.512,73.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 6.294 |  Acc: 30.630,49.210,59.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.348 |  Acc: 42.228,62.234,73.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 6.696 |  Acc: 25.730,48.770,57.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.333 |  Acc: 42.238,62.600,73.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 6.899 |  Acc: 30.490,43.300,51.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.344 |  Acc: 42.438,62.360,73.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 6.140 |  Acc: 33.550,50.110,58.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.329 |  Acc: 42.692,62.450,73.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 6.844 |  Acc: 28.480,47.830,57.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.313 |  Acc: 43.036,62.780,73.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 6.202 |  Acc: 31.740,50.030,58.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.327 |  Acc: 42.346,62.642,73.322,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 5.764 |  Acc: 35.620,51.560,60.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.316 |  Acc: 42.850,62.786,73.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 6.222 |  Acc: 31.740,50.880,58.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.323 |  Acc: 42.566,62.632,73.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 5.793 |  Acc: 35.470,51.170,59.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.320 |  Acc: 42.480,62.598,73.254,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 6.165 |  Acc: 31.810,49.490,60.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.317 |  Acc: 42.672,62.730,73.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.153 |  Acc: 32.050,50.510,58.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.303 |  Acc: 42.678,62.694,73.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 6.742 |  Acc: 26.720,47.700,56.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.310 |  Acc: 42.620,62.686,73.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 6.925 |  Acc: 27.350,49.590,58.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.310 |  Acc: 42.674,62.632,73.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 8.365 |  Acc: 20.440,37.560,51.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.313 |  Acc: 42.794,62.886,73.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 6.371 |  Acc: 32.890,49.280,57.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.306 |  Acc: 42.724,62.638,73.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 5.822 |  Acc: 33.410,51.990,60.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.290 |  Acc: 42.834,62.954,73.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 6.245 |  Acc: 30.950,49.980,59.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.284 |  Acc: 42.792,63.062,73.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 6.540 |  Acc: 29.490,48.540,57.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.292 |  Acc: 42.906,62.992,73.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 6.377 |  Acc: 30.820,48.360,57.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.296 |  Acc: 42.884,63.060,73.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 6.496 |  Acc: 30.200,47.530,57.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.301 |  Acc: 42.766,62.702,73.596,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 6.741 |  Acc: 29.830,45.510,55.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.279 |  Acc: 42.922,62.950,73.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 7.031 |  Acc: 25.350,44.310,56.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.612 |  Acc: 46.904,70.624,81.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.401 |  Acc: 44.380,62.950,70.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.422 |  Acc: 48.090,72.140,84.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.360 |  Acc: 45.000,63.380,70.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.354 |  Acc: 48.048,72.718,85.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.334 |  Acc: 45.010,63.880,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.310 |  Acc: 48.194,73.086,85.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.339 |  Acc: 45.150,63.970,70.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.267 |  Acc: 48.746,73.428,86.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.392 |  Acc: 44.970,64.150,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.238 |  Acc: 48.732,73.600,86.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.342 |  Acc: 45.410,64.180,70.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.212 |  Acc: 48.980,74.046,87.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.368 |  Acc: 45.020,64.150,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.189 |  Acc: 49.016,74.262,87.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.385 |  Acc: 44.960,64.420,70.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.172 |  Acc: 48.920,74.192,87.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.398 |  Acc: 44.860,63.850,70.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.161 |  Acc: 48.996,74.404,87.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.366 |  Acc: 44.920,64.080,70.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.128 |  Acc: 49.134,74.488,88.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.422 |  Acc: 44.580,63.700,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.124 |  Acc: 49.340,74.592,88.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.418 |  Acc: 44.880,64.230,70.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.102 |  Acc: 49.354,74.570,88.766,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.390 |  Acc: 45.300,64.400,70.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.093 |  Acc: 49.112,74.686,89.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.435 |  Acc: 44.790,64.120,70.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.076 |  Acc: 49.396,75.098,89.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.403 |  Acc: 45.140,64.380,70.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.073 |  Acc: 49.312,74.796,89.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.455 |  Acc: 45.080,64.030,70.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.060 |  Acc: 49.570,75.022,89.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.391 |  Acc: 45.260,64.350,69.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 3.055 |  Acc: 49.504,74.902,89.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.469 |  Acc: 45.060,64.100,69.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 3.040 |  Acc: 49.544,75.482,89.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.495 |  Acc: 44.650,63.780,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 3.014 |  Acc: 49.724,75.552,89.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.467 |  Acc: 45.250,63.780,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 3.013 |  Acc: 49.792,75.512,89.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.450 |  Acc: 45.870,64.060,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 3.005 |  Acc: 49.584,75.594,90.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.499 |  Acc: 44.890,63.990,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 2.998 |  Acc: 49.628,75.692,90.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.562 |  Acc: 44.470,63.760,69.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 2.997 |  Acc: 49.660,75.816,90.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.557 |  Acc: 44.650,64.290,68.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 2.985 |  Acc: 49.892,75.762,90.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.681 |  Acc: 43.000,63.350,69.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 2.977 |  Acc: 49.950,75.730,90.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.514 |  Acc: 45.240,64.230,68.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.974 |  Acc: 49.758,75.980,90.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.496 |  Acc: 45.220,64.350,69.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.968 |  Acc: 49.828,75.868,90.512,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.573 |  Acc: 44.750,63.250,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.946 |  Acc: 49.956,76.198,90.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.589 |  Acc: 44.260,64.210,68.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.946 |  Acc: 49.942,76.116,90.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.576 |  Acc: 44.680,63.480,68.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.946 |  Acc: 49.752,75.934,90.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.548 |  Acc: 45.350,64.150,69.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.933 |  Acc: 50.086,76.232,91.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.634 |  Acc: 42.980,63.650,69.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.938 |  Acc: 49.836,76.098,90.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.559 |  Acc: 45.140,63.800,68.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.931 |  Acc: 49.870,76.132,91.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.650 |  Acc: 44.720,63.180,68.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.928 |  Acc: 49.718,76.248,91.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.595 |  Acc: 44.720,64.340,69.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.910 |  Acc: 50.196,76.356,91.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.650 |  Acc: 44.500,63.600,68.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.909 |  Acc: 50.018,76.360,91.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.573 |  Acc: 45.000,63.560,68.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.907 |  Acc: 49.984,76.348,91.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.692 |  Acc: 44.000,63.310,68.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.897 |  Acc: 50.020,76.500,91.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.681 |  Acc: 44.230,63.440,68.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.891 |  Acc: 50.080,76.416,91.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.628 |  Acc: 44.980,63.940,68.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.891 |  Acc: 50.112,76.416,91.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.624 |  Acc: 44.840,63.760,68.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.876 |  Acc: 50.296,76.790,91.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.597 |  Acc: 44.900,64.120,68.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.872 |  Acc: 50.386,76.860,91.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.754 |  Acc: 43.290,62.980,68.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.870 |  Acc: 50.354,76.922,91.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.639 |  Acc: 45.010,63.280,68.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.866 |  Acc: 50.350,76.708,91.774,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.720 |  Acc: 44.550,62.440,68.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.869 |  Acc: 50.426,76.772,91.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.723 |  Acc: 43.790,63.160,68.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.866 |  Acc: 50.302,76.914,91.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.623 |  Acc: 44.940,63.410,67.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.864 |  Acc: 50.126,76.648,91.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.822 |  Acc: 43.030,62.430,67.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.865 |  Acc: 50.188,76.764,91.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.791 |  Acc: 43.470,63.230,67.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.870 |  Acc: 50.222,76.872,91.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.671 |  Acc: 45.430,63.380,68.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.846 |  Acc: 50.312,77.110,92.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.627 |  Acc: 45.460,63.520,68.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.856 |  Acc: 50.136,76.918,92.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.791 |  Acc: 43.410,62.560,67.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.848 |  Acc: 50.292,77.020,92.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.830 |  Acc: 43.230,62.520,67.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.846 |  Acc: 50.184,77.104,92.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.752 |  Acc: 44.110,62.730,68.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.852 |  Acc: 50.310,76.918,91.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.746 |  Acc: 43.970,62.820,68.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.839 |  Acc: 50.056,77.198,92.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.645 |  Acc: 45.380,63.250,68.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.841 |  Acc: 50.466,77.230,92.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.810 |  Acc: 44.290,62.190,67.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.826 |  Acc: 50.552,77.196,92.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.815 |  Acc: 43.400,63.040,67.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.817 |  Acc: 50.590,77.284,92.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.727 |  Acc: 44.650,62.940,67.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.822 |  Acc: 50.634,77.318,92.238,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.789 |  Acc: 44.330,63.200,67.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.819 |  Acc: 50.598,77.220,92.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.779 |  Acc: 43.800,63.140,67.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.829 |  Acc: 50.518,77.060,92.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.683 |  Acc: 45.400,63.260,67.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.829 |  Acc: 50.290,77.122,92.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.860 |  Acc: 43.480,62.720,67.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.814 |  Acc: 50.538,77.210,92.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.780 |  Acc: 44.450,63.040,67.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.815 |  Acc: 50.404,77.398,92.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.780 |  Acc: 43.660,62.690,67.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.818 |  Acc: 50.390,77.110,92.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.786 |  Acc: 44.750,61.980,67.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.807 |  Acc: 50.516,77.450,92.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.836 |  Acc: 43.970,62.060,67.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.808 |  Acc: 50.416,77.358,92.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.861 |  Acc: 43.270,62.210,67.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.802 |  Acc: 50.444,77.368,92.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.903 |  Acc: 43.880,62.360,67.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.801 |  Acc: 50.406,77.558,92.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.882 |  Acc: 44.300,62.230,66.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.805 |  Acc: 50.346,77.322,92.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.933 |  Acc: 42.980,62.280,66.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.801 |  Acc: 50.290,77.232,92.608,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.901 |  Acc: 43.360,62.050,67.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.805 |  Acc: 50.400,77.500,92.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 5.060 |  Acc: 42.670,61.040,66.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.799 |  Acc: 50.412,77.488,92.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.933 |  Acc: 43.440,62.380,66.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.796 |  Acc: 50.538,77.328,92.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.873 |  Acc: 43.290,62.160,67.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.661 |  Acc: 51.454,79.400,94.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.531 |  Acc: 46.280,65.070,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.606 |  Acc: 51.724,80.002,95.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.522 |  Acc: 46.430,64.700,69.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.581 |  Acc: 51.864,80.354,95.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.515 |  Acc: 46.730,65.100,69.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.579 |  Acc: 51.956,80.304,95.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.538 |  Acc: 46.310,64.900,69.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.568 |  Acc: 52.012,80.542,95.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.527 |  Acc: 46.620,64.850,69.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.560 |  Acc: 52.118,80.780,95.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.534 |  Acc: 46.620,64.830,69.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.565 |  Acc: 51.874,80.482,95.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.538 |  Acc: 46.300,64.820,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.562 |  Acc: 52.098,80.596,95.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.547 |  Acc: 46.740,64.970,69.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.552 |  Acc: 51.824,80.900,95.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.555 |  Acc: 46.550,64.820,68.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.554 |  Acc: 52.070,80.630,95.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.555 |  Acc: 46.840,64.900,69.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.550 |  Acc: 52.064,80.772,95.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.531 |  Acc: 46.710,65.060,69.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.554 |  Acc: 51.948,80.712,95.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.550 |  Acc: 46.600,64.920,69.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.539 |  Acc: 52.142,80.968,95.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.554 |  Acc: 46.380,64.660,69.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.539 |  Acc: 52.030,80.934,95.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.562 |  Acc: 46.510,64.730,68.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.544 |  Acc: 52.226,80.910,95.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.571 |  Acc: 46.560,64.760,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.543 |  Acc: 51.936,80.938,95.940,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.565 |  Acc: 46.700,64.950,69.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.530 |  Acc: 52.194,80.800,96.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.563 |  Acc: 46.600,64.600,69.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.530 |  Acc: 52.176,80.970,95.962,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.590 |  Acc: 46.690,64.590,68.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.536 |  Acc: 51.960,80.816,95.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.571 |  Acc: 46.790,64.760,69.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.530 |  Acc: 52.178,80.954,96.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.556 |  Acc: 46.640,64.880,69.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.533 |  Acc: 52.048,81.158,96.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.575 |  Acc: 46.790,64.650,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.535 |  Acc: 52.042,81.014,95.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.565 |  Acc: 46.720,64.730,68.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.521 |  Acc: 52.148,81.164,96.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.569 |  Acc: 46.720,64.730,69.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.528 |  Acc: 51.996,81.044,96.104,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.565 |  Acc: 46.810,64.890,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.531 |  Acc: 52.062,81.064,96.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.570 |  Acc: 46.840,64.720,69.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.521 |  Acc: 51.788,81.136,96.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.589 |  Acc: 46.620,64.320,68.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.517 |  Acc: 52.184,81.102,96.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.568 |  Acc: 47.030,64.950,69.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.520 |  Acc: 52.228,80.900,96.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.573 |  Acc: 46.900,65.080,69.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.523 |  Acc: 52.240,80.922,96.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.565 |  Acc: 46.840,64.670,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.524 |  Acc: 51.930,81.176,96.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.579 |  Acc: 46.790,64.690,69.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.520 |  Acc: 52.072,81.026,96.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.589 |  Acc: 46.800,64.770,68.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.510 |  Acc: 52.310,81.140,96.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.584 |  Acc: 46.550,64.750,68.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.513 |  Acc: 52.070,81.272,96.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.581 |  Acc: 46.650,64.690,68.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.519 |  Acc: 52.038,81.284,96.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.617 |  Acc: 46.710,64.720,68.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.513 |  Acc: 52.198,81.258,96.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.579 |  Acc: 46.870,64.860,69.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.510 |  Acc: 52.244,81.270,96.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.575 |  Acc: 46.800,64.880,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.515 |  Acc: 52.214,81.260,96.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.583 |  Acc: 46.720,64.610,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.501 |  Acc: 52.258,81.298,96.474,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.585 |  Acc: 46.800,64.850,68.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.492 |  Acc: 51.976,81.614,96.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.591 |  Acc: 46.740,64.730,69.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.498 |  Acc: 52.254,81.500,96.432,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.575 |  Acc: 46.970,64.840,68.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.495 |  Acc: 52.080,81.452,96.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.584 |  Acc: 46.750,64.750,69.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.489 |  Acc: 52.430,81.464,96.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.572 |  Acc: 47.040,64.940,69.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.487 |  Acc: 52.336,81.576,96.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.588 |  Acc: 46.840,64.700,69.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.490 |  Acc: 52.340,81.458,96.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.588 |  Acc: 46.870,64.990,69.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.493 |  Acc: 52.264,81.556,96.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.577 |  Acc: 46.880,64.860,69.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.487 |  Acc: 52.280,81.586,96.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.599 |  Acc: 46.670,64.880,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.484 |  Acc: 52.310,81.400,96.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.570 |  Acc: 46.730,65.030,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.487 |  Acc: 52.066,81.586,96.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.602 |  Acc: 46.880,64.590,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.490 |  Acc: 52.332,81.442,96.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.566 |  Acc: 46.950,64.920,69.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.488 |  Acc: 52.470,81.654,96.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.576 |  Acc: 46.920,64.700,69.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.497 |  Acc: 52.062,81.360,96.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.582 |  Acc: 46.920,64.790,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.488 |  Acc: 52.580,81.660,96.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.582 |  Acc: 46.830,64.680,69.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.487 |  Acc: 52.520,81.652,96.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.596 |  Acc: 46.860,64.740,69.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.491 |  Acc: 52.536,81.694,96.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.577 |  Acc: 46.990,64.840,69.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.487 |  Acc: 52.358,81.680,96.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.586 |  Acc: 46.710,64.790,69.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.490 |  Acc: 52.222,81.482,96.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.580 |  Acc: 46.860,64.900,69.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.482 |  Acc: 52.460,81.644,96.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.577 |  Acc: 47.020,64.890,69.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.489 |  Acc: 52.334,81.610,96.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.576 |  Acc: 46.920,64.920,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.496 |  Acc: 52.222,81.462,96.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.584 |  Acc: 46.730,64.720,69.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.491 |  Acc: 52.374,81.622,96.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.584 |  Acc: 46.840,65.000,69.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.490 |  Acc: 52.350,81.630,96.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.588 |  Acc: 46.910,64.810,69.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.488 |  Acc: 52.292,81.538,96.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.590 |  Acc: 46.640,64.720,69.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.486 |  Acc: 52.330,81.508,96.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.583 |  Acc: 46.850,64.740,69.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.484 |  Acc: 52.508,81.676,96.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.592 |  Acc: 46.770,64.820,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.480 |  Acc: 52.214,81.670,96.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.577 |  Acc: 47.060,64.840,69.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.476 |  Acc: 52.292,81.494,96.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.596 |  Acc: 47.030,64.820,68.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.485 |  Acc: 52.312,81.458,96.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.582 |  Acc: 46.760,64.890,69.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.489 |  Acc: 52.162,81.616,96.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.583 |  Acc: 46.930,64.730,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.490 |  Acc: 52.346,81.592,96.500,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.595 |  Acc: 46.760,64.710,69.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.486 |  Acc: 52.604,81.696,96.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.582 |  Acc: 46.870,64.940,69.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.481 |  Acc: 52.462,81.588,96.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.584 |  Acc: 47.030,64.910,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.481 |  Acc: 52.468,81.724,96.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.592 |  Acc: 46.790,64.770,69.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.484 |  Acc: 52.342,81.534,96.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.593 |  Acc: 46.920,64.720,69.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.483 |  Acc: 52.508,81.508,96.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.586 |  Acc: 46.790,64.660,69.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.496 |  Acc: 52.296,81.442,96.500,% | Adaptive Acc:86.798% | clf_exit: 0.363 0.440 0.197
Testing: Epoch=299 | Loss: 4.612 |  Acc: 46.590,64.550,69.030,% | Adaptive Acc:63.620% | clf_exit: 0.421 0.372 0.207

circles: 0
Testing: Epoch=299 | Loss: 7.688 |  Acc: 46.590,34.060,28.400,% | Adaptive Acc:44.530% | clf_exit: 0.421 0.138 0.442
circles: 1
Testing: Epoch=299 | Loss: 4.890 |  Acc: 46.590,62.020,63.790,% | Adaptive Acc:61.240% | clf_exit: 0.421 0.274 0.305
circles: 2
Testing: Epoch=299 | Loss: 4.612 |  Acc: 46.590,64.550,69.030,% | Adaptive Acc:63.620% | clf_exit: 0.421 0.372 0.207
