==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (linear_h): Linear(in_features=64, out_features=64, bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (linear_h): Linear(in_features=128, out_features=80, bias=False)
      (linear): Linear(in_features=80, out_features=100, bias=True)
      (BN1d): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=144, out_features=100, bias=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 10.060 | Acc: 0.000,0.000,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.877 | Acc: 1.116,1.079,1.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.666 | Acc: 1.353,1.334,1.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.504 | Acc: 1.716,1.742,2.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.376 | Acc: 1.987,2.257,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.271 | Acc: 2.328,2.468,3.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.188 | Acc: 2.499,2.809,4.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.115 | Acc: 2.665,2.959,4.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.056 | Acc: 2.790,3.140,4.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.994 | Acc: 2.883,3.341,5.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.945 | Acc: 3.055,3.514,5.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.894 | Acc: 3.196,3.676,5.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.844 | Acc: 3.300,3.913,5.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.801 | Acc: 3.373,4.032,6.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.758 | Acc: 3.461,4.184,6.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.716 | Acc: 3.579,4.322,6.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.680 | Acc: 3.702,4.515,7.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.646 | Acc: 3.805,4.616,7.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.612 | Acc: 3.913,4.746,7.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.580 | Acc: 4.035,4.893,7.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.924 | Acc: 3.906,8.594,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.065 | Acc: 6.324,8.073,10.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.062 | Acc: 5.812,7.870,10.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.080 | Acc: 5.930,7.812,10.515,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 8.007 | Acc: 7.031,10.156,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.967 | Acc: 5.729,7.292,10.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.951 | Acc: 5.659,7.774,11.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.936 | Acc: 6.007,8.235,11.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.900 | Acc: 6.269,8.488,12.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.894 | Acc: 6.250,8.284,12.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.880 | Acc: 6.360,8.361,12.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.862 | Acc: 6.666,8.511,12.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.845 | Acc: 6.920,8.744,12.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.833 | Acc: 6.949,8.879,12.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.818 | Acc: 7.008,8.963,13.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.806 | Acc: 7.042,9.071,13.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.789 | Acc: 7.099,9.158,13.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.775 | Acc: 7.184,9.267,13.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.762 | Acc: 7.304,9.364,13.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.748 | Acc: 7.410,9.458,13.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.732 | Acc: 7.484,9.555,13.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.718 | Acc: 7.613,9.652,13.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.706 | Acc: 7.706,9.745,14.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.693 | Acc: 7.774,9.822,14.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.351 | Acc: 7.031,11.719,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.438 | Acc: 8.557,11.421,16.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.436 | Acc: 8.365,11.490,16.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.453 | Acc: 8.350,11.578,16.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 7.388 | Acc: 9.375,10.938,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.423 | Acc: 9.598,11.830,17.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.404 | Acc: 9.394,11.128,16.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.400 | Acc: 9.721,11.194,17.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.399 | Acc: 9.375,11.150,16.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.386 | Acc: 9.460,11.309,16.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.371 | Acc: 9.440,11.383,17.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.352 | Acc: 9.569,11.669,17.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.339 | Acc: 9.579,11.811,17.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.324 | Acc: 9.716,11.969,17.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.313 | Acc: 9.810,12.131,17.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.304 | Acc: 9.831,12.210,17.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.296 | Acc: 9.933,12.257,17.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.287 | Acc: 9.980,12.386,17.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.270 | Acc: 10.145,12.561,18.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.257 | Acc: 10.276,12.687,18.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.252 | Acc: 10.276,12.748,18.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.245 | Acc: 10.314,12.821,18.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.235 | Acc: 10.405,12.911,18.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.225 | Acc: 10.490,12.961,18.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.067 | Acc: 11.719,15.625,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.215 | Acc: 10.565,12.091,18.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.195 | Acc: 10.099,11.776,17.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.193 | Acc: 10.284,11.949,17.815,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 7.103 | Acc: 14.062,14.062,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.024 | Acc: 12.277,14.360,21.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.961 | Acc: 12.157,14.844,21.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.960 | Acc: 12.308,15.190,21.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.937 | Acc: 12.461,15.355,21.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.929 | Acc: 12.732,15.540,21.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.917 | Acc: 12.661,15.476,21.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.909 | Acc: 12.749,15.536,21.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.889 | Acc: 12.772,15.698,21.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.887 | Acc: 12.742,15.746,21.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.890 | Acc: 12.675,15.695,21.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.887 | Acc: 12.652,15.632,21.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.877 | Acc: 12.646,15.703,21.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.876 | Acc: 12.617,15.673,21.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.866 | Acc: 12.709,15.792,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.854 | Acc: 12.775,15.918,21.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.847 | Acc: 12.855,15.944,21.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.843 | Acc: 12.889,15.969,21.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.831 | Acc: 12.989,16.058,22.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.827 | Acc: 12.972,16.109,22.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.574 | Acc: 11.719,17.188,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.677 | Acc: 14.249,16.629,24.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.652 | Acc: 13.529,16.768,24.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.657 | Acc: 13.307,16.842,23.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 6.634 | Acc: 12.500,17.188,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.639 | Acc: 13.839,16.815,24.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.614 | Acc: 13.872,16.921,24.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.610 | Acc: 14.229,17.623,24.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.613 | Acc: 14.120,17.573,24.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.607 | Acc: 14.117,17.713,24.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.594 | Acc: 14.185,17.898,24.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.574 | Acc: 14.522,18.152,24.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.555 | Acc: 14.810,18.313,24.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.549 | Acc: 14.865,18.465,24.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.541 | Acc: 14.902,18.486,24.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.541 | Acc: 14.876,18.517,24.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.535 | Acc: 14.912,18.559,24.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.526 | Acc: 14.993,18.726,25.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.518 | Acc: 15.075,18.817,25.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.506 | Acc: 15.137,18.976,25.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.506 | Acc: 15.082,18.898,25.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.498 | Acc: 15.126,18.954,25.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.490 | Acc: 15.168,19.001,25.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.481 | Acc: 15.305,19.140,25.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.365 | Acc: 14.062,17.969,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.541 | Acc: 13.318,17.113,25.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.524 | Acc: 12.919,17.073,24.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.532 | Acc: 12.705,17.034,24.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 6.038 | Acc: 22.656,21.875,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.309 | Acc: 15.737,19.717,27.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.263 | Acc: 15.854,19.874,28.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.250 | Acc: 16.778,20.492,28.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.239 | Acc: 16.860,20.592,28.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.234 | Acc: 16.855,20.699,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.231 | Acc: 16.949,20.726,28.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.208 | Acc: 17.110,20.905,28.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.215 | Acc: 17.066,20.725,28.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.211 | Acc: 17.032,20.761,28.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.201 | Acc: 17.063,20.833,28.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.197 | Acc: 17.064,20.928,29.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.197 | Acc: 17.045,20.928,29.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.196 | Acc: 17.086,21.070,29.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.187 | Acc: 17.162,21.183,29.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.180 | Acc: 17.136,21.291,29.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.177 | Acc: 17.166,21.430,29.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.171 | Acc: 17.229,21.497,29.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.170 | Acc: 17.252,21.503,29.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.162 | Acc: 17.347,21.565,29.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.037 | Acc: 17.188,25.000,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.097 | Acc: 16.741,22.173,29.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.103 | Acc: 16.921,22.180,29.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.109 | Acc: 16.906,22.067,29.214,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 5.860 | Acc: 17.969,21.875,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.976 | Acc: 18.527,23.140,30.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.984 | Acc: 18.140,22.732,31.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.952 | Acc: 18.443,23.386,31.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.954 | Acc: 18.104,23.167,31.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.950 | Acc: 18.294,23.151,31.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.943 | Acc: 18.518,23.224,31.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.931 | Acc: 18.656,23.521,31.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.924 | Acc: 18.799,23.646,31.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.919 | Acc: 18.897,23.727,31.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.916 | Acc: 18.964,23.745,31.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.915 | Acc: 18.973,23.890,31.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.912 | Acc: 18.909,23.823,31.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.915 | Acc: 18.858,23.791,31.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.907 | Acc: 18.886,23.899,31.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.905 | Acc: 18.916,23.866,31.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.900 | Acc: 19.027,23.924,32.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.891 | Acc: 19.139,24.033,32.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.885 | Acc: 19.211,24.080,32.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.875 | Acc: 19.246,24.110,32.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.724 | Acc: 19.531,18.750,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.971 | Acc: 16.741,21.912,32.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.965 | Acc: 16.616,21.894,32.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.984 | Acc: 16.739,22.170,31.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 5.490 | Acc: 18.750,29.688,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.733 | Acc: 20.238,25.744,33.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.719 | Acc: 20.332,25.191,33.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.715 | Acc: 20.133,25.487,33.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.680 | Acc: 20.534,25.926,34.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.694 | Acc: 20.289,25.743,34.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.696 | Acc: 20.409,25.878,34.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.690 | Acc: 20.368,25.654,34.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.689 | Acc: 20.502,25.839,34.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.681 | Acc: 20.645,25.971,34.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.688 | Acc: 20.561,25.871,34.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.672 | Acc: 20.804,26.103,34.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.664 | Acc: 20.912,26.222,34.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.659 | Acc: 20.860,26.170,34.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.656 | Acc: 20.813,26.162,34.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.654 | Acc: 20.873,26.191,34.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.656 | Acc: 20.807,26.154,34.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.652 | Acc: 20.821,26.173,34.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.647 | Acc: 20.841,26.242,34.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.642 | Acc: 20.901,26.267,34.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.832 | Acc: 18.750,24.219,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.839 | Acc: 17.374,23.363,33.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.842 | Acc: 16.883,23.399,33.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.851 | Acc: 17.098,23.079,32.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 5.465 | Acc: 20.312,25.781,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.482 | Acc: 21.280,26.525,36.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.421 | Acc: 22.504,28.506,37.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.444 | Acc: 22.400,28.445,37.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.429 | Acc: 22.521,28.308,37.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.433 | Acc: 22.239,28.110,37.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.442 | Acc: 21.952,28.028,37.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.445 | Acc: 22.124,28.070,37.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.436 | Acc: 22.059,28.115,37.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.453 | Acc: 21.996,27.991,37.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.450 | Acc: 21.929,28.001,37.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.450 | Acc: 21.829,27.955,37.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.442 | Acc: 21.859,28.012,37.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.434 | Acc: 21.977,28.140,37.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.430 | Acc: 22.061,28.225,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.425 | Acc: 22.077,28.314,37.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.421 | Acc: 22.123,28.381,37.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.421 | Acc: 22.088,28.400,37.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.423 | Acc: 22.117,28.326,37.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.420 | Acc: 22.156,28.338,37.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.896 | Acc: 16.406,29.688,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.847 | Acc: 16.592,23.177,33.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.877 | Acc: 16.159,22.904,32.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.861 | Acc: 15.971,23.053,33.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 5.372 | Acc: 20.312,25.000,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.303 | Acc: 22.098,28.311,38.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.332 | Acc: 22.218,28.411,38.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.303 | Acc: 22.298,28.868,39.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.301 | Acc: 22.647,29.003,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.278 | Acc: 23.128,29.409,39.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.275 | Acc: 23.095,29.236,39.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.279 | Acc: 23.088,29.261,39.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.272 | Acc: 23.151,29.362,39.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.276 | Acc: 23.183,29.381,39.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.280 | Acc: 23.127,29.361,39.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.289 | Acc: 23.155,29.306,38.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.288 | Acc: 23.191,29.457,38.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.278 | Acc: 23.279,29.508,38.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.270 | Acc: 23.443,29.554,39.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.259 | Acc: 23.601,29.771,39.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.250 | Acc: 23.620,29.960,39.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.245 | Acc: 23.630,29.995,39.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.240 | Acc: 23.624,29.990,39.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.243 | Acc: 23.573,29.934,39.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.291 | Acc: 24.219,35.156,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.425 | Acc: 21.875,30.022,37.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.449 | Acc: 22.008,28.811,37.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.467 | Acc: 21.760,28.496,37.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 5.241 | Acc: 18.750,29.688,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.166 | Acc: 23.289,30.171,40.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.123 | Acc: 23.571,30.583,40.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.102 | Acc: 23.796,31.365,40.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.097 | Acc: 24.122,31.578,41.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.099 | Acc: 23.894,31.351,41.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.110 | Acc: 23.948,31.276,41.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.092 | Acc: 24.335,31.438,41.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.104 | Acc: 24.282,31.328,41.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.095 | Acc: 24.456,31.634,41.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.091 | Acc: 24.596,31.744,41.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.094 | Acc: 24.449,31.582,41.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.091 | Acc: 24.420,31.487,41.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.083 | Acc: 24.446,31.678,41.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.077 | Acc: 24.494,31.750,41.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.073 | Acc: 24.543,31.743,41.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.076 | Acc: 24.535,31.729,41.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.078 | Acc: 24.496,31.644,41.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.078 | Acc: 24.437,31.605,41.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.075 | Acc: 24.494,31.664,41.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.041 | Acc: 19.531,31.250,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.369 | Acc: 19.234,27.344,38.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.367 | Acc: 19.684,27.287,37.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.396 | Acc: 19.582,27.011,38.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 4.926 | Acc: 28.125,32.031,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.942 | Acc: 26.079,33.929,42.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.947 | Acc: 24.752,32.946,42.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.950 | Acc: 24.769,32.787,42.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.915 | Acc: 24.817,32.880,42.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.923 | Acc: 24.946,32.859,42.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.927 | Acc: 25.032,32.896,43.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.938 | Acc: 25.072,32.912,42.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.939 | Acc: 25.112,32.866,42.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.935 | Acc: 25.181,32.916,43.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.937 | Acc: 25.117,32.875,42.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.932 | Acc: 25.219,32.950,43.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.927 | Acc: 25.389,33.056,43.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.925 | Acc: 25.326,32.935,43.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.925 | Acc: 25.275,32.935,43.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.933 | Acc: 25.122,32.820,43.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.931 | Acc: 25.209,32.941,43.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.929 | Acc: 25.227,32.957,43.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.932 | Acc: 25.305,32.973,43.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.927 | Acc: 25.381,33.083,43.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.498 | Acc: 22.656,21.875,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.531 | Acc: 21.615,27.046,36.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.544 | Acc: 22.085,26.353,35.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.539 | Acc: 21.849,26.230,35.566,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 4.846 | Acc: 28.906,34.375,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.815 | Acc: 25.260,33.631,44.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.823 | Acc: 25.095,33.632,45.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.799 | Acc: 25.576,34.388,44.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.806 | Acc: 25.878,34.471,44.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.812 | Acc: 25.743,34.073,44.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.804 | Acc: 25.943,34.259,44.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.815 | Acc: 25.765,34.164,44.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.823 | Acc: 25.708,34.118,44.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.822 | Acc: 25.734,34.133,44.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.813 | Acc: 25.906,34.363,44.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.805 | Acc: 25.969,34.361,44.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.800 | Acc: 26.096,34.479,44.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.798 | Acc: 26.200,34.611,44.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.796 | Acc: 26.240,34.614,44.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.800 | Acc: 26.254,34.598,44.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.795 | Acc: 26.261,34.657,44.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.796 | Acc: 26.249,34.666,44.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.794 | Acc: 26.303,34.726,45.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.792 | Acc: 26.277,34.728,45.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.599 | Acc: 21.094,27.344,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.597 | Acc: 19.829,26.897,38.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.683 | Acc: 19.798,26.391,37.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.719 | Acc: 19.685,26.716,37.269,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 4.847 | Acc: 25.000,30.469,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.704 | Acc: 27.753,35.751,45.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.700 | Acc: 27.401,36.166,45.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.699 | Acc: 27.549,35.989,45.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.702 | Acc: 27.382,35.870,46.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.695 | Acc: 27.390,35.922,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.693 | Acc: 27.228,35.899,46.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.697 | Acc: 27.061,35.810,46.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.704 | Acc: 27.135,35.714,45.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.702 | Acc: 27.206,35.566,45.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.707 | Acc: 27.169,35.560,45.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.704 | Acc: 27.110,35.577,45.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.691 | Acc: 27.214,35.711,46.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.688 | Acc: 27.215,35.734,46.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.686 | Acc: 27.099,35.723,46.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.689 | Acc: 27.035,35.766,46.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.688 | Acc: 27.105,35.721,46.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.683 | Acc: 27.149,35.809,46.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.684 | Acc: 27.130,35.797,46.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.686 | Acc: 27.141,35.788,46.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.400 | Acc: 20.312,32.812,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.533 | Acc: 20.982,27.307,39.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.603 | Acc: 20.655,26.734,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.619 | Acc: 20.505,26.627,38.089,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 4.357 | Acc: 28.906,43.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.513 | Acc: 29.650,38.467,49.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.501 | Acc: 29.554,38.681,49.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.524 | Acc: 28.586,38.025,49.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.546 | Acc: 28.231,37.654,49.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.548 | Acc: 28.024,37.631,49.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.540 | Acc: 28.144,37.803,48.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.555 | Acc: 28.025,37.716,48.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.568 | Acc: 28.013,37.524,48.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.578 | Acc: 27.892,37.349,48.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.584 | Acc: 27.892,37.150,48.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.575 | Acc: 27.853,37.146,48.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.569 | Acc: 27.853,37.364,48.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.561 | Acc: 27.871,37.356,48.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.559 | Acc: 27.819,37.289,48.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.562 | Acc: 27.777,37.230,48.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.565 | Acc: 27.731,37.242,48.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.566 | Acc: 27.802,37.232,47.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.560 | Acc: 27.870,37.366,48.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.559 | Acc: 27.969,37.367,48.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.739 | Acc: 28.125,42.969,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.969 | Acc: 24.330,32.180,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.050 | Acc: 24.333,31.841,43.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.052 | Acc: 23.975,31.814,43.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 4.519 | Acc: 27.344,35.156,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.601 | Acc: 27.455,36.644,48.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.532 | Acc: 27.954,37.138,48.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.501 | Acc: 28.394,37.718,49.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.484 | Acc: 28.569,38.069,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.467 | Acc: 28.659,38.304,49.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.468 | Acc: 28.706,38.397,49.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.454 | Acc: 28.762,38.658,49.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.468 | Acc: 28.664,38.422,49.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.472 | Acc: 28.626,38.342,49.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.476 | Acc: 28.611,38.320,49.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.481 | Acc: 28.599,38.218,49.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.472 | Acc: 28.553,38.294,49.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.480 | Acc: 28.505,38.281,49.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.480 | Acc: 28.511,38.248,49.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.481 | Acc: 28.473,38.232,48.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.478 | Acc: 28.485,38.247,48.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.478 | Acc: 28.503,38.343,48.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.484 | Acc: 28.460,38.338,48.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.478 | Acc: 28.498,38.441,48.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.767 | Acc: 30.469,38.281,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.041 | Acc: 24.070,33.854,41.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.044 | Acc: 24.047,33.022,41.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.048 | Acc: 23.796,33.005,42.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 4.476 | Acc: 32.812,42.188,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 30.655,41.257,51.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.318 | Acc: 29.840,40.396,50.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.293 | Acc: 30.097,41.009,51.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.312 | Acc: 30.035,40.779,51.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.326 | Acc: 29.896,40.671,50.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.336 | Acc: 29.875,40.548,50.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.345 | Acc: 29.887,40.293,50.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.351 | Acc: 29.838,40.256,50.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.358 | Acc: 29.657,40.094,50.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.368 | Acc: 29.610,39.956,50.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.373 | Acc: 29.592,39.922,50.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.367 | Acc: 29.632,39.973,50.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.380 | Acc: 29.433,39.790,50.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.383 | Acc: 29.421,39.763,50.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.387 | Acc: 29.347,39.732,50.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.379 | Acc: 29.381,39.861,50.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.382 | Acc: 29.287,39.839,50.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.381 | Acc: 29.220,39.707,50.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.383 | Acc: 29.152,39.678,50.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.810 | Acc: 28.906,42.188,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.939 | Acc: 25.186,33.445,44.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.010 | Acc: 24.371,33.441,44.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.025 | Acc: 23.975,33.274,44.390,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.575 | Acc: 23.438,41.406,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.297 | Acc: 30.134,41.034,51.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 29.973,39.939,51.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.327 | Acc: 30.008,39.972,50.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.324 | Acc: 29.736,40.191,50.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.303 | Acc: 29.927,40.246,50.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.278 | Acc: 30.010,40.754,51.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.291 | Acc: 29.998,40.680,51.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.302 | Acc: 29.799,40.445,50.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.286 | Acc: 29.903,40.565,51.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.285 | Acc: 29.948,40.745,51.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.285 | Acc: 29.931,40.770,51.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.282 | Acc: 30.051,40.768,51.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.290 | Acc: 29.972,40.760,51.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.296 | Acc: 29.960,40.708,51.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.299 | Acc: 30.017,40.692,51.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.295 | Acc: 30.021,40.696,51.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.293 | Acc: 30.093,40.817,51.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.296 | Acc: 30.103,40.815,51.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.296 | Acc: 30.091,40.842,51.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.448 | Acc: 29.688,43.750,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.663 | Acc: 25.558,35.789,48.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.723 | Acc: 25.286,35.595,47.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.721 | Acc: 25.384,35.528,47.195,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.487 | Acc: 28.906,36.719,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 28.906,39.844,51.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.248 | Acc: 29.249,40.454,52.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.229 | Acc: 29.547,41.048,52.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.210 | Acc: 30.266,41.850,52.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.208 | Acc: 30.291,41.808,52.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.213 | Acc: 30.262,41.632,52.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.203 | Acc: 30.380,41.750,52.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.206 | Acc: 30.396,41.843,52.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.211 | Acc: 30.365,41.639,52.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.215 | Acc: 30.372,41.608,52.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.224 | Acc: 30.296,41.526,52.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.215 | Acc: 30.394,41.675,52.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.215 | Acc: 30.451,41.682,52.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.215 | Acc: 30.435,41.626,52.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.217 | Acc: 30.464,41.637,52.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.210 | Acc: 30.581,41.681,52.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.210 | Acc: 30.659,41.754,52.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.216 | Acc: 30.583,41.722,52.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.215 | Acc: 30.629,41.779,52.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.079 | Acc: 27.344,38.281,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.101 | Acc: 24.554,32.552,43.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.163 | Acc: 23.609,31.955,43.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.142 | Acc: 23.502,32.147,43.366,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 3.926 | Acc: 33.594,48.438,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.122 | Acc: 31.176,42.894,53.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.109 | Acc: 31.250,42.797,53.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.139 | Acc: 30.917,42.956,52.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.135 | Acc: 30.720,42.564,53.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.130 | Acc: 30.948,42.420,53.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.135 | Acc: 30.850,42.342,53.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.122 | Acc: 31.034,42.808,53.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.117 | Acc: 30.925,42.954,53.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.121 | Acc: 30.853,42.969,53.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.126 | Acc: 30.877,42.875,53.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.128 | Acc: 30.843,42.824,53.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.138 | Acc: 30.913,42.813,53.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.141 | Acc: 30.801,42.777,53.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.139 | Acc: 30.908,42.719,53.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.138 | Acc: 30.972,42.665,53.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.143 | Acc: 30.956,42.638,53.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.148 | Acc: 30.970,42.639,53.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.152 | Acc: 30.960,42.597,53.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.155 | Acc: 30.990,42.602,53.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.682 | Acc: 23.438,31.250,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.859 | Acc: 24.405,33.333,47.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.963 | Acc: 23.876,32.774,46.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.992 | Acc: 23.758,32.159,45.927,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 3.794 | Acc: 37.500,41.406,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.014 | Acc: 31.994,43.415,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.064 | Acc: 31.574,43.312,54.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.065 | Acc: 31.865,43.494,54.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.051 | Acc: 31.674,43.808,54.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.076 | Acc: 31.722,43.332,54.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.062 | Acc: 31.825,43.647,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.057 | Acc: 31.688,43.634,54.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.072 | Acc: 31.551,43.546,54.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.077 | Acc: 31.323,43.431,53.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.075 | Acc: 31.297,43.641,54.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.079 | Acc: 31.261,43.623,53.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.076 | Acc: 31.367,43.633,54.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.071 | Acc: 31.448,43.714,54.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.073 | Acc: 31.522,43.803,54.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.070 | Acc: 31.517,43.828,54.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.068 | Acc: 31.576,43.891,54.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.073 | Acc: 31.541,43.849,54.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.073 | Acc: 31.564,43.906,54.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.075 | Acc: 31.615,43.801,54.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 30.469,38.281,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.708 | Acc: 26.414,33.333,47.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.752 | Acc: 26.582,33.822,46.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.749 | Acc: 25.948,34.349,46.542,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.030 | Acc: 35.156,42.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.989 | Acc: 32.850,44.159,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.009 | Acc: 32.222,43.826,54.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.992 | Acc: 32.351,44.326,55.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.987 | Acc: 32.311,44.338,55.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.010 | Acc: 32.101,44.083,55.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.001 | Acc: 32.160,44.292,55.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.000 | Acc: 32.031,44.227,55.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.991 | Acc: 32.240,44.405,55.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.983 | Acc: 32.338,44.626,55.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.989 | Acc: 32.183,44.636,54.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.989 | Acc: 32.250,44.655,55.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.990 | Acc: 32.219,44.590,55.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.997 | Acc: 32.130,44.483,55.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.994 | Acc: 32.259,44.567,55.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.999 | Acc: 32.265,44.516,54.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.004 | Acc: 32.221,44.412,54.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.006 | Acc: 32.210,44.437,54.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.006 | Acc: 32.202,44.317,54.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.010 | Acc: 32.197,44.330,54.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.856 | Acc: 27.344,35.938,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.777 | Acc: 24.740,35.417,49.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.818 | Acc: 24.257,34.642,48.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.805 | Acc: 24.103,34.913,48.630,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 3.859 | Acc: 28.906,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.881 | Acc: 34.412,45.982,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.915 | Acc: 33.899,45.865,56.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.897 | Acc: 33.555,46.017,56.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.893 | Acc: 33.401,46.074,56.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.895 | Acc: 33.099,46.071,56.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.907 | Acc: 33.103,45.926,56.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.918 | Acc: 33.040,45.916,56.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.922 | Acc: 33.113,45.807,56.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.931 | Acc: 32.713,45.554,55.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.935 | Acc: 32.665,45.538,55.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.931 | Acc: 32.717,45.571,55.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.943 | Acc: 32.566,45.449,55.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.948 | Acc: 32.486,45.378,55.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.949 | Acc: 32.457,45.312,55.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.953 | Acc: 32.540,45.310,55.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.954 | Acc: 32.545,45.383,55.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.950 | Acc: 32.583,45.434,55.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.951 | Acc: 32.622,45.445,55.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.953 | Acc: 32.663,45.399,55.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.359 | Acc: 32.031,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.639 | Acc: 28.385,36.644,48.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.693 | Acc: 28.258,36.395,47.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.667 | Acc: 28.330,36.399,47.925,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 4.667 | Acc: 25.781,35.938,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.972 | Acc: 31.176,44.234,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.917 | Acc: 32.184,44.627,56.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.910 | Acc: 32.710,44.941,56.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.915 | Acc: 32.475,45.168,56.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.907 | Acc: 32.488,45.490,56.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.898 | Acc: 32.677,45.700,56.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.887 | Acc: 32.774,45.822,56.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.888 | Acc: 32.769,45.977,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.893 | Acc: 32.687,45.830,56.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.886 | Acc: 32.762,45.997,56.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.889 | Acc: 32.844,45.991,56.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.897 | Acc: 32.806,45.915,56.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.892 | Acc: 32.998,46.004,56.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.889 | Acc: 33.032,46.105,56.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.898 | Acc: 32.885,45.902,56.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.894 | Acc: 32.900,45.875,56.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.899 | Acc: 32.936,45.853,56.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.903 | Acc: 32.947,45.828,56.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.899 | Acc: 32.964,45.858,56.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 26.562,45.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.716 | Acc: 25.856,37.314,49.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.722 | Acc: 25.629,37.252,49.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.716 | Acc: 25.295,37.974,49.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 3.681 | Acc: 36.719,50.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.860 | Acc: 31.734,45.982,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.823 | Acc: 33.175,47.123,57.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.797 | Acc: 34.029,47.746,58.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.798 | Acc: 33.700,47.203,58.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.803 | Acc: 33.779,47.254,57.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.814 | Acc: 33.678,47.191,57.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.817 | Acc: 33.743,47.169,57.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.813 | Acc: 33.812,47.108,57.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.822 | Acc: 33.745,47.108,57.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.824 | Acc: 33.609,47.182,57.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.826 | Acc: 33.523,47.045,57.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.833 | Acc: 33.490,46.875,57.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.840 | Acc: 33.477,46.851,57.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.842 | Acc: 33.474,46.800,57.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.848 | Acc: 33.394,46.808,57.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.849 | Acc: 33.453,46.736,57.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.851 | Acc: 33.427,46.744,57.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.854 | Acc: 33.367,46.650,57.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.852 | Acc: 33.317,46.615,57.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.499 | Acc: 28.125,39.062,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.581 | Acc: 26.525,38.914,49.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 25.762,38.072,49.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.643 | Acc: 25.448,37.410,49.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 3.544 | Acc: 32.812,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.698 | Acc: 34.635,49.256,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.735 | Acc: 34.051,47.732,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.706 | Acc: 34.401,47.989,59.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.703 | Acc: 34.568,48.052,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.711 | Acc: 34.197,47.826,59.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.742 | Acc: 33.749,47.611,58.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.745 | Acc: 33.915,47.695,58.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.751 | Acc: 34.060,47.744,58.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.757 | Acc: 33.969,47.708,58.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.773 | Acc: 33.741,47.493,58.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.770 | Acc: 33.650,47.508,58.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.785 | Acc: 33.568,47.342,58.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.790 | Acc: 33.648,47.222,57.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.786 | Acc: 33.702,47.286,58.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.788 | Acc: 33.674,47.298,57.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.789 | Acc: 33.696,47.294,57.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.800 | Acc: 33.674,47.171,57.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.803 | Acc: 33.726,47.219,57.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.806 | Acc: 33.639,47.197,57.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.180 | Acc: 28.125,45.312,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.644 | Acc: 23.698,39.025,51.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.672 | Acc: 23.590,38.205,50.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 23.630,38.102,50.282,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 3.252 | Acc: 45.312,55.469,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.671 | Acc: 34.449,47.693,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.735 | Acc: 33.651,47.542,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.754 | Acc: 33.619,47.823,57.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.746 | Acc: 33.661,47.656,58.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.761 | Acc: 33.741,47.331,57.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.757 | Acc: 33.813,47.714,58.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.758 | Acc: 34.009,47.845,58.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.755 | Acc: 33.948,47.831,58.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.760 | Acc: 33.835,47.872,58.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.772 | Acc: 33.765,47.695,57.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.765 | Acc: 33.869,47.755,57.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.764 | Acc: 33.869,47.796,57.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.770 | Acc: 33.809,47.752,57.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.772 | Acc: 33.850,47.843,57.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.777 | Acc: 33.799,47.820,57.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.775 | Acc: 33.883,47.800,57.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.778 | Acc: 33.830,47.840,57.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.776 | Acc: 33.890,47.812,57.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.774 | Acc: 33.959,47.857,57.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.461 | Acc: 28.906,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.826 | Acc: 24.330,36.905,47.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.791 | Acc: 24.638,36.471,47.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.797 | Acc: 24.347,36.194,46.939,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 3.870 | Acc: 35.156,42.188,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.614 | Acc: 34.449,47.768,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.634 | Acc: 34.432,48.571,60.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.702 | Acc: 34.029,48.361,59.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.709 | Acc: 34.028,48.225,59.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.703 | Acc: 34.120,48.407,59.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.716 | Acc: 33.936,48.483,59.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.713 | Acc: 33.893,48.582,59.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.703 | Acc: 34.293,48.704,59.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.710 | Acc: 34.306,48.571,59.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.716 | Acc: 34.185,48.449,59.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.716 | Acc: 34.029,48.349,58.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.716 | Acc: 34.077,48.324,58.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.713 | Acc: 34.180,48.396,59.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.716 | Acc: 34.217,48.379,58.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.715 | Acc: 34.214,48.383,58.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.717 | Acc: 34.207,48.369,58.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.716 | Acc: 34.309,48.426,58.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.721 | Acc: 34.330,48.347,58.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.720 | Acc: 34.381,48.450,58.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.059 | Acc: 39.062,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.178 | Acc: 31.548,43.527,54.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.223 | Acc: 30.983,42.302,53.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.242 | Acc: 30.686,41.803,52.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 3.985 | Acc: 29.688,42.188,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.585 | Acc: 34.412,49.368,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.602 | Acc: 35.042,49.314,60.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.620 | Acc: 35.220,49.372,60.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.598 | Acc: 35.475,49.556,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.625 | Acc: 35.210,49.257,60.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.636 | Acc: 35.111,49.206,59.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.639 | Acc: 34.973,49.241,59.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.655 | Acc: 34.734,49.005,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.647 | Acc: 34.733,49.145,59.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.651 | Acc: 34.558,49.176,59.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.648 | Acc: 34.675,49.293,59.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.657 | Acc: 34.592,49.199,59.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.660 | Acc: 34.611,49.210,59.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.675 | Acc: 34.542,49.096,59.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.676 | Acc: 34.487,49.034,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.669 | Acc: 34.521,49.031,59.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.672 | Acc: 34.506,49.010,59.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.676 | Acc: 34.516,49.026,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.676 | Acc: 34.576,49.073,59.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.906 | Acc: 30.469,46.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 27.679,40.997,51.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 28.201,41.444,52.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 28.061,40.945,51.601,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 3.231 | Acc: 43.750,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.545 | Acc: 35.156,50.707,61.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.611 | Acc: 34.375,49.428,60.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.625 | Acc: 33.940,49.270,59.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.639 | Acc: 33.719,49.084,59.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.641 | Acc: 33.981,49.196,59.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.632 | Acc: 33.988,49.232,59.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.636 | Acc: 34.159,49.136,59.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.637 | Acc: 34.288,49.063,59.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.634 | Acc: 34.349,49.141,59.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.638 | Acc: 34.398,48.982,59.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.635 | Acc: 34.569,48.996,59.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.635 | Acc: 34.602,49.060,59.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.632 | Acc: 34.653,49.114,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.635 | Acc: 34.706,49.096,59.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.637 | Acc: 34.699,49.076,59.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.640 | Acc: 34.674,49.056,59.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.645 | Acc: 34.666,49.045,59.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.645 | Acc: 34.667,49.106,59.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.641 | Acc: 34.719,49.122,59.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.076 | Acc: 34.375,39.844,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.559 | Acc: 25.632,39.137,49.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.550 | Acc: 26.258,39.062,49.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 26.037,38.307,49.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 3.971 | Acc: 31.250,45.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.584 | Acc: 34.338,49.256,61.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.577 | Acc: 35.366,49.581,60.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.567 | Acc: 35.348,49.898,61.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.568 | Acc: 35.523,50.087,61.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.576 | Acc: 35.628,49.861,60.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.570 | Acc: 35.808,50.045,60.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.571 | Acc: 35.744,50.094,60.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.574 | Acc: 35.773,50.126,60.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.580 | Acc: 35.562,50.052,60.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.582 | Acc: 35.560,50.008,60.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.578 | Acc: 35.658,50.106,60.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.582 | Acc: 35.753,50.107,60.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.585 | Acc: 35.719,50.033,60.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.580 | Acc: 35.682,50.097,60.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.584 | Acc: 35.717,50.091,60.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.587 | Acc: 35.675,50.068,60.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.586 | Acc: 35.669,50.119,60.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.586 | Acc: 35.712,50.080,60.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.585 | Acc: 35.851,50.137,60.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.279 | Acc: 31.250,43.750,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.474 | Acc: 25.744,39.769,51.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.538 | Acc: 25.324,38.662,49.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 24.769,38.166,49.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 3.762 | Acc: 39.844,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.514 | Acc: 36.979,50.409,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.514 | Acc: 36.090,50.476,61.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.477 | Acc: 36.693,50.679,61.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.495 | Acc: 36.449,50.608,61.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.528 | Acc: 35.938,50.170,61.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.547 | Acc: 35.427,49.864,61.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.548 | Acc: 35.688,49.956,61.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.553 | Acc: 35.569,49.956,61.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.545 | Acc: 35.657,50.134,61.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.551 | Acc: 35.580,50.210,60.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.550 | Acc: 35.687,50.184,60.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.556 | Acc: 35.597,50.071,60.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.556 | Acc: 35.617,50.114,60.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.554 | Acc: 35.712,50.197,60.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.558 | Acc: 35.631,50.187,60.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.570 | Acc: 35.541,50.107,60.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.578 | Acc: 35.498,49.970,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.579 | Acc: 35.457,49.998,60.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.578 | Acc: 35.474,50.064,60.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.153 | Acc: 32.031,44.531,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.269 | Acc: 27.418,43.638,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 27.420,42.664,53.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.359 | Acc: 27.408,42.034,52.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.545 | Acc: 37.500,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.438 | Acc: 36.272,51.190,63.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.464 | Acc: 36.662,51.162,62.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.494 | Acc: 35.771,50.474,62.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.513 | Acc: 35.677,50.212,61.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.519 | Acc: 35.504,50.224,61.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.509 | Acc: 35.628,50.549,61.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.504 | Acc: 35.699,50.582,61.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.503 | Acc: 35.840,50.641,61.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.504 | Acc: 35.830,50.704,61.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.510 | Acc: 35.747,50.556,61.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.523 | Acc: 35.669,50.286,61.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.523 | Acc: 35.740,50.363,61.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.525 | Acc: 35.740,50.434,61.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.529 | Acc: 35.710,50.439,61.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.533 | Acc: 35.722,50.335,61.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.535 | Acc: 35.787,50.292,61.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.540 | Acc: 35.724,50.220,61.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.544 | Acc: 35.682,50.238,61.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.548 | Acc: 35.634,50.244,61.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.288 | Acc: 27.344,47.656,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 27.418,41.406,52.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.490 | Acc: 26.905,41.368,52.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.522 | Acc: 25.973,40.984,51.473,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 3.560 | Acc: 37.500,53.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.494 | Acc: 36.421,51.265,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.466 | Acc: 35.880,50.762,63.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.454 | Acc: 35.873,51.114,63.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.447 | Acc: 36.410,51.601,63.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.469 | Acc: 36.177,51.354,62.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.476 | Acc: 36.163,51.440,62.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.480 | Acc: 36.037,51.346,62.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.491 | Acc: 35.976,51.242,62.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.498 | Acc: 35.886,51.070,62.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.503 | Acc: 35.840,51.038,62.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.499 | Acc: 35.895,51.170,62.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.494 | Acc: 35.950,51.355,62.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.492 | Acc: 35.976,51.326,62.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.492 | Acc: 35.904,51.312,62.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.495 | Acc: 35.893,51.241,61.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.504 | Acc: 35.806,51.161,61.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.501 | Acc: 35.905,51.171,61.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.504 | Acc: 35.922,51.138,61.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.507 | Acc: 35.964,51.103,61.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.876 | Acc: 34.375,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.132 | Acc: 27.865,44.643,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.200 | Acc: 28.506,43.731,54.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.236 | Acc: 28.240,43.686,53.509,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 3.597 | Acc: 35.156,46.094,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.383 | Acc: 37.277,53.311,63.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.410 | Acc: 36.719,53.011,63.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.402 | Acc: 36.911,53.048,63.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.432 | Acc: 36.786,52.758,62.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.454 | Acc: 36.610,52.297,62.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.459 | Acc: 36.493,52.260,62.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.450 | Acc: 36.674,52.333,62.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.461 | Acc: 36.355,52.067,62.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.469 | Acc: 36.326,51.977,62.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.470 | Acc: 36.303,51.994,62.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.469 | Acc: 36.242,51.923,62.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.472 | Acc: 36.216,51.809,62.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.479 | Acc: 36.108,51.682,62.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.489 | Acc: 36.049,51.518,62.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.489 | Acc: 36.057,51.581,62.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.488 | Acc: 36.103,51.655,62.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.495 | Acc: 36.050,51.560,61.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.498 | Acc: 36.091,51.534,61.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.499 | Acc: 36.099,51.454,61.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.774 | Acc: 35.938,50.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.121 | Acc: 28.497,45.685,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.129 | Acc: 29.345,45.065,54.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.153 | Acc: 29.329,44.787,54.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.377 | Acc: 36.719,52.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.318 | Acc: 36.756,52.530,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.336 | Acc: 36.700,52.649,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.340 | Acc: 36.655,52.830,64.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.360 | Acc: 36.690,52.778,64.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.386 | Acc: 36.634,52.568,63.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.395 | Acc: 36.577,52.460,63.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.403 | Acc: 36.652,52.410,63.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.415 | Acc: 36.432,52.237,63.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.424 | Acc: 36.382,52.128,63.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.437 | Acc: 36.338,51.908,62.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.440 | Acc: 36.295,51.856,62.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.436 | Acc: 36.404,51.926,62.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.439 | Acc: 36.345,51.901,62.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.435 | Acc: 36.460,52.010,62.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.441 | Acc: 36.441,51.905,62.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.445 | Acc: 36.415,51.911,62.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.448 | Acc: 36.364,51.890,62.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.459 | Acc: 36.249,51.733,62.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.462 | Acc: 36.245,51.700,62.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.529 | Acc: 28.125,42.188,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.899 | Acc: 25.521,36.868,46.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.854 | Acc: 26.143,36.928,47.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.870 | Acc: 26.447,36.936,47.784,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.602 | Acc: 35.156,48.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.355 | Acc: 36.124,50.744,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.347 | Acc: 36.261,51.963,64.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.356 | Acc: 35.989,52.203,64.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.382 | Acc: 35.851,51.948,64.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.366 | Acc: 36.494,52.367,64.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.394 | Acc: 36.525,52.176,63.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.392 | Acc: 36.641,52.288,63.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.400 | Acc: 36.622,52.208,63.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.411 | Acc: 36.576,52.068,63.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.432 | Acc: 36.482,51.842,62.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.433 | Acc: 36.556,51.813,62.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.440 | Acc: 36.576,51.725,62.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.439 | Acc: 36.506,51.739,62.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.436 | Acc: 36.569,51.866,62.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.439 | Acc: 36.542,51.825,62.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.444 | Acc: 36.609,51.842,62.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.439 | Acc: 36.606,51.952,62.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.439 | Acc: 36.613,51.941,62.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.440 | Acc: 36.573,51.981,62.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.689 | Acc: 35.938,57.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.997 | Acc: 31.659,47.359,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.981 | Acc: 32.260,46.856,54.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.011 | Acc: 31.865,46.555,54.521,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.542 | Acc: 39.844,52.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.295 | Acc: 37.165,54.539,65.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.329 | Acc: 36.986,53.258,65.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.321 | Acc: 37.013,53.048,65.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.336 | Acc: 36.796,52.903,65.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.330 | Acc: 36.850,53.303,64.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.345 | Acc: 36.557,53.028,64.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.354 | Acc: 36.453,52.959,64.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.363 | Acc: 36.510,52.907,64.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.372 | Acc: 36.676,52.853,63.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.375 | Acc: 36.719,52.849,63.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.385 | Acc: 36.595,52.860,63.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.383 | Acc: 36.660,52.940,63.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.391 | Acc: 36.641,52.808,63.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.395 | Acc: 36.469,52.702,63.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.402 | Acc: 36.376,52.590,63.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.402 | Acc: 36.446,52.607,63.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.403 | Acc: 36.451,52.612,63.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.408 | Acc: 36.435,52.556,63.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.416 | Acc: 36.387,52.459,63.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.050 | Acc: 28.906,46.094,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.211 | Acc: 28.385,41.629,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.245 | Acc: 28.620,41.959,54.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.263 | Acc: 28.535,41.611,53.829,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.175 | Acc: 38.281,58.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.285 | Acc: 37.128,53.385,64.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.304 | Acc: 36.509,53.335,64.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.324 | Acc: 36.373,53.023,64.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.318 | Acc: 36.777,53.221,64.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.339 | Acc: 36.448,52.986,64.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.359 | Acc: 36.389,52.466,64.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.363 | Acc: 36.403,52.377,64.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.375 | Acc: 36.369,52.271,63.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.371 | Acc: 36.572,52.525,63.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.381 | Acc: 36.443,52.355,63.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.387 | Acc: 36.376,52.280,63.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.384 | Acc: 36.450,52.451,63.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.386 | Acc: 36.458,52.377,63.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.382 | Acc: 36.546,52.405,63.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.386 | Acc: 36.607,52.414,63.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.391 | Acc: 36.604,52.405,63.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.392 | Acc: 36.554,52.417,63.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.389 | Acc: 36.641,52.575,63.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.391 | Acc: 36.692,52.616,63.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.367 | Acc: 31.250,50.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.645 | Acc: 23.438,41.704,52.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.676 | Acc: 22.771,41.139,51.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.666 | Acc: 22.964,41.598,51.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.488 | Acc: 35.938,59.375,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.298 | Acc: 36.905,55.022,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.224 | Acc: 38.148,55.545,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.284 | Acc: 37.039,54.444,65.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.289 | Acc: 37.133,54.205,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.294 | Acc: 37.144,53.976,65.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.295 | Acc: 37.106,53.919,65.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.303 | Acc: 37.007,53.984,65.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.303 | Acc: 37.131,54.013,65.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.305 | Acc: 37.142,53.824,65.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.328 | Acc: 36.983,53.455,64.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.336 | Acc: 36.941,53.344,64.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.338 | Acc: 37.072,53.300,64.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.337 | Acc: 37.135,53.370,64.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.347 | Acc: 37.069,53.264,64.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.351 | Acc: 36.963,53.172,64.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.357 | Acc: 36.882,53.057,64.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.356 | Acc: 36.872,53.077,64.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.357 | Acc: 36.955,53.021,64.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.358 | Acc: 36.981,53.006,64.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.292 | Acc: 32.031,46.875,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.173 | Acc: 28.125,44.792,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.196 | Acc: 28.239,44.341,54.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.211 | Acc: 27.984,44.147,53.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.396 | Acc: 36.719,58.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.306 | Acc: 36.793,54.725,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.271 | Acc: 36.966,54.783,65.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.334 | Acc: 36.424,53.279,64.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.332 | Acc: 36.256,52.990,64.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.321 | Acc: 36.572,53.202,64.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.317 | Acc: 36.454,53.196,64.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.311 | Acc: 36.658,53.236,64.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.329 | Acc: 36.631,53.067,64.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.336 | Acc: 36.607,53.000,64.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.347 | Acc: 36.660,53.008,64.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.346 | Acc: 36.729,53.160,64.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.352 | Acc: 36.758,53.083,64.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.358 | Acc: 36.737,52.963,64.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.359 | Acc: 36.847,52.925,64.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.357 | Acc: 36.916,53.021,64.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.356 | Acc: 36.972,53.047,63.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.357 | Acc: 37.069,53.075,63.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.360 | Acc: 37.091,53.144,63.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.358 | Acc: 37.098,53.234,63.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.804 | Acc: 34.375,44.531,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.119 | Acc: 30.469,44.457,56.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.132 | Acc: 30.183,44.055,55.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.150 | Acc: 30.072,44.057,54.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.360 | Acc: 39.062,53.906,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.246 | Acc: 38.802,52.716,64.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.262 | Acc: 38.548,53.201,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.256 | Acc: 38.358,53.317,65.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.253 | Acc: 38.407,53.549,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.274 | Acc: 38.243,53.558,65.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.282 | Acc: 38.049,53.680,64.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.296 | Acc: 37.927,53.674,64.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.302 | Acc: 37.592,53.654,64.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.310 | Acc: 37.496,53.695,64.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.314 | Acc: 37.477,53.696,64.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.322 | Acc: 37.316,53.592,64.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.322 | Acc: 37.344,53.666,64.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.326 | Acc: 37.362,53.622,64.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.328 | Acc: 37.286,53.500,64.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.331 | Acc: 37.209,53.353,64.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.332 | Acc: 37.252,53.315,64.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.335 | Acc: 37.218,53.297,64.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.337 | Acc: 37.234,53.283,64.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.335 | Acc: 37.233,53.293,64.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.304 | Acc: 28.906,44.531,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.451 | Acc: 29.055,42.262,53.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 29.230,41.406,51.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.505 | Acc: 29.034,41.214,50.948,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.183 | Acc: 31.250,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.209 | Acc: 36.756,54.911,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.214 | Acc: 37.252,54.325,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.252 | Acc: 36.988,54.098,66.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.250 | Acc: 37.317,54.090,66.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.249 | Acc: 37.554,54.200,66.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.252 | Acc: 37.649,54.416,66.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.254 | Acc: 37.622,54.322,66.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.255 | Acc: 37.660,54.450,66.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.266 | Acc: 37.673,54.286,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.269 | Acc: 37.512,54.260,65.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.280 | Acc: 37.475,54.118,65.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.286 | Acc: 37.529,54.101,65.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.288 | Acc: 37.461,54.059,65.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.296 | Acc: 37.389,53.970,64.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.299 | Acc: 37.370,53.880,64.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.303 | Acc: 37.303,53.899,64.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.308 | Acc: 37.298,53.904,64.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.308 | Acc: 37.307,53.980,64.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.310 | Acc: 37.262,53.859,64.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.960 | Acc: 28.906,47.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.111 | Acc: 29.464,46.243,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.143 | Acc: 29.002,44.722,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.174 | Acc: 28.701,44.147,54.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.353 | Acc: 32.812,51.562,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.229 | Acc: 37.612,53.348,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.234 | Acc: 37.309,53.963,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.226 | Acc: 37.513,54.201,66.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.233 | Acc: 37.635,54.533,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.236 | Acc: 37.693,54.672,66.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.226 | Acc: 37.868,54.926,66.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.233 | Acc: 37.744,54.671,66.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.244 | Acc: 37.568,54.547,65.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.253 | Acc: 37.608,54.519,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.251 | Acc: 37.741,54.474,65.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.253 | Acc: 37.733,54.482,65.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.259 | Acc: 37.639,54.376,65.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.263 | Acc: 37.650,54.445,65.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.271 | Acc: 37.572,54.290,65.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.284 | Acc: 37.497,54.148,65.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.288 | Acc: 37.502,54.118,65.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.290 | Acc: 37.509,54.138,65.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.298 | Acc: 37.476,53.980,64.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.296 | Acc: 37.555,54.040,64.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.262 | Acc: 34.375,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 26.860,41.369,51.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.509 | Acc: 27.306,40.796,51.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.519 | Acc: 27.894,40.510,51.370,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 3.287 | Acc: 35.156,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.142 | Acc: 38.207,55.655,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.207 | Acc: 37.824,54.935,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.230 | Acc: 37.513,54.547,66.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.214 | Acc: 37.519,54.524,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.222 | Acc: 37.670,54.533,66.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.224 | Acc: 37.371,54.558,66.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.225 | Acc: 37.566,54.615,66.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.224 | Acc: 37.670,54.799,66.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.220 | Acc: 37.642,54.791,66.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.231 | Acc: 37.659,54.738,65.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.241 | Acc: 37.670,54.695,65.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.250 | Acc: 37.484,54.597,65.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.246 | Acc: 37.542,54.580,65.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.254 | Acc: 37.492,54.462,65.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.254 | Acc: 37.497,54.493,65.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.258 | Acc: 37.583,54.493,65.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.264 | Acc: 37.482,54.415,65.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.267 | Acc: 37.535,54.361,65.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.267 | Acc: 37.594,54.402,65.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.828 | Acc: 33.594,50.781,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.084 | Acc: 29.501,47.805,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.100 | Acc: 29.421,46.932,56.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.113 | Acc: 29.329,46.491,56.148,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.033 | Acc: 34.375,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.215 | Acc: 37.835,55.208,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.217 | Acc: 38.357,55.145,65.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.198 | Acc: 38.358,55.405,66.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.203 | Acc: 38.281,55.150,66.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.201 | Acc: 38.490,55.183,66.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.209 | Acc: 38.352,55.023,66.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.209 | Acc: 38.370,54.998,66.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.219 | Acc: 38.053,54.891,66.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.228 | Acc: 38.152,54.692,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.232 | Acc: 37.920,54.688,65.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.233 | Acc: 37.967,54.772,65.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.237 | Acc: 37.866,54.691,65.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.245 | Acc: 37.829,54.622,65.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.252 | Acc: 37.711,54.540,65.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.257 | Acc: 37.752,54.508,65.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.258 | Acc: 37.719,54.551,65.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.256 | Acc: 37.729,54.541,65.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.258 | Acc: 37.675,54.480,65.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.261 | Acc: 37.650,54.417,65.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.936 | Acc: 28.906,46.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.170 | Acc: 27.195,45.238,54.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.195 | Acc: 27.477,43.693,54.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.207 | Acc: 26.947,43.648,53.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 2.966 | Acc: 41.406,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.150 | Acc: 39.249,55.022,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.166 | Acc: 39.024,54.764,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.152 | Acc: 38.742,54.854,67.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.167 | Acc: 38.677,54.823,67.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.177 | Acc: 38.606,54.773,67.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.169 | Acc: 38.753,55.075,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.178 | Acc: 38.625,55.009,66.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.183 | Acc: 38.529,54.988,66.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.194 | Acc: 38.355,54.834,66.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.199 | Acc: 38.250,54.715,66.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.212 | Acc: 38.158,54.642,66.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.210 | Acc: 38.249,54.723,66.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.217 | Acc: 38.242,54.693,66.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.224 | Acc: 38.195,54.604,65.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.231 | Acc: 38.092,54.566,65.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.234 | Acc: 38.016,54.602,65.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.236 | Acc: 37.967,54.541,65.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.240 | Acc: 37.972,54.523,65.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.243 | Acc: 37.910,54.476,65.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.897 | Acc: 31.250,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.053 | Acc: 29.725,46.838,54.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.084 | Acc: 29.554,46.361,54.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.124 | Acc: 29.022,45.761,54.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 2.921 | Acc: 35.156,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.157 | Acc: 37.277,55.692,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.126 | Acc: 37.976,57.012,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.168 | Acc: 37.871,55.840,67.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.144 | Acc: 38.011,55.970,67.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.148 | Acc: 38.181,55.848,67.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.167 | Acc: 37.939,55.559,66.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.171 | Acc: 38.043,55.652,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.182 | Acc: 38.189,55.478,66.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.189 | Acc: 38.134,55.331,66.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.194 | Acc: 38.099,55.364,66.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.201 | Acc: 38.119,55.345,66.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.204 | Acc: 38.210,55.320,66.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.211 | Acc: 38.063,55.256,66.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.215 | Acc: 38.006,55.155,66.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.218 | Acc: 38.068,55.157,66.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.218 | Acc: 38.065,55.169,66.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.224 | Acc: 37.899,55.082,65.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.226 | Acc: 37.898,55.016,65.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.228 | Acc: 37.873,55.016,65.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.575 | Acc: 25.000,43.750,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.221 | Acc: 24.442,46.317,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.237 | Acc: 23.838,45.503,56.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.254 | Acc: 24.027,45.364,56.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.223 | Acc: 42.969,51.562,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.110 | Acc: 39.509,56.399,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.121 | Acc: 39.139,56.098,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.127 | Acc: 38.768,55.994,67.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.133 | Acc: 38.937,56.202,67.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.153 | Acc: 38.506,55.972,67.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.167 | Acc: 38.378,55.888,67.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.165 | Acc: 38.409,55.801,67.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.164 | Acc: 38.543,55.988,67.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.175 | Acc: 38.372,55.775,67.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.179 | Acc: 38.277,55.616,66.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.177 | Acc: 38.299,55.596,67.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.188 | Acc: 38.103,55.430,66.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.191 | Acc: 38.120,55.394,66.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.199 | Acc: 38.081,55.249,66.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.204 | Acc: 38.050,55.259,66.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.204 | Acc: 38.101,55.250,66.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.201 | Acc: 38.137,55.219,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.202 | Acc: 38.203,55.213,66.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.202 | Acc: 38.199,55.245,66.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.724 | Acc: 33.594,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.016 | Acc: 28.720,46.615,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.078 | Acc: 27.820,45.884,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.108 | Acc: 27.805,45.722,56.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 2.854 | Acc: 41.406,57.031,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.159 | Acc: 37.426,54.911,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.180 | Acc: 38.129,55.011,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.158 | Acc: 37.820,54.969,67.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.146 | Acc: 38.252,55.459,67.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.159 | Acc: 37.995,55.446,67.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.166 | Acc: 38.191,55.404,66.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.189 | Acc: 37.927,55.114,66.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.198 | Acc: 37.966,55.124,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.195 | Acc: 38.117,55.158,66.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.190 | Acc: 38.099,55.177,66.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.196 | Acc: 38.080,55.221,66.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.200 | Acc: 38.084,55.252,66.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.199 | Acc: 38.102,55.265,66.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.199 | Acc: 38.142,55.246,66.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.200 | Acc: 38.123,55.199,66.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.195 | Acc: 38.199,55.257,66.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.196 | Acc: 38.242,55.304,66.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.196 | Acc: 38.290,55.374,66.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.203 | Acc: 38.224,55.292,65.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.283 | Acc: 17.969,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.304 | Acc: 23.661,44.680,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.353 | Acc: 23.133,43.826,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.386 | Acc: 23.053,43.340,54.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.298 | Acc: 39.844,50.781,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.073 | Acc: 38.914,56.064,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.100 | Acc: 38.758,56.688,68.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.104 | Acc: 38.973,56.826,67.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.113 | Acc: 38.609,56.298,67.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.108 | Acc: 38.467,56.103,67.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.114 | Acc: 38.649,56.211,67.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.134 | Acc: 38.514,56.134,67.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.148 | Acc: 38.470,55.954,67.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.152 | Acc: 38.303,55.918,67.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.158 | Acc: 38.308,55.826,67.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.163 | Acc: 38.264,55.773,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.165 | Acc: 38.220,55.754,66.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.171 | Acc: 38.218,55.666,66.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.174 | Acc: 38.170,55.613,66.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.176 | Acc: 38.123,55.575,66.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.174 | Acc: 38.155,55.661,66.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.174 | Acc: 38.251,55.657,66.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.176 | Acc: 38.223,55.631,66.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.177 | Acc: 38.222,55.643,66.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.217 | Acc: 25.781,47.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.369 | Acc: 24.368,44.010,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.337 | Acc: 24.809,44.893,54.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.364 | Acc: 24.936,44.416,54.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.315 | Acc: 35.938,53.125,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.041 | Acc: 39.286,58.296,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.095 | Acc: 38.796,56.726,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.059 | Acc: 38.845,57.031,68.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.092 | Acc: 38.609,56.684,68.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.091 | Acc: 38.892,56.567,68.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.096 | Acc: 38.830,56.618,68.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.111 | Acc: 38.885,56.588,68.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.116 | Acc: 38.956,56.527,67.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.127 | Acc: 39.032,56.444,67.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.120 | Acc: 39.000,56.503,67.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.121 | Acc: 38.935,56.335,67.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.126 | Acc: 38.829,56.253,67.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.130 | Acc: 38.859,56.295,67.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.141 | Acc: 38.732,56.155,67.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.143 | Acc: 38.699,56.193,67.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.148 | Acc: 38.654,56.116,67.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.152 | Acc: 38.682,56.080,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.154 | Acc: 38.695,56.055,67.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.158 | Acc: 38.577,55.967,67.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.047 | Acc: 26.562,53.906,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.090 | Acc: 27.455,45.647,57.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.150 | Acc: 27.191,44.931,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.189 | Acc: 27.113,44.634,56.007,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.345 | Acc: 38.281,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.074 | Acc: 38.430,56.510,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.021 | Acc: 38.948,57.279,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.041 | Acc: 38.550,57.044,69.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.055 | Acc: 38.715,56.935,68.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.079 | Acc: 38.784,56.815,68.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.107 | Acc: 38.604,56.431,67.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.116 | Acc: 38.625,56.483,67.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.126 | Acc: 38.407,56.279,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.122 | Acc: 38.557,56.306,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.129 | Acc: 38.382,56.133,67.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.134 | Acc: 38.465,56.126,67.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.147 | Acc: 38.343,55.932,67.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.148 | Acc: 38.455,55.867,67.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.148 | Acc: 38.526,55.891,66.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.154 | Acc: 38.406,55.809,66.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.157 | Acc: 38.383,55.763,66.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.160 | Acc: 38.412,55.723,66.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.161 | Acc: 38.402,55.726,66.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.167 | Acc: 38.357,55.641,66.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.081 | Acc: 28.906,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.321 | Acc: 25.632,45.461,55.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 25.800,45.598,55.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.358 | Acc: 26.012,44.877,54.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 3.488 | Acc: 32.031,47.656,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.041 | Acc: 38.504,57.887,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.032 | Acc: 39.043,58.041,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.040 | Acc: 38.998,57.505,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.069 | Acc: 38.908,57.186,68.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.084 | Acc: 38.676,56.931,68.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.089 | Acc: 38.436,56.683,68.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.094 | Acc: 38.348,56.654,68.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.093 | Acc: 38.407,56.813,68.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.091 | Acc: 38.583,56.897,68.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.092 | Acc: 38.658,56.887,67.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.096 | Acc: 38.716,56.837,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.103 | Acc: 38.638,56.688,67.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.103 | Acc: 38.661,56.726,67.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.107 | Acc: 38.698,56.564,67.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.111 | Acc: 38.697,56.429,67.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.115 | Acc: 38.627,56.364,67.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.120 | Acc: 38.533,56.312,67.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.124 | Acc: 38.558,56.339,67.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.128 | Acc: 38.589,56.334,67.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.425 | Acc: 30.469,44.531,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.299 | Acc: 30.320,43.676,53.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.352 | Acc: 29.402,42.740,52.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.356 | Acc: 29.483,42.482,52.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 3.253 | Acc: 32.031,54.688,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.083 | Acc: 38.876,56.994,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.076 | Acc: 38.472,56.383,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.070 | Acc: 38.512,56.365,68.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.087 | Acc: 38.436,56.443,68.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.090 | Acc: 38.738,56.366,68.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.093 | Acc: 38.656,56.482,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.105 | Acc: 38.580,56.161,68.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.113 | Acc: 38.723,56.226,67.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.121 | Acc: 38.557,56.129,67.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.118 | Acc: 38.682,56.219,67.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.120 | Acc: 38.744,56.232,67.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.130 | Acc: 38.596,56.104,67.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.132 | Acc: 38.616,56.046,67.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.131 | Acc: 38.682,56.053,67.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.127 | Acc: 38.746,56.123,67.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.123 | Acc: 38.761,56.184,67.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.129 | Acc: 38.746,56.039,67.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.127 | Acc: 38.831,56.083,67.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.127 | Acc: 38.780,56.127,67.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.871 | Acc: 27.344,50.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.128 | Acc: 26.823,48.103,57.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.154 | Acc: 26.848,46.913,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.185 | Acc: 26.601,46.247,56.250,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 2.620 | Acc: 37.500,60.938,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.037 | Acc: 39.062,57.254,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.051 | Acc: 38.624,56.936,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.050 | Acc: 38.781,57.287,69.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.046 | Acc: 38.937,57.427,69.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.063 | Acc: 38.482,57.031,68.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.085 | Acc: 38.572,56.708,68.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.082 | Acc: 38.752,56.882,68.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.082 | Acc: 38.844,56.924,68.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.083 | Acc: 38.816,56.967,68.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.080 | Acc: 38.697,57.000,68.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.087 | Acc: 38.592,56.819,68.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.094 | Acc: 38.638,56.811,68.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.095 | Acc: 38.646,56.786,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.093 | Acc: 38.668,56.878,68.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.095 | Acc: 38.712,56.813,68.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.102 | Acc: 38.710,56.729,67.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.105 | Acc: 38.671,56.626,67.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.107 | Acc: 38.645,56.650,67.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.113 | Acc: 38.638,56.539,67.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.320 | Acc: 22.656,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.312 | Acc: 25.744,45.387,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 25.019,44.798,57.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.372 | Acc: 24.436,44.326,56.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 2.657 | Acc: 45.312,57.812,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.996 | Acc: 39.397,59.115,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.014 | Acc: 38.662,58.194,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.001 | Acc: 39.370,58.325,69.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.003 | Acc: 39.361,58.160,69.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.017 | Acc: 39.271,57.859,69.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.021 | Acc: 39.250,57.780,69.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.021 | Acc: 39.583,57.724,69.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.026 | Acc: 39.305,57.594,69.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.047 | Acc: 39.127,57.234,68.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.055 | Acc: 39.008,57.160,68.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.058 | Acc: 39.084,57.102,68.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.071 | Acc: 38.968,56.979,68.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.080 | Acc: 38.898,56.909,68.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.090 | Acc: 38.793,56.820,68.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.089 | Acc: 38.759,56.813,68.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.096 | Acc: 38.736,56.700,67.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.100 | Acc: 38.813,56.656,67.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.102 | Acc: 38.837,56.611,67.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.097 | Acc: 38.911,56.709,67.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.192 | Acc: 26.562,50.781,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.218 | Acc: 25.186,46.912,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.231 | Acc: 25.305,45.808,57.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.257 | Acc: 24.808,45.722,57.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.066 | Acc: 42.188,60.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.996 | Acc: 39.137,57.366,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.973 | Acc: 39.539,58.079,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.021 | Acc: 39.050,57.377,69.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.023 | Acc: 39.371,56.867,68.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.039 | Acc: 39.171,56.761,68.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.056 | Acc: 38.882,56.489,68.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.064 | Acc: 38.924,56.488,68.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.061 | Acc: 38.999,56.643,68.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.056 | Acc: 39.157,56.850,68.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.066 | Acc: 38.989,56.736,67.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.068 | Acc: 38.833,56.731,67.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.074 | Acc: 38.716,56.701,67.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.079 | Acc: 38.679,56.747,67.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.083 | Acc: 38.721,56.706,67.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.082 | Acc: 38.837,56.800,67.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.083 | Acc: 38.856,56.844,67.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.090 | Acc: 38.797,56.722,67.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.090 | Acc: 38.801,56.724,67.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.091 | Acc: 38.837,56.732,67.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.039 | Acc: 25.781,50.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.945 | Acc: 25.781,49.182,60.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.015 | Acc: 25.686,48.399,58.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.051 | Acc: 25.154,47.669,58.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.199 | Acc: 34.375,57.812,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.009 | Acc: 39.435,57.552,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.984 | Acc: 39.463,57.774,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.000 | Acc: 39.395,57.300,69.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.992 | Acc: 39.709,57.523,69.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.994 | Acc: 39.635,57.403,69.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.007 | Acc: 39.521,57.438,69.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.017 | Acc: 39.389,57.358,69.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.033 | Acc: 39.194,57.123,68.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.027 | Acc: 39.296,57.061,68.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.038 | Acc: 39.028,56.794,68.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.047 | Acc: 38.995,56.632,68.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.046 | Acc: 39.075,56.626,68.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.052 | Acc: 39.009,56.597,68.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.055 | Acc: 39.015,56.634,68.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.055 | Acc: 38.930,56.626,68.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.065 | Acc: 38.870,56.537,68.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.069 | Acc: 38.900,56.596,68.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.071 | Acc: 38.911,56.596,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.076 | Acc: 38.925,56.564,68.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.176 | Acc: 25.781,47.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.435 | Acc: 24.554,43.155,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.497 | Acc: 24.543,42.054,52.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.542 | Acc: 24.488,42.008,51.921,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 2.580 | Acc: 48.438,72.656,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.036 | Acc: 38.318,57.440,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.976 | Acc: 39.272,57.832,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.017 | Acc: 38.986,57.403,70.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.018 | Acc: 38.985,57.340,69.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.015 | Acc: 39.349,57.464,69.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.029 | Acc: 39.276,57.173,69.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.037 | Acc: 39.218,56.992,68.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.029 | Acc: 39.300,57.085,68.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.024 | Acc: 39.378,57.109,68.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.039 | Acc: 39.292,57.093,68.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.042 | Acc: 39.292,57.063,68.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.048 | Acc: 39.127,56.983,68.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.054 | Acc: 39.027,56.926,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.054 | Acc: 39.143,56.909,68.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.057 | Acc: 39.101,56.839,68.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.061 | Acc: 39.048,56.807,68.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.066 | Acc: 39.053,56.765,68.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.070 | Acc: 39.043,56.765,68.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.075 | Acc: 38.948,56.711,68.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.648 | Acc: 35.938,50.781,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.944 | Acc: 31.250,48.177,58.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.963 | Acc: 30.983,47.580,57.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.998 | Acc: 30.174,47.246,57.569,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 2.589 | Acc: 41.406,60.156,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.986 | Acc: 38.653,56.920,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.964 | Acc: 39.024,57.374,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.976 | Acc: 39.485,57.377,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.965 | Acc: 39.622,58.054,70.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.967 | Acc: 39.890,57.913,70.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.973 | Acc: 39.773,57.948,70.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.986 | Acc: 39.716,57.674,69.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.993 | Acc: 39.805,57.677,69.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.008 | Acc: 39.762,57.489,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.021 | Acc: 39.638,57.280,69.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.022 | Acc: 39.635,57.219,68.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.030 | Acc: 39.630,57.129,68.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.032 | Acc: 39.520,57.091,68.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.034 | Acc: 39.446,57.115,68.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.036 | Acc: 39.473,57.138,68.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.039 | Acc: 39.396,57.131,68.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.041 | Acc: 39.422,57.089,68.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.046 | Acc: 39.359,57.055,68.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.048 | Acc: 39.325,57.058,68.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.898 | Acc: 32.031,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.124 | Acc: 31.027,47.693,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.151 | Acc: 30.412,46.646,54.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.167 | Acc: 30.289,46.849,54.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 3.383 | Acc: 32.031,51.562,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.958 | Acc: 39.509,57.366,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.966 | Acc: 39.691,57.832,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.960 | Acc: 39.997,57.800,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.966 | Acc: 40.278,57.890,70.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.965 | Acc: 40.331,57.967,70.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.989 | Acc: 40.089,57.677,69.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.004 | Acc: 39.916,57.552,69.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.018 | Acc: 39.786,57.240,69.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.022 | Acc: 39.749,57.325,68.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.025 | Acc: 39.750,57.288,68.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.022 | Acc: 39.660,57.342,68.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.025 | Acc: 39.555,57.388,68.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.034 | Acc: 39.455,57.331,68.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.042 | Acc: 39.393,57.206,68.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.045 | Acc: 39.325,57.226,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.049 | Acc: 39.274,57.243,68.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.050 | Acc: 39.257,57.212,68.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.056 | Acc: 39.281,57.174,68.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.059 | Acc: 39.304,57.146,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.676 | Acc: 28.906,50.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.882 | Acc: 27.641,47.805,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.910 | Acc: 28.258,47.447,58.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.943 | Acc: 27.805,47.374,58.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 3.017 | Acc: 42.188,53.906,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.990 | Acc: 39.323,56.771,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.005 | Acc: 39.482,57.431,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.994 | Acc: 39.460,57.595,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.008 | Acc: 39.670,57.764,69.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.995 | Acc: 39.720,58.037,69.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.001 | Acc: 39.508,57.929,69.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.009 | Acc: 39.306,57.812,69.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.018 | Acc: 39.189,57.725,69.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.026 | Acc: 39.132,57.623,68.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.030 | Acc: 39.218,57.715,68.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.037 | Acc: 39.130,57.554,68.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.041 | Acc: 39.108,57.407,68.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.040 | Acc: 39.122,57.498,68.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.039 | Acc: 39.146,57.582,68.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.036 | Acc: 39.265,57.649,68.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.036 | Acc: 39.296,57.701,68.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.029 | Acc: 39.402,57.758,68.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.031 | Acc: 39.437,57.698,68.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.036 | Acc: 39.376,57.628,68.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.362 | Acc: 25.781,42.969,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.380 | Acc: 26.302,42.708,55.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.419 | Acc: 25.896,42.626,54.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.457 | Acc: 26.076,41.970,54.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 3.144 | Acc: 35.156,53.906,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.993 | Acc: 39.435,58.073,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.984 | Acc: 39.958,58.194,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.967 | Acc: 39.857,58.543,70.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.968 | Acc: 39.622,58.661,70.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.981 | Acc: 39.418,58.308,70.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.989 | Acc: 39.205,58.064,70.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.002 | Acc: 39.090,57.812,69.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.992 | Acc: 39.179,57.939,69.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.000 | Acc: 39.101,57.713,69.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.006 | Acc: 39.082,57.696,69.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.012 | Acc: 39.119,57.572,69.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.011 | Acc: 39.189,57.501,69.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.012 | Acc: 39.221,57.483,69.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.013 | Acc: 39.218,57.498,69.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.016 | Acc: 39.327,57.532,69.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.020 | Acc: 39.355,57.547,69.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.020 | Acc: 39.344,57.572,69.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.026 | Acc: 39.314,57.497,69.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.031 | Acc: 39.233,57.445,69.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.103 | Acc: 31.250,46.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.265 | Acc: 26.488,45.833,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.287 | Acc: 26.200,45.046,56.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.307 | Acc: 25.589,44.890,56.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 2.738 | Acc: 42.969,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 40.513,58.929,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.924 | Acc: 39.863,58.556,71.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.942 | Acc: 39.088,58.248,70.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.946 | Acc: 39.188,58.536,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.937 | Acc: 39.604,58.973,70.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.955 | Acc: 39.456,58.807,70.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.955 | Acc: 39.434,58.849,70.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.967 | Acc: 39.213,58.705,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.968 | Acc: 39.231,58.576,70.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.976 | Acc: 39.140,58.368,70.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.976 | Acc: 39.200,58.452,70.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.983 | Acc: 39.140,58.240,69.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.990 | Acc: 39.086,58.151,69.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.996 | Acc: 39.118,58.077,69.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.007 | Acc: 39.000,57.924,69.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.009 | Acc: 39.011,57.893,69.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.016 | Acc: 39.017,57.838,69.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.020 | Acc: 39.032,57.752,69.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.019 | Acc: 39.040,57.755,69.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.050 | Acc: 30.469,46.094,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.586 | Acc: 27.232,40.699,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 28.296,40.492,54.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.559 | Acc: 28.227,40.766,54.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 3.175 | Acc: 31.250,53.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.910 | Acc: 40.997,59.152,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.883 | Acc: 40.377,58.880,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.946 | Acc: 39.383,58.081,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.939 | Acc: 39.525,58.642,70.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.940 | Acc: 39.558,58.617,70.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.941 | Acc: 39.553,58.407,70.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.947 | Acc: 39.323,58.311,70.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.954 | Acc: 39.320,58.298,70.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.965 | Acc: 39.343,58.093,69.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.967 | Acc: 39.335,58.116,69.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.969 | Acc: 39.465,58.145,69.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.981 | Acc: 39.406,58.007,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.988 | Acc: 39.446,57.959,69.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.988 | Acc: 39.538,58.024,69.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.988 | Acc: 39.525,58.020,69.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.999 | Acc: 39.401,57.851,69.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.003 | Acc: 39.431,57.831,69.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.002 | Acc: 39.523,57.810,69.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.003 | Acc: 39.487,57.788,69.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.931 | Acc: 25.781,50.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.978 | Acc: 29.315,47.656,59.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.970 | Acc: 29.078,47.694,58.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.987 | Acc: 28.714,47.426,58.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 2.946 | Acc: 37.500,54.688,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.975 | Acc: 38.132,58.110,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.928 | Acc: 39.501,58.841,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.925 | Acc: 40.292,58.978,70.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.922 | Acc: 40.326,58.970,70.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.938 | Acc: 40.215,58.656,70.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.948 | Acc: 40.018,58.665,70.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.954 | Acc: 39.999,58.666,70.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.955 | Acc: 39.800,58.633,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.963 | Acc: 39.814,58.494,69.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.965 | Acc: 39.855,58.384,69.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.961 | Acc: 39.943,58.435,69.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.964 | Acc: 39.870,58.390,69.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.972 | Acc: 39.844,58.306,69.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.981 | Acc: 39.933,58.191,69.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.979 | Acc: 39.916,58.295,69.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.983 | Acc: 39.902,58.282,69.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.989 | Acc: 39.803,58.174,69.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.999 | Acc: 39.746,58.070,69.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.999 | Acc: 39.770,58.026,69.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.943 | Acc: 29.688,49.219,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.217 | Acc: 27.269,44.420,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.231 | Acc: 27.229,44.284,55.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.231 | Acc: 27.164,44.045,55.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 2.921 | Acc: 45.312,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.953 | Acc: 38.728,57.366,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.949 | Acc: 39.691,58.098,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.937 | Acc: 39.472,58.235,71.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.946 | Acc: 39.429,57.784,70.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.936 | Acc: 39.774,58.192,70.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.941 | Acc: 39.624,57.980,70.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.937 | Acc: 39.794,58.117,70.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.943 | Acc: 39.941,58.273,70.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.962 | Acc: 39.818,58.080,69.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.965 | Acc: 39.902,58.182,69.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.964 | Acc: 40.049,58.102,69.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.966 | Acc: 40.093,58.107,69.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.974 | Acc: 39.978,58.037,69.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.980 | Acc: 39.919,58.043,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.983 | Acc: 39.877,58.033,69.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.984 | Acc: 39.798,58.000,69.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.987 | Acc: 39.819,58.023,69.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.988 | Acc: 39.826,58.022,69.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.992 | Acc: 39.795,57.962,69.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.638 | Acc: 23.438,39.844,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 24.330,43.490,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 24.466,42.492,54.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 23.809,42.764,54.201,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 2.766 | Acc: 45.312,59.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.904 | Acc: 38.914,59.859,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.881 | Acc: 39.005,59.470,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.896 | Acc: 39.229,59.106,71.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.926 | Acc: 38.995,58.980,70.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.943 | Acc: 39.380,58.733,70.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.945 | Acc: 39.276,58.607,70.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.944 | Acc: 39.306,58.688,70.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.958 | Acc: 39.227,58.463,70.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.963 | Acc: 39.196,58.391,70.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.966 | Acc: 39.109,58.368,70.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.966 | Acc: 39.239,58.477,70.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.970 | Acc: 39.166,58.441,69.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.967 | Acc: 39.365,58.471,69.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.968 | Acc: 39.413,58.374,69.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.971 | Acc: 39.454,58.324,69.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.972 | Acc: 39.474,58.331,69.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.975 | Acc: 39.457,58.358,69.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.978 | Acc: 39.502,58.291,69.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.978 | Acc: 39.596,58.210,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.282 | Acc: 30.469,38.281,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.069 | Acc: 31.771,46.131,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.131 | Acc: 31.040,46.322,54.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.154 | Acc: 30.571,46.529,54.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 2.678 | Acc: 42.969,64.844,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.906 | Acc: 40.216,58.594,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.937 | Acc: 39.482,58.194,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.958 | Acc: 39.075,58.171,70.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.944 | Acc: 39.159,58.333,70.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.945 | Acc: 39.542,58.346,69.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.958 | Acc: 39.527,58.213,69.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.960 | Acc: 39.550,58.228,69.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.961 | Acc: 39.698,58.172,69.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.955 | Acc: 39.887,58.184,69.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.959 | Acc: 39.871,58.135,69.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.964 | Acc: 39.975,58.152,69.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.972 | Acc: 39.905,58.010,69.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.977 | Acc: 39.856,57.920,69.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.974 | Acc: 39.916,58.013,69.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.971 | Acc: 40.020,58.093,69.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.967 | Acc: 40.007,58.170,69.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.968 | Acc: 40.075,58.202,69.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.972 | Acc: 40.110,58.120,69.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.972 | Acc: 40.078,58.171,69.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.630 | Acc: 32.812,53.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.834 | Acc: 28.609,50.223,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.898 | Acc: 28.430,49.886,59.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.907 | Acc: 28.471,49.974,59.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 2.815 | Acc: 45.312,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.918 | Acc: 39.881,58.073,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.886 | Acc: 40.530,59.242,71.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.897 | Acc: 40.151,59.337,70.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.919 | Acc: 39.969,58.970,70.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.933 | Acc: 39.828,58.718,70.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.939 | Acc: 39.618,58.471,70.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.952 | Acc: 39.528,58.422,70.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.948 | Acc: 39.640,58.594,70.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.946 | Acc: 39.589,58.676,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.945 | Acc: 39.704,58.652,70.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.956 | Acc: 39.695,58.466,70.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.951 | Acc: 39.785,58.548,70.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.949 | Acc: 39.892,58.519,70.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.954 | Acc: 39.810,58.438,70.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.959 | Acc: 39.839,58.412,70.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.962 | Acc: 39.810,58.314,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.962 | Acc: 39.837,58.239,70.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.962 | Acc: 39.831,58.278,70.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.963 | Acc: 39.897,58.284,70.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.006 | Acc: 28.906,53.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.098 | Acc: 28.162,48.400,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.122 | Acc: 28.449,47.580,56.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.104 | Acc: 28.356,47.964,56.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 3.027 | Acc: 40.625,54.688,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.945 | Acc: 40.476,56.920,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.956 | Acc: 39.844,57.279,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.949 | Acc: 39.664,57.454,70.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.938 | Acc: 39.718,57.649,70.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.925 | Acc: 39.766,57.959,70.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.933 | Acc: 39.728,57.987,70.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.932 | Acc: 39.971,58.090,70.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.943 | Acc: 40.111,58.079,70.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.946 | Acc: 40.155,58.141,70.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.948 | Acc: 40.108,57.972,70.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.952 | Acc: 40.098,58.018,69.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.948 | Acc: 40.136,58.156,69.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.946 | Acc: 40.170,58.169,70.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.948 | Acc: 40.225,58.191,70.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.953 | Acc: 40.181,58.116,69.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.962 | Acc: 40.007,57.915,69.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.963 | Acc: 40.022,57.900,69.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.964 | Acc: 40.036,57.994,69.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.968 | Acc: 40.000,57.970,69.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.661 | Acc: 28.906,57.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.933 | Acc: 29.576,49.516,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.983 | Acc: 29.211,48.838,57.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.002 | Acc: 28.778,48.297,56.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 2.953 | Acc: 39.844,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.915 | Acc: 39.658,58.333,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.878 | Acc: 40.549,59.280,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.892 | Acc: 40.676,58.811,71.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.901 | Acc: 40.461,58.806,71.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.899 | Acc: 40.401,58.864,71.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.899 | Acc: 40.580,59.033,71.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.898 | Acc: 40.553,59.065,71.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.903 | Acc: 40.591,59.074,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.912 | Acc: 40.465,58.995,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.918 | Acc: 40.536,58.975,70.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.919 | Acc: 40.427,58.954,70.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.928 | Acc: 40.259,58.879,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.937 | Acc: 40.098,58.854,70.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.938 | Acc: 40.183,58.863,70.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.941 | Acc: 40.215,58.848,70.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.943 | Acc: 40.248,58.849,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.941 | Acc: 40.268,58.873,70.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.945 | Acc: 40.168,58.780,70.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.953 | Acc: 40.049,58.668,69.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.343 | Acc: 27.344,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.356 | Acc: 24.628,45.052,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.416 | Acc: 25.114,44.226,54.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.430 | Acc: 24.769,43.942,53.624,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 3.059 | Acc: 42.969,53.906,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.748 | Acc: 42.001,60.193,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 40.873,59.356,72.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.850 | Acc: 40.497,58.811,72.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.873 | Acc: 40.451,58.999,72.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.894 | Acc: 40.548,59.011,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.902 | Acc: 40.502,59.104,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.903 | Acc: 40.470,58.965,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.910 | Acc: 40.489,58.914,71.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.916 | Acc: 40.426,58.633,70.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.922 | Acc: 40.376,58.590,70.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.930 | Acc: 40.310,58.587,70.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.934 | Acc: 40.152,58.535,70.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.935 | Acc: 40.116,58.552,70.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.935 | Acc: 40.080,58.699,70.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.938 | Acc: 40.020,58.615,70.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.943 | Acc: 39.985,58.613,70.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.944 | Acc: 40.022,58.543,70.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.950 | Acc: 39.948,58.442,70.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.952 | Acc: 39.983,58.438,70.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.416 | Acc: 25.000,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.800 | Acc: 24.665,40.513,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.778 | Acc: 24.371,40.701,51.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.802 | Acc: 24.577,40.727,51.767,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 2.662 | Acc: 41.406,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.824 | Acc: 40.067,59.784,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.799 | Acc: 40.644,59.966,72.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.810 | Acc: 40.843,60.169,72.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.826 | Acc: 40.924,59.877,72.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.838 | Acc: 40.795,59.406,72.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.834 | Acc: 40.903,59.691,72.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.853 | Acc: 40.874,59.364,71.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.867 | Acc: 40.771,59.215,71.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.868 | Acc: 40.793,59.228,71.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.879 | Acc: 40.672,59.103,71.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 40.554,58.976,71.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.892 | Acc: 40.589,59.057,70.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.896 | Acc: 40.499,59.103,70.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.903 | Acc: 40.405,59.022,70.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.910 | Acc: 40.324,58.887,70.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.913 | Acc: 40.418,58.888,70.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.919 | Acc: 40.332,58.805,70.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.923 | Acc: 40.283,58.756,70.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.926 | Acc: 40.192,58.709,70.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.802 | Acc: 36.719,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.813 | Acc: 31.436,51.376,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.845 | Acc: 30.678,50.648,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.860 | Acc: 30.405,50.243,58.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 2.958 | Acc: 41.406,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.825 | Acc: 39.732,60.565,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.825 | Acc: 40.339,60.728,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.834 | Acc: 40.651,60.297,72.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.846 | Acc: 40.114,60.127,71.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.860 | Acc: 39.867,59.824,71.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.876 | Acc: 39.895,59.356,71.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.875 | Acc: 39.916,59.336,71.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.875 | Acc: 39.917,59.273,71.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.877 | Acc: 39.999,59.267,71.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.887 | Acc: 40.015,59.087,71.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 40.031,59.096,70.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.900 | Acc: 40.016,59.022,70.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.901 | Acc: 40.140,59.040,70.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.908 | Acc: 39.999,58.941,70.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.918 | Acc: 39.875,58.843,70.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.917 | Acc: 39.922,58.762,70.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.913 | Acc: 39.956,58.825,70.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.915 | Acc: 40.034,58.817,70.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.916 | Acc: 40.043,58.825,70.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.188 | Acc: 32.812,46.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.540 | Acc: 28.423,43.341,54.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.527 | Acc: 28.411,42.530,53.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 27.715,42.059,53.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 2.887 | Acc: 41.406,58.594,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.832 | Acc: 40.551,57.961,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 40.377,59.204,72.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.860 | Acc: 40.100,59.132,72.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.860 | Acc: 40.239,59.057,71.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.872 | Acc: 40.099,58.957,71.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.880 | Acc: 40.399,58.878,71.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.887 | Acc: 40.193,58.854,71.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.891 | Acc: 40.120,58.807,71.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.900 | Acc: 40.077,58.684,71.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.909 | Acc: 40.147,58.559,70.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.909 | Acc: 40.190,58.555,70.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.912 | Acc: 40.230,58.616,70.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.909 | Acc: 40.263,58.696,70.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.911 | Acc: 40.230,58.769,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.916 | Acc: 40.140,58.770,70.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.917 | Acc: 40.148,58.725,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.917 | Acc: 40.151,58.821,70.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.924 | Acc: 40.151,58.721,70.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.928 | Acc: 40.211,58.698,70.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.169 | Acc: 25.000,42.188,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.402 | Acc: 23.289,43.341,55.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.446 | Acc: 23.857,43.064,54.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.476 | Acc: 23.668,42.764,54.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 2.780 | Acc: 45.312,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.797 | Acc: 42.374,59.226,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 41.578,59.108,72.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.831 | Acc: 41.214,59.503,72.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.837 | Acc: 41.040,59.520,72.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 41.097,59.437,72.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.835 | Acc: 41.213,59.685,72.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.855 | Acc: 40.963,59.320,71.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.860 | Acc: 40.868,59.457,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.858 | Acc: 40.802,59.535,71.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.866 | Acc: 40.687,59.585,71.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.873 | Acc: 40.604,59.534,71.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.878 | Acc: 40.651,59.475,71.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.881 | Acc: 40.667,59.411,71.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.889 | Acc: 40.553,59.244,70.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.897 | Acc: 40.581,59.160,70.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.896 | Acc: 40.586,59.110,70.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 40.490,59.031,70.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.905 | Acc: 40.389,58.970,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.907 | Acc: 40.369,58.998,70.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.726 | Acc: 30.469,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.853 | Acc: 31.548,48.326,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.852 | Acc: 31.441,48.457,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.880 | Acc: 31.352,48.284,58.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.724 | Acc: 37.500,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.810 | Acc: 41.109,61.235,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.851 | Acc: 40.549,60.023,71.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.855 | Acc: 40.471,59.708,71.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.843 | Acc: 40.490,59.635,71.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.845 | Acc: 40.548,59.452,71.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.858 | Acc: 40.774,59.304,71.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 40.603,59.281,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.862 | Acc: 40.785,59.511,71.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.863 | Acc: 40.944,59.561,71.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.867 | Acc: 40.847,59.585,71.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.869 | Acc: 40.812,59.576,71.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 40.797,59.560,71.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.876 | Acc: 40.709,59.635,71.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.883 | Acc: 40.675,59.558,71.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.887 | Acc: 40.633,59.564,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.884 | Acc: 40.657,59.606,70.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.886 | Acc: 40.586,59.609,70.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.889 | Acc: 40.486,59.518,70.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.894 | Acc: 40.506,59.549,70.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.396 | Acc: 22.656,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.203 | Acc: 25.037,45.982,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.268 | Acc: 24.638,45.198,57.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.315 | Acc: 24.424,44.954,56.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 2.662 | Acc: 39.062,57.031,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.819 | Acc: 41.481,58.891,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.818 | Acc: 41.044,59.661,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.811 | Acc: 41.355,59.939,72.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.804 | Acc: 41.561,59.992,72.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.817 | Acc: 40.911,59.715,72.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.808 | Acc: 41.116,59.904,72.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.823 | Acc: 41.035,59.835,72.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.851 | Acc: 40.737,59.550,71.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.856 | Acc: 40.776,59.453,71.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.857 | Acc: 40.757,59.515,71.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.870 | Acc: 40.544,59.276,71.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 40.434,59.404,71.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.873 | Acc: 40.430,59.426,71.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.876 | Acc: 40.522,59.419,71.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.883 | Acc: 40.508,59.349,71.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.886 | Acc: 40.523,59.341,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.889 | Acc: 40.547,59.320,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.894 | Acc: 40.432,59.226,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.895 | Acc: 40.412,59.266,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.103 | Acc: 27.344,55.469,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.007 | Acc: 27.790,49.107,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.007 | Acc: 27.934,48.628,59.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.997 | Acc: 28.407,49.449,59.926,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 2.599 | Acc: 39.844,62.500,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.797 | Acc: 40.960,59.933,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 42.473,61.776,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.747 | Acc: 42.162,61.744,73.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 41.667,60.947,73.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.805 | Acc: 41.205,60.404,72.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.812 | Acc: 41.090,60.292,72.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.809 | Acc: 41.362,60.400,72.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.816 | Acc: 41.484,60.331,72.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.823 | Acc: 41.406,60.251,72.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.834 | Acc: 41.169,60.129,72.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.851 | Acc: 40.887,59.820,71.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.848 | Acc: 40.810,59.796,71.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.850 | Acc: 40.793,59.728,71.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.859 | Acc: 40.767,59.684,71.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.864 | Acc: 40.638,59.624,71.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.872 | Acc: 40.520,59.489,71.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.874 | Acc: 40.561,59.487,71.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.877 | Acc: 40.510,59.446,71.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.881 | Acc: 40.432,59.398,71.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.554 | Acc: 30.469,52.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.823 | Acc: 29.278,50.186,60.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.877 | Acc: 29.516,50.114,59.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 29.073,50.128,59.580,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 2.677 | Acc: 41.406,56.250,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.783 | Acc: 39.546,60.417,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.790 | Acc: 39.844,60.023,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.803 | Acc: 40.138,60.246,73.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.809 | Acc: 40.133,60.166,72.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.842 | Acc: 40.084,59.955,72.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.841 | Acc: 40.309,60.014,72.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.845 | Acc: 40.387,59.984,72.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.837 | Acc: 40.620,60.113,72.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.850 | Acc: 40.569,60.022,71.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.851 | Acc: 40.652,60.036,71.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.854 | Acc: 40.636,60.050,71.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.862 | Acc: 40.596,59.894,71.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.868 | Acc: 40.592,59.734,71.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.874 | Acc: 40.578,59.667,71.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.875 | Acc: 40.542,59.655,71.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.883 | Acc: 40.433,59.599,71.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.889 | Acc: 40.339,59.499,71.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.889 | Acc: 40.344,59.570,71.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.884 | Acc: 40.432,59.625,71.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.429 | Acc: 19.531,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.291 | Acc: 21.763,48.921,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.349 | Acc: 21.341,48.133,57.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.374 | Acc: 21.209,48.130,58.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 2.926 | Acc: 38.281,59.375,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.840 | Acc: 40.327,59.747,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.816 | Acc: 40.930,60.442,72.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.814 | Acc: 40.727,59.964,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.837 | Acc: 40.789,59.790,72.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.837 | Acc: 41.267,59.646,72.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.855 | Acc: 41.135,59.478,71.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.856 | Acc: 41.029,59.591,71.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.861 | Acc: 41.047,59.647,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.876 | Acc: 40.867,59.561,71.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.877 | Acc: 40.543,59.429,71.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.869 | Acc: 40.498,59.640,71.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.869 | Acc: 40.525,59.570,71.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.875 | Acc: 40.481,59.513,71.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.879 | Acc: 40.475,59.497,71.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.883 | Acc: 40.415,59.388,71.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.887 | Acc: 40.428,59.331,71.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.886 | Acc: 40.428,59.348,71.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.883 | Acc: 40.415,59.327,71.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.886 | Acc: 40.330,59.264,71.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.853 | Acc: 28.125,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.144 | Acc: 26.897,47.768,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.171 | Acc: 27.153,47.561,57.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.200 | Acc: 26.614,46.670,56.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.926 | Acc: 34.375,55.469,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.822 | Acc: 41.741,59.375,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.803 | Acc: 41.482,60.309,72.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.802 | Acc: 41.573,60.528,72.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.798 | Acc: 41.358,60.513,72.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.810 | Acc: 41.275,60.473,72.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.815 | Acc: 41.271,60.189,72.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.833 | Acc: 41.013,60.034,71.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.848 | Acc: 40.761,59.797,71.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.841 | Acc: 40.880,59.781,71.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.847 | Acc: 40.831,59.709,71.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.850 | Acc: 40.781,59.757,71.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.856 | Acc: 40.735,59.738,71.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.861 | Acc: 40.676,59.689,71.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.865 | Acc: 40.614,59.647,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.872 | Acc: 40.503,59.533,71.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.872 | Acc: 40.625,59.553,71.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.871 | Acc: 40.648,59.529,71.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.871 | Acc: 40.610,59.600,71.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.870 | Acc: 40.609,59.644,71.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.887 | Acc: 32.812,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.015 | Acc: 31.473,47.396,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 31.745,46.837,56.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.066 | Acc: 31.468,46.747,56.391,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.960 | Acc: 41.406,54.688,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.785 | Acc: 40.365,60.640,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.789 | Acc: 40.663,61.223,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.769 | Acc: 41.048,61.347,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.790 | Acc: 40.693,61.024,72.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.782 | Acc: 40.857,61.200,73.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.802 | Acc: 41.142,60.879,72.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 41.401,60.843,72.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.813 | Acc: 41.076,60.739,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.809 | Acc: 41.143,60.584,72.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.814 | Acc: 41.091,60.518,72.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 40.961,60.425,72.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.832 | Acc: 40.845,60.156,72.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.833 | Acc: 40.823,60.108,72.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.837 | Acc: 40.831,60.126,71.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.842 | Acc: 40.820,60.112,71.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 40.878,60.059,71.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.848 | Acc: 40.749,59.950,71.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 40.722,59.845,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.860 | Acc: 40.725,59.746,71.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.008 | Acc: 19.531,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.142 | Acc: 19.940,38.839,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.155 | Acc: 19.931,38.453,54.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.175 | Acc: 19.711,38.256,53.650,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 2.522 | Acc: 42.188,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.769 | Acc: 41.257,60.789,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.784 | Acc: 41.082,60.518,72.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.809 | Acc: 39.959,60.297,72.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.817 | Acc: 39.844,60.060,72.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.824 | Acc: 39.790,59.816,72.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.825 | Acc: 40.147,60.053,72.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.827 | Acc: 40.342,60.034,72.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.825 | Acc: 40.513,60.181,72.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.820 | Acc: 40.508,60.480,72.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.831 | Acc: 40.501,60.300,71.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.841 | Acc: 40.583,60.089,71.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.846 | Acc: 40.667,59.949,71.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.848 | Acc: 40.832,59.965,71.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.851 | Acc: 40.739,59.867,71.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.855 | Acc: 40.752,59.816,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.858 | Acc: 40.708,59.755,71.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.857 | Acc: 40.714,59.799,71.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.861 | Acc: 40.644,59.778,71.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.861 | Acc: 40.666,59.769,71.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.027 | Acc: 30.469,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.071 | Acc: 31.548,47.359,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.112 | Acc: 31.631,46.875,56.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.123 | Acc: 30.981,46.747,57.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 2.526 | Acc: 45.312,64.062,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.733 | Acc: 41.592,61.012,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.787 | Acc: 40.796,60.404,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.812 | Acc: 40.779,60.003,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.824 | Acc: 40.731,59.491,72.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.821 | Acc: 40.772,59.553,72.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.818 | Acc: 40.806,59.840,71.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.822 | Acc: 40.946,59.796,71.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.826 | Acc: 40.999,59.758,71.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.839 | Acc: 40.845,59.530,71.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.846 | Acc: 40.691,59.418,71.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.850 | Acc: 40.533,59.400,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.858 | Acc: 40.560,59.265,71.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.866 | Acc: 40.529,59.100,71.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.862 | Acc: 40.578,59.133,71.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.859 | Acc: 40.713,59.191,71.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.865 | Acc: 40.662,59.183,71.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.864 | Acc: 40.675,59.233,71.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.863 | Acc: 40.681,59.295,71.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.863 | Acc: 40.643,59.283,71.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.787 | Acc: 34.375,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.033 | Acc: 28.051,48.996,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.041 | Acc: 28.316,48.438,58.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.022 | Acc: 28.394,48.373,58.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.060 | Acc: 39.844,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.768 | Acc: 40.811,61.347,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 41.578,61.585,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.740 | Acc: 42.059,61.270,74.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.748 | Acc: 42.052,61.343,73.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.783 | Acc: 41.244,60.752,73.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.784 | Acc: 41.180,60.582,72.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 41.085,60.627,72.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.819 | Acc: 40.999,60.467,72.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.826 | Acc: 41.121,60.407,72.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.828 | Acc: 41.208,60.304,72.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.828 | Acc: 41.081,60.266,72.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.830 | Acc: 41.114,60.325,72.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.833 | Acc: 41.032,60.330,72.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.844 | Acc: 41.045,60.184,71.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.844 | Acc: 41.038,60.187,71.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.847 | Acc: 40.997,60.161,71.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.849 | Acc: 41.014,60.049,71.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.851 | Acc: 40.900,59.925,71.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.853 | Acc: 40.846,59.884,71.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.711 | Acc: 30.469,50.781,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.794 | Acc: 33.147,48.586,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.809 | Acc: 32.774,48.095,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.817 | Acc: 32.595,48.758,59.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 3.189 | Acc: 32.812,49.219,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.841 | Acc: 38.616,58.743,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.815 | Acc: 39.920,59.337,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.792 | Acc: 40.548,59.926,73.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 40.442,60.311,72.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.786 | Acc: 40.540,60.195,72.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.796 | Acc: 40.644,60.260,72.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.804 | Acc: 40.503,60.012,72.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.802 | Acc: 40.596,60.219,72.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 40.698,60.156,72.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.813 | Acc: 40.695,60.055,72.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.823 | Acc: 40.685,59.990,72.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.830 | Acc: 40.742,59.894,71.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.830 | Acc: 40.852,59.926,71.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.832 | Acc: 40.845,59.934,71.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.829 | Acc: 41.048,60.006,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.829 | Acc: 41.090,60.061,71.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.829 | Acc: 41.157,60.110,71.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.833 | Acc: 41.175,60.139,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.838 | Acc: 41.084,60.013,71.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.763 | Acc: 33.594,49.219,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.908 | Acc: 28.199,47.061,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.957 | Acc: 29.364,46.646,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.976 | Acc: 28.919,46.644,59.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 3.040 | Acc: 41.406,54.688,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.784 | Acc: 40.662,60.528,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 41.387,61.014,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.794 | Acc: 40.715,60.630,72.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.794 | Acc: 40.731,60.581,72.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.784 | Acc: 40.532,60.636,72.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.787 | Acc: 40.522,60.615,72.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.785 | Acc: 40.786,60.799,72.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.798 | Acc: 40.766,60.700,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.803 | Acc: 41.057,60.480,72.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.807 | Acc: 41.095,60.300,72.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.801 | Acc: 41.176,60.319,72.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.810 | Acc: 41.157,60.292,72.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 41.197,60.336,72.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.817 | Acc: 41.226,60.290,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.832 | Acc: 41.040,60.161,72.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.832 | Acc: 41.080,60.129,72.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.836 | Acc: 41.049,60.088,71.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 40.997,60.061,71.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 40.953,59.955,71.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.680 | Acc: 25.781,52.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.802 | Acc: 27.641,49.144,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.848 | Acc: 27.496,48.647,60.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.855 | Acc: 27.766,48.937,60.361,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 2.301 | Acc: 46.875,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.763 | Acc: 42.374,60.789,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.760 | Acc: 41.235,60.556,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.735 | Acc: 41.445,61.027,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.752 | Acc: 41.435,61.044,73.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.752 | Acc: 41.615,61.092,73.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.754 | Acc: 41.458,61.041,73.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.758 | Acc: 41.401,61.021,73.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 41.295,60.821,72.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 41.134,60.782,72.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 40.979,60.809,72.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.801 | Acc: 40.975,60.708,72.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.798 | Acc: 41.056,60.753,72.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.800 | Acc: 41.011,60.782,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.806 | Acc: 40.920,60.593,72.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.814 | Acc: 40.861,60.491,72.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.814 | Acc: 40.907,60.529,72.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.819 | Acc: 40.840,60.374,72.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.823 | Acc: 40.818,60.312,72.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 40.807,60.318,71.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.721 | Acc: 32.031,49.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.938 | Acc: 30.357,48.847,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.011 | Acc: 30.412,48.114,57.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.035 | Acc: 30.558,47.579,57.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 2.902 | Acc: 40.625,53.125,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.744 | Acc: 40.923,60.379,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.784 | Acc: 40.530,60.309,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.780 | Acc: 41.291,60.451,73.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.770 | Acc: 41.696,60.899,73.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.775 | Acc: 41.298,60.945,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.789 | Acc: 41.219,60.783,72.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 40.985,60.527,72.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 41.130,60.632,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.796 | Acc: 41.264,60.635,72.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 41.185,60.382,72.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.799 | Acc: 41.240,60.506,72.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.806 | Acc: 41.264,60.425,72.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.806 | Acc: 41.233,60.432,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.814 | Acc: 41.109,60.351,72.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.816 | Acc: 41.157,60.268,72.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 41.126,60.178,72.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 41.051,60.071,72.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.829 | Acc: 41.032,60.072,71.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.830 | Acc: 40.992,60.035,71.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.606 | Acc: 39.062,55.469,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.824 | Acc: 30.283,50.856,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.830 | Acc: 30.050,50.171,59.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.848 | Acc: 30.430,50.154,59.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 2.567 | Acc: 41.406,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.691 | Acc: 42.560,62.165,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.689 | Acc: 42.797,61.928,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.721 | Acc: 41.701,61.386,74.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.726 | Acc: 41.387,61.024,73.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.722 | Acc: 41.692,61.224,73.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.736 | Acc: 41.484,60.931,73.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.746 | Acc: 41.567,60.871,73.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.761 | Acc: 41.397,60.632,72.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 41.350,60.653,72.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.784 | Acc: 41.231,60.502,72.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 41.222,60.365,72.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.795 | Acc: 41.260,60.276,72.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.799 | Acc: 41.242,60.192,72.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 41.192,60.220,72.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 41.193,60.200,72.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.808 | Acc: 41.090,60.120,72.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.819 | Acc: 41.031,60.042,72.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.824 | Acc: 41.032,60.005,71.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.827 | Acc: 40.982,60.015,71.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.097 | Acc: 25.781,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.875 | Acc: 30.134,49.182,59.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.956 | Acc: 29.726,48.628,58.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.993 | Acc: 29.764,48.386,58.120,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 2.987 | Acc: 40.625,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.759 | Acc: 42.039,59.561,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.727 | Acc: 42.607,60.518,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.744 | Acc: 42.085,60.861,73.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.776 | Acc: 41.570,60.262,72.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.788 | Acc: 41.545,60.125,72.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.789 | Acc: 41.490,60.247,72.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 41.124,59.940,72.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.788 | Acc: 41.154,60.185,72.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.788 | Acc: 41.026,60.251,72.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.783 | Acc: 41.060,60.421,72.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.793 | Acc: 40.940,60.276,72.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.793 | Acc: 40.982,60.325,72.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.801 | Acc: 40.993,60.165,72.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.807 | Acc: 40.948,60.159,72.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.809 | Acc: 40.965,60.154,72.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.811 | Acc: 41.039,60.115,72.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.811 | Acc: 41.047,60.090,72.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.817 | Acc: 40.950,60.076,72.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.816 | Acc: 41.013,60.125,71.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.590 | Acc: 36.719,53.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.695 | Acc: 32.589,52.344,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.758 | Acc: 32.298,52.172,59.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.791 | Acc: 31.954,51.729,58.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 2.587 | Acc: 47.656,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.715 | Acc: 42.932,61.384,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.717 | Acc: 41.749,61.776,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 41.586,61.565,73.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.759 | Acc: 41.435,61.188,73.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.777 | Acc: 41.151,60.852,73.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.780 | Acc: 41.335,60.712,72.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.776 | Acc: 41.401,60.832,72.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 41.479,60.777,72.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.773 | Acc: 41.583,60.635,72.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.781 | Acc: 41.484,60.514,72.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.785 | Acc: 41.399,60.549,72.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.790 | Acc: 41.397,60.322,72.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.797 | Acc: 41.346,60.327,72.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.795 | Acc: 41.412,60.412,72.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.797 | Acc: 41.341,60.452,72.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.802 | Acc: 41.280,60.370,71.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.804 | Acc: 41.276,60.356,71.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.807 | Acc: 41.214,60.347,71.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.808 | Acc: 41.250,60.328,71.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.771 | Acc: 35.156,52.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.967 | Acc: 29.576,47.135,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.037 | Acc: 28.716,46.589,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.055 | Acc: 28.356,46.862,58.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 2.482 | Acc: 42.188,61.719,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.686 | Acc: 42.448,62.202,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.691 | Acc: 41.787,61.471,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 41.060,61.130,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.727 | Acc: 41.262,61.439,73.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.731 | Acc: 41.460,61.518,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.746 | Acc: 41.309,61.235,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.754 | Acc: 41.218,61.120,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.756 | Acc: 41.421,61.209,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.762 | Acc: 41.436,61.175,73.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.778 | Acc: 41.262,60.938,72.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.783 | Acc: 41.286,60.881,72.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.793 | Acc: 41.144,60.717,72.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.798 | Acc: 41.170,60.647,72.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.791 | Acc: 41.365,60.762,72.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.793 | Acc: 41.349,60.639,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.800 | Acc: 41.248,60.531,72.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.805 | Acc: 41.232,60.466,72.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.807 | Acc: 41.155,60.464,72.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.811 | Acc: 41.162,60.378,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.033 | Acc: 26.562,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.203 | Acc: 26.935,44.457,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.220 | Acc: 26.753,43.921,56.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.257 | Acc: 26.127,43.097,56.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 3.038 | Acc: 33.594,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.717 | Acc: 41.443,60.789,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.714 | Acc: 41.463,61.414,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 41.586,61.514,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.709 | Acc: 41.715,61.806,73.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.715 | Acc: 41.723,61.448,73.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.726 | Acc: 41.439,61.183,73.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.739 | Acc: 41.157,60.910,73.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.734 | Acc: 41.314,61.069,73.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.748 | Acc: 41.247,60.998,73.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 41.095,60.829,73.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.772 | Acc: 41.046,60.662,73.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.784 | Acc: 41.046,60.529,72.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.784 | Acc: 41.065,60.539,72.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.787 | Acc: 41.109,60.540,72.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.790 | Acc: 41.142,60.572,72.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.790 | Acc: 41.146,60.529,72.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.787 | Acc: 41.223,60.592,72.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.785 | Acc: 41.209,60.544,72.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.786 | Acc: 41.271,60.501,72.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.130 | Acc: 28.125,49.219,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 23.363,43.006,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 23.476,42.340,56.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 23.719,42.277,55.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.870 | Acc: 41.406,54.688,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.682 | Acc: 40.439,59.821,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.701 | Acc: 40.911,60.747,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.743 | Acc: 40.766,60.681,73.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.743 | Acc: 41.377,61.034,73.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 41.190,60.675,73.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.759 | Acc: 40.922,60.724,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.758 | Acc: 41.102,60.893,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.772 | Acc: 41.091,60.787,73.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 41.177,60.799,72.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.782 | Acc: 41.169,60.751,72.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 41.191,60.687,72.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.798 | Acc: 41.121,60.662,72.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.799 | Acc: 41.128,60.584,72.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.798 | Acc: 41.264,60.601,72.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.798 | Acc: 41.276,60.608,72.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.808 | Acc: 41.168,60.526,72.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 41.225,60.516,72.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.813 | Acc: 41.367,60.468,72.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.809 | Acc: 41.363,60.486,72.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.048 | Acc: 20.312,35.156,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.874 | Acc: 18.638,40.141,54.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.865 | Acc: 19.112,40.263,54.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.889 | Acc: 18.865,40.074,54.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 2.864 | Acc: 36.719,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.708 | Acc: 40.774,61.607,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.766 | Acc: 40.911,60.614,73.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.784 | Acc: 40.228,60.336,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 40.693,60.658,72.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.793 | Acc: 40.625,60.566,72.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.795 | Acc: 40.599,60.537,72.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.799 | Acc: 40.509,60.406,72.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.790 | Acc: 40.839,60.418,72.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.793 | Acc: 40.815,60.372,72.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.786 | Acc: 40.917,60.440,72.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 40.844,60.457,72.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.785 | Acc: 40.959,60.633,72.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.786 | Acc: 40.984,60.611,72.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.789 | Acc: 40.992,60.637,72.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.795 | Acc: 41.077,60.613,72.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.797 | Acc: 41.051,60.597,72.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.798 | Acc: 41.058,60.585,72.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.795 | Acc: 41.064,60.611,72.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.795 | Acc: 41.103,60.583,72.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.244 | Acc: 41.406,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.574 | Acc: 33.371,52.307,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.584 | Acc: 33.232,52.382,60.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.622 | Acc: 33.466,52.216,60.169,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 3.144 | Acc: 35.156,56.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.791 | Acc: 38.542,59.933,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.780 | Acc: 40.111,60.652,72.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.754 | Acc: 39.997,60.899,73.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.726 | Acc: 40.451,61.516,73.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.732 | Acc: 40.586,61.317,73.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.730 | Acc: 40.670,61.454,73.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.730 | Acc: 40.836,61.674,73.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.750 | Acc: 40.775,61.345,73.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.758 | Acc: 40.772,61.227,73.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.771 | Acc: 40.703,61.039,72.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.773 | Acc: 40.872,60.892,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.779 | Acc: 40.849,60.769,72.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.780 | Acc: 40.975,60.668,72.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.786 | Acc: 41.064,60.629,72.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.784 | Acc: 41.209,60.714,72.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.785 | Acc: 41.277,60.684,72.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.788 | Acc: 41.266,60.665,72.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.791 | Acc: 41.259,60.667,72.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.792 | Acc: 41.300,60.655,72.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.583 | Acc: 18.750,42.969,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.454 | Acc: 20.387,44.531,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 19.627,43.902,55.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 19.787,43.596,55.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.844 | Acc: 43.750,55.469,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.671 | Acc: 43.043,62.537,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.678 | Acc: 42.359,62.405,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 42.674,61.885,73.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.708 | Acc: 42.486,61.834,73.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.718 | Acc: 42.420,61.696,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.721 | Acc: 42.123,61.512,73.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.739 | Acc: 41.794,61.192,73.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.746 | Acc: 41.814,61.132,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.751 | Acc: 41.721,60.994,73.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.762 | Acc: 41.647,60.922,73.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.759 | Acc: 41.721,60.983,72.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.763 | Acc: 41.581,60.941,72.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.766 | Acc: 41.514,60.923,72.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.764 | Acc: 41.537,60.982,72.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.765 | Acc: 41.526,61.013,72.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.768 | Acc: 41.479,60.942,72.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.773 | Acc: 41.464,60.855,72.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.778 | Acc: 41.411,60.870,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.779 | Acc: 41.345,60.767,72.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.805 | Acc: 27.344,48.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.083 | Acc: 25.446,48.772,58.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.083 | Acc: 25.629,49.333,58.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.094 | Acc: 24.859,49.168,58.363,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.388 | Acc: 49.219,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.718 | Acc: 41.220,61.012,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.717 | Acc: 41.502,61.014,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.736 | Acc: 41.009,60.848,74.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.732 | Acc: 41.368,60.812,74.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.727 | Acc: 41.306,61.054,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.731 | Acc: 41.432,61.118,73.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.739 | Acc: 41.567,61.104,73.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.741 | Acc: 41.591,61.136,73.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.747 | Acc: 41.786,61.149,73.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 41.616,60.996,72.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.761 | Acc: 41.579,61.008,72.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.776 | Acc: 41.435,60.811,72.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.775 | Acc: 41.418,60.917,72.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.780 | Acc: 41.264,60.773,72.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.786 | Acc: 41.258,60.854,72.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.789 | Acc: 41.199,60.823,72.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.789 | Acc: 41.086,60.782,72.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.791 | Acc: 41.088,60.790,72.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.792 | Acc: 41.160,60.831,72.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.565 | Acc: 32.031,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.729 | Acc: 29.985,50.298,62.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.740 | Acc: 30.030,49.981,61.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.781 | Acc: 29.880,49.590,61.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 2.747 | Acc: 39.062,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.703 | Acc: 42.448,61.942,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.699 | Acc: 41.273,61.719,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.680 | Acc: 42.085,61.949,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.671 | Acc: 42.226,61.931,74.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.682 | Acc: 42.296,61.827,74.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.697 | Acc: 42.020,61.887,74.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.708 | Acc: 41.955,61.702,74.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.713 | Acc: 41.828,61.787,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.719 | Acc: 41.717,61.585,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.719 | Acc: 41.737,61.497,73.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.734 | Acc: 41.668,61.284,73.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.740 | Acc: 41.701,61.271,73.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.752 | Acc: 41.619,61.084,73.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.749 | Acc: 41.626,61.085,73.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.757 | Acc: 41.557,61.005,73.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.756 | Acc: 41.603,61.052,73.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.762 | Acc: 41.452,61.020,72.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.766 | Acc: 41.478,60.992,72.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.769 | Acc: 41.480,61.011,72.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.917 | Acc: 32.031,48.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.934 | Acc: 28.199,50.558,59.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.936 | Acc: 28.354,50.572,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.962 | Acc: 28.714,50.333,59.183,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 2.637 | Acc: 41.406,54.688,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.735 | Acc: 41.369,60.565,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.679 | Acc: 41.959,61.662,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.670 | Acc: 41.688,61.680,74.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.680 | Acc: 41.725,61.815,74.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.688 | Acc: 41.615,61.634,73.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.690 | Acc: 41.697,61.674,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.704 | Acc: 41.661,61.525,73.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.716 | Acc: 41.542,61.214,73.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.720 | Acc: 41.652,61.261,73.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.722 | Acc: 41.678,61.171,73.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.720 | Acc: 41.859,61.174,73.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.736 | Acc: 41.747,61.035,72.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.744 | Acc: 41.756,60.914,72.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.755 | Acc: 41.709,60.824,72.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.758 | Acc: 41.749,60.771,72.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.764 | Acc: 41.720,60.745,72.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.769 | Acc: 41.658,60.724,72.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.773 | Acc: 41.545,60.723,72.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.777 | Acc: 41.484,60.667,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.148 | Acc: 25.781,53.906,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.151 | Acc: 26.153,46.466,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.196 | Acc: 25.476,45.903,58.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.202 | Acc: 24.949,46.107,58.145,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 2.973 | Acc: 35.156,53.906,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.734 | Acc: 42.634,61.533,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.704 | Acc: 42.492,62.424,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.673 | Acc: 42.572,62.910,75.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.697 | Acc: 42.188,62.307,74.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.708 | Acc: 41.592,61.920,74.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.718 | Acc: 41.542,61.706,74.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.716 | Acc: 41.761,61.702,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.728 | Acc: 41.702,61.544,73.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.728 | Acc: 41.682,61.503,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.733 | Acc: 41.624,61.369,73.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.744 | Acc: 41.526,61.249,73.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.746 | Acc: 41.546,61.252,73.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.751 | Acc: 41.514,61.183,73.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.755 | Acc: 41.523,61.001,72.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.754 | Acc: 41.614,61.028,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.759 | Acc: 41.577,60.959,72.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.769 | Acc: 41.443,60.850,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.768 | Acc: 41.597,60.907,72.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.771 | Acc: 41.546,60.851,72.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 23.438,39.062,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.152 | Acc: 24.888,46.540,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.225 | Acc: 24.104,46.608,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.244 | Acc: 23.668,46.619,59.426,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 2.911 | Acc: 35.156,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.741 | Acc: 41.220,62.202,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.739 | Acc: 41.368,61.928,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 41.073,62.295,74.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.731 | Acc: 40.866,61.728,74.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.719 | Acc: 41.267,62.005,74.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.720 | Acc: 41.335,61.867,74.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.724 | Acc: 41.279,61.796,73.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.726 | Acc: 41.338,61.753,73.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.739 | Acc: 41.126,61.572,73.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.739 | Acc: 41.056,61.536,73.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.735 | Acc: 41.102,61.584,73.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.742 | Acc: 41.166,61.472,73.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.748 | Acc: 41.191,61.401,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.751 | Acc: 41.212,61.307,73.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.755 | Acc: 41.269,61.257,73.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.759 | Acc: 41.268,61.198,73.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.762 | Acc: 41.230,61.178,72.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.764 | Acc: 41.318,61.104,72.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.767 | Acc: 41.390,61.081,72.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.735 | Acc: 28.906,54.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.946 | Acc: 28.943,48.698,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.944 | Acc: 28.792,48.571,59.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.966 | Acc: 28.509,48.245,59.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 2.687 | Acc: 42.969,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.728 | Acc: 40.811,62.946,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.684 | Acc: 41.406,62.462,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.679 | Acc: 42.136,62.513,74.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.659 | Acc: 42.506,62.760,74.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.685 | Acc: 41.940,62.423,74.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.700 | Acc: 41.768,62.138,74.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.708 | Acc: 41.667,61.841,73.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.712 | Acc: 41.688,61.656,73.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.711 | Acc: 41.825,61.598,73.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.721 | Acc: 41.744,61.435,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.727 | Acc: 41.760,61.298,73.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.734 | Acc: 41.695,61.203,73.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.740 | Acc: 41.628,61.117,72.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.752 | Acc: 41.606,61.040,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.759 | Acc: 41.544,60.914,72.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.766 | Acc: 41.555,60.833,72.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.766 | Acc: 41.461,60.832,72.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.763 | Acc: 41.547,60.938,72.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.762 | Acc: 41.599,61.038,72.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.208 | Acc: 21.875,49.219,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.607 | Acc: 22.842,42.820,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.600 | Acc: 23.552,42.416,55.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 23.181,42.610,55.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.917 | Acc: 35.938,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.669 | Acc: 41.927,62.016,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.705 | Acc: 42.035,61.909,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.716 | Acc: 42.059,61.719,74.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.723 | Acc: 41.811,61.468,73.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.729 | Acc: 41.607,61.255,73.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.724 | Acc: 41.593,61.209,73.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.728 | Acc: 41.628,61.287,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.731 | Acc: 41.649,61.442,73.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.732 | Acc: 41.726,61.460,73.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.739 | Acc: 41.612,61.357,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.744 | Acc: 41.562,61.295,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.745 | Acc: 41.552,61.278,73.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.740 | Acc: 41.667,61.372,73.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.743 | Acc: 41.662,61.302,73.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.746 | Acc: 41.676,61.303,73.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.744 | Acc: 41.674,61.363,73.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.748 | Acc: 41.752,61.318,72.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.753 | Acc: 41.707,61.215,72.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.757 | Acc: 41.691,61.145,72.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.490 | Acc: 21.875,47.656,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.364 | Acc: 19.829,48.028,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.422 | Acc: 19.531,47.046,57.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.433 | Acc: 19.160,47.182,56.865,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 3.065 | Acc: 38.281,56.250,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.763 | Acc: 40.923,59.598,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.721 | Acc: 41.559,60.823,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.696 | Acc: 41.919,61.706,74.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.711 | Acc: 41.705,61.487,73.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.716 | Acc: 41.762,61.711,73.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.720 | Acc: 41.903,61.622,73.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.715 | Acc: 41.899,61.686,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.718 | Acc: 41.955,61.646,73.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.720 | Acc: 42.036,61.619,73.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.721 | Acc: 42.001,61.587,73.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.729 | Acc: 41.830,61.439,73.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.732 | Acc: 41.899,61.375,73.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.739 | Acc: 41.765,61.261,73.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.747 | Acc: 41.790,61.174,73.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.747 | Acc: 41.801,61.231,72.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.748 | Acc: 41.788,61.266,72.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.752 | Acc: 41.702,61.219,72.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.756 | Acc: 41.649,61.208,72.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.760 | Acc: 41.601,61.157,72.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.529 | Acc: 20.312,45.312,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.251 | Acc: 22.284,47.284,61.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 21.608,46.170,60.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.372 | Acc: 21.286,45.902,59.708,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 2.608 | Acc: 46.875,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.587 | Acc: 43.862,64.137,76.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.605 | Acc: 42.988,62.557,75.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.639 | Acc: 42.764,62.756,75.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.660 | Acc: 42.091,62.384,75.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.672 | Acc: 41.963,62.384,74.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.671 | Acc: 42.123,62.481,74.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.692 | Acc: 41.999,62.035,74.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.698 | Acc: 41.916,61.966,74.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.709 | Acc: 41.803,61.848,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.719 | Acc: 41.713,61.645,73.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.718 | Acc: 41.724,61.595,73.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.730 | Acc: 41.452,61.408,73.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.736 | Acc: 41.370,61.384,73.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.747 | Acc: 41.295,61.143,73.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.747 | Acc: 41.336,61.161,73.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.747 | Acc: 41.350,61.171,73.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.752 | Acc: 41.363,61.116,73.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.753 | Acc: 41.359,61.054,73.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.754 | Acc: 41.421,61.093,73.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.813 | Acc: 24.219,47.656,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.970 | Acc: 29.501,47.731,59.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.038 | Acc: 28.163,46.913,58.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.054 | Acc: 28.317,46.798,58.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.193 | Acc: 51.562,68.750,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.652 | Acc: 41.853,62.463,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.648 | Acc: 42.111,62.729,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.644 | Acc: 42.508,62.718,74.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.646 | Acc: 42.390,62.587,74.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.661 | Acc: 42.559,62.237,74.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.663 | Acc: 42.362,62.222,74.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.675 | Acc: 42.199,62.001,73.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.678 | Acc: 42.100,62.010,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.686 | Acc: 42.045,61.960,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.691 | Acc: 41.985,61.890,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.700 | Acc: 42.039,61.705,73.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.708 | Acc: 41.931,61.592,73.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.715 | Acc: 41.879,61.560,73.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.722 | Acc: 41.837,61.510,73.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.725 | Acc: 41.884,61.405,73.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.728 | Acc: 41.927,61.366,73.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.729 | Acc: 41.979,61.322,73.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.737 | Acc: 41.902,61.253,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.742 | Acc: 41.939,61.245,73.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.300 | Acc: 25.781,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.441 | Acc: 25.781,44.978,55.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.514 | Acc: 24.924,43.693,55.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.534 | Acc: 24.539,43.481,55.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.440 | Acc: 47.656,61.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 41.406,60.938,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.690 | Acc: 41.273,61.681,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.691 | Acc: 41.598,61.757,74.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.698 | Acc: 41.618,61.564,74.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.713 | Acc: 41.607,61.479,74.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.715 | Acc: 41.684,61.422,73.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.713 | Acc: 41.750,61.436,73.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.717 | Acc: 41.824,61.471,73.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.718 | Acc: 42.028,61.473,73.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.713 | Acc: 42.083,61.478,73.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.715 | Acc: 42.046,61.535,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.714 | Acc: 42.038,61.524,73.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.717 | Acc: 42.074,61.458,73.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.725 | Acc: 42.018,61.371,73.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.732 | Acc: 42.053,61.215,73.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.735 | Acc: 42.061,61.159,73.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.739 | Acc: 42.073,61.144,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.740 | Acc: 42.123,61.184,73.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.746 | Acc: 42.091,61.108,73.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.515 | Acc: 36.719,53.125,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.892 | Acc: 32.143,50.595,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.915 | Acc: 32.336,49.790,58.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.916 | Acc: 31.890,49.795,59.119,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 2.761 | Acc: 42.188,60.938,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.647 | Acc: 42.560,61.979,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.665 | Acc: 42.302,61.947,75.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.673 | Acc: 42.418,61.680,75.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.680 | Acc: 42.409,61.603,75.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.686 | Acc: 42.071,61.726,74.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.693 | Acc: 42.220,61.900,74.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.701 | Acc: 42.204,61.702,74.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.703 | Acc: 42.241,61.733,74.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.709 | Acc: 42.209,61.594,73.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.715 | Acc: 42.013,61.540,73.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.721 | Acc: 41.940,61.493,73.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.716 | Acc: 42.045,61.553,73.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.720 | Acc: 41.999,61.515,73.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.721 | Acc: 41.985,61.519,73.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.729 | Acc: 41.907,61.438,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.730 | Acc: 41.893,61.463,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.728 | Acc: 41.883,61.469,73.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.730 | Acc: 41.885,61.455,73.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.733 | Acc: 41.927,61.428,73.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.026 | Acc: 14.844,33.594,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.230 | Acc: 16.667,36.384,53.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.236 | Acc: 16.730,36.071,52.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.238 | Acc: 16.790,35.745,51.806,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.476 | Acc: 46.875,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.684 | Acc: 42.262,62.946,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.692 | Acc: 41.063,62.329,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 40.932,62.013,74.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.700 | Acc: 41.155,61.796,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.697 | Acc: 41.422,61.734,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.692 | Acc: 41.710,61.829,73.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.694 | Acc: 41.944,61.708,73.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.704 | Acc: 41.649,61.500,73.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.700 | Acc: 41.812,61.615,73.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.702 | Acc: 41.775,61.447,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.706 | Acc: 41.799,61.450,73.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.715 | Acc: 41.568,61.258,73.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.716 | Acc: 41.592,61.297,73.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.714 | Acc: 41.651,61.374,73.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.725 | Acc: 41.697,61.272,73.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.728 | Acc: 41.698,61.259,73.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.731 | Acc: 41.702,61.222,73.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.735 | Acc: 41.675,61.230,73.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.735 | Acc: 41.574,61.241,73.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.577 | Acc: 30.469,45.312,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.542 | Acc: 27.567,43.080,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 26.696,42.569,54.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 26.562,42.674,54.150,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.656 | Acc: 39.844,57.812,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.641 | Acc: 41.257,61.421,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.616 | Acc: 42.111,62.767,75.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.604 | Acc: 41.867,63.230,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.648 | Acc: 40.905,62.519,75.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.658 | Acc: 41.012,62.562,74.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.674 | Acc: 41.245,62.345,74.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.669 | Acc: 41.367,62.273,74.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.686 | Acc: 41.285,61.995,74.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.692 | Acc: 41.376,61.878,74.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.689 | Acc: 41.550,61.960,74.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.694 | Acc: 41.569,61.811,74.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.699 | Acc: 41.585,61.738,74.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.710 | Acc: 41.640,61.737,73.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.714 | Acc: 41.662,61.627,73.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.717 | Acc: 41.627,61.573,73.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.722 | Acc: 41.584,61.473,73.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.725 | Acc: 41.580,61.444,73.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.732 | Acc: 41.495,61.292,73.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.735 | Acc: 41.410,61.311,73.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.642 | Acc: 29.688,47.656,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.853 | Acc: 29.204,49.219,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.913 | Acc: 28.678,48.914,59.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.957 | Acc: 28.612,48.950,58.901,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 3.027 | Acc: 35.938,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.732 | Acc: 41.146,62.016,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.669 | Acc: 42.054,62.767,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.652 | Acc: 42.290,62.718,75.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.655 | Acc: 42.178,62.645,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.688 | Acc: 41.832,61.904,74.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.686 | Acc: 42.020,61.841,74.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.697 | Acc: 41.794,61.630,74.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.707 | Acc: 41.576,61.466,73.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.709 | Acc: 41.570,61.581,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.711 | Acc: 41.671,61.602,73.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.720 | Acc: 41.604,61.447,73.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.729 | Acc: 41.565,61.310,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.731 | Acc: 41.514,61.270,73.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.725 | Acc: 41.732,61.441,73.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.723 | Acc: 41.749,61.462,73.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.727 | Acc: 41.752,61.458,73.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.724 | Acc: 41.828,61.451,73.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.728 | Acc: 41.852,61.375,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.733 | Acc: 41.816,61.356,73.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.614 | Acc: 22.656,46.094,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.677 | Acc: 22.098,46.317,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.710 | Acc: 21.627,45.046,53.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.720 | Acc: 21.504,45.172,53.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 2.532 | Acc: 42.188,61.719,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.600 | Acc: 42.411,63.281,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.657 | Acc: 41.883,62.386,75.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.664 | Acc: 41.919,62.193,75.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.643 | Acc: 42.236,62.404,75.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.655 | Acc: 42.010,62.438,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.655 | Acc: 42.084,62.597,75.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.672 | Acc: 41.971,62.345,74.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.680 | Acc: 42.047,62.136,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.685 | Acc: 41.903,62.176,74.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.693 | Acc: 41.849,62.045,74.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.698 | Acc: 41.820,61.835,74.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.707 | Acc: 41.834,61.764,73.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.707 | Acc: 41.876,61.743,74.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.714 | Acc: 41.815,61.680,73.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.720 | Acc: 41.879,61.597,73.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.724 | Acc: 41.922,61.478,73.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.726 | Acc: 41.894,61.547,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.728 | Acc: 41.936,61.543,73.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.733 | Acc: 41.851,61.446,73.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.222 | Acc: 21.875,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.249 | Acc: 23.772,49.554,59.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.334 | Acc: 22.923,48.037,58.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.382 | Acc: 22.503,47.733,57.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 2.689 | Acc: 42.969,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.677 | Acc: 41.629,60.900,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.647 | Acc: 41.768,61.433,75.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.637 | Acc: 41.662,61.732,75.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.642 | Acc: 42.033,61.863,75.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.644 | Acc: 41.986,61.742,75.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.663 | Acc: 41.665,61.532,74.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.673 | Acc: 41.689,61.608,74.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.685 | Acc: 41.513,61.452,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.688 | Acc: 41.488,61.481,74.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.689 | Acc: 41.538,61.400,74.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.701 | Acc: 41.420,61.330,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.705 | Acc: 41.594,61.339,73.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.708 | Acc: 41.559,61.240,73.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.709 | Acc: 41.629,61.277,73.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.713 | Acc: 41.640,61.226,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.710 | Acc: 41.652,61.312,73.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.709 | Acc: 41.727,61.398,73.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.709 | Acc: 41.781,61.385,73.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.710 | Acc: 41.843,61.354,73.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.205 | Acc: 14.844,39.844,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.286 | Acc: 16.071,40.774,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.319 | Acc: 16.063,40.549,51.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.285 | Acc: 16.214,40.651,51.319,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.895 | Acc: 45.312,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.716 | Acc: 41.071,60.975,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.682 | Acc: 41.597,61.128,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.680 | Acc: 41.534,60.809,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.689 | Acc: 41.570,60.860,74.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.689 | Acc: 41.399,61.100,74.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.698 | Acc: 41.497,61.041,74.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.690 | Acc: 41.833,61.420,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.697 | Acc: 41.809,61.374,74.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.700 | Acc: 41.721,61.443,74.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.702 | Acc: 41.717,61.353,74.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.700 | Acc: 41.968,61.362,74.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.711 | Acc: 41.863,61.216,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.711 | Acc: 41.954,61.303,73.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.713 | Acc: 41.834,61.316,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.715 | Acc: 41.907,61.319,73.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.717 | Acc: 41.927,61.346,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.721 | Acc: 41.835,61.263,73.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.721 | Acc: 41.947,61.273,73.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.727 | Acc: 41.968,61.225,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.208 | Acc: 25.000,50.781,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.613 | Acc: 23.624,46.391,56.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 23.628,45.941,55.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 23.450,45.761,55.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 2.709 | Acc: 42.969,60.938,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.610 | Acc: 41.332,62.686,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.565 | Acc: 42.721,63.700,76.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.600 | Acc: 42.789,62.807,75.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.619 | Acc: 42.660,62.442,75.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.645 | Acc: 42.435,62.314,74.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.644 | Acc: 42.543,62.255,74.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.656 | Acc: 42.520,62.134,74.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.669 | Acc: 42.367,61.947,74.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.671 | Acc: 42.291,61.986,74.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.683 | Acc: 42.180,61.831,74.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.693 | Acc: 42.057,61.775,74.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.700 | Acc: 41.974,61.677,73.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.699 | Acc: 41.927,61.704,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.705 | Acc: 41.876,61.646,73.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.708 | Acc: 41.866,61.688,73.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.717 | Acc: 41.776,61.541,73.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.718 | Acc: 41.793,61.506,73.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.721 | Acc: 41.852,61.444,73.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.723 | Acc: 41.868,61.456,73.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.910 | Acc: 24.219,55.469,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.107 | Acc: 24.256,49.405,59.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.124 | Acc: 25.038,48.971,58.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.134 | Acc: 24.539,49.065,58.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 2.555 | Acc: 52.344,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.626 | Acc: 41.555,62.574,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.642 | Acc: 41.768,62.900,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.663 | Acc: 41.624,61.911,74.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.663 | Acc: 42.043,62.249,74.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.666 | Acc: 42.017,62.113,74.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.664 | Acc: 41.916,62.087,74.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.656 | Acc: 42.215,62.156,74.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.655 | Acc: 42.188,62.209,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.666 | Acc: 42.157,62.068,74.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.672 | Acc: 42.172,61.925,74.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.674 | Acc: 42.223,61.998,74.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.688 | Acc: 41.944,61.751,74.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.692 | Acc: 42.086,61.746,74.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.700 | Acc: 42.026,61.691,73.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.703 | Acc: 41.990,61.628,73.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.708 | Acc: 41.912,61.478,73.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.711 | Acc: 41.963,61.414,73.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.710 | Acc: 41.958,61.405,73.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.713 | Acc: 42.048,61.364,73.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.466 | Acc: 28.125,58.594,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.815 | Acc: 30.618,52.455,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.837 | Acc: 30.736,51.620,60.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.832 | Acc: 30.584,51.767,60.720,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.533 | Acc: 43.750,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.528 | Acc: 42.188,65.216,77.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 43.045,64.539,76.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.592 | Acc: 42.188,63.204,75.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.596 | Acc: 42.197,63.320,75.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.599 | Acc: 42.095,63.181,75.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.608 | Acc: 42.155,63.049,75.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.625 | Acc: 41.883,62.639,75.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.625 | Acc: 42.081,62.680,75.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.633 | Acc: 42.166,62.509,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.642 | Acc: 42.079,62.387,74.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.649 | Acc: 42.085,62.295,74.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.652 | Acc: 41.977,62.263,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.659 | Acc: 41.999,62.225,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.669 | Acc: 41.957,62.114,74.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.676 | Acc: 41.993,61.950,74.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.682 | Acc: 41.976,61.938,74.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.693 | Acc: 41.908,61.817,74.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.701 | Acc: 41.876,61.738,73.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.707 | Acc: 41.810,61.696,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.467 | Acc: 21.875,47.656,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.671 | Acc: 19.494,43.899,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.716 | Acc: 18.960,44.646,58.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.759 | Acc: 18.238,44.019,57.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 2.843 | Acc: 40.625,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.636 | Acc: 42.522,61.682,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.618 | Acc: 42.435,62.633,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.610 | Acc: 42.367,62.577,75.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.620 | Acc: 42.351,62.326,75.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.634 | Acc: 42.450,62.237,75.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.643 | Acc: 42.175,62.177,75.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.643 | Acc: 42.110,62.312,75.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.644 | Acc: 42.081,62.345,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.652 | Acc: 41.976,62.116,75.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.657 | Acc: 41.962,61.936,74.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.670 | Acc: 41.937,61.828,74.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.669 | Acc: 42.090,61.894,74.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.677 | Acc: 42.038,61.856,74.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.685 | Acc: 42.029,61.805,74.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.689 | Acc: 42.104,61.771,74.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.691 | Acc: 42.005,61.728,74.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.695 | Acc: 41.901,61.751,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.697 | Acc: 41.859,61.820,73.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.697 | Acc: 41.905,61.862,73.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.926 | Acc: 31.250,50.000,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.111 | Acc: 27.604,47.284,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.140 | Acc: 28.754,46.532,58.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.180 | Acc: 28.650,46.440,57.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.405 | Acc: 50.000,67.969,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 42.299,61.644,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.673 | Acc: 42.092,62.024,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.695 | Acc: 41.957,61.924,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.692 | Acc: 41.773,61.989,74.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.682 | Acc: 41.925,61.966,74.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.683 | Acc: 41.968,62.035,74.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.685 | Acc: 42.237,61.935,74.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.686 | Acc: 42.420,61.932,73.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.681 | Acc: 42.580,61.952,74.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.681 | Acc: 42.603,61.936,74.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.682 | Acc: 42.587,61.913,74.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.684 | Acc: 42.625,61.913,73.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.691 | Acc: 42.559,61.862,73.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.700 | Acc: 42.463,61.791,73.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.704 | Acc: 42.411,61.786,73.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.703 | Acc: 42.390,61.850,73.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.711 | Acc: 42.281,61.742,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.713 | Acc: 42.261,61.773,73.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.718 | Acc: 42.155,61.645,73.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.432 | Acc: 19.531,52.344,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.345 | Acc: 25.149,47.396,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.371 | Acc: 24.905,47.409,56.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.397 | Acc: 24.718,47.118,56.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 2.778 | Acc: 40.625,53.906,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.627 | Acc: 41.146,61.644,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.636 | Acc: 40.911,61.909,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.632 | Acc: 41.624,62.372,75.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.649 | Acc: 41.676,62.452,74.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.646 | Acc: 41.700,62.369,74.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.653 | Acc: 41.748,62.397,74.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.667 | Acc: 41.772,62.173,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.674 | Acc: 41.819,62.223,74.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.686 | Acc: 41.795,61.982,73.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.683 | Acc: 41.904,62.018,73.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.685 | Acc: 41.944,61.970,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.682 | Acc: 42.106,62.033,74.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.686 | Acc: 42.002,61.928,73.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.690 | Acc: 41.979,61.955,73.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.696 | Acc: 41.886,61.890,73.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.700 | Acc: 41.857,61.770,73.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.701 | Acc: 41.846,61.707,73.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.700 | Acc: 41.921,61.801,73.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.706 | Acc: 41.972,61.754,73.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.948 | Acc: 33.594,47.656,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.124 | Acc: 28.423,48.847,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.135 | Acc: 28.316,47.618,58.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.154 | Acc: 28.189,47.695,58.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.874 | Acc: 41.406,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.592 | Acc: 43.304,63.504,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.598 | Acc: 43.388,63.681,75.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.621 | Acc: 42.444,62.961,75.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.634 | Acc: 42.101,62.539,74.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.646 | Acc: 42.188,62.129,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.652 | Acc: 42.349,62.054,74.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.671 | Acc: 42.188,61.663,74.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.678 | Acc: 42.328,61.617,74.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.676 | Acc: 42.416,61.689,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.681 | Acc: 42.265,61.606,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.685 | Acc: 42.255,61.659,74.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.686 | Acc: 42.278,61.767,74.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.685 | Acc: 42.313,61.827,74.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.686 | Acc: 42.385,61.841,74.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.690 | Acc: 42.309,61.773,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.691 | Acc: 42.346,61.748,73.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.697 | Acc: 42.366,61.700,73.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.701 | Acc: 42.380,61.771,73.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.706 | Acc: 42.315,61.696,73.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.087 | Acc: 27.344,46.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.108 | Acc: 28.534,46.466,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.162 | Acc: 28.201,46.589,58.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.144 | Acc: 28.266,46.657,58.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.820 | Acc: 46.875,57.031,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.623 | Acc: 43.601,63.095,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.649 | Acc: 42.473,62.595,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.644 | Acc: 42.533,62.205,74.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.658 | Acc: 42.274,61.825,74.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.672 | Acc: 41.847,61.610,74.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.674 | Acc: 41.871,61.635,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.666 | Acc: 42.082,61.902,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.654 | Acc: 42.202,62.146,74.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.660 | Acc: 41.993,62.206,74.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.658 | Acc: 41.978,62.205,74.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.669 | Acc: 41.848,61.952,74.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.674 | Acc: 41.957,61.910,74.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.678 | Acc: 41.900,61.871,74.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.677 | Acc: 41.929,61.966,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.686 | Acc: 41.829,61.887,74.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.687 | Acc: 41.937,61.892,74.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.685 | Acc: 42.045,61.996,74.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.691 | Acc: 41.973,61.937,73.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.696 | Acc: 41.962,61.873,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.271 | Acc: 32.812,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.970 | Acc: 31.771,49.888,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.041 | Acc: 31.593,48.876,56.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.049 | Acc: 31.340,48.745,56.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.550 | Acc: 49.219,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.485 | Acc: 44.643,63.653,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.593 | Acc: 43.331,62.748,75.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.632 | Acc: 42.559,62.641,75.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.642 | Acc: 42.554,62.259,74.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.651 | Acc: 42.443,62.183,74.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.658 | Acc: 42.627,62.319,74.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.658 | Acc: 42.730,62.317,74.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.660 | Acc: 42.712,62.194,74.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.656 | Acc: 42.662,62.332,74.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.656 | Acc: 42.763,62.278,74.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.668 | Acc: 42.714,61.994,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.668 | Acc: 42.654,62.007,74.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.676 | Acc: 42.460,61.770,74.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.683 | Acc: 42.285,61.652,74.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.688 | Acc: 42.234,61.584,74.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.691 | Acc: 42.212,61.534,74.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.689 | Acc: 42.201,61.579,74.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.693 | Acc: 42.237,61.574,74.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.697 | Acc: 42.265,61.542,74.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.803 | Acc: 32.031,54.688,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.009 | Acc: 29.018,48.772,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.052 | Acc: 28.678,48.190,59.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.087 | Acc: 28.650,47.797,58.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 2.187 | Acc: 53.125,68.750,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.554 | Acc: 42.746,61.756,76.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.602 | Acc: 42.778,61.986,75.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.603 | Acc: 42.700,61.796,75.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.619 | Acc: 42.419,61.757,74.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.620 | Acc: 42.450,62.191,74.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.631 | Acc: 42.510,62.319,74.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.640 | Acc: 42.426,62.184,74.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.641 | Acc: 42.585,62.126,74.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.652 | Acc: 42.377,61.978,74.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.647 | Acc: 42.397,62.034,74.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.652 | Acc: 42.502,62.069,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.665 | Acc: 42.431,61.985,74.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.675 | Acc: 42.259,61.832,74.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.681 | Acc: 42.176,61.705,74.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.682 | Acc: 42.242,61.747,74.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.686 | Acc: 42.280,61.741,73.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.688 | Acc: 42.275,61.751,73.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.692 | Acc: 42.179,61.691,73.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.694 | Acc: 42.155,61.651,73.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.945 | Acc: 25.000,50.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.026 | Acc: 24.740,50.149,60.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.072 | Acc: 24.486,49.619,59.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.093 | Acc: 24.411,49.436,58.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 2.530 | Acc: 37.500,64.844,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.632 | Acc: 42.560,63.318,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.632 | Acc: 41.864,63.110,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.639 | Acc: 42.136,62.590,74.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.634 | Acc: 42.081,62.240,75.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.632 | Acc: 42.149,62.369,75.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.630 | Acc: 41.974,62.526,75.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.633 | Acc: 42.032,62.472,75.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.644 | Acc: 42.285,62.413,74.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.642 | Acc: 42.317,62.453,74.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.647 | Acc: 42.378,62.325,74.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.649 | Acc: 42.428,62.334,74.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.647 | Acc: 42.450,62.286,74.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.647 | Acc: 42.391,62.320,74.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.646 | Acc: 42.471,62.330,74.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.653 | Acc: 42.320,62.189,74.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.660 | Acc: 42.219,62.084,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.662 | Acc: 42.233,62.056,74.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.669 | Acc: 42.257,61.879,74.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.669 | Acc: 42.298,61.922,74.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.224 | Acc: 28.125,51.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.066 | Acc: 28.720,48.475,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.132 | Acc: 28.887,48.171,58.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.165 | Acc: 28.624,48.053,58.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 2.650 | Acc: 47.656,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.643 | Acc: 42.857,62.240,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.633 | Acc: 43.293,62.443,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.606 | Acc: 42.892,63.140,75.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.605 | Acc: 42.622,63.050,75.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.619 | Acc: 42.567,62.802,75.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.623 | Acc: 42.782,62.642,75.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.634 | Acc: 42.736,62.350,74.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.630 | Acc: 42.644,62.490,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.641 | Acc: 42.554,62.332,74.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.649 | Acc: 42.514,62.267,74.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.653 | Acc: 42.552,62.090,74.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.655 | Acc: 42.541,62.066,74.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.658 | Acc: 42.520,62.030,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.670 | Acc: 42.415,61.897,74.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.674 | Acc: 42.411,61.836,74.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.682 | Acc: 42.341,61.746,74.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.682 | Acc: 42.339,61.758,74.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.687 | Acc: 42.294,61.732,73.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.688 | Acc: 42.343,61.750,73.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.915 | Acc: 26.562,49.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.322 | Acc: 26.376,45.796,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.350 | Acc: 26.391,45.351,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.385 | Acc: 26.153,45.364,56.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 2.758 | Acc: 41.406,62.500,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.569 | Acc: 43.266,63.021,76.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.604 | Acc: 42.607,62.214,75.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.580 | Acc: 42.892,62.577,75.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.585 | Acc: 42.940,62.683,75.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.601 | Acc: 42.768,62.454,75.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.603 | Acc: 42.833,62.468,75.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.608 | Acc: 42.891,62.539,75.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.614 | Acc: 42.770,62.626,75.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.631 | Acc: 42.658,62.591,74.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.637 | Acc: 42.600,62.535,74.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.645 | Acc: 42.636,62.489,74.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.647 | Acc: 42.479,62.490,74.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.650 | Acc: 42.415,62.377,74.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.658 | Acc: 42.357,62.317,74.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.664 | Acc: 42.377,62.204,74.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.668 | Acc: 42.438,62.176,74.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.673 | Acc: 42.368,62.154,74.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.677 | Acc: 42.326,62.132,73.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.681 | Acc: 42.362,62.129,73.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.318 | Acc: 29.688,46.094,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.369 | Acc: 24.330,43.713,58.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.388 | Acc: 24.733,43.902,57.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.413 | Acc: 24.782,44.301,57.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 2.274 | Acc: 50.781,62.500,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.522 | Acc: 45.238,63.728,77.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.583 | Acc: 44.112,62.614,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.593 | Acc: 43.648,62.487,75.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.617 | Acc: 42.949,62.278,75.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.628 | Acc: 42.775,62.276,74.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.623 | Acc: 42.659,62.532,75.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.633 | Acc: 42.675,62.489,74.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.650 | Acc: 42.416,62.267,74.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.661 | Acc: 42.153,62.103,74.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.658 | Acc: 42.238,62.310,74.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.663 | Acc: 42.237,62.207,74.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.661 | Acc: 42.450,62.289,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.659 | Acc: 42.412,62.267,74.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.661 | Acc: 42.321,62.291,74.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.661 | Acc: 42.341,62.212,74.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.669 | Acc: 42.353,62.132,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.675 | Acc: 42.224,62.039,74.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.681 | Acc: 42.151,61.901,73.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.683 | Acc: 42.175,61.842,73.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.636 | Acc: 32.812,51.562,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.958 | Acc: 28.609,50.223,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.004 | Acc: 27.992,49.238,59.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.043 | Acc: 26.972,48.553,58.927,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 3.115 | Acc: 39.844,58.594,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.541 | Acc: 41.518,64.286,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.584 | Acc: 42.016,63.243,76.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.578 | Acc: 42.136,63.281,75.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.598 | Acc: 42.101,62.799,75.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.612 | Acc: 41.700,62.570,75.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.622 | Acc: 42.110,62.539,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.632 | Acc: 42.293,62.361,74.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.642 | Acc: 42.435,62.330,74.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.643 | Acc: 42.429,62.336,74.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.645 | Acc: 42.343,62.278,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.650 | Acc: 42.209,62.203,74.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.654 | Acc: 42.152,62.036,74.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.655 | Acc: 42.256,62.126,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.659 | Acc: 42.249,62.175,74.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.663 | Acc: 42.229,62.266,74.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.663 | Acc: 42.229,62.291,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.665 | Acc: 42.236,62.292,74.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.666 | Acc: 42.207,62.325,74.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.669 | Acc: 42.153,62.311,74.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.653 | Acc: 31.250,53.125,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.915 | Acc: 29.911,48.512,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.896 | Acc: 30.335,48.171,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.900 | Acc: 30.033,48.502,58.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.925 | Acc: 39.062,57.031,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 42.188,60.863,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.659 | Acc: 42.550,61.757,75.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.650 | Acc: 42.290,62.039,75.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.649 | Acc: 42.679,62.085,75.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.624 | Acc: 42.830,62.616,75.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.634 | Acc: 42.678,62.539,75.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.635 | Acc: 42.625,62.539,75.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.638 | Acc: 42.605,62.519,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.647 | Acc: 42.520,62.271,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.657 | Acc: 42.498,62.177,74.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.663 | Acc: 42.513,62.178,74.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.669 | Acc: 42.486,62.095,74.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.665 | Acc: 42.454,62.093,74.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.674 | Acc: 42.427,62.002,74.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.677 | Acc: 42.452,61.996,74.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.685 | Acc: 42.355,61.909,74.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.683 | Acc: 42.387,61.930,74.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.685 | Acc: 42.374,61.903,74.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.689 | Acc: 42.321,61.858,73.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.526 | Acc: 32.031,53.906,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.814 | Acc: 30.990,48.251,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.887 | Acc: 30.030,47.618,59.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.880 | Acc: 30.328,47.938,59.990,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 2.659 | Acc: 37.500,58.594,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 41.295,60.268,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.652 | Acc: 42.664,61.128,75.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.643 | Acc: 42.687,61.655,75.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.628 | Acc: 43.220,62.307,75.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.636 | Acc: 42.992,62.322,75.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.640 | Acc: 42.698,62.190,75.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.626 | Acc: 42.941,62.517,75.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.640 | Acc: 42.833,62.253,74.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.644 | Acc: 42.796,62.353,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.645 | Acc: 42.794,62.368,74.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.648 | Acc: 42.757,62.408,74.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.663 | Acc: 42.505,62.218,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.668 | Acc: 42.376,62.180,74.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.670 | Acc: 42.310,62.089,74.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.675 | Acc: 42.213,62.072,74.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.677 | Acc: 42.224,62.091,74.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.674 | Acc: 42.275,62.188,74.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.675 | Acc: 42.317,62.143,74.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.679 | Acc: 42.286,62.057,74.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.999 | Acc: 25.000,46.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.463 | Acc: 23.921,47.284,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.427 | Acc: 23.780,47.046,56.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.441 | Acc: 23.527,46.939,56.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 2.356 | Acc: 44.531,67.188,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.642 | Acc: 40.476,60.789,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.611 | Acc: 41.654,61.738,76.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.613 | Acc: 41.778,61.936,76.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.627 | Acc: 41.927,61.941,75.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.627 | Acc: 41.700,61.920,75.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.637 | Acc: 41.781,62.048,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.642 | Acc: 42.038,62.179,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.646 | Acc: 41.940,62.136,74.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.653 | Acc: 42.019,62.038,74.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.656 | Acc: 42.005,61.987,74.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.663 | Acc: 42.004,61.963,74.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.668 | Acc: 42.042,61.972,74.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.669 | Acc: 42.029,62.039,74.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.668 | Acc: 42.057,62.130,74.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.667 | Acc: 42.099,62.131,74.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.667 | Acc: 42.107,62.130,74.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.668 | Acc: 42.096,62.085,74.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.667 | Acc: 42.211,62.097,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.667 | Acc: 42.341,62.110,74.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.625 | Acc: 32.812,48.438,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.017 | Acc: 28.534,48.400,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.042 | Acc: 28.563,47.637,59.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.076 | Acc: 28.407,48.130,58.863,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 2.783 | Acc: 39.844,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.637 | Acc: 41.146,62.649,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.570 | Acc: 42.397,63.224,76.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.567 | Acc: 42.585,63.422,76.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.576 | Acc: 42.728,63.426,76.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.597 | Acc: 42.412,63.142,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.615 | Acc: 42.207,62.933,75.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.618 | Acc: 42.232,62.943,75.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.629 | Acc: 42.314,62.854,75.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.637 | Acc: 42.459,62.781,74.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.648 | Acc: 42.300,62.609,74.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.653 | Acc: 42.241,62.500,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.658 | Acc: 42.210,62.494,74.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.660 | Acc: 42.373,62.431,74.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.661 | Acc: 42.382,62.453,74.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.665 | Acc: 42.372,62.339,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.669 | Acc: 42.407,62.261,74.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.674 | Acc: 42.421,62.115,73.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.675 | Acc: 42.419,62.093,73.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.673 | Acc: 42.434,62.153,73.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.197 | Acc: 21.875,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.407 | Acc: 23.586,47.024,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.488 | Acc: 23.018,46.437,58.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.485 | Acc: 22.374,46.683,58.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 2.456 | Acc: 48.438,60.938,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 40.811,60.007,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.668 | Acc: 41.463,60.880,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.653 | Acc: 41.701,61.322,75.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.628 | Acc: 42.139,61.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.635 | Acc: 42.087,62.028,74.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.639 | Acc: 41.968,62.113,74.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.638 | Acc: 41.944,62.273,74.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.641 | Acc: 42.071,62.422,74.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.638 | Acc: 42.308,62.478,74.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.643 | Acc: 42.351,62.434,74.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.645 | Acc: 42.424,62.401,74.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.654 | Acc: 42.440,62.309,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.649 | Acc: 42.541,62.416,74.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.649 | Acc: 42.507,62.519,74.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.653 | Acc: 42.476,62.484,74.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.656 | Acc: 42.424,62.422,74.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.664 | Acc: 42.346,62.308,74.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.668 | Acc: 42.322,62.305,74.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.673 | Acc: 42.308,62.203,73.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.591 | Acc: 35.156,48.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.816 | Acc: 29.911,52.344,60.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.852 | Acc: 29.802,51.639,59.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.892 | Acc: 29.867,51.486,59.413,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 2.391 | Acc: 39.844,67.188,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.593 | Acc: 42.597,61.496,76.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.585 | Acc: 43.559,62.081,76.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.608 | Acc: 42.597,62.205,75.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.609 | Acc: 42.622,62.355,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.610 | Acc: 42.590,62.384,75.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.608 | Acc: 42.807,62.487,75.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.607 | Acc: 42.769,62.439,75.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.610 | Acc: 42.794,62.500,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.621 | Acc: 42.705,62.401,75.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.627 | Acc: 42.603,62.251,74.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.632 | Acc: 42.665,62.330,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.640 | Acc: 42.551,62.302,74.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.640 | Acc: 42.583,62.308,74.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.643 | Acc: 42.630,62.244,74.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.645 | Acc: 42.691,62.253,74.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.649 | Acc: 42.669,62.196,74.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.652 | Acc: 42.630,62.159,74.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.653 | Acc: 42.674,62.160,74.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.655 | Acc: 42.694,62.125,74.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.107 | Acc: 21.094,37.500,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.340 | Acc: 20.833,38.467,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.386 | Acc: 20.713,38.529,51.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.442 | Acc: 20.569,38.358,51.486,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 2.671 | Acc: 39.844,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.631 | Acc: 41.518,62.946,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.647 | Acc: 42.035,62.633,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.647 | Acc: 42.200,62.551,74.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.634 | Acc: 42.583,62.693,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.634 | Acc: 42.799,62.709,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.637 | Acc: 42.949,62.532,74.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.647 | Acc: 42.747,62.251,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.656 | Acc: 42.600,62.209,74.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.661 | Acc: 42.503,62.176,74.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.665 | Acc: 42.483,62.177,74.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.667 | Acc: 42.534,62.210,74.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.666 | Acc: 42.599,62.299,74.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.665 | Acc: 42.648,62.326,74.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.668 | Acc: 42.560,62.214,74.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.666 | Acc: 42.543,62.282,74.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.668 | Acc: 42.455,62.271,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.669 | Acc: 42.423,62.234,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.669 | Acc: 42.402,62.251,74.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.670 | Acc: 42.395,62.240,74.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.683 | Acc: 25.781,52.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.814 | Acc: 27.865,51.525,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.870 | Acc: 27.325,50.705,60.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.899 | Acc: 26.729,50.102,60.592,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.768 | Acc: 48.438,61.719,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.584 | Acc: 43.787,63.653,76.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.561 | Acc: 42.931,63.643,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.586 | Acc: 42.252,63.115,76.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.602 | Acc: 42.486,62.895,76.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.602 | Acc: 42.652,62.639,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.615 | Acc: 42.639,62.532,75.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.621 | Acc: 42.681,62.655,75.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.621 | Acc: 42.547,62.587,75.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.622 | Acc: 42.459,62.500,75.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.618 | Acc: 42.483,62.589,75.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.624 | Acc: 42.421,62.581,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.637 | Acc: 42.372,62.519,74.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.639 | Acc: 42.337,62.542,74.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.645 | Acc: 42.232,62.469,74.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.647 | Acc: 42.330,62.422,74.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.652 | Acc: 42.365,62.344,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.653 | Acc: 42.380,62.330,74.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.654 | Acc: 42.439,62.301,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.653 | Acc: 42.516,62.315,74.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.923 | Acc: 23.438,46.094,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.782 | Acc: 22.879,42.262,53.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.817 | Acc: 22.675,42.454,54.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.820 | Acc: 22.503,42.585,53.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 2.596 | Acc: 44.531,64.844,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.679 | Acc: 42.076,61.347,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.627 | Acc: 43.274,62.405,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.636 | Acc: 42.918,62.282,75.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.644 | Acc: 42.757,62.018,74.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.651 | Acc: 42.976,61.982,74.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.659 | Acc: 42.801,61.880,74.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.652 | Acc: 42.747,61.824,74.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.657 | Acc: 42.644,61.898,74.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.656 | Acc: 42.792,62.094,74.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.652 | Acc: 42.716,62.135,74.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.647 | Acc: 42.704,62.270,74.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.646 | Acc: 42.797,62.257,74.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.648 | Acc: 42.756,62.246,74.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.656 | Acc: 42.721,62.152,74.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.660 | Acc: 42.616,62.103,74.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.659 | Acc: 42.655,62.154,74.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.660 | Acc: 42.659,62.159,74.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.665 | Acc: 42.568,62.052,74.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.670 | Acc: 42.577,61.944,74.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.491 | Acc: 23.438,47.656,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.501 | Acc: 22.768,42.969,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 22.409,42.340,56.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.552 | Acc: 22.246,42.956,56.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.605 | Acc: 41.406,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.641 | Acc: 41.704,61.756,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.594 | Acc: 42.740,62.386,76.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.576 | Acc: 42.943,62.769,76.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.582 | Acc: 43.036,62.809,75.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.582 | Acc: 42.868,62.918,76.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.589 | Acc: 42.840,62.913,75.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.600 | Acc: 42.553,62.799,75.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.604 | Acc: 42.440,62.767,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.615 | Acc: 42.567,62.625,75.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.623 | Acc: 42.549,62.652,75.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.627 | Acc: 42.559,62.645,75.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.632 | Acc: 42.444,62.558,75.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.638 | Acc: 42.526,62.446,74.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.641 | Acc: 42.571,62.417,74.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.646 | Acc: 42.590,62.394,74.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.648 | Acc: 42.674,62.339,74.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.651 | Acc: 42.662,62.303,74.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.656 | Acc: 42.612,62.264,74.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.660 | Acc: 42.635,62.270,74.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.412 | Acc: 34.375,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.177 | Acc: 30.357,45.647,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.224 | Acc: 29.516,44.607,55.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.242 | Acc: 29.124,44.775,55.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.192 | Acc: 47.656,63.281,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.573 | Acc: 43.787,62.463,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.567 | Acc: 43.350,63.110,76.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.578 | Acc: 43.340,63.281,76.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.574 | Acc: 43.393,63.493,76.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.582 | Acc: 43.232,63.080,76.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.596 | Acc: 43.408,62.913,75.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.590 | Acc: 43.401,63.281,75.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.598 | Acc: 43.056,62.854,75.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.606 | Acc: 43.008,62.867,75.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.603 | Acc: 43.171,62.951,75.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.606 | Acc: 43.227,62.885,75.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.614 | Acc: 43.205,62.821,75.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.615 | Acc: 43.250,62.841,75.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.617 | Acc: 43.088,62.875,75.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.625 | Acc: 42.971,62.715,74.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.632 | Acc: 42.881,62.617,74.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.629 | Acc: 42.994,62.615,74.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.629 | Acc: 43.038,62.630,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.634 | Acc: 42.958,62.582,74.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.149 | Acc: 26.562,51.562,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.889 | Acc: 29.167,52.269,61.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.933 | Acc: 29.059,51.677,60.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.948 | Acc: 29.060,51.486,60.476,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 2.961 | Acc: 45.312,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.545 | Acc: 43.862,64.583,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.563 | Acc: 43.140,63.700,76.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.599 | Acc: 42.533,62.628,75.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.570 | Acc: 42.679,63.329,76.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.576 | Acc: 42.713,63.266,76.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.579 | Acc: 42.762,63.184,75.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.585 | Acc: 42.708,63.204,75.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.582 | Acc: 42.809,63.087,75.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.583 | Acc: 42.641,63.083,75.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.586 | Acc: 42.767,62.939,75.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.597 | Acc: 42.668,62.723,75.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.605 | Acc: 42.654,62.711,75.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.609 | Acc: 42.675,62.757,75.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.617 | Acc: 42.763,62.706,75.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.624 | Acc: 42.720,62.627,75.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.627 | Acc: 42.774,62.644,75.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.634 | Acc: 42.740,62.706,74.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.636 | Acc: 42.750,62.667,74.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.645 | Acc: 42.661,62.529,74.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.130 | Acc: 28.906,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.304 | Acc: 23.624,47.396,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.367 | Acc: 22.847,47.294,58.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.365 | Acc: 22.746,47.451,58.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.534 | Acc: 50.000,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.565 | Acc: 43.155,64.397,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.578 | Acc: 43.274,63.167,76.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.560 | Acc: 43.609,63.204,76.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.574 | Acc: 43.760,63.329,76.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.589 | Acc: 43.526,63.134,76.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.587 | Acc: 43.518,63.165,76.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.585 | Acc: 43.567,63.226,76.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.595 | Acc: 43.464,63.073,75.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.601 | Acc: 43.284,62.940,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.603 | Acc: 43.109,62.819,75.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.608 | Acc: 42.909,62.677,75.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.612 | Acc: 42.956,62.633,75.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.613 | Acc: 42.927,62.602,75.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.621 | Acc: 42.866,62.575,75.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.621 | Acc: 42.792,62.578,75.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.622 | Acc: 42.820,62.558,75.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.628 | Acc: 42.767,62.459,75.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.631 | Acc: 42.757,62.522,75.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.634 | Acc: 42.760,62.451,75.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.655 | Acc: 32.031,59.375,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.933 | Acc: 31.771,51.376,58.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.950 | Acc: 31.479,50.629,58.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.983 | Acc: 30.994,49.795,58.017,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 2.624 | Acc: 42.969,63.281,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.588 | Acc: 43.192,62.202,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.608 | Acc: 42.835,62.481,76.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.589 | Acc: 43.238,62.935,76.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.579 | Acc: 43.461,63.069,76.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.594 | Acc: 43.394,62.918,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.600 | Acc: 43.266,62.939,75.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.591 | Acc: 43.362,63.010,75.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.596 | Acc: 43.342,62.917,75.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.603 | Acc: 43.103,62.720,75.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.611 | Acc: 43.000,62.582,75.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.617 | Acc: 42.877,62.422,75.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.624 | Acc: 42.862,62.257,74.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.632 | Acc: 42.843,62.165,74.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.633 | Acc: 42.858,62.169,74.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.633 | Acc: 42.842,62.191,74.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.631 | Acc: 42.947,62.208,74.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.627 | Acc: 42.914,62.319,74.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.629 | Acc: 42.826,62.325,74.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.633 | Acc: 42.751,62.328,74.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.682 | Acc: 30.469,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.873 | Acc: 28.906,51.302,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.934 | Acc: 28.296,50.267,59.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.951 | Acc: 28.279,49.808,59.810,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 2.739 | Acc: 35.938,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.499 | Acc: 44.568,63.988,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.547 | Acc: 43.902,64.120,76.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.550 | Acc: 43.263,63.435,76.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.550 | Acc: 43.673,63.426,76.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.542 | Acc: 43.758,63.560,76.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.550 | Acc: 43.653,63.714,76.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.573 | Acc: 43.279,63.425,75.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.576 | Acc: 43.299,63.383,75.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.589 | Acc: 43.228,63.251,75.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.595 | Acc: 43.124,63.238,75.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.597 | Acc: 43.170,63.211,75.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.599 | Acc: 43.192,63.178,75.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.610 | Acc: 43.041,62.940,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.612 | Acc: 43.119,62.856,75.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.619 | Acc: 43.047,62.684,75.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.622 | Acc: 43.064,62.634,74.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.631 | Acc: 42.960,62.548,74.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.633 | Acc: 42.895,62.574,74.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.638 | Acc: 42.879,62.494,74.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.458 | Acc: 20.312,50.781,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.611 | Acc: 18.824,44.940,60.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.673 | Acc: 18.864,44.379,58.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.691 | Acc: 19.070,44.173,58.145,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.556 | Acc: 36.719,59.375,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.519 | Acc: 42.820,63.058,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.553 | Acc: 43.445,62.671,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.546 | Acc: 43.110,62.987,76.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.547 | Acc: 43.355,62.847,76.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.557 | Acc: 43.533,62.864,76.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.577 | Acc: 43.705,62.765,76.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.586 | Acc: 43.689,62.733,76.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.603 | Acc: 43.420,62.626,75.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.606 | Acc: 43.491,62.474,75.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.609 | Acc: 43.455,62.473,75.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.608 | Acc: 43.450,62.405,75.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.613 | Acc: 43.436,62.435,75.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.615 | Acc: 43.340,62.470,75.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.613 | Acc: 43.327,62.539,75.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.616 | Acc: 43.270,62.609,75.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.623 | Acc: 43.198,62.627,75.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.625 | Acc: 43.127,62.537,75.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.630 | Acc: 43.077,62.494,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.633 | Acc: 43.090,62.477,74.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.076 | Acc: 26.562,53.125,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.323 | Acc: 21.838,47.359,60.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.404 | Acc: 21.341,46.399,60.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.454 | Acc: 20.966,45.927,59.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 2.462 | Acc: 38.281,59.375,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.497 | Acc: 42.894,63.244,76.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.440 | Acc: 43.502,65.244,78.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.386 | Acc: 44.339,66.176,78.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.360 | Acc: 44.695,66.445,79.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.336 | Acc: 45.127,66.677,79.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.313 | Acc: 45.364,66.910,80.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.291 | Acc: 45.617,67.160,80.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.278 | Acc: 45.686,67.309,80.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.268 | Acc: 45.964,67.546,80.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.257 | Acc: 46.102,67.728,81.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.247 | Acc: 46.299,67.877,81.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.242 | Acc: 46.392,68.024,81.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.234 | Acc: 46.483,68.074,81.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.228 | Acc: 46.658,68.052,81.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.217 | Acc: 46.763,68.158,81.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.209 | Acc: 46.890,68.397,82.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.203 | Acc: 46.912,68.450,82.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.199 | Acc: 46.946,68.469,82.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.195 | Acc: 47.012,68.555,82.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.535 | Acc: 46.094,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.683 | Acc: 45.312,63.839,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 44.531,63.281,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.751 | Acc: 44.429,62.846,71.004,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 2.022 | Acc: 49.219,66.406,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.047 | Acc: 48.214,70.499,85.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.999 | Acc: 48.895,71.589,86.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.042 | Acc: 48.130,70.786,85.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.042 | Acc: 48.495,70.660,85.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.065 | Acc: 48.144,70.204,84.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.068 | Acc: 47.902,69.951,84.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.063 | Acc: 47.878,69.853,84.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.059 | Acc: 47.991,70.104,85.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.060 | Acc: 47.941,70.066,84.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.062 | Acc: 47.878,70.138,84.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.061 | Acc: 47.985,70.199,84.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.056 | Acc: 48.039,70.335,85.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.052 | Acc: 48.033,70.414,85.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.053 | Acc: 48.020,70.307,85.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.053 | Acc: 47.960,70.362,85.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.054 | Acc: 47.870,70.398,85.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.053 | Acc: 47.917,70.393,85.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.052 | Acc: 47.890,70.386,85.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.052 | Acc: 47.790,70.329,85.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.457 | Acc: 45.312,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 46.243,64.621,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.738 | Acc: 45.179,63.643,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.758 | Acc: 44.903,63.192,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.775 | Acc: 50.000,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.051 | Acc: 47.135,69.606,86.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.028 | Acc: 47.732,70.408,86.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 47.579,70.645,86.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.012 | Acc: 47.791,70.621,86.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.998 | Acc: 48.058,70.692,86.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.997 | Acc: 47.947,70.752,86.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.997 | Acc: 47.989,70.839,86.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.006 | Acc: 47.724,70.686,86.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.004 | Acc: 47.803,70.714,86.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.004 | Acc: 47.944,70.674,86.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.002 | Acc: 47.992,70.730,86.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.004 | Acc: 47.977,70.779,86.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.003 | Acc: 48.051,70.690,86.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.005 | Acc: 48.023,70.682,86.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.005 | Acc: 48.004,70.702,86.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.007 | Acc: 48.046,70.731,86.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.004 | Acc: 48.085,70.711,86.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.002 | Acc: 48.072,70.739,86.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.005 | Acc: 48.042,70.760,86.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.487 | Acc: 47.656,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 45.647,64.546,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 45.408,63.739,72.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.748 | Acc: 44.915,63.307,71.773,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.852 | Acc: 53.125,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.988 | Acc: 47.359,70.089,86.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.979 | Acc: 47.370,70.732,86.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 47.439,70.863,86.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.962 | Acc: 47.733,70.959,87.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.958 | Acc: 47.966,70.955,87.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.970 | Acc: 47.998,70.894,87.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.978 | Acc: 47.933,70.689,86.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.981 | Acc: 47.787,70.623,86.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.975 | Acc: 48.053,70.645,87.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.974 | Acc: 48.103,70.767,86.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.973 | Acc: 48.215,70.832,86.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.977 | Acc: 48.230,70.815,86.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.972 | Acc: 48.291,70.917,86.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.969 | Acc: 48.276,71.008,86.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.976 | Acc: 48.204,70.899,86.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.975 | Acc: 48.155,70.953,86.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.974 | Acc: 48.183,70.956,86.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.977 | Acc: 48.111,70.953,86.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.977 | Acc: 48.128,70.975,86.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.490 | Acc: 46.875,65.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.680 | Acc: 46.094,65.327,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 45.446,64.101,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.756 | Acc: 45.108,63.742,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.844 | Acc: 51.562,73.438,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.912 | Acc: 50.074,71.689,87.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.902 | Acc: 49.981,72.351,87.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.901 | Acc: 49.654,72.387,88.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.925 | Acc: 49.151,71.827,87.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.934 | Acc: 48.832,71.666,87.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.938 | Acc: 48.728,71.798,87.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.939 | Acc: 48.770,71.825,87.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.937 | Acc: 48.709,71.686,87.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.939 | Acc: 48.584,71.625,87.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.947 | Acc: 48.469,71.498,87.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.946 | Acc: 48.317,71.518,87.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.945 | Acc: 48.496,71.564,87.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.945 | Acc: 48.557,71.531,87.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.942 | Acc: 48.579,71.552,87.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.943 | Acc: 48.536,71.600,87.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.943 | Acc: 48.511,71.646,87.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.944 | Acc: 48.538,71.614,87.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.945 | Acc: 48.450,71.503,87.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.947 | Acc: 48.413,71.457,87.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.486 | Acc: 48.438,66.406,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 45.461,64.695,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.745 | Acc: 45.770,63.796,71.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.766 | Acc: 45.940,63.461,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.965 | Acc: 44.531,71.875,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.898 | Acc: 47.731,72.247,88.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.930 | Acc: 48.114,71.189,87.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.920 | Acc: 48.117,71.875,88.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.928 | Acc: 48.042,71.605,87.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.926 | Acc: 48.283,71.620,87.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.932 | Acc: 48.328,71.772,87.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.937 | Acc: 48.210,71.454,87.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.937 | Acc: 48.311,71.433,87.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.935 | Acc: 48.407,71.599,87.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.934 | Acc: 48.496,71.486,87.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.933 | Acc: 48.430,71.468,87.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.931 | Acc: 48.450,71.603,87.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.931 | Acc: 48.381,71.507,87.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.930 | Acc: 48.371,71.547,87.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.931 | Acc: 48.292,71.564,87.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.927 | Acc: 48.377,71.658,87.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.928 | Acc: 48.474,71.602,87.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.926 | Acc: 48.563,71.641,87.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.925 | Acc: 48.581,71.656,87.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.419 | Acc: 49.219,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 45.945,64.695,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.749 | Acc: 45.484,64.120,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.766 | Acc: 45.325,63.653,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.771 | Acc: 53.906,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.933 | Acc: 47.768,71.987,88.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.893 | Acc: 48.876,72.294,88.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.897 | Acc: 48.796,72.131,88.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.899 | Acc: 48.727,72.097,88.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.889 | Acc: 49.219,72.486,88.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.893 | Acc: 48.909,72.443,88.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.905 | Acc: 48.665,72.285,88.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.905 | Acc: 48.709,72.317,88.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.907 | Acc: 48.753,72.143,88.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.910 | Acc: 48.644,72.027,88.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.907 | Acc: 48.632,72.023,88.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.907 | Acc: 48.739,71.988,88.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.905 | Acc: 48.851,72.010,88.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.902 | Acc: 48.974,72.000,88.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.902 | Acc: 48.928,71.961,88.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.903 | Acc: 48.936,71.948,88.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.907 | Acc: 48.827,71.804,88.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.910 | Acc: 48.762,71.765,88.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.910 | Acc: 48.727,71.777,88.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.455 | Acc: 50.000,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.699 | Acc: 46.317,64.472,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 45.998,63.891,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.771 | Acc: 45.581,63.781,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.794 | Acc: 51.562,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.854 | Acc: 50.298,71.987,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.853 | Acc: 49.581,72.561,89.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.861 | Acc: 49.513,72.400,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.871 | Acc: 49.277,72.242,89.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.879 | Acc: 49.064,72.092,88.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.874 | Acc: 49.135,72.211,88.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.873 | Acc: 49.202,72.291,89.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.877 | Acc: 49.165,72.273,88.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.879 | Acc: 49.025,72.143,88.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.880 | Acc: 48.873,72.073,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.881 | Acc: 48.812,72.087,88.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.878 | Acc: 48.979,72.164,88.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.877 | Acc: 49.027,72.180,88.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.885 | Acc: 48.916,72.078,88.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.887 | Acc: 48.809,72.067,88.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.891 | Acc: 48.815,71.989,88.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.891 | Acc: 48.799,71.978,88.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.892 | Acc: 48.847,71.998,88.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.892 | Acc: 48.852,72.014,88.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.496 | Acc: 50.781,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.706 | Acc: 45.945,64.955,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 45.732,64.139,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.772 | Acc: 45.581,63.845,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.834 | Acc: 51.562,68.750,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.878 | Acc: 47.917,71.317,89.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.887 | Acc: 47.790,71.494,88.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.883 | Acc: 47.784,71.183,88.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.890 | Acc: 47.541,71.103,88.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.893 | Acc: 47.904,71.117,88.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.889 | Acc: 47.973,71.229,88.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.881 | Acc: 48.105,71.509,88.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.885 | Acc: 48.263,71.516,88.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.877 | Acc: 48.524,71.767,88.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.876 | Acc: 48.574,71.926,88.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.876 | Acc: 48.671,72.048,88.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.874 | Acc: 48.755,72.121,88.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.876 | Acc: 48.794,72.073,88.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.877 | Acc: 48.774,72.095,88.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.879 | Acc: 48.689,72.085,88.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.882 | Acc: 48.610,72.111,88.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.881 | Acc: 48.621,72.148,88.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.882 | Acc: 48.693,72.126,88.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.882 | Acc: 48.698,72.086,88.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.479 | Acc: 50.000,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.744 | Acc: 46.466,64.286,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.783 | Acc: 46.170,63.681,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.806 | Acc: 45.786,63.294,71.324,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 1.846 | Acc: 50.000,69.531,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.828 | Acc: 51.376,72.954,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.876 | Acc: 49.790,72.771,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.872 | Acc: 49.488,72.515,88.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.865 | Acc: 49.431,72.666,89.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.862 | Acc: 49.157,72.687,89.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.858 | Acc: 49.335,72.656,89.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.861 | Acc: 48.997,72.523,89.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.855 | Acc: 49.102,72.443,89.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.852 | Acc: 49.102,72.479,89.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.852 | Acc: 49.106,72.563,89.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.854 | Acc: 49.000,72.437,89.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.859 | Acc: 48.891,72.352,89.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.864 | Acc: 48.886,72.297,89.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.861 | Acc: 48.960,72.387,89.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.862 | Acc: 48.967,72.392,89.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.862 | Acc: 49.000,72.357,89.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.866 | Acc: 48.935,72.274,89.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.864 | Acc: 48.972,72.280,89.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.866 | Acc: 48.973,72.293,89.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.453 | Acc: 45.312,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.737 | Acc: 46.391,64.769,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.790 | Acc: 45.293,63.910,71.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.808 | Acc: 45.082,63.499,71.209,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.889 | Acc: 49.219,64.844,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.845 | Acc: 48.772,71.540,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.868 | Acc: 49.409,71.341,89.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.858 | Acc: 49.296,71.990,89.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.859 | Acc: 49.026,71.952,89.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.852 | Acc: 49.025,72.006,89.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.856 | Acc: 48.948,71.952,89.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.852 | Acc: 48.964,71.997,89.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.854 | Acc: 48.957,72.025,89.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.853 | Acc: 48.921,71.996,89.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.852 | Acc: 49.141,72.034,89.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.852 | Acc: 48.964,72.130,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.848 | Acc: 48.982,72.235,89.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.852 | Acc: 48.991,72.117,89.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.854 | Acc: 48.893,72.072,89.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.854 | Acc: 48.874,72.072,89.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.855 | Acc: 48.815,72.160,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.858 | Acc: 48.745,72.118,89.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.859 | Acc: 48.753,72.146,89.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.858 | Acc: 48.807,72.133,89.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.460 | Acc: 48.438,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.735 | Acc: 46.205,65.402,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.794 | Acc: 45.827,64.463,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 45.645,63.845,71.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.840 | Acc: 49.219,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.805 | Acc: 50.037,72.805,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.815 | Acc: 49.447,73.114,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.833 | Acc: 48.706,72.695,89.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.833 | Acc: 48.360,72.454,89.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.836 | Acc: 48.600,72.672,89.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.839 | Acc: 48.722,72.417,89.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.843 | Acc: 48.792,72.390,89.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.837 | Acc: 48.753,72.409,89.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.836 | Acc: 48.727,72.320,89.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.841 | Acc: 48.585,72.170,89.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.845 | Acc: 48.674,72.225,89.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.847 | Acc: 48.765,72.254,89.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.848 | Acc: 48.728,72.276,89.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.848 | Acc: 48.766,72.253,89.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.848 | Acc: 48.835,72.282,89.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.849 | Acc: 48.822,72.308,89.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.847 | Acc: 48.900,72.333,89.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.849 | Acc: 48.909,72.345,89.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.852 | Acc: 48.815,72.250,89.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.435 | Acc: 50.000,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.788 | Acc: 46.057,65.290,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.819 | Acc: 45.484,64.558,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.836 | Acc: 45.248,64.139,70.812,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 2.074 | Acc: 43.750,70.312,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.820 | Acc: 48.810,73.326,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.829 | Acc: 48.361,72.599,89.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.818 | Acc: 48.425,72.490,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.810 | Acc: 48.621,72.733,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.812 | Acc: 48.515,72.850,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.815 | Acc: 48.567,72.831,90.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.815 | Acc: 48.404,72.983,90.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.820 | Acc: 48.535,72.821,90.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.826 | Acc: 48.485,72.635,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.828 | Acc: 48.480,72.672,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.828 | Acc: 48.536,72.755,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.832 | Acc: 48.522,72.659,90.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.835 | Acc: 48.455,72.557,90.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.832 | Acc: 48.577,72.481,90.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.833 | Acc: 48.606,72.477,89.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.831 | Acc: 48.722,72.488,89.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.833 | Acc: 48.754,72.441,89.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.833 | Acc: 48.753,72.423,89.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.834 | Acc: 48.790,72.474,89.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.428 | Acc: 53.125,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.784 | Acc: 45.387,64.249,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.823 | Acc: 45.675,63.605,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.844 | Acc: 45.466,63.473,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.746 | Acc: 50.000,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.831 | Acc: 48.661,72.619,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.825 | Acc: 48.914,71.837,90.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.817 | Acc: 48.886,72.080,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.826 | Acc: 48.457,72.242,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.826 | Acc: 48.383,72.300,90.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.830 | Acc: 48.573,72.301,90.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.828 | Acc: 48.654,72.457,90.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.829 | Acc: 48.593,72.409,90.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.829 | Acc: 48.524,72.466,90.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.830 | Acc: 48.577,72.512,90.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.832 | Acc: 48.590,72.476,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.830 | Acc: 48.732,72.617,90.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.827 | Acc: 48.797,72.668,90.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.824 | Acc: 48.857,72.792,90.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.824 | Acc: 48.881,72.747,90.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.825 | Acc: 48.851,72.695,90.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.821 | Acc: 48.937,72.711,90.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.823 | Acc: 48.903,72.667,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.824 | Acc: 48.913,72.654,90.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.528 | Acc: 42.188,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 45.908,65.290,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.802 | Acc: 45.579,64.634,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.823 | Acc: 45.364,64.203,70.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.961 | Acc: 50.781,66.406,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.755 | Acc: 51.600,72.210,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.793 | Acc: 49.752,72.618,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.807 | Acc: 49.590,72.746,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.814 | Acc: 49.441,72.656,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.809 | Acc: 49.683,72.881,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.810 | Acc: 49.561,72.895,90.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.809 | Acc: 49.274,72.850,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.811 | Acc: 49.146,72.865,90.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.811 | Acc: 49.042,72.863,90.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.806 | Acc: 49.122,72.936,90.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.804 | Acc: 49.219,72.957,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.806 | Acc: 49.167,72.919,90.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.808 | Acc: 49.018,72.899,90.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.810 | Acc: 49.066,72.826,90.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.815 | Acc: 49.003,72.778,90.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.813 | Acc: 49.114,72.870,90.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.817 | Acc: 49.088,72.874,90.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.818 | Acc: 49.160,72.836,90.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.819 | Acc: 49.163,72.812,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.499 | Acc: 47.656,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.785 | Acc: 46.615,64.658,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.817 | Acc: 45.713,64.253,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.835 | Acc: 45.377,63.806,70.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.701 | Acc: 47.656,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.747 | Acc: 50.893,73.549,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.749 | Acc: 50.495,73.819,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.763 | Acc: 50.051,73.335,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.757 | Acc: 50.260,73.775,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.767 | Acc: 50.193,73.523,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.783 | Acc: 49.761,73.412,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.789 | Acc: 49.518,73.183,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.790 | Acc: 49.529,73.054,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.799 | Acc: 49.378,72.971,90.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.804 | Acc: 49.157,72.905,90.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.807 | Acc: 49.148,72.815,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.807 | Acc: 49.199,72.792,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.807 | Acc: 49.192,72.779,90.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.808 | Acc: 49.180,72.709,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.808 | Acc: 49.195,72.739,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.810 | Acc: 49.185,72.710,90.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.813 | Acc: 49.111,72.677,90.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.811 | Acc: 49.214,72.721,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.812 | Acc: 49.227,72.722,90.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.571 | Acc: 48.438,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.784 | Acc: 46.503,64.769,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.835 | Acc: 45.808,64.386,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.848 | Acc: 45.287,64.114,70.902,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.857 | Acc: 50.000,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.770 | Acc: 50.298,73.400,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.791 | Acc: 49.295,73.361,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.773 | Acc: 49.654,73.886,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.783 | Acc: 49.431,73.351,91.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.794 | Acc: 49.234,73.283,90.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.791 | Acc: 49.277,73.379,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.795 | Acc: 49.036,73.205,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.789 | Acc: 49.083,73.200,90.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.792 | Acc: 48.977,73.161,90.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.794 | Acc: 48.997,73.146,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.794 | Acc: 49.035,73.130,90.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.793 | Acc: 49.128,73.149,90.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.790 | Acc: 49.210,73.180,90.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.789 | Acc: 49.194,73.207,90.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.791 | Acc: 49.149,73.178,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.794 | Acc: 49.114,73.043,90.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.793 | Acc: 49.239,73.098,90.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.798 | Acc: 49.208,73.037,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.798 | Acc: 49.239,73.034,90.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.496 | Acc: 47.656,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.792 | Acc: 46.243,64.881,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.835 | Acc: 46.113,64.367,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.861 | Acc: 45.850,63.896,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.969 | Acc: 53.906,73.438,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.773 | Acc: 51.042,73.884,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.764 | Acc: 50.343,73.495,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.755 | Acc: 50.487,73.143,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.760 | Acc: 50.029,73.216,90.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.766 | Acc: 49.752,73.198,90.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.758 | Acc: 49.987,73.470,91.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.764 | Acc: 49.701,73.476,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.769 | Acc: 49.636,73.438,90.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.775 | Acc: 49.374,73.239,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.781 | Acc: 49.296,73.146,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.786 | Acc: 49.233,73.020,90.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.787 | Acc: 49.264,73.045,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.790 | Acc: 49.225,72.953,90.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.792 | Acc: 49.219,72.948,90.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.794 | Acc: 49.190,72.822,90.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.794 | Acc: 49.250,72.956,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.795 | Acc: 49.171,72.959,90.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.795 | Acc: 49.137,72.957,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.797 | Acc: 49.083,72.894,90.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.616 | Acc: 47.656,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.809 | Acc: 46.057,64.621,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.854 | Acc: 45.713,63.681,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.873 | Acc: 45.530,63.537,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.686 | Acc: 50.000,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.768 | Acc: 48.735,73.438,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.775 | Acc: 49.181,73.514,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.782 | Acc: 48.873,73.194,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.776 | Acc: 48.929,73.466,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.785 | Acc: 48.878,73.321,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.787 | Acc: 49.090,73.444,90.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.787 | Acc: 49.064,73.305,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.792 | Acc: 49.170,73.200,90.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.792 | Acc: 49.236,73.295,90.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.784 | Acc: 49.312,73.313,90.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.782 | Acc: 49.289,73.278,90.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.786 | Acc: 49.222,73.227,90.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.789 | Acc: 49.165,73.129,90.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.787 | Acc: 49.163,73.154,90.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.787 | Acc: 49.094,73.087,90.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.785 | Acc: 49.246,73.072,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.783 | Acc: 49.297,73.114,90.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.784 | Acc: 49.338,73.176,90.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.785 | Acc: 49.377,73.181,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.528 | Acc: 46.094,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.815 | Acc: 46.057,64.732,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.863 | Acc: 45.579,63.624,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.876 | Acc: 45.261,63.563,70.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.531 | Acc: 53.125,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.738 | Acc: 51.116,74.516,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.779 | Acc: 49.638,73.552,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.776 | Acc: 49.590,73.899,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.788 | Acc: 49.113,73.563,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.776 | Acc: 49.660,73.523,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.779 | Acc: 49.529,73.379,91.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.772 | Acc: 49.823,73.543,91.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.774 | Acc: 49.854,73.559,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.776 | Acc: 49.784,73.532,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.777 | Acc: 49.705,73.430,91.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.778 | Acc: 49.728,73.395,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.776 | Acc: 49.686,73.425,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.772 | Acc: 49.749,73.503,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.773 | Acc: 49.714,73.432,91.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.778 | Acc: 49.670,73.339,90.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.780 | Acc: 49.482,73.306,90.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.781 | Acc: 49.496,73.302,90.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.785 | Acc: 49.481,73.135,90.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.783 | Acc: 49.500,73.161,90.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.577 | Acc: 42.188,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.833 | Acc: 45.387,65.104,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.868 | Acc: 45.236,64.101,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.897 | Acc: 44.762,63.601,70.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 1.831 | Acc: 48.438,71.094,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.731 | Acc: 50.521,72.954,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.753 | Acc: 49.848,73.323,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.737 | Acc: 50.397,73.911,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.751 | Acc: 49.990,73.650,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.750 | Acc: 50.093,73.554,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.743 | Acc: 50.387,73.670,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.750 | Acc: 50.288,73.720,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.759 | Acc: 49.981,73.704,91.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.759 | Acc: 49.832,73.671,91.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.762 | Acc: 49.841,73.535,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.763 | Acc: 49.745,73.508,91.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.766 | Acc: 49.708,73.473,91.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.768 | Acc: 49.560,73.366,91.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.766 | Acc: 49.644,73.396,91.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.769 | Acc: 49.538,73.271,91.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.768 | Acc: 49.650,73.304,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.768 | Acc: 49.679,73.277,91.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.770 | Acc: 49.591,73.212,91.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.773 | Acc: 49.571,73.183,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.589 | Acc: 46.094,66.406,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.842 | Acc: 46.131,64.211,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.875 | Acc: 45.941,63.796,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.902 | Acc: 45.594,63.473,70.838,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.707 | Acc: 52.344,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.728 | Acc: 50.335,74.144,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.743 | Acc: 50.362,74.200,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.758 | Acc: 50.269,73.706,91.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.757 | Acc: 50.251,73.553,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.754 | Acc: 49.876,73.670,91.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.757 | Acc: 49.697,73.457,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.762 | Acc: 49.651,73.210,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.760 | Acc: 49.699,73.209,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.764 | Acc: 49.620,73.239,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.763 | Acc: 49.681,73.325,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.763 | Acc: 49.678,73.342,91.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.762 | Acc: 49.676,73.327,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.765 | Acc: 49.656,73.327,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.769 | Acc: 49.544,73.276,91.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.771 | Acc: 49.517,73.199,91.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.771 | Acc: 49.533,73.199,91.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.773 | Acc: 49.617,73.151,91.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.772 | Acc: 49.584,73.165,91.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.770 | Acc: 49.612,73.196,91.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.572 | Acc: 48.438,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 46.131,64.807,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.840 | Acc: 46.056,64.539,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.855 | Acc: 45.722,64.421,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.462 | Acc: 55.469,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.761 | Acc: 50.484,73.214,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.732 | Acc: 50.667,74.276,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.744 | Acc: 50.589,74.014,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.743 | Acc: 50.598,73.862,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.750 | Acc: 49.961,73.724,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.745 | Acc: 50.129,73.573,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.741 | Acc: 50.100,73.698,91.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.748 | Acc: 49.777,73.486,91.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.754 | Acc: 49.797,73.312,91.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.756 | Acc: 49.860,73.212,91.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.758 | Acc: 49.791,73.247,91.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.754 | Acc: 49.711,73.318,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.756 | Acc: 49.740,73.288,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.761 | Acc: 49.666,73.235,91.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.762 | Acc: 49.608,73.204,91.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.760 | Acc: 49.657,73.235,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.763 | Acc: 49.572,73.213,91.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.764 | Acc: 49.500,73.165,91.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.767 | Acc: 49.469,73.165,91.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.544 | Acc: 47.656,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.867 | Acc: 45.908,65.253,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.888 | Acc: 45.770,64.291,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.902 | Acc: 45.312,64.229,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.895 | Acc: 47.656,66.406,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.747 | Acc: 49.926,73.624,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.738 | Acc: 49.486,73.399,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.735 | Acc: 49.193,73.719,91.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.743 | Acc: 48.929,73.495,91.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.746 | Acc: 49.010,73.360,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.743 | Acc: 49.206,73.412,91.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.747 | Acc: 49.091,73.360,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.753 | Acc: 49.078,73.379,91.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.754 | Acc: 49.050,73.213,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.756 | Acc: 48.982,73.270,91.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.753 | Acc: 49.212,73.367,91.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.756 | Acc: 49.164,73.337,91.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.760 | Acc: 49.129,73.234,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.758 | Acc: 49.160,73.237,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.753 | Acc: 49.221,73.305,91.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.752 | Acc: 49.338,73.408,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.753 | Acc: 49.324,73.410,91.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.754 | Acc: 49.414,73.492,91.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.755 | Acc: 49.385,73.499,91.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.536 | Acc: 45.312,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.868 | Acc: 45.908,64.360,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.906 | Acc: 45.751,63.700,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.929 | Acc: 45.850,63.665,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.809 | Acc: 50.000,74.219,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.758 | Acc: 49.070,74.814,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.777 | Acc: 48.476,73.457,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.757 | Acc: 49.270,73.886,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.749 | Acc: 49.151,74.026,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.756 | Acc: 49.335,73.894,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.751 | Acc: 49.509,73.857,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.751 | Acc: 49.463,73.964,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.751 | Acc: 49.500,73.879,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.754 | Acc: 49.465,73.904,91.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.749 | Acc: 49.382,73.877,91.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.743 | Acc: 49.601,73.925,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.744 | Acc: 49.711,73.953,91.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.743 | Acc: 49.773,73.851,91.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.745 | Acc: 49.766,73.830,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.744 | Acc: 49.818,73.866,91.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.746 | Acc: 49.805,73.817,91.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.748 | Acc: 49.748,73.795,91.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.756 | Acc: 49.548,73.615,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.755 | Acc: 49.569,73.556,91.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.518 | Acc: 47.656,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.838 | Acc: 45.871,66.146,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.870 | Acc: 46.132,65.053,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.881 | Acc: 45.812,64.741,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.704 | Acc: 51.562,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.707 | Acc: 50.260,74.554,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.740 | Acc: 49.543,73.876,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.731 | Acc: 49.949,73.694,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.741 | Acc: 49.740,73.601,91.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.740 | Acc: 49.683,73.654,91.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.743 | Acc: 49.658,73.586,91.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.744 | Acc: 49.778,73.532,91.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.745 | Acc: 49.762,73.622,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.741 | Acc: 49.849,73.653,91.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.743 | Acc: 49.852,73.647,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.747 | Acc: 49.707,73.597,91.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.742 | Acc: 49.776,73.613,91.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.742 | Acc: 49.859,73.605,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.741 | Acc: 49.889,73.585,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.745 | Acc: 49.811,73.598,91.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.745 | Acc: 49.805,73.547,91.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.744 | Acc: 49.778,73.536,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.744 | Acc: 49.810,73.450,91.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.744 | Acc: 49.776,73.435,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.565 | Acc: 38.281,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.904 | Acc: 44.680,63.653,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.954 | Acc: 44.646,63.319,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.965 | Acc: 44.211,63.038,69.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.680 | Acc: 49.219,72.656,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.738 | Acc: 49.591,74.107,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.725 | Acc: 50.095,74.333,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 50.269,74.385,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.715 | Acc: 50.357,74.209,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.710 | Acc: 50.812,74.188,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.711 | Acc: 50.458,74.077,92.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.723 | Acc: 50.271,73.753,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.723 | Acc: 50.214,73.763,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.730 | Acc: 50.052,73.645,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.731 | Acc: 49.996,73.760,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.734 | Acc: 49.926,73.621,91.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.734 | Acc: 49.922,73.587,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.734 | Acc: 49.991,73.626,91.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.733 | Acc: 49.930,73.618,91.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.737 | Acc: 49.800,73.502,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.737 | Acc: 49.815,73.486,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.740 | Acc: 49.778,73.424,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.741 | Acc: 49.684,73.360,91.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.744 | Acc: 49.627,73.292,91.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.544 | Acc: 49.219,67.188,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.859 | Acc: 45.908,64.472,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.904 | Acc: 45.751,63.758,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.919 | Acc: 45.543,63.448,70.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.729 | Acc: 51.562,70.312,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.745 | Acc: 47.917,72.917,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.745 | Acc: 48.742,73.723,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.727 | Acc: 49.334,73.963,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 49.431,73.756,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.730 | Acc: 49.466,73.615,92.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.727 | Acc: 49.509,73.651,92.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.736 | Acc: 49.451,73.476,91.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.741 | Acc: 49.345,73.316,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.739 | Acc: 49.353,73.425,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.736 | Acc: 49.355,73.605,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.735 | Acc: 49.456,73.614,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.732 | Acc: 49.523,73.671,91.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.734 | Acc: 49.608,73.647,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.735 | Acc: 49.691,73.649,91.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.737 | Acc: 49.618,73.645,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.736 | Acc: 49.674,73.647,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.736 | Acc: 49.597,73.618,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.738 | Acc: 49.593,73.632,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.738 | Acc: 49.608,73.618,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.572 | Acc: 44.531,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.864 | Acc: 46.726,65.885,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.920 | Acc: 45.636,64.596,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.934 | Acc: 45.351,64.216,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.615 | Acc: 50.000,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.708 | Acc: 50.186,74.405,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.732 | Acc: 49.867,73.895,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.712 | Acc: 49.987,74.360,91.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.727 | Acc: 49.392,73.978,92.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.735 | Acc: 49.226,73.801,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.728 | Acc: 49.509,74.064,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.723 | Acc: 49.607,74.136,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.718 | Acc: 49.694,74.039,92.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.717 | Acc: 49.745,74.068,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.719 | Acc: 49.674,73.935,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.723 | Acc: 49.668,73.812,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.725 | Acc: 49.763,73.849,92.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.723 | Acc: 49.776,73.779,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.726 | Acc: 49.786,73.749,91.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.729 | Acc: 49.686,73.853,91.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.730 | Acc: 49.730,73.803,91.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.734 | Acc: 49.711,73.696,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.735 | Acc: 49.712,73.680,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.736 | Acc: 49.651,73.653,91.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.474 | Acc: 50.000,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 46.912,64.546,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.914 | Acc: 46.208,64.062,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 45.889,63.870,69.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.948 | Acc: 45.312,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.692 | Acc: 49.740,73.958,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.715 | Acc: 50.114,73.876,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.733 | Acc: 49.757,73.002,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.727 | Acc: 50.039,73.447,92.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.730 | Acc: 49.876,73.314,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.732 | Acc: 49.774,73.347,92.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.724 | Acc: 49.817,73.637,92.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.724 | Acc: 49.845,73.632,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.726 | Acc: 49.737,73.623,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.724 | Acc: 49.833,73.624,92.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.725 | Acc: 49.936,73.671,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.722 | Acc: 49.912,73.661,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.730 | Acc: 49.665,73.632,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.730 | Acc: 49.652,73.613,92.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.732 | Acc: 49.626,73.593,91.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.728 | Acc: 49.696,73.605,91.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.731 | Acc: 49.684,73.564,91.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.732 | Acc: 49.632,73.576,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.729 | Acc: 49.740,73.649,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.740 | Acc: 45.312,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.928 | Acc: 44.792,64.509,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.964 | Acc: 44.912,64.005,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.980 | Acc: 44.506,63.640,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.776 | Acc: 43.750,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.712 | Acc: 49.293,73.810,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.713 | Acc: 49.466,73.495,92.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.720 | Acc: 49.142,73.706,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 49.016,73.601,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.718 | Acc: 49.451,73.894,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.725 | Acc: 49.341,73.644,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.727 | Acc: 49.396,73.726,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.724 | Acc: 49.481,73.869,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.718 | Acc: 49.633,73.990,92.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.719 | Acc: 49.747,73.935,92.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.718 | Acc: 49.639,73.950,92.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.720 | Acc: 49.562,73.882,92.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.720 | Acc: 49.563,73.940,92.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.720 | Acc: 49.605,73.944,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.718 | Acc: 49.631,73.954,92.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.717 | Acc: 49.691,73.963,92.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.718 | Acc: 49.746,73.909,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.719 | Acc: 49.794,73.927,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.722 | Acc: 49.733,73.839,91.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.617 | Acc: 45.312,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 44.531,64.769,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.973 | Acc: 44.493,63.815,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 44.134,63.461,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.767 | Acc: 49.219,75.000,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.719 | Acc: 49.479,74.256,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.683 | Acc: 50.800,74.848,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.685 | Acc: 50.371,74.436,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.687 | Acc: 50.280,74.518,92.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.699 | Acc: 50.193,74.110,92.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.695 | Acc: 50.187,73.980,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.700 | Acc: 50.100,74.058,92.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.710 | Acc: 49.961,73.898,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.712 | Acc: 49.840,73.748,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.716 | Acc: 49.689,73.710,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.713 | Acc: 49.756,73.703,92.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.714 | Acc: 49.747,73.668,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.717 | Acc: 49.707,73.608,92.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.719 | Acc: 49.589,73.582,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.718 | Acc: 49.686,73.723,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.715 | Acc: 49.740,73.829,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.718 | Acc: 49.654,73.783,92.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.720 | Acc: 49.636,73.732,91.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.724 | Acc: 49.561,73.712,91.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.705 | Acc: 46.094,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.886 | Acc: 46.577,65.588,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.938 | Acc: 45.884,64.901,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.944 | Acc: 45.697,64.191,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 1.721 | Acc: 45.312,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.711 | Acc: 48.996,74.479,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.699 | Acc: 49.962,74.428,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.690 | Acc: 49.731,74.142,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.705 | Acc: 49.412,74.007,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.707 | Acc: 49.381,74.110,92.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.699 | Acc: 49.632,74.393,92.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.701 | Acc: 49.463,74.318,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.698 | Acc: 49.554,74.423,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.698 | Acc: 49.586,74.486,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.702 | Acc: 49.518,74.374,92.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.704 | Acc: 49.512,74.364,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.708 | Acc: 49.569,74.300,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.710 | Acc: 49.629,74.177,92.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.714 | Acc: 49.522,74.074,92.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.713 | Acc: 49.590,74.073,92.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.711 | Acc: 49.710,74.065,92.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.712 | Acc: 49.734,74.081,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.712 | Acc: 49.686,74.082,92.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.712 | Acc: 49.766,74.067,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.507 | Acc: 49.219,67.188,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.851 | Acc: 47.061,65.588,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.921 | Acc: 46.265,64.253,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.936 | Acc: 45.825,63.845,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.644 | Acc: 50.000,75.781,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.709 | Acc: 48.661,73.326,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.713 | Acc: 49.486,73.342,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.721 | Acc: 49.424,73.514,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.721 | Acc: 49.421,73.515,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.720 | Acc: 49.497,73.438,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.708 | Acc: 49.548,73.722,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.710 | Acc: 49.474,73.903,92.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.706 | Acc: 49.602,74.034,92.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.712 | Acc: 49.530,73.938,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.713 | Acc: 49.736,73.912,92.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.712 | Acc: 49.781,73.901,92.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.712 | Acc: 49.793,73.852,92.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.713 | Acc: 49.808,73.800,92.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.715 | Acc: 49.811,73.777,92.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.716 | Acc: 49.707,73.822,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.716 | Acc: 49.718,73.832,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.718 | Acc: 49.709,73.804,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.717 | Acc: 49.760,73.877,92.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.717 | Acc: 49.717,73.907,92.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.581 | Acc: 47.656,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.986 | Acc: 43.118,64.249,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.994 | Acc: 43.845,63.796,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 43.532,63.051,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.759 | Acc: 48.438,68.750,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.643 | Acc: 50.818,74.330,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.684 | Acc: 49.390,73.914,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.690 | Acc: 49.052,73.873,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.701 | Acc: 49.209,73.418,92.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.697 | Acc: 49.404,73.778,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.698 | Acc: 49.393,73.709,92.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.698 | Acc: 49.391,73.692,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.699 | Acc: 49.495,73.821,92.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.708 | Acc: 49.301,73.766,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.711 | Acc: 49.269,73.725,92.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.709 | Acc: 49.420,73.720,92.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.709 | Acc: 49.553,73.710,92.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.705 | Acc: 49.746,73.752,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.706 | Acc: 49.828,73.774,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.708 | Acc: 49.748,73.803,92.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.708 | Acc: 49.698,73.803,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.710 | Acc: 49.645,73.738,92.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.708 | Acc: 49.745,73.775,92.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.711 | Acc: 49.738,73.772,92.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.553 | Acc: 50.781,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.872 | Acc: 46.652,64.993,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.911 | Acc: 46.475,64.653,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.933 | Acc: 45.978,64.319,70.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 2.013 | Acc: 43.750,65.625,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.696 | Acc: 50.000,74.516,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 50.648,74.066,93.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.688 | Acc: 49.962,74.206,92.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.690 | Acc: 49.923,74.296,92.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.688 | Acc: 49.954,74.366,92.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.686 | Acc: 49.890,74.445,92.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.689 | Acc: 49.817,74.368,92.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.692 | Acc: 49.699,74.306,92.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.695 | Acc: 49.689,74.266,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.696 | Acc: 49.782,74.227,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.695 | Acc: 49.714,74.321,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.699 | Acc: 49.682,74.225,92.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.695 | Acc: 49.835,74.312,92.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.694 | Acc: 49.869,74.260,92.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.695 | Acc: 49.862,74.255,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.697 | Acc: 49.886,74.168,92.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.701 | Acc: 49.814,74.095,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.704 | Acc: 49.697,74.015,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.704 | Acc: 49.725,74.016,92.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.599 | Acc: 46.094,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.895 | Acc: 46.131,65.253,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.934 | Acc: 45.979,64.367,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.949 | Acc: 45.799,63.934,69.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.591 | Acc: 53.125,76.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.728 | Acc: 49.293,72.917,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.682 | Acc: 50.362,73.876,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.686 | Acc: 50.218,73.988,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.689 | Acc: 50.058,73.920,92.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.689 | Acc: 50.000,73.855,92.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.689 | Acc: 50.058,73.838,92.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.684 | Acc: 50.183,73.964,92.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.692 | Acc: 50.092,74.059,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.701 | Acc: 49.832,73.912,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.699 | Acc: 49.914,74.009,92.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.701 | Acc: 49.834,73.961,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 49.880,73.966,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.701 | Acc: 50.000,73.973,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.699 | Acc: 50.086,73.994,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.700 | Acc: 50.171,74.009,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.703 | Acc: 50.088,74.002,92.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.705 | Acc: 49.975,73.992,92.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.707 | Acc: 49.857,73.918,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.706 | Acc: 49.885,73.923,92.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.717 | Acc: 42.969,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 45.610,64.249,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.984 | Acc: 44.264,63.777,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 43.916,63.384,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.657 | Acc: 47.656,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.670 | Acc: 50.186,74.293,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.669 | Acc: 50.724,74.428,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.671 | Acc: 50.512,74.232,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.671 | Acc: 50.511,74.306,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.672 | Acc: 50.750,74.319,92.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.673 | Acc: 50.794,74.361,92.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.675 | Acc: 50.565,74.341,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.677 | Acc: 50.330,74.248,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 50.181,74.025,92.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.687 | Acc: 50.078,74.024,92.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.688 | Acc: 50.021,74.024,92.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.688 | Acc: 49.958,74.047,92.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.692 | Acc: 49.817,73.988,92.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.693 | Acc: 49.753,73.974,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.692 | Acc: 49.816,73.993,92.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.693 | Acc: 49.754,73.915,92.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.694 | Acc: 49.803,73.900,92.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.695 | Acc: 49.771,73.855,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.697 | Acc: 49.807,73.833,92.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.598 | Acc: 47.656,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 46.280,64.732,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.986 | Acc: 45.579,64.196,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.992 | Acc: 45.274,63.640,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.684 | Acc: 50.781,75.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.687 | Acc: 50.967,73.884,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.675 | Acc: 50.667,74.371,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.676 | Acc: 50.589,74.232,93.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.679 | Acc: 50.714,74.161,92.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.677 | Acc: 50.951,74.265,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.681 | Acc: 50.710,74.096,92.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.684 | Acc: 50.687,74.025,92.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.686 | Acc: 50.558,73.991,92.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 50.401,73.908,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.695 | Acc: 50.175,73.919,92.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.695 | Acc: 50.159,73.833,92.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.697 | Acc: 50.227,73.804,92.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.699 | Acc: 50.102,73.812,92.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.701 | Acc: 50.031,73.816,92.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.704 | Acc: 49.956,73.798,92.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.703 | Acc: 49.951,73.815,92.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.703 | Acc: 49.977,73.836,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.703 | Acc: 49.987,73.838,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.702 | Acc: 50.012,73.817,92.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.615 | Acc: 49.219,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.929 | Acc: 47.433,64.360,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.978 | Acc: 47.066,64.062,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 46.452,63.537,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.659 | Acc: 49.219,73.438,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.679 | Acc: 50.781,74.591,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.700 | Acc: 50.019,73.685,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.681 | Acc: 50.487,74.424,92.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.689 | Acc: 50.405,74.171,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.696 | Acc: 49.930,73.832,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 50.110,74.251,92.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.683 | Acc: 49.934,74.213,92.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.678 | Acc: 49.966,74.296,92.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.674 | Acc: 50.125,74.249,92.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.678 | Acc: 49.988,74.242,92.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.683 | Acc: 49.972,74.099,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.684 | Acc: 49.981,74.053,92.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.684 | Acc: 49.979,74.069,92.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.684 | Acc: 50.017,74.077,92.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.685 | Acc: 49.977,74.097,92.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.689 | Acc: 49.908,74.051,92.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.689 | Acc: 49.947,74.058,92.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.693 | Acc: 49.907,73.931,92.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.695 | Acc: 49.922,73.899,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.563 | Acc: 47.656,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.905 | Acc: 46.912,64.732,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.944 | Acc: 46.322,64.082,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.962 | Acc: 45.966,63.781,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.483 | Acc: 51.562,76.562,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.676 | Acc: 50.409,74.144,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 49.829,74.371,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.679 | Acc: 50.320,74.257,93.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 50.154,74.412,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.681 | Acc: 50.093,74.528,92.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.686 | Acc: 49.955,74.245,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.683 | Acc: 50.022,74.241,92.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.688 | Acc: 50.000,74.180,92.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.686 | Acc: 50.009,74.171,92.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 50.035,74.223,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.685 | Acc: 50.064,74.261,92.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.685 | Acc: 50.062,74.280,92.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.687 | Acc: 49.988,74.258,92.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.688 | Acc: 49.958,74.219,92.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.687 | Acc: 50.044,74.271,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.688 | Acc: 50.061,74.263,92.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.692 | Acc: 49.995,74.157,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.692 | Acc: 49.970,74.167,92.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.692 | Acc: 49.920,74.149,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.632 | Acc: 48.438,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.928 | Acc: 47.024,64.955,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.965 | Acc: 46.665,64.367,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.986 | Acc: 46.350,63.832,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.925 | Acc: 40.625,64.844,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.679 | Acc: 49.740,73.847,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.661 | Acc: 50.800,74.695,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.663 | Acc: 50.564,74.321,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.668 | Acc: 50.424,74.286,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.673 | Acc: 50.603,74.412,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.675 | Acc: 50.420,74.277,92.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.676 | Acc: 50.598,74.291,92.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.680 | Acc: 50.641,74.020,92.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.686 | Acc: 50.406,73.977,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.683 | Acc: 50.428,74.021,92.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.682 | Acc: 50.449,74.095,92.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.676 | Acc: 50.541,74.355,92.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.680 | Acc: 50.467,74.330,92.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.679 | Acc: 50.381,74.441,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.679 | Acc: 50.343,74.398,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 50.144,74.360,92.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.681 | Acc: 50.165,74.359,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.684 | Acc: 50.110,74.353,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.687 | Acc: 50.074,74.274,92.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.644 | Acc: 48.438,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.903 | Acc: 46.838,65.997,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.932 | Acc: 46.208,65.072,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.953 | Acc: 45.902,64.536,69.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.487 | Acc: 52.344,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.661 | Acc: 50.112,75.186,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.648 | Acc: 50.095,75.343,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.667 | Acc: 49.680,74.949,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.671 | Acc: 50.231,74.749,93.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.678 | Acc: 50.131,74.683,93.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.678 | Acc: 50.103,74.561,93.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.681 | Acc: 49.983,74.490,93.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.674 | Acc: 50.146,74.558,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.676 | Acc: 50.104,74.508,92.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.681 | Acc: 50.047,74.479,92.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.687 | Acc: 49.890,74.364,92.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.689 | Acc: 49.880,74.245,92.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.690 | Acc: 49.970,74.222,92.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.691 | Acc: 49.917,74.255,92.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.690 | Acc: 49.914,74.299,92.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 49.854,74.263,92.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.688 | Acc: 49.911,74.258,92.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.688 | Acc: 49.970,74.301,92.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.690 | Acc: 49.869,74.297,92.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.532 | Acc: 49.219,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.928 | Acc: 47.024,65.030,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.964 | Acc: 46.265,64.367,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.984 | Acc: 46.068,63.883,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.389 | Acc: 55.469,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.653 | Acc: 48.996,75.000,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.678 | Acc: 49.390,74.562,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.670 | Acc: 49.577,74.488,93.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.668 | Acc: 49.836,74.450,93.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.671 | Acc: 49.675,74.203,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.673 | Acc: 49.638,74.199,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 49.568,74.102,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.670 | Acc: 49.622,74.102,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.679 | Acc: 49.551,74.025,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.679 | Acc: 49.569,74.009,93.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.684 | Acc: 49.463,73.883,93.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.686 | Acc: 49.520,73.878,92.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.685 | Acc: 49.593,73.970,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.687 | Acc: 49.652,73.866,92.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.688 | Acc: 49.644,73.923,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.685 | Acc: 49.727,74.087,92.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 49.757,74.134,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.684 | Acc: 49.812,74.186,92.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.684 | Acc: 49.854,74.237,92.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.589 | Acc: 45.312,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 46.280,65.253,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 45.922,64.177,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.998 | Acc: 45.517,63.781,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.484 | Acc: 53.125,75.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.667 | Acc: 49.442,73.661,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.659 | Acc: 50.095,73.952,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.644 | Acc: 50.154,74.360,93.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.650 | Acc: 50.646,74.084,93.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.649 | Acc: 50.789,74.103,93.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.651 | Acc: 50.878,74.238,93.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.664 | Acc: 50.499,73.986,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.670 | Acc: 50.432,73.942,93.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.673 | Acc: 50.363,73.912,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.667 | Acc: 50.474,74.118,93.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 50.650,74.314,93.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.663 | Acc: 50.616,74.303,93.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.671 | Acc: 50.392,74.153,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.674 | Acc: 50.425,74.074,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.673 | Acc: 50.340,74.133,93.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.675 | Acc: 50.239,74.187,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.674 | Acc: 50.195,74.221,92.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.673 | Acc: 50.225,74.232,92.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.677 | Acc: 50.205,74.126,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.564 | Acc: 49.219,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.004 | Acc: 45.982,64.249,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.008 | Acc: 46.113,63.739,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.037 | Acc: 45.710,63.627,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.689 | Acc: 50.000,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 51.228,74.368,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.632 | Acc: 51.105,74.867,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.642 | Acc: 50.781,75.115,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.637 | Acc: 50.617,75.569,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.648 | Acc: 50.603,75.271,93.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.648 | Acc: 50.768,75.291,93.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.658 | Acc: 50.698,74.972,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.663 | Acc: 50.485,74.786,93.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.665 | Acc: 50.419,74.776,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.669 | Acc: 50.319,74.674,93.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.669 | Acc: 50.216,74.562,93.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.669 | Acc: 50.243,74.540,93.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.672 | Acc: 50.132,74.440,92.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.674 | Acc: 50.125,74.488,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.675 | Acc: 50.080,74.455,92.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.678 | Acc: 50.015,74.287,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.681 | Acc: 49.975,74.281,92.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.681 | Acc: 49.970,74.214,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 49.984,74.266,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.658 | Acc: 44.531,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 45.685,64.174,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.017 | Acc: 44.970,64.024,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.030 | Acc: 44.454,63.422,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.749 | Acc: 46.875,77.344,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.653 | Acc: 49.033,75.112,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.661 | Acc: 50.229,75.019,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.660 | Acc: 49.962,74.667,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.653 | Acc: 50.260,74.836,93.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.651 | Acc: 50.317,74.683,93.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.653 | Acc: 50.342,74.716,93.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.660 | Acc: 50.139,74.701,93.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.657 | Acc: 50.136,74.699,93.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.662 | Acc: 50.086,74.538,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.663 | Acc: 50.023,74.537,92.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.669 | Acc: 49.947,74.385,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.675 | Acc: 49.922,74.235,92.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.676 | Acc: 49.916,74.234,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.676 | Acc: 49.886,74.244,92.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.675 | Acc: 49.894,74.185,92.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.676 | Acc: 49.796,74.168,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.677 | Acc: 49.808,74.205,92.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.678 | Acc: 49.855,74.204,92.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.677 | Acc: 49.863,74.225,92.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.724 | Acc: 50.000,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 46.391,65.067,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.979 | Acc: 45.903,64.101,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.996 | Acc: 45.453,63.614,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.630 | Acc: 46.875,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.628 | Acc: 51.079,75.967,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.632 | Acc: 50.953,75.305,93.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 50.026,74.821,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.652 | Acc: 50.125,74.691,93.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.652 | Acc: 50.456,74.799,93.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.647 | Acc: 50.600,74.968,93.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.647 | Acc: 50.720,74.911,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.651 | Acc: 50.534,74.801,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.654 | Acc: 50.470,74.732,93.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.653 | Acc: 50.540,74.693,93.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.655 | Acc: 50.488,74.657,93.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.657 | Acc: 50.493,74.598,93.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.657 | Acc: 50.539,74.638,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.659 | Acc: 50.539,74.594,93.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.661 | Acc: 50.498,74.587,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 50.433,74.516,93.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.665 | Acc: 50.399,74.432,93.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.668 | Acc: 50.357,74.459,93.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.670 | Acc: 50.299,74.344,93.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.646 | Acc: 47.656,64.844,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.954 | Acc: 45.722,64.732,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 45.236,64.234,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 45.005,63.794,69.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.597 | Acc: 51.562,69.531,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.646 | Acc: 50.037,75.298,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.665 | Acc: 48.876,74.466,93.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.651 | Acc: 49.347,74.629,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.643 | Acc: 49.904,74.672,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.635 | Acc: 50.186,74.706,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.639 | Acc: 50.291,74.709,93.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.643 | Acc: 50.355,74.601,93.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.653 | Acc: 50.286,74.510,93.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.658 | Acc: 50.311,74.404,93.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.660 | Acc: 50.218,74.378,93.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 50.219,74.367,93.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.662 | Acc: 50.172,74.394,93.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.662 | Acc: 50.227,74.374,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.665 | Acc: 50.234,74.277,93.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.665 | Acc: 50.174,74.325,93.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.665 | Acc: 50.246,74.304,93.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.666 | Acc: 50.245,74.283,93.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.669 | Acc: 50.182,74.232,93.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.669 | Acc: 50.211,74.254,93.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.603 | Acc: 48.438,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.937 | Acc: 45.647,64.472,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.976 | Acc: 45.503,63.586,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.004 | Acc: 45.287,63.627,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.846 | Acc: 49.219,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.609 | Acc: 52.009,75.521,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.625 | Acc: 51.848,75.343,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.624 | Acc: 51.703,75.282,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.620 | Acc: 51.591,75.154,93.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.627 | Acc: 51.292,75.031,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.640 | Acc: 50.891,74.742,93.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.647 | Acc: 50.659,74.745,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.646 | Acc: 50.713,74.791,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.654 | Acc: 50.673,74.629,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.653 | Acc: 50.742,74.708,93.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.658 | Acc: 50.590,74.576,93.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.659 | Acc: 50.629,74.582,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.659 | Acc: 50.506,74.620,93.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.661 | Acc: 50.428,74.575,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.662 | Acc: 50.439,74.593,93.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.665 | Acc: 50.333,74.469,93.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.668 | Acc: 50.284,74.381,93.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.668 | Acc: 50.288,74.439,93.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.670 | Acc: 50.193,74.399,93.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.538 | Acc: 49.219,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.934 | Acc: 46.131,65.476,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.964 | Acc: 45.808,64.844,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.994 | Acc: 45.300,64.319,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.655 | Acc: 53.125,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.608 | Acc: 51.004,75.446,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.649 | Acc: 50.572,74.962,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.645 | Acc: 50.564,74.872,93.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.648 | Acc: 50.367,74.740,93.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.653 | Acc: 50.410,74.497,93.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.652 | Acc: 50.284,74.535,93.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.650 | Acc: 50.177,74.551,93.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.650 | Acc: 50.112,74.481,93.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.657 | Acc: 50.009,74.413,93.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.651 | Acc: 50.167,74.549,93.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.658 | Acc: 50.113,74.519,93.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.657 | Acc: 50.026,74.455,93.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.661 | Acc: 50.021,74.416,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.662 | Acc: 50.011,74.472,93.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.664 | Acc: 50.016,74.489,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.666 | Acc: 50.044,74.428,93.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.669 | Acc: 49.959,74.381,93.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.668 | Acc: 49.991,74.405,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.669 | Acc: 50.029,74.448,92.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.891 | Acc: 46.094,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.998 | Acc: 45.982,64.397,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.026 | Acc: 45.789,63.948,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.051 | Acc: 45.505,63.601,69.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.474 | Acc: 61.719,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.719 | Acc: 50.112,73.810,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.687 | Acc: 50.514,74.238,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 50.115,73.950,93.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.680 | Acc: 49.788,73.958,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.682 | Acc: 50.023,74.064,93.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 50.478,74.257,93.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.664 | Acc: 50.504,74.296,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.664 | Acc: 50.378,74.442,93.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.667 | Acc: 50.224,74.301,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.668 | Acc: 50.272,74.227,93.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.671 | Acc: 50.117,74.145,93.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.675 | Acc: 49.990,74.073,93.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.677 | Acc: 49.928,74.069,93.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 49.828,74.055,93.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.676 | Acc: 49.852,74.120,93.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.675 | Acc: 49.900,74.141,93.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.673 | Acc: 49.897,74.161,92.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.672 | Acc: 49.998,74.193,92.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.673 | Acc: 49.977,74.221,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.597 | Acc: 45.312,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.994 | Acc: 45.871,64.025,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.026 | Acc: 45.617,63.796,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.045 | Acc: 45.312,63.281,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.500 | Acc: 50.781,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.631 | Acc: 50.484,74.777,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.634 | Acc: 49.962,75.019,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.642 | Acc: 50.064,74.821,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.640 | Acc: 50.502,74.942,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.651 | Acc: 49.992,74.644,93.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.649 | Acc: 49.968,74.819,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.654 | Acc: 50.111,74.717,93.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.653 | Acc: 50.311,74.685,93.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.654 | Acc: 50.281,74.728,93.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.653 | Acc: 50.241,74.790,93.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.657 | Acc: 50.258,74.731,93.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.658 | Acc: 50.240,74.708,93.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.655 | Acc: 50.248,74.793,93.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.657 | Acc: 50.131,74.786,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.661 | Acc: 50.145,74.665,93.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.664 | Acc: 50.148,74.645,93.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.666 | Acc: 50.082,74.620,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.669 | Acc: 50.035,74.567,92.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.669 | Acc: 50.053,74.504,92.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.540 | Acc: 45.312,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.028 | Acc: 47.135,63.504,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.040 | Acc: 46.418,63.510,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.064 | Acc: 45.735,63.153,68.609,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.842 | Acc: 42.188,66.406,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 50.595,75.484,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.637 | Acc: 49.619,75.534,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.647 | Acc: 49.987,75.435,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.641 | Acc: 50.473,75.424,93.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.648 | Acc: 50.302,74.969,93.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.653 | Acc: 50.284,74.735,93.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.646 | Acc: 50.338,74.911,93.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.652 | Acc: 50.209,74.830,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.654 | Acc: 50.190,74.806,93.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.656 | Acc: 50.175,74.712,93.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.658 | Acc: 50.134,74.544,93.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.657 | Acc: 50.259,74.617,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.657 | Acc: 50.138,74.596,93.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.658 | Acc: 50.181,74.600,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.657 | Acc: 50.275,74.593,93.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 50.324,74.545,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.661 | Acc: 50.318,74.494,93.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.663 | Acc: 50.346,74.478,93.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.661 | Acc: 50.375,74.512,93.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.643 | Acc: 49.219,63.281,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.993 | Acc: 46.094,64.174,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.022 | Acc: 45.827,63.796,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.030 | Acc: 45.825,63.704,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.702 | Acc: 49.219,71.875,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.644 | Acc: 48.586,74.442,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.655 | Acc: 49.486,74.447,93.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.653 | Acc: 49.757,74.731,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.652 | Acc: 50.193,74.691,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.649 | Acc: 50.278,74.698,93.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.647 | Acc: 50.291,74.709,93.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.650 | Acc: 50.111,74.568,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.658 | Acc: 49.888,74.335,93.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.654 | Acc: 49.883,74.607,93.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.656 | Acc: 50.039,74.600,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.656 | Acc: 50.138,74.721,93.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.658 | Acc: 50.162,74.728,93.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.657 | Acc: 50.159,74.647,93.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.660 | Acc: 50.120,74.608,93.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.660 | Acc: 50.148,74.554,93.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.660 | Acc: 50.297,74.628,93.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.659 | Acc: 50.321,74.588,93.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.662 | Acc: 50.294,74.533,93.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.662 | Acc: 50.248,74.465,93.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.651 | Acc: 46.094,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.935 | Acc: 46.689,64.621,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.972 | Acc: 46.132,64.062,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.997 | Acc: 45.697,63.730,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.600 | Acc: 48.438,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.621 | Acc: 49.665,75.856,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.651 | Acc: 49.466,74.543,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.651 | Acc: 49.962,74.385,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.647 | Acc: 50.241,74.711,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.643 | Acc: 50.456,74.884,93.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.642 | Acc: 50.394,74.793,93.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.645 | Acc: 50.360,74.795,93.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.649 | Acc: 50.432,74.573,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.648 | Acc: 50.328,74.512,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.646 | Acc: 50.439,74.596,93.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.645 | Acc: 50.378,74.608,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.647 | Acc: 50.263,74.582,93.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.648 | Acc: 50.254,74.575,93.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.651 | Acc: 50.309,74.594,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.654 | Acc: 50.280,74.541,93.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.655 | Acc: 50.292,74.516,93.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.657 | Acc: 50.291,74.430,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.658 | Acc: 50.249,74.450,93.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.659 | Acc: 50.199,74.475,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.801 | Acc: 46.094,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.044 | Acc: 44.159,64.583,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.091 | Acc: 43.540,63.643,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.114 | Acc: 42.828,63.038,69.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.590 | Acc: 51.562,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.633 | Acc: 49.702,73.698,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.625 | Acc: 50.133,74.962,93.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.628 | Acc: 50.115,74.974,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.633 | Acc: 49.981,74.952,93.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.637 | Acc: 49.915,74.861,93.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.653 | Acc: 49.626,74.503,93.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.654 | Acc: 49.656,74.457,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.663 | Acc: 49.539,74.389,93.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.657 | Acc: 49.711,74.400,93.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.658 | Acc: 49.650,74.304,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.657 | Acc: 49.763,74.311,93.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.654 | Acc: 49.861,74.387,93.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.652 | Acc: 49.910,74.431,93.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.650 | Acc: 50.103,74.458,93.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.654 | Acc: 50.005,74.364,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 50.080,74.413,93.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.661 | Acc: 50.128,74.372,93.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.664 | Acc: 50.045,74.277,92.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.665 | Acc: 50.094,74.352,92.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.663 | Acc: 48.438,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.988 | Acc: 45.610,64.918,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.023 | Acc: 45.598,64.348,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.045 | Acc: 45.210,63.665,69.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.638 | Acc: 50.781,71.094,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.643 | Acc: 49.628,74.405,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.635 | Acc: 50.019,74.981,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.645 | Acc: 50.192,74.898,93.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.635 | Acc: 50.145,75.154,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.648 | Acc: 49.706,74.621,93.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.647 | Acc: 49.935,74.806,93.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.649 | Acc: 49.867,74.584,93.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.647 | Acc: 49.956,74.704,93.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.651 | Acc: 50.069,74.685,93.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.652 | Acc: 50.097,74.681,93.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.653 | Acc: 50.159,74.714,93.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.651 | Acc: 50.159,74.699,93.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.648 | Acc: 50.177,74.719,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.649 | Acc: 50.114,74.708,93.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.652 | Acc: 50.143,74.707,93.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.654 | Acc: 50.068,74.664,93.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.656 | Acc: 50.108,74.661,93.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.655 | Acc: 50.180,74.602,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 50.129,74.524,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.596 | Acc: 49.219,67.188,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.974 | Acc: 47.433,64.323,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.013 | Acc: 46.056,63.643,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.031 | Acc: 45.492,63.256,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.485 | Acc: 55.469,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.670 | Acc: 49.516,74.591,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.636 | Acc: 50.210,74.562,93.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.631 | Acc: 50.218,74.974,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.638 | Acc: 50.492,75.010,93.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.639 | Acc: 50.449,74.946,93.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.633 | Acc: 50.743,75.077,93.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.639 | Acc: 50.504,74.922,93.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.641 | Acc: 50.349,74.854,93.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.643 | Acc: 50.224,74.974,93.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.645 | Acc: 50.086,74.934,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.642 | Acc: 50.127,74.958,93.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.644 | Acc: 50.123,74.984,93.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.646 | Acc: 50.201,74.922,93.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.649 | Acc: 50.150,74.797,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.648 | Acc: 50.174,74.795,93.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.650 | Acc: 50.197,74.766,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.650 | Acc: 50.202,74.773,93.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.653 | Acc: 50.110,74.745,93.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.655 | Acc: 50.131,74.719,93.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.695 | Acc: 50.000,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.055 | Acc: 46.429,65.030,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.074 | Acc: 46.341,63.986,68.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.080 | Acc: 45.914,63.781,68.673,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.509 | Acc: 57.031,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 51.637,74.554,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.632 | Acc: 50.305,75.095,93.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.631 | Acc: 51.012,75.000,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.620 | Acc: 51.206,75.376,93.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.621 | Acc: 51.183,75.302,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.624 | Acc: 51.052,75.245,93.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.629 | Acc: 51.047,75.105,93.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.636 | Acc: 50.980,74.995,93.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.639 | Acc: 51.045,74.914,93.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.644 | Acc: 50.851,74.705,93.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.647 | Acc: 50.633,74.646,93.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.646 | Acc: 50.564,74.647,93.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.647 | Acc: 50.515,74.563,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.648 | Acc: 50.425,74.530,93.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.653 | Acc: 50.361,74.517,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.652 | Acc: 50.258,74.555,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.652 | Acc: 50.266,74.558,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.656 | Acc: 50.184,74.485,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.656 | Acc: 50.209,74.539,93.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.647 | Acc: 45.312,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.020 | Acc: 45.722,64.100,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.066 | Acc: 45.103,64.062,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.093 | Acc: 44.544,63.499,68.801,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.425 | Acc: 58.594,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.625 | Acc: 50.967,74.888,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.630 | Acc: 51.543,74.867,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.630 | Acc: 51.127,74.680,94.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.646 | Acc: 50.347,74.470,93.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.644 | Acc: 50.511,74.466,93.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.642 | Acc: 50.349,74.522,93.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.641 | Acc: 50.288,74.568,93.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.645 | Acc: 50.223,74.602,93.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.646 | Acc: 50.073,74.521,93.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.648 | Acc: 50.027,74.592,93.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.651 | Acc: 49.958,74.558,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.650 | Acc: 50.049,74.588,93.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.652 | Acc: 50.057,74.479,93.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.650 | Acc: 50.075,74.399,93.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.646 | Acc: 50.187,74.494,93.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.647 | Acc: 50.294,74.484,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.648 | Acc: 50.348,74.423,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.645 | Acc: 50.431,74.515,93.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.648 | Acc: 50.332,74.473,93.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.917 | Acc: 44.531,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.048 | Acc: 45.052,64.174,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.082 | Acc: 44.855,63.510,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.113 | Acc: 44.339,63.025,68.404,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.720 | Acc: 45.312,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.633 | Acc: 50.707,75.558,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.663 | Acc: 50.076,74.505,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.653 | Acc: 50.128,74.629,93.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.655 | Acc: 50.270,74.518,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.656 | Acc: 50.101,74.296,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.656 | Acc: 50.200,74.277,93.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.644 | Acc: 50.416,74.679,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.645 | Acc: 50.364,74.612,93.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.652 | Acc: 50.207,74.629,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.651 | Acc: 50.214,74.600,93.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.656 | Acc: 50.131,74.434,93.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.654 | Acc: 50.256,74.491,93.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.656 | Acc: 50.165,74.464,93.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.654 | Acc: 50.100,74.469,93.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.656 | Acc: 49.992,74.387,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.654 | Acc: 50.100,74.375,93.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.654 | Acc: 50.108,74.310,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.652 | Acc: 50.169,74.385,93.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.653 | Acc: 50.215,74.391,93.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.638 | Acc: 48.438,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.039 | Acc: 46.391,64.918,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.061 | Acc: 46.284,64.272,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.070 | Acc: 45.940,63.704,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.525 | Acc: 56.250,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.632 | Acc: 50.595,74.628,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.630 | Acc: 51.162,74.619,93.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.626 | Acc: 50.794,74.757,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.630 | Acc: 50.868,74.797,93.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.628 | Acc: 50.913,75.031,93.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.633 | Acc: 50.826,75.006,93.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.637 | Acc: 50.693,74.884,93.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.640 | Acc: 50.558,74.879,93.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.640 | Acc: 50.522,74.776,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.645 | Acc: 50.393,74.654,93.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.653 | Acc: 50.237,74.540,93.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.653 | Acc: 50.263,74.533,93.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.651 | Acc: 50.275,74.614,93.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.654 | Acc: 50.133,74.575,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.656 | Acc: 50.042,74.561,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.659 | Acc: 50.037,74.474,93.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 50.062,74.436,93.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.658 | Acc: 50.110,74.504,93.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.658 | Acc: 50.119,74.489,93.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.776 | Acc: 44.531,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.030 | Acc: 46.652,64.100,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.066 | Acc: 45.865,63.396,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.086 | Acc: 45.325,63.025,68.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.483 | Acc: 53.125,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.603 | Acc: 51.079,74.851,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.615 | Acc: 50.724,74.981,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.600 | Acc: 51.153,75.282,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.623 | Acc: 50.955,74.884,94.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.626 | Acc: 50.789,74.838,94.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.628 | Acc: 50.936,74.929,93.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.628 | Acc: 50.964,75.006,93.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.634 | Acc: 50.772,74.825,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.631 | Acc: 50.682,74.780,93.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.633 | Acc: 50.669,74.701,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.634 | Acc: 50.636,74.629,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.635 | Acc: 50.648,74.647,93.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.639 | Acc: 50.593,74.608,93.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.643 | Acc: 50.445,74.611,93.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.647 | Acc: 50.395,74.655,93.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.650 | Acc: 50.341,74.603,93.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.651 | Acc: 50.399,74.604,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.653 | Acc: 50.335,74.602,93.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.655 | Acc: 50.316,74.615,93.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.582 | Acc: 42.969,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.996 | Acc: 47.135,64.323,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.044 | Acc: 46.475,64.005,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.069 | Acc: 46.132,63.781,68.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.510 | Acc: 53.906,75.000,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.662 | Acc: 51.749,74.591,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.647 | Acc: 51.315,75.267,92.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 51.025,75.282,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.639 | Acc: 50.974,75.424,93.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.637 | Acc: 50.913,75.217,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.636 | Acc: 50.956,75.374,93.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.633 | Acc: 51.147,75.504,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.637 | Acc: 51.077,75.412,93.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.642 | Acc: 51.096,75.302,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.640 | Acc: 51.030,75.260,93.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.640 | Acc: 50.817,75.170,93.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.645 | Acc: 50.648,75.078,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.645 | Acc: 50.572,75.012,93.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.644 | Acc: 50.581,75.053,93.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.645 | Acc: 50.498,75.049,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.647 | Acc: 50.477,74.993,93.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.650 | Acc: 50.344,74.966,93.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.651 | Acc: 50.377,74.931,93.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.653 | Acc: 50.353,74.859,93.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.757 | Acc: 46.875,64.844,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.037 | Acc: 44.940,64.100,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.112 | Acc: 44.188,63.377,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.130 | Acc: 43.763,62.961,68.699,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.633 | Acc: 42.969,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.644 | Acc: 49.777,75.372,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.634 | Acc: 50.324,75.800,92.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.622 | Acc: 50.026,75.679,93.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.622 | Acc: 50.077,75.453,93.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.626 | Acc: 49.969,75.178,93.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.632 | Acc: 49.942,75.129,93.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.632 | Acc: 49.956,75.310,93.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.634 | Acc: 50.039,75.184,93.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.638 | Acc: 50.060,75.155,93.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.639 | Acc: 50.187,75.082,93.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.640 | Acc: 50.237,75.173,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.639 | Acc: 50.334,75.185,93.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.647 | Acc: 50.198,74.958,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.648 | Acc: 50.117,74.880,93.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.648 | Acc: 50.257,74.852,93.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.648 | Acc: 50.239,74.793,93.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.647 | Acc: 50.257,74.782,93.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.648 | Acc: 50.260,74.777,93.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.650 | Acc: 50.297,74.703,93.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.821 | Acc: 44.531,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.072 | Acc: 45.536,63.914,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.119 | Acc: 45.027,63.034,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.149 | Acc: 44.954,62.641,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.614 | Acc: 50.781,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.663 | Acc: 49.591,74.554,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.662 | Acc: 49.123,74.314,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.631 | Acc: 49.757,74.603,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.624 | Acc: 50.174,74.904,93.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.629 | Acc: 50.139,74.892,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.631 | Acc: 50.226,74.716,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.633 | Acc: 50.133,74.634,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.637 | Acc: 50.218,74.607,93.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.641 | Acc: 50.138,74.568,93.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.641 | Acc: 50.202,74.545,93.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.644 | Acc: 50.141,74.526,93.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.641 | Acc: 50.227,74.540,93.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.639 | Acc: 50.290,74.596,93.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.643 | Acc: 50.225,74.447,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.641 | Acc: 50.376,74.509,93.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.641 | Acc: 50.360,74.615,93.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.645 | Acc: 50.263,74.539,93.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.646 | Acc: 50.281,74.567,93.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.644 | Acc: 50.359,74.617,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.938 | Acc: 50.000,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.089 | Acc: 46.131,63.802,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.138 | Acc: 45.903,62.862,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.145 | Acc: 45.287,62.743,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.603 | Acc: 50.781,75.000,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.636 | Acc: 50.818,75.074,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.647 | Acc: 50.248,74.486,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 49.808,74.334,93.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.657 | Acc: 50.116,74.383,93.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.659 | Acc: 50.039,74.482,93.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.660 | Acc: 50.116,74.509,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.653 | Acc: 50.183,74.457,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.657 | Acc: 50.160,74.345,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.652 | Acc: 50.294,74.404,93.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.652 | Acc: 50.377,74.316,93.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.653 | Acc: 50.311,74.445,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.652 | Acc: 50.415,74.455,93.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.649 | Acc: 50.428,74.569,93.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.647 | Acc: 50.439,74.608,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.648 | Acc: 50.446,74.605,93.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.649 | Acc: 50.450,74.625,93.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.649 | Acc: 50.444,74.624,93.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.653 | Acc: 50.385,74.621,93.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.652 | Acc: 50.363,74.660,93.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.698 | Acc: 50.000,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.024 | Acc: 46.763,64.695,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.050 | Acc: 46.418,63.739,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.059 | Acc: 46.247,63.345,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.717 | Acc: 46.875,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.670 | Acc: 50.112,74.926,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.635 | Acc: 50.724,75.705,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.644 | Acc: 50.205,75.461,93.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.638 | Acc: 49.797,75.280,93.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.640 | Acc: 49.954,75.015,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.646 | Acc: 49.871,74.845,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.645 | Acc: 50.050,74.767,93.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.648 | Acc: 49.990,74.830,93.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.644 | Acc: 50.095,74.940,93.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.642 | Acc: 50.016,74.992,93.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.642 | Acc: 49.940,74.982,93.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.647 | Acc: 49.958,74.841,93.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.648 | Acc: 49.937,74.829,93.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.649 | Acc: 49.936,74.744,93.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.650 | Acc: 49.969,74.753,93.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.648 | Acc: 50.083,74.766,93.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.648 | Acc: 50.254,74.803,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.647 | Acc: 50.268,74.686,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.646 | Acc: 50.344,74.725,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.655 | Acc: 46.094,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 45.908,64.955,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.986 | Acc: 46.113,64.177,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.010 | Acc: 45.927,63.794,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.621 | Acc: 48.438,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.597 | Acc: 49.963,75.781,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.621 | Acc: 49.695,74.333,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.613 | Acc: 50.589,74.987,93.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.622 | Acc: 50.415,74.624,94.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.615 | Acc: 50.758,74.853,93.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.624 | Acc: 50.743,74.632,93.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.626 | Acc: 50.770,74.867,93.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.629 | Acc: 50.641,74.869,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.631 | Acc: 50.570,74.875,93.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.630 | Acc: 50.486,74.852,93.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.631 | Acc: 50.488,74.714,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.632 | Acc: 50.327,74.744,93.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.634 | Acc: 50.353,74.680,93.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.633 | Acc: 50.384,74.755,93.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.632 | Acc: 50.311,74.766,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.632 | Acc: 50.399,74.725,93.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.635 | Acc: 50.289,74.677,93.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.637 | Acc: 50.266,74.582,93.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.638 | Acc: 50.349,74.610,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.757 | Acc: 47.656,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.164 | Acc: 44.643,61.979,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.189 | Acc: 44.646,61.528,67.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.195 | Acc: 44.339,61.450,67.687,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.591 | Acc: 48.438,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.631 | Acc: 51.451,75.037,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.628 | Acc: 51.620,74.505,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.619 | Acc: 51.409,75.026,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.615 | Acc: 51.235,75.367,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.629 | Acc: 50.851,75.008,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.630 | Acc: 50.665,75.084,93.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.627 | Acc: 50.881,75.150,93.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.628 | Acc: 50.670,75.243,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.633 | Acc: 50.686,75.095,93.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.642 | Acc: 50.525,74.981,93.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.645 | Acc: 50.322,74.883,93.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.642 | Acc: 50.376,74.932,93.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.645 | Acc: 50.389,74.856,93.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.646 | Acc: 50.353,74.811,93.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.642 | Acc: 50.493,74.881,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.644 | Acc: 50.443,74.757,93.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.646 | Acc: 50.373,74.757,93.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.648 | Acc: 50.359,74.682,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.648 | Acc: 50.439,74.678,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.810 | Acc: 47.656,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.093 | Acc: 45.015,63.207,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.115 | Acc: 45.675,63.186,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.126 | Acc: 45.172,62.666,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.711 | Acc: 53.125,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.649 | Acc: 48.921,74.256,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.642 | Acc: 49.733,74.714,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.629 | Acc: 50.461,74.731,93.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.632 | Acc: 50.376,74.971,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.622 | Acc: 50.541,75.317,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.618 | Acc: 50.523,75.297,93.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.621 | Acc: 50.499,75.166,93.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.626 | Acc: 50.383,74.874,93.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.624 | Acc: 50.445,74.871,93.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.628 | Acc: 50.416,74.856,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.626 | Acc: 50.498,75.018,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.626 | Acc: 50.509,75.055,93.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.631 | Acc: 50.407,74.931,93.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.633 | Acc: 50.256,74.878,93.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.637 | Acc: 50.208,74.805,93.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.638 | Acc: 50.253,74.781,93.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.636 | Acc: 50.293,74.757,93.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.640 | Acc: 50.190,74.673,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.640 | Acc: 50.234,74.658,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.801 | Acc: 49.219,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.077 | Acc: 45.796,64.100,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.123 | Acc: 45.293,63.053,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.119 | Acc: 45.082,62.474,68.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.753 | Acc: 49.219,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.620 | Acc: 51.042,74.702,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.590 | Acc: 51.753,75.934,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.590 | Acc: 51.972,75.679,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.613 | Acc: 51.138,75.260,93.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.625 | Acc: 50.572,75.015,93.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.625 | Acc: 50.504,75.026,93.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.622 | Acc: 50.521,74.950,93.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.624 | Acc: 50.485,74.922,93.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.621 | Acc: 50.488,74.953,93.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.618 | Acc: 50.517,75.054,93.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.623 | Acc: 50.421,74.986,93.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.624 | Acc: 50.444,74.961,93.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.627 | Acc: 50.527,74.877,93.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.631 | Acc: 50.498,74.808,93.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.633 | Acc: 50.407,74.808,93.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.634 | Acc: 50.406,74.735,93.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.638 | Acc: 50.334,74.624,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.639 | Acc: 50.338,74.645,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.642 | Acc: 50.342,74.623,93.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.765 | Acc: 44.531,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.052 | Acc: 46.205,63.765,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.110 | Acc: 45.655,63.091,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.134 | Acc: 45.312,62.308,68.238,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.676 | Acc: 51.562,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.618 | Acc: 49.740,75.595,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.617 | Acc: 49.981,75.629,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.615 | Acc: 50.346,75.154,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.605 | Acc: 50.550,75.338,94.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.605 | Acc: 50.688,75.379,94.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.612 | Acc: 50.497,75.349,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.624 | Acc: 50.338,75.177,93.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.628 | Acc: 50.320,75.184,93.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.636 | Acc: 50.108,75.013,93.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.639 | Acc: 50.093,74.872,93.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.638 | Acc: 50.293,74.763,93.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.639 | Acc: 50.395,74.754,93.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.642 | Acc: 50.332,74.647,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.641 | Acc: 50.425,74.636,93.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.642 | Acc: 50.400,74.650,93.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.643 | Acc: 50.411,74.674,93.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.641 | Acc: 50.493,74.762,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.640 | Acc: 50.619,74.773,93.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.639 | Acc: 50.656,74.764,93.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.631 | Acc: 43.750,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.016 | Acc: 46.689,64.137,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.072 | Acc: 46.246,63.148,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.091 | Acc: 45.889,62.987,68.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.619 | Acc: 50.000,80.469,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 50.409,75.856,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.599 | Acc: 51.029,75.514,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.604 | Acc: 51.050,75.743,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.602 | Acc: 50.936,75.646,94.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.611 | Acc: 50.743,75.565,93.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.616 | Acc: 50.633,75.439,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.620 | Acc: 50.305,75.404,93.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.617 | Acc: 50.446,75.252,93.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.623 | Acc: 50.423,75.237,93.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.625 | Acc: 50.393,75.163,93.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.632 | Acc: 50.297,75.035,93.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.634 | Acc: 50.295,75.042,93.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.632 | Acc: 50.398,75.078,93.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.630 | Acc: 50.423,75.128,93.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.633 | Acc: 50.304,75.049,93.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.632 | Acc: 50.297,75.002,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.635 | Acc: 50.245,74.984,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.637 | Acc: 50.219,74.894,93.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.636 | Acc: 50.275,74.916,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.859 | Acc: 49.219,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.114 | Acc: 46.577,63.318,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.166 | Acc: 45.789,62.329,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.180 | Acc: 45.223,61.962,68.033,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.967 | Acc: 40.625,71.875,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.632 | Acc: 49.554,74.219,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.612 | Acc: 50.419,74.314,94.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.596 | Acc: 50.615,75.410,94.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.587 | Acc: 50.897,75.424,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.589 | Acc: 51.021,75.340,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.588 | Acc: 51.111,75.291,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.581 | Acc: 51.247,75.593,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.580 | Acc: 51.140,75.689,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.575 | Acc: 51.049,75.781,94.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.573 | Acc: 51.092,75.890,94.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.570 | Acc: 51.167,76.018,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.566 | Acc: 51.177,76.167,94.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.562 | Acc: 51.293,76.320,94.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.563 | Acc: 51.273,76.360,94.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.559 | Acc: 51.365,76.376,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.557 | Acc: 51.326,76.395,94.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.557 | Acc: 51.262,76.356,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.556 | Acc: 51.283,76.398,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.552 | Acc: 51.247,76.458,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.588 | Acc: 45.312,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.871 | Acc: 47.619,65.625,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.928 | Acc: 47.332,65.149,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.943 | Acc: 47.003,64.664,70.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.636 | Acc: 46.094,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.562 | Acc: 48.884,77.158,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.516 | Acc: 50.495,77.534,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.519 | Acc: 50.909,77.113,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.525 | Acc: 50.965,76.910,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.522 | Acc: 50.951,76.725,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.515 | Acc: 50.956,76.679,95.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.521 | Acc: 50.848,76.668,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.517 | Acc: 50.922,76.878,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.521 | Acc: 50.868,76.735,95.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.524 | Acc: 50.968,76.745,95.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.522 | Acc: 51.004,76.852,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.522 | Acc: 51.015,76.812,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.523 | Acc: 51.021,76.835,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.524 | Acc: 51.068,76.846,95.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 51.082,76.915,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.524 | Acc: 51.141,76.838,95.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.524 | Acc: 51.239,76.776,95.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.525 | Acc: 51.210,76.729,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.526 | Acc: 51.189,76.675,95.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.576 | Acc: 46.875,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.873 | Acc: 48.065,65.625,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 47.389,65.034,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.940 | Acc: 47.003,64.767,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.619 | Acc: 51.562,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.577 | Acc: 48.884,75.484,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.557 | Acc: 49.790,76.200,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.534 | Acc: 50.064,76.972,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.526 | Acc: 50.675,76.929,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.524 | Acc: 50.851,76.872,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.520 | Acc: 51.136,77.021,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.509 | Acc: 51.396,77.227,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.503 | Acc: 51.606,77.353,96.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.506 | Acc: 51.528,77.301,96.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.503 | Acc: 51.570,77.274,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 51.509,77.231,96.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 51.465,77.208,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 51.443,77.233,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.506 | Acc: 51.510,77.224,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.505 | Acc: 51.479,77.224,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 51.443,77.220,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.505 | Acc: 51.512,77.250,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.504 | Acc: 51.459,77.285,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.506 | Acc: 51.376,77.256,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.602 | Acc: 46.875,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.885 | Acc: 47.507,65.923,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.939 | Acc: 47.332,65.206,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.953 | Acc: 47.016,64.780,70.620,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.601 | Acc: 51.562,78.125,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.529 | Acc: 50.335,77.567,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.526 | Acc: 50.743,77.668,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.518 | Acc: 51.409,77.651,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.518 | Acc: 51.264,77.681,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.515 | Acc: 51.570,77.522,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.511 | Acc: 51.569,77.634,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.505 | Acc: 51.662,77.654,96.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 51.562,77.572,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 51.351,77.417,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.504 | Acc: 51.376,77.363,96.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 51.280,77.312,96.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.508 | Acc: 51.238,77.263,96.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.508 | Acc: 51.203,77.266,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 51.246,77.363,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.506 | Acc: 51.290,77.256,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 51.492,77.349,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 51.505,77.440,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 51.515,77.419,96.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 51.528,77.422,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.603 | Acc: 45.312,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.890 | Acc: 47.582,65.997,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.943 | Acc: 47.199,65.454,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.952 | Acc: 46.824,64.972,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.580 | Acc: 47.656,75.781,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 51.711,76.972,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.508 | Acc: 51.486,76.848,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.506 | Acc: 51.191,77.075,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 51.061,77.141,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.499 | Acc: 51.338,77.460,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.495 | Acc: 51.511,77.596,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.503 | Acc: 51.330,77.538,96.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.503 | Acc: 51.359,77.489,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.506 | Acc: 51.355,77.387,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.507 | Acc: 51.376,77.406,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.507 | Acc: 51.223,77.354,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.505 | Acc: 51.274,77.324,96.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 51.287,77.224,96.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.503 | Acc: 51.365,77.263,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.502 | Acc: 51.433,77.214,96.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 51.370,77.212,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.504 | Acc: 51.267,77.144,96.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.502 | Acc: 51.355,77.240,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.499 | Acc: 51.491,77.344,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.648 | Acc: 46.094,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.884 | Acc: 47.991,66.146,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.934 | Acc: 47.580,65.473,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.942 | Acc: 47.234,65.010,71.004,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.579 | Acc: 51.562,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.524 | Acc: 51.711,76.860,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.493 | Acc: 51.334,77.630,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 51.447,77.523,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 50.974,77.218,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.486 | Acc: 51.485,77.506,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 51.414,77.299,96.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.480 | Acc: 51.507,77.488,96.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.483 | Acc: 51.495,77.611,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.483 | Acc: 51.502,77.633,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.481 | Acc: 51.590,77.573,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 51.456,77.446,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.487 | Acc: 51.400,77.376,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.488 | Acc: 51.401,77.299,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.493 | Acc: 51.307,77.219,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.495 | Acc: 51.303,77.204,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.497 | Acc: 51.292,77.176,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.497 | Acc: 51.450,77.218,96.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.496 | Acc: 51.459,77.240,96.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.495 | Acc: 51.509,77.247,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.625 | Acc: 46.875,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.901 | Acc: 47.582,65.885,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.948 | Acc: 47.218,65.358,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.961 | Acc: 46.939,64.869,70.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.653 | Acc: 49.219,69.531,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.516 | Acc: 50.558,78.832,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.508 | Acc: 50.648,77.934,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 51.652,77.779,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.497 | Acc: 51.659,77.324,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.487 | Acc: 51.949,77.553,96.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 51.860,77.608,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 51.646,77.333,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.495 | Acc: 51.456,77.300,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.495 | Acc: 51.468,77.214,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.494 | Acc: 51.434,77.208,96.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.491 | Acc: 51.449,77.266,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.486 | Acc: 51.498,77.357,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.487 | Acc: 51.574,77.296,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 51.621,77.344,96.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.491 | Acc: 51.453,77.289,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.493 | Acc: 51.555,77.220,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.494 | Acc: 51.643,77.243,96.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.495 | Acc: 51.679,77.188,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.494 | Acc: 51.704,77.178,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.574 | Acc: 45.312,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.883 | Acc: 47.731,66.034,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.935 | Acc: 47.351,65.358,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.954 | Acc: 47.016,64.985,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.392 | Acc: 52.344,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.483 | Acc: 51.749,78.720,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.493 | Acc: 50.629,78.106,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.484 | Acc: 50.909,77.856,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.490 | Acc: 51.350,77.894,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 51.663,77.839,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 51.737,77.660,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.496 | Acc: 51.474,77.360,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.495 | Acc: 51.655,77.407,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.493 | Acc: 51.739,77.551,96.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 51.683,77.600,96.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 51.683,77.513,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 51.705,77.593,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 51.598,77.550,96.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.489 | Acc: 51.640,77.527,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.486 | Acc: 51.726,77.634,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 51.784,77.587,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.487 | Acc: 51.723,77.577,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.489 | Acc: 51.664,77.513,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 51.700,77.475,96.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.652 | Acc: 46.094,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.910 | Acc: 47.656,65.774,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.957 | Acc: 47.085,65.492,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.968 | Acc: 46.644,64.959,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.590 | Acc: 55.469,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 51.897,76.935,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.494 | Acc: 51.620,77.287,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.487 | Acc: 51.729,77.741,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.496 | Acc: 51.611,77.218,96.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.496 | Acc: 51.849,77.096,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.497 | Acc: 51.679,77.163,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.497 | Acc: 51.529,77.056,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.501 | Acc: 51.344,76.912,96.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 51.334,77.033,96.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.498 | Acc: 51.372,76.990,96.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.494 | Acc: 51.464,77.079,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 51.456,77.068,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.496 | Acc: 51.446,77.131,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.492 | Acc: 51.537,77.191,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.493 | Acc: 51.407,77.165,96.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.491 | Acc: 51.499,77.227,96.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.490 | Acc: 51.553,77.314,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.489 | Acc: 51.632,77.365,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 51.645,77.368,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.635 | Acc: 46.094,67.188,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.898 | Acc: 47.545,65.737,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.947 | Acc: 47.389,65.339,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.959 | Acc: 46.990,64.997,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.334 | Acc: 59.375,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.440 | Acc: 51.935,77.232,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.452 | Acc: 52.229,77.058,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.479 | Acc: 51.806,76.985,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.479 | Acc: 52.064,76.939,96.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.479 | Acc: 51.957,77.266,96.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.481 | Acc: 51.885,77.357,96.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 51.546,77.222,96.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.489 | Acc: 51.640,77.169,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.491 | Acc: 51.472,77.128,96.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.494 | Acc: 51.504,76.994,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 51.545,77.004,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 51.562,77.104,96.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 51.548,77.098,96.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 51.518,77.171,96.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.484 | Acc: 51.633,77.256,96.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.483 | Acc: 51.638,77.259,96.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.481 | Acc: 51.640,77.277,96.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 51.627,77.244,96.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.482 | Acc: 51.657,77.264,96.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.653 | Acc: 46.875,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.897 | Acc: 48.289,66.034,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.947 | Acc: 47.466,65.301,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.964 | Acc: 47.093,64.959,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.422 | Acc: 53.906,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.481 | Acc: 51.488,77.865,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 50.705,77.382,96.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 50.794,77.305,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.495 | Acc: 50.945,77.180,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.494 | Acc: 51.098,77.189,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.492 | Acc: 51.369,77.305,96.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.488 | Acc: 51.457,77.460,96.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.485 | Acc: 51.339,77.470,96.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 51.411,77.374,96.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.481 | Acc: 51.469,77.476,96.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.480 | Acc: 51.566,77.528,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.481 | Acc: 51.579,77.499,96.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.481 | Acc: 51.545,77.481,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.483 | Acc: 51.596,77.385,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.484 | Acc: 51.575,77.398,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 51.580,77.373,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.484 | Acc: 51.581,77.390,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 51.599,77.424,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.485 | Acc: 51.606,77.395,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.637 | Acc: 44.531,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.921 | Acc: 47.805,66.257,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.962 | Acc: 47.370,65.606,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.974 | Acc: 47.144,65.202,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.580 | Acc: 50.781,78.125,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.482 | Acc: 50.707,77.455,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 51.105,77.229,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.483 | Acc: 51.473,77.664,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.482 | Acc: 51.582,77.961,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 51.516,77.885,96.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.481 | Acc: 51.808,77.873,96.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.479 | Acc: 51.856,77.754,96.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 51.888,77.683,96.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.477 | Acc: 51.912,77.611,96.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.479 | Acc: 51.823,77.593,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.479 | Acc: 51.746,77.665,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 51.718,77.671,96.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.480 | Acc: 51.673,77.634,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.481 | Acc: 51.574,77.591,96.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.479 | Acc: 51.583,77.624,96.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.479 | Acc: 51.553,77.565,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.480 | Acc: 51.540,77.591,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.478 | Acc: 51.584,77.625,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.478 | Acc: 51.567,77.569,96.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.559 | Acc: 44.531,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.918 | Acc: 47.656,65.774,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.967 | Acc: 47.218,65.053,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.977 | Acc: 46.901,64.869,70.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.338 | Acc: 57.812,79.688,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 53.423,77.679,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.453 | Acc: 52.782,78.011,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.460 | Acc: 52.062,77.818,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.468 | Acc: 52.045,77.739,96.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.470 | Acc: 52.297,77.653,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.468 | Acc: 52.144,77.809,96.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.472 | Acc: 51.928,77.621,96.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.472 | Acc: 51.946,77.703,96.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.476 | Acc: 51.804,77.702,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.478 | Acc: 51.675,77.616,96.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.479 | Acc: 51.722,77.528,96.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.478 | Acc: 51.657,77.587,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.481 | Acc: 51.542,77.493,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.480 | Acc: 51.615,77.544,96.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.484 | Acc: 51.544,77.448,96.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.482 | Acc: 51.599,77.480,96.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 51.572,77.426,96.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.483 | Acc: 51.586,77.348,96.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 51.671,77.477,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.646 | Acc: 47.656,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.912 | Acc: 47.879,66.257,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.964 | Acc: 47.428,65.454,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 47.106,65.087,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.544 | Acc: 50.000,73.438,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.473 | Acc: 51.302,78.237,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.481 | Acc: 51.505,77.439,97.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.479 | Acc: 51.537,77.305,96.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 51.861,77.778,96.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.473 | Acc: 51.617,77.669,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.470 | Acc: 51.924,77.686,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.467 | Acc: 52.022,77.815,96.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.463 | Acc: 52.038,78.033,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.467 | Acc: 51.994,77.939,96.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.468 | Acc: 51.881,77.942,96.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.470 | Acc: 51.958,77.867,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.471 | Acc: 51.890,77.778,96.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.476 | Acc: 51.841,77.694,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.474 | Acc: 51.827,77.752,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 51.682,77.640,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.477 | Acc: 51.684,77.597,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 51.613,77.545,96.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.480 | Acc: 51.608,77.504,96.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.478 | Acc: 51.681,77.547,96.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.610 | Acc: 45.312,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.933 | Acc: 47.917,65.811,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.976 | Acc: 47.389,65.263,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.987 | Acc: 46.913,64.857,70.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.390 | Acc: 54.688,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 51.339,77.455,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.465 | Acc: 51.810,77.915,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.476 | Acc: 51.332,77.497,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.477 | Acc: 51.620,77.691,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 51.578,77.406,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.482 | Acc: 51.795,77.473,96.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 51.828,77.438,96.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.482 | Acc: 51.902,77.198,96.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.483 | Acc: 51.800,77.171,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.480 | Acc: 51.850,77.200,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 51.683,77.139,96.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.482 | Acc: 51.744,77.234,96.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.481 | Acc: 51.679,77.221,96.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.481 | Acc: 51.599,77.288,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.482 | Acc: 51.666,77.224,96.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.481 | Acc: 51.740,77.246,96.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.481 | Acc: 51.755,77.264,96.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.480 | Acc: 51.827,77.231,96.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 51.821,77.223,96.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.604 | Acc: 45.312,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.939 | Acc: 47.470,65.960,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 47.104,65.282,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.988 | Acc: 46.888,64.959,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.423 | Acc: 54.688,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.500 | Acc: 51.711,77.046,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.483 | Acc: 51.963,76.982,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.480 | Acc: 51.844,76.985,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.478 | Acc: 51.784,77.045,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.480 | Acc: 51.810,77.019,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.477 | Acc: 51.769,77.189,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.475 | Acc: 51.917,77.344,96.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.475 | Acc: 52.019,77.460,96.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.474 | Acc: 51.977,77.590,96.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.470 | Acc: 52.037,77.631,96.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.474 | Acc: 51.930,77.538,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.475 | Acc: 51.984,77.529,96.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.474 | Acc: 52.003,77.574,96.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.477 | Acc: 52.010,77.488,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 51.962,77.515,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.475 | Acc: 52.010,77.500,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.476 | Acc: 51.993,77.479,96.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.477 | Acc: 51.870,77.517,96.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.475 | Acc: 51.876,77.518,96.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.578 | Acc: 46.875,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.912 | Acc: 47.656,66.109,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.967 | Acc: 47.237,65.339,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.979 | Acc: 46.849,64.985,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.552 | Acc: 51.562,72.656,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.516 | Acc: 52.158,77.195,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 52.420,77.992,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.461 | Acc: 52.523,78.612,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.470 | Acc: 52.064,78.173,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.473 | Acc: 52.050,77.862,96.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.469 | Acc: 52.098,77.815,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.471 | Acc: 51.967,77.831,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.475 | Acc: 51.660,77.683,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.475 | Acc: 51.783,77.633,96.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.475 | Acc: 51.807,77.558,96.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.475 | Acc: 51.799,77.411,96.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.474 | Acc: 51.789,77.441,96.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.473 | Acc: 51.730,77.443,96.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.474 | Acc: 51.646,77.466,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.473 | Acc: 51.617,77.512,96.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.473 | Acc: 51.650,77.490,96.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.474 | Acc: 51.634,77.438,96.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.473 | Acc: 51.690,77.471,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.473 | Acc: 51.673,77.454,96.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.631 | Acc: 46.094,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.920 | Acc: 47.954,66.109,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.968 | Acc: 47.523,65.339,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.982 | Acc: 47.157,65.164,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.506 | Acc: 49.219,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.469 | Acc: 50.707,77.493,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.461 | Acc: 51.582,77.382,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.474 | Acc: 51.332,77.241,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.475 | Acc: 51.138,77.469,96.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.472 | Acc: 51.470,77.638,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.473 | Acc: 51.595,77.570,96.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 51.701,77.626,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.468 | Acc: 51.956,77.742,96.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.471 | Acc: 51.761,77.788,96.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.472 | Acc: 51.722,77.802,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.470 | Acc: 51.683,77.800,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.472 | Acc: 51.592,77.772,96.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.471 | Acc: 51.536,77.718,96.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.469 | Acc: 51.649,77.722,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.472 | Acc: 51.674,77.754,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.475 | Acc: 51.704,77.697,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.477 | Acc: 51.645,77.616,96.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.475 | Acc: 51.582,77.694,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.476 | Acc: 51.591,77.684,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.612 | Acc: 47.656,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.924 | Acc: 47.842,65.997,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.980 | Acc: 47.275,65.339,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.990 | Acc: 47.182,65.087,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.332 | Acc: 62.500,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.497 | Acc: 50.967,78.497,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.485 | Acc: 51.162,77.915,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 50.768,78.125,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.481 | Acc: 51.215,78.057,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.482 | Acc: 51.052,77.939,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.487 | Acc: 51.175,77.783,96.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.481 | Acc: 51.346,77.942,96.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.482 | Acc: 51.344,77.989,96.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 51.342,78.043,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.476 | Acc: 51.438,78.098,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.473 | Acc: 51.506,78.125,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.472 | Acc: 51.585,78.083,96.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.472 | Acc: 51.634,78.050,96.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.470 | Acc: 51.732,78.003,96.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.471 | Acc: 51.736,77.910,96.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.470 | Acc: 51.794,77.925,96.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.471 | Acc: 51.764,77.875,96.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.471 | Acc: 51.766,77.831,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.471 | Acc: 51.776,77.809,96.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.597 | Acc: 45.312,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.928 | Acc: 48.177,65.997,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.977 | Acc: 47.732,65.549,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.989 | Acc: 47.195,65.202,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.408 | Acc: 55.469,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.445 | Acc: 52.269,79.204,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.449 | Acc: 52.401,79.040,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.455 | Acc: 52.100,78.829,96.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.449 | Acc: 52.488,78.771,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.445 | Acc: 52.468,78.736,96.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.453 | Acc: 52.299,78.454,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.458 | Acc: 52.266,78.142,96.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.456 | Acc: 52.222,78.140,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.459 | Acc: 51.981,78.086,96.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.459 | Acc: 51.975,77.966,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.459 | Acc: 51.916,77.856,96.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.461 | Acc: 51.819,77.775,96.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.461 | Acc: 51.850,77.748,96.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.463 | Acc: 51.790,77.730,96.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.463 | Acc: 51.858,77.733,96.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.464 | Acc: 51.918,77.745,96.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.465 | Acc: 51.881,77.733,96.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.466 | Acc: 51.859,77.722,96.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.467 | Acc: 51.815,77.744,96.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.634 | Acc: 46.094,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.941 | Acc: 47.470,65.662,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.973 | Acc: 47.085,65.034,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.982 | Acc: 46.926,64.972,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.690 | Acc: 44.531,75.781,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.414 | Acc: 53.646,78.832,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.435 | Acc: 52.934,78.239,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.443 | Acc: 52.626,77.959,97.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.452 | Acc: 52.537,77.778,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.455 | Acc: 52.266,77.715,97.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.458 | Acc: 52.150,77.815,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.458 | Acc: 51.895,77.837,97.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.459 | Acc: 51.795,77.892,97.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.460 | Acc: 51.830,77.827,97.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.460 | Acc: 51.873,77.767,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.460 | Acc: 51.898,77.800,96.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.459 | Acc: 51.903,77.775,96.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.461 | Acc: 51.847,77.685,96.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.460 | Acc: 51.802,77.691,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.460 | Acc: 51.736,77.736,96.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.462 | Acc: 51.777,77.687,96.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.464 | Acc: 51.716,77.658,96.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.465 | Acc: 51.671,77.632,96.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.466 | Acc: 51.692,77.639,96.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.633 | Acc: 47.656,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 47.842,65.737,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.994 | Acc: 47.085,65.396,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.006 | Acc: 46.785,64.882,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.483 | Acc: 51.562,73.438,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.499 | Acc: 50.446,76.823,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.464 | Acc: 51.886,77.668,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.448 | Acc: 52.216,77.997,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 51.717,77.720,96.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.463 | Acc: 51.887,77.622,96.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.459 | Acc: 51.924,77.634,97.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.466 | Acc: 51.557,77.565,96.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.471 | Acc: 51.606,77.378,96.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.469 | Acc: 51.623,77.378,96.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.466 | Acc: 51.850,77.449,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.470 | Acc: 51.768,77.326,96.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.473 | Acc: 51.640,77.237,96.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.470 | Acc: 51.787,77.287,96.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.470 | Acc: 51.807,77.296,96.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.468 | Acc: 51.697,77.448,96.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.466 | Acc: 51.726,77.570,96.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.468 | Acc: 51.684,77.516,96.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.469 | Acc: 51.638,77.588,96.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.468 | Acc: 51.655,77.610,96.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.623 | Acc: 47.656,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.946 | Acc: 47.693,65.811,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.992 | Acc: 47.389,65.168,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.001 | Acc: 47.131,64.921,70.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.476 | Acc: 50.000,75.781,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.465 | Acc: 51.786,77.493,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.451 | Acc: 52.896,77.325,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.450 | Acc: 52.408,77.702,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.451 | Acc: 52.440,77.392,96.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.440 | Acc: 52.684,77.932,96.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.447 | Acc: 52.544,77.912,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.446 | Acc: 52.499,78.009,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.448 | Acc: 52.281,77.941,96.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.452 | Acc: 52.210,77.888,96.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.456 | Acc: 52.025,77.837,96.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.459 | Acc: 51.990,77.658,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.460 | Acc: 52.013,77.616,96.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.463 | Acc: 51.943,77.613,96.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.462 | Acc: 51.971,77.602,96.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.468 | Acc: 51.804,77.525,96.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.468 | Acc: 51.757,77.485,96.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.471 | Acc: 51.677,77.319,96.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.469 | Acc: 51.731,77.413,96.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.466 | Acc: 51.813,77.459,96.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.656 | Acc: 44.531,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.936 | Acc: 47.879,66.034,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 47.313,65.511,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.996 | Acc: 47.054,65.202,70.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.380 | Acc: 53.125,75.000,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.477 | Acc: 51.525,78.385,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.473 | Acc: 51.886,77.877,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.472 | Acc: 51.729,77.933,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.464 | Acc: 51.881,77.980,96.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.466 | Acc: 51.764,77.808,96.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.471 | Acc: 51.537,77.731,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.468 | Acc: 51.585,77.914,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.468 | Acc: 51.567,77.916,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.465 | Acc: 51.709,78.039,96.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.466 | Acc: 51.706,78.098,96.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.468 | Acc: 51.509,77.991,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.472 | Acc: 51.481,77.930,96.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.469 | Acc: 51.634,77.942,96.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.468 | Acc: 51.560,78.039,96.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.468 | Acc: 51.531,77.961,96.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.468 | Acc: 51.516,78.018,96.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.467 | Acc: 51.585,78.017,96.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.468 | Acc: 51.556,77.974,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.470 | Acc: 51.495,77.850,96.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.653 | Acc: 46.875,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.946 | Acc: 47.693,66.295,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 47.351,65.701,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.001 | Acc: 47.157,65.138,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.320 | Acc: 64.844,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 50.744,77.009,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.481 | Acc: 51.486,77.382,97.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.481 | Acc: 51.178,77.638,96.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.473 | Acc: 51.177,77.826,97.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.467 | Acc: 51.300,78.009,97.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.462 | Acc: 51.524,77.822,97.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.464 | Acc: 51.596,77.776,97.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.459 | Acc: 51.684,77.975,97.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.462 | Acc: 51.588,77.844,97.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.465 | Acc: 51.559,77.725,97.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.465 | Acc: 51.591,77.747,97.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.462 | Acc: 51.702,77.811,97.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.464 | Acc: 51.691,77.787,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.465 | Acc: 51.601,77.783,97.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.465 | Acc: 51.524,77.730,97.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.466 | Acc: 51.555,77.687,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.465 | Acc: 51.606,77.653,97.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.465 | Acc: 51.645,77.645,97.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.466 | Acc: 51.645,77.664,97.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.659 | Acc: 43.750,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.936 | Acc: 48.103,66.481,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.986 | Acc: 47.370,65.568,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.994 | Acc: 47.106,65.177,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.500 | Acc: 48.438,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.478 | Acc: 50.074,78.757,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.473 | Acc: 50.400,78.258,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.465 | Acc: 50.832,78.484,96.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 50.704,78.029,97.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.469 | Acc: 50.743,77.723,97.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.474 | Acc: 50.762,77.776,97.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 50.931,77.831,96.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.472 | Acc: 51.077,77.931,96.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.468 | Acc: 51.282,78.004,96.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.465 | Acc: 51.380,78.187,96.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.465 | Acc: 51.464,78.143,96.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.467 | Acc: 51.391,78.083,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.466 | Acc: 51.407,78.092,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.464 | Acc: 51.526,78.086,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.465 | Acc: 51.516,77.985,97.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.464 | Acc: 51.614,77.906,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.463 | Acc: 51.631,77.958,97.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.464 | Acc: 51.634,77.939,96.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.464 | Acc: 51.612,77.914,97.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.649 | Acc: 46.875,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.935 | Acc: 47.582,66.220,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.980 | Acc: 47.313,65.549,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.990 | Acc: 46.990,65.100,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.282 | Acc: 53.906,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.472 | Acc: 51.302,76.749,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.475 | Acc: 51.429,77.287,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.474 | Acc: 51.447,77.344,97.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.469 | Acc: 51.553,77.730,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 51.949,77.862,96.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.463 | Acc: 52.085,77.847,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.462 | Acc: 51.795,77.776,96.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.464 | Acc: 51.640,77.751,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.463 | Acc: 51.752,77.775,96.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.463 | Acc: 51.788,77.764,96.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.462 | Acc: 51.736,77.726,96.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.461 | Acc: 51.776,77.736,96.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.461 | Acc: 51.763,77.862,97.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.463 | Acc: 51.713,77.889,96.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.464 | Acc: 51.775,77.858,96.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.463 | Acc: 51.898,77.862,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.463 | Acc: 51.860,77.834,96.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.463 | Acc: 51.896,77.831,96.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.461 | Acc: 51.925,77.920,96.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.652 | Acc: 46.094,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.946 | Acc: 47.879,66.071,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.987 | Acc: 47.389,65.396,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.003 | Acc: 47.144,65.177,70.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.542 | Acc: 48.438,79.688,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.429 | Acc: 52.976,79.315,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.465 | Acc: 51.867,77.706,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.457 | Acc: 52.011,77.754,97.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.456 | Acc: 51.948,77.575,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.465 | Acc: 51.779,77.475,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.474 | Acc: 51.324,77.182,96.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.472 | Acc: 51.396,77.388,96.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.468 | Acc: 51.553,77.586,96.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.462 | Acc: 51.692,77.655,97.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.459 | Acc: 51.741,77.861,97.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.461 | Acc: 51.842,77.789,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.463 | Acc: 51.851,77.713,96.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.461 | Acc: 51.847,77.832,96.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.464 | Acc: 51.785,77.786,96.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.465 | Acc: 51.692,77.743,96.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.465 | Acc: 51.657,77.684,96.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.465 | Acc: 51.702,77.694,96.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.464 | Acc: 51.723,77.686,96.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.463 | Acc: 51.698,77.707,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.678 | Acc: 45.312,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.957 | Acc: 47.619,66.481,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.000 | Acc: 47.275,65.663,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.012 | Acc: 47.080,65.151,70.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.512 | Acc: 42.969,78.125,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.457 | Acc: 51.562,77.046,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.462 | Acc: 51.239,77.077,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.462 | Acc: 51.473,77.267,97.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.457 | Acc: 51.659,77.488,97.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.452 | Acc: 52.042,77.715,97.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.453 | Acc: 52.053,77.970,97.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.458 | Acc: 51.862,77.815,97.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.457 | Acc: 51.990,77.858,97.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.459 | Acc: 51.899,77.853,97.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.462 | Acc: 51.722,77.701,97.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.463 | Acc: 51.771,77.722,97.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.461 | Acc: 51.854,77.853,97.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.459 | Acc: 51.934,77.859,97.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.459 | Acc: 51.957,77.861,97.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.459 | Acc: 51.996,77.814,97.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.460 | Acc: 51.976,77.852,97.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.460 | Acc: 52.039,77.859,97.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.460 | Acc: 52.019,77.876,97.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.460 | Acc: 51.942,77.879,97.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.581 | Acc: 46.875,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 47.545,66.257,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 47.332,65.454,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.004 | Acc: 47.093,64.985,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.463 | Acc: 59.375,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.440 | Acc: 53.125,78.757,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.441 | Acc: 52.439,78.335,97.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.467 | Acc: 51.434,77.792,96.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.460 | Acc: 51.543,77.739,97.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.459 | Acc: 51.624,77.831,97.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.461 | Acc: 51.608,77.763,97.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.458 | Acc: 51.773,77.798,97.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.458 | Acc: 51.883,77.800,96.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.461 | Acc: 51.796,77.814,96.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.460 | Acc: 51.862,77.826,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.463 | Acc: 51.955,77.740,96.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.460 | Acc: 51.961,77.762,96.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.459 | Acc: 51.913,77.667,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.462 | Acc: 51.852,77.636,96.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.460 | Acc: 51.913,77.707,96.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.461 | Acc: 51.879,77.687,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.462 | Acc: 51.748,77.669,96.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.462 | Acc: 51.692,77.671,97.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.462 | Acc: 51.712,77.645,97.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.635 | Acc: 46.094,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.957 | Acc: 47.954,65.997,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.004 | Acc: 47.332,65.263,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.015 | Acc: 47.080,65.010,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.247 | Acc: 57.031,82.031,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.439 | Acc: 50.484,77.939,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.440 | Acc: 51.448,77.763,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.451 | Acc: 51.383,77.856,97.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.453 | Acc: 51.437,77.884,97.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.456 | Acc: 51.408,77.847,97.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.458 | Acc: 51.575,77.815,96.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.460 | Acc: 51.640,77.837,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.461 | Acc: 51.582,77.780,96.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.463 | Acc: 51.429,77.698,97.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.462 | Acc: 51.496,77.740,97.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.459 | Acc: 51.591,77.849,97.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.459 | Acc: 51.601,77.814,97.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.459 | Acc: 51.715,77.874,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.458 | Acc: 51.715,77.916,97.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.460 | Acc: 51.656,77.795,97.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.459 | Acc: 51.718,77.801,97.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.460 | Acc: 51.695,77.816,97.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.459 | Acc: 51.716,77.831,97.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.458 | Acc: 51.729,77.848,97.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.607 | Acc: 44.531,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.943 | Acc: 47.619,66.183,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.994 | Acc: 47.351,65.511,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.007 | Acc: 47.067,65.023,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.287 | Acc: 60.156,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 51.637,78.534,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.442 | Acc: 51.124,78.220,97.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.444 | Acc: 51.255,78.253,97.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.439 | Acc: 51.698,78.414,97.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.449 | Acc: 51.609,78.125,97.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.441 | Acc: 51.821,78.396,97.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.446 | Acc: 51.884,78.291,97.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.451 | Acc: 51.766,78.232,97.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.454 | Acc: 51.727,78.207,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.457 | Acc: 51.691,78.129,97.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.460 | Acc: 51.623,78.114,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.460 | Acc: 51.666,78.080,97.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.458 | Acc: 51.640,78.143,97.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.459 | Acc: 51.607,78.036,97.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.460 | Acc: 51.550,78.000,97.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.460 | Acc: 51.524,77.996,97.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.460 | Acc: 51.542,77.946,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.459 | Acc: 51.495,77.974,97.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.458 | Acc: 51.458,77.959,97.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.630 | Acc: 46.875,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.942 | Acc: 48.103,66.443,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.993 | Acc: 47.523,65.568,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.003 | Acc: 47.144,65.126,70.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.361 | Acc: 55.469,79.688,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.462 | Acc: 50.893,77.976,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.451 | Acc: 51.753,78.506,97.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.454 | Acc: 52.011,78.163,97.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.451 | Acc: 51.968,78.106,97.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.450 | Acc: 52.274,78.195,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.451 | Acc: 52.279,78.119,97.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.450 | Acc: 52.238,77.948,97.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.453 | Acc: 52.067,78.057,97.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.453 | Acc: 52.033,78.198,97.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.448 | Acc: 52.060,78.172,97.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.449 | Acc: 52.082,78.178,97.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.448 | Acc: 52.117,78.235,97.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.451 | Acc: 51.991,78.191,97.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.452 | Acc: 51.929,78.153,97.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.455 | Acc: 51.900,78.029,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.457 | Acc: 51.864,78.008,97.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.459 | Acc: 51.794,77.928,97.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.459 | Acc: 51.783,77.926,97.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.458 | Acc: 51.792,77.945,97.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.627 | Acc: 46.875,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 47.879,66.518,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.001 | Acc: 47.237,65.492,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.015 | Acc: 46.913,65.151,70.120,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.254 | Acc: 57.031,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.427 | Acc: 51.711,78.423,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.443 | Acc: 51.886,78.354,97.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.459 | Acc: 51.550,77.626,97.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.459 | Acc: 51.437,77.623,97.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.455 | Acc: 51.354,77.754,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.452 | Acc: 51.388,78.041,97.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.461 | Acc: 51.413,77.887,97.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.454 | Acc: 51.592,78.013,97.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.456 | Acc: 51.489,78.004,97.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.458 | Acc: 51.547,77.884,97.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.463 | Acc: 51.499,77.768,97.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.464 | Acc: 51.550,77.694,97.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.461 | Acc: 51.554,77.745,97.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.463 | Acc: 51.496,77.700,97.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.462 | Acc: 51.508,77.681,97.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.460 | Acc: 51.655,77.733,97.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.456 | Acc: 51.755,77.845,97.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.459 | Acc: 51.673,77.805,97.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.460 | Acc: 51.595,77.811,97.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.593 | Acc: 46.094,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 47.693,66.443,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.007 | Acc: 47.466,65.549,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.017 | Acc: 47.041,65.215,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.656 | Acc: 40.625,69.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.444 | Acc: 51.414,78.013,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.451 | Acc: 51.391,78.773,97.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.476 | Acc: 51.358,78.048,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.472 | Acc: 51.591,77.807,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.465 | Acc: 51.779,78.017,96.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.464 | Acc: 51.640,78.119,97.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.465 | Acc: 51.623,78.003,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.470 | Acc: 51.529,77.713,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.470 | Acc: 51.601,77.642,97.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.467 | Acc: 51.695,77.670,96.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.465 | Acc: 51.690,77.747,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.467 | Acc: 51.624,77.723,96.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.466 | Acc: 51.542,77.721,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.468 | Acc: 51.651,77.638,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.467 | Acc: 51.653,77.650,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.464 | Acc: 51.755,77.706,97.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.465 | Acc: 51.691,77.681,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.466 | Acc: 51.699,77.588,96.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.464 | Acc: 51.739,77.606,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.656 | Acc: 46.875,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.958 | Acc: 47.842,66.332,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.994 | Acc: 47.142,65.473,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.011 | Acc: 47.016,64.933,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.534 | Acc: 53.125,73.438,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.497 | Acc: 50.558,76.749,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.472 | Acc: 50.534,77.306,97.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.476 | Acc: 50.730,77.344,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.480 | Acc: 51.051,77.296,97.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.466 | Acc: 51.153,77.723,97.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.457 | Acc: 51.634,77.847,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.465 | Acc: 51.435,77.682,97.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.462 | Acc: 51.786,77.839,96.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.463 | Acc: 51.666,77.788,97.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.465 | Acc: 51.609,77.787,96.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.465 | Acc: 51.566,77.789,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.466 | Acc: 51.559,77.720,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.466 | Acc: 51.530,77.703,96.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.464 | Acc: 51.607,77.722,96.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.461 | Acc: 51.708,77.842,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.460 | Acc: 51.755,77.884,96.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.459 | Acc: 51.709,77.905,96.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.458 | Acc: 51.855,77.956,96.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.457 | Acc: 51.874,77.920,96.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.597 | Acc: 47.656,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.949 | Acc: 48.028,66.704,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.999 | Acc: 47.580,65.682,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 47.310,65.266,70.120,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.265 | Acc: 60.156,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.452 | Acc: 52.790,77.530,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.445 | Acc: 52.477,78.201,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.434 | Acc: 52.574,78.560,97.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.441 | Acc: 52.286,78.646,97.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.449 | Acc: 51.849,78.280,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.453 | Acc: 51.995,78.254,97.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.455 | Acc: 52.072,78.369,97.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.456 | Acc: 52.101,78.377,96.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.456 | Acc: 52.098,78.367,96.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.454 | Acc: 52.301,78.300,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.457 | Acc: 52.216,78.125,96.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.461 | Acc: 52.201,77.882,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.463 | Acc: 52.041,77.892,96.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.463 | Acc: 52.052,77.761,96.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.462 | Acc: 52.066,77.790,96.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.466 | Acc: 51.864,77.711,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.462 | Acc: 51.968,77.777,96.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.460 | Acc: 51.956,77.865,96.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.461 | Acc: 51.954,77.838,96.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.627 | Acc: 48.438,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.964 | Acc: 47.991,66.257,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.010 | Acc: 47.389,65.606,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.023 | Acc: 47.080,65.164,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.508 | Acc: 49.219,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.458 | Acc: 51.116,77.269,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.454 | Acc: 51.029,77.515,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.457 | Acc: 50.922,77.933,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.454 | Acc: 50.810,78.202,97.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.455 | Acc: 51.067,78.063,97.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.450 | Acc: 51.408,78.060,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.453 | Acc: 51.424,77.898,97.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.458 | Acc: 51.465,77.756,97.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.454 | Acc: 51.571,77.767,97.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.454 | Acc: 51.605,77.818,97.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.452 | Acc: 51.722,77.853,97.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.452 | Acc: 51.676,77.940,97.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.449 | Acc: 51.799,77.963,97.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.449 | Acc: 51.824,77.947,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.447 | Acc: 51.949,78.003,97.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.448 | Acc: 51.898,77.952,97.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.450 | Acc: 51.920,77.949,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.451 | Acc: 51.928,77.935,97.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.449 | Acc: 51.950,78.002,97.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.645 | Acc: 47.656,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.958 | Acc: 48.028,66.034,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.010 | Acc: 47.504,65.339,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.025 | Acc: 47.170,65.100,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.292 | Acc: 59.375,81.250,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.441 | Acc: 52.753,77.195,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.441 | Acc: 52.820,77.820,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.433 | Acc: 53.087,78.074,97.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.438 | Acc: 52.720,78.009,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.442 | Acc: 52.854,77.831,97.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.438 | Acc: 52.712,77.983,97.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.435 | Acc: 52.632,78.070,97.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.431 | Acc: 52.737,78.392,97.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.429 | Acc: 52.875,78.345,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.428 | Acc: 52.942,78.378,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.431 | Acc: 52.934,78.316,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.438 | Acc: 52.736,78.125,97.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.437 | Acc: 52.646,78.158,97.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.436 | Acc: 52.625,78.228,97.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.440 | Acc: 52.468,78.195,97.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.443 | Acc: 52.349,78.147,97.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.446 | Acc: 52.209,78.070,97.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.445 | Acc: 52.194,78.093,97.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.446 | Acc: 52.184,78.107,97.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.643 | Acc: 47.656,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.938 | Acc: 47.805,66.406,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.989 | Acc: 47.409,65.606,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.005 | Acc: 47.118,65.202,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.495 | Acc: 53.906,78.125,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.430 | Acc: 51.972,78.795,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.441 | Acc: 52.496,78.716,96.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.435 | Acc: 52.907,78.650,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.435 | Acc: 53.000,78.646,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.436 | Acc: 52.553,78.434,97.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.435 | Acc: 52.512,78.312,97.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 52.460,78.219,97.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.439 | Acc: 52.417,78.135,97.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.440 | Acc: 52.408,78.177,97.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.439 | Acc: 52.332,78.137,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.440 | Acc: 52.347,78.083,97.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.440 | Acc: 52.383,78.021,97.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.441 | Acc: 52.305,77.942,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.443 | Acc: 52.188,77.900,97.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.445 | Acc: 52.144,77.824,97.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.447 | Acc: 52.027,77.833,97.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.449 | Acc: 52.005,77.788,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.452 | Acc: 51.859,77.755,97.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.450 | Acc: 51.891,77.871,97.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.616 | Acc: 45.312,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.955 | Acc: 47.805,66.443,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.007 | Acc: 47.370,65.644,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.021 | Acc: 47.157,65.356,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.358 | Acc: 57.031,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.427 | Acc: 51.860,77.790,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.430 | Acc: 51.944,78.525,97.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.440 | Acc: 52.293,78.304,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.435 | Acc: 52.180,78.144,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.445 | Acc: 51.972,78.171,97.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.446 | Acc: 52.021,78.112,97.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.445 | Acc: 51.878,78.180,97.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.445 | Acc: 51.917,78.280,97.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.447 | Acc: 51.908,78.328,97.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.447 | Acc: 51.838,78.296,97.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.444 | Acc: 51.944,78.401,97.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.446 | Acc: 51.883,78.391,97.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.445 | Acc: 51.892,78.418,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.444 | Acc: 51.932,78.414,97.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.444 | Acc: 51.980,78.421,97.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.443 | Acc: 52.025,78.356,97.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 52.023,78.370,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.444 | Acc: 52.084,78.376,97.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.444 | Acc: 51.983,78.375,97.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.597 | Acc: 46.875,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 47.805,66.071,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 47.332,65.377,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.010 | Acc: 47.106,65.036,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.600 | Acc: 51.562,71.875,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.458 | Acc: 52.083,77.753,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.455 | Acc: 51.829,77.687,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.462 | Acc: 52.036,77.254,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.456 | Acc: 51.997,77.643,96.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.459 | Acc: 52.313,77.862,96.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.448 | Acc: 52.699,77.970,96.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.442 | Acc: 52.854,78.053,96.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.448 | Acc: 52.596,78.043,97.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.449 | Acc: 52.417,77.952,97.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.449 | Acc: 52.340,77.973,97.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.450 | Acc: 52.308,78.005,97.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.447 | Acc: 52.308,78.125,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.448 | Acc: 52.203,78.095,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.452 | Acc: 52.149,78.011,97.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.451 | Acc: 52.141,78.045,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.453 | Acc: 52.115,77.991,97.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.452 | Acc: 52.078,77.999,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.450 | Acc: 52.091,78.054,97.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.451 | Acc: 52.036,78.022,97.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.623 | Acc: 49.219,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.947 | Acc: 47.805,66.332,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.995 | Acc: 47.351,65.511,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.012 | Acc: 47.041,65.228,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.389 | Acc: 50.781,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 51.972,78.348,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.437 | Acc: 51.791,78.335,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.439 | Acc: 51.908,78.381,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.441 | Acc: 51.611,78.405,97.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.445 | Acc: 51.547,78.419,97.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.450 | Acc: 51.517,78.164,97.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.454 | Acc: 51.430,78.186,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.456 | Acc: 51.203,78.033,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.455 | Acc: 51.183,78.030,97.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.453 | Acc: 51.368,78.102,97.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.451 | Acc: 51.439,78.192,97.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.450 | Acc: 51.456,78.206,97.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.451 | Acc: 51.536,78.185,97.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.451 | Acc: 51.651,78.108,97.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.450 | Acc: 51.736,78.143,97.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.452 | Acc: 51.638,78.001,97.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.450 | Acc: 51.707,78.015,97.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.448 | Acc: 51.753,78.080,97.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.448 | Acc: 51.731,78.092,97.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.641 | Acc: 46.094,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.972 | Acc: 48.177,65.737,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.019 | Acc: 47.599,65.206,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.031 | Acc: 47.285,64.908,70.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.367 | Acc: 57.031,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 52.083,78.534,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.467 | Acc: 51.753,78.296,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.455 | Acc: 52.331,78.176,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.441 | Acc: 52.267,78.308,97.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.440 | Acc: 52.297,78.427,97.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.434 | Acc: 52.447,78.642,97.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.435 | Acc: 52.371,78.657,97.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.434 | Acc: 52.368,78.625,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.435 | Acc: 52.352,78.604,97.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.438 | Acc: 52.231,78.619,97.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.436 | Acc: 52.216,78.549,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.436 | Acc: 52.243,78.508,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.437 | Acc: 52.185,78.421,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.439 | Acc: 52.160,78.361,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.439 | Acc: 52.154,78.314,97.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.441 | Acc: 52.139,78.213,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.441 | Acc: 52.147,78.228,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.440 | Acc: 52.184,78.192,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.442 | Acc: 52.102,78.148,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.615 | Acc: 46.094,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 47.656,66.332,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.005 | Acc: 47.580,65.587,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.017 | Acc: 47.234,65.305,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.403 | Acc: 53.906,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.433 | Acc: 52.046,77.493,97.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.427 | Acc: 52.248,77.915,97.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.437 | Acc: 51.639,78.074,97.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.444 | Acc: 51.707,77.884,97.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.448 | Acc: 51.911,77.607,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.440 | Acc: 51.950,77.802,97.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.449 | Acc: 51.928,77.765,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.444 | Acc: 52.057,77.902,97.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.442 | Acc: 52.072,77.888,97.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.444 | Acc: 52.033,77.919,97.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.447 | Acc: 51.997,77.863,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.448 | Acc: 52.039,77.937,97.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.445 | Acc: 52.209,78.005,97.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.445 | Acc: 52.191,78.017,97.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.446 | Acc: 52.126,78.003,97.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.446 | Acc: 52.159,77.913,97.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.443 | Acc: 52.277,77.997,97.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.445 | Acc: 52.285,77.950,97.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.447 | Acc: 52.217,77.918,97.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.582 | Acc: 46.875,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.969 | Acc: 47.842,66.443,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.008 | Acc: 47.618,65.587,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.021 | Acc: 47.362,65.164,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.606 | Acc: 48.438,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.447 | Acc: 53.125,77.976,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.453 | Acc: 52.287,77.630,97.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.449 | Acc: 52.318,77.651,97.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.452 | Acc: 52.151,77.720,97.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.456 | Acc: 52.096,77.723,97.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.452 | Acc: 52.318,77.847,97.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.457 | Acc: 52.222,77.698,97.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.454 | Acc: 52.203,77.902,97.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.454 | Acc: 52.119,77.905,97.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.455 | Acc: 52.181,77.876,97.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.451 | Acc: 52.220,77.973,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.451 | Acc: 52.198,77.992,97.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.450 | Acc: 52.095,77.957,97.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.453 | Acc: 51.968,77.930,97.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.453 | Acc: 51.949,77.917,97.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.453 | Acc: 52.059,77.923,97.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.451 | Acc: 52.078,77.871,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.452 | Acc: 52.069,77.859,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.452 | Acc: 52.075,77.856,97.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.630 | Acc: 46.094,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 47.656,66.406,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.001 | Acc: 47.351,65.454,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 47.118,65.074,70.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.449 | Acc: 55.469,78.125,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.453 | Acc: 51.637,78.646,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.439 | Acc: 52.363,78.811,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.437 | Acc: 52.357,78.714,97.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.427 | Acc: 52.787,78.762,97.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.425 | Acc: 52.723,78.821,97.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.430 | Acc: 52.544,78.784,97.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.431 | Acc: 52.399,78.618,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.435 | Acc: 52.349,78.537,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.438 | Acc: 52.270,78.453,97.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.442 | Acc: 52.169,78.417,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.444 | Acc: 52.061,78.312,97.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.444 | Acc: 52.020,78.320,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.447 | Acc: 52.014,78.215,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.446 | Acc: 52.096,78.281,97.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.446 | Acc: 52.079,78.257,97.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.446 | Acc: 52.098,78.235,97.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.446 | Acc: 52.105,78.201,97.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.447 | Acc: 52.060,78.203,97.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.446 | Acc: 52.159,78.213,97.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.630 | Acc: 47.656,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.955 | Acc: 47.991,66.146,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 47.618,65.434,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 47.234,65.164,70.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.482 | Acc: 55.469,71.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.433 | Acc: 53.348,77.716,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.444 | Acc: 51.963,78.258,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.445 | Acc: 51.883,78.304,97.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.435 | Acc: 52.431,78.366,97.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.431 | Acc: 52.437,78.543,97.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.443 | Acc: 52.150,78.338,97.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.438 | Acc: 52.211,78.535,97.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.444 | Acc: 52.121,78.275,97.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.449 | Acc: 51.774,78.181,97.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.453 | Acc: 51.769,78.125,97.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.451 | Acc: 51.768,78.185,97.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.452 | Acc: 51.738,78.183,97.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.450 | Acc: 51.808,78.131,97.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.452 | Acc: 51.732,78.069,97.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.450 | Acc: 51.739,78.089,97.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.447 | Acc: 51.852,78.157,97.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.447 | Acc: 51.904,78.130,97.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.448 | Acc: 51.883,78.110,97.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.449 | Acc: 51.891,78.047,97.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.622 | Acc: 46.875,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.975 | Acc: 47.954,66.667,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.013 | Acc: 47.561,65.682,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.024 | Acc: 47.259,65.279,70.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.527 | Acc: 40.625,78.125,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.401 | Acc: 51.414,79.539,97.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.413 | Acc: 51.848,79.478,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.417 | Acc: 51.883,79.124,97.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.427 | Acc: 52.074,78.935,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.426 | Acc: 52.011,78.829,97.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.435 | Acc: 51.756,78.706,97.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.435 | Acc: 51.945,78.602,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.437 | Acc: 51.878,78.513,97.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.435 | Acc: 51.942,78.630,97.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.436 | Acc: 51.990,78.642,97.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.438 | Acc: 51.973,78.613,97.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.441 | Acc: 51.815,78.556,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.444 | Acc: 51.784,78.379,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.443 | Acc: 51.821,78.350,97.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.447 | Acc: 51.723,78.247,97.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.447 | Acc: 51.711,78.191,97.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.447 | Acc: 51.727,78.201,97.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.447 | Acc: 51.720,78.264,97.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.448 | Acc: 51.794,78.279,97.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.629 | Acc: 50.000,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.955 | Acc: 48.251,66.295,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.993 | Acc: 47.618,65.377,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.010 | Acc: 47.246,65.087,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.365 | Acc: 57.812,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.438 | Acc: 51.451,78.757,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.443 | Acc: 51.620,78.163,97.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.435 | Acc: 52.344,78.714,97.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.437 | Acc: 52.488,78.511,97.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.440 | Acc: 52.390,78.148,97.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.439 | Acc: 52.299,78.138,97.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.436 | Acc: 52.421,78.241,97.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.435 | Acc: 52.494,78.295,97.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.438 | Acc: 52.339,78.198,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.438 | Acc: 52.309,78.238,97.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.440 | Acc: 52.227,78.235,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.440 | Acc: 52.162,78.320,97.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.441 | Acc: 51.997,78.269,97.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.444 | Acc: 51.910,78.200,97.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.442 | Acc: 51.983,78.180,97.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.444 | Acc: 51.991,78.103,97.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.447 | Acc: 51.879,78.077,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.446 | Acc: 51.844,78.106,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.447 | Acc: 51.780,78.066,97.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.628 | Acc: 47.656,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.958 | Acc: 48.140,66.220,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.002 | Acc: 47.675,65.415,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.019 | Acc: 47.323,64.972,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.404 | Acc: 49.219,75.781,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.390 | Acc: 53.125,79.836,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.439 | Acc: 51.505,78.220,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.447 | Acc: 51.063,77.971,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.442 | Acc: 51.524,78.115,97.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.447 | Acc: 51.400,78.017,97.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.445 | Acc: 51.595,78.028,97.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.447 | Acc: 51.651,78.031,97.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.447 | Acc: 51.626,78.149,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.446 | Acc: 51.532,78.069,97.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.446 | Acc: 51.594,78.071,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.445 | Acc: 51.700,78.157,97.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.445 | Acc: 51.666,78.109,97.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.448 | Acc: 51.718,78.065,97.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.448 | Acc: 51.852,78.122,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.447 | Acc: 51.858,78.154,97.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.445 | Acc: 51.945,78.200,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 51.973,78.217,97.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.445 | Acc: 51.961,78.196,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.444 | Acc: 51.983,78.234,97.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.631 | Acc: 46.875,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.956 | Acc: 48.065,66.369,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.002 | Acc: 47.485,65.415,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 47.144,65.061,70.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.507 | Acc: 48.438,73.438,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.476 | Acc: 51.525,77.121,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.438 | Acc: 52.382,77.877,97.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.429 | Acc: 52.446,78.125,97.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.441 | Acc: 51.833,77.894,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.439 | Acc: 52.328,78.017,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.432 | Acc: 52.447,78.099,97.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.433 | Acc: 52.388,78.214,97.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.440 | Acc: 52.247,78.154,97.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.444 | Acc: 52.214,78.142,97.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.443 | Acc: 52.231,78.141,97.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.443 | Acc: 52.192,78.189,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.447 | Acc: 51.997,78.102,97.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.447 | Acc: 52.050,78.131,97.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.448 | Acc: 51.932,78.081,97.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.445 | Acc: 52.032,78.141,97.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.445 | Acc: 51.984,78.162,97.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.446 | Acc: 51.945,78.150,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.446 | Acc: 51.933,78.073,97.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.446 | Acc: 51.938,78.031,97.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.654 | Acc: 48.438,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 48.177,66.109,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.007 | Acc: 47.389,65.396,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.021 | Acc: 47.182,65.126,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.413 | Acc: 58.594,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.408 | Acc: 52.046,79.464,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.421 | Acc: 52.477,78.811,97.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.423 | Acc: 52.382,78.804,97.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.428 | Acc: 52.344,78.607,97.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.419 | Acc: 52.568,78.813,97.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.428 | Acc: 52.176,78.687,97.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.429 | Acc: 52.183,78.474,97.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.430 | Acc: 52.300,78.547,97.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.437 | Acc: 52.080,78.341,97.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.437 | Acc: 52.079,78.292,97.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.441 | Acc: 51.980,78.217,97.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.442 | Acc: 52.046,78.170,97.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.445 | Acc: 52.003,78.062,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.443 | Acc: 52.105,78.072,97.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.444 | Acc: 52.040,77.998,97.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.443 | Acc: 52.066,77.928,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 52.057,77.937,97.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.443 | Acc: 52.136,77.958,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.445 | Acc: 52.159,77.934,97.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.638 | Acc: 46.094,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.955 | Acc: 48.177,66.406,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.002 | Acc: 47.618,65.568,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 47.298,65.228,70.569,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.456 | Acc: 54.688,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.447 | Acc: 51.265,78.423,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.439 | Acc: 51.562,78.620,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.432 | Acc: 51.870,78.560,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.441 | Acc: 51.910,78.337,97.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.443 | Acc: 52.050,78.256,97.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.442 | Acc: 52.124,78.119,97.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.449 | Acc: 51.984,77.970,97.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.452 | Acc: 51.815,77.907,97.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.451 | Acc: 51.899,77.983,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.450 | Acc: 51.990,78.067,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.449 | Acc: 51.888,78.196,97.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.446 | Acc: 51.971,78.307,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.444 | Acc: 52.101,78.349,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.443 | Acc: 52.005,78.314,97.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.446 | Acc: 51.918,78.286,97.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.447 | Acc: 51.840,78.227,97.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 51.989,78.217,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.446 | Acc: 51.898,78.177,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.446 | Acc: 51.954,78.201,97.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.637 | Acc: 46.875,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.955 | Acc: 48.065,66.704,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.998 | Acc: 47.694,65.796,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.012 | Acc: 47.310,65.330,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.351 | Acc: 56.250,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.422 | Acc: 52.121,79.762,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.447 | Acc: 52.210,79.002,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.450 | Acc: 52.331,78.445,97.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.450 | Acc: 52.247,78.289,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.447 | Acc: 52.205,78.349,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.451 | Acc: 52.163,78.086,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.446 | Acc: 52.178,78.136,97.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.450 | Acc: 52.009,78.091,97.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.447 | Acc: 51.908,78.034,97.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.445 | Acc: 51.889,77.950,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.444 | Acc: 51.983,77.966,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.445 | Acc: 51.968,77.953,97.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.446 | Acc: 52.038,77.963,97.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.447 | Acc: 51.977,77.961,97.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.445 | Acc: 52.115,78.000,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.446 | Acc: 52.074,77.977,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.446 | Acc: 52.023,77.971,97.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.445 | Acc: 52.075,77.999,97.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.446 | Acc: 52.057,78.039,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.592 | Acc: 45.312,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.971 | Acc: 47.954,65.960,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.011 | Acc: 47.599,65.511,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.025 | Acc: 47.259,65.126,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.277 | Acc: 50.000,82.031,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.398 | Acc: 52.865,79.092,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.413 | Acc: 52.820,78.830,97.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.408 | Acc: 53.176,78.804,97.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.414 | Acc: 52.922,78.762,97.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.411 | Acc: 52.746,78.844,97.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.417 | Acc: 52.660,78.648,97.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.423 | Acc: 52.665,78.469,97.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.425 | Acc: 52.664,78.513,97.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.427 | Acc: 52.577,78.539,97.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.431 | Acc: 52.558,78.471,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.436 | Acc: 52.358,78.372,97.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.438 | Acc: 52.240,78.294,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.440 | Acc: 52.191,78.149,97.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.442 | Acc: 52.055,78.133,97.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.443 | Acc: 52.022,78.185,97.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.444 | Acc: 52.049,78.215,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.443 | Acc: 52.057,78.196,97.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.442 | Acc: 52.041,78.127,97.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.443 | Acc: 51.971,78.061,97.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.636 | Acc: 48.438,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.965 | Acc: 47.991,66.443,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.004 | Acc: 47.637,65.758,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.015 | Acc: 47.272,65.292,70.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.678 | Acc: 46.094,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.454 | Acc: 51.302,78.237,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.451 | Acc: 51.277,78.087,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.451 | Acc: 51.652,77.984,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.455 | Acc: 51.746,78.019,97.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.452 | Acc: 51.887,78.202,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.443 | Acc: 52.118,78.241,97.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.442 | Acc: 52.161,78.363,97.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.440 | Acc: 52.004,78.324,97.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.439 | Acc: 52.033,78.293,97.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.444 | Acc: 51.967,78.137,97.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.443 | Acc: 52.054,78.150,97.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.445 | Acc: 51.974,78.109,97.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.447 | Acc: 51.955,78.035,97.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.448 | Acc: 51.921,77.994,97.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.447 | Acc: 51.993,77.961,97.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.447 | Acc: 52.008,77.960,97.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.448 | Acc: 51.977,77.960,97.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.449 | Acc: 51.967,77.952,97.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.451 | Acc: 51.886,77.891,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.647 | Acc: 45.312,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.956 | Acc: 47.582,66.592,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.997 | Acc: 47.275,65.606,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 47.106,65.369,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.414 | Acc: 53.906,77.344,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 52.009,77.865,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.422 | Acc: 53.106,78.087,97.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.426 | Acc: 52.920,78.176,97.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.433 | Acc: 52.595,78.135,97.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.425 | Acc: 52.908,78.512,97.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.434 | Acc: 52.712,78.390,97.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 52.455,78.291,97.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.435 | Acc: 52.596,78.382,97.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.437 | Acc: 52.456,78.380,97.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.437 | Acc: 52.375,78.296,97.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.439 | Acc: 52.326,78.281,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.437 | Acc: 52.263,78.352,97.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.435 | Acc: 52.320,78.448,97.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.438 | Acc: 52.244,78.389,97.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.441 | Acc: 52.105,78.361,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.440 | Acc: 52.125,78.327,97.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.441 | Acc: 52.089,78.317,97.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.440 | Acc: 52.047,78.313,97.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.442 | Acc: 51.997,78.225,97.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.660 | Acc: 46.094,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 47.954,66.481,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.009 | Acc: 47.523,65.492,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.020 | Acc: 47.182,65.190,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.620 | Acc: 49.219,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.501 | Acc: 51.228,77.418,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.490 | Acc: 51.143,77.344,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.475 | Acc: 51.422,77.395,97.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.455 | Acc: 51.958,77.884,97.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.450 | Acc: 51.965,77.939,97.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.447 | Acc: 52.279,77.893,97.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.445 | Acc: 52.399,77.992,97.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.442 | Acc: 52.392,78.076,97.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.441 | Acc: 52.335,78.276,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.435 | Acc: 52.324,78.417,97.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.440 | Acc: 52.231,78.189,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.439 | Acc: 52.221,78.219,97.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.441 | Acc: 52.209,78.251,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.442 | Acc: 52.082,78.253,97.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.445 | Acc: 52.058,78.169,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.445 | Acc: 52.071,78.108,97.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 52.048,78.159,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.444 | Acc: 51.995,78.207,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.445 | Acc: 51.979,78.193,97.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.615 | Acc: 47.656,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.955 | Acc: 48.251,66.406,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.998 | Acc: 47.618,65.511,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.011 | Acc: 47.374,65.228,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.315 | Acc: 57.031,84.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.411 | Acc: 52.269,78.906,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.435 | Acc: 52.210,77.744,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.435 | Acc: 51.908,77.741,97.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.431 | Acc: 51.948,77.739,97.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 52.189,77.877,97.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.436 | Acc: 52.176,77.828,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.434 | Acc: 52.427,78.047,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.433 | Acc: 52.499,78.251,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.436 | Acc: 52.352,78.233,97.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.438 | Acc: 52.219,78.273,97.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.437 | Acc: 52.379,78.380,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.438 | Acc: 52.253,78.381,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.440 | Acc: 52.167,78.514,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.439 | Acc: 52.241,78.500,97.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.442 | Acc: 52.178,78.398,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.443 | Acc: 52.113,78.332,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 52.096,78.306,97.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.445 | Acc: 51.991,78.294,97.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.446 | Acc: 51.969,78.256,97.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.668 | Acc: 47.656,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.970 | Acc: 47.879,66.518,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.006 | Acc: 47.523,65.644,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.022 | Acc: 47.234,65.254,70.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.530 | Acc: 51.562,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.437 | Acc: 52.493,78.906,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.441 | Acc: 52.534,78.373,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.448 | Acc: 51.793,78.279,97.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.453 | Acc: 52.054,77.971,97.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.444 | Acc: 52.096,78.210,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.441 | Acc: 52.234,78.054,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 52.189,78.075,97.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.438 | Acc: 52.213,78.091,97.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.441 | Acc: 52.262,78.095,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.443 | Acc: 52.243,78.074,97.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.443 | Acc: 52.234,78.086,97.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.441 | Acc: 52.337,78.102,97.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.443 | Acc: 52.254,78.113,97.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.442 | Acc: 52.313,78.144,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.444 | Acc: 52.175,78.058,97.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.444 | Acc: 52.173,78.076,97.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.445 | Acc: 52.165,78.093,97.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.445 | Acc: 52.194,78.138,97.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.444 | Acc: 52.172,78.213,97.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.628 | Acc: 44.531,67.188,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.969 | Acc: 47.731,66.369,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.001 | Acc: 47.599,65.701,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.015 | Acc: 47.118,65.394,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.296 | Acc: 54.688,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.427 | Acc: 51.860,78.609,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.416 | Acc: 52.591,78.639,97.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.430 | Acc: 52.561,78.445,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.439 | Acc: 52.373,78.511,97.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.438 | Acc: 52.305,78.558,97.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.444 | Acc: 52.034,78.377,97.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.444 | Acc: 51.956,78.435,97.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.449 | Acc: 51.873,78.275,97.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.450 | Acc: 51.882,78.129,97.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.453 | Acc: 51.757,77.977,97.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.454 | Acc: 51.637,77.973,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.450 | Acc: 51.760,78.089,97.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.450 | Acc: 51.700,78.017,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.452 | Acc: 51.599,77.939,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.449 | Acc: 51.653,77.985,97.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.449 | Acc: 51.716,77.967,97.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.448 | Acc: 51.714,78.020,97.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.450 | Acc: 51.714,78.004,97.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.450 | Acc: 51.768,77.979,97.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.612 | Acc: 45.312,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 47.693,66.406,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.004 | Acc: 47.180,65.587,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 46.926,65.292,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.430 | Acc: 46.875,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.431 | Acc: 52.753,78.571,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.440 | Acc: 52.153,78.373,97.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.448 | Acc: 51.934,78.074,97.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.442 | Acc: 52.103,78.038,97.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.439 | Acc: 52.096,78.179,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.440 | Acc: 51.808,78.183,97.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.440 | Acc: 51.823,78.097,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.438 | Acc: 51.926,78.009,97.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.441 | Acc: 51.921,77.922,97.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.440 | Acc: 51.978,78.016,97.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.442 | Acc: 51.927,78.005,97.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.437 | Acc: 52.191,78.187,97.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.440 | Acc: 52.074,78.194,97.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.439 | Acc: 52.082,78.245,97.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.442 | Acc: 52.001,78.187,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.446 | Acc: 51.889,78.084,97.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 52.000,78.159,97.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.443 | Acc: 52.069,78.196,97.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.444 | Acc: 52.040,78.193,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.630 | Acc: 45.312,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.957 | Acc: 48.065,66.443,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.002 | Acc: 47.485,65.454,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 47.067,65.215,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.378 | Acc: 52.344,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.420 | Acc: 52.121,79.055,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.431 | Acc: 51.372,78.773,97.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.440 | Acc: 50.999,78.599,97.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.444 | Acc: 51.196,78.675,97.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.444 | Acc: 51.454,78.411,97.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.443 | Acc: 51.595,78.441,97.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.443 | Acc: 51.623,78.391,97.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.444 | Acc: 51.674,78.305,97.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.448 | Acc: 51.597,78.151,97.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.447 | Acc: 51.632,78.218,97.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.446 | Acc: 51.757,78.302,97.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.445 | Acc: 51.828,78.310,97.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.445 | Acc: 51.784,78.338,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.443 | Acc: 51.891,78.384,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.444 | Acc: 51.913,78.312,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.445 | Acc: 51.913,78.249,97.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.443 | Acc: 51.970,78.267,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.442 | Acc: 52.054,78.326,97.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.443 | Acc: 52.051,78.254,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.610 | Acc: 46.094,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 48.028,66.555,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.005 | Acc: 47.466,65.644,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.022 | Acc: 47.208,65.318,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.513 | Acc: 48.438,72.656,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.467 | Acc: 51.079,77.716,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.457 | Acc: 51.315,77.668,97.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.453 | Acc: 51.089,77.907,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.431 | Acc: 51.736,78.559,97.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 52.096,78.512,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.434 | Acc: 52.208,78.467,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.432 | Acc: 52.255,78.607,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.431 | Acc: 52.329,78.683,97.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.435 | Acc: 52.232,78.583,97.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.439 | Acc: 52.037,78.634,97.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.436 | Acc: 52.075,78.669,97.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.439 | Acc: 51.968,78.614,97.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.438 | Acc: 51.991,78.583,97.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.436 | Acc: 51.982,78.653,97.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.439 | Acc: 51.840,78.545,97.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.438 | Acc: 51.898,78.536,97.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.437 | Acc: 51.908,78.505,97.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.437 | Acc: 51.959,78.478,97.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.438 | Acc: 51.913,78.426,97.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.617 | Acc: 46.094,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 48.028,66.034,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.004 | Acc: 47.542,65.358,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.018 | Acc: 47.131,65.023,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.367 | Acc: 54.688,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.470 | Acc: 51.004,77.827,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.428 | Acc: 51.886,78.563,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.433 | Acc: 52.280,78.548,97.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.441 | Acc: 51.997,78.328,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.436 | Acc: 52.166,78.434,97.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.436 | Acc: 52.066,78.467,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 52.039,78.557,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.443 | Acc: 51.965,78.300,97.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.443 | Acc: 51.895,78.311,97.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.439 | Acc: 52.064,78.358,97.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.438 | Acc: 52.054,78.404,97.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.437 | Acc: 51.919,78.401,97.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.441 | Acc: 51.883,78.332,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.440 | Acc: 51.882,78.292,97.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.445 | Acc: 51.796,78.159,97.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.445 | Acc: 51.850,78.142,97.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.446 | Acc: 51.808,78.148,97.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.448 | Acc: 51.679,78.138,97.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.449 | Acc: 51.634,78.113,97.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.628 | Acc: 46.875,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.947 | Acc: 47.991,66.778,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.995 | Acc: 47.866,65.854,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.010 | Acc: 47.439,65.356,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.355 | Acc: 51.562,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.457 | Acc: 51.116,78.013,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.424 | Acc: 52.268,79.059,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.428 | Acc: 52.561,78.663,97.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.425 | Acc: 52.672,78.713,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 52.645,78.427,97.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.432 | Acc: 52.615,78.390,97.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.437 | Acc: 52.238,78.308,97.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.443 | Acc: 52.145,78.207,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.444 | Acc: 52.184,78.099,97.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.444 | Acc: 52.091,78.141,97.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.448 | Acc: 51.980,78.100,97.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.445 | Acc: 52.097,78.115,97.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.446 | Acc: 52.065,78.050,97.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.447 | Acc: 52.057,78.022,97.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.449 | Acc: 51.999,78.029,97.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.448 | Acc: 51.974,78.106,97.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.449 | Acc: 51.998,78.120,97.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.448 | Acc: 51.965,78.095,97.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.449 | Acc: 51.987,78.057,97.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.620 | Acc: 46.094,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 47.879,66.629,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.998 | Acc: 47.428,65.739,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 47.195,65.292,70.569,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.697 | Acc: 44.531,71.875,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.450 | Acc: 52.232,77.381,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.436 | Acc: 52.534,77.744,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.425 | Acc: 52.523,78.176,97.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.427 | Acc: 52.247,78.356,97.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.429 | Acc: 52.019,78.287,97.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.431 | Acc: 52.008,78.435,97.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.433 | Acc: 51.928,78.385,97.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.432 | Acc: 52.067,78.455,97.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.431 | Acc: 52.175,78.535,97.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.431 | Acc: 52.204,78.486,97.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.428 | Acc: 52.344,78.496,97.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.431 | Acc: 52.237,78.475,97.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.430 | Acc: 52.182,78.463,97.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.433 | Acc: 52.060,78.431,97.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.435 | Acc: 51.991,78.343,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.437 | Acc: 51.908,78.259,97.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.440 | Acc: 51.840,78.159,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.439 | Acc: 51.852,78.216,97.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.440 | Acc: 51.774,78.219,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.615 | Acc: 46.875,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 48.363,66.592,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.000 | Acc: 47.732,65.644,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.012 | Acc: 47.362,65.330,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.660 | Acc: 50.000,73.438,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.454 | Acc: 52.083,78.051,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.449 | Acc: 51.658,78.411,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.453 | Acc: 51.627,78.304,97.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.442 | Acc: 51.842,78.289,97.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.442 | Acc: 51.895,78.373,97.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.440 | Acc: 51.943,78.448,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 51.873,78.280,97.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.437 | Acc: 52.038,78.207,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.438 | Acc: 52.154,78.216,97.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.438 | Acc: 52.165,78.199,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.437 | Acc: 52.220,78.217,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.437 | Acc: 52.240,78.258,97.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.437 | Acc: 52.194,78.191,97.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.439 | Acc: 52.163,78.189,97.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.440 | Acc: 52.268,78.325,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.439 | Acc: 52.263,78.288,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.439 | Acc: 52.190,78.272,97.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.440 | Acc: 52.186,78.201,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.441 | Acc: 52.073,78.143,97.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.635 | Acc: 45.312,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.948 | Acc: 48.140,66.406,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.999 | Acc: 47.580,65.511,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.015 | Acc: 47.298,65.228,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.282 | Acc: 61.719,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.438 | Acc: 52.493,77.604,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.448 | Acc: 51.810,78.068,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.452 | Acc: 51.550,77.920,97.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.444 | Acc: 51.765,77.922,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.452 | Acc: 51.663,77.808,97.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.452 | Acc: 51.414,77.751,97.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.451 | Acc: 51.568,77.798,97.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.451 | Acc: 51.431,77.829,97.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.449 | Acc: 51.364,77.905,97.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.447 | Acc: 51.419,77.989,97.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.446 | Acc: 51.545,78.132,97.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.445 | Acc: 51.699,78.170,97.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.444 | Acc: 51.751,78.155,97.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.443 | Acc: 51.802,78.206,97.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.445 | Acc: 51.825,78.096,97.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.445 | Acc: 51.803,78.130,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 51.801,78.111,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.443 | Acc: 51.785,78.123,97.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.443 | Acc: 51.802,78.152,97.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.604 | Acc: 46.094,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 47.842,65.885,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.008 | Acc: 47.428,65.454,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.024 | Acc: 47.208,65.100,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.384 | Acc: 51.562,78.906,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.426 | Acc: 51.488,79.464,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.416 | Acc: 51.715,79.459,97.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.421 | Acc: 51.716,78.906,97.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.424 | Acc: 51.389,78.713,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.430 | Acc: 51.555,78.535,97.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.438 | Acc: 51.427,78.177,97.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.442 | Acc: 51.291,77.953,97.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.442 | Acc: 51.402,78.033,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.439 | Acc: 51.770,78.073,97.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.442 | Acc: 51.679,78.051,97.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.442 | Acc: 51.577,77.962,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.442 | Acc: 51.618,78.028,97.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.445 | Acc: 51.604,77.972,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.444 | Acc: 51.768,77.972,97.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.443 | Acc: 51.822,78.006,97.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.442 | Acc: 51.884,78.076,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.442 | Acc: 51.872,78.095,97.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.442 | Acc: 51.887,78.119,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.444 | Acc: 51.891,78.049,97.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.630 | Acc: 45.312,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 47.991,66.369,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.000 | Acc: 47.370,65.587,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 47.118,65.228,70.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.200 | Acc: 56.250,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.425 | Acc: 52.976,78.906,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.447 | Acc: 52.020,77.992,97.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.453 | Acc: 52.241,77.894,97.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.444 | Acc: 52.431,77.720,97.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.451 | Acc: 52.406,77.715,97.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.445 | Acc: 52.576,77.873,97.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.441 | Acc: 52.715,77.937,97.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.439 | Acc: 52.693,78.091,97.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.436 | Acc: 52.676,78.194,97.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.443 | Acc: 52.515,78.183,97.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.445 | Acc: 52.467,78.107,97.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.445 | Acc: 52.396,78.119,97.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.443 | Acc: 52.365,78.167,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.441 | Acc: 52.388,78.197,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.440 | Acc: 52.354,78.229,97.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.440 | Acc: 52.322,78.278,97.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.442 | Acc: 52.193,78.265,97.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.443 | Acc: 52.086,78.251,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.443 | Acc: 52.063,78.209,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.629 | Acc: 46.094,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.937 | Acc: 47.879,66.518,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.986 | Acc: 47.428,65.511,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.005 | Acc: 47.131,65.126,70.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.431 | Acc: 57.812,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.410 | Acc: 52.121,79.576,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.448 | Acc: 51.486,78.335,97.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.443 | Acc: 52.024,78.535,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.443 | Acc: 51.871,78.337,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.446 | Acc: 51.702,78.055,97.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.444 | Acc: 51.879,78.119,97.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.440 | Acc: 51.984,78.119,97.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.441 | Acc: 52.067,78.193,97.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.443 | Acc: 52.016,78.155,97.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.447 | Acc: 51.788,78.078,97.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.444 | Acc: 51.976,78.153,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.444 | Acc: 51.948,78.154,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.444 | Acc: 51.970,78.158,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.444 | Acc: 52.030,78.147,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.443 | Acc: 52.167,78.164,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.445 | Acc: 52.139,78.159,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 52.115,78.212,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.444 | Acc: 52.039,78.205,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.446 | Acc: 51.971,78.170,97.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.650 | Acc: 47.656,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 47.879,66.629,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 47.466,65.587,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 47.195,65.215,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.582 | Acc: 45.312,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.474 | Acc: 50.930,77.790,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.464 | Acc: 51.677,78.411,97.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.475 | Acc: 51.204,77.613,97.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.480 | Acc: 51.177,77.373,97.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.471 | Acc: 51.400,77.382,97.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.463 | Acc: 51.743,77.673,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.459 | Acc: 51.878,77.787,97.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.454 | Acc: 52.028,77.955,97.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.452 | Acc: 51.981,78.021,97.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.450 | Acc: 52.060,77.946,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.448 | Acc: 52.135,78.015,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.446 | Acc: 52.120,78.067,97.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.446 | Acc: 52.026,78.212,97.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.443 | Acc: 52.052,78.275,97.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.442 | Acc: 52.095,78.330,97.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.439 | Acc: 52.181,78.344,97.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.440 | Acc: 52.128,78.279,97.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.441 | Acc: 52.099,78.253,97.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.440 | Acc: 52.174,78.287,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.617 | Acc: 49.219,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 48.065,66.369,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.000 | Acc: 47.637,65.549,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 47.259,65.254,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 1.538 | Acc: 50.781,78.125,97.656,% | Adaptive Acc: 91.406% | clf_exit: 0.273 0.422 0.305
Batch: 20 | Loss: 1.415 | Acc: 52.827,79.315,97.210,% | Adaptive Acc: 90.551% | clf_exit: 0.304 0.412 0.284
Batch: 40 | Loss: 1.445 | Acc: 52.420,79.021,97.008,% | Adaptive Acc: 89.958% | clf_exit: 0.310 0.399 0.291
Batch: 60 | Loss: 1.453 | Acc: 52.164,78.522,97.054,% | Adaptive Acc: 89.703% | clf_exit: 0.311 0.394 0.295
Batch: 80 | Loss: 1.447 | Acc: 52.440,78.742,97.116,% | Adaptive Acc: 89.747% | clf_exit: 0.314 0.393 0.293
Batch: 100 | Loss: 1.438 | Acc: 52.537,78.868,97.200,% | Adaptive Acc: 89.975% | clf_exit: 0.313 0.392 0.295
Batch: 120 | Loss: 1.444 | Acc: 52.363,78.648,97.191,% | Adaptive Acc: 89.786% | clf_exit: 0.312 0.392 0.296
Batch: 140 | Loss: 1.452 | Acc: 52.078,78.502,97.169,% | Adaptive Acc: 89.683% | clf_exit: 0.311 0.392 0.298
Batch: 160 | Loss: 1.451 | Acc: 51.941,78.343,97.263,% | Adaptive Acc: 89.635% | clf_exit: 0.311 0.391 0.298
Batch: 180 | Loss: 1.452 | Acc: 51.813,78.319,97.315,% | Adaptive Acc: 89.680% | clf_exit: 0.310 0.391 0.299
Batch: 200 | Loss: 1.451 | Acc: 51.908,78.300,97.310,% | Adaptive Acc: 89.657% | clf_exit: 0.312 0.390 0.298
Batch: 220 | Loss: 1.449 | Acc: 52.004,78.351,97.292,% | Adaptive Acc: 89.685% | clf_exit: 0.313 0.390 0.298
Batch: 240 | Loss: 1.449 | Acc: 51.942,78.391,97.306,% | Adaptive Acc: 89.581% | clf_exit: 0.313 0.389 0.297
Batch: 260 | Loss: 1.447 | Acc: 51.967,78.338,97.288,% | Adaptive Acc: 89.622% | clf_exit: 0.313 0.390 0.297
Batch: 280 | Loss: 1.446 | Acc: 52.007,78.336,97.284,% | Adaptive Acc: 89.621% | clf_exit: 0.313 0.391 0.297
Batch: 300 | Loss: 1.446 | Acc: 51.957,78.278,97.272,% | Adaptive Acc: 89.605% | clf_exit: 0.313 0.391 0.297
Batch: 320 | Loss: 1.445 | Acc: 51.998,78.298,97.262,% | Adaptive Acc: 89.596% | clf_exit: 0.313 0.391 0.296
Batch: 340 | Loss: 1.444 | Acc: 52.048,78.347,97.248,% | Adaptive Acc: 89.550% | clf_exit: 0.313 0.391 0.296
Batch: 360 | Loss: 1.444 | Acc: 51.991,78.354,97.260,% | Adaptive Acc: 89.541% | clf_exit: 0.313 0.391 0.296
Batch: 380 | Loss: 1.444 | Acc: 52.046,78.312,97.271,% | Adaptive Acc: 89.544% | clf_exit: 0.313 0.390 0.296
Batch: 0 | Loss: 2.647 | Acc: 46.094,68.750,77.344,% | Adaptive Acc: 70.312% | clf_exit: 0.391 0.383 0.227
Batch: 20 | Loss: 2.952 | Acc: 47.693,66.443,70.982,% | Adaptive Acc: 67.746% | clf_exit: 0.377 0.342 0.281
Batch: 40 | Loss: 2.996 | Acc: 47.428,65.682,70.655,% | Adaptive Acc: 67.054% | clf_exit: 0.372 0.340 0.288
Batch: 60 | Loss: 3.012 | Acc: 47.131,65.369,70.428,% | Adaptive Acc: 66.829% | clf_exit: 0.371 0.339 0.290
model is save as models/resnet56_2con3_conv_cifar100_adaptive0_circles0_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 2.647 | Acc: 46.094,68.750,77.344,% | Adaptive Acc: 70.312% | clf_exit: 0.391 0.383 0.227
Batch: 20 | Loss: 2.952 | Acc: 47.693,66.443,70.982,% | Adaptive Acc: 67.746% | clf_exit: 0.377 0.342 0.281
Batch: 40 | Loss: 2.996 | Acc: 47.428,65.682,70.655,% | Adaptive Acc: 67.054% | clf_exit: 0.372 0.340 0.288
Batch: 60 | Loss: 3.012 | Acc: 47.131,65.369,70.428,% | Adaptive Acc: 66.829% | clf_exit: 0.371 0.339 0.290







Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 8.565 |  Acc: 4.094,4.984,7.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 8.064 |  Acc: 5.890,7.770,10.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 7.688 |  Acc: 7.794,9.850,14.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 7.449 |  Acc: 8.390,11.450,15.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 7.219 |  Acc: 10.536,12.994,18.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 7.188 |  Acc: 10.470,11.980,17.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 6.821 |  Acc: 13.004,16.124,22.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 6.650 |  Acc: 13.360,16.540,23.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 6.478 |  Acc: 15.302,19.130,25.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 6.526 |  Acc: 12.730,17.010,24.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 6.157 |  Acc: 17.368,21.614,29.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 6.093 |  Acc: 16.780,21.950,29.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 5.875 |  Acc: 19.236,24.102,32.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 5.972 |  Acc: 16.810,22.220,31.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 5.642 |  Acc: 20.896,26.284,34.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 5.842 |  Acc: 17.200,23.090,32.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 5.421 |  Acc: 22.164,28.348,37.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 5.842 |  Acc: 16.050,23.260,33.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 5.239 |  Acc: 23.588,29.960,39.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 5.462 |  Acc: 21.790,28.710,37.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 5.075 |  Acc: 24.512,31.716,41.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 5.390 |  Acc: 19.580,27.060,38.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 4.926 |  Acc: 25.388,33.092,43.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 5.520 |  Acc: 21.810,26.630,35.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 4.793 |  Acc: 26.276,34.716,45.060,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 5.728 |  Acc: 19.610,26.690,37.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 4.686 |  Acc: 27.094,35.774,46.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 5.640 |  Acc: 20.160,26.430,38.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 4.562 |  Acc: 27.966,37.364,48.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 5.044 |  Acc: 24.270,31.670,43.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 4.478 |  Acc: 28.490,38.500,49.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 5.044 |  Acc: 23.780,32.720,42.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 4.384 |  Acc: 29.230,39.710,50.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 5.021 |  Acc: 24.100,33.390,44.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 4.295 |  Acc: 30.102,40.854,51.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 4.712 |  Acc: 25.460,35.420,47.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.215 |  Acc: 30.612,41.824,52.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 5.131 |  Acc: 23.520,32.160,43.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.157 |  Acc: 30.996,42.540,52.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 4.979 |  Acc: 23.630,32.310,46.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.077 |  Acc: 31.612,43.778,54.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 4.739 |  Acc: 26.020,34.500,47.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.012 |  Acc: 32.170,44.334,54.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 4.769 |  Acc: 24.230,35.230,49.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 3.956 |  Acc: 32.654,45.300,55.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 4.662 |  Acc: 27.870,36.080,48.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 3.898 |  Acc: 32.952,45.894,56.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 4.727 |  Acc: 25.120,37.700,49.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 3.853 |  Acc: 33.320,46.546,56.994,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 4.636 |  Acc: 25.550,37.220,49.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 3.808 |  Acc: 33.580,47.166,57.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 4.669 |  Acc: 23.790,38.040,50.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 3.778 |  Acc: 33.948,47.786,57.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 4.795 |  Acc: 24.230,36.250,47.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 3.724 |  Acc: 34.356,48.392,58.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 4.235 |  Acc: 30.480,41.630,52.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 3.678 |  Acc: 34.560,49.038,59.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 4.272 |  Acc: 28.130,41.290,52.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 3.642 |  Acc: 34.734,49.128,59.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 4.557 |  Acc: 26.240,38.560,49.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 3.590 |  Acc: 35.790,50.066,60.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 4.539 |  Acc: 25.180,38.290,50.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 3.582 |  Acc: 35.408,50.074,60.524,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 4.341 |  Acc: 27.620,42.160,52.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 3.549 |  Acc: 35.630,50.264,61.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 4.500 |  Acc: 26.100,41.220,51.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 3.512 |  Acc: 35.938,51.052,61.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 4.214 |  Acc: 28.500,43.670,53.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 3.500 |  Acc: 36.076,51.374,61.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 4.147 |  Acc: 29.190,44.880,54.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.465 |  Acc: 36.226,51.678,62.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 4.873 |  Acc: 26.280,37.220,47.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.441 |  Acc: 36.592,51.972,62.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 4.000 |  Acc: 31.910,46.390,54.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.415 |  Acc: 36.354,52.418,63.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 4.243 |  Acc: 28.670,41.780,54.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.392 |  Acc: 36.664,52.602,63.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 4.643 |  Acc: 23.110,42.060,52.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.359 |  Acc: 36.964,53.066,64.006,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 4.205 |  Acc: 28.170,44.200,53.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.356 |  Acc: 37.138,53.216,63.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 4.137 |  Acc: 29.940,44.000,55.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.333 |  Acc: 37.242,53.292,64.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 4.508 |  Acc: 28.730,41.000,50.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.312 |  Acc: 37.274,53.834,64.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 4.169 |  Acc: 28.570,44.340,55.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.294 |  Acc: 37.574,54.056,64.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 4.501 |  Acc: 28.040,40.860,51.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.271 |  Acc: 37.550,54.342,65.138,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 4.094 |  Acc: 29.230,46.550,56.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.261 |  Acc: 37.644,54.420,65.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 4.206 |  Acc: 26.940,43.460,53.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.244 |  Acc: 37.932,54.484,65.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 4.106 |  Acc: 29.160,45.820,54.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.231 |  Acc: 37.872,54.980,65.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 4.245 |  Acc: 24.020,45.420,56.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.207 |  Acc: 38.238,55.196,66.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 4.092 |  Acc: 27.940,45.780,56.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.205 |  Acc: 38.214,55.260,65.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 4.379 |  Acc: 23.090,43.580,54.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.177 |  Acc: 38.206,55.674,66.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 4.350 |  Acc: 24.910,44.160,55.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.162 |  Acc: 38.486,55.882,66.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 4.176 |  Acc: 26.960,44.590,56.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.167 |  Acc: 38.430,55.670,66.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 4.345 |  Acc: 26.080,44.940,54.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.129 |  Acc: 38.548,56.312,67.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 4.329 |  Acc: 29.990,42.670,53.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.127 |  Acc: 38.772,56.144,67.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 4.182 |  Acc: 26.540,46.210,56.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.111 |  Acc: 38.710,56.562,67.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 4.366 |  Acc: 24.380,44.430,56.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.100 |  Acc: 38.898,56.688,67.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 4.231 |  Acc: 24.800,45.890,57.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.092 |  Acc: 38.862,56.692,67.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 4.024 |  Acc: 25.180,47.600,59.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.078 |  Acc: 38.934,56.546,67.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 4.526 |  Acc: 24.880,42.200,52.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.075 |  Acc: 38.910,56.698,68.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 3.990 |  Acc: 29.970,46.870,57.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.050 |  Acc: 39.354,57.044,68.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 4.137 |  Acc: 30.250,46.430,55.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.059 |  Acc: 39.328,57.188,68.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 3.933 |  Acc: 27.740,47.530,59.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.040 |  Acc: 39.360,57.560,68.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 4.433 |  Acc: 25.970,42.500,54.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.030 |  Acc: 39.262,57.488,69.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 4.306 |  Acc: 25.490,44.950,56.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.019 |  Acc: 39.058,57.702,69.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 4.541 |  Acc: 28.320,40.660,54.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.007 |  Acc: 39.484,57.766,68.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 3.992 |  Acc: 28.810,47.350,58.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.004 |  Acc: 39.696,57.984,69.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 4.202 |  Acc: 27.110,44.440,55.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 2.995 |  Acc: 39.808,57.970,69.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 4.577 |  Acc: 23.830,42.970,54.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 2.980 |  Acc: 39.550,58.156,69.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 4.131 |  Acc: 30.360,46.720,54.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 2.975 |  Acc: 40.086,58.156,69.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 3.870 |  Acc: 28.610,50.270,59.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 2.965 |  Acc: 39.868,58.230,70.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 4.090 |  Acc: 28.190,48.080,56.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 2.968 |  Acc: 40.020,57.974,69.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 3.971 |  Acc: 28.770,48.670,57.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 2.951 |  Acc: 40.082,58.682,69.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 4.413 |  Acc: 24.720,44.110,54.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 2.954 |  Acc: 39.918,58.416,70.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 4.794 |  Acc: 24.180,40.810,52.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 2.930 |  Acc: 40.160,58.642,70.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 3.844 |  Acc: 30.520,50.410,57.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 2.917 |  Acc: 40.028,58.848,70.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 4.537 |  Acc: 27.710,42.260,53.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 2.925 |  Acc: 40.262,58.754,70.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 4.469 |  Acc: 23.810,42.600,54.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 2.907 |  Acc: 40.374,59.032,70.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 3.875 |  Acc: 31.250,48.290,58.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 2.895 |  Acc: 40.472,59.510,70.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 4.309 |  Acc: 24.390,44.820,56.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 2.896 |  Acc: 40.458,59.276,70.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 3.986 |  Acc: 28.420,49.820,59.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 2.882 |  Acc: 40.418,59.406,71.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 3.866 |  Acc: 29.390,50.420,59.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 2.883 |  Acc: 40.436,59.684,71.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 4.383 |  Acc: 21.060,48.250,58.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 2.887 |  Acc: 40.388,59.246,71.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 4.188 |  Acc: 26.790,46.580,56.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 2.871 |  Acc: 40.590,59.618,71.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 4.055 |  Acc: 31.200,46.990,56.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 2.861 |  Acc: 40.694,59.714,71.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 5.132 |  Acc: 19.480,38.950,54.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 2.861 |  Acc: 40.618,59.750,71.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 4.109 |  Acc: 30.670,46.790,57.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 2.865 |  Acc: 40.674,59.328,71.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 3.987 |  Acc: 28.420,48.650,58.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 2.853 |  Acc: 40.852,59.876,71.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 3.812 |  Acc: 32.340,48.930,59.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 2.840 |  Acc: 41.020,59.986,71.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 3.969 |  Acc: 28.870,46.840,59.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 2.845 |  Acc: 40.916,59.946,71.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 3.844 |  Acc: 27.530,49.200,60.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 2.825 |  Acc: 40.830,60.318,71.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 4.028 |  Acc: 30.870,47.540,57.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 2.830 |  Acc: 41.028,60.044,71.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 3.849 |  Acc: 30.640,50.250,59.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 2.830 |  Acc: 40.960,59.966,71.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 3.977 |  Acc: 29.930,48.470,58.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 2.819 |  Acc: 41.010,60.098,72.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 3.766 |  Acc: 31.960,51.900,59.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 2.809 |  Acc: 41.182,60.300,71.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 4.025 |  Acc: 28.390,47.280,58.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 2.814 |  Acc: 41.168,60.352,71.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 4.244 |  Acc: 26.020,42.950,56.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 2.791 |  Acc: 41.266,60.468,72.508,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 4.587 |  Acc: 23.570,42.090,56.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 2.809 |  Acc: 41.394,60.480,72.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 4.850 |  Acc: 19.100,40.400,55.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 2.797 |  Acc: 41.096,60.564,72.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 3.590 |  Acc: 33.650,52.670,60.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 2.792 |  Acc: 41.310,60.706,72.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 4.565 |  Acc: 19.710,43.660,55.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 2.782 |  Acc: 41.300,60.712,72.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 4.083 |  Acc: 24.900,49.500,58.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 2.793 |  Acc: 41.176,60.826,72.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 3.781 |  Acc: 29.830,49.510,61.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 2.773 |  Acc: 41.490,60.940,72.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 3.956 |  Acc: 28.600,50.370,59.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.777 |  Acc: 41.532,60.696,72.304,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 4.184 |  Acc: 24.890,46.500,58.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.772 |  Acc: 41.516,60.816,72.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 4.220 |  Acc: 23.910,46.990,59.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.765 |  Acc: 41.406,61.142,72.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 3.957 |  Acc: 28.350,48.340,59.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.768 |  Acc: 41.564,60.956,72.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 4.554 |  Acc: 23.030,42.790,55.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.759 |  Acc: 41.722,61.154,72.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 4.405 |  Acc: 19.280,47.450,56.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.760 |  Acc: 41.604,61.146,72.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 4.373 |  Acc: 21.180,46.150,59.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.756 |  Acc: 41.410,61.070,72.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 4.025 |  Acc: 28.370,47.030,58.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.745 |  Acc: 41.936,61.220,72.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 4.514 |  Acc: 24.520,43.890,55.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 2.747 |  Acc: 42.116,61.082,73.140,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 3.886 |  Acc: 31.930,49.690,59.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.734 |  Acc: 41.928,61.418,73.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 5.210 |  Acc: 16.970,36.010,52.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.741 |  Acc: 41.572,61.206,73.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 4.643 |  Acc: 26.350,42.680,54.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.738 |  Acc: 41.426,61.256,73.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 3.941 |  Acc: 28.270,49.230,59.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.735 |  Acc: 41.770,61.296,73.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 4.699 |  Acc: 21.070,45.160,53.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 2.736 |  Acc: 41.854,61.436,73.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 4.374 |  Acc: 22.540,47.550,57.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 2.714 |  Acc: 41.776,61.308,73.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 5.231 |  Acc: 16.310,41.010,51.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 2.728 |  Acc: 41.988,61.270,73.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 4.560 |  Acc: 23.450,45.770,55.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 2.723 |  Acc: 41.864,61.454,73.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 4.106 |  Acc: 24.710,49.270,58.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 2.714 |  Acc: 42.020,61.350,73.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 3.818 |  Acc: 30.500,51.490,61.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 2.709 |  Acc: 41.800,61.642,73.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 4.748 |  Acc: 18.560,44.230,57.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 2.699 |  Acc: 41.882,61.802,73.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 4.164 |  Acc: 28.770,46.490,57.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 2.721 |  Acc: 42.140,61.630,73.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 4.380 |  Acc: 24.770,47.380,56.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 2.707 |  Acc: 42.000,61.732,73.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 4.145 |  Acc: 28.090,47.950,58.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 2.705 |  Acc: 42.326,61.682,73.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 4.123 |  Acc: 28.150,46.680,58.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 2.698 |  Acc: 41.932,61.878,73.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 4.035 |  Acc: 31.360,48.960,56.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 2.699 |  Acc: 42.250,61.552,74.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 4.046 |  Acc: 28.590,48.430,59.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 2.693 |  Acc: 42.194,61.662,73.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 4.072 |  Acc: 24.640,49.710,59.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 2.672 |  Acc: 42.332,61.878,74.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 4.142 |  Acc: 28.600,48.070,58.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 2.689 |  Acc: 42.340,61.774,73.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 4.394 |  Acc: 26.090,45.810,56.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 2.689 |  Acc: 42.244,62.046,73.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 4.403 |  Acc: 24.780,44.080,57.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 2.686 |  Acc: 42.172,61.800,73.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 4.035 |  Acc: 26.910,48.880,58.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 2.674 |  Acc: 42.070,62.208,74.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 3.884 |  Acc: 30.070,48.860,58.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 2.687 |  Acc: 42.316,61.874,73.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 3.853 |  Acc: 30.430,48.230,60.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 2.681 |  Acc: 42.232,62.042,74.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 4.406 |  Acc: 23.870,46.910,56.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 2.666 |  Acc: 42.376,62.106,74.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 4.064 |  Acc: 28.150,48.390,59.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 2.675 |  Acc: 42.412,62.170,73.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 4.462 |  Acc: 22.320,47.040,58.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 2.675 |  Acc: 42.306,62.102,73.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 3.871 |  Acc: 29.740,51.870,59.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 2.657 |  Acc: 42.662,62.126,74.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 5.472 |  Acc: 20.370,38.220,51.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 2.674 |  Acc: 42.354,62.182,74.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 3.884 |  Acc: 26.590,49.970,60.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 2.656 |  Acc: 42.504,62.318,74.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 4.818 |  Acc: 22.580,42.760,54.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 2.668 |  Acc: 42.622,62.000,74.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 4.522 |  Acc: 22.230,43.530,56.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 2.659 |  Acc: 42.684,62.302,74.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 4.238 |  Acc: 28.930,44.590,56.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 2.638 |  Acc: 42.924,62.516,74.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 3.940 |  Acc: 29.070,51.690,60.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 2.648 |  Acc: 42.578,62.510,74.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 4.323 |  Acc: 23.190,47.530,58.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 2.636 |  Acc: 42.768,62.468,74.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 3.992 |  Acc: 30.680,49.530,58.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 2.634 |  Acc: 42.770,62.362,74.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 3.952 |  Acc: 28.200,49.990,59.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 2.642 |  Acc: 42.862,62.520,74.596,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 4.702 |  Acc: 18.950,44.010,58.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 2.633 |  Acc: 43.118,62.484,74.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 4.440 |  Acc: 20.820,46.160,59.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.193 |  Acc: 46.994,68.562,82.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 2.750 |  Acc: 44.470,62.820,71.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.053 |  Acc: 47.784,70.314,85.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 2.751 |  Acc: 44.940,63.240,71.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 2.005 |  Acc: 48.032,70.752,86.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 2.747 |  Acc: 45.010,63.390,71.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.976 |  Acc: 48.132,71.038,86.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 2.754 |  Acc: 45.150,63.820,71.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.948 |  Acc: 48.440,71.486,87.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 2.761 |  Acc: 45.890,63.700,71.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.926 |  Acc: 48.540,71.626,87.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 2.770 |  Acc: 45.380,63.770,71.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.911 |  Acc: 48.718,71.818,88.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 2.777 |  Acc: 45.530,63.940,71.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.891 |  Acc: 48.874,72.004,88.554,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 2.778 |  Acc: 45.730,64.050,71.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.880 |  Acc: 48.726,72.124,88.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 2.804 |  Acc: 45.700,63.420,71.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.867 |  Acc: 48.932,72.252,89.154,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 2.806 |  Acc: 45.130,64.030,71.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.857 |  Acc: 48.834,72.148,89.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 2.806 |  Acc: 45.680,63.960,71.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.853 |  Acc: 48.818,72.232,89.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 2.834 |  Acc: 45.260,64.150,70.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.834 |  Acc: 48.792,72.458,89.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 2.838 |  Acc: 45.490,63.520,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.825 |  Acc: 48.896,72.576,90.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 2.820 |  Acc: 45.540,64.280,70.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.819 |  Acc: 49.096,72.808,89.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 2.831 |  Acc: 45.270,64.150,70.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.815 |  Acc: 49.178,72.676,90.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 2.843 |  Acc: 45.420,64.360,71.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.801 |  Acc: 49.208,73.020,90.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 2.857 |  Acc: 45.750,64.080,70.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.796 |  Acc: 49.154,72.932,90.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 2.871 |  Acc: 45.480,63.620,70.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.787 |  Acc: 49.342,73.134,90.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 2.872 |  Acc: 45.420,63.880,70.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.782 |  Acc: 49.516,73.160,90.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 2.892 |  Acc: 44.820,63.770,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.775 |  Acc: 49.550,73.148,91.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 2.906 |  Acc: 45.500,63.850,70.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.770 |  Acc: 49.656,73.176,91.172,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 2.852 |  Acc: 45.970,64.400,70.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.765 |  Acc: 49.526,73.218,91.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 2.896 |  Acc: 45.420,64.480,70.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.754 |  Acc: 49.368,73.500,91.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 2.929 |  Acc: 45.770,63.830,70.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.756 |  Acc: 49.538,73.538,91.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 2.879 |  Acc: 45.890,64.750,70.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.746 |  Acc: 49.730,73.394,91.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 2.960 |  Acc: 44.170,63.230,70.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.745 |  Acc: 49.596,73.258,91.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 2.919 |  Acc: 45.440,63.740,70.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.740 |  Acc: 49.526,73.560,91.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 2.930 |  Acc: 45.330,64.190,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.735 |  Acc: 49.680,73.676,91.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 2.931 |  Acc: 45.890,64.030,70.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.730 |  Acc: 49.640,73.618,91.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 2.981 |  Acc: 44.610,63.760,70.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.723 |  Acc: 49.742,73.778,91.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 2.977 |  Acc: 44.130,63.350,70.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.725 |  Acc: 49.572,73.760,91.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 2.935 |  Acc: 45.600,64.310,70.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.713 |  Acc: 49.762,73.984,92.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 2.928 |  Acc: 45.760,63.970,70.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.717 |  Acc: 49.732,73.884,92.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 3.010 |  Acc: 43.700,63.170,70.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.711 |  Acc: 49.744,73.772,92.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 2.930 |  Acc: 45.930,64.290,70.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.705 |  Acc: 49.694,73.942,92.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 2.940 |  Acc: 45.970,64.170,69.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.707 |  Acc: 49.820,73.912,92.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 3.019 |  Acc: 43.920,63.420,69.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.697 |  Acc: 49.866,73.864,92.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 2.982 |  Acc: 45.450,63.840,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.704 |  Acc: 50.020,73.846,92.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 3.004 |  Acc: 46.390,63.640,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.696 |  Acc: 49.928,73.930,92.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 2.962 |  Acc: 45.910,64.100,70.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.694 |  Acc: 49.930,74.108,92.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 2.971 |  Acc: 46.340,63.780,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.687 |  Acc: 50.034,74.284,92.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 2.956 |  Acc: 45.890,64.680,69.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.690 |  Acc: 49.900,74.322,92.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 2.990 |  Acc: 45.980,63.970,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.684 |  Acc: 49.784,74.252,92.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 2.990 |  Acc: 45.440,64.090,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.679 |  Acc: 50.134,74.090,92.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 3.023 |  Acc: 45.750,63.660,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.679 |  Acc: 49.962,74.272,92.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 3.031 |  Acc: 44.530,63.580,69.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.677 |  Acc: 49.816,74.206,92.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 2.987 |  Acc: 45.350,63.900,69.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.671 |  Acc: 50.296,74.320,92.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 3.006 |  Acc: 45.050,64.140,69.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.669 |  Acc: 50.212,74.284,93.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 2.998 |  Acc: 45.590,63.880,69.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.670 |  Acc: 50.136,74.374,93.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 2.986 |  Acc: 45.470,64.460,69.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.670 |  Acc: 50.040,74.456,92.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 3.050 |  Acc: 45.310,63.880,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.671 |  Acc: 49.972,74.234,92.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 3.038 |  Acc: 45.140,63.440,69.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.672 |  Acc: 50.028,74.488,92.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 3.057 |  Acc: 45.530,63.310,68.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.663 |  Acc: 50.408,74.474,93.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 3.022 |  Acc: 46.010,64.060,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.664 |  Acc: 50.222,74.450,93.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 2.986 |  Acc: 45.700,64.000,69.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.660 |  Acc: 50.234,74.470,93.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 3.112 |  Acc: 43.120,63.280,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.667 |  Acc: 50.094,74.306,92.944,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 3.040 |  Acc: 45.350,63.920,69.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.658 |  Acc: 50.124,74.540,93.090,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 3.026 |  Acc: 45.450,63.520,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.656 |  Acc: 50.110,74.680,93.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 3.076 |  Acc: 45.880,64.010,69.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.659 |  Acc: 50.134,74.512,93.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 3.079 |  Acc: 44.700,63.710,69.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.649 |  Acc: 50.310,74.432,93.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 3.104 |  Acc: 44.480,63.110,68.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.653 |  Acc: 50.240,74.400,93.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 3.063 |  Acc: 46.080,63.880,69.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.661 |  Acc: 50.066,74.446,93.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 3.082 |  Acc: 45.240,63.000,68.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.655 |  Acc: 50.326,74.608,93.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 3.050 |  Acc: 46.110,63.970,68.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.653 |  Acc: 50.394,74.876,93.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 3.128 |  Acc: 43.650,63.200,68.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.651 |  Acc: 50.330,74.720,93.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 3.148 |  Acc: 45.010,62.910,68.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.644 |  Acc: 50.374,74.598,93.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 3.142 |  Acc: 45.300,63.040,68.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.653 |  Acc: 50.374,74.620,93.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 3.050 |  Acc: 46.410,63.620,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.647 |  Acc: 50.350,74.744,93.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 3.007 |  Acc: 46.090,63.970,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.639 |  Acc: 50.352,74.608,93.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 3.188 |  Acc: 44.480,61.860,67.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.649 |  Acc: 50.414,74.656,93.190,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 3.114 |  Acc: 45.510,62.910,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.640 |  Acc: 50.264,74.640,93.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 3.111 |  Acc: 45.230,62.730,68.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.642 |  Acc: 50.378,74.604,93.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 3.121 |  Acc: 45.220,62.640,68.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.640 |  Acc: 50.596,74.770,93.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 3.077 |  Acc: 46.200,63.370,68.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.636 |  Acc: 50.264,74.932,93.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 3.170 |  Acc: 45.150,62.370,68.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.554 |  Acc: 51.172,76.394,95.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 2.937 |  Acc: 47.260,64.950,70.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.527 |  Acc: 51.164,76.654,95.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 2.932 |  Acc: 47.190,65.060,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.507 |  Acc: 51.390,77.210,96.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 2.949 |  Acc: 47.230,65.040,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.503 |  Acc: 51.486,77.394,96.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 2.946 |  Acc: 46.880,65.150,70.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.500 |  Acc: 51.492,77.306,96.322,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 2.935 |  Acc: 47.420,65.230,70.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.495 |  Acc: 51.530,77.264,96.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 2.952 |  Acc: 47.180,65.120,70.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.494 |  Acc: 51.652,77.186,96.322,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 2.946 |  Acc: 47.110,65.230,70.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.490 |  Acc: 51.692,77.388,96.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 2.960 |  Acc: 46.940,65.190,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.488 |  Acc: 51.654,77.352,96.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 2.952 |  Acc: 47.210,65.170,70.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.483 |  Acc: 51.642,77.222,96.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 2.959 |  Acc: 47.300,65.190,70.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.486 |  Acc: 51.586,77.366,96.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 2.967 |  Acc: 47.300,65.360,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.479 |  Acc: 51.570,77.506,96.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 2.970 |  Acc: 47.190,64.970,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.482 |  Acc: 51.654,77.438,96.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 2.970 |  Acc: 47.190,65.260,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.478 |  Acc: 51.736,77.576,96.636,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 2.979 |  Acc: 47.100,65.040,70.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.482 |  Acc: 51.816,77.238,96.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 2.979 |  Acc: 47.070,65.190,70.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.478 |  Acc: 51.776,77.430,96.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 2.973 |  Acc: 47.060,65.110,70.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.472 |  Acc: 51.690,77.460,96.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 2.975 |  Acc: 47.340,65.410,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.476 |  Acc: 51.596,77.682,96.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 2.983 |  Acc: 47.270,65.290,70.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.472 |  Acc: 51.790,77.788,96.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 2.979 |  Acc: 47.410,65.370,70.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.469 |  Acc: 51.784,77.686,96.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 2.974 |  Acc: 47.130,65.270,70.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.467 |  Acc: 51.678,77.606,96.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 2.995 |  Acc: 47.070,65.080,70.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.468 |  Acc: 51.698,77.612,96.940,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 2.991 |  Acc: 47.280,65.170,70.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.468 |  Acc: 51.770,77.388,96.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 2.989 |  Acc: 47.350,65.390,70.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.472 |  Acc: 51.494,77.776,96.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 2.994 |  Acc: 47.380,65.270,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.464 |  Acc: 51.650,77.682,97.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 2.991 |  Acc: 47.310,65.310,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.464 |  Acc: 51.628,77.912,96.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 2.983 |  Acc: 47.260,65.210,70.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.460 |  Acc: 51.930,77.944,97.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 2.995 |  Acc: 47.500,65.320,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.464 |  Acc: 51.688,77.720,96.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 3.005 |  Acc: 47.300,65.360,70.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.459 |  Acc: 52.000,77.900,97.038,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 2.995 |  Acc: 47.320,65.200,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.462 |  Acc: 51.758,77.676,96.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 3.009 |  Acc: 47.330,65.250,70.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.458 |  Acc: 51.756,77.838,97.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 3.000 |  Acc: 47.300,65.300,70.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.459 |  Acc: 51.458,77.940,97.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 3.003 |  Acc: 47.310,65.320,70.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.459 |  Acc: 51.834,77.966,97.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 3.007 |  Acc: 47.200,65.280,70.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.460 |  Acc: 51.630,77.776,97.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 3.009 |  Acc: 47.340,65.430,70.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.463 |  Acc: 51.768,77.640,97.036,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 3.006 |  Acc: 47.250,65.120,70.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.457 |  Acc: 51.856,77.920,96.986,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 3.004 |  Acc: 47.510,65.360,70.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.462 |  Acc: 51.912,77.818,96.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 3.015 |  Acc: 47.270,65.320,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.451 |  Acc: 51.890,77.984,97.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 3.016 |  Acc: 47.370,65.250,70.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.448 |  Acc: 52.096,78.058,97.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 2.996 |  Acc: 47.440,65.200,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.448 |  Acc: 52.012,77.898,97.238,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 3.012 |  Acc: 47.440,65.360,70.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.444 |  Acc: 51.974,78.388,97.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 3.002 |  Acc: 47.300,65.150,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.451 |  Acc: 51.990,78.018,97.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 3.003 |  Acc: 47.230,65.360,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.448 |  Acc: 51.774,78.080,97.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 3.017 |  Acc: 47.530,65.100,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.443 |  Acc: 52.052,78.146,97.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 3.006 |  Acc: 47.490,65.490,70.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.447 |  Acc: 52.188,77.938,97.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 3.010 |  Acc: 47.570,65.240,70.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.453 |  Acc: 52.024,77.766,97.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 3.002 |  Acc: 47.420,65.200,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.446 |  Acc: 52.120,78.192,97.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 3.007 |  Acc: 47.580,65.390,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.447 |  Acc: 51.944,78.060,97.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 3.015 |  Acc: 47.400,65.460,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.450 |  Acc: 51.734,78.258,97.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 2.999 |  Acc: 47.480,65.230,70.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.447 |  Acc: 51.796,78.076,97.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 3.008 |  Acc: 47.540,65.190,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.444 |  Acc: 51.994,78.236,97.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 3.007 |  Acc: 47.430,65.230,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.445 |  Acc: 51.980,78.024,97.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 3.013 |  Acc: 47.390,65.290,70.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.445 |  Acc: 52.118,77.920,97.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 3.005 |  Acc: 47.520,65.350,70.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.446 |  Acc: 51.938,78.230,97.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 3.004 |  Acc: 47.540,65.430,70.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.447 |  Acc: 51.958,78.028,97.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 3.013 |  Acc: 47.470,65.310,70.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.443 |  Acc: 51.968,78.080,97.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 3.006 |  Acc: 47.550,65.440,70.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.453 |  Acc: 51.854,77.856,97.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 3.005 |  Acc: 47.400,65.520,70.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.441 |  Acc: 51.978,78.260,97.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 3.009 |  Acc: 47.430,65.370,70.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.446 |  Acc: 51.958,78.184,97.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 3.004 |  Acc: 47.540,65.410,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.447 |  Acc: 51.924,78.240,97.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 3.013 |  Acc: 47.530,65.430,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.445 |  Acc: 52.160,78.180,97.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 3.006 |  Acc: 47.400,65.540,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.449 |  Acc: 51.792,77.968,97.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 3.006 |  Acc: 47.200,65.380,70.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.446 |  Acc: 52.054,78.146,97.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 3.006 |  Acc: 47.510,65.350,70.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.443 |  Acc: 52.050,78.214,97.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 3.016 |  Acc: 47.450,65.450,70.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.440 |  Acc: 51.862,78.376,97.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 3.009 |  Acc: 47.380,65.210,70.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.449 |  Acc: 51.698,78.180,97.230,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 3.003 |  Acc: 47.640,65.490,70.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.448 |  Acc: 51.986,78.058,97.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 3.010 |  Acc: 47.420,65.410,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.441 |  Acc: 51.766,78.248,97.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 3.004 |  Acc: 47.610,65.490,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.443 |  Acc: 52.026,78.148,97.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 3.011 |  Acc: 47.460,65.290,70.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.444 |  Acc: 51.802,78.118,97.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 3.017 |  Acc: 47.490,65.370,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.445 |  Acc: 51.892,78.072,97.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 3.008 |  Acc: 47.400,65.330,70.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.443 |  Acc: 52.032,78.200,97.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 2.998 |  Acc: 47.420,65.350,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.444 |  Acc: 52.064,78.220,97.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 3.007 |  Acc: 47.490,65.300,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.441 |  Acc: 52.134,78.300,97.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 3.004 |  Acc: 47.500,65.380,70.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.445 |  Acc: 52.006,78.280,97.274,% | Adaptive Acc:89.502% | clf_exit: 0.314 0.390 0.296
Testing: Epoch=299 | Loss: 3.004 |  Acc: 47.400,65.360,70.680,% | Adaptive Acc:66.910% | clf_exit: 0.372 0.339 0.289

circles: 0
Testing: Epoch=299 | Loss: 3.004 |  Acc: 47.400,65.360,70.680,% | Adaptive Acc:66.910% | clf_exit: 0.372 0.339 0.289
