==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (linear_h): Linear(in_features=64, out_features=64, bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (linear_h): Linear(in_features=128, out_features=80, bias=False)
      (linear): Linear(in_features=80, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x80])
      (linear_bw): Linear(in_features=80, out_features=128, bias=False)
      (BN1d): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=144, bias=False)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=144, out_features=100, bias=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 10.016 | Acc: 0.781,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.607 | Acc: 0.744,1.265,1.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.459 | Acc: 1.143,1.353,1.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.365 | Acc: 1.383,1.396,2.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.309 | Acc: 1.447,1.524,2.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.259 | Acc: 1.663,1.725,2.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.226 | Acc: 1.821,1.847,2.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.189 | Acc: 1.950,2.050,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.148 | Acc: 2.072,2.271,2.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.109 | Acc: 2.227,2.426,3.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.073 | Acc: 2.317,2.565,3.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.041 | Acc: 2.450,2.665,3.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.009 | Acc: 2.548,2.794,3.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.977 | Acc: 2.646,2.912,3.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.948 | Acc: 2.755,3.000,4.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.918 | Acc: 2.865,3.058,4.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.887 | Acc: 2.955,3.149,4.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.856 | Acc: 3.123,3.269,4.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.828 | Acc: 3.279,3.372,4.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.802 | Acc: 3.357,3.437,5.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.361 | Acc: 6.250,3.125,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.407 | Acc: 5.022,3.832,7.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.411 | Acc: 4.973,3.925,7.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.424 | Acc: 5.161,4.150,7.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 8.248 | Acc: 6.250,6.250,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.253 | Acc: 5.543,5.097,8.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.236 | Acc: 5.697,5.316,8.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.211 | Acc: 5.815,5.341,8.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.173 | Acc: 6.154,5.594,9.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.168 | Acc: 6.180,5.724,9.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.145 | Acc: 6.244,5.785,9.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.140 | Acc: 6.200,5.790,9.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.130 | Acc: 6.168,5.808,9.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.115 | Acc: 6.259,5.849,9.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.110 | Acc: 6.281,5.904,9.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.092 | Acc: 6.324,6.024,9.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.084 | Acc: 6.331,6.143,9.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.074 | Acc: 6.328,6.154,9.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.069 | Acc: 6.392,6.136,9.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.058 | Acc: 6.486,6.227,9.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.050 | Acc: 6.564,6.248,10.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.039 | Acc: 6.644,6.326,10.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.025 | Acc: 6.743,6.401,10.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.017 | Acc: 6.761,6.455,10.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.876 | Acc: 10.156,9.375,7.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.902 | Acc: 8.817,7.180,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.891 | Acc: 8.213,6.936,11.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.899 | Acc: 8.133,7.057,11.386,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 7.709 | Acc: 10.156,10.156,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.761 | Acc: 8.519,8.519,12.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.743 | Acc: 8.384,8.861,12.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.747 | Acc: 8.350,9.093,12.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.725 | Acc: 8.382,8.980,13.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.716 | Acc: 8.369,9.035,13.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.706 | Acc: 8.555,8.949,13.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.697 | Acc: 8.522,9.009,13.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.676 | Acc: 8.647,9.050,13.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.671 | Acc: 8.628,9.056,13.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.661 | Acc: 8.706,9.099,13.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.643 | Acc: 8.788,9.290,13.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.639 | Acc: 8.824,9.359,13.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.625 | Acc: 8.926,9.483,13.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.612 | Acc: 9.002,9.622,13.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.602 | Acc: 9.082,9.705,14.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.590 | Acc: 9.161,9.803,14.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.582 | Acc: 9.199,9.824,14.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.568 | Acc: 9.295,9.884,14.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.555 | Acc: 9.361,9.953,14.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.391 | Acc: 12.500,10.156,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.386 | Acc: 10.863,10.900,15.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.362 | Acc: 11.185,10.709,15.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.375 | Acc: 11.027,10.438,15.548,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 7.325 | Acc: 12.500,8.594,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.283 | Acc: 11.793,12.500,17.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.279 | Acc: 11.338,12.043,17.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.267 | Acc: 11.296,12.090,17.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.266 | Acc: 11.034,11.892,16.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.267 | Acc: 11.069,11.928,17.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.260 | Acc: 11.105,12.035,17.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.245 | Acc: 11.187,12.229,17.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.230 | Acc: 11.432,12.335,17.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.219 | Acc: 11.537,12.314,17.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.211 | Acc: 11.528,12.372,17.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.198 | Acc: 11.620,12.521,17.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.189 | Acc: 11.563,12.620,17.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.176 | Acc: 11.635,12.733,18.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.170 | Acc: 11.644,12.689,17.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.164 | Acc: 11.693,12.804,18.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.156 | Acc: 11.763,12.919,18.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.148 | Acc: 11.859,13.052,18.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.138 | Acc: 11.901,13.160,18.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.129 | Acc: 11.899,13.150,18.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.209 | Acc: 10.938,11.719,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.311 | Acc: 10.268,10.603,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.272 | Acc: 10.633,10.614,15.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.285 | Acc: 10.771,10.835,15.471,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 7.138 | Acc: 17.188,14.844,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.891 | Acc: 14.360,15.551,20.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.897 | Acc: 14.082,15.320,20.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.884 | Acc: 13.896,15.420,20.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.884 | Acc: 13.927,15.297,20.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.871 | Acc: 14.016,15.439,20.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.857 | Acc: 14.121,15.464,20.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.858 | Acc: 14.013,15.342,20.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.845 | Acc: 14.111,15.489,20.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.851 | Acc: 14.123,15.401,20.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.846 | Acc: 14.074,15.392,20.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.841 | Acc: 14.031,15.427,20.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.829 | Acc: 14.053,15.486,20.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.820 | Acc: 14.089,15.538,20.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.806 | Acc: 14.277,15.745,20.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.805 | Acc: 14.210,15.737,21.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.794 | Acc: 14.279,15.749,21.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.787 | Acc: 14.292,15.767,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.781 | Acc: 14.342,15.802,21.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.772 | Acc: 14.399,15.863,21.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.632 | Acc: 16.406,12.500,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.749 | Acc: 13.430,14.249,21.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.749 | Acc: 13.967,14.729,21.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.761 | Acc: 13.960,14.511,21.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 6.581 | Acc: 12.500,14.062,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.540 | Acc: 14.695,17.746,24.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.554 | Acc: 14.825,17.740,24.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.555 | Acc: 14.933,17.738,23.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.541 | Acc: 14.979,17.641,23.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.546 | Acc: 15.300,17.729,23.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.546 | Acc: 15.354,17.652,23.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.534 | Acc: 15.509,17.747,23.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.529 | Acc: 15.586,17.770,23.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.523 | Acc: 15.608,17.740,23.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.522 | Acc: 15.621,17.798,23.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.519 | Acc: 15.830,17.820,23.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.513 | Acc: 15.852,17.920,23.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.501 | Acc: 15.927,18.077,24.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.489 | Acc: 16.039,18.130,24.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.484 | Acc: 16.061,18.200,24.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.469 | Acc: 16.207,18.288,24.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.468 | Acc: 16.182,18.342,24.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.458 | Acc: 16.270,18.432,24.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.446 | Acc: 16.359,18.512,24.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.572 | Acc: 20.312,18.750,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.540 | Acc: 14.249,18.080,22.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.547 | Acc: 14.691,18.598,22.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.548 | Acc: 14.869,18.596,21.901,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 5.885 | Acc: 26.562,21.875,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.289 | Acc: 17.262,19.457,26.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.284 | Acc: 17.188,19.760,26.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.252 | Acc: 17.392,20.005,26.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.237 | Acc: 17.757,19.917,26.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.242 | Acc: 17.737,19.903,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.237 | Acc: 17.743,20.074,26.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.234 | Acc: 17.875,20.008,26.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.237 | Acc: 17.988,20.089,26.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.230 | Acc: 18.059,20.205,26.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.221 | Acc: 18.097,20.141,26.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.216 | Acc: 18.015,20.111,26.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.213 | Acc: 18.069,20.124,26.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.206 | Acc: 18.208,20.196,26.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.199 | Acc: 18.236,20.338,26.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.192 | Acc: 18.272,20.401,26.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.188 | Acc: 18.268,20.429,26.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.182 | Acc: 18.308,20.487,26.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.175 | Acc: 18.378,20.564,26.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.169 | Acc: 18.453,20.661,27.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.305 | Acc: 21.875,18.750,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.348 | Acc: 17.411,18.341,24.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.315 | Acc: 17.607,18.388,25.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.323 | Acc: 17.572,18.635,25.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 5.896 | Acc: 25.000,25.781,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.935 | Acc: 19.829,23.103,30.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.941 | Acc: 19.703,22.313,29.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.957 | Acc: 19.723,22.259,29.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.969 | Acc: 19.589,22.396,29.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.976 | Acc: 19.539,22.308,29.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.986 | Acc: 19.596,22.392,28.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.979 | Acc: 19.786,22.484,28.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.980 | Acc: 19.740,22.239,28.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.977 | Acc: 19.652,22.285,28.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.978 | Acc: 19.566,22.198,28.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.972 | Acc: 19.514,22.190,28.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.967 | Acc: 19.544,22.225,29.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.964 | Acc: 19.657,22.279,29.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.962 | Acc: 19.743,22.309,29.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.956 | Acc: 19.822,22.477,29.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.945 | Acc: 19.894,22.578,29.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.940 | Acc: 19.996,22.684,29.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.937 | Acc: 20.103,22.671,29.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.932 | Acc: 20.161,22.728,29.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.964 | Acc: 26.562,24.219,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.145 | Acc: 20.126,20.387,26.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.160 | Acc: 19.627,20.179,26.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.177 | Acc: 19.595,19.813,26.050,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 5.681 | Acc: 18.750,24.219,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.823 | Acc: 21.057,23.586,31.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.810 | Acc: 20.941,23.666,30.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.787 | Acc: 20.774,23.796,31.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.744 | Acc: 21.046,24.113,31.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.726 | Acc: 21.310,24.443,32.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.720 | Acc: 21.623,24.432,32.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.720 | Acc: 21.587,24.518,32.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.714 | Acc: 21.695,24.573,32.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.728 | Acc: 21.616,24.534,31.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.722 | Acc: 21.770,24.666,31.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.726 | Acc: 21.758,24.657,31.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.728 | Acc: 21.820,24.653,31.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.728 | Acc: 21.902,24.608,31.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.726 | Acc: 21.814,24.597,31.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.723 | Acc: 21.789,24.564,31.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.721 | Acc: 21.800,24.564,31.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.716 | Acc: 21.797,24.574,32.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.713 | Acc: 21.778,24.628,32.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.708 | Acc: 21.883,24.649,32.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.963 | Acc: 28.125,21.094,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.930 | Acc: 20.945,22.470,28.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.986 | Acc: 20.293,21.837,28.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.033 | Acc: 19.890,21.491,28.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 5.473 | Acc: 21.094,24.219,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.518 | Acc: 23.140,27.493,34.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.501 | Acc: 22.866,26.029,34.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.529 | Acc: 23.028,25.961,34.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.521 | Acc: 23.264,26.177,34.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.545 | Acc: 23.097,25.851,33.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.547 | Acc: 22.953,25.684,33.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.559 | Acc: 22.878,25.665,33.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.551 | Acc: 22.913,25.728,33.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.541 | Acc: 23.006,25.928,33.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.538 | Acc: 22.987,25.987,33.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.533 | Acc: 23.038,26.018,33.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.522 | Acc: 23.214,26.238,34.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.519 | Acc: 23.162,26.188,34.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.520 | Acc: 23.109,26.190,34.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.514 | Acc: 23.152,26.251,34.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.511 | Acc: 23.267,26.278,34.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.507 | Acc: 23.266,26.343,34.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.509 | Acc: 23.208,26.387,34.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.508 | Acc: 23.218,26.384,34.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.748 | Acc: 27.344,25.781,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.027 | Acc: 19.680,21.615,29.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.027 | Acc: 19.150,20.998,29.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.031 | Acc: 18.840,20.914,28.727,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 5.243 | Acc: 25.781,31.250,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.337 | Acc: 25.037,29.055,35.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.367 | Acc: 24.371,27.210,36.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.371 | Acc: 24.180,27.113,36.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.350 | Acc: 24.431,27.469,36.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.371 | Acc: 24.304,27.382,35.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.365 | Acc: 24.400,27.589,35.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.360 | Acc: 24.529,27.637,35.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.357 | Acc: 24.515,27.785,36.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.356 | Acc: 24.504,27.948,36.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.359 | Acc: 24.417,27.958,35.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.356 | Acc: 24.459,28.033,36.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.353 | Acc: 24.595,28.109,36.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.352 | Acc: 24.521,28.038,36.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.353 | Acc: 24.469,28.036,36.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.345 | Acc: 24.450,28.078,36.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.341 | Acc: 24.423,28.191,36.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.340 | Acc: 24.354,28.171,36.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.336 | Acc: 24.422,28.279,36.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.333 | Acc: 24.387,28.279,36.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.415 | Acc: 21.875,21.875,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.425 | Acc: 14.360,20.610,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.464 | Acc: 14.691,20.389,26.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.460 | Acc: 14.703,20.236,26.396,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 5.289 | Acc: 25.781,19.531,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.293 | Acc: 24.554,27.046,37.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.229 | Acc: 25.152,28.678,38.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.238 | Acc: 25.128,28.586,38.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.233 | Acc: 25.087,28.771,37.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.241 | Acc: 25.139,28.721,37.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.244 | Acc: 24.916,28.558,37.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.228 | Acc: 24.812,28.513,37.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.222 | Acc: 24.879,28.591,37.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.223 | Acc: 24.905,28.621,37.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.227 | Acc: 24.988,28.720,37.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.227 | Acc: 24.982,28.726,37.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.231 | Acc: 24.990,28.725,37.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.229 | Acc: 24.964,28.688,37.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.226 | Acc: 24.975,28.728,37.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.215 | Acc: 25.036,28.880,38.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.211 | Acc: 25.178,28.916,38.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.203 | Acc: 25.172,28.909,38.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.197 | Acc: 25.221,28.986,38.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.191 | Acc: 25.269,29.056,38.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.063 | Acc: 25.000,21.094,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.264 | Acc: 19.234,20.833,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.291 | Acc: 18.674,20.579,27.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.298 | Acc: 18.110,20.312,27.805,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 5.098 | Acc: 27.344,34.375,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.049 | Acc: 26.935,30.469,39.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.030 | Acc: 26.696,30.659,40.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.017 | Acc: 26.319,30.661,40.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.004 | Acc: 26.678,31.115,40.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.005 | Acc: 26.663,31.041,40.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.007 | Acc: 26.769,30.940,40.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.013 | Acc: 26.640,30.990,40.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.021 | Acc: 26.427,30.779,40.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.026 | Acc: 26.489,30.905,40.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.033 | Acc: 26.290,30.819,40.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.030 | Acc: 26.280,30.752,40.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.036 | Acc: 26.336,30.722,40.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.035 | Acc: 26.269,30.783,40.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.031 | Acc: 26.287,30.763,40.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.028 | Acc: 26.287,30.817,40.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.028 | Acc: 26.266,30.846,40.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.026 | Acc: 26.221,30.819,40.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.021 | Acc: 26.292,30.899,40.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.020 | Acc: 26.286,30.957,40.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.361 | Acc: 29.688,36.719,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.357 | Acc: 24.293,28.460,37.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.362 | Acc: 24.104,28.144,36.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.377 | Acc: 24.078,27.856,35.886,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 4.750 | Acc: 33.594,36.719,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.964 | Acc: 26.972,32.068,40.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.903 | Acc: 26.486,31.555,41.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.899 | Acc: 27.049,31.814,41.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.913 | Acc: 27.247,31.829,41.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.917 | Acc: 27.313,31.799,41.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.932 | Acc: 27.182,31.767,41.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.933 | Acc: 27.222,31.871,41.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.937 | Acc: 27.116,31.988,41.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.942 | Acc: 27.076,31.910,41.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.932 | Acc: 26.963,31.988,41.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.924 | Acc: 26.973,31.996,41.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.926 | Acc: 26.922,31.947,41.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.926 | Acc: 26.946,31.915,41.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.925 | Acc: 26.921,31.967,41.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.920 | Acc: 27.025,32.060,41.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.915 | Acc: 27.025,32.095,41.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.911 | Acc: 27.048,32.123,41.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.907 | Acc: 27.010,32.161,41.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.906 | Acc: 26.999,32.150,41.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.356 | Acc: 25.781,36.719,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.632 | Acc: 21.875,29.353,32.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.659 | Acc: 21.837,28.201,32.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.648 | Acc: 21.926,27.959,32.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 4.698 | Acc: 28.125,35.938,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.844 | Acc: 27.716,33.668,43.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.794 | Acc: 27.839,33.518,43.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.806 | Acc: 27.946,33.414,43.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.792 | Acc: 28.086,33.652,44.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.785 | Acc: 28.419,33.864,44.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.788 | Acc: 28.112,33.807,43.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.792 | Acc: 27.986,33.555,43.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.799 | Acc: 27.747,33.409,43.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.808 | Acc: 27.693,33.270,43.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.810 | Acc: 27.565,33.170,43.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.806 | Acc: 27.648,33.212,43.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.814 | Acc: 27.626,33.172,43.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.807 | Acc: 27.679,33.318,43.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.802 | Acc: 27.705,33.405,43.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.804 | Acc: 27.764,33.386,43.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.802 | Acc: 27.831,33.404,43.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.801 | Acc: 27.802,33.433,43.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.792 | Acc: 27.859,33.533,43.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.789 | Acc: 27.885,33.489,43.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.835 | Acc: 28.906,32.031,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.972 | Acc: 20.089,23.103,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.076 | Acc: 19.912,22.351,33.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.066 | Acc: 19.890,22.400,33.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 4.637 | Acc: 32.812,30.469,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.689 | Acc: 28.088,32.701,45.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.696 | Acc: 28.277,33.117,45.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.723 | Acc: 27.869,32.928,45.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.722 | Acc: 27.971,33.314,45.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.712 | Acc: 28.133,33.679,45.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.713 | Acc: 28.299,33.781,44.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.708 | Acc: 28.241,33.898,44.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.702 | Acc: 28.314,34.074,44.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.704 | Acc: 28.289,34.151,44.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.702 | Acc: 28.238,34.258,44.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.698 | Acc: 28.245,34.272,44.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.695 | Acc: 28.365,34.339,44.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.696 | Acc: 28.382,34.387,44.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.690 | Acc: 28.484,34.436,44.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.690 | Acc: 28.366,34.481,44.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.690 | Acc: 28.356,34.499,44.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.687 | Acc: 28.416,34.533,45.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.688 | Acc: 28.508,34.542,45.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.684 | Acc: 28.513,34.564,45.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.294 | Acc: 25.781,35.156,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.311 | Acc: 20.647,29.799,41.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.350 | Acc: 21.113,29.002,40.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.386 | Acc: 20.697,28.445,40.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 4.665 | Acc: 22.656,37.500,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 28.832,35.975,46.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 28.849,35.042,45.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 28.829,34.567,46.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.606 | Acc: 28.559,34.529,46.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.603 | Acc: 28.868,34.785,46.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.583 | Acc: 29.294,35.189,46.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.580 | Acc: 29.283,34.973,46.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.585 | Acc: 29.193,34.967,46.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.588 | Acc: 29.144,35.035,46.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.594 | Acc: 29.202,35.218,46.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.599 | Acc: 29.104,35.298,46.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.597 | Acc: 29.273,35.370,46.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.591 | Acc: 29.352,35.444,46.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.596 | Acc: 29.329,35.420,46.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.593 | Acc: 29.293,35.426,46.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.593 | Acc: 29.254,35.468,46.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.592 | Acc: 29.280,35.511,46.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.592 | Acc: 29.289,35.539,46.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.590 | Acc: 29.343,35.570,46.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.785 | Acc: 21.094,24.219,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.765 | Acc: 19.048,25.781,34.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.831 | Acc: 18.979,25.038,34.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.870 | Acc: 18.840,25.064,34.477,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.362 | Acc: 32.812,39.844,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.455 | Acc: 29.725,37.686,48.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.469 | Acc: 29.573,36.909,48.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.469 | Acc: 29.854,37.065,48.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.477 | Acc: 29.794,37.027,48.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.491 | Acc: 29.850,37.005,48.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.480 | Acc: 30.030,37.248,48.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.486 | Acc: 29.765,37.179,47.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.483 | Acc: 29.654,36.971,47.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.493 | Acc: 29.575,36.676,47.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.494 | Acc: 29.555,36.769,47.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.500 | Acc: 29.592,36.825,47.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.498 | Acc: 29.681,36.816,47.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.502 | Acc: 29.667,36.821,47.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.504 | Acc: 29.668,36.780,47.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.500 | Acc: 29.620,36.843,47.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.499 | Acc: 29.702,36.799,47.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.498 | Acc: 29.713,36.765,47.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.494 | Acc: 29.709,36.805,47.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.489 | Acc: 29.806,36.829,47.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.706 | Acc: 28.125,40.625,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.801 | Acc: 25.335,33.557,45.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.806 | Acc: 25.972,33.594,45.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.828 | Acc: 25.884,33.491,44.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.050 | Acc: 28.125,35.938,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.307 | Acc: 30.618,39.137,50.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.273 | Acc: 31.745,39.082,50.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.342 | Acc: 30.815,37.897,49.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.337 | Acc: 31.047,38.166,49.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.337 | Acc: 31.211,37.995,49.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.346 | Acc: 31.037,37.816,49.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.375 | Acc: 30.657,37.323,49.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.387 | Acc: 30.745,37.340,49.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.394 | Acc: 30.637,37.323,48.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.400 | Acc: 30.581,37.267,48.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.398 | Acc: 30.670,37.479,49.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.396 | Acc: 30.767,37.565,49.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.392 | Acc: 30.699,37.590,49.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.399 | Acc: 30.566,37.506,49.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.399 | Acc: 30.575,37.518,49.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.398 | Acc: 30.612,37.568,49.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.400 | Acc: 30.599,37.580,49.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.400 | Acc: 30.614,37.658,49.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.399 | Acc: 30.577,37.658,49.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.009 | Acc: 25.781,39.844,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.175 | Acc: 23.475,32.775,43.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.169 | Acc: 23.228,32.069,42.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.192 | Acc: 22.848,31.801,41.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 4.457 | Acc: 37.500,38.281,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.264 | Acc: 31.473,39.249,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.308 | Acc: 31.879,38.853,50.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.316 | Acc: 31.660,38.537,50.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.310 | Acc: 31.549,38.850,50.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.314 | Acc: 31.273,38.552,50.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.311 | Acc: 31.250,38.669,50.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.311 | Acc: 31.344,38.719,50.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.313 | Acc: 31.347,38.626,50.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.315 | Acc: 31.116,38.475,50.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.309 | Acc: 31.126,38.507,50.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.306 | Acc: 31.109,38.614,50.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.317 | Acc: 30.923,38.505,50.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.325 | Acc: 30.804,38.407,50.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.332 | Acc: 30.716,38.398,49.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.327 | Acc: 30.796,38.497,50.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.331 | Acc: 30.763,38.432,49.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.330 | Acc: 30.789,38.604,50.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.329 | Acc: 30.813,38.727,50.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.329 | Acc: 30.813,38.712,49.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.347 | Acc: 32.812,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 27.865,37.054,48.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 27.973,37.119,47.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 27.754,37.410,47.285,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.176 | Acc: 28.125,40.625,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.127 | Acc: 32.664,41.109,52.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.141 | Acc: 32.508,40.892,52.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.141 | Acc: 31.993,40.497,52.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.161 | Acc: 31.800,40.635,51.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.187 | Acc: 31.451,40.416,51.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.199 | Acc: 31.399,40.380,51.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.201 | Acc: 31.427,40.453,51.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.215 | Acc: 31.473,40.271,51.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.222 | Acc: 31.392,40.111,51.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.234 | Acc: 31.332,40.019,51.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.228 | Acc: 31.303,39.992,51.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.229 | Acc: 31.273,39.954,51.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.225 | Acc: 31.331,39.993,51.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.241 | Acc: 31.222,39.908,51.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.242 | Acc: 31.260,39.896,51.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.254 | Acc: 31.177,39.724,50.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.260 | Acc: 31.206,39.750,50.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.258 | Acc: 31.196,39.777,50.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.255 | Acc: 31.221,39.795,50.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.038 | Acc: 23.438,29.688,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.207 | Acc: 22.321,29.092,42.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.219 | Acc: 22.732,29.935,42.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.242 | Acc: 22.669,29.816,41.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.196 | Acc: 32.812,45.312,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.179 | Acc: 31.064,40.402,53.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.162 | Acc: 30.831,40.606,53.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.097 | Acc: 31.237,41.368,53.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.115 | Acc: 31.607,41.329,53.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.125 | Acc: 31.637,41.399,53.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.127 | Acc: 31.586,41.445,52.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.118 | Acc: 31.943,41.611,53.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.128 | Acc: 31.944,41.615,52.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.127 | Acc: 32.005,41.691,52.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.133 | Acc: 31.942,41.480,52.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.146 | Acc: 31.890,41.261,52.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.151 | Acc: 31.902,41.153,52.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.157 | Acc: 31.867,41.059,52.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.156 | Acc: 31.812,41.070,52.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.164 | Acc: 31.787,40.892,52.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.166 | Acc: 31.824,40.929,52.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.166 | Acc: 31.891,40.973,52.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.168 | Acc: 31.880,40.926,52.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.172 | Acc: 31.861,40.922,52.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.323 | Acc: 27.344,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.791 | Acc: 24.330,37.165,47.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.823 | Acc: 24.505,36.185,46.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.840 | Acc: 24.603,35.694,46.055,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 3.846 | Acc: 39.844,46.875,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.008 | Acc: 33.073,41.890,53.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.094 | Acc: 31.764,40.873,53.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.059 | Acc: 32.403,41.919,53.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.068 | Acc: 32.456,41.831,53.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.077 | Acc: 32.395,41.561,53.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.074 | Acc: 32.587,41.794,53.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.082 | Acc: 32.729,41.833,53.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.092 | Acc: 32.584,41.673,53.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.091 | Acc: 32.493,41.691,53.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.095 | Acc: 32.373,41.573,53.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.095 | Acc: 32.420,41.686,53.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.100 | Acc: 32.271,41.610,53.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.101 | Acc: 32.250,41.598,52.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.102 | Acc: 32.318,41.579,52.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.107 | Acc: 32.314,41.500,52.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.112 | Acc: 32.297,41.460,52.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.111 | Acc: 32.338,41.473,52.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.114 | Acc: 32.284,41.395,52.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.116 | Acc: 32.324,41.443,52.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.617 | Acc: 25.000,35.156,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.760 | Acc: 24.740,36.496,44.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.731 | Acc: 25.210,36.471,45.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.762 | Acc: 24.782,36.219,44.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 3.769 | Acc: 34.375,44.531,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.864 | Acc: 34.115,44.754,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.943 | Acc: 34.070,44.379,55.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.978 | Acc: 33.478,43.865,54.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.004 | Acc: 33.237,43.345,54.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.031 | Acc: 33.029,43.139,53.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.039 | Acc: 33.000,42.962,53.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.033 | Acc: 32.896,42.897,53.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.035 | Acc: 33.002,42.755,53.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.034 | Acc: 32.765,42.524,53.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.025 | Acc: 32.840,42.689,54.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.022 | Acc: 32.957,42.711,53.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.028 | Acc: 32.936,42.612,53.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.031 | Acc: 32.887,42.586,53.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.033 | Acc: 32.899,42.602,53.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.041 | Acc: 32.828,42.535,53.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.047 | Acc: 32.798,42.445,53.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.054 | Acc: 32.748,42.371,53.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.056 | Acc: 32.687,42.313,53.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.056 | Acc: 32.689,42.315,53.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.600 | Acc: 30.469,36.719,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.799 | Acc: 28.943,34.933,44.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.851 | Acc: 28.544,34.223,44.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.878 | Acc: 28.445,34.529,43.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 3.884 | Acc: 38.281,50.000,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.920 | Acc: 33.222,45.387,56.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.922 | Acc: 33.460,44.588,55.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.923 | Acc: 33.005,44.288,55.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.921 | Acc: 33.121,44.059,55.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.932 | Acc: 33.315,44.044,55.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.951 | Acc: 33.258,43.866,55.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.946 | Acc: 33.295,43.822,55.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.953 | Acc: 33.210,43.755,55.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.960 | Acc: 33.102,43.590,55.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.972 | Acc: 33.065,43.365,55.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.977 | Acc: 32.989,43.252,54.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.974 | Acc: 33.017,43.166,55.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.981 | Acc: 33.052,43.077,54.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.982 | Acc: 33.099,43.174,55.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.982 | Acc: 33.038,43.182,55.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.981 | Acc: 32.961,43.163,55.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.989 | Acc: 32.849,43.044,54.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.994 | Acc: 32.791,42.980,54.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.993 | Acc: 32.837,42.946,54.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.558 | Acc: 21.875,25.781,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.488 | Acc: 21.317,29.167,41.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.644 | Acc: 20.694,27.858,39.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.645 | Acc: 20.274,27.792,39.946,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 3.726 | Acc: 30.469,44.531,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.915 | Acc: 31.808,42.857,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.908 | Acc: 32.431,43.178,57.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.877 | Acc: 33.261,43.622,57.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.881 | Acc: 33.092,43.750,57.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.891 | Acc: 33.261,43.696,56.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.903 | Acc: 33.219,43.447,56.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.919 | Acc: 33.283,43.462,56.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.911 | Acc: 33.375,43.604,56.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.920 | Acc: 33.210,43.633,56.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.928 | Acc: 33.193,43.509,56.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.930 | Acc: 33.099,43.428,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.934 | Acc: 32.968,43.364,55.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.930 | Acc: 33.106,43.514,55.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.932 | Acc: 33.068,43.572,55.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.935 | Acc: 33.080,43.529,55.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.936 | Acc: 33.153,43.633,55.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.938 | Acc: 33.271,43.638,55.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.941 | Acc: 33.152,43.599,55.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.936 | Acc: 33.249,43.670,55.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.644 | Acc: 24.219,40.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.987 | Acc: 22.396,34.710,46.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.986 | Acc: 22.713,35.690,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.993 | Acc: 22.490,35.528,45.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 4.207 | Acc: 28.906,45.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.817 | Acc: 31.362,45.052,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.822 | Acc: 32.851,45.236,57.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.838 | Acc: 33.235,44.826,56.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.831 | Acc: 33.565,44.927,57.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.828 | Acc: 34.042,44.918,57.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.842 | Acc: 34.136,44.744,56.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.849 | Acc: 34.109,44.836,56.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.871 | Acc: 33.861,44.546,56.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.870 | Acc: 33.788,44.488,56.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.866 | Acc: 33.947,44.660,56.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.868 | Acc: 33.848,44.697,56.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.874 | Acc: 33.856,44.632,56.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.882 | Acc: 33.719,44.480,56.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.883 | Acc: 33.669,44.428,56.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.890 | Acc: 33.630,44.368,56.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.887 | Acc: 33.674,44.439,56.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.888 | Acc: 33.628,44.433,56.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.885 | Acc: 33.633,44.581,56.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.887 | Acc: 33.608,44.525,55.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.369 | Acc: 31.250,39.844,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.469 | Acc: 26.042,38.579,50.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.473 | Acc: 26.582,38.700,50.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.479 | Acc: 26.396,38.576,50.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 3.910 | Acc: 33.594,46.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.888 | Acc: 32.366,45.685,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.827 | Acc: 33.365,45.903,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.834 | Acc: 33.466,45.645,56.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.839 | Acc: 33.372,45.438,56.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.823 | Acc: 33.919,45.877,56.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.838 | Acc: 33.632,45.571,56.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.826 | Acc: 33.788,45.590,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.828 | Acc: 33.749,45.410,56.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.838 | Acc: 33.801,45.360,56.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.842 | Acc: 33.773,45.227,56.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.849 | Acc: 33.693,45.107,56.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.844 | Acc: 33.791,45.154,56.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.842 | Acc: 33.851,45.196,56.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.847 | Acc: 33.738,45.023,56.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.845 | Acc: 33.781,45.123,56.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.844 | Acc: 33.840,45.106,56.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.838 | Acc: 33.898,45.209,56.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.837 | Acc: 33.890,45.174,56.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.845 | Acc: 33.782,45.071,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.362 | Acc: 28.125,41.406,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 25.260,38.504,49.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 25.819,39.234,49.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 25.371,38.794,48.809,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 3.901 | Acc: 29.688,40.625,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.782 | Acc: 34.375,45.610,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.776 | Acc: 34.032,45.427,58.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.768 | Acc: 33.850,45.722,58.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.750 | Acc: 33.787,45.602,58.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.745 | Acc: 34.112,45.862,58.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.731 | Acc: 34.246,45.816,58.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.738 | Acc: 34.170,45.916,58.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.748 | Acc: 34.220,45.909,58.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.749 | Acc: 34.120,46.094,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.755 | Acc: 33.994,46.199,58.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.754 | Acc: 34.057,46.313,58.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.771 | Acc: 34.018,46.081,57.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.773 | Acc: 34.076,46.022,57.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.773 | Acc: 34.080,46.133,57.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.775 | Acc: 34.178,46.086,57.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.774 | Acc: 34.222,46.060,57.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.781 | Acc: 34.146,46.020,57.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.788 | Acc: 34.053,45.968,57.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.793 | Acc: 33.973,45.874,57.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.920 | Acc: 24.219,40.625,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.240 | Acc: 20.908,31.027,44.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.216 | Acc: 21.151,31.688,45.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.221 | Acc: 21.030,31.237,44.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 3.439 | Acc: 35.156,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.732 | Acc: 33.817,44.829,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.717 | Acc: 33.670,45.751,59.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.691 | Acc: 33.888,46.580,59.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.720 | Acc: 33.796,46.335,58.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.723 | Acc: 33.942,46.349,58.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.723 | Acc: 33.988,46.378,58.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.723 | Acc: 34.087,46.482,59.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.730 | Acc: 34.200,46.477,58.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.727 | Acc: 34.289,46.806,58.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.725 | Acc: 34.313,46.786,58.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.728 | Acc: 34.315,46.833,58.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.733 | Acc: 34.190,46.716,58.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.737 | Acc: 34.210,46.680,58.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.735 | Acc: 34.244,46.692,58.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.739 | Acc: 34.152,46.551,58.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.745 | Acc: 34.078,46.432,58.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.750 | Acc: 34.070,46.348,58.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.753 | Acc: 34.087,46.273,58.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.754 | Acc: 34.080,46.254,58.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.919 | Acc: 36.719,46.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.312 | Acc: 26.935,39.583,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.357 | Acc: 27.191,40.111,51.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.375 | Acc: 27.203,39.062,51.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 3.523 | Acc: 32.812,44.531,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.610 | Acc: 35.603,48.921,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.628 | Acc: 35.347,48.533,59.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.656 | Acc: 34.465,48.143,59.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.660 | Acc: 34.433,47.830,59.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.672 | Acc: 34.197,47.703,59.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.677 | Acc: 34.388,47.656,59.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.665 | Acc: 34.414,47.656,59.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.683 | Acc: 34.322,47.467,59.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.689 | Acc: 34.293,47.445,58.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.698 | Acc: 34.169,47.303,58.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.691 | Acc: 34.255,47.437,58.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.697 | Acc: 34.232,47.352,58.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.711 | Acc: 34.186,47.270,58.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.711 | Acc: 34.175,47.273,58.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.712 | Acc: 34.295,47.246,58.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.714 | Acc: 34.343,47.233,58.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.721 | Acc: 34.313,47.127,58.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.729 | Acc: 34.293,47.068,58.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.735 | Acc: 34.207,46.986,58.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.316 | Acc: 27.344,44.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.746 | Acc: 22.359,38.690,50.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.774 | Acc: 22.732,38.700,49.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.792 | Acc: 22.605,38.153,49.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 3.446 | Acc: 28.906,48.438,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.583 | Acc: 35.789,48.586,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.619 | Acc: 35.595,47.904,60.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.620 | Acc: 35.451,48.015,60.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.622 | Acc: 35.484,48.032,59.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.630 | Acc: 35.466,47.819,59.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.629 | Acc: 35.292,47.992,59.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.630 | Acc: 35.262,48.055,59.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.631 | Acc: 35.210,48.040,59.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.647 | Acc: 35.048,47.829,59.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.650 | Acc: 35.051,47.742,59.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.648 | Acc: 35.004,47.702,59.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.649 | Acc: 34.959,47.718,59.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.655 | Acc: 34.863,47.665,59.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.662 | Acc: 34.734,47.523,59.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.668 | Acc: 34.754,47.532,59.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.669 | Acc: 34.833,47.530,59.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.679 | Acc: 34.719,47.356,59.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.677 | Acc: 34.704,47.420,59.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.678 | Acc: 34.760,47.453,59.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.304 | Acc: 28.906,41.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.714 | Acc: 28.162,36.719,47.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.790 | Acc: 27.820,36.528,46.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.783 | Acc: 27.613,36.680,47.195,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.687 | Acc: 37.500,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.607 | Acc: 35.565,48.624,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.563 | Acc: 35.442,49.047,60.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.565 | Acc: 35.476,48.655,60.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.580 | Acc: 35.571,48.978,60.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.582 | Acc: 35.705,48.755,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.585 | Acc: 35.699,48.560,60.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.601 | Acc: 35.395,48.266,60.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.608 | Acc: 35.224,48.040,60.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.618 | Acc: 35.079,48.015,60.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.622 | Acc: 34.997,47.940,60.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.624 | Acc: 35.011,47.890,60.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.631 | Acc: 34.955,47.818,60.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.632 | Acc: 34.908,47.788,60.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.634 | Acc: 34.825,47.776,60.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.632 | Acc: 34.871,47.890,60.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.633 | Acc: 34.869,47.883,60.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.632 | Acc: 34.948,47.842,59.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.635 | Acc: 34.936,47.782,59.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.639 | Acc: 34.970,47.804,59.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.575 | Acc: 30.469,42.188,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.765 | Acc: 25.186,35.826,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.814 | Acc: 25.019,34.242,47.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.847 | Acc: 24.910,34.541,47.784,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 3.560 | Acc: 36.719,44.531,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.574 | Acc: 35.603,49.665,61.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.571 | Acc: 35.709,48.914,60.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.569 | Acc: 36.040,49.257,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.579 | Acc: 35.783,48.987,60.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.589 | Acc: 35.458,48.515,60.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.591 | Acc: 35.208,48.547,60.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.582 | Acc: 35.328,48.665,60.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.581 | Acc: 35.263,48.738,60.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.579 | Acc: 35.260,48.671,60.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.590 | Acc: 35.269,48.434,60.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.591 | Acc: 35.255,48.473,60.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.595 | Acc: 35.266,48.444,60.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.599 | Acc: 35.315,48.432,60.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.607 | Acc: 35.290,48.418,60.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.608 | Acc: 35.361,48.409,60.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.612 | Acc: 35.271,48.301,60.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.614 | Acc: 35.388,48.325,60.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.617 | Acc: 35.308,48.295,60.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.621 | Acc: 35.296,48.284,60.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.561 | Acc: 21.094,39.062,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.715 | Acc: 20.424,39.286,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.719 | Acc: 20.941,39.024,50.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.728 | Acc: 21.119,39.178,50.781,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 3.863 | Acc: 28.125,42.969,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.563 | Acc: 35.045,48.177,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.550 | Acc: 35.252,49.657,60.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.493 | Acc: 35.989,49.923,61.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.483 | Acc: 36.265,50.222,61.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.504 | Acc: 35.945,50.062,61.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.515 | Acc: 35.996,49.923,61.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.533 | Acc: 35.921,49.717,61.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.545 | Acc: 35.748,49.554,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.548 | Acc: 35.644,49.478,60.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.558 | Acc: 35.467,49.285,60.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.556 | Acc: 35.605,49.286,60.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.547 | Acc: 35.746,49.459,60.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.554 | Acc: 35.680,49.315,60.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.557 | Acc: 35.679,49.333,60.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.561 | Acc: 35.623,49.268,60.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.567 | Acc: 35.575,49.197,60.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.564 | Acc: 35.656,49.274,60.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.568 | Acc: 35.684,49.297,60.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.571 | Acc: 35.622,49.319,60.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.177 | Acc: 31.250,41.406,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.589 | Acc: 28.274,38.132,49.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.633 | Acc: 28.258,37.233,48.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.658 | Acc: 28.035,36.706,48.425,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.549 | Acc: 36.719,42.188,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.526 | Acc: 36.756,49.033,61.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.548 | Acc: 36.014,48.895,61.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.522 | Acc: 35.912,49.232,61.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.499 | Acc: 36.024,49.624,62.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.497 | Acc: 36.015,49.698,62.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.499 | Acc: 36.041,49.793,62.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.508 | Acc: 36.043,49.690,62.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.522 | Acc: 35.734,49.340,61.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.524 | Acc: 35.791,49.318,62.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.521 | Acc: 35.833,49.285,61.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.527 | Acc: 35.994,49.215,61.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.525 | Acc: 35.902,49.267,61.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.533 | Acc: 35.857,49.162,61.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.535 | Acc: 35.787,49.180,61.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.540 | Acc: 35.758,49.060,61.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.542 | Acc: 35.784,49.078,61.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.545 | Acc: 35.699,49.081,61.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.548 | Acc: 35.665,49.080,61.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.550 | Acc: 35.640,49.034,61.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.484 | Acc: 25.781,36.719,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.728 | Acc: 21.987,35.565,50.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.810 | Acc: 22.809,34.870,49.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.838 | Acc: 22.477,34.785,49.155,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.511 | Acc: 32.031,53.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.401 | Acc: 35.863,49.926,62.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.420 | Acc: 35.575,50.419,63.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.410 | Acc: 36.181,50.423,63.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.420 | Acc: 36.208,50.550,63.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.425 | Acc: 36.046,50.410,63.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.452 | Acc: 36.092,50.077,62.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.470 | Acc: 35.777,49.795,62.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.484 | Acc: 35.675,49.534,62.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.480 | Acc: 35.691,49.612,62.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.486 | Acc: 35.821,49.736,62.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.495 | Acc: 35.708,49.611,62.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.504 | Acc: 35.617,49.601,61.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.506 | Acc: 35.671,49.725,61.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.509 | Acc: 35.684,49.661,61.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.509 | Acc: 35.681,49.605,61.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.517 | Acc: 35.660,49.584,61.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.518 | Acc: 35.653,49.549,61.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.526 | Acc: 35.628,49.485,61.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.524 | Acc: 35.771,49.623,61.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.759 | Acc: 32.031,47.656,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.257 | Acc: 29.018,40.737,52.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.260 | Acc: 29.707,40.530,52.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.298 | Acc: 29.483,40.535,52.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.675 | Acc: 30.469,45.312,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.433 | Acc: 36.905,50.670,63.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.452 | Acc: 36.128,50.534,62.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.461 | Acc: 35.605,50.295,62.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.447 | Acc: 35.860,50.588,62.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.452 | Acc: 35.767,50.580,62.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.449 | Acc: 36.060,50.510,62.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.450 | Acc: 36.037,50.438,62.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.462 | Acc: 35.942,50.432,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.470 | Acc: 35.903,50.384,62.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.477 | Acc: 35.883,50.257,62.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.484 | Acc: 35.807,50.212,62.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.493 | Acc: 35.694,50.104,62.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.496 | Acc: 35.722,50.087,62.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.498 | Acc: 35.657,50.039,61.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.502 | Acc: 35.647,50.065,61.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.499 | Acc: 35.680,49.983,61.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.497 | Acc: 35.793,50.030,61.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.503 | Acc: 35.738,49.968,61.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.508 | Acc: 35.757,49.920,61.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.916 | Acc: 32.812,44.531,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.185 | Acc: 31.362,41.071,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.183 | Acc: 31.536,41.711,54.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.199 | Acc: 31.391,41.560,53.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.247 | Acc: 36.719,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.406 | Acc: 35.826,51.860,63.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.420 | Acc: 35.614,51.296,63.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.402 | Acc: 36.309,51.857,63.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.422 | Acc: 36.179,51.476,63.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.413 | Acc: 36.200,51.562,63.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.430 | Acc: 36.073,50.968,63.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.446 | Acc: 35.893,50.493,62.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.451 | Acc: 36.073,50.582,62.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.457 | Acc: 36.071,50.371,62.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.461 | Acc: 36.027,50.276,62.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.455 | Acc: 36.033,50.361,62.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.452 | Acc: 36.009,50.431,62.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.451 | Acc: 36.048,50.500,62.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.453 | Acc: 36.124,50.428,62.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.465 | Acc: 36.080,50.304,62.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.461 | Acc: 36.098,50.358,62.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.467 | Acc: 36.118,50.286,62.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.467 | Acc: 36.098,50.266,62.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.472 | Acc: 36.058,50.295,62.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.670 | Acc: 25.781,36.719,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.774 | Acc: 21.912,38.021,52.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.832 | Acc: 22.237,37.881,50.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.820 | Acc: 22.182,38.281,49.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.270 | Acc: 39.844,48.438,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.357 | Acc: 38.690,51.376,63.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.341 | Acc: 37.976,51.829,64.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.384 | Acc: 37.474,51.473,63.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.416 | Acc: 36.709,51.080,63.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.424 | Acc: 36.479,50.874,62.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.423 | Acc: 36.325,50.872,62.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.426 | Acc: 36.353,50.787,62.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.418 | Acc: 36.365,50.898,63.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.416 | Acc: 36.585,51.023,63.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.421 | Acc: 36.579,50.956,62.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.427 | Acc: 36.659,50.923,62.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.428 | Acc: 36.589,50.960,62.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.434 | Acc: 36.491,50.883,62.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.438 | Acc: 36.435,50.809,62.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.439 | Acc: 36.355,50.781,62.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.439 | Acc: 36.293,50.740,62.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.437 | Acc: 36.281,50.806,62.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.443 | Acc: 36.251,50.760,62.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.450 | Acc: 36.216,50.709,62.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.644 | Acc: 28.125,42.188,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.647 | Acc: 25.707,37.984,49.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.708 | Acc: 26.277,38.053,48.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.708 | Acc: 25.961,37.846,48.502,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.164 | Acc: 38.281,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.340 | Acc: 36.756,52.269,64.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.335 | Acc: 36.986,52.191,64.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.356 | Acc: 37.385,52.331,64.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.345 | Acc: 37.172,52.469,64.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.330 | Acc: 37.283,52.529,64.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.343 | Acc: 37.132,52.473,64.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.359 | Acc: 36.830,52.155,64.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.373 | Acc: 36.738,52.048,63.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.375 | Acc: 36.736,51.964,63.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.373 | Acc: 36.727,51.955,63.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.381 | Acc: 36.673,51.909,63.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.393 | Acc: 36.472,51.666,63.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.394 | Acc: 36.521,51.715,63.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.397 | Acc: 36.635,51.613,63.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.405 | Acc: 36.470,51.466,63.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.409 | Acc: 36.449,51.434,63.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.420 | Acc: 36.290,51.255,63.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.421 | Acc: 36.230,51.251,63.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.426 | Acc: 36.247,51.202,62.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.026 | Acc: 28.125,50.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.153 | Acc: 29.501,44.420,54.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.190 | Acc: 29.040,43.960,53.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.215 | Acc: 28.906,43.519,53.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.041 | Acc: 39.844,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.379 | Acc: 33.854,50.781,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.354 | Acc: 35.023,51.181,65.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.339 | Acc: 35.912,51.447,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.334 | Acc: 36.449,51.408,64.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.333 | Acc: 36.858,51.539,64.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.343 | Acc: 36.783,51.440,64.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.359 | Acc: 36.602,51.269,64.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.367 | Acc: 36.510,51.179,64.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.372 | Acc: 36.585,51.222,64.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.375 | Acc: 36.528,51.329,64.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.381 | Acc: 36.457,51.258,63.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.391 | Acc: 36.320,51.021,63.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.393 | Acc: 36.389,51.093,63.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.395 | Acc: 36.357,51.084,63.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.400 | Acc: 36.345,51.028,63.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.400 | Acc: 36.373,51.095,63.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.404 | Acc: 36.304,51.081,63.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.407 | Acc: 36.292,51.017,63.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.408 | Acc: 36.358,51.060,63.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.529 | Acc: 25.781,41.406,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.594 | Acc: 23.996,40.216,50.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.661 | Acc: 23.780,39.825,49.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.669 | Acc: 24.078,40.279,49.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.678 | Acc: 37.500,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.342 | Acc: 34.375,52.009,63.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.289 | Acc: 36.490,52.725,64.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.315 | Acc: 36.296,52.305,64.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.326 | Acc: 36.796,52.479,64.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.330 | Acc: 36.928,52.305,64.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.340 | Acc: 36.932,52.428,64.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.348 | Acc: 36.841,52.377,64.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.357 | Acc: 36.699,52.349,63.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.361 | Acc: 36.684,52.240,63.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.360 | Acc: 36.781,52.262,63.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.375 | Acc: 36.637,52.135,63.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.373 | Acc: 36.780,52.062,63.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.365 | Acc: 36.898,52.179,63.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.372 | Acc: 36.844,51.974,63.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.375 | Acc: 36.807,51.858,63.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.379 | Acc: 36.707,51.726,63.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.378 | Acc: 36.680,51.785,63.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.387 | Acc: 36.526,51.653,63.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.381 | Acc: 36.614,51.694,63.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.034 | Acc: 26.562,32.812,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.965 | Acc: 23.326,36.049,48.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.017 | Acc: 24.066,35.518,47.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.034 | Acc: 23.950,35.374,47.041,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.257 | Acc: 44.531,47.656,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.310 | Acc: 37.016,52.604,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.325 | Acc: 36.757,52.630,64.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.340 | Acc: 36.808,52.574,64.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.354 | Acc: 36.728,52.450,64.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.335 | Acc: 36.989,52.669,64.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.327 | Acc: 37.003,52.751,64.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.323 | Acc: 37.168,52.837,64.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.315 | Acc: 37.170,52.824,64.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.314 | Acc: 37.198,52.831,64.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.318 | Acc: 37.205,52.787,64.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.318 | Acc: 37.214,52.697,64.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.322 | Acc: 37.338,52.671,64.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.334 | Acc: 37.252,52.523,64.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.340 | Acc: 37.308,52.441,64.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.345 | Acc: 37.212,52.375,64.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.348 | Acc: 37.074,52.305,64.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.349 | Acc: 37.026,52.296,64.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.361 | Acc: 36.870,52.056,63.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.365 | Acc: 36.823,51.925,63.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.346 | Acc: 29.688,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 22.135,42.262,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 22.370,41.597,54.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 22.310,41.522,54.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 3.002 | Acc: 33.594,54.688,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.205 | Acc: 36.198,52.046,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.269 | Acc: 36.776,52.420,64.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.292 | Acc: 36.680,52.638,64.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.311 | Acc: 36.632,52.431,64.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.306 | Acc: 36.448,52.560,64.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.312 | Acc: 36.364,52.395,64.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.322 | Acc: 36.364,52.333,64.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.311 | Acc: 36.500,52.601,64.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.311 | Acc: 36.650,52.672,64.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.319 | Acc: 36.703,52.585,64.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.320 | Acc: 36.832,52.598,64.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.326 | Acc: 36.748,52.548,63.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.327 | Acc: 36.743,52.565,63.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.330 | Acc: 36.799,52.611,63.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.328 | Acc: 36.799,52.559,63.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.329 | Acc: 36.811,52.507,63.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.328 | Acc: 36.760,52.502,63.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.335 | Acc: 36.710,52.374,63.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.334 | Acc: 36.758,52.420,63.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.686 | Acc: 27.344,40.625,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.803 | Acc: 22.247,37.500,51.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.870 | Acc: 21.494,36.509,50.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.855 | Acc: 21.311,36.642,50.602,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.553 | Acc: 32.031,52.344,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.306 | Acc: 36.644,52.493,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.352 | Acc: 35.595,51.658,65.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.360 | Acc: 35.950,51.716,64.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.346 | Acc: 35.947,51.794,64.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.324 | Acc: 36.193,52.166,64.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.334 | Acc: 36.209,51.879,64.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.333 | Acc: 36.098,51.884,64.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.326 | Acc: 36.219,52.218,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.318 | Acc: 36.464,52.430,64.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.313 | Acc: 36.517,52.503,64.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.315 | Acc: 36.538,52.482,64.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.310 | Acc: 36.683,52.499,64.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.319 | Acc: 36.770,52.457,64.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.326 | Acc: 36.727,52.327,64.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.329 | Acc: 36.690,52.401,64.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.331 | Acc: 36.665,52.409,64.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.328 | Acc: 36.730,52.426,64.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.330 | Acc: 36.732,52.443,64.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.329 | Acc: 36.766,52.465,64.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.248 | Acc: 21.875,44.531,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.313 | Acc: 24.851,41.890,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.378 | Acc: 23.971,41.025,54.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.407 | Acc: 23.899,41.009,54.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.070 | Acc: 34.375,57.031,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.289 | Acc: 35.565,53.423,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.260 | Acc: 37.443,53.411,65.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.242 | Acc: 37.538,53.701,65.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.253 | Acc: 37.278,53.492,65.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.249 | Acc: 37.369,53.519,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.243 | Acc: 37.429,53.551,66.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.251 | Acc: 37.400,53.524,65.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.252 | Acc: 37.578,53.605,65.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.253 | Acc: 37.647,53.613,65.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.265 | Acc: 37.275,53.257,65.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.261 | Acc: 37.245,53.164,65.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.266 | Acc: 37.176,53.151,65.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.277 | Acc: 37.021,52.978,65.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.283 | Acc: 37.114,52.861,64.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.285 | Acc: 37.121,52.837,64.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.293 | Acc: 37.150,52.806,64.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.294 | Acc: 37.097,52.795,64.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.297 | Acc: 37.050,52.733,64.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.305 | Acc: 36.967,52.575,64.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.749 | Acc: 31.250,42.969,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 28.795,39.807,50.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.690 | Acc: 28.487,38.872,48.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.663 | Acc: 28.420,39.344,49.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.520 | Acc: 32.812,46.875,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.287 | Acc: 37.649,52.753,65.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.254 | Acc: 37.290,53.030,66.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.266 | Acc: 37.039,52.574,65.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.245 | Acc: 37.095,52.681,65.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.244 | Acc: 37.500,52.870,65.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.244 | Acc: 37.339,52.944,65.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.236 | Acc: 37.528,53.247,65.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.237 | Acc: 37.442,53.406,65.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.243 | Acc: 37.379,53.298,65.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.259 | Acc: 37.193,53.071,65.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.268 | Acc: 37.104,52.948,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.280 | Acc: 37.027,52.817,65.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.283 | Acc: 37.084,52.817,65.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.285 | Acc: 37.102,52.922,65.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.283 | Acc: 37.087,52.899,64.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.285 | Acc: 37.081,52.899,64.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.287 | Acc: 37.085,52.939,64.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.292 | Acc: 37.072,52.805,64.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.289 | Acc: 37.209,52.901,64.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.263 | Acc: 25.000,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.321 | Acc: 25.298,43.713,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.406 | Acc: 25.000,42.321,53.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.419 | Acc: 24.347,42.175,53.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.480 | Acc: 30.469,50.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.145 | Acc: 37.798,53.943,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.168 | Acc: 37.633,54.097,66.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.213 | Acc: 36.962,53.727,66.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.221 | Acc: 36.854,53.549,66.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.221 | Acc: 36.866,53.543,66.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.233 | Acc: 36.874,53.383,65.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.225 | Acc: 37.023,53.602,66.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.232 | Acc: 36.908,53.372,66.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.231 | Acc: 37.086,53.401,66.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.236 | Acc: 37.154,53.300,65.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.244 | Acc: 37.161,53.316,65.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.249 | Acc: 37.143,53.303,65.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.255 | Acc: 37.138,53.299,65.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.258 | Acc: 37.211,53.281,65.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.260 | Acc: 37.331,53.286,65.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.264 | Acc: 37.254,53.225,65.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.266 | Acc: 37.259,53.191,65.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.272 | Acc: 37.264,53.106,65.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.275 | Acc: 37.295,53.088,65.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.496 | Acc: 21.875,45.312,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.261 | Acc: 29.464,42.225,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.332 | Acc: 29.840,41.559,53.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.323 | Acc: 29.547,41.816,52.882,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.067 | Acc: 32.812,53.125,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.154 | Acc: 38.988,53.609,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.158 | Acc: 38.777,53.659,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.167 | Acc: 38.422,53.663,66.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.172 | Acc: 38.407,53.993,67.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.187 | Acc: 38.420,54.192,66.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.202 | Acc: 38.126,54.210,66.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.210 | Acc: 38.010,54.061,66.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.215 | Acc: 37.942,54.222,66.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.222 | Acc: 37.983,54.113,66.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.228 | Acc: 38.021,54.066,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.219 | Acc: 38.027,54.157,66.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.227 | Acc: 37.938,54.156,65.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.228 | Acc: 37.997,54.083,65.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.243 | Acc: 37.820,53.853,65.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.250 | Acc: 37.741,53.823,65.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.255 | Acc: 37.622,53.741,65.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.256 | Acc: 37.516,53.760,65.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.260 | Acc: 37.500,53.698,65.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.262 | Acc: 37.492,53.623,65.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.596 | Acc: 26.562,40.625,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.685 | Acc: 25.298,38.281,48.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.749 | Acc: 25.495,37.805,48.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.767 | Acc: 25.474,37.961,48.130,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.178 | Acc: 41.406,53.906,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.141 | Acc: 36.905,54.055,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.186 | Acc: 37.309,54.211,66.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.181 | Acc: 37.398,54.162,66.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.169 | Acc: 37.278,54.427,66.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.173 | Acc: 37.624,54.332,66.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.180 | Acc: 37.887,54.268,66.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.214 | Acc: 37.650,53.829,66.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.221 | Acc: 37.553,53.766,65.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.229 | Acc: 37.388,53.699,65.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.229 | Acc: 37.251,53.755,65.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.234 | Acc: 37.309,53.616,65.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.232 | Acc: 37.305,53.686,65.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.235 | Acc: 37.347,53.769,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.230 | Acc: 37.344,53.787,65.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.233 | Acc: 37.287,53.828,65.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.238 | Acc: 37.240,53.716,65.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.242 | Acc: 37.248,53.707,65.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.248 | Acc: 37.223,53.590,65.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.251 | Acc: 37.227,53.545,65.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.936 | Acc: 39.062,50.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.111 | Acc: 29.725,45.052,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.141 | Acc: 30.145,44.989,54.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.166 | Acc: 30.020,44.775,54.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.157 | Acc: 39.844,48.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.155 | Acc: 40.030,54.762,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.156 | Acc: 38.129,54.211,67.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.143 | Acc: 38.345,54.905,67.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.128 | Acc: 38.792,54.890,67.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.134 | Acc: 38.583,54.796,67.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.138 | Acc: 38.249,54.778,67.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.137 | Acc: 38.126,54.893,67.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.142 | Acc: 38.131,54.838,67.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.149 | Acc: 37.897,54.735,67.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.150 | Acc: 38.029,54.754,67.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.160 | Acc: 37.843,54.645,66.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.173 | Acc: 37.792,54.454,66.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.183 | Acc: 37.805,54.355,66.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.194 | Acc: 37.781,54.195,66.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.203 | Acc: 37.726,54.070,66.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.208 | Acc: 37.680,54.023,66.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.213 | Acc: 37.654,53.982,65.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.217 | Acc: 37.621,53.943,65.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.223 | Acc: 37.555,53.824,65.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.946 | Acc: 28.906,39.844,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.189 | Acc: 28.385,41.146,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.242 | Acc: 29.154,40.473,54.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 28.855,40.023,54.150,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.772 | Acc: 28.906,46.094,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.171 | Acc: 36.719,54.390,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.171 | Acc: 37.271,54.573,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.154 | Acc: 37.833,55.046,67.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.150 | Acc: 38.175,55.083,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.170 | Acc: 37.980,54.827,67.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.169 | Acc: 37.874,54.791,66.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.180 | Acc: 37.816,54.466,66.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.177 | Acc: 37.680,54.537,66.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.179 | Acc: 37.686,54.588,66.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.189 | Acc: 37.488,54.450,66.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.186 | Acc: 37.599,54.267,66.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.188 | Acc: 37.636,54.256,66.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.189 | Acc: 37.608,54.236,66.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.185 | Acc: 37.678,54.290,66.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.189 | Acc: 37.752,54.249,66.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.193 | Acc: 37.843,54.259,66.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.198 | Acc: 37.798,54.154,66.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.203 | Acc: 37.773,54.162,66.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.208 | Acc: 37.740,54.117,66.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.017 | Acc: 25.781,48.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.480 | Acc: 28.311,41.704,52.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.423 | Acc: 28.563,42.035,53.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.450 | Acc: 28.189,41.201,53.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 2.930 | Acc: 39.062,56.250,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.117 | Acc: 37.537,53.943,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.076 | Acc: 38.434,55.316,68.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.061 | Acc: 39.191,56.045,68.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.074 | Acc: 39.034,55.565,68.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.086 | Acc: 38.900,55.446,68.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.095 | Acc: 38.707,55.327,67.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.104 | Acc: 38.403,55.258,67.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.108 | Acc: 38.359,55.386,67.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.122 | Acc: 38.195,55.305,67.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.123 | Acc: 38.192,55.438,67.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.130 | Acc: 38.009,55.281,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.141 | Acc: 37.941,55.245,67.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.144 | Acc: 37.967,55.232,67.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.152 | Acc: 37.914,55.160,67.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.158 | Acc: 37.796,55.017,67.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.165 | Acc: 37.753,54.950,66.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.166 | Acc: 37.729,54.976,66.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.170 | Acc: 37.771,54.826,66.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.176 | Acc: 37.767,54.808,66.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.834 | Acc: 32.812,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.988 | Acc: 30.766,45.982,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.021 | Acc: 30.545,44.931,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.021 | Acc: 30.635,44.659,55.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 3.332 | Acc: 37.500,55.469,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.122 | Acc: 37.909,55.097,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.170 | Acc: 37.595,54.249,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.134 | Acc: 38.243,54.880,67.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.112 | Acc: 38.783,55.247,67.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.136 | Acc: 38.451,55.306,67.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.144 | Acc: 38.275,55.101,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.142 | Acc: 38.082,55.114,67.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.144 | Acc: 38.000,54.916,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.146 | Acc: 38.074,54.860,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.142 | Acc: 38.102,54.886,67.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.153 | Acc: 37.878,54.673,66.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.157 | Acc: 37.753,54.694,66.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.160 | Acc: 37.736,54.634,66.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.161 | Acc: 37.764,54.718,66.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.163 | Acc: 37.798,54.807,66.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.164 | Acc: 37.865,54.748,66.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.166 | Acc: 37.942,54.816,66.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.169 | Acc: 37.931,54.869,66.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.171 | Acc: 37.881,54.843,66.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.207 | Acc: 25.000,46.094,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.193 | Acc: 24.516,44.234,57.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.220 | Acc: 24.752,44.055,56.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.261 | Acc: 24.039,43.750,56.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 3.144 | Acc: 38.281,53.906,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.158 | Acc: 36.198,54.576,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.080 | Acc: 37.614,55.488,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.091 | Acc: 37.500,54.892,68.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.122 | Acc: 37.365,54.851,68.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.110 | Acc: 37.717,55.446,68.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.116 | Acc: 37.758,55.456,68.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.109 | Acc: 37.932,55.474,67.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.111 | Acc: 38.058,55.585,67.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.120 | Acc: 38.100,55.439,67.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.131 | Acc: 38.110,55.138,67.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.148 | Acc: 38.055,54.882,67.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.155 | Acc: 38.025,54.827,66.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.148 | Acc: 38.006,54.804,66.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.150 | Acc: 37.878,54.732,66.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.150 | Acc: 37.871,54.713,66.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.155 | Acc: 37.858,54.756,66.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.158 | Acc: 37.832,54.836,66.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.157 | Acc: 37.816,54.876,66.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.157 | Acc: 37.832,54.888,66.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.100 | Acc: 27.344,42.188,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.138 | Acc: 28.571,43.899,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.162 | Acc: 27.801,43.579,55.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.170 | Acc: 27.766,43.801,55.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 3.396 | Acc: 33.594,50.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.084 | Acc: 38.653,55.915,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.076 | Acc: 38.815,56.269,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.091 | Acc: 38.858,56.212,67.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.099 | Acc: 38.600,56.231,67.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.090 | Acc: 38.745,56.289,67.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.093 | Acc: 38.559,56.114,67.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.090 | Acc: 38.619,56.250,67.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.091 | Acc: 38.437,56.231,67.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.094 | Acc: 38.381,56.207,67.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.099 | Acc: 38.336,56.040,67.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.099 | Acc: 38.168,55.921,67.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.109 | Acc: 38.181,55.689,67.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.118 | Acc: 38.188,55.544,67.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.127 | Acc: 38.195,55.433,67.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.135 | Acc: 38.120,55.344,67.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.138 | Acc: 38.065,55.311,66.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.139 | Acc: 38.066,55.343,66.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.143 | Acc: 38.024,55.194,66.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.147 | Acc: 37.906,55.155,66.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.872 | Acc: 23.438,39.062,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.856 | Acc: 22.582,39.695,49.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.972 | Acc: 22.027,38.396,48.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.013 | Acc: 22.080,38.192,48.770,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 2.985 | Acc: 44.531,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.191 | Acc: 37.314,55.022,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.162 | Acc: 37.557,54.726,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.145 | Acc: 37.846,55.238,67.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.119 | Acc: 37.616,55.421,67.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.122 | Acc: 37.523,55.345,67.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.124 | Acc: 37.184,55.049,67.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.121 | Acc: 37.417,55.341,67.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.118 | Acc: 37.582,55.367,67.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.122 | Acc: 37.565,55.283,67.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.130 | Acc: 37.543,55.193,67.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.130 | Acc: 37.673,55.197,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.139 | Acc: 37.743,55.102,67.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.131 | Acc: 37.814,55.268,67.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.133 | Acc: 37.861,55.291,67.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.136 | Acc: 37.817,55.271,67.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.142 | Acc: 37.799,55.109,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.138 | Acc: 37.889,55.150,67.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.146 | Acc: 37.842,55.023,66.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.147 | Acc: 37.863,55.057,66.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.292 | Acc: 32.031,43.750,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.400 | Acc: 28.497,41.815,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 28.678,41.463,53.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.481 | Acc: 28.317,41.586,52.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.820 | Acc: 28.906,47.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.124 | Acc: 38.281,55.246,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.073 | Acc: 38.624,56.136,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.073 | Acc: 38.358,55.994,68.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.064 | Acc: 38.416,55.739,69.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.087 | Acc: 38.119,55.654,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.106 | Acc: 37.862,55.378,68.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.108 | Acc: 37.949,55.524,68.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.096 | Acc: 38.160,55.697,68.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.098 | Acc: 38.199,55.732,68.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.103 | Acc: 38.157,55.776,68.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.105 | Acc: 38.122,55.759,68.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.112 | Acc: 38.171,55.731,67.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.114 | Acc: 38.132,55.654,67.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.111 | Acc: 38.295,55.805,67.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.115 | Acc: 38.224,55.741,67.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.114 | Acc: 38.247,55.715,67.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.116 | Acc: 38.240,55.586,67.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.123 | Acc: 38.223,55.508,67.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.125 | Acc: 38.195,55.479,67.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.872 | Acc: 29.688,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.272 | Acc: 25.037,47.433,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.267 | Acc: 25.248,46.989,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.280 | Acc: 25.205,46.696,55.725,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 3.046 | Acc: 36.719,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.049 | Acc: 37.760,56.436,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.079 | Acc: 37.633,56.098,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.055 | Acc: 38.409,56.481,68.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.061 | Acc: 38.503,56.520,68.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.059 | Acc: 38.614,56.397,68.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.059 | Acc: 38.604,56.347,68.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.071 | Acc: 38.492,56.289,68.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.083 | Acc: 38.422,56.012,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.094 | Acc: 38.363,55.849,67.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.095 | Acc: 38.285,55.857,67.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.099 | Acc: 38.246,55.773,67.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.109 | Acc: 38.171,55.621,67.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.115 | Acc: 38.212,55.565,67.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.117 | Acc: 38.245,55.560,67.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.115 | Acc: 38.214,55.567,67.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.112 | Acc: 38.284,55.590,67.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.113 | Acc: 38.213,55.563,67.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.114 | Acc: 38.307,55.529,67.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.118 | Acc: 38.320,55.541,67.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.460 | Acc: 28.125,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 27.790,45.126,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.308 | Acc: 28.239,45.141,53.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.323 | Acc: 27.754,45.184,53.612,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 2.700 | Acc: 42.188,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.976 | Acc: 38.393,58.371,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.979 | Acc: 37.843,58.803,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 38.025,57.966,68.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.032 | Acc: 38.175,57.330,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.039 | Acc: 38.289,57.317,68.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.049 | Acc: 38.507,56.792,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.052 | Acc: 38.442,56.627,68.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.054 | Acc: 38.393,56.609,68.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.052 | Acc: 38.480,56.587,68.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.058 | Acc: 38.386,56.437,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.060 | Acc: 38.543,56.480,68.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.065 | Acc: 38.544,56.506,68.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.069 | Acc: 38.548,56.382,68.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.075 | Acc: 38.392,56.297,68.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.079 | Acc: 38.299,56.193,68.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.090 | Acc: 38.211,56.033,68.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.088 | Acc: 38.213,56.005,68.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.091 | Acc: 38.320,56.010,68.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.097 | Acc: 38.263,56.014,67.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.078 | Acc: 32.031,50.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.088 | Acc: 31.176,45.833,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.080 | Acc: 31.860,45.732,56.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.096 | Acc: 31.481,45.517,56.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 2.851 | Acc: 39.844,55.469,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.041 | Acc: 38.579,56.473,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.016 | Acc: 38.319,56.993,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.996 | Acc: 38.947,57.659,69.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.020 | Acc: 38.995,57.022,69.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.043 | Acc: 38.683,56.691,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.046 | Acc: 38.798,56.547,68.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.055 | Acc: 38.697,56.455,68.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.059 | Acc: 38.679,56.415,68.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.069 | Acc: 38.670,56.345,68.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.076 | Acc: 38.573,56.320,68.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.075 | Acc: 38.660,56.342,68.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.075 | Acc: 38.628,56.282,68.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.079 | Acc: 38.515,56.214,68.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.076 | Acc: 38.540,56.247,68.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.079 | Acc: 38.504,56.240,68.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.077 | Acc: 38.542,56.194,68.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.083 | Acc: 38.448,56.023,68.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.090 | Acc: 38.322,55.915,67.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.092 | Acc: 38.337,55.910,67.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.770 | Acc: 35.938,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.009 | Acc: 30.618,49.033,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.019 | Acc: 30.583,48.266,57.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.031 | Acc: 30.622,47.964,56.429,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 3.165 | Acc: 33.594,53.125,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.983 | Acc: 38.318,56.808,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.024 | Acc: 37.862,56.574,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.023 | Acc: 38.473,56.826,68.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.027 | Acc: 38.474,56.838,68.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.036 | Acc: 38.676,56.931,68.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.034 | Acc: 38.843,56.870,68.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.043 | Acc: 38.725,56.649,68.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.044 | Acc: 38.708,56.701,68.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.055 | Acc: 38.665,56.505,68.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.049 | Acc: 38.584,56.596,68.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.054 | Acc: 38.539,56.529,68.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.057 | Acc: 38.541,56.493,68.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.063 | Acc: 38.458,56.424,68.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.065 | Acc: 38.515,56.370,68.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.062 | Acc: 38.611,56.393,68.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.063 | Acc: 38.598,56.403,68.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.062 | Acc: 38.584,56.449,68.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.067 | Acc: 38.491,56.436,68.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.074 | Acc: 38.408,56.344,67.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.604 | Acc: 28.125,42.188,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.593 | Acc: 24.368,40.997,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 23.914,41.768,55.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 23.924,41.573,54.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 2.740 | Acc: 45.312,62.500,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.034 | Acc: 36.942,56.622,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.026 | Acc: 38.338,56.860,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.036 | Acc: 38.140,56.570,69.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.045 | Acc: 38.590,56.501,68.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.037 | Acc: 38.567,56.730,68.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.030 | Acc: 38.468,56.909,68.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.021 | Acc: 38.569,57.059,69.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.033 | Acc: 38.446,56.983,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.041 | Acc: 38.381,56.897,68.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.035 | Acc: 38.464,56.841,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.034 | Acc: 38.543,56.770,68.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.036 | Acc: 38.589,56.717,68.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.047 | Acc: 38.476,56.717,68.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.049 | Acc: 38.476,56.725,68.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.054 | Acc: 38.502,56.647,68.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.057 | Acc: 38.525,56.639,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.059 | Acc: 38.444,56.646,68.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.063 | Acc: 38.495,56.635,68.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.064 | Acc: 38.536,56.627,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.841 | Acc: 25.000,50.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.900 | Acc: 30.841,48.400,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.924 | Acc: 30.964,47.618,58.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.951 | Acc: 31.173,47.503,57.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 3.128 | Acc: 39.844,55.469,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.968 | Acc: 39.695,57.292,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.015 | Acc: 39.386,56.421,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.020 | Acc: 38.947,56.340,68.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.020 | Acc: 39.034,56.858,68.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.026 | Acc: 38.660,56.691,68.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.041 | Acc: 38.507,56.392,68.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.046 | Acc: 38.630,56.366,68.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.051 | Acc: 38.485,56.585,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.049 | Acc: 38.592,56.470,68.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.056 | Acc: 38.581,56.405,68.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.055 | Acc: 38.578,56.462,68.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.053 | Acc: 38.570,56.493,68.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.060 | Acc: 38.608,56.397,68.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.062 | Acc: 38.568,56.350,68.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.059 | Acc: 38.554,56.393,68.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.056 | Acc: 38.671,56.381,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.057 | Acc: 38.650,56.326,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.060 | Acc: 38.586,56.291,68.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.061 | Acc: 38.587,56.316,68.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.809 | Acc: 35.156,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.898 | Acc: 30.171,48.958,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.945 | Acc: 30.107,47.637,58.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.975 | Acc: 30.187,46.785,57.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 3.024 | Acc: 39.062,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.064 | Acc: 38.430,57.031,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.056 | Acc: 38.681,57.546,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.060 | Acc: 38.371,57.185,69.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.039 | Acc: 38.735,57.041,68.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.025 | Acc: 38.846,57.194,68.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.026 | Acc: 38.882,57.096,68.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.023 | Acc: 39.090,57.142,68.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.029 | Acc: 39.062,56.915,68.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.023 | Acc: 38.993,56.884,68.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.032 | Acc: 38.841,56.744,69.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.027 | Acc: 38.893,56.763,68.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.034 | Acc: 38.803,56.743,68.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.033 | Acc: 38.847,56.747,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.037 | Acc: 38.854,56.625,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.037 | Acc: 38.790,56.551,68.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.041 | Acc: 38.751,56.523,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.042 | Acc: 38.774,56.539,68.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.041 | Acc: 38.768,56.482,68.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.040 | Acc: 38.796,56.482,68.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.190 | Acc: 34.375,42.188,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.107 | Acc: 32.626,43.415,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.132 | Acc: 32.698,43.140,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.157 | Acc: 32.172,42.559,55.353,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 3.311 | Acc: 36.719,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.915 | Acc: 39.509,58.668,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.948 | Acc: 38.586,58.232,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.948 | Acc: 38.806,58.184,70.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.971 | Acc: 39.169,57.812,69.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.959 | Acc: 39.364,57.890,70.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.969 | Acc: 39.108,57.587,69.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.980 | Acc: 38.946,57.281,69.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.986 | Acc: 38.752,57.138,69.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.987 | Acc: 38.722,57.096,69.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.998 | Acc: 38.860,57.012,69.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.998 | Acc: 38.882,57.010,69.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.005 | Acc: 38.855,56.996,69.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.006 | Acc: 38.907,57.028,69.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.014 | Acc: 38.854,56.912,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.018 | Acc: 38.790,56.925,68.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.021 | Acc: 38.751,56.880,68.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.027 | Acc: 38.616,56.885,68.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.028 | Acc: 38.612,56.880,68.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.029 | Acc: 38.722,56.873,68.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.609 | Acc: 24.219,44.531,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.518 | Acc: 25.298,43.080,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.560 | Acc: 25.000,42.473,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 25.295,42.661,52.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 2.899 | Acc: 42.188,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.031 | Acc: 38.988,58.147,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.007 | Acc: 39.596,57.222,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 39.447,57.108,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.997 | Acc: 39.082,57.542,69.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.977 | Acc: 39.101,57.921,69.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.977 | Acc: 39.146,57.587,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.983 | Acc: 39.074,57.657,69.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.983 | Acc: 39.223,57.609,69.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.994 | Acc: 39.119,57.225,69.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.995 | Acc: 39.086,57.101,69.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.999 | Acc: 38.985,56.978,69.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.999 | Acc: 39.043,57.005,69.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.001 | Acc: 39.071,57.064,69.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.010 | Acc: 39.037,56.853,68.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.010 | Acc: 39.081,56.888,68.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.012 | Acc: 39.041,56.824,68.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.014 | Acc: 39.113,56.850,68.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.020 | Acc: 39.123,56.817,68.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.022 | Acc: 39.099,56.767,68.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.051 | Acc: 32.031,50.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.032 | Acc: 30.655,47.805,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.031 | Acc: 30.393,47.199,57.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.018 | Acc: 30.302,46.888,57.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 2.678 | Acc: 45.312,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 39.360,59.040,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.893 | Acc: 39.958,59.280,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.900 | Acc: 40.100,58.811,70.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.916 | Acc: 39.612,58.536,70.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.915 | Acc: 39.372,58.338,70.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.933 | Acc: 39.463,58.310,70.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.954 | Acc: 39.389,58.006,70.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.953 | Acc: 39.490,58.011,70.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.961 | Acc: 39.438,57.812,69.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.962 | Acc: 39.432,57.770,69.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.979 | Acc: 39.218,57.551,69.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.989 | Acc: 39.144,57.498,69.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.996 | Acc: 39.137,57.334,69.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.002 | Acc: 39.140,57.279,69.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.006 | Acc: 39.120,57.247,69.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.009 | Acc: 39.038,57.197,69.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.012 | Acc: 38.991,57.105,69.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.017 | Acc: 38.993,57.057,69.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.020 | Acc: 38.980,57.031,68.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.096 | Acc: 32.031,50.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.368 | Acc: 28.869,44.085,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.358 | Acc: 29.383,43.979,55.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 28.868,43.724,55.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 2.926 | Acc: 38.281,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.970 | Acc: 39.509,58.445,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.935 | Acc: 39.768,58.841,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.931 | Acc: 38.998,58.607,70.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.924 | Acc: 39.198,58.275,70.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.935 | Acc: 39.542,58.099,70.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.948 | Acc: 39.411,57.858,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.949 | Acc: 39.351,57.785,70.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.946 | Acc: 39.101,57.817,70.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.962 | Acc: 38.903,57.851,69.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.965 | Acc: 39.090,57.882,69.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.970 | Acc: 39.059,57.858,69.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.986 | Acc: 38.904,57.569,69.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.994 | Acc: 38.823,57.507,69.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.997 | Acc: 38.837,57.473,69.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.998 | Acc: 38.850,57.584,69.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.003 | Acc: 38.714,57.513,69.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.007 | Acc: 38.712,57.473,69.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.006 | Acc: 38.773,57.525,69.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.007 | Acc: 38.812,57.476,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.347 | Acc: 25.781,46.094,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.174 | Acc: 28.237,45.387,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.239 | Acc: 28.335,44.798,55.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.288 | Acc: 28.291,44.134,55.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 2.832 | Acc: 35.938,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 39.211,58.594,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.927 | Acc: 39.215,57.889,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 39.293,57.672,70.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.932 | Acc: 39.188,57.890,70.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.934 | Acc: 39.356,57.929,70.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.948 | Acc: 39.179,57.625,69.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.948 | Acc: 39.306,57.713,69.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.954 | Acc: 39.266,57.667,69.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.958 | Acc: 39.425,57.730,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.958 | Acc: 39.443,57.828,69.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.962 | Acc: 39.430,57.777,69.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.968 | Acc: 39.507,57.725,69.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.972 | Acc: 39.467,57.699,69.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.976 | Acc: 39.393,57.707,69.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.977 | Acc: 39.340,57.706,69.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.981 | Acc: 39.235,57.742,69.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.990 | Acc: 39.159,57.599,69.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.994 | Acc: 39.117,57.555,69.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.995 | Acc: 39.067,57.491,69.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.473 | Acc: 21.875,35.938,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.274 | Acc: 18.192,34.338,50.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.327 | Acc: 18.369,34.242,50.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.371 | Acc: 17.956,34.042,49.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 3.236 | Acc: 36.719,50.000,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.881 | Acc: 39.955,59.449,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.940 | Acc: 38.720,58.518,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.948 | Acc: 39.050,58.466,70.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.948 | Acc: 39.111,58.324,70.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.961 | Acc: 38.815,57.944,70.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.967 | Acc: 39.056,57.871,70.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.972 | Acc: 39.118,58.045,69.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.963 | Acc: 39.271,58.181,70.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.974 | Acc: 39.123,57.912,69.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.963 | Acc: 39.350,58.019,69.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.963 | Acc: 39.324,57.954,69.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.974 | Acc: 39.189,57.877,69.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.976 | Acc: 39.266,57.848,69.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.977 | Acc: 39.263,57.749,69.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.982 | Acc: 39.226,57.644,69.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.987 | Acc: 39.165,57.628,69.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.986 | Acc: 39.159,57.632,69.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.987 | Acc: 39.127,57.590,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.989 | Acc: 39.104,57.554,69.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.884 | Acc: 27.344,50.781,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.266 | Acc: 26.042,44.643,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.240 | Acc: 27.649,44.360,57.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 27.113,43.827,56.468,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 2.645 | Acc: 46.094,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.874 | Acc: 40.625,58.557,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.913 | Acc: 40.473,59.108,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.923 | Acc: 39.895,58.581,70.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.950 | Acc: 39.169,57.919,70.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.952 | Acc: 39.318,58.037,70.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.930 | Acc: 39.256,58.258,70.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.936 | Acc: 39.428,57.984,70.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.947 | Acc: 39.160,57.774,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.958 | Acc: 39.145,57.623,70.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.953 | Acc: 39.269,57.797,70.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.955 | Acc: 39.197,57.858,70.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.953 | Acc: 39.263,57.903,70.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.954 | Acc: 39.233,57.807,70.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.967 | Acc: 39.126,57.715,69.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.968 | Acc: 39.223,57.667,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.969 | Acc: 39.299,57.703,69.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.973 | Acc: 39.266,57.641,69.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.978 | Acc: 39.171,57.574,69.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.980 | Acc: 39.165,57.612,69.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.682 | Acc: 20.312,36.719,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.611 | Acc: 24.926,39.993,52.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.690 | Acc: 24.123,39.520,51.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.726 | Acc: 23.950,39.178,51.409,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 2.743 | Acc: 44.531,57.812,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.853 | Acc: 40.625,58.854,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.875 | Acc: 40.187,58.784,71.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.898 | Acc: 40.356,58.619,71.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.903 | Acc: 40.017,58.787,70.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.916 | Acc: 39.596,58.555,70.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.918 | Acc: 39.624,58.471,70.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.919 | Acc: 39.639,58.577,70.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.918 | Acc: 39.625,58.565,70.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.924 | Acc: 39.460,58.400,70.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.926 | Acc: 39.576,58.368,70.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.939 | Acc: 39.423,58.180,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.935 | Acc: 39.646,58.308,70.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.936 | Acc: 39.601,58.351,70.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.942 | Acc: 39.388,58.168,70.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.951 | Acc: 39.255,58.085,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.953 | Acc: 39.245,57.951,69.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.963 | Acc: 39.246,57.780,69.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.967 | Acc: 39.314,57.741,69.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.970 | Acc: 39.286,57.683,69.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.289 | Acc: 28.906,50.000,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.239 | Acc: 26.600,44.829,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.258 | Acc: 26.524,44.817,55.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.278 | Acc: 26.486,44.518,55.187,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 3.145 | Acc: 41.406,53.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.958 | Acc: 40.327,57.850,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.901 | Acc: 39.234,58.232,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.909 | Acc: 39.203,58.145,71.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.898 | Acc: 39.574,58.227,71.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.922 | Acc: 39.488,58.014,70.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.927 | Acc: 39.482,58.258,70.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.928 | Acc: 39.384,58.311,70.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.929 | Acc: 39.528,58.113,70.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.933 | Acc: 39.524,58.089,70.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.936 | Acc: 39.568,58.022,70.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.938 | Acc: 39.490,58.014,70.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.939 | Acc: 39.588,57.994,70.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.946 | Acc: 39.610,57.950,70.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.956 | Acc: 39.530,57.860,70.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.956 | Acc: 39.454,57.883,70.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.956 | Acc: 39.452,57.905,70.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.960 | Acc: 39.363,57.861,69.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.963 | Acc: 39.359,57.817,69.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.962 | Acc: 39.374,57.870,69.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.117 | Acc: 28.906,54.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.239 | Acc: 27.121,47.470,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.215 | Acc: 27.382,46.856,57.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.235 | Acc: 27.254,45.889,56.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 2.889 | Acc: 39.062,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.753 | Acc: 41.369,60.603,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.820 | Acc: 40.473,59.794,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.858 | Acc: 39.869,59.477,71.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.875 | Acc: 39.622,59.047,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.878 | Acc: 39.875,59.158,71.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.879 | Acc: 39.928,58.975,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.887 | Acc: 39.860,58.887,71.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.886 | Acc: 39.917,58.967,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.895 | Acc: 39.766,58.758,70.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.896 | Acc: 39.684,58.691,70.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.905 | Acc: 39.738,58.587,70.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.909 | Acc: 39.815,58.496,70.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.913 | Acc: 39.811,58.432,70.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.921 | Acc: 39.799,58.355,70.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.925 | Acc: 39.737,58.207,70.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.927 | Acc: 39.793,58.231,70.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.928 | Acc: 39.786,58.250,70.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.933 | Acc: 39.736,58.191,70.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.939 | Acc: 39.754,58.120,69.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.947 | Acc: 24.219,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.182 | Acc: 29.353,44.085,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.204 | Acc: 30.069,44.303,55.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.272 | Acc: 29.380,44.006,54.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 2.904 | Acc: 38.281,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.891 | Acc: 39.397,58.594,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.881 | Acc: 39.958,59.508,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.870 | Acc: 39.780,59.554,71.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.848 | Acc: 39.796,59.684,71.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.857 | Acc: 40.076,59.669,71.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.874 | Acc: 39.850,59.369,71.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.876 | Acc: 39.794,59.259,71.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.886 | Acc: 39.815,59.064,71.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.898 | Acc: 39.835,58.823,70.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.911 | Acc: 39.824,58.718,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.922 | Acc: 39.685,58.562,70.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.918 | Acc: 39.672,58.552,70.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.922 | Acc: 39.628,58.543,70.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.934 | Acc: 39.432,58.285,70.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.937 | Acc: 39.390,58.324,70.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.933 | Acc: 39.505,58.343,70.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.935 | Acc: 39.514,58.268,69.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.939 | Acc: 39.491,58.202,69.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.944 | Acc: 39.444,58.177,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.050 | Acc: 21.094,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.185 | Acc: 26.562,47.954,58.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.274 | Acc: 25.819,46.665,57.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.303 | Acc: 26.012,46.363,57.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 3.030 | Acc: 37.500,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.874 | Acc: 39.137,59.375,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.903 | Acc: 39.425,58.746,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.895 | Acc: 39.421,58.440,70.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.883 | Acc: 39.738,58.777,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.882 | Acc: 39.650,58.795,70.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.882 | Acc: 39.663,58.800,70.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.888 | Acc: 39.622,58.649,70.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.887 | Acc: 39.538,58.637,70.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.895 | Acc: 39.507,58.598,70.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.898 | Acc: 39.377,58.586,70.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.896 | Acc: 39.395,58.569,70.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.902 | Acc: 39.341,58.461,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.906 | Acc: 39.476,58.351,70.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.913 | Acc: 39.377,58.277,70.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.914 | Acc: 39.364,58.256,70.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.917 | Acc: 39.364,58.192,70.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.920 | Acc: 39.431,58.108,70.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.924 | Acc: 39.420,58.120,70.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.926 | Acc: 39.454,58.153,70.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.900 | Acc: 34.375,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.893 | Acc: 30.618,49.144,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.930 | Acc: 30.602,48.285,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.939 | Acc: 30.315,47.938,57.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.761 | Acc: 39.844,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.815 | Acc: 40.216,59.487,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.825 | Acc: 39.939,59.508,72.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.854 | Acc: 39.639,59.285,71.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.853 | Acc: 39.776,59.327,71.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.865 | Acc: 39.797,59.135,71.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.878 | Acc: 39.766,59.033,71.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.875 | Acc: 39.755,58.882,71.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.886 | Acc: 39.688,58.827,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.902 | Acc: 39.494,58.628,70.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.903 | Acc: 39.653,58.652,70.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.914 | Acc: 39.540,58.520,70.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.915 | Acc: 39.562,58.480,70.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.917 | Acc: 39.479,58.474,70.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.926 | Acc: 39.402,58.385,70.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.927 | Acc: 39.405,58.360,70.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.930 | Acc: 39.316,58.360,70.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.930 | Acc: 39.342,58.328,70.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.934 | Acc: 39.329,58.213,70.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.935 | Acc: 39.343,58.208,70.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.200 | Acc: 31.250,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.420 | Acc: 28.571,42.708,55.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.466 | Acc: 27.611,41.730,53.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.476 | Acc: 27.677,41.624,53.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 3.022 | Acc: 38.281,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.854 | Acc: 39.621,59.189,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.809 | Acc: 40.511,60.004,72.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.805 | Acc: 40.702,60.246,72.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.810 | Acc: 40.538,60.089,72.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.830 | Acc: 40.439,59.878,72.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.839 | Acc: 40.412,59.788,72.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.849 | Acc: 40.221,59.619,71.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.853 | Acc: 40.135,59.569,71.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.855 | Acc: 40.012,59.444,71.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.862 | Acc: 39.902,59.391,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.867 | Acc: 39.936,59.333,71.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.873 | Acc: 39.954,59.236,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.884 | Acc: 39.802,59.136,71.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.884 | Acc: 39.719,58.994,70.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.889 | Acc: 39.750,59.027,70.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.899 | Acc: 39.676,58.801,70.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.904 | Acc: 39.688,58.708,70.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.910 | Acc: 39.621,58.641,70.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.914 | Acc: 39.592,58.602,70.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.256 | Acc: 26.562,44.531,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.849 | Acc: 25.632,40.588,52.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.872 | Acc: 25.572,40.015,52.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.854 | Acc: 25.154,39.677,51.870,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 2.838 | Acc: 38.281,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.801 | Acc: 41.109,59.673,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.805 | Acc: 41.254,59.909,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.805 | Acc: 41.048,59.580,72.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.821 | Acc: 40.606,59.298,72.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.834 | Acc: 40.323,59.305,71.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.831 | Acc: 40.425,59.485,71.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.832 | Acc: 40.281,59.619,71.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.822 | Acc: 40.416,59.841,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.828 | Acc: 40.565,59.729,71.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.841 | Acc: 40.458,59.608,71.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.853 | Acc: 40.420,59.439,71.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.863 | Acc: 40.259,59.287,71.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.865 | Acc: 40.206,59.267,71.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.872 | Acc: 40.208,59.175,71.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.880 | Acc: 40.140,59.110,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.888 | Acc: 40.041,59.073,70.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.893 | Acc: 39.979,58.997,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.899 | Acc: 39.919,58.869,70.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.901 | Acc: 39.942,58.846,70.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.335 | Acc: 29.688,43.750,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 26.972,41.220,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 26.772,40.930,52.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.590 | Acc: 27.088,40.817,52.946,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 2.820 | Acc: 41.406,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.845 | Acc: 40.141,59.970,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.828 | Acc: 40.206,59.813,71.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.835 | Acc: 39.882,59.670,71.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.850 | Acc: 39.834,59.578,71.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.856 | Acc: 39.875,59.329,71.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.859 | Acc: 39.818,59.304,71.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.857 | Acc: 39.927,59.314,71.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.865 | Acc: 39.887,59.016,71.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.871 | Acc: 39.904,59.056,71.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.863 | Acc: 39.976,59.060,71.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.874 | Acc: 39.886,58.862,70.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.877 | Acc: 40.029,58.915,70.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.882 | Acc: 39.969,58.917,70.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.886 | Acc: 39.908,58.891,70.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 39.901,58.861,70.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.893 | Acc: 39.878,58.810,70.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.898 | Acc: 39.853,58.734,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.905 | Acc: 39.787,58.657,70.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.906 | Acc: 39.838,58.663,70.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.173 | Acc: 28.906,45.312,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 23.400,44.234,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.466 | Acc: 23.552,43.960,54.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.461 | Acc: 23.642,43.891,54.547,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 2.716 | Acc: 43.750,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.850 | Acc: 38.914,59.561,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.828 | Acc: 39.520,59.775,72.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 39.383,60.259,72.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.833 | Acc: 39.130,59.819,72.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.848 | Acc: 39.171,59.638,71.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.851 | Acc: 39.327,59.691,71.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.862 | Acc: 39.240,59.375,71.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.870 | Acc: 39.291,59.365,71.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.880 | Acc: 39.451,59.353,71.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.883 | Acc: 39.478,59.161,71.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.883 | Acc: 39.487,59.142,71.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.893 | Acc: 39.400,59.080,71.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.895 | Acc: 39.455,59.016,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.901 | Acc: 39.527,58.950,70.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.908 | Acc: 39.530,58.869,70.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.905 | Acc: 39.549,58.898,70.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.905 | Acc: 39.571,58.894,70.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.908 | Acc: 39.539,58.810,70.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.912 | Acc: 39.553,58.741,70.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.823 | Acc: 29.688,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.858 | Acc: 31.213,47.991,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.880 | Acc: 30.812,48.190,59.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.910 | Acc: 30.738,47.733,59.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.823 | Acc: 44.531,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.827 | Acc: 39.100,59.003,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.853 | Acc: 38.643,58.822,72.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.840 | Acc: 39.011,58.978,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.841 | Acc: 39.313,59.172,72.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.874 | Acc: 39.140,59.004,71.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.873 | Acc: 39.424,59.033,71.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.868 | Acc: 39.556,59.098,71.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.871 | Acc: 39.635,59.045,71.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.867 | Acc: 39.637,59.129,71.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.868 | Acc: 39.560,59.076,71.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.869 | Acc: 39.589,59.120,71.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.866 | Acc: 39.558,59.174,71.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.877 | Acc: 39.544,59.031,71.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.883 | Acc: 39.671,58.961,71.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 39.678,58.908,71.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.892 | Acc: 39.639,58.842,70.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.895 | Acc: 39.704,58.905,70.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.895 | Acc: 39.755,58.903,70.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.896 | Acc: 39.829,58.961,70.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.137 | Acc: 26.562,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.032 | Acc: 26.451,48.326,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.064 | Acc: 26.562,47.370,57.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.126 | Acc: 26.716,47.067,57.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 3.000 | Acc: 33.594,50.781,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.818 | Acc: 40.141,59.301,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.851 | Acc: 39.634,59.184,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.817 | Acc: 39.908,59.311,72.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.814 | Acc: 40.037,59.076,72.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.846 | Acc: 39.658,58.687,72.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.849 | Acc: 39.715,58.516,71.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.844 | Acc: 39.711,58.655,71.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.851 | Acc: 39.684,58.696,71.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.860 | Acc: 39.606,58.775,71.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.864 | Acc: 39.638,58.800,71.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.866 | Acc: 39.671,58.774,71.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 39.669,58.772,71.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.877 | Acc: 39.568,58.588,71.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.878 | Acc: 39.599,58.583,71.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.884 | Acc: 39.566,58.531,70.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.887 | Acc: 39.574,58.504,70.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 39.654,58.550,70.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.894 | Acc: 39.604,58.533,70.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.896 | Acc: 39.604,58.528,70.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.553 | Acc: 31.250,54.688,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.865 | Acc: 31.287,47.842,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.893 | Acc: 31.707,46.951,58.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.944 | Acc: 31.698,46.414,58.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 2.393 | Acc: 48.438,65.625,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.837 | Acc: 38.244,59.970,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.822 | Acc: 38.262,59.985,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.801 | Acc: 39.267,60.387,72.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.843 | Acc: 39.622,59.578,71.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.854 | Acc: 39.728,59.491,71.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.872 | Acc: 39.618,58.942,71.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.873 | Acc: 39.700,59.054,71.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.860 | Acc: 40.048,59.263,71.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.868 | Acc: 39.779,59.176,71.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.876 | Acc: 39.719,59.060,71.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.879 | Acc: 39.865,59.025,71.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.884 | Acc: 39.821,59.022,71.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.883 | Acc: 39.889,59.031,71.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.888 | Acc: 39.838,58.944,71.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.885 | Acc: 39.929,58.975,71.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.884 | Acc: 39.963,59.032,71.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 39.892,59.036,71.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.889 | Acc: 39.889,59.018,71.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.889 | Acc: 39.940,59.061,71.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.749 | Acc: 32.031,54.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.079 | Acc: 28.609,48.438,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.077 | Acc: 28.906,48.342,56.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.111 | Acc: 28.484,47.477,56.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 3.032 | Acc: 35.938,58.594,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.709 | Acc: 41.853,62.054,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.758 | Acc: 40.968,60.823,72.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.784 | Acc: 40.202,60.195,72.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.795 | Acc: 40.268,60.108,72.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.805 | Acc: 40.308,59.994,72.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.825 | Acc: 40.018,59.569,71.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.834 | Acc: 39.977,59.552,71.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.844 | Acc: 40.004,59.351,71.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.846 | Acc: 40.111,59.401,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.854 | Acc: 39.995,59.286,71.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.854 | Acc: 40.028,59.297,71.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.863 | Acc: 40.048,59.278,70.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.866 | Acc: 40.023,59.267,70.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.868 | Acc: 39.927,59.236,70.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.876 | Acc: 39.839,59.131,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.876 | Acc: 39.778,59.044,70.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.874 | Acc: 39.798,59.107,70.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.874 | Acc: 39.842,59.040,70.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.877 | Acc: 39.813,59.022,70.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.090 | Acc: 29.688,51.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.223 | Acc: 29.576,44.271,55.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.283 | Acc: 29.992,43.407,54.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.286 | Acc: 29.803,42.892,54.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 2.702 | Acc: 47.656,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.846 | Acc: 39.732,60.007,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.842 | Acc: 39.672,59.947,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.865 | Acc: 39.434,59.926,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.861 | Acc: 39.747,59.992,71.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.841 | Acc: 39.782,60.226,71.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.848 | Acc: 39.682,60.130,71.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.841 | Acc: 39.849,60.167,71.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.846 | Acc: 39.902,59.918,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.849 | Acc: 40.094,59.858,71.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.848 | Acc: 40.217,59.779,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.850 | Acc: 40.250,59.683,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.848 | Acc: 40.301,59.719,71.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.845 | Acc: 40.392,59.713,71.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.850 | Acc: 40.316,59.717,71.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 40.280,59.702,71.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.856 | Acc: 40.275,59.652,71.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.861 | Acc: 40.240,59.613,71.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.861 | Acc: 40.184,59.633,71.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.864 | Acc: 40.102,59.576,71.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.789 | Acc: 19.531,45.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.521 | Acc: 25.632,40.885,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 25.267,41.006,53.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 24.910,40.958,53.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 3.061 | Acc: 39.062,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.758 | Acc: 39.955,61.272,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.826 | Acc: 39.901,60.137,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.806 | Acc: 40.113,60.592,71.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.808 | Acc: 40.230,60.349,71.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.834 | Acc: 39.913,59.978,71.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.843 | Acc: 39.818,59.595,71.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.855 | Acc: 39.683,59.375,71.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.852 | Acc: 39.800,59.433,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.852 | Acc: 40.055,59.492,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 40.085,59.530,71.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.852 | Acc: 40.021,59.460,71.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.858 | Acc: 39.996,59.424,71.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.859 | Acc: 39.978,59.381,71.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.864 | Acc: 40.036,59.333,71.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.862 | Acc: 40.114,59.305,71.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.862 | Acc: 40.167,59.331,71.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.867 | Acc: 40.116,59.288,71.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.867 | Acc: 40.153,59.301,71.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.868 | Acc: 40.100,59.293,71.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.075 | Acc: 29.688,45.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.148 | Acc: 28.237,43.713,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.131 | Acc: 28.201,44.550,57.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.147 | Acc: 28.125,44.582,57.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.975 | Acc: 38.281,56.250,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.738 | Acc: 40.774,61.049,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.753 | Acc: 40.530,60.328,72.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.791 | Acc: 40.126,60.092,72.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 40.326,60.243,72.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 40.408,60.141,72.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.805 | Acc: 40.186,59.995,72.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.804 | Acc: 40.215,60.084,72.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.807 | Acc: 40.106,60.083,72.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.813 | Acc: 40.224,60.022,71.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.818 | Acc: 40.186,60.005,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.824 | Acc: 40.183,59.958,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.834 | Acc: 40.230,59.758,71.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.843 | Acc: 40.152,59.626,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.851 | Acc: 40.141,59.492,71.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.851 | Acc: 40.088,59.559,71.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.849 | Acc: 40.165,59.616,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.846 | Acc: 40.192,59.625,71.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.850 | Acc: 40.212,59.557,71.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 40.102,59.406,71.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.086 | Acc: 31.250,42.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.482 | Acc: 26.935,43.415,54.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.497 | Acc: 26.715,42.607,53.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.534 | Acc: 26.793,42.316,52.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 2.947 | Acc: 35.938,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.699 | Acc: 41.741,61.347,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.692 | Acc: 41.635,61.452,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.720 | Acc: 41.496,61.514,73.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.739 | Acc: 40.963,60.735,73.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.763 | Acc: 40.919,60.412,72.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.772 | Acc: 40.670,60.305,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.779 | Acc: 40.603,60.189,72.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.767 | Acc: 40.741,60.297,72.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 40.729,60.152,72.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 40.415,59.768,72.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.818 | Acc: 40.378,59.661,72.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.827 | Acc: 40.359,59.582,71.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.832 | Acc: 40.335,59.701,71.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 40.286,59.692,71.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 40.311,59.720,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 40.236,59.672,71.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.846 | Acc: 40.226,59.574,71.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.854 | Acc: 40.006,59.492,71.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.855 | Acc: 40.036,59.506,71.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.849 | Acc: 22.656,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.980 | Acc: 28.943,48.958,58.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.027 | Acc: 27.858,47.694,58.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.054 | Acc: 27.830,47.374,57.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 2.786 | Acc: 41.406,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.719 | Acc: 40.625,61.124,73.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.710 | Acc: 40.034,61.452,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 40.535,61.270,73.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.730 | Acc: 40.741,60.957,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.731 | Acc: 40.826,60.914,73.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.742 | Acc: 40.774,60.576,72.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.743 | Acc: 40.885,60.478,72.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.760 | Acc: 40.814,60.151,72.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.770 | Acc: 40.634,59.932,72.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.776 | Acc: 40.668,59.900,72.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.787 | Acc: 40.590,59.842,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.796 | Acc: 40.486,59.631,71.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.806 | Acc: 40.353,59.492,71.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 40.230,59.417,71.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.824 | Acc: 40.111,59.240,71.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.826 | Acc: 40.236,59.331,71.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.830 | Acc: 40.197,59.283,71.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.835 | Acc: 40.127,59.275,71.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.839 | Acc: 40.139,59.295,71.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.590 | Acc: 34.375,58.594,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.791 | Acc: 33.147,52.121,59.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.833 | Acc: 33.556,50.267,58.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.878 | Acc: 33.363,49.769,57.838,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 2.612 | Acc: 41.406,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.759 | Acc: 40.179,60.714,73.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.743 | Acc: 40.339,60.995,73.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.746 | Acc: 39.895,60.617,73.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.751 | Acc: 40.355,60.629,72.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.747 | Acc: 40.339,60.628,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.759 | Acc: 40.334,60.569,72.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.768 | Acc: 40.420,60.544,72.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.768 | Acc: 40.368,60.525,72.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.778 | Acc: 40.344,60.368,72.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.782 | Acc: 40.400,60.277,72.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.788 | Acc: 40.310,60.234,72.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 40.359,60.279,72.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.793 | Acc: 40.412,60.255,72.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.796 | Acc: 40.397,60.176,72.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.804 | Acc: 40.428,60.084,72.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.809 | Acc: 40.413,59.979,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.814 | Acc: 40.426,59.886,71.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.822 | Acc: 40.404,59.834,71.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.829 | Acc: 40.399,59.732,71.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.732 | Acc: 28.906,42.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.734 | Acc: 21.875,42.708,54.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.782 | Acc: 21.475,41.559,54.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.777 | Acc: 21.183,41.650,54.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 3.006 | Acc: 33.594,55.469,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.767 | Acc: 40.848,60.342,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.756 | Acc: 40.777,60.709,72.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.759 | Acc: 40.535,60.592,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.749 | Acc: 40.345,60.831,73.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.753 | Acc: 40.633,60.713,72.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.759 | Acc: 40.644,60.802,72.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.776 | Acc: 40.442,60.516,72.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 40.470,60.326,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.786 | Acc: 40.401,60.299,72.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.795 | Acc: 40.349,60.257,72.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.799 | Acc: 40.310,60.132,72.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.801 | Acc: 40.362,60.166,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.806 | Acc: 40.406,60.105,72.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 40.308,59.973,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.816 | Acc: 40.327,59.990,71.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.820 | Acc: 40.250,59.881,71.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.826 | Acc: 40.300,59.817,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.831 | Acc: 40.270,59.739,71.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.833 | Acc: 40.227,59.662,71.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.805 | Acc: 32.812,46.875,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.138 | Acc: 31.436,46.763,56.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.114 | Acc: 31.479,46.608,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.111 | Acc: 31.199,46.580,56.481,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 2.547 | Acc: 39.062,63.281,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.771 | Acc: 40.699,60.938,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.745 | Acc: 41.521,61.338,73.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.752 | Acc: 41.637,60.938,72.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 40.953,60.426,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.755 | Acc: 40.989,60.412,72.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.764 | Acc: 40.980,60.343,72.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.770 | Acc: 40.802,60.284,72.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.777 | Acc: 40.712,60.268,72.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.784 | Acc: 40.599,60.074,72.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.786 | Acc: 40.621,60.172,72.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.788 | Acc: 40.586,60.050,72.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 40.593,59.903,72.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.810 | Acc: 40.544,59.914,72.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.822 | Acc: 40.544,59.647,71.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.834 | Acc: 40.433,59.489,71.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.834 | Acc: 40.333,59.482,71.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.837 | Acc: 40.332,59.506,71.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.836 | Acc: 40.300,59.518,71.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 40.373,59.527,71.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.875 | Acc: 24.219,46.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.895 | Acc: 20.908,39.955,53.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.032 | Acc: 19.893,38.853,51.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.051 | Acc: 19.787,38.640,51.575,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 2.875 | Acc: 37.500,57.031,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.770 | Acc: 41.555,61.049,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.773 | Acc: 41.387,60.671,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.775 | Acc: 40.996,60.528,73.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 40.789,60.282,73.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.768 | Acc: 40.880,60.319,72.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.783 | Acc: 40.573,60.189,72.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.800 | Acc: 40.326,59.940,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.799 | Acc: 40.280,59.986,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.794 | Acc: 40.396,60.074,72.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.798 | Acc: 40.403,60.145,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.803 | Acc: 40.275,60.054,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 40.307,59.981,72.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.801 | Acc: 40.401,60.040,72.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.811 | Acc: 40.330,59.928,72.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.816 | Acc: 40.347,59.860,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 40.408,59.869,72.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.821 | Acc: 40.368,59.838,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.825 | Acc: 40.268,59.778,71.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 40.373,59.740,71.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.397 | Acc: 31.250,57.812,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.858 | Acc: 31.659,50.707,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.902 | Acc: 31.498,48.857,58.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.935 | Acc: 31.327,48.361,57.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 2.991 | Acc: 42.969,60.156,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.637 | Acc: 42.001,62.314,73.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.669 | Acc: 41.673,61.871,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.721 | Acc: 40.996,60.899,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.731 | Acc: 40.895,60.899,73.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.734 | Acc: 41.035,60.783,73.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.739 | Acc: 41.012,60.712,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.746 | Acc: 40.847,60.683,73.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.759 | Acc: 40.678,60.578,72.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.767 | Acc: 40.392,60.571,72.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.773 | Acc: 40.473,60.537,72.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.781 | Acc: 40.275,60.400,72.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.779 | Acc: 40.340,60.409,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.779 | Acc: 40.383,60.279,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.782 | Acc: 40.391,60.229,72.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.786 | Acc: 40.428,60.255,72.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.787 | Acc: 40.440,60.159,72.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.802 | Acc: 40.343,59.948,72.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.810 | Acc: 40.357,59.788,72.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.817 | Acc: 40.377,59.683,71.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.256 | Acc: 26.562,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.344 | Acc: 25.967,47.061,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.280 | Acc: 27.001,47.428,55.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.276 | Acc: 26.691,47.157,55.635,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.488 | Acc: 46.094,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.767 | Acc: 40.216,60.565,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.751 | Acc: 40.873,60.804,73.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.746 | Acc: 40.920,60.950,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.750 | Acc: 40.982,61.034,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.754 | Acc: 40.873,60.729,72.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.759 | Acc: 41.038,60.737,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.771 | Acc: 40.769,60.649,72.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 40.902,60.578,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.785 | Acc: 40.789,60.463,72.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 40.784,60.327,72.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.782 | Acc: 40.904,60.499,72.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.782 | Acc: 40.972,60.425,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.788 | Acc: 40.870,60.381,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.788 | Acc: 40.956,60.443,72.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.797 | Acc: 40.931,60.346,72.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.800 | Acc: 40.837,60.271,72.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.804 | Acc: 40.769,60.273,72.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.811 | Acc: 40.651,60.124,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.815 | Acc: 40.559,60.146,71.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.979 | Acc: 29.688,53.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.069 | Acc: 29.576,46.689,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 29.402,46.132,57.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.084 | Acc: 29.188,46.247,57.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 2.935 | Acc: 39.844,59.375,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.709 | Acc: 40.885,61.868,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.709 | Acc: 41.044,61.547,73.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 41.393,61.680,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.734 | Acc: 40.876,61.265,73.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.749 | Acc: 40.780,61.046,73.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.749 | Acc: 40.890,60.912,73.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.754 | Acc: 40.974,60.888,72.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.762 | Acc: 40.746,60.675,72.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.760 | Acc: 40.767,60.657,72.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.757 | Acc: 40.773,60.650,72.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.757 | Acc: 40.841,60.740,72.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.763 | Acc: 40.790,60.620,72.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.769 | Acc: 40.736,60.527,72.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.771 | Acc: 40.750,60.476,72.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.777 | Acc: 40.752,60.475,72.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.780 | Acc: 40.810,60.387,72.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.788 | Acc: 40.746,60.255,72.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.794 | Acc: 40.759,60.130,72.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.801 | Acc: 40.721,60.105,71.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.975 | Acc: 32.031,44.531,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.935 | Acc: 32.068,47.768,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.999 | Acc: 31.631,47.027,57.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.001 | Acc: 31.980,47.285,57.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 2.493 | Acc: 42.188,67.188,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.643 | Acc: 42.336,61.384,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.694 | Acc: 41.044,60.842,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 41.163,61.258,74.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.711 | Acc: 41.020,61.555,74.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.735 | Acc: 40.594,61.402,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.752 | Acc: 40.554,61.286,73.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.754 | Acc: 40.636,61.131,73.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.752 | Acc: 40.746,61.098,73.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.759 | Acc: 40.621,60.899,73.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.764 | Acc: 40.629,60.868,73.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.766 | Acc: 40.639,60.810,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.780 | Acc: 40.499,60.581,72.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.782 | Acc: 40.511,60.444,72.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.787 | Acc: 40.500,60.487,72.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.791 | Acc: 40.552,60.398,72.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.796 | Acc: 40.559,60.327,72.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.803 | Acc: 40.444,60.220,72.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.803 | Acc: 40.439,60.178,72.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.802 | Acc: 40.443,60.199,72.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.520 | Acc: 25.000,42.969,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.636 | Acc: 26.079,43.304,51.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.655 | Acc: 26.315,42.759,51.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.655 | Acc: 25.973,42.303,51.895,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.813 | Acc: 36.719,60.156,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.660 | Acc: 40.774,61.644,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.704 | Acc: 40.091,61.223,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 40.574,61.130,74.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.729 | Acc: 40.770,61.024,73.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.734 | Acc: 40.733,60.976,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.747 | Acc: 40.470,60.770,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.755 | Acc: 40.564,60.721,73.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.755 | Acc: 40.494,60.690,73.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.765 | Acc: 40.465,60.510,73.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.777 | Acc: 40.295,60.335,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.778 | Acc: 40.374,60.308,72.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.777 | Acc: 40.528,60.360,72.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.783 | Acc: 40.481,60.321,72.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.788 | Acc: 40.458,60.201,72.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.796 | Acc: 40.495,60.097,72.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.795 | Acc: 40.613,60.134,72.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.804 | Acc: 40.529,60.060,72.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.805 | Acc: 40.586,60.037,72.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.807 | Acc: 40.518,59.984,72.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.714 | Acc: 29.688,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.912 | Acc: 30.246,49.033,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.940 | Acc: 30.297,48.704,58.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.962 | Acc: 30.366,48.028,58.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.544 | Acc: 48.438,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.686 | Acc: 42.448,61.086,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.696 | Acc: 41.806,61.280,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.720 | Acc: 41.176,61.040,73.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.728 | Acc: 41.001,60.561,73.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.747 | Acc: 40.857,60.481,72.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.746 | Acc: 40.967,60.486,72.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.744 | Acc: 40.935,60.533,72.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.750 | Acc: 40.795,60.345,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.750 | Acc: 40.716,60.372,72.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.760 | Acc: 40.831,60.250,72.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.764 | Acc: 40.872,60.344,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.770 | Acc: 40.865,60.257,72.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.769 | Acc: 40.838,60.198,72.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.768 | Acc: 40.931,60.192,72.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.770 | Acc: 40.960,60.198,72.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.777 | Acc: 40.878,60.185,72.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.782 | Acc: 40.836,60.120,72.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.785 | Acc: 40.796,60.145,72.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.790 | Acc: 40.769,60.056,72.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.097 | Acc: 25.781,53.125,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.397 | Acc: 29.353,44.978,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.379 | Acc: 29.059,43.998,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.437 | Acc: 29.367,43.404,53.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 2.575 | Acc: 44.531,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.739 | Acc: 41.629,61.012,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.750 | Acc: 41.197,60.595,73.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.727 | Acc: 41.586,60.938,73.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.729 | Acc: 41.368,60.774,73.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.733 | Acc: 41.623,60.744,73.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.751 | Acc: 41.271,60.402,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.745 | Acc: 41.390,60.566,73.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.744 | Acc: 41.659,60.675,73.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.744 | Acc: 41.635,60.739,73.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.743 | Acc: 41.569,60.731,73.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.752 | Acc: 41.413,60.619,73.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.757 | Acc: 41.358,60.681,72.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.769 | Acc: 41.313,60.554,72.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.777 | Acc: 41.206,60.462,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.773 | Acc: 41.248,60.546,72.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.780 | Acc: 41.041,60.502,72.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.781 | Acc: 41.047,60.504,72.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.787 | Acc: 40.906,60.401,72.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.793 | Acc: 40.937,60.339,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.059 | Acc: 24.219,50.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.977 | Acc: 29.501,47.396,58.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.060 | Acc: 28.106,47.008,57.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.066 | Acc: 28.023,47.054,57.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 3.328 | Acc: 30.469,57.031,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.731 | Acc: 40.699,61.310,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 40.396,60.880,73.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.717 | Acc: 41.112,61.322,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.696 | Acc: 41.686,61.632,73.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.700 | Acc: 41.708,61.440,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.708 | Acc: 41.684,61.441,73.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.718 | Acc: 41.373,61.336,73.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.722 | Acc: 41.421,61.428,73.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.726 | Acc: 41.411,61.382,73.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.733 | Acc: 41.224,61.163,73.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.737 | Acc: 41.194,61.093,73.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.745 | Acc: 41.114,60.980,72.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.752 | Acc: 41.044,60.905,72.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.758 | Acc: 41.003,60.979,72.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.765 | Acc: 40.931,60.896,72.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.771 | Acc: 40.800,60.816,72.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.774 | Acc: 40.760,60.823,72.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.778 | Acc: 40.742,60.771,72.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.776 | Acc: 40.791,60.714,72.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.916 | Acc: 28.125,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.008 | Acc: 27.009,48.251,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.025 | Acc: 27.553,47.161,59.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.012 | Acc: 27.549,47.695,60.028,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 2.615 | Acc: 44.531,58.594,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.703 | Acc: 40.737,61.421,73.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.709 | Acc: 40.968,61.966,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 40.971,61.744,73.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.711 | Acc: 40.972,61.564,73.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.722 | Acc: 41.174,61.324,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.726 | Acc: 40.864,61.241,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.719 | Acc: 41.079,61.303,73.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.730 | Acc: 41.047,60.938,73.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.731 | Acc: 41.130,60.963,73.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.736 | Acc: 41.154,60.930,73.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.741 | Acc: 41.152,60.923,72.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.748 | Acc: 41.267,60.853,72.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.758 | Acc: 41.161,60.713,72.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.761 | Acc: 41.178,60.676,72.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.766 | Acc: 41.196,60.636,72.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.778 | Acc: 41.068,60.390,72.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.786 | Acc: 41.040,60.353,72.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.790 | Acc: 41.019,60.325,72.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.790 | Acc: 40.959,60.351,72.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.757 | Acc: 32.812,52.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.898 | Acc: 32.552,50.260,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.934 | Acc: 31.460,49.352,58.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.975 | Acc: 31.058,48.348,57.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 2.628 | Acc: 40.625,58.594,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.672 | Acc: 40.662,61.644,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.705 | Acc: 41.216,61.319,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.713 | Acc: 40.958,60.912,73.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.701 | Acc: 41.522,61.343,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.700 | Acc: 41.476,61.719,73.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.681 | Acc: 41.632,62.029,74.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.695 | Acc: 41.307,61.846,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.713 | Acc: 41.130,61.607,73.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.724 | Acc: 40.957,61.425,73.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.723 | Acc: 41.029,61.396,73.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.725 | Acc: 41.138,61.277,73.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.738 | Acc: 41.076,61.151,73.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.748 | Acc: 41.008,61.129,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.753 | Acc: 41.036,61.146,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.751 | Acc: 41.074,61.158,72.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.756 | Acc: 40.971,61.042,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.757 | Acc: 41.051,60.974,72.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.757 | Acc: 41.071,60.974,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.756 | Acc: 41.107,60.995,72.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.223 | Acc: 14.844,35.938,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.007 | Acc: 15.960,41.034,53.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.043 | Acc: 16.521,40.111,53.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.047 | Acc: 16.560,39.818,53.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 2.410 | Acc: 43.750,60.938,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.706 | Acc: 41.146,62.016,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 40.244,61.890,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 40.279,61.821,74.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.728 | Acc: 40.557,61.728,73.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.733 | Acc: 40.532,61.564,73.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.731 | Acc: 40.651,61.622,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.736 | Acc: 40.608,61.547,73.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.734 | Acc: 40.863,61.636,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.742 | Acc: 40.975,61.369,73.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.744 | Acc: 41.134,61.377,72.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.751 | Acc: 41.155,61.206,72.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.754 | Acc: 40.985,61.067,72.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.745 | Acc: 41.155,61.189,72.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.749 | Acc: 41.195,61.063,72.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.752 | Acc: 41.196,61.047,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.760 | Acc: 41.078,60.894,72.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.766 | Acc: 40.978,60.779,72.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.769 | Acc: 40.945,60.771,72.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.772 | Acc: 41.029,60.663,72.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.000 | Acc: 28.125,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.165 | Acc: 26.897,48.549,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.196 | Acc: 26.582,47.466,58.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.216 | Acc: 26.358,46.901,57.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.787 | Acc: 36.719,51.562,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.744 | Acc: 40.179,59.226,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.698 | Acc: 40.492,61.128,73.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.696 | Acc: 41.060,61.424,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.717 | Acc: 41.011,60.976,73.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.721 | Acc: 40.965,61.262,73.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.728 | Acc: 41.103,61.338,73.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.734 | Acc: 41.218,61.281,72.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.735 | Acc: 41.285,61.229,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.739 | Acc: 41.462,61.145,73.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.743 | Acc: 41.449,61.109,72.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.744 | Acc: 41.350,61.044,72.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.746 | Acc: 41.286,61.051,72.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.740 | Acc: 41.346,61.192,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.742 | Acc: 41.409,61.213,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.748 | Acc: 41.287,61.127,72.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.759 | Acc: 41.209,60.993,72.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.767 | Acc: 40.980,60.866,72.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.769 | Acc: 40.924,60.866,72.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.771 | Acc: 40.898,60.821,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.310 | Acc: 23.438,46.094,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.600 | Acc: 23.698,45.015,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.620 | Acc: 23.838,44.150,55.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.661 | Acc: 23.617,43.673,54.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 2.922 | Acc: 40.625,56.250,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.665 | Acc: 41.815,61.161,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.715 | Acc: 41.273,61.414,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.688 | Acc: 41.265,61.808,73.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.704 | Acc: 41.184,61.391,73.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.717 | Acc: 41.166,61.309,73.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.717 | Acc: 41.316,61.247,73.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.734 | Acc: 41.174,60.865,73.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.744 | Acc: 41.164,60.831,73.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.751 | Acc: 41.221,60.704,72.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.752 | Acc: 41.123,60.681,72.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.757 | Acc: 41.074,60.704,72.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.760 | Acc: 41.124,60.662,72.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.756 | Acc: 41.182,60.674,72.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.758 | Acc: 41.139,60.634,72.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.761 | Acc: 41.175,60.556,72.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.764 | Acc: 41.156,60.516,72.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.765 | Acc: 41.099,60.555,72.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.767 | Acc: 41.101,60.596,72.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.769 | Acc: 41.111,60.554,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.001 | Acc: 23.438,50.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.240 | Acc: 25.112,46.243,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.252 | Acc: 25.305,45.827,58.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.281 | Acc: 25.154,45.581,57.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 2.619 | Acc: 44.531,59.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.697 | Acc: 41.629,60.714,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.709 | Acc: 40.739,60.938,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 40.407,61.066,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.712 | Acc: 40.654,61.236,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.714 | Acc: 40.803,61.494,73.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.717 | Acc: 41.006,61.719,73.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.715 | Acc: 40.974,61.564,73.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.711 | Acc: 41.086,61.675,73.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.707 | Acc: 41.126,61.805,73.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.716 | Acc: 41.049,61.559,73.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.720 | Acc: 41.085,61.471,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.722 | Acc: 40.884,61.382,73.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.727 | Acc: 41.005,61.282,73.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.729 | Acc: 40.978,61.254,73.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.735 | Acc: 40.916,61.200,72.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.737 | Acc: 40.958,61.127,72.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.740 | Acc: 40.943,60.992,72.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.740 | Acc: 40.971,61.041,72.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.744 | Acc: 40.949,61.036,72.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.008 | Acc: 36.719,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.264 | Acc: 28.646,46.763,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.299 | Acc: 28.316,46.208,56.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.331 | Acc: 28.381,45.735,56.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.801 | Acc: 35.156,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.672 | Acc: 42.188,61.533,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 41.864,61.280,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 41.931,61.335,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.721 | Acc: 41.802,61.449,73.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.704 | Acc: 41.816,61.572,73.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.717 | Acc: 41.807,61.357,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.720 | Acc: 41.600,61.143,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.725 | Acc: 41.513,61.146,73.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.724 | Acc: 41.536,61.106,73.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.728 | Acc: 41.437,60.969,73.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.741 | Acc: 41.212,60.754,72.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.738 | Acc: 41.264,60.743,72.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.740 | Acc: 41.301,60.665,72.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.741 | Acc: 41.309,60.693,72.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.736 | Acc: 41.435,60.792,72.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.741 | Acc: 41.404,60.738,72.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.746 | Acc: 41.429,60.800,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.748 | Acc: 41.356,60.803,72.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.749 | Acc: 41.271,60.808,72.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.225 | Acc: 36.719,53.125,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.494 | Acc: 35.231,54.501,63.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.504 | Acc: 35.042,53.392,62.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.516 | Acc: 35.156,53.253,62.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 3.125 | Acc: 42.188,50.781,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.623 | Acc: 42.001,62.091,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.661 | Acc: 41.597,61.128,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.654 | Acc: 42.290,61.988,74.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.655 | Acc: 42.052,62.211,74.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.665 | Acc: 41.847,61.773,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.669 | Acc: 41.923,61.790,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.692 | Acc: 41.694,61.336,73.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.687 | Acc: 41.775,61.437,73.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.699 | Acc: 41.600,61.274,73.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.699 | Acc: 41.686,61.303,73.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.705 | Acc: 41.724,61.273,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.707 | Acc: 41.675,61.310,73.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.710 | Acc: 41.673,61.291,73.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.717 | Acc: 41.562,61.310,73.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.722 | Acc: 41.593,61.254,73.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.726 | Acc: 41.533,61.166,73.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.729 | Acc: 41.514,61.086,72.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.735 | Acc: 41.421,60.998,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.743 | Acc: 41.326,60.821,72.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.160 | Acc: 31.250,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.605 | Acc: 26.488,42.225,54.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 26.200,42.207,53.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 26.101,42.200,53.727,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 2.765 | Acc: 42.188,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.727 | Acc: 40.997,60.342,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.695 | Acc: 41.273,61.528,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.689 | Acc: 41.112,61.744,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.694 | Acc: 41.242,61.535,74.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.693 | Acc: 41.600,61.564,74.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.702 | Acc: 41.497,61.370,73.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.717 | Acc: 41.412,61.176,73.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.727 | Acc: 41.367,61.234,73.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.730 | Acc: 41.342,61.032,73.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.733 | Acc: 41.325,60.906,73.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.740 | Acc: 41.187,60.870,72.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.743 | Acc: 41.260,60.847,72.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.750 | Acc: 41.149,60.746,72.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.754 | Acc: 41.134,60.748,72.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.754 | Acc: 41.149,60.771,72.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.754 | Acc: 41.209,60.762,72.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.752 | Acc: 41.239,60.784,72.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.751 | Acc: 41.227,60.821,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.750 | Acc: 41.211,60.814,72.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.009 | Acc: 26.562,50.000,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.246 | Acc: 27.902,46.801,56.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.220 | Acc: 27.934,46.418,55.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.252 | Acc: 27.856,46.043,55.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.542 | Acc: 37.500,62.500,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.628 | Acc: 41.741,63.728,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.672 | Acc: 41.502,62.500,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.679 | Acc: 41.419,61.706,74.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.684 | Acc: 41.310,61.613,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.670 | Acc: 41.878,61.781,74.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.660 | Acc: 42.181,61.764,74.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.670 | Acc: 42.226,61.691,74.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.680 | Acc: 42.236,61.525,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.680 | Acc: 42.114,61.464,73.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.685 | Acc: 42.114,61.454,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.688 | Acc: 41.975,61.390,73.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.704 | Acc: 41.737,61.200,73.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.711 | Acc: 41.619,61.084,73.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.720 | Acc: 41.618,60.935,73.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.723 | Acc: 41.559,60.896,73.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.728 | Acc: 41.465,60.867,73.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.735 | Acc: 41.443,60.775,73.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.739 | Acc: 41.400,60.734,72.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.745 | Acc: 41.293,60.673,72.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.153 | Acc: 28.125,53.125,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.338 | Acc: 27.195,44.792,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.432 | Acc: 26.296,44.703,54.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.455 | Acc: 26.050,44.224,54.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.500 | Acc: 39.844,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.730 | Acc: 40.885,60.826,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.663 | Acc: 41.502,61.776,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.638 | Acc: 41.317,61.578,74.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.645 | Acc: 41.580,61.767,74.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.665 | Acc: 41.429,61.703,74.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.678 | Acc: 41.251,61.570,74.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.674 | Acc: 41.528,61.702,74.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.680 | Acc: 41.586,61.578,74.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.692 | Acc: 41.631,61.455,73.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.693 | Acc: 41.449,61.365,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.699 | Acc: 41.297,61.295,73.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.704 | Acc: 41.390,61.301,73.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.718 | Acc: 41.263,61.039,73.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.722 | Acc: 41.287,60.968,73.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.727 | Acc: 41.238,60.854,73.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.730 | Acc: 41.250,60.816,72.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.734 | Acc: 41.193,60.782,72.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.737 | Acc: 41.168,60.799,72.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.738 | Acc: 41.238,60.763,72.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.070 | Acc: 27.344,51.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.031 | Acc: 26.711,47.954,58.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.058 | Acc: 26.277,47.923,57.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.063 | Acc: 26.089,48.066,57.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 2.567 | Acc: 45.312,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.699 | Acc: 40.662,60.751,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.691 | Acc: 40.892,60.728,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.688 | Acc: 41.329,60.745,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.680 | Acc: 41.744,61.150,74.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.675 | Acc: 41.925,61.193,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.683 | Acc: 41.800,61.235,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.681 | Acc: 41.850,61.275,74.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.689 | Acc: 41.751,61.277,73.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.705 | Acc: 41.497,61.037,73.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.710 | Acc: 41.402,60.934,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.714 | Acc: 41.286,60.860,73.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.714 | Acc: 41.354,60.886,73.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.715 | Acc: 41.433,60.994,73.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.719 | Acc: 41.473,61.029,73.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.718 | Acc: 41.554,61.054,73.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.721 | Acc: 41.504,61.084,73.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.719 | Acc: 41.537,61.034,73.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.722 | Acc: 41.545,60.994,73.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.726 | Acc: 41.523,60.938,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.383 | Acc: 22.656,44.531,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.368 | Acc: 25.260,45.275,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 25.000,44.760,56.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.375 | Acc: 25.115,44.941,56.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 3.011 | Acc: 36.719,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.620 | Acc: 42.150,62.872,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.684 | Acc: 42.054,61.700,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.661 | Acc: 42.431,62.052,74.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.659 | Acc: 42.544,62.133,74.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.671 | Acc: 42.172,62.144,73.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.687 | Acc: 41.871,61.822,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.690 | Acc: 41.772,61.636,73.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.697 | Acc: 41.557,61.471,73.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.710 | Acc: 41.415,61.218,73.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.710 | Acc: 41.445,61.054,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.708 | Acc: 41.576,61.227,73.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.719 | Acc: 41.409,61.006,73.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.725 | Acc: 41.406,60.988,73.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.731 | Acc: 41.403,60.901,73.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.734 | Acc: 41.432,60.901,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.736 | Acc: 41.414,60.882,73.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.736 | Acc: 41.452,60.921,72.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.740 | Acc: 41.372,60.886,72.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.737 | Acc: 41.361,60.952,72.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.023 | Acc: 25.000,46.094,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.001 | Acc: 29.874,47.396,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.997 | Acc: 30.011,47.199,59.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.016 | Acc: 29.880,46.632,58.965,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 2.487 | Acc: 40.625,67.188,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.571 | Acc: 41.815,63.839,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.583 | Acc: 42.302,63.567,75.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.632 | Acc: 41.509,62.513,75.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.639 | Acc: 41.541,62.278,75.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.654 | Acc: 41.236,62.090,74.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.661 | Acc: 41.238,61.996,74.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.674 | Acc: 41.284,61.885,74.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.676 | Acc: 41.392,61.927,74.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.686 | Acc: 41.281,61.689,73.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.695 | Acc: 41.332,61.571,73.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.699 | Acc: 41.427,61.581,73.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.700 | Acc: 41.575,61.527,73.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.710 | Acc: 41.517,61.357,73.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.711 | Acc: 41.462,61.282,73.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.712 | Acc: 41.494,61.231,73.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.717 | Acc: 41.435,61.230,73.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.718 | Acc: 41.473,61.283,73.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.719 | Acc: 41.538,61.338,73.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.720 | Acc: 41.624,61.280,73.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.458 | Acc: 25.000,44.531,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.339 | Acc: 23.996,44.010,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.442 | Acc: 23.323,43.312,56.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.462 | Acc: 23.284,43.225,56.404,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.608 | Acc: 42.188,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.642 | Acc: 42.299,61.644,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.658 | Acc: 41.806,61.452,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.626 | Acc: 41.944,62.039,74.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.620 | Acc: 42.351,62.568,74.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.629 | Acc: 42.311,62.299,74.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.641 | Acc: 42.355,62.087,74.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.647 | Acc: 42.487,62.051,74.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.654 | Acc: 42.372,62.034,73.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.660 | Acc: 42.287,61.982,73.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.662 | Acc: 42.292,61.874,73.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.675 | Acc: 42.081,61.733,73.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.676 | Acc: 42.009,61.728,73.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.681 | Acc: 42.029,61.710,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.688 | Acc: 41.987,61.697,73.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.690 | Acc: 41.936,61.763,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.694 | Acc: 41.934,61.690,73.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.702 | Acc: 41.826,61.547,73.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.710 | Acc: 41.789,61.496,73.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.716 | Acc: 41.712,61.430,72.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.998 | Acc: 27.344,46.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.146 | Acc: 30.618,48.065,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.207 | Acc: 29.954,47.409,57.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.201 | Acc: 29.752,47.208,57.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 2.533 | Acc: 41.406,59.375,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 41.704,62.128,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.673 | Acc: 41.349,62.138,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.658 | Acc: 41.317,62.410,74.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.670 | Acc: 40.799,62.346,74.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.668 | Acc: 41.252,62.245,74.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.664 | Acc: 41.581,62.268,74.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.671 | Acc: 41.545,61.979,74.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.673 | Acc: 41.431,61.675,74.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.678 | Acc: 41.510,61.607,74.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.684 | Acc: 41.453,61.521,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.686 | Acc: 41.463,61.514,73.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.687 | Acc: 41.610,61.686,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.685 | Acc: 41.586,61.659,73.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.692 | Acc: 41.568,61.630,73.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.693 | Acc: 41.562,61.555,73.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.703 | Acc: 41.435,61.449,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.708 | Acc: 41.482,61.396,73.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.708 | Acc: 41.452,61.444,73.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.711 | Acc: 41.505,61.438,73.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.322 | Acc: 34.375,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.829 | Acc: 30.543,51.674,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.855 | Acc: 30.774,51.048,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 31.096,50.564,58.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 2.826 | Acc: 33.594,58.594,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.675 | Acc: 40.513,62.388,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.659 | Acc: 40.606,61.795,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.648 | Acc: 40.881,61.552,74.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.662 | Acc: 40.770,61.535,74.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.668 | Acc: 40.849,61.587,74.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.676 | Acc: 41.142,61.570,74.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.678 | Acc: 41.262,61.597,74.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.681 | Acc: 41.188,61.622,74.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.690 | Acc: 41.268,61.529,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.696 | Acc: 41.371,61.517,73.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.701 | Acc: 41.452,61.542,73.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.694 | Acc: 41.494,61.518,73.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.697 | Acc: 41.598,61.506,73.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.699 | Acc: 41.609,61.580,73.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.701 | Acc: 41.549,61.620,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.701 | Acc: 41.642,61.663,73.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.700 | Acc: 41.706,61.629,73.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.705 | Acc: 41.724,61.598,73.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.710 | Acc: 41.685,61.514,73.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.873 | Acc: 29.688,53.125,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.962 | Acc: 28.646,50.484,59.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.967 | Acc: 28.449,49.390,59.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.940 | Acc: 28.586,49.539,59.375,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.714 | Acc: 42.969,61.719,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.650 | Acc: 41.406,61.905,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.683 | Acc: 41.235,61.357,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.674 | Acc: 41.522,61.719,74.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.677 | Acc: 41.387,61.487,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.674 | Acc: 41.538,61.610,74.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.665 | Acc: 41.890,61.841,74.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.670 | Acc: 42.005,61.652,74.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.668 | Acc: 41.984,61.792,73.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.681 | Acc: 41.700,61.503,73.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.677 | Acc: 41.783,61.567,73.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.690 | Acc: 41.498,61.386,73.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.700 | Acc: 41.445,61.375,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.702 | Acc: 41.532,61.363,73.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.710 | Acc: 41.406,61.224,73.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.720 | Acc: 41.209,61.057,73.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.723 | Acc: 41.212,61.086,73.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.726 | Acc: 41.200,61.059,73.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.726 | Acc: 41.292,60.979,73.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.728 | Acc: 41.312,60.884,73.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.826 | Acc: 35.156,53.125,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.027 | Acc: 30.915,49.740,57.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.053 | Acc: 30.659,49.123,57.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.047 | Acc: 30.277,49.168,57.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 2.680 | Acc: 37.500,55.469,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.638 | Acc: 43.006,62.351,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.619 | Acc: 42.092,62.786,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.616 | Acc: 41.726,62.500,74.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.622 | Acc: 41.995,62.336,74.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.631 | Acc: 41.878,62.121,74.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.641 | Acc: 41.884,62.126,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.665 | Acc: 41.550,61.625,73.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.668 | Acc: 41.528,61.515,73.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.669 | Acc: 41.609,61.486,73.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.677 | Acc: 41.562,61.540,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.690 | Acc: 41.562,61.333,73.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.690 | Acc: 41.623,61.401,73.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.696 | Acc: 41.523,61.306,73.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.701 | Acc: 41.479,61.216,73.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.702 | Acc: 41.474,61.213,73.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.705 | Acc: 41.572,61.237,73.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.709 | Acc: 41.615,61.224,72.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.711 | Acc: 41.638,61.197,72.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.716 | Acc: 41.687,61.126,72.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.802 | Acc: 20.312,46.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.825 | Acc: 20.201,39.621,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.912 | Acc: 19.150,38.510,53.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.928 | Acc: 18.776,38.038,52.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.219 | Acc: 52.344,71.094,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.670 | Acc: 42.076,61.979,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.664 | Acc: 41.406,61.776,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.639 | Acc: 41.573,62.590,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.624 | Acc: 41.609,62.847,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.628 | Acc: 41.832,62.678,74.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.642 | Acc: 41.800,62.577,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.654 | Acc: 41.628,62.411,74.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.652 | Acc: 41.702,62.408,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.662 | Acc: 41.596,62.189,74.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.674 | Acc: 41.659,62.139,74.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.671 | Acc: 41.689,62.207,74.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.675 | Acc: 41.698,62.137,74.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.674 | Acc: 41.741,62.111,73.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.680 | Acc: 41.684,61.980,73.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.691 | Acc: 41.611,61.833,73.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.696 | Acc: 41.630,61.733,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.696 | Acc: 41.651,61.648,73.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.692 | Acc: 41.668,61.727,73.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.699 | Acc: 41.642,61.624,73.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.038 | Acc: 30.469,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.916 | Acc: 31.362,48.810,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.891 | Acc: 31.936,48.971,59.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.894 | Acc: 31.609,49.308,59.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 2.859 | Acc: 35.156,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.600 | Acc: 43.192,63.467,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.593 | Acc: 42.797,62.271,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.601 | Acc: 42.239,62.154,75.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.632 | Acc: 42.120,62.211,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.639 | Acc: 42.041,62.175,74.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.653 | Acc: 41.949,61.945,74.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.666 | Acc: 41.955,61.907,74.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.667 | Acc: 42.095,61.893,74.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.671 | Acc: 41.937,61.857,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.673 | Acc: 41.915,61.750,73.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.678 | Acc: 41.929,61.627,73.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.682 | Acc: 41.837,61.664,73.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.680 | Acc: 41.825,61.656,73.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.677 | Acc: 41.918,61.644,73.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.688 | Acc: 41.871,61.576,73.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.692 | Acc: 41.864,61.519,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.686 | Acc: 41.913,61.554,73.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.689 | Acc: 41.872,61.487,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.694 | Acc: 41.794,61.473,73.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.921 | Acc: 28.125,47.656,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.018 | Acc: 28.571,49.144,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.064 | Acc: 27.744,48.095,58.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.098 | Acc: 27.818,48.092,58.235,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.481 | Acc: 46.094,60.156,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.573 | Acc: 42.597,61.942,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.605 | Acc: 42.340,62.271,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.652 | Acc: 41.765,61.770,74.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.628 | Acc: 42.168,62.220,74.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.628 | Acc: 42.396,62.291,74.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.647 | Acc: 42.033,61.977,74.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.671 | Acc: 41.827,61.370,73.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.668 | Acc: 41.906,61.452,74.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.671 | Acc: 41.989,61.330,74.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.680 | Acc: 41.912,61.252,73.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.680 | Acc: 42.064,61.305,73.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.681 | Acc: 42.145,61.216,73.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.683 | Acc: 42.113,61.231,73.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.688 | Acc: 42.060,61.185,73.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.693 | Acc: 42.027,61.171,73.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.696 | Acc: 42.112,61.186,73.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.699 | Acc: 42.032,61.206,73.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.704 | Acc: 41.984,61.176,73.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.705 | Acc: 41.950,61.171,73.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.035 | Acc: 29.688,47.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.006 | Acc: 28.274,46.912,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.062 | Acc: 27.839,47.732,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.093 | Acc: 28.279,47.490,59.029,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.948 | Acc: 41.406,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.674 | Acc: 41.890,61.868,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.661 | Acc: 41.959,61.604,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.653 | Acc: 42.456,61.808,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.630 | Acc: 43.133,62.172,74.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.631 | Acc: 42.806,61.935,74.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.647 | Acc: 42.633,61.674,74.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.668 | Acc: 42.215,61.359,74.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.668 | Acc: 42.280,61.389,74.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.682 | Acc: 42.218,61.201,73.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.687 | Acc: 42.188,61.225,73.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.682 | Acc: 42.166,61.333,73.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.679 | Acc: 41.954,61.443,73.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.686 | Acc: 41.954,61.413,73.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.685 | Acc: 41.998,61.446,73.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.684 | Acc: 41.995,61.594,73.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.688 | Acc: 41.956,61.617,73.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.687 | Acc: 41.968,61.627,73.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.695 | Acc: 41.880,61.513,73.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.703 | Acc: 41.857,61.411,73.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.085 | Acc: 30.469,49.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.234 | Acc: 28.757,46.875,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.261 | Acc: 28.087,45.960,56.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.270 | Acc: 27.882,46.043,56.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.762 | Acc: 41.406,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.682 | Acc: 41.406,62.314,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.664 | Acc: 40.739,62.138,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.679 | Acc: 41.317,61.732,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.675 | Acc: 41.242,61.680,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.672 | Acc: 41.352,61.502,74.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.670 | Acc: 41.626,61.745,74.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.666 | Acc: 41.595,61.868,74.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.659 | Acc: 41.824,61.893,74.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.659 | Acc: 41.898,61.952,74.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.659 | Acc: 41.962,61.956,74.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.656 | Acc: 42.283,62.097,74.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.659 | Acc: 42.149,62.056,74.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.663 | Acc: 42.056,62.006,74.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.664 | Acc: 42.118,62.044,74.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.666 | Acc: 42.060,61.952,74.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.672 | Acc: 42.039,61.918,73.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.677 | Acc: 42.023,61.792,73.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.676 | Acc: 42.099,61.801,73.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.677 | Acc: 42.159,61.811,73.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.736 | Acc: 28.125,53.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.880 | Acc: 28.348,49.665,62.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.964 | Acc: 27.096,48.819,60.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.987 | Acc: 26.908,48.668,60.797,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 2.348 | Acc: 48.438,66.406,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.585 | Acc: 42.746,62.909,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.584 | Acc: 42.664,63.205,75.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.607 | Acc: 42.111,62.410,75.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.613 | Acc: 42.197,62.481,75.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.627 | Acc: 42.505,62.338,74.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.635 | Acc: 42.452,62.410,74.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.650 | Acc: 42.381,62.378,74.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.652 | Acc: 42.484,62.364,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.660 | Acc: 42.446,62.194,73.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.658 | Acc: 42.506,62.228,73.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.658 | Acc: 42.396,62.217,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.656 | Acc: 42.350,62.208,74.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.657 | Acc: 42.325,62.210,73.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.668 | Acc: 42.276,62.136,73.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.670 | Acc: 42.180,62.093,73.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.669 | Acc: 42.253,62.089,73.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.671 | Acc: 42.240,62.083,73.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.677 | Acc: 42.170,61.952,73.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.678 | Acc: 42.134,61.907,73.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.053 | Acc: 25.000,53.125,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.085 | Acc: 27.455,48.661,58.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.145 | Acc: 26.715,47.694,56.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.157 | Acc: 26.575,47.374,56.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 2.469 | Acc: 50.000,63.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.590 | Acc: 43.490,62.649,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.591 | Acc: 42.988,62.500,75.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.593 | Acc: 42.585,62.628,75.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.595 | Acc: 42.631,62.240,75.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.605 | Acc: 42.427,62.222,75.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.605 | Acc: 42.439,62.390,75.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.619 | Acc: 42.393,62.256,74.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.630 | Acc: 42.319,62.272,74.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.631 | Acc: 42.373,62.181,74.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.642 | Acc: 42.168,62.170,74.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.646 | Acc: 42.163,62.048,74.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.650 | Acc: 42.210,62.036,74.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.657 | Acc: 42.155,62.039,74.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.660 | Acc: 42.151,62.000,74.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.666 | Acc: 42.130,61.862,73.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.666 | Acc: 42.107,61.896,73.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.673 | Acc: 42.075,61.778,73.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.675 | Acc: 42.086,61.807,73.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.678 | Acc: 42.087,61.762,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.081 | Acc: 31.250,46.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.447 | Acc: 27.381,45.312,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.479 | Acc: 27.001,44.112,54.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.493 | Acc: 27.357,43.865,54.303,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 2.629 | Acc: 41.406,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.670 | Acc: 41.332,62.463,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.624 | Acc: 41.673,63.186,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.612 | Acc: 42.277,63.409,75.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.613 | Acc: 42.429,63.223,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.612 | Acc: 42.389,62.887,75.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.625 | Acc: 42.155,62.610,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.629 | Acc: 42.027,62.539,74.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.634 | Acc: 41.906,62.379,74.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.631 | Acc: 42.080,62.444,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.636 | Acc: 42.219,62.403,74.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.637 | Acc: 42.233,62.443,74.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.644 | Acc: 42.152,62.322,74.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.657 | Acc: 42.068,62.189,74.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.657 | Acc: 41.993,62.161,74.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.665 | Acc: 41.931,62.105,73.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.666 | Acc: 41.898,62.052,73.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.666 | Acc: 41.910,62.037,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.674 | Acc: 41.936,61.961,73.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.680 | Acc: 41.870,61.893,73.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.009 | Acc: 28.125,49.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.079 | Acc: 27.753,48.847,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.093 | Acc: 27.763,48.323,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.086 | Acc: 27.715,48.476,57.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 2.459 | Acc: 45.312,67.188,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.570 | Acc: 42.485,63.504,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.561 | Acc: 42.854,63.815,76.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.564 | Acc: 42.892,63.345,75.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.578 | Acc: 42.766,62.973,75.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.597 | Acc: 42.760,62.701,75.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.590 | Acc: 42.672,62.784,75.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.597 | Acc: 42.498,62.539,75.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.607 | Acc: 42.411,62.529,74.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.614 | Acc: 42.278,62.371,74.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.612 | Acc: 42.409,62.531,74.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.624 | Acc: 42.343,62.352,74.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.623 | Acc: 42.275,62.419,74.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.632 | Acc: 42.226,62.395,74.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.638 | Acc: 42.313,62.300,74.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.645 | Acc: 42.273,62.204,74.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.648 | Acc: 42.200,62.147,74.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.659 | Acc: 42.073,62.058,74.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.665 | Acc: 41.988,62.024,74.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.667 | Acc: 42.093,61.998,74.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.898 | Acc: 27.344,49.219,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.043 | Acc: 28.385,48.958,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.069 | Acc: 28.659,48.285,58.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.069 | Acc: 28.829,48.245,58.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 2.971 | Acc: 39.844,54.688,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.600 | Acc: 42.783,61.496,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.597 | Acc: 42.969,62.614,75.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.617 | Acc: 43.020,62.551,75.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.600 | Acc: 42.853,62.895,75.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.600 | Acc: 43.000,62.840,75.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.602 | Acc: 42.865,62.752,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.610 | Acc: 43.129,62.572,74.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.625 | Acc: 42.940,62.199,74.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.631 | Acc: 42.805,62.241,74.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.633 | Acc: 42.887,62.313,74.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.649 | Acc: 42.887,62.005,74.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.656 | Acc: 42.781,61.887,73.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.658 | Acc: 42.759,61.830,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.666 | Acc: 42.816,61.785,73.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.667 | Acc: 42.704,61.838,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.669 | Acc: 42.657,61.875,73.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.669 | Acc: 42.680,61.881,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.674 | Acc: 42.638,61.883,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.680 | Acc: 42.608,61.829,73.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.621 | Acc: 35.938,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.911 | Acc: 32.626,50.372,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.929 | Acc: 32.527,49.752,58.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.947 | Acc: 32.595,49.360,57.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 2.755 | Acc: 38.281,57.031,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.589 | Acc: 42.634,62.091,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.595 | Acc: 42.511,62.024,75.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.595 | Acc: 42.674,62.500,75.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.599 | Acc: 42.747,62.394,75.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.593 | Acc: 42.845,62.577,75.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.594 | Acc: 42.885,62.532,75.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.601 | Acc: 43.046,62.528,75.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.620 | Acc: 42.940,62.253,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.629 | Acc: 42.865,62.099,74.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.632 | Acc: 42.825,61.971,74.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.640 | Acc: 42.778,61.927,74.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.642 | Acc: 42.784,62.007,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.641 | Acc: 42.960,61.949,74.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.646 | Acc: 42.880,61.894,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.653 | Acc: 42.787,61.874,74.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.658 | Acc: 42.803,61.814,73.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.666 | Acc: 42.648,61.689,73.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.669 | Acc: 42.616,61.628,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.671 | Acc: 42.583,61.633,73.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.448 | Acc: 28.125,46.094,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.257 | Acc: 27.716,44.978,57.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.254 | Acc: 27.630,45.141,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.269 | Acc: 27.959,45.453,56.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.914 | Acc: 34.375,58.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.593 | Acc: 42.597,63.281,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.569 | Acc: 42.816,63.777,75.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.581 | Acc: 42.572,63.217,75.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.597 | Acc: 42.525,62.654,75.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.603 | Acc: 42.605,62.438,75.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.616 | Acc: 42.413,62.145,75.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.619 | Acc: 42.420,62.068,74.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.631 | Acc: 42.537,61.845,74.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.635 | Acc: 42.477,61.775,74.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.631 | Acc: 42.634,62.049,74.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.629 | Acc: 42.598,62.139,74.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.625 | Acc: 42.564,62.189,74.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.630 | Acc: 42.463,62.093,74.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.635 | Acc: 42.396,62.044,74.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.635 | Acc: 42.439,62.131,74.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.642 | Acc: 42.390,62.011,74.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.651 | Acc: 42.407,61.877,74.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.654 | Acc: 42.413,61.816,74.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.655 | Acc: 42.468,61.877,74.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.800 | Acc: 35.156,50.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.889 | Acc: 32.068,50.558,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.905 | Acc: 32.736,50.267,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.881 | Acc: 32.915,50.115,58.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 2.250 | Acc: 44.531,61.719,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.550 | Acc: 42.783,62.909,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.577 | Acc: 42.454,63.205,75.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.588 | Acc: 41.778,62.859,75.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.603 | Acc: 41.184,62.423,75.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.603 | Acc: 41.785,62.546,75.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.601 | Acc: 41.916,62.668,75.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.606 | Acc: 42.021,62.539,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.610 | Acc: 42.066,62.413,74.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.624 | Acc: 42.006,62.319,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.633 | Acc: 42.005,62.193,74.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.638 | Acc: 41.937,62.125,74.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.650 | Acc: 41.893,61.975,74.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.659 | Acc: 41.879,61.841,73.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.660 | Acc: 41.879,61.747,73.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.665 | Acc: 41.923,61.646,73.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.667 | Acc: 41.968,61.595,73.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.667 | Acc: 41.979,61.602,73.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.665 | Acc: 42.081,61.649,73.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.666 | Acc: 42.099,61.750,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.623 | Acc: 30.469,57.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.899 | Acc: 28.274,51.079,61.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.913 | Acc: 28.468,50.953,60.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.939 | Acc: 28.714,50.640,60.259,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 2.589 | Acc: 46.875,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.524 | Acc: 43.899,64.211,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.557 | Acc: 43.598,63.624,76.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.554 | Acc: 42.994,63.281,76.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.546 | Acc: 43.123,63.223,75.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.563 | Acc: 42.814,62.987,75.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.567 | Acc: 42.794,63.055,75.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.586 | Acc: 42.570,62.821,75.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.594 | Acc: 42.513,62.592,75.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.595 | Acc: 42.585,62.651,75.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.606 | Acc: 42.452,62.539,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.613 | Acc: 42.460,62.309,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.617 | Acc: 42.330,62.244,74.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.636 | Acc: 42.143,62.096,74.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.640 | Acc: 42.149,62.075,74.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.644 | Acc: 42.162,62.028,74.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.652 | Acc: 42.185,61.926,74.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.655 | Acc: 42.155,61.865,74.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.662 | Acc: 42.114,61.797,73.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.663 | Acc: 42.171,61.791,73.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.990 | Acc: 30.469,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.112 | Acc: 27.418,46.577,59.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.130 | Acc: 27.058,46.151,58.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.163 | Acc: 27.472,46.183,57.979,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 2.604 | Acc: 38.281,61.719,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.564 | Acc: 42.634,62.426,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.571 | Acc: 42.397,62.862,75.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.580 | Acc: 42.380,62.820,75.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.579 | Acc: 42.824,62.789,75.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.584 | Acc: 42.845,62.840,75.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.594 | Acc: 42.652,62.726,75.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.589 | Acc: 42.780,62.910,75.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.587 | Acc: 42.852,62.985,75.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.591 | Acc: 42.900,62.962,75.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.606 | Acc: 42.697,62.655,74.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.620 | Acc: 42.492,62.436,74.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.625 | Acc: 42.444,62.338,74.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.622 | Acc: 42.535,62.314,74.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.624 | Acc: 42.529,62.389,74.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.633 | Acc: 42.489,62.344,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.636 | Acc: 42.523,62.310,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.638 | Acc: 42.568,62.319,74.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.643 | Acc: 42.445,62.225,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.651 | Acc: 42.325,62.063,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.559 | Acc: 39.062,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.869 | Acc: 35.417,49.777,58.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 34.889,48.876,58.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.902 | Acc: 34.349,48.886,58.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 2.571 | Acc: 39.844,58.594,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.594 | Acc: 42.560,62.240,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.607 | Acc: 42.530,62.557,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.640 | Acc: 42.341,62.167,74.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.620 | Acc: 42.303,62.394,74.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.612 | Acc: 42.466,62.430,74.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.613 | Acc: 42.181,62.500,74.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.615 | Acc: 42.426,62.539,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.617 | Acc: 42.357,62.325,74.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.630 | Acc: 42.196,62.232,74.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.632 | Acc: 42.226,62.189,74.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.629 | Acc: 42.347,62.253,74.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.631 | Acc: 42.363,62.205,74.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.632 | Acc: 42.475,62.201,74.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.637 | Acc: 42.477,62.200,74.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.640 | Acc: 42.525,62.202,74.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.647 | Acc: 42.448,62.101,74.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.650 | Acc: 42.389,61.994,74.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.654 | Acc: 42.371,62.007,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.657 | Acc: 42.364,61.932,73.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.305 | Acc: 36.719,57.812,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.692 | Acc: 32.515,53.125,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.695 | Acc: 32.565,53.125,60.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.715 | Acc: 32.339,52.702,60.771,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 2.376 | Acc: 48.438,64.844,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.572 | Acc: 41.778,63.095,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.588 | Acc: 42.188,62.748,75.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.626 | Acc: 41.701,62.001,74.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.625 | Acc: 41.898,61.912,74.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.628 | Acc: 41.778,62.198,74.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.627 | Acc: 41.987,62.326,74.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.624 | Acc: 42.160,62.434,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.621 | Acc: 42.430,62.519,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.625 | Acc: 42.438,62.522,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.634 | Acc: 42.397,62.461,74.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.639 | Acc: 42.318,62.528,74.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.645 | Acc: 42.282,62.338,73.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.651 | Acc: 42.310,62.252,73.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.653 | Acc: 42.446,62.214,73.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.653 | Acc: 42.408,62.256,73.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.651 | Acc: 42.453,62.296,73.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.651 | Acc: 42.407,62.280,73.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.657 | Acc: 42.291,62.197,73.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.660 | Acc: 42.304,62.133,73.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.829 | Acc: 32.031,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.816 | Acc: 33.743,50.632,60.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.849 | Acc: 33.479,50.667,59.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.857 | Acc: 33.350,50.051,59.298,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 2.780 | Acc: 36.719,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.612 | Acc: 42.857,61.942,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.613 | Acc: 42.835,61.604,75.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.577 | Acc: 42.828,62.282,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.579 | Acc: 42.728,62.490,75.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.565 | Acc: 42.969,62.763,75.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.579 | Acc: 42.627,62.739,75.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.590 | Acc: 42.548,62.639,75.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.587 | Acc: 42.576,62.801,75.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.588 | Acc: 42.727,62.824,75.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.584 | Acc: 42.693,62.893,75.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.590 | Acc: 42.799,62.903,75.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.601 | Acc: 42.696,62.792,74.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.609 | Acc: 42.622,62.698,74.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.623 | Acc: 42.529,62.456,74.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.629 | Acc: 42.525,62.373,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.634 | Acc: 42.392,62.303,74.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.633 | Acc: 42.446,62.214,74.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.636 | Acc: 42.460,62.173,74.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.638 | Acc: 42.532,62.250,74.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.008 | Acc: 22.656,49.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.919 | Acc: 26.525,50.558,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.954 | Acc: 26.410,49.981,61.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.999 | Acc: 26.012,49.488,61.130,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.763 | Acc: 38.281,58.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.598 | Acc: 42.634,62.426,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.592 | Acc: 42.264,62.481,75.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.613 | Acc: 41.931,62.282,75.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.608 | Acc: 41.956,62.442,75.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.600 | Acc: 42.358,62.655,75.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.605 | Acc: 42.388,62.616,75.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.610 | Acc: 42.381,62.494,75.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.621 | Acc: 42.188,62.442,75.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.618 | Acc: 42.464,62.504,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.622 | Acc: 42.471,62.403,74.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.620 | Acc: 42.534,62.482,74.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.622 | Acc: 42.538,62.539,74.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.622 | Acc: 42.505,62.716,74.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.627 | Acc: 42.468,62.681,74.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.634 | Acc: 42.356,62.632,74.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.641 | Acc: 42.307,62.546,74.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.644 | Acc: 42.240,62.518,74.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.651 | Acc: 42.200,62.435,74.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.652 | Acc: 42.165,62.402,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.310 | Acc: 32.812,46.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.327 | Acc: 27.939,44.680,55.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.401 | Acc: 27.248,43.845,54.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.371 | Acc: 27.395,44.237,55.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 2.827 | Acc: 43.750,57.812,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.637 | Acc: 42.113,61.979,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.604 | Acc: 43.159,62.519,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.593 | Acc: 42.853,62.795,75.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.573 | Acc: 42.959,62.712,75.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.577 | Acc: 42.752,62.856,75.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.574 | Acc: 42.865,62.668,75.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.585 | Acc: 42.936,62.594,75.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.591 | Acc: 42.799,62.680,75.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.595 | Acc: 42.887,62.694,74.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.611 | Acc: 42.747,62.551,74.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.612 | Acc: 42.760,62.610,74.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.617 | Acc: 42.709,62.542,74.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.623 | Acc: 42.636,62.494,74.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.632 | Acc: 42.560,62.361,74.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.639 | Acc: 42.455,62.272,74.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.644 | Acc: 42.475,62.257,74.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.646 | Acc: 42.504,62.262,74.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.650 | Acc: 42.516,62.232,74.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.656 | Acc: 42.452,62.156,74.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.501 | Acc: 32.031,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 28.088,42.448,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 27.591,41.883,54.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 27.113,41.726,54.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.451 | Acc: 50.781,67.188,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.553 | Acc: 43.564,62.537,76.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.588 | Acc: 43.216,62.290,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.564 | Acc: 43.430,63.153,75.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.558 | Acc: 43.239,63.137,75.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.556 | Acc: 43.294,63.150,75.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.558 | Acc: 43.259,62.997,75.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.559 | Acc: 43.390,63.054,75.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.570 | Acc: 43.177,62.976,75.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.579 | Acc: 43.051,62.755,75.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.583 | Acc: 43.113,62.780,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.589 | Acc: 43.128,62.716,75.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.606 | Acc: 43.060,62.477,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.611 | Acc: 42.996,62.374,74.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.617 | Acc: 42.896,62.286,74.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.618 | Acc: 42.969,62.285,74.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.621 | Acc: 42.837,62.218,74.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.633 | Acc: 42.685,62.149,74.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.638 | Acc: 42.638,62.072,74.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.643 | Acc: 42.628,62.065,73.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.932 | Acc: 32.812,46.875,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.153 | Acc: 28.460,46.391,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.115 | Acc: 29.135,46.513,57.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.120 | Acc: 29.355,46.376,57.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.236 | Acc: 49.219,66.406,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.538 | Acc: 40.402,63.430,76.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.557 | Acc: 41.444,63.319,75.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.575 | Acc: 41.739,62.807,75.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.578 | Acc: 41.657,62.915,75.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.589 | Acc: 41.739,63.142,75.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.594 | Acc: 42.033,63.036,74.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.599 | Acc: 42.204,62.916,74.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.601 | Acc: 42.304,62.946,74.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.599 | Acc: 42.576,63.070,74.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.600 | Acc: 42.576,62.966,74.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.602 | Acc: 42.647,62.857,74.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.615 | Acc: 42.580,62.623,74.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.616 | Acc: 42.451,62.488,74.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.617 | Acc: 42.457,62.564,74.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.617 | Acc: 42.507,62.536,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.620 | Acc: 42.475,62.522,74.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.630 | Acc: 42.430,62.358,74.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.630 | Acc: 42.458,62.372,74.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.635 | Acc: 42.438,62.268,74.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.840 | Acc: 39.062,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.850 | Acc: 35.045,49.963,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.876 | Acc: 35.347,49.257,57.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.868 | Acc: 35.540,49.552,57.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 2.567 | Acc: 47.656,59.375,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.556 | Acc: 43.155,63.318,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.556 | Acc: 43.064,63.129,75.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.568 | Acc: 43.199,63.128,75.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.583 | Acc: 42.930,62.481,75.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.578 | Acc: 42.884,62.585,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.588 | Acc: 42.756,62.268,75.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.588 | Acc: 42.963,62.240,75.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.581 | Acc: 43.202,62.481,75.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.589 | Acc: 43.288,62.517,75.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.598 | Acc: 43.183,62.430,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.602 | Acc: 43.174,62.479,74.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.610 | Acc: 43.205,62.416,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.618 | Acc: 43.160,62.368,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.624 | Acc: 42.947,62.269,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.628 | Acc: 42.956,62.116,74.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.629 | Acc: 42.983,62.091,74.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.629 | Acc: 43.010,62.145,74.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.632 | Acc: 42.932,62.147,74.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.632 | Acc: 42.915,62.207,74.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.281 | Acc: 25.000,44.531,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.407 | Acc: 23.996,43.341,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.435 | Acc: 23.533,42.569,56.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.408 | Acc: 24.052,42.367,56.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.254 | Acc: 54.688,66.406,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.587 | Acc: 42.820,61.979,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.539 | Acc: 43.445,63.567,75.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.544 | Acc: 43.097,63.217,75.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.562 | Acc: 43.248,62.895,75.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.586 | Acc: 43.093,62.848,75.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.599 | Acc: 42.698,62.616,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.613 | Acc: 42.531,62.511,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.618 | Acc: 42.488,62.456,74.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.612 | Acc: 42.516,62.569,74.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.614 | Acc: 42.572,62.531,74.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.613 | Acc: 42.658,62.627,74.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.614 | Acc: 42.641,62.665,74.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.617 | Acc: 42.672,62.575,74.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.621 | Acc: 42.627,62.564,74.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.621 | Acc: 42.733,62.622,74.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.631 | Acc: 42.740,62.537,74.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.631 | Acc: 42.843,62.493,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.636 | Acc: 42.800,62.422,74.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.638 | Acc: 42.743,62.359,74.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.720 | Acc: 35.938,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.982 | Acc: 30.320,47.656,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.966 | Acc: 30.793,48.190,59.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.970 | Acc: 30.699,48.156,58.991,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 2.403 | Acc: 44.531,60.156,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.614 | Acc: 41.853,62.314,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.593 | Acc: 42.931,62.881,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.589 | Acc: 43.186,62.820,75.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.607 | Acc: 42.901,62.596,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.610 | Acc: 43.108,62.655,74.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.614 | Acc: 43.091,62.700,74.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.613 | Acc: 42.969,62.788,74.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.613 | Acc: 42.847,62.757,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.618 | Acc: 42.960,62.655,74.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.624 | Acc: 42.697,62.574,74.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.616 | Acc: 42.824,62.747,74.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.616 | Acc: 42.790,62.685,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.619 | Acc: 42.702,62.689,74.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.619 | Acc: 42.713,62.675,74.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.621 | Acc: 42.626,62.653,74.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.627 | Acc: 42.594,62.505,74.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.627 | Acc: 42.616,62.509,74.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.637 | Acc: 42.519,62.398,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.640 | Acc: 42.577,62.359,74.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.931 | Acc: 30.469,46.875,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.159 | Acc: 29.241,47.470,58.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.209 | Acc: 29.478,47.294,57.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.262 | Acc: 28.676,46.913,57.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 2.113 | Acc: 48.438,71.094,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.476 | Acc: 42.857,64.062,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.477 | Acc: 43.426,64.787,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.484 | Acc: 43.814,64.690,77.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 43.885,64.400,76.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.523 | Acc: 43.742,63.931,76.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.525 | Acc: 43.673,63.927,76.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.540 | Acc: 43.467,63.619,75.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.552 | Acc: 43.372,63.320,75.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.555 | Acc: 43.435,63.398,75.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.556 | Acc: 43.408,63.312,75.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.565 | Acc: 43.255,63.097,75.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.580 | Acc: 43.102,62.967,75.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.591 | Acc: 42.999,62.943,75.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.606 | Acc: 42.913,62.784,74.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.611 | Acc: 42.922,62.715,74.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.613 | Acc: 42.884,62.726,74.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.618 | Acc: 42.928,62.674,74.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.622 | Acc: 42.845,62.664,74.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.626 | Acc: 42.817,62.551,74.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.200 | Acc: 28.906,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 27.567,47.024,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.281 | Acc: 27.420,46.723,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.262 | Acc: 27.331,46.414,55.917,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.838 | Acc: 39.062,62.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.570 | Acc: 42.857,62.946,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.568 | Acc: 43.026,62.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.587 | Acc: 42.623,62.398,75.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.595 | Acc: 42.776,62.307,75.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.597 | Acc: 42.837,62.384,74.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.589 | Acc: 42.865,62.649,75.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.583 | Acc: 42.869,62.716,74.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.575 | Acc: 43.046,62.864,75.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.592 | Acc: 42.861,62.785,74.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.595 | Acc: 42.662,62.776,74.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.593 | Acc: 42.714,62.627,74.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.605 | Acc: 42.602,62.552,74.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.606 | Acc: 42.699,62.617,74.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.610 | Acc: 42.752,62.506,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.614 | Acc: 42.784,62.404,74.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.614 | Acc: 42.823,62.532,74.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.617 | Acc: 42.749,62.489,74.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.622 | Acc: 42.664,62.437,74.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.628 | Acc: 42.544,62.285,74.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.753 | Acc: 34.375,50.000,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.832 | Acc: 30.246,50.000,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.874 | Acc: 30.316,49.390,60.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.915 | Acc: 30.110,49.270,59.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 2.430 | Acc: 38.281,64.062,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.524 | Acc: 42.039,63.095,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.406 | Acc: 43.617,65.473,78.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.349 | Acc: 44.672,66.470,79.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.320 | Acc: 44.985,66.811,80.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.293 | Acc: 45.104,67.064,80.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.275 | Acc: 45.170,67.284,80.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.259 | Acc: 45.601,67.598,80.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.245 | Acc: 45.710,67.974,81.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.237 | Acc: 45.770,68.167,81.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.225 | Acc: 45.962,68.307,81.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.214 | Acc: 46.111,68.428,81.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.204 | Acc: 46.233,68.562,81.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.195 | Acc: 46.264,68.726,81.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.190 | Acc: 46.325,68.794,82.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.184 | Acc: 46.291,68.805,82.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.175 | Acc: 46.444,69.069,82.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.172 | Acc: 46.508,69.066,82.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.172 | Acc: 46.522,69.090,82.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.167 | Acc: 46.498,69.156,82.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.621 | Acc: 45.312,61.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.754 | Acc: 43.713,63.095,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.768 | Acc: 44.112,62.748,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.767 | Acc: 44.390,62.615,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.853 | Acc: 50.781,72.656,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.042 | Acc: 47.024,71.168,85.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.019 | Acc: 47.713,71.589,85.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.006 | Acc: 47.848,71.593,85.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.004 | Acc: 47.637,71.711,85.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.008 | Acc: 47.618,71.736,85.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.014 | Acc: 47.553,71.533,85.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.019 | Acc: 47.385,71.576,85.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.019 | Acc: 47.278,71.516,85.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.020 | Acc: 47.220,71.525,85.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.027 | Acc: 47.065,71.339,85.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.026 | Acc: 46.953,71.242,85.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.026 | Acc: 46.995,71.262,85.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.027 | Acc: 47.079,71.243,85.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.023 | Acc: 47.058,71.341,85.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.025 | Acc: 47.127,71.291,85.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.026 | Acc: 47.184,71.279,85.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.027 | Acc: 47.223,71.279,85.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.026 | Acc: 47.234,71.293,85.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.023 | Acc: 47.285,71.319,85.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.526 | Acc: 46.875,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.733 | Acc: 44.308,63.467,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.754 | Acc: 44.684,63.377,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.753 | Acc: 44.582,63.179,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.862 | Acc: 44.531,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.977 | Acc: 46.912,72.582,86.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 46.646,72.980,86.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.950 | Acc: 47.131,72.541,86.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.944 | Acc: 47.434,72.560,86.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.950 | Acc: 47.447,72.331,86.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.954 | Acc: 47.443,72.463,86.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.961 | Acc: 47.435,72.257,86.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.959 | Acc: 47.292,72.239,86.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.963 | Acc: 47.341,72.233,86.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.965 | Acc: 47.407,72.174,86.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.965 | Acc: 47.472,72.076,86.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.963 | Acc: 47.510,72.144,86.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.966 | Acc: 47.399,72.141,86.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.966 | Acc: 47.412,72.097,86.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.965 | Acc: 47.459,72.140,86.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.969 | Acc: 47.389,72.021,86.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.973 | Acc: 47.377,71.992,86.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.974 | Acc: 47.423,72.074,86.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.975 | Acc: 47.420,72.045,86.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.604 | Acc: 43.750,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.741 | Acc: 43.973,64.174,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 44.188,63.758,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.773 | Acc: 44.275,63.461,71.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 2.034 | Acc: 46.875,72.656,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.979 | Acc: 45.908,72.693,87.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 46.570,72.618,87.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.942 | Acc: 46.965,72.477,87.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.941 | Acc: 47.213,72.589,87.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.948 | Acc: 47.300,72.478,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.941 | Acc: 47.734,72.650,87.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.950 | Acc: 47.512,72.363,87.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.947 | Acc: 47.535,72.438,87.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.945 | Acc: 47.445,72.393,87.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.942 | Acc: 47.559,72.400,87.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.939 | Acc: 47.670,72.578,87.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.939 | Acc: 47.718,72.578,87.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.938 | Acc: 47.806,72.584,87.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.937 | Acc: 47.854,72.528,87.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.940 | Acc: 47.760,72.371,86.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.944 | Acc: 47.676,72.228,86.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.942 | Acc: 47.668,72.191,87.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.939 | Acc: 47.671,72.221,87.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.939 | Acc: 47.656,72.232,86.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.577 | Acc: 44.531,63.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.722 | Acc: 45.312,64.769,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.751 | Acc: 45.198,64.024,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.756 | Acc: 44.954,63.691,71.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.017 | Acc: 46.875,71.875,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.939 | Acc: 46.615,72.284,86.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.950 | Acc: 46.875,72.199,86.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.949 | Acc: 47.259,72.323,86.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.936 | Acc: 47.676,72.405,87.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.932 | Acc: 47.803,72.262,86.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.936 | Acc: 47.882,72.172,86.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.926 | Acc: 48.116,72.196,87.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.927 | Acc: 48.209,72.292,87.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.922 | Acc: 48.269,72.337,87.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.918 | Acc: 48.235,72.524,87.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.914 | Acc: 48.261,72.610,87.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.916 | Acc: 48.227,72.601,87.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.917 | Acc: 48.249,72.557,87.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.916 | Acc: 48.254,72.615,87.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.918 | Acc: 48.178,72.625,87.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.919 | Acc: 48.158,72.537,87.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.918 | Acc: 48.165,72.599,87.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.921 | Acc: 48.093,72.520,87.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.924 | Acc: 48.105,72.478,87.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.552 | Acc: 46.875,60.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.739 | Acc: 45.238,64.249,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.755 | Acc: 45.332,63.986,71.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.753 | Acc: 45.287,63.922,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.897 | Acc: 50.000,71.875,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.890 | Acc: 47.433,72.842,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.890 | Acc: 47.580,72.447,88.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.901 | Acc: 47.733,72.554,88.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.892 | Acc: 47.801,72.695,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.882 | Acc: 48.074,73.082,88.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.882 | Acc: 48.199,73.173,88.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.887 | Acc: 48.077,73.044,88.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.886 | Acc: 48.059,73.059,88.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.888 | Acc: 48.088,73.084,88.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.883 | Acc: 48.072,73.158,88.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.880 | Acc: 48.116,73.144,88.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.880 | Acc: 48.126,73.152,88.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.881 | Acc: 48.240,73.159,88.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.885 | Acc: 48.232,73.101,88.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.892 | Acc: 48.186,72.963,88.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.891 | Acc: 48.279,72.960,88.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.888 | Acc: 48.298,72.991,88.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.891 | Acc: 48.303,72.933,88.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.893 | Acc: 48.245,72.859,88.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.621 | Acc: 47.656,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.767 | Acc: 45.275,64.286,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.785 | Acc: 44.931,63.929,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.778 | Acc: 44.967,63.627,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 2.154 | Acc: 35.156,67.969,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.921 | Acc: 46.503,72.433,88.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.873 | Acc: 47.866,73.247,88.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.859 | Acc: 48.169,73.233,88.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.862 | Acc: 48.592,73.370,88.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.859 | Acc: 48.569,73.283,88.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.872 | Acc: 48.308,73.076,88.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.877 | Acc: 48.122,73.183,88.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.875 | Acc: 47.909,73.195,88.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.875 | Acc: 47.963,73.161,88.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.874 | Acc: 48.037,73.134,88.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.873 | Acc: 48.169,73.194,88.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.879 | Acc: 48.194,73.065,88.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.880 | Acc: 48.111,73.030,88.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.885 | Acc: 47.982,72.934,88.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.883 | Acc: 48.160,72.944,88.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.879 | Acc: 48.192,72.960,88.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.879 | Acc: 48.128,72.922,88.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.880 | Acc: 48.096,72.970,88.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.879 | Acc: 48.101,72.984,88.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.508 | Acc: 45.312,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.721 | Acc: 45.499,64.583,73.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.749 | Acc: 45.503,64.348,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.758 | Acc: 45.556,64.139,72.106,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 2.093 | Acc: 34.375,64.844,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.831 | Acc: 46.540,73.549,89.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.828 | Acc: 47.732,73.209,88.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.866 | Acc: 47.310,72.515,88.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.852 | Acc: 48.042,72.782,88.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.850 | Acc: 48.314,73.051,88.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.863 | Acc: 48.173,72.676,88.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.861 | Acc: 48.221,72.845,88.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.862 | Acc: 48.137,72.884,88.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.859 | Acc: 47.997,73.101,88.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.868 | Acc: 48.002,72.967,88.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.868 | Acc: 48.077,72.999,88.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.865 | Acc: 48.363,73.081,88.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.868 | Acc: 48.219,73.081,88.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.866 | Acc: 48.190,73.143,88.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.864 | Acc: 48.230,73.116,88.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.863 | Acc: 48.218,73.114,88.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.864 | Acc: 48.202,73.101,88.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.863 | Acc: 48.260,73.135,88.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.865 | Acc: 48.198,73.124,88.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.546 | Acc: 46.875,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.740 | Acc: 45.312,64.546,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.757 | Acc: 45.293,64.291,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.757 | Acc: 45.325,63.922,71.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.786 | Acc: 50.781,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.846 | Acc: 48.400,73.512,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.831 | Acc: 49.066,73.056,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.834 | Acc: 48.591,73.207,89.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.839 | Acc: 48.351,73.331,89.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.849 | Acc: 48.407,73.128,88.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.843 | Acc: 48.547,73.392,89.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.848 | Acc: 48.443,73.205,88.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.844 | Acc: 48.171,73.379,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.845 | Acc: 48.118,73.312,88.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.846 | Acc: 48.099,73.360,88.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.845 | Acc: 48.201,73.413,88.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.851 | Acc: 48.010,73.262,88.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.849 | Acc: 47.953,73.303,88.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.848 | Acc: 48.090,73.357,88.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.848 | Acc: 48.108,73.336,88.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.849 | Acc: 48.158,73.379,88.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.847 | Acc: 48.259,73.449,88.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.845 | Acc: 48.349,73.509,88.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.846 | Acc: 48.366,73.464,88.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.586 | Acc: 46.094,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.761 | Acc: 45.126,64.100,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.782 | Acc: 45.351,63.700,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 45.338,63.614,71.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 1.774 | Acc: 50.781,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.860 | Acc: 47.545,73.251,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.812 | Acc: 48.133,73.685,89.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.814 | Acc: 48.489,73.527,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.802 | Acc: 48.756,73.640,89.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.800 | Acc: 48.631,73.979,90.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.805 | Acc: 48.670,73.922,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.804 | Acc: 48.559,73.947,89.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.809 | Acc: 48.462,73.923,89.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.811 | Acc: 48.610,73.895,89.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.812 | Acc: 48.535,73.943,89.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.816 | Acc: 48.575,73.819,89.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.822 | Acc: 48.509,73.684,89.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.828 | Acc: 48.363,73.581,89.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.832 | Acc: 48.212,73.501,89.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.835 | Acc: 48.204,73.495,89.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.835 | Acc: 48.226,73.469,89.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.834 | Acc: 48.353,73.486,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.832 | Acc: 48.256,73.574,89.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.832 | Acc: 48.335,73.597,89.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.556 | Acc: 48.438,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.728 | Acc: 45.722,65.141,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.749 | Acc: 45.503,65.091,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.753 | Acc: 45.543,64.793,71.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.762 | Acc: 53.906,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.809 | Acc: 49.479,73.586,89.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.831 | Acc: 49.123,73.190,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.833 | Acc: 48.719,73.220,89.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.827 | Acc: 48.486,73.466,89.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.821 | Acc: 48.445,73.476,89.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.821 | Acc: 48.547,73.534,89.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.820 | Acc: 48.659,73.654,89.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.826 | Acc: 48.559,73.695,89.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.830 | Acc: 48.433,73.576,89.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.831 | Acc: 48.410,73.500,89.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.825 | Acc: 48.685,73.681,89.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.830 | Acc: 48.651,73.600,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.828 | Acc: 48.755,73.542,89.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.829 | Acc: 48.741,73.538,89.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.830 | Acc: 48.700,73.570,89.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.829 | Acc: 48.715,73.559,89.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.830 | Acc: 48.653,73.554,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.828 | Acc: 48.652,73.552,89.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.829 | Acc: 48.610,73.507,89.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.588 | Acc: 42.969,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.762 | Acc: 45.238,63.839,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.789 | Acc: 45.446,63.853,71.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.788 | Acc: 45.377,63.883,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.766 | Acc: 46.875,70.312,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.762 | Acc: 47.619,74.330,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.786 | Acc: 47.923,74.047,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.781 | Acc: 48.412,74.385,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.791 | Acc: 48.245,73.910,90.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.792 | Acc: 48.167,74.018,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.783 | Acc: 48.444,74.186,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.786 | Acc: 48.377,74.036,90.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.787 | Acc: 48.467,73.986,90.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.791 | Acc: 48.394,73.899,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.791 | Acc: 48.523,73.935,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.796 | Acc: 48.441,73.840,90.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.797 | Acc: 48.425,73.788,90.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.802 | Acc: 48.411,73.752,89.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.802 | Acc: 48.546,73.768,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.806 | Acc: 48.502,73.778,89.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.806 | Acc: 48.569,73.793,89.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.809 | Acc: 48.552,73.756,89.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.813 | Acc: 48.496,73.736,89.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.812 | Acc: 48.454,73.753,89.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.527 | Acc: 49.219,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 45.052,64.137,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.790 | Acc: 45.217,63.720,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.794 | Acc: 45.364,63.627,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.852 | Acc: 52.344,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.750 | Acc: 50.856,74.888,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.776 | Acc: 49.428,74.905,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.777 | Acc: 49.027,74.705,90.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.764 | Acc: 49.325,74.720,90.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.779 | Acc: 48.755,74.420,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.776 | Acc: 48.967,74.471,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.777 | Acc: 49.047,74.391,90.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.779 | Acc: 48.797,74.364,90.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.785 | Acc: 48.826,74.227,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.791 | Acc: 48.644,74.122,90.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.792 | Acc: 48.787,74.074,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.795 | Acc: 48.690,74.070,90.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.799 | Acc: 48.647,73.928,90.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.800 | Acc: 48.668,73.896,90.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.802 | Acc: 48.648,73.941,89.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.801 | Acc: 48.620,73.932,89.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.805 | Acc: 48.554,73.843,89.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.806 | Acc: 48.608,73.868,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.805 | Acc: 48.622,73.829,89.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.602 | Acc: 45.312,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.792 | Acc: 45.201,64.658,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.797 | Acc: 45.084,64.596,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 44.915,64.178,71.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.749 | Acc: 44.531,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.738 | Acc: 48.884,75.744,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.733 | Acc: 49.257,75.381,91.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.738 | Acc: 49.155,75.077,91.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.750 | Acc: 49.228,74.643,90.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.756 | Acc: 49.226,74.644,90.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.764 | Acc: 49.006,74.451,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.775 | Acc: 48.748,74.091,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.776 | Acc: 48.666,74.059,90.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.774 | Acc: 48.701,74.119,90.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.782 | Acc: 48.640,74.005,90.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.780 | Acc: 48.749,74.053,90.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.784 | Acc: 48.616,73.989,90.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.787 | Acc: 48.644,73.952,90.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.787 | Acc: 48.702,73.988,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.785 | Acc: 48.822,74.045,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.787 | Acc: 48.820,74.012,90.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.787 | Acc: 48.772,73.990,90.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.784 | Acc: 48.883,74.024,90.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.786 | Acc: 48.846,74.005,90.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.488 | Acc: 48.438,65.625,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.755 | Acc: 46.057,64.323,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.782 | Acc: 45.846,63.929,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.782 | Acc: 45.556,63.947,72.131,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.784 | Acc: 47.656,78.906,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.832 | Acc: 47.210,72.879,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.789 | Acc: 48.780,73.780,90.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.771 | Acc: 49.052,74.091,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.773 | Acc: 49.219,73.987,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.775 | Acc: 49.172,74.056,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.777 | Acc: 48.915,74.083,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.768 | Acc: 48.775,74.274,90.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.774 | Acc: 48.690,74.102,90.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.775 | Acc: 48.675,74.068,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.777 | Acc: 48.624,73.993,90.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.776 | Acc: 48.688,73.978,90.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.776 | Acc: 48.878,74.037,90.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.775 | Acc: 48.886,74.129,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.776 | Acc: 48.791,74.091,90.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.779 | Acc: 48.715,74.084,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.780 | Acc: 48.700,74.134,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.777 | Acc: 48.671,74.161,90.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.776 | Acc: 48.626,74.126,90.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.776 | Acc: 48.626,74.147,90.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.454 | Acc: 48.438,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.796 | Acc: 44.234,64.881,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.809 | Acc: 44.627,64.139,71.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 44.647,63.819,71.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.689 | Acc: 45.312,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.751 | Acc: 48.512,75.074,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.748 | Acc: 48.209,75.400,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.755 | Acc: 48.361,74.718,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.754 | Acc: 48.457,74.643,91.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.754 | Acc: 48.662,74.513,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.755 | Acc: 48.799,74.554,90.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.762 | Acc: 48.365,74.385,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.769 | Acc: 48.321,74.209,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.772 | Acc: 48.248,74.262,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.771 | Acc: 48.406,74.184,90.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.766 | Acc: 48.508,74.282,90.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.768 | Acc: 48.551,74.248,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.769 | Acc: 48.701,74.228,90.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.770 | Acc: 48.727,74.202,90.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.772 | Acc: 48.694,74.198,90.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.774 | Acc: 48.635,74.134,90.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.775 | Acc: 48.607,74.118,90.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.777 | Acc: 48.624,74.078,90.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.775 | Acc: 48.645,74.018,90.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.543 | Acc: 51.562,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.776 | Acc: 45.759,63.951,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.793 | Acc: 45.846,64.177,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.793 | Acc: 45.838,64.088,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.708 | Acc: 47.656,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.771 | Acc: 48.661,74.740,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.759 | Acc: 49.143,74.695,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.763 | Acc: 48.604,74.385,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.753 | Acc: 48.669,74.662,90.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.751 | Acc: 48.646,74.528,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.756 | Acc: 48.747,74.419,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.758 | Acc: 48.814,74.230,90.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.760 | Acc: 48.884,74.190,90.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.764 | Acc: 48.770,74.249,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.763 | Acc: 48.729,74.351,90.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.759 | Acc: 48.837,74.360,90.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.757 | Acc: 48.788,74.459,90.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.760 | Acc: 48.815,74.392,90.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.760 | Acc: 48.827,74.291,90.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.763 | Acc: 48.772,74.265,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.763 | Acc: 48.773,74.231,90.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.765 | Acc: 48.685,74.168,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.765 | Acc: 48.704,74.208,90.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.768 | Acc: 48.649,74.161,90.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.601 | Acc: 41.406,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.761 | Acc: 44.903,64.286,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.800 | Acc: 45.217,63.891,72.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.810 | Acc: 45.056,63.870,71.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.902 | Acc: 49.219,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.768 | Acc: 48.251,74.442,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.757 | Acc: 48.304,74.543,90.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.744 | Acc: 48.745,74.757,90.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.738 | Acc: 48.872,74.749,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.743 | Acc: 48.847,74.737,90.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.739 | Acc: 49.038,74.793,90.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.734 | Acc: 49.219,74.972,90.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.741 | Acc: 48.962,74.753,90.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.746 | Acc: 48.904,74.624,90.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.745 | Acc: 48.721,74.681,90.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.745 | Acc: 48.851,74.703,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.749 | Acc: 48.752,74.579,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.749 | Acc: 48.845,74.593,90.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.748 | Acc: 48.927,74.605,90.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.752 | Acc: 48.944,74.525,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.753 | Acc: 48.919,74.467,90.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.756 | Acc: 48.829,74.425,90.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.758 | Acc: 48.771,74.359,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.760 | Acc: 48.743,74.274,90.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.494 | Acc: 49.219,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.774 | Acc: 45.685,64.472,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.804 | Acc: 45.884,64.253,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.808 | Acc: 45.710,64.178,71.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.713 | Acc: 48.438,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.739 | Acc: 49.814,75.186,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.725 | Acc: 49.543,75.152,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.720 | Acc: 48.924,75.077,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.729 | Acc: 48.592,74.836,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.731 | Acc: 48.894,74.698,91.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.734 | Acc: 48.948,74.697,91.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.732 | Acc: 49.058,74.778,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.735 | Acc: 49.044,74.665,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.737 | Acc: 49.128,74.612,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.737 | Acc: 49.219,74.623,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.741 | Acc: 49.095,74.487,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.741 | Acc: 49.027,74.514,90.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.741 | Acc: 49.033,74.461,90.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.738 | Acc: 49.183,74.525,90.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.743 | Acc: 49.032,74.367,90.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.744 | Acc: 49.034,74.309,90.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.746 | Acc: 48.997,74.274,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.747 | Acc: 49.005,74.299,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.748 | Acc: 48.967,74.366,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.568 | Acc: 49.219,62.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 45.312,64.137,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.833 | Acc: 45.465,63.758,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.829 | Acc: 45.505,63.563,71.209,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.731 | Acc: 53.906,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.787 | Acc: 47.693,73.735,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.752 | Acc: 48.056,74.257,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.762 | Acc: 48.233,74.091,90.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.755 | Acc: 48.563,74.113,90.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.743 | Acc: 48.716,74.482,91.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.741 | Acc: 48.825,74.471,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.739 | Acc: 48.781,74.391,91.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.731 | Acc: 49.020,74.602,91.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.733 | Acc: 49.037,74.573,91.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.732 | Acc: 49.129,74.537,91.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.737 | Acc: 49.014,74.438,91.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.735 | Acc: 49.099,74.504,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.736 | Acc: 48.958,74.518,91.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.740 | Acc: 48.938,74.497,91.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.738 | Acc: 48.951,74.499,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.738 | Acc: 48.893,74.496,91.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.741 | Acc: 48.921,74.478,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.741 | Acc: 48.920,74.496,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.742 | Acc: 48.889,74.465,91.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.556 | Acc: 44.531,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.796 | Acc: 45.312,64.658,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 45.522,64.386,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.831 | Acc: 45.108,64.075,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 1.898 | Acc: 45.312,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.787 | Acc: 47.582,73.214,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.748 | Acc: 48.476,73.895,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.746 | Acc: 47.861,73.963,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.736 | Acc: 48.351,74.325,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.730 | Acc: 48.554,74.304,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.722 | Acc: 48.793,74.658,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.723 | Acc: 48.986,74.839,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.724 | Acc: 49.015,74.811,91.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.723 | Acc: 49.102,74.793,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.733 | Acc: 48.838,74.452,91.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.734 | Acc: 48.904,74.367,91.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.732 | Acc: 48.969,74.501,91.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.732 | Acc: 48.979,74.464,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.730 | Acc: 49.099,74.516,91.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.730 | Acc: 49.105,74.543,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.731 | Acc: 49.095,74.486,91.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.735 | Acc: 49.035,74.427,91.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.733 | Acc: 49.065,74.507,91.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.733 | Acc: 49.005,74.518,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.584 | Acc: 46.875,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.846 | Acc: 45.424,63.839,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.864 | Acc: 45.312,64.177,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.867 | Acc: 45.120,63.947,70.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.758 | Acc: 45.312,81.250,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.749 | Acc: 48.772,74.851,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.717 | Acc: 49.219,75.210,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.713 | Acc: 49.565,75.282,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.708 | Acc: 49.585,74.981,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.713 | Acc: 49.528,75.031,91.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.713 | Acc: 49.458,75.084,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.718 | Acc: 49.125,74.961,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.712 | Acc: 49.238,75.102,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.715 | Acc: 49.197,74.965,91.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.717 | Acc: 49.056,75.012,91.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.717 | Acc: 49.141,75.078,91.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.725 | Acc: 48.940,74.912,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.727 | Acc: 48.916,74.853,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.726 | Acc: 48.980,74.853,91.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.727 | Acc: 49.055,74.759,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.726 | Acc: 49.041,74.737,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.729 | Acc: 49.017,74.723,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.730 | Acc: 49.033,74.704,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.729 | Acc: 49.126,74.715,91.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.652 | Acc: 46.094,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.803 | Acc: 45.647,64.844,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.831 | Acc: 45.770,64.577,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.826 | Acc: 45.722,64.255,71.273,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.871 | Acc: 45.312,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.675 | Acc: 50.670,76.562,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.675 | Acc: 49.981,76.372,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.674 | Acc: 49.731,76.012,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.690 | Acc: 49.518,75.444,92.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.713 | Acc: 49.126,74.977,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.712 | Acc: 48.999,75.110,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.718 | Acc: 49.091,74.928,91.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.721 | Acc: 48.986,74.961,91.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.720 | Acc: 48.951,74.987,91.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.718 | Acc: 48.989,74.961,91.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.714 | Acc: 48.925,75.085,91.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.714 | Acc: 48.979,75.078,91.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.713 | Acc: 49.012,75.078,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.712 | Acc: 49.019,75.083,91.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.712 | Acc: 49.042,75.044,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.713 | Acc: 48.973,75.041,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.714 | Acc: 48.951,74.934,91.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.718 | Acc: 48.937,74.851,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.720 | Acc: 48.936,74.838,91.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.772 | Acc: 44.531,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.853 | Acc: 44.568,63.802,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.870 | Acc: 45.198,63.986,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.875 | Acc: 45.184,63.768,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.613 | Acc: 48.438,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.655 | Acc: 49.814,76.339,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.660 | Acc: 49.505,75.667,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.672 | Acc: 49.142,75.397,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 49.354,75.424,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.685 | Acc: 48.979,75.588,92.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.686 | Acc: 49.096,75.555,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 49.186,75.377,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.693 | Acc: 49.000,75.325,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.691 | Acc: 49.171,75.315,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.691 | Acc: 49.246,75.299,92.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.688 | Acc: 49.374,75.315,92.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.691 | Acc: 49.238,75.305,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.695 | Acc: 49.222,75.230,91.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.696 | Acc: 49.188,75.139,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.700 | Acc: 49.201,75.060,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.700 | Acc: 49.219,75.083,91.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.703 | Acc: 49.150,74.945,91.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.708 | Acc: 49.102,74.803,91.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.709 | Acc: 49.081,74.770,91.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.668 | Acc: 52.344,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.854 | Acc: 45.387,63.690,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.866 | Acc: 45.484,63.529,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.865 | Acc: 45.556,63.435,71.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.617 | Acc: 50.000,75.000,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.672 | Acc: 49.368,76.190,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.699 | Acc: 48.742,75.419,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.703 | Acc: 48.963,75.192,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.705 | Acc: 48.785,74.875,91.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.703 | Acc: 49.080,74.799,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.704 | Acc: 49.167,74.703,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.702 | Acc: 49.091,74.523,91.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.700 | Acc: 49.262,74.723,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.699 | Acc: 49.318,74.909,91.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.702 | Acc: 49.234,74.864,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.705 | Acc: 49.145,74.767,91.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.709 | Acc: 49.011,74.711,91.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.713 | Acc: 48.904,74.635,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.712 | Acc: 49.030,74.639,91.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.713 | Acc: 49.053,74.608,91.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.714 | Acc: 49.075,74.635,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.716 | Acc: 49.056,74.556,91.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.714 | Acc: 49.095,74.565,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.716 | Acc: 49.075,74.551,91.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.671 | Acc: 42.969,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.833 | Acc: 45.089,64.546,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.861 | Acc: 45.370,64.386,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.860 | Acc: 45.159,64.306,71.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.707 | Acc: 49.219,74.219,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 48.214,74.070,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.704 | Acc: 48.876,74.981,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.702 | Acc: 48.886,74.987,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.708 | Acc: 48.862,74.865,91.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.702 | Acc: 48.948,74.814,91.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.702 | Acc: 49.025,74.709,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.704 | Acc: 48.997,74.607,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.708 | Acc: 48.835,74.524,91.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.704 | Acc: 48.912,74.676,91.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.700 | Acc: 49.098,74.802,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.699 | Acc: 49.024,74.777,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.702 | Acc: 48.898,74.754,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.702 | Acc: 49.021,74.770,91.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.699 | Acc: 49.110,74.819,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.701 | Acc: 49.141,74.792,91.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.701 | Acc: 49.173,74.800,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.701 | Acc: 49.214,74.753,91.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.704 | Acc: 49.149,74.706,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.702 | Acc: 49.221,74.746,91.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.764 | Acc: 44.531,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.840 | Acc: 45.238,64.509,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 44.874,64.577,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.877 | Acc: 44.775,64.139,70.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.855 | Acc: 47.656,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.704 | Acc: 48.475,75.000,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 48.990,75.362,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.685 | Acc: 49.257,75.602,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.676 | Acc: 49.238,75.511,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 49.335,75.402,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.670 | Acc: 49.367,75.400,92.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.673 | Acc: 49.341,75.321,92.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.675 | Acc: 49.301,75.286,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.676 | Acc: 49.374,75.281,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.675 | Acc: 49.378,75.257,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.679 | Acc: 49.311,75.134,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.680 | Acc: 49.258,75.107,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.683 | Acc: 49.165,75.048,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.687 | Acc: 49.099,74.969,91.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.686 | Acc: 49.079,74.984,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.688 | Acc: 49.058,74.998,91.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 49.171,75.082,91.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.687 | Acc: 49.130,75.028,91.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.691 | Acc: 49.137,74.975,91.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.577 | Acc: 46.094,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.835 | Acc: 45.015,64.509,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.861 | Acc: 45.293,64.234,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.862 | Acc: 45.466,64.178,71.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.459 | Acc: 50.781,75.000,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.625 | Acc: 50.223,77.121,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.644 | Acc: 50.343,76.143,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.651 | Acc: 50.166,75.756,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.662 | Acc: 49.817,75.473,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.659 | Acc: 49.776,75.495,92.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.663 | Acc: 49.703,75.458,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.663 | Acc: 49.584,75.576,92.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 49.549,75.466,92.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.672 | Acc: 49.607,75.358,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.672 | Acc: 49.452,75.346,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.669 | Acc: 49.410,75.354,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.669 | Acc: 49.397,75.318,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.674 | Acc: 49.225,75.272,92.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 49.241,75.206,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 49.367,75.140,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.679 | Acc: 49.370,75.187,92.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.681 | Acc: 49.368,75.140,92.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.686 | Acc: 49.329,75.061,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.688 | Acc: 49.272,75.066,92.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.743 | Acc: 42.188,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.817 | Acc: 45.647,64.881,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.876 | Acc: 45.694,63.929,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.885 | Acc: 45.620,63.806,70.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.570 | Acc: 55.469,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.688 | Acc: 48.810,74.182,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.664 | Acc: 49.486,74.886,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 49.693,75.269,92.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.665 | Acc: 49.402,75.116,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.676 | Acc: 49.335,75.101,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.676 | Acc: 49.199,75.303,92.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.677 | Acc: 49.296,75.150,92.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.679 | Acc: 49.141,75.155,92.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.679 | Acc: 49.223,75.112,92.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.680 | Acc: 49.351,75.167,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.679 | Acc: 49.417,75.219,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.677 | Acc: 49.426,75.272,92.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.680 | Acc: 49.377,75.174,92.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.683 | Acc: 49.422,75.142,92.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.681 | Acc: 49.452,75.249,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.682 | Acc: 49.465,75.224,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.684 | Acc: 49.331,75.142,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.685 | Acc: 49.301,75.141,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.688 | Acc: 49.293,75.129,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.586 | Acc: 50.000,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.854 | Acc: 45.573,64.807,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.893 | Acc: 45.636,64.329,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.904 | Acc: 45.210,64.011,70.927,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.711 | Acc: 49.219,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.683 | Acc: 49.442,74.926,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.684 | Acc: 49.219,75.229,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.666 | Acc: 49.232,75.346,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.661 | Acc: 49.518,75.444,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.659 | Acc: 49.520,75.425,92.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.664 | Acc: 49.554,75.504,92.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.663 | Acc: 49.579,75.427,92.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 49.728,75.286,92.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.678 | Acc: 49.482,75.086,92.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.677 | Acc: 49.580,75.194,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.676 | Acc: 49.608,75.219,92.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.678 | Acc: 49.501,75.211,92.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.679 | Acc: 49.488,75.129,92.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.683 | Acc: 49.397,75.056,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.684 | Acc: 49.354,75.062,92.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.683 | Acc: 49.377,75.075,92.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 49.361,75.073,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.680 | Acc: 49.429,75.061,92.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 49.446,75.049,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.622 | Acc: 49.219,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.898 | Acc: 45.350,64.249,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.902 | Acc: 45.884,64.291,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.902 | Acc: 45.799,64.139,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.567 | Acc: 55.469,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.674 | Acc: 48.400,76.488,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.662 | Acc: 49.104,76.639,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.664 | Acc: 48.655,76.294,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.656 | Acc: 49.122,76.177,92.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.659 | Acc: 49.350,76.021,92.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.658 | Acc: 49.542,75.968,92.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.662 | Acc: 49.512,75.704,92.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.661 | Acc: 49.539,75.626,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.660 | Acc: 49.534,75.622,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.659 | Acc: 49.378,75.680,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.664 | Acc: 49.381,75.601,92.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.667 | Acc: 49.352,75.600,92.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.667 | Acc: 49.410,75.572,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.663 | Acc: 49.550,75.598,92.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.669 | Acc: 49.432,75.459,92.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.672 | Acc: 49.365,75.324,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.670 | Acc: 49.494,75.339,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.672 | Acc: 49.507,75.279,92.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.672 | Acc: 49.471,75.262,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.770 | Acc: 45.312,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.971 | Acc: 44.531,63.021,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.969 | Acc: 44.798,63.014,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.969 | Acc: 44.595,63.064,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.912 | Acc: 42.188,73.438,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.672 | Acc: 49.256,75.744,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.682 | Acc: 49.257,75.457,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.665 | Acc: 49.603,75.589,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.656 | Acc: 49.807,75.704,92.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.658 | Acc: 49.683,75.696,92.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.660 | Acc: 49.380,75.458,92.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.662 | Acc: 49.158,75.277,92.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.662 | Acc: 49.277,75.345,92.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.663 | Acc: 49.197,75.388,92.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.664 | Acc: 49.273,75.381,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 49.424,75.399,92.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 49.410,75.370,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.663 | Acc: 49.359,75.320,92.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.665 | Acc: 49.369,75.320,92.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.667 | Acc: 49.395,75.249,92.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.668 | Acc: 49.319,75.200,92.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.669 | Acc: 49.313,75.154,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.668 | Acc: 49.383,75.128,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.667 | Acc: 49.375,75.187,92.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.763 | Acc: 47.656,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.889 | Acc: 45.536,64.174,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.894 | Acc: 45.827,64.367,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.899 | Acc: 45.748,63.934,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.030 | Acc: 42.188,67.969,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.695 | Acc: 47.693,74.554,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.655 | Acc: 49.295,75.210,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.643 | Acc: 50.102,75.551,93.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.650 | Acc: 50.077,75.579,92.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.661 | Acc: 49.861,75.302,92.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.659 | Acc: 49.722,75.355,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.657 | Acc: 49.612,75.355,92.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.654 | Acc: 49.665,75.539,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.655 | Acc: 49.573,75.617,92.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.657 | Acc: 49.584,75.595,92.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.657 | Acc: 49.625,75.679,92.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.658 | Acc: 49.566,75.593,92.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.657 | Acc: 49.488,75.572,92.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.663 | Acc: 49.411,75.445,92.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.663 | Acc: 49.432,75.405,92.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.667 | Acc: 49.348,75.316,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.667 | Acc: 49.425,75.284,92.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.670 | Acc: 49.377,75.180,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.671 | Acc: 49.399,75.182,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.646 | Acc: 49.219,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 44.940,63.765,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.881 | Acc: 45.732,63.929,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.889 | Acc: 45.620,63.922,70.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.752 | Acc: 42.969,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.636 | Acc: 49.665,76.674,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.646 | Acc: 49.085,76.200,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.640 | Acc: 49.910,76.345,92.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.638 | Acc: 50.299,75.868,92.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.634 | Acc: 50.364,76.044,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.636 | Acc: 50.284,75.968,92.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.640 | Acc: 50.050,75.992,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.646 | Acc: 49.961,75.825,92.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.646 | Acc: 50.000,75.833,92.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.648 | Acc: 49.953,75.906,92.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.650 | Acc: 49.816,75.877,92.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.653 | Acc: 49.767,75.807,92.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.651 | Acc: 49.838,75.778,92.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.654 | Acc: 49.783,75.631,92.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.656 | Acc: 49.772,75.548,92.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 49.832,75.423,92.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.658 | Acc: 49.798,75.376,92.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.663 | Acc: 49.712,75.355,92.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.663 | Acc: 49.629,75.322,92.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.787 | Acc: 44.531,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.915 | Acc: 44.122,63.318,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.919 | Acc: 44.703,63.929,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.932 | Acc: 44.429,63.768,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.612 | Acc: 52.344,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.686 | Acc: 49.926,74.888,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.664 | Acc: 49.886,74.981,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.679 | Acc: 49.629,74.910,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.666 | Acc: 49.730,75.077,92.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.671 | Acc: 49.312,74.923,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.679 | Acc: 49.135,74.903,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.676 | Acc: 49.202,74.823,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.679 | Acc: 49.214,74.762,92.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.678 | Acc: 49.305,74.676,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.675 | Acc: 49.363,74.810,92.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.674 | Acc: 49.466,74.915,92.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.672 | Acc: 49.404,74.880,92.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.669 | Acc: 49.461,74.976,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.669 | Acc: 49.494,74.983,92.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.667 | Acc: 49.535,75.044,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.667 | Acc: 49.574,75.102,92.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.667 | Acc: 49.572,75.066,92.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.667 | Acc: 49.541,75.011,92.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.667 | Acc: 49.532,74.996,92.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.593 | Acc: 51.562,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.867 | Acc: 45.536,64.807,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.907 | Acc: 45.598,64.329,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.927 | Acc: 45.261,63.934,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.351 | Acc: 58.594,78.125,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.613 | Acc: 50.558,76.228,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.619 | Acc: 49.981,76.105,93.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.622 | Acc: 49.782,75.820,93.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.628 | Acc: 49.875,75.762,93.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.639 | Acc: 49.567,75.410,93.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.638 | Acc: 49.367,75.562,93.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.641 | Acc: 49.562,75.471,93.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.640 | Acc: 49.631,75.563,93.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.638 | Acc: 49.672,75.600,93.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.641 | Acc: 49.837,75.567,93.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.644 | Acc: 49.742,75.583,93.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.641 | Acc: 49.786,75.726,93.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.643 | Acc: 49.767,75.751,92.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.644 | Acc: 49.791,75.773,92.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.648 | Acc: 49.743,75.688,92.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.648 | Acc: 49.752,75.638,92.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.652 | Acc: 49.643,75.532,92.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.653 | Acc: 49.610,75.513,92.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 49.504,75.492,92.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.615 | Acc: 44.531,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.879 | Acc: 45.275,64.360,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.890 | Acc: 45.141,64.082,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.921 | Acc: 44.890,63.537,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.669 | Acc: 44.531,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.647 | Acc: 48.884,74.702,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.626 | Acc: 49.085,75.419,93.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.623 | Acc: 49.372,75.871,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.628 | Acc: 49.441,75.588,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.626 | Acc: 49.420,75.673,93.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.630 | Acc: 49.645,75.607,93.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.636 | Acc: 49.490,75.410,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.636 | Acc: 49.602,75.480,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.637 | Acc: 49.560,75.436,93.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.637 | Acc: 49.569,75.498,92.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.645 | Acc: 49.321,75.329,92.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.646 | Acc: 49.203,75.321,92.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.641 | Acc: 49.398,75.449,92.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.643 | Acc: 49.399,75.409,92.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.646 | Acc: 49.419,75.306,92.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.653 | Acc: 49.253,75.219,92.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.653 | Acc: 49.281,75.243,92.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.651 | Acc: 49.331,75.214,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.655 | Acc: 49.325,75.185,92.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.673 | Acc: 46.094,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.853 | Acc: 46.243,64.435,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.893 | Acc: 46.227,64.177,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.917 | Acc: 45.914,63.730,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.638 | Acc: 46.094,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.663 | Acc: 48.140,75.446,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.650 | Acc: 49.562,75.648,92.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.642 | Acc: 50.026,75.692,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.651 | Acc: 49.961,75.482,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.638 | Acc: 50.155,75.704,92.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.646 | Acc: 49.671,75.678,92.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.650 | Acc: 49.673,75.471,92.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.647 | Acc: 49.816,75.471,92.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.646 | Acc: 49.741,75.445,93.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.642 | Acc: 49.674,75.591,93.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.645 | Acc: 49.601,75.481,93.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.649 | Acc: 49.455,75.363,93.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.654 | Acc: 49.410,75.230,92.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.655 | Acc: 49.411,75.247,92.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.651 | Acc: 49.476,75.291,92.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.650 | Acc: 49.567,75.265,92.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.648 | Acc: 49.622,75.302,92.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.648 | Acc: 49.630,75.312,92.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.648 | Acc: 49.662,75.336,92.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.775 | Acc: 45.312,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.912 | Acc: 46.317,64.323,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.938 | Acc: 46.037,63.319,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.949 | Acc: 45.402,63.358,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.822 | Acc: 45.312,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.610 | Acc: 49.219,76.265,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.582 | Acc: 50.534,76.734,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.616 | Acc: 49.629,76.268,93.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.627 | Acc: 49.373,76.071,93.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.624 | Acc: 49.590,76.029,93.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.626 | Acc: 49.483,75.962,93.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.628 | Acc: 49.590,76.003,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.632 | Acc: 49.355,75.932,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.632 | Acc: 49.271,75.915,93.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.630 | Acc: 49.468,75.913,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.633 | Acc: 49.512,75.933,93.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.633 | Acc: 49.523,75.846,93.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.633 | Acc: 49.578,75.790,93.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.638 | Acc: 49.494,75.620,93.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.637 | Acc: 49.450,75.636,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.637 | Acc: 49.413,75.618,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.640 | Acc: 49.446,75.584,92.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.642 | Acc: 49.463,75.556,92.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.643 | Acc: 49.469,75.515,92.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.650 | Acc: 46.094,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.858 | Acc: 46.094,65.216,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 46.151,64.444,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.904 | Acc: 45.927,64.229,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.683 | Acc: 50.781,73.438,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.611 | Acc: 49.888,76.376,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.637 | Acc: 49.676,75.819,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.650 | Acc: 49.565,75.397,93.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.633 | Acc: 49.711,75.791,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.630 | Acc: 49.985,75.851,93.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.629 | Acc: 50.168,75.917,93.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.634 | Acc: 50.000,75.648,93.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.637 | Acc: 49.893,75.432,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.636 | Acc: 49.784,75.552,93.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.635 | Acc: 49.759,75.501,93.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.637 | Acc: 49.629,75.498,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.639 | Acc: 49.520,75.408,93.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.640 | Acc: 49.575,75.455,93.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.637 | Acc: 49.683,75.587,93.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.636 | Acc: 49.808,75.542,93.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.638 | Acc: 49.766,75.511,93.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.640 | Acc: 49.753,75.472,93.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.640 | Acc: 49.788,75.431,93.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.639 | Acc: 49.799,75.412,93.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.698 | Acc: 47.656,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.875 | Acc: 46.354,64.844,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.904 | Acc: 46.437,64.444,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.918 | Acc: 46.145,64.011,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.453 | Acc: 57.031,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.635 | Acc: 50.893,76.935,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.631 | Acc: 50.133,76.791,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.625 | Acc: 50.564,76.780,93.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.635 | Acc: 50.193,76.235,93.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.625 | Acc: 50.178,76.431,93.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.625 | Acc: 50.103,76.278,93.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.619 | Acc: 50.332,76.313,93.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.626 | Acc: 50.082,76.165,93.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.630 | Acc: 49.978,76.096,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.628 | Acc: 49.829,76.143,93.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.627 | Acc: 49.802,76.110,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.627 | Acc: 49.757,76.005,93.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.627 | Acc: 49.832,76.024,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.629 | Acc: 49.766,76.006,93.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.627 | Acc: 49.857,75.997,93.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.627 | Acc: 49.917,76.003,93.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.629 | Acc: 49.950,75.960,93.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.631 | Acc: 49.907,75.876,93.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.630 | Acc: 49.893,75.869,93.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.761 | Acc: 48.438,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.965 | Acc: 45.461,63.542,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.987 | Acc: 45.446,63.529,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.986 | Acc: 45.364,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.366 | Acc: 46.875,85.938,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.578 | Acc: 50.595,77.418,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.579 | Acc: 50.210,77.553,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.600 | Acc: 49.603,77.062,93.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.606 | Acc: 49.373,76.919,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.604 | Acc: 49.296,76.756,93.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.606 | Acc: 49.483,76.575,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.609 | Acc: 49.751,76.546,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.612 | Acc: 49.685,76.485,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.613 | Acc: 49.676,76.312,93.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.617 | Acc: 49.716,76.123,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.623 | Acc: 49.590,76.007,93.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.625 | Acc: 49.556,75.937,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.623 | Acc: 49.680,75.904,93.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.625 | Acc: 49.577,75.826,93.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.628 | Acc: 49.590,75.820,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.628 | Acc: 49.552,75.864,93.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.629 | Acc: 49.627,75.891,93.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.630 | Acc: 49.621,75.799,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.632 | Acc: 49.672,75.707,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.820 | Acc: 43.750,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.976 | Acc: 45.238,63.170,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 45.217,63.014,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.995 | Acc: 44.851,62.935,69.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.742 | Acc: 44.531,70.312,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.598 | Acc: 49.926,74.963,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.606 | Acc: 50.553,75.572,92.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.620 | Acc: 50.090,75.474,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.620 | Acc: 49.788,75.868,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.609 | Acc: 49.892,76.137,93.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.616 | Acc: 49.916,76.014,93.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.620 | Acc: 49.983,75.942,93.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.626 | Acc: 49.869,75.859,93.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.628 | Acc: 49.637,75.859,93.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.629 | Acc: 49.572,75.789,93.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.630 | Acc: 49.678,75.855,93.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.629 | Acc: 49.627,75.833,93.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.628 | Acc: 49.728,75.868,93.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.629 | Acc: 49.714,75.867,93.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.631 | Acc: 49.689,75.719,93.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.632 | Acc: 49.720,75.645,93.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.634 | Acc: 49.709,75.619,93.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.634 | Acc: 49.775,75.625,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.636 | Acc: 49.705,75.578,92.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.750 | Acc: 45.312,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.915 | Acc: 45.610,64.211,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.955 | Acc: 45.465,63.624,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.976 | Acc: 45.645,62.871,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.649 | Acc: 50.000,74.219,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.566 | Acc: 52.269,76.972,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.600 | Acc: 50.629,76.277,93.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.598 | Acc: 50.884,76.562,93.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.586 | Acc: 50.579,76.678,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.591 | Acc: 50.394,76.346,93.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.595 | Acc: 50.426,76.278,93.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.598 | Acc: 50.393,76.374,93.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.602 | Acc: 50.286,76.223,93.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.607 | Acc: 50.410,76.247,93.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.608 | Acc: 50.358,76.182,93.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.608 | Acc: 50.184,76.209,93.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.612 | Acc: 50.133,76.109,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.615 | Acc: 50.018,76.009,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.618 | Acc: 50.019,75.909,93.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.617 | Acc: 50.018,75.932,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.618 | Acc: 49.968,75.898,93.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.619 | Acc: 49.929,75.974,93.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.625 | Acc: 49.814,75.876,93.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.628 | Acc: 49.772,75.779,93.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.708 | Acc: 41.406,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.905 | Acc: 45.796,63.839,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.958 | Acc: 46.018,63.586,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.967 | Acc: 45.838,63.563,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.566 | Acc: 48.438,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.601 | Acc: 49.777,75.558,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.571 | Acc: 50.229,76.448,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.592 | Acc: 49.821,76.396,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.604 | Acc: 49.769,76.485,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.596 | Acc: 49.899,76.671,94.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.601 | Acc: 49.923,76.517,93.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.598 | Acc: 50.155,76.524,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.596 | Acc: 50.189,76.533,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.597 | Acc: 50.259,76.364,93.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.601 | Acc: 50.152,76.325,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.609 | Acc: 50.067,76.216,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.613 | Acc: 49.968,76.063,93.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.618 | Acc: 49.877,75.967,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.620 | Acc: 49.814,75.915,93.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.620 | Acc: 49.878,75.880,93.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.620 | Acc: 49.852,75.869,93.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.621 | Acc: 49.895,75.811,93.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.622 | Acc: 49.922,75.755,93.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.625 | Acc: 49.828,75.668,93.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.627 | Acc: 46.875,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.898 | Acc: 46.615,64.881,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.911 | Acc: 46.494,64.558,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.933 | Acc: 46.158,64.024,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.603 | Acc: 57.031,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.602 | Acc: 48.698,75.558,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.604 | Acc: 48.952,75.705,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.603 | Acc: 49.539,76.063,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.596 | Acc: 49.913,76.408,93.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.600 | Acc: 49.807,76.416,93.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.604 | Acc: 49.716,76.149,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.607 | Acc: 49.701,76.152,93.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.610 | Acc: 49.743,76.106,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.609 | Acc: 49.866,76.114,93.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.616 | Acc: 49.736,75.972,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.615 | Acc: 49.692,75.919,93.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.610 | Acc: 49.831,75.930,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.612 | Acc: 49.743,75.832,93.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.611 | Acc: 49.764,75.803,93.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.611 | Acc: 49.816,75.872,93.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.611 | Acc: 49.810,75.939,93.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.613 | Acc: 49.739,75.987,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.616 | Acc: 49.734,75.883,93.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.619 | Acc: 49.746,75.820,93.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.672 | Acc: 46.094,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.979 | Acc: 43.824,63.988,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 44.417,64.062,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.003 | Acc: 43.993,63.576,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.571 | Acc: 52.344,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.598 | Acc: 49.516,77.232,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.601 | Acc: 49.619,77.191,94.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.591 | Acc: 49.539,77.357,93.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.601 | Acc: 49.315,77.074,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.615 | Acc: 49.265,76.547,93.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.617 | Acc: 49.374,76.324,93.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.623 | Acc: 49.263,76.075,93.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.619 | Acc: 49.452,76.111,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.617 | Acc: 49.590,76.127,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.616 | Acc: 49.782,76.073,93.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.617 | Acc: 49.745,76.046,93.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.615 | Acc: 49.789,76.070,93.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.614 | Acc: 49.823,76.069,93.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.620 | Acc: 49.711,75.870,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.617 | Acc: 49.785,75.862,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.618 | Acc: 49.669,75.879,93.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.618 | Acc: 49.787,75.910,93.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.620 | Acc: 49.734,75.857,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.618 | Acc: 49.854,75.902,93.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.749 | Acc: 47.656,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.986 | Acc: 44.606,63.728,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 45.084,63.281,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.030 | Acc: 45.044,63.153,69.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.440 | Acc: 55.469,78.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.602 | Acc: 49.442,76.525,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.588 | Acc: 49.943,76.867,93.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.578 | Acc: 50.307,76.601,94.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.578 | Acc: 50.087,76.669,94.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.591 | Acc: 50.155,76.439,93.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.594 | Acc: 50.084,76.143,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.598 | Acc: 49.934,76.053,93.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.601 | Acc: 50.010,75.975,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.603 | Acc: 50.086,75.915,93.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.602 | Acc: 50.078,75.917,93.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.598 | Acc: 49.986,76.082,93.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.599 | Acc: 49.857,76.125,93.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.604 | Acc: 49.758,75.985,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.606 | Acc: 49.741,75.965,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.607 | Acc: 49.787,75.906,93.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.609 | Acc: 49.796,75.864,93.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.610 | Acc: 49.801,75.894,93.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.613 | Acc: 49.751,75.825,93.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.612 | Acc: 49.783,75.908,93.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.721 | Acc: 43.750,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.917 | Acc: 46.094,63.802,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.945 | Acc: 46.322,63.815,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.965 | Acc: 46.055,63.755,69.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.541 | Acc: 50.000,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.570 | Acc: 50.632,77.716,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.575 | Acc: 50.152,77.248,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.592 | Acc: 50.295,77.011,93.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.598 | Acc: 49.942,76.948,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.599 | Acc: 49.567,76.965,93.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.608 | Acc: 49.542,76.666,93.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.604 | Acc: 49.529,76.862,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.599 | Acc: 49.777,76.883,93.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.610 | Acc: 49.586,76.528,93.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.612 | Acc: 49.588,76.376,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.611 | Acc: 49.685,76.347,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.611 | Acc: 49.643,76.232,93.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.611 | Acc: 49.659,76.152,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.611 | Acc: 49.561,76.109,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.611 | Acc: 49.665,76.077,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.615 | Acc: 49.635,76.022,93.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.617 | Acc: 49.622,75.937,93.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.619 | Acc: 49.595,75.851,93.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.618 | Acc: 49.641,75.857,93.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.894 | Acc: 46.875,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.970 | Acc: 45.238,63.765,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 45.255,63.624,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 44.826,63.166,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.648 | Acc: 53.125,75.000,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 49.256,76.042,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.614 | Acc: 49.714,76.067,93.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.603 | Acc: 49.769,76.358,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.610 | Acc: 49.498,76.032,93.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.601 | Acc: 49.722,76.524,93.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.597 | Acc: 49.780,76.582,93.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.588 | Acc: 50.017,76.535,93.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.587 | Acc: 50.136,76.577,93.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.590 | Acc: 50.173,76.601,93.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.593 | Acc: 50.089,76.559,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.597 | Acc: 50.025,76.389,93.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.597 | Acc: 49.744,76.439,93.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.598 | Acc: 49.713,76.392,93.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.603 | Acc: 49.697,76.221,93.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.606 | Acc: 49.696,76.134,93.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.610 | Acc: 49.635,76.039,93.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.613 | Acc: 49.624,75.971,93.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.615 | Acc: 49.632,75.905,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.618 | Acc: 49.543,75.773,93.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.593 | Acc: 46.094,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.990 | Acc: 45.126,62.723,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 45.560,62.881,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.996 | Acc: 45.005,63.012,69.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.603 | Acc: 49.219,70.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.604 | Acc: 49.330,75.112,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.612 | Acc: 48.952,75.591,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.598 | Acc: 49.116,75.884,93.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.597 | Acc: 49.199,75.810,93.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.601 | Acc: 49.188,75.990,93.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.595 | Acc: 49.477,76.033,93.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.602 | Acc: 49.440,75.820,93.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.599 | Acc: 49.597,75.883,93.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.599 | Acc: 49.637,75.893,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.602 | Acc: 49.658,75.910,93.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.605 | Acc: 49.657,75.802,93.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.604 | Acc: 49.728,75.784,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.602 | Acc: 49.892,75.829,93.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.602 | Acc: 49.917,75.803,93.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.606 | Acc: 49.935,75.779,93.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.607 | Acc: 49.932,75.808,93.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.609 | Acc: 49.888,75.841,93.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.612 | Acc: 49.849,75.812,93.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.613 | Acc: 49.867,75.841,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.795 | Acc: 46.094,67.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.021 | Acc: 44.531,63.207,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.075 | Acc: 45.065,62.519,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.073 | Acc: 44.634,62.423,69.429,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.694 | Acc: 47.656,74.219,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.596 | Acc: 49.814,77.083,93.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.590 | Acc: 50.457,76.601,93.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.576 | Acc: 50.359,77.126,93.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.574 | Acc: 50.145,76.977,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.573 | Acc: 50.147,76.849,93.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.572 | Acc: 50.245,76.924,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.576 | Acc: 50.094,76.806,93.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.581 | Acc: 49.971,76.752,93.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.586 | Acc: 50.009,76.683,93.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.585 | Acc: 50.175,76.640,93.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.588 | Acc: 50.071,76.637,93.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.597 | Acc: 49.903,76.358,93.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.600 | Acc: 49.859,76.251,93.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.602 | Acc: 49.814,76.229,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.604 | Acc: 49.875,76.139,93.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.609 | Acc: 49.813,76.015,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.609 | Acc: 49.789,75.953,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.608 | Acc: 49.851,75.896,93.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.606 | Acc: 49.961,75.974,93.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.786 | Acc: 48.438,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.934 | Acc: 46.280,64.025,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 46.322,63.891,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.987 | Acc: 46.222,63.704,69.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.634 | Acc: 48.438,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.623 | Acc: 49.740,75.260,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.624 | Acc: 49.505,75.019,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.597 | Acc: 49.885,75.781,93.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.594 | Acc: 49.981,75.598,93.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.589 | Acc: 50.046,75.665,93.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.588 | Acc: 49.832,75.943,93.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.588 | Acc: 49.861,75.925,93.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.588 | Acc: 49.859,75.883,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.590 | Acc: 49.896,75.859,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.588 | Acc: 50.086,76.077,93.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.594 | Acc: 50.042,76.071,93.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.599 | Acc: 49.971,75.943,93.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.599 | Acc: 50.060,75.955,93.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.602 | Acc: 50.039,75.912,93.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.599 | Acc: 50.174,75.979,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.601 | Acc: 50.180,75.920,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.606 | Acc: 50.064,75.875,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.607 | Acc: 50.028,75.905,93.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.607 | Acc: 50.035,75.937,93.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.746 | Acc: 49.219,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.006 | Acc: 44.978,63.318,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.016 | Acc: 45.217,63.034,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.018 | Acc: 45.172,63.115,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.640 | Acc: 51.562,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.580 | Acc: 50.298,76.786,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.596 | Acc: 50.248,76.105,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.604 | Acc: 50.448,76.050,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.597 | Acc: 50.338,76.418,93.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.589 | Acc: 50.193,76.454,94.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.589 | Acc: 50.362,76.259,93.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.588 | Acc: 50.211,76.430,93.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.588 | Acc: 50.214,76.412,93.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.588 | Acc: 50.043,76.433,93.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.589 | Acc: 50.047,76.454,93.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.590 | Acc: 49.929,76.425,93.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.590 | Acc: 49.835,76.430,93.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.593 | Acc: 49.662,76.356,93.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.594 | Acc: 49.589,76.223,93.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.594 | Acc: 49.712,76.194,93.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.597 | Acc: 49.667,76.144,93.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.599 | Acc: 49.711,76.134,93.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.601 | Acc: 49.721,76.084,93.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.603 | Acc: 49.637,76.003,93.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.703 | Acc: 42.188,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.965 | Acc: 45.722,63.318,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.999 | Acc: 45.675,63.491,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.011 | Acc: 45.300,63.230,69.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.681 | Acc: 50.781,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.567 | Acc: 51.525,76.153,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.583 | Acc: 50.800,76.105,93.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.587 | Acc: 50.576,76.396,93.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.587 | Acc: 50.309,76.341,93.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.580 | Acc: 50.402,76.516,94.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.581 | Acc: 50.374,76.653,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.582 | Acc: 50.249,76.701,94.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.581 | Acc: 49.971,76.689,94.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.583 | Acc: 49.996,76.606,94.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.581 | Acc: 50.070,76.683,94.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.584 | Acc: 50.134,76.577,93.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.588 | Acc: 49.958,76.546,93.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.590 | Acc: 49.985,76.586,93.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.592 | Acc: 49.947,76.560,93.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.593 | Acc: 49.912,76.469,93.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.592 | Acc: 49.876,76.343,93.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.594 | Acc: 49.888,76.283,93.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.594 | Acc: 49.911,76.303,93.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.597 | Acc: 49.750,76.208,93.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.784 | Acc: 46.875,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.976 | Acc: 45.536,63.430,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.992 | Acc: 45.636,63.415,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.012 | Acc: 45.146,63.294,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.629 | Acc: 38.281,71.875,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.564 | Acc: 50.521,76.637,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.562 | Acc: 49.752,77.134,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.573 | Acc: 49.270,77.011,94.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.582 | Acc: 49.219,76.717,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.591 | Acc: 49.404,76.454,93.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.590 | Acc: 49.516,76.556,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.590 | Acc: 49.662,76.507,93.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.589 | Acc: 49.845,76.611,93.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.585 | Acc: 50.060,76.679,93.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.585 | Acc: 50.117,76.667,93.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.589 | Acc: 50.064,76.623,93.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.590 | Acc: 50.068,76.566,93.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.591 | Acc: 50.036,76.401,93.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.590 | Acc: 50.081,76.426,93.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.593 | Acc: 50.099,76.344,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.594 | Acc: 50.066,76.326,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.593 | Acc: 50.094,76.251,93.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.594 | Acc: 50.050,76.225,93.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.595 | Acc: 50.033,76.212,93.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.714 | Acc: 49.219,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 46.949,63.690,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.986 | Acc: 46.589,63.777,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.009 | Acc: 46.196,63.166,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.619 | Acc: 49.219,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.589 | Acc: 49.516,76.302,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.571 | Acc: 49.371,76.334,94.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.583 | Acc: 49.411,76.101,94.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.571 | Acc: 49.653,76.109,94.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.568 | Acc: 49.869,76.261,94.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.563 | Acc: 49.819,76.395,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.572 | Acc: 49.773,76.180,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.569 | Acc: 49.728,76.368,94.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.571 | Acc: 49.827,76.502,94.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.576 | Acc: 49.876,76.349,94.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.579 | Acc: 49.922,76.329,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.582 | Acc: 49.877,76.284,94.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.586 | Acc: 49.847,76.236,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.590 | Acc: 49.705,76.182,93.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.591 | Acc: 49.738,76.129,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.594 | Acc: 49.754,76.095,93.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.594 | Acc: 49.787,76.109,93.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.597 | Acc: 49.777,75.998,93.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.597 | Acc: 49.723,75.972,93.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.813 | Acc: 45.312,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.941 | Acc: 46.168,64.211,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.973 | Acc: 45.808,63.891,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.990 | Acc: 45.505,63.640,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.669 | Acc: 50.000,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.616 | Acc: 48.103,76.488,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.579 | Acc: 49.200,77.001,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.577 | Acc: 49.898,77.088,94.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.597 | Acc: 49.682,76.437,94.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.588 | Acc: 49.590,76.446,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.594 | Acc: 49.606,76.401,93.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.601 | Acc: 49.568,76.263,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.603 | Acc: 49.641,76.242,93.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.603 | Acc: 49.737,76.226,93.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.598 | Acc: 49.790,76.255,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.596 | Acc: 49.894,76.322,93.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.598 | Acc: 49.838,76.203,93.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.602 | Acc: 49.731,76.111,93.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.604 | Acc: 49.750,76.018,93.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.606 | Acc: 49.792,76.020,93.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.606 | Acc: 49.744,75.983,93.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.608 | Acc: 49.748,75.928,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.606 | Acc: 49.797,75.965,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.606 | Acc: 49.762,76.011,93.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.749 | Acc: 42.969,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.989 | Acc: 45.052,64.062,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.030 | Acc: 44.912,63.643,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.044 | Acc: 44.864,63.140,69.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.435 | Acc: 51.562,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.538 | Acc: 51.116,77.716,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.568 | Acc: 50.133,76.810,94.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.587 | Acc: 49.731,76.985,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.594 | Acc: 49.662,76.505,93.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.593 | Acc: 49.590,76.423,93.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.590 | Acc: 49.780,76.530,93.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.589 | Acc: 49.789,76.341,93.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.591 | Acc: 49.757,76.262,93.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.590 | Acc: 49.732,76.278,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.589 | Acc: 49.767,76.228,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.588 | Acc: 49.802,76.343,93.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.591 | Acc: 49.812,76.316,93.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.591 | Acc: 49.871,76.278,93.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.591 | Acc: 49.861,76.273,93.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.588 | Acc: 49.899,76.378,93.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.590 | Acc: 49.895,76.266,93.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.591 | Acc: 49.830,76.228,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.594 | Acc: 49.758,76.145,93.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.593 | Acc: 49.908,76.163,93.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.742 | Acc: 46.875,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 45.982,63.393,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 45.884,63.377,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.004 | Acc: 45.722,63.192,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.365 | Acc: 54.688,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.563 | Acc: 51.265,77.232,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.586 | Acc: 50.514,76.239,93.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.588 | Acc: 50.487,76.370,93.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.593 | Acc: 50.231,76.090,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.593 | Acc: 50.023,76.199,93.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.587 | Acc: 50.071,76.498,94.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.586 | Acc: 50.072,76.452,94.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.590 | Acc: 50.044,76.364,93.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.582 | Acc: 50.104,76.606,94.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.584 | Acc: 50.082,76.590,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.586 | Acc: 49.926,76.485,94.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.588 | Acc: 49.932,76.410,94.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.590 | Acc: 50.000,76.383,93.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.592 | Acc: 49.905,76.387,93.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.594 | Acc: 49.987,76.334,93.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.595 | Acc: 50.007,76.297,93.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.596 | Acc: 49.975,76.214,93.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.596 | Acc: 49.974,76.173,93.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.595 | Acc: 50.004,76.232,93.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.750 | Acc: 43.750,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 45.312,63.802,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.994 | Acc: 45.351,63.624,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 45.082,63.422,69.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.463 | Acc: 46.875,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.593 | Acc: 49.107,75.335,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.567 | Acc: 49.886,76.410,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.577 | Acc: 49.872,76.127,94.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.570 | Acc: 50.116,76.572,94.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.579 | Acc: 50.209,76.122,94.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.578 | Acc: 50.355,76.188,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.577 | Acc: 50.427,76.191,93.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.576 | Acc: 50.359,76.257,94.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.580 | Acc: 50.263,76.118,93.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.581 | Acc: 50.292,76.135,93.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.580 | Acc: 50.209,76.273,93.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.583 | Acc: 50.224,76.232,93.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.585 | Acc: 50.177,76.272,93.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.585 | Acc: 50.161,76.315,93.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.587 | Acc: 50.200,76.274,93.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.587 | Acc: 50.265,76.261,93.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.587 | Acc: 50.236,76.258,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.590 | Acc: 50.186,76.201,93.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.588 | Acc: 50.209,76.230,93.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.809 | Acc: 42.969,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.004 | Acc: 45.387,63.170,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.016 | Acc: 45.522,63.205,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.035 | Acc: 45.453,63.076,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.557 | Acc: 48.438,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.592 | Acc: 47.656,76.265,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.565 | Acc: 49.638,76.925,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.562 | Acc: 49.910,76.780,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.555 | Acc: 50.270,77.006,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.555 | Acc: 49.961,77.096,94.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.556 | Acc: 49.935,77.079,94.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.554 | Acc: 49.956,77.166,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.555 | Acc: 50.029,77.023,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.563 | Acc: 49.948,76.869,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.567 | Acc: 49.860,76.827,94.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.571 | Acc: 49.890,76.647,94.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.577 | Acc: 49.851,76.443,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.579 | Acc: 49.805,76.467,94.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.579 | Acc: 49.883,76.493,94.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.578 | Acc: 49.953,76.511,94.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.580 | Acc: 49.956,76.375,93.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.581 | Acc: 49.973,76.320,93.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.584 | Acc: 49.959,76.281,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.588 | Acc: 49.936,76.200,93.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.703 | Acc: 45.312,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.968 | Acc: 45.722,63.802,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.976 | Acc: 45.979,63.948,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.994 | Acc: 45.966,63.525,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.548 | Acc: 49.219,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.549 | Acc: 51.637,77.865,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.562 | Acc: 51.315,77.496,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.552 | Acc: 51.588,77.677,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.561 | Acc: 50.858,77.546,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.567 | Acc: 50.433,76.934,93.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.564 | Acc: 50.562,77.079,93.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.568 | Acc: 50.255,76.906,93.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.568 | Acc: 50.301,76.805,93.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.573 | Acc: 50.112,76.748,93.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.576 | Acc: 50.202,76.687,93.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.577 | Acc: 50.251,76.534,93.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.580 | Acc: 50.289,76.413,93.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.583 | Acc: 50.281,76.416,93.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.586 | Acc: 50.314,76.373,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.588 | Acc: 50.306,76.355,93.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.594 | Acc: 50.136,76.258,93.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.594 | Acc: 50.124,76.244,93.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.594 | Acc: 50.145,76.223,93.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.594 | Acc: 50.119,76.185,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.027 | Acc: 44.531,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 45.759,62.649,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.041 | Acc: 45.427,62.843,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.065 | Acc: 45.620,62.718,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.563 | Acc: 50.000,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.556 | Acc: 50.707,77.455,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.567 | Acc: 50.229,76.620,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.569 | Acc: 50.077,76.460,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.575 | Acc: 49.788,76.418,94.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.569 | Acc: 50.039,76.733,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.566 | Acc: 50.381,76.756,94.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.571 | Acc: 50.393,76.607,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.570 | Acc: 50.587,76.645,94.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.576 | Acc: 50.345,76.541,94.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.579 | Acc: 50.097,76.485,94.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.582 | Acc: 49.940,76.435,94.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.583 | Acc: 49.932,76.387,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.582 | Acc: 50.105,76.473,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.586 | Acc: 50.083,76.423,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.584 | Acc: 50.078,76.425,94.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.583 | Acc: 50.051,76.434,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.580 | Acc: 50.094,76.450,94.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.582 | Acc: 50.126,76.379,94.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.580 | Acc: 50.168,76.448,94.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.868 | Acc: 44.531,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.065 | Acc: 44.568,63.876,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.066 | Acc: 44.722,63.739,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.088 | Acc: 44.352,63.192,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.583 | Acc: 51.562,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.562 | Acc: 50.037,76.562,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.573 | Acc: 49.524,76.124,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.574 | Acc: 49.769,76.204,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.570 | Acc: 50.058,76.524,94.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.583 | Acc: 49.899,76.323,93.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.578 | Acc: 50.161,76.427,94.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.581 | Acc: 50.033,76.435,93.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.581 | Acc: 50.141,76.533,93.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.579 | Acc: 50.233,76.567,93.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.578 | Acc: 50.237,76.547,93.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.578 | Acc: 50.297,76.587,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.577 | Acc: 50.421,76.524,93.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.577 | Acc: 50.266,76.518,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.575 | Acc: 50.272,76.596,93.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.576 | Acc: 50.288,76.633,93.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.580 | Acc: 50.246,76.570,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.584 | Acc: 50.151,76.482,93.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.585 | Acc: 50.141,76.526,93.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.586 | Acc: 50.076,76.489,93.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.865 | Acc: 46.094,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.033 | Acc: 45.350,62.798,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.034 | Acc: 45.351,63.186,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.057 | Acc: 45.146,62.846,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.406 | Acc: 51.562,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.515 | Acc: 51.562,77.716,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.555 | Acc: 50.381,76.448,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.565 | Acc: 50.499,76.434,94.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.557 | Acc: 50.617,76.794,94.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.559 | Acc: 50.480,76.771,94.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.559 | Acc: 50.639,76.730,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.559 | Acc: 50.593,76.923,94.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.562 | Acc: 50.485,76.820,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.565 | Acc: 50.423,76.847,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.572 | Acc: 50.303,76.648,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.574 | Acc: 50.279,76.623,93.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.572 | Acc: 50.279,76.692,93.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.576 | Acc: 50.105,76.503,93.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.580 | Acc: 50.017,76.421,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.580 | Acc: 50.029,76.357,93.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.582 | Acc: 50.063,76.346,93.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.582 | Acc: 50.080,76.388,93.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.582 | Acc: 50.087,76.353,93.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.580 | Acc: 50.105,76.442,93.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.774 | Acc: 43.750,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.070 | Acc: 44.494,62.909,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.103 | Acc: 44.455,62.271,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.100 | Acc: 43.916,61.936,69.390,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.656 | Acc: 42.188,74.219,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.538 | Acc: 52.046,77.269,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.571 | Acc: 49.676,76.582,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.561 | Acc: 49.539,77.152,94.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.570 | Acc: 49.932,76.678,94.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.565 | Acc: 49.884,76.702,94.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.559 | Acc: 49.942,76.782,94.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.568 | Acc: 49.861,76.679,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.575 | Acc: 49.675,76.485,94.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.572 | Acc: 49.702,76.407,94.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.572 | Acc: 49.918,76.310,94.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.569 | Acc: 50.113,76.396,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.570 | Acc: 50.117,76.284,93.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.575 | Acc: 50.066,76.236,93.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.580 | Acc: 49.930,76.115,93.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.579 | Acc: 49.977,76.186,93.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.581 | Acc: 50.066,76.239,93.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.583 | Acc: 50.044,76.249,93.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.586 | Acc: 50.048,76.140,93.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.587 | Acc: 50.066,76.136,93.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.832 | Acc: 45.312,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.050 | Acc: 44.792,62.835,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.048 | Acc: 45.255,63.148,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.075 | Acc: 45.018,62.820,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.504 | Acc: 48.438,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.589 | Acc: 49.814,76.339,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.571 | Acc: 50.648,76.620,94.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.582 | Acc: 49.923,76.319,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.576 | Acc: 50.106,76.611,94.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.570 | Acc: 50.101,76.578,94.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.554 | Acc: 50.471,76.879,94.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.558 | Acc: 50.554,76.768,94.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.565 | Acc: 50.364,76.529,94.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.564 | Acc: 50.380,76.567,94.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.565 | Acc: 50.396,76.617,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.569 | Acc: 50.318,76.570,94.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.574 | Acc: 50.204,76.462,93.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.574 | Acc: 50.236,76.509,93.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.576 | Acc: 50.117,76.457,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.580 | Acc: 50.039,76.389,93.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.580 | Acc: 50.158,76.404,93.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.580 | Acc: 50.103,76.425,93.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.582 | Acc: 50.106,76.383,93.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.582 | Acc: 50.082,76.362,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.987 | Acc: 50.000,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.101 | Acc: 44.680,63.095,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.094 | Acc: 45.160,63.053,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.103 | Acc: 45.005,62.705,68.865,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.475 | Acc: 57.812,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.571 | Acc: 49.777,78.460,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.604 | Acc: 49.123,76.658,93.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.579 | Acc: 49.565,77.075,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.587 | Acc: 50.183,76.726,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.573 | Acc: 50.364,76.980,93.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.579 | Acc: 50.045,76.821,93.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.576 | Acc: 50.111,76.856,93.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.574 | Acc: 50.267,76.888,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.581 | Acc: 50.125,76.632,93.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.580 | Acc: 50.066,76.691,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.580 | Acc: 49.947,76.768,93.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.579 | Acc: 50.071,76.754,93.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.583 | Acc: 50.027,76.619,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.583 | Acc: 50.122,76.702,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.582 | Acc: 50.130,76.705,93.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.582 | Acc: 50.097,76.713,93.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.583 | Acc: 50.142,76.686,93.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.587 | Acc: 50.074,76.547,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.584 | Acc: 50.193,76.560,93.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.769 | Acc: 44.531,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.035 | Acc: 45.275,64.211,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.046 | Acc: 45.370,64.062,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.049 | Acc: 45.261,63.768,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.551 | Acc: 50.781,71.875,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.526 | Acc: 50.409,77.790,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.556 | Acc: 50.171,77.306,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.550 | Acc: 50.512,77.318,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.550 | Acc: 50.569,77.093,94.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.559 | Acc: 50.325,76.771,94.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.560 | Acc: 50.407,76.808,94.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.569 | Acc: 50.211,76.590,94.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.568 | Acc: 50.301,76.674,94.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.569 | Acc: 50.199,76.584,94.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.572 | Acc: 50.272,76.644,94.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.572 | Acc: 50.117,76.573,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.576 | Acc: 50.016,76.475,93.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.576 | Acc: 50.054,76.452,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.576 | Acc: 50.234,76.462,93.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.576 | Acc: 50.218,76.402,93.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.578 | Acc: 50.207,76.358,93.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.580 | Acc: 50.151,76.347,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.582 | Acc: 50.126,76.379,93.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.582 | Acc: 50.119,76.429,93.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.909 | Acc: 42.969,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.012 | Acc: 45.499,62.984,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.033 | Acc: 45.808,63.281,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.061 | Acc: 45.607,62.935,69.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.616 | Acc: 43.750,72.656,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.595 | Acc: 48.958,77.083,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.573 | Acc: 49.771,76.810,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.570 | Acc: 49.910,76.434,94.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.576 | Acc: 49.788,76.331,94.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.569 | Acc: 49.923,76.524,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.566 | Acc: 49.994,76.679,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.569 | Acc: 49.983,76.679,94.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.568 | Acc: 50.087,76.761,94.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.569 | Acc: 50.009,76.627,94.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.568 | Acc: 50.012,76.629,94.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.565 | Acc: 50.074,76.768,94.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.566 | Acc: 50.055,76.751,94.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.567 | Acc: 49.988,76.772,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.569 | Acc: 49.992,76.713,94.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.571 | Acc: 49.956,76.697,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.577 | Acc: 49.810,76.601,93.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.578 | Acc: 49.833,76.592,93.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.576 | Acc: 49.879,76.643,93.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.579 | Acc: 49.885,76.604,93.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.966 | Acc: 46.094,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.973 | Acc: 46.354,63.765,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.014 | Acc: 46.284,63.262,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.045 | Acc: 45.812,63.012,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.762 | Acc: 49.219,71.094,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.607 | Acc: 49.330,74.777,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.585 | Acc: 50.286,75.877,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.556 | Acc: 50.282,76.575,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.557 | Acc: 50.386,76.871,94.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.551 | Acc: 50.611,77.027,94.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.561 | Acc: 50.136,76.666,94.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.565 | Acc: 50.022,76.551,94.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.564 | Acc: 50.131,76.558,94.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.568 | Acc: 49.931,76.545,94.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.569 | Acc: 49.992,76.477,94.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.566 | Acc: 50.088,76.616,94.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.569 | Acc: 50.032,76.488,94.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.570 | Acc: 50.030,76.422,94.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.572 | Acc: 49.983,76.396,94.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.573 | Acc: 49.997,76.443,94.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.577 | Acc: 49.985,76.421,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.578 | Acc: 49.998,76.420,93.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.578 | Acc: 50.013,76.465,93.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.579 | Acc: 49.979,76.458,93.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.871 | Acc: 51.562,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.037 | Acc: 46.689,64.286,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.049 | Acc: 46.856,63.491,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.062 | Acc: 46.542,63.166,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.482 | Acc: 50.781,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.540 | Acc: 51.116,78.051,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.547 | Acc: 50.667,77.973,94.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.556 | Acc: 50.384,77.446,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.557 | Acc: 50.424,77.373,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.561 | Acc: 50.495,77.065,94.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.564 | Acc: 50.491,76.931,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.566 | Acc: 50.460,76.973,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.570 | Acc: 50.233,77.019,94.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.572 | Acc: 50.479,76.985,93.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.572 | Acc: 50.505,76.916,93.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.574 | Acc: 50.527,76.732,93.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.571 | Acc: 50.548,76.767,93.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.572 | Acc: 50.509,76.697,93.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.573 | Acc: 50.528,76.651,93.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.572 | Acc: 50.517,76.669,93.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.576 | Acc: 50.450,76.548,93.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.577 | Acc: 50.456,76.526,93.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.576 | Acc: 50.452,76.537,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.578 | Acc: 50.299,76.528,93.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.841 | Acc: 44.531,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.986 | Acc: 45.350,64.360,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.035 | Acc: 45.903,63.624,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.048 | Acc: 45.812,63.397,69.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.672 | Acc: 49.219,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.550 | Acc: 49.777,76.935,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.567 | Acc: 50.133,76.353,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.554 | Acc: 50.064,76.627,94.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.551 | Acc: 49.923,76.620,94.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.550 | Acc: 50.077,76.849,94.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.553 | Acc: 50.032,76.750,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.560 | Acc: 50.078,76.695,94.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.558 | Acc: 50.136,76.771,94.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.559 | Acc: 50.017,76.714,94.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.559 | Acc: 50.043,76.632,94.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.559 | Acc: 50.071,76.538,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.561 | Acc: 50.006,76.663,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.563 | Acc: 49.949,76.658,94.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.565 | Acc: 49.956,76.599,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.567 | Acc: 50.003,76.588,94.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.567 | Acc: 50.007,76.687,94.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.569 | Acc: 50.027,76.634,93.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.571 | Acc: 49.926,76.578,93.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.571 | Acc: 50.000,76.567,93.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.885 | Acc: 47.656,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.030 | Acc: 45.573,63.839,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.060 | Acc: 45.675,63.014,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.079 | Acc: 45.236,62.833,68.904,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.836 | Acc: 44.531,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.547 | Acc: 50.670,77.679,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.568 | Acc: 50.095,76.944,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.568 | Acc: 50.282,76.934,93.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.563 | Acc: 50.367,77.103,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.555 | Acc: 50.356,77.073,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.566 | Acc: 50.155,76.737,94.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.561 | Acc: 50.299,76.806,94.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.567 | Acc: 50.063,76.776,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.563 | Acc: 50.043,76.934,94.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.564 | Acc: 50.031,76.901,94.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.564 | Acc: 50.057,76.895,94.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.564 | Acc: 50.133,76.909,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.563 | Acc: 50.129,76.910,94.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.567 | Acc: 49.986,76.727,94.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.569 | Acc: 49.956,76.669,94.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.566 | Acc: 50.039,76.743,94.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.566 | Acc: 50.060,76.769,94.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.564 | Acc: 50.130,76.803,94.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.566 | Acc: 50.082,76.776,94.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.895 | Acc: 43.750,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.010 | Acc: 45.759,64.211,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.066 | Acc: 45.789,63.377,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.067 | Acc: 46.043,63.281,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.439 | Acc: 57.812,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.520 | Acc: 50.632,77.009,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.524 | Acc: 50.343,77.477,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.531 | Acc: 50.179,77.241,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.517 | Acc: 50.646,77.652,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.507 | Acc: 51.083,77.645,95.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 51.072,77.757,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.498 | Acc: 50.997,78.059,95.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.502 | Acc: 51.004,77.771,95.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.500 | Acc: 51.088,77.879,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.501 | Acc: 51.038,77.927,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.500 | Acc: 51.004,77.955,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 51.076,77.966,95.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 50.907,77.903,95.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.503 | Acc: 50.834,77.889,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 50.857,77.933,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.499 | Acc: 50.823,77.994,95.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.499 | Acc: 50.738,78.017,95.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 50.744,78.008,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.499 | Acc: 50.666,77.949,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.640 | Acc: 45.312,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.864 | Acc: 46.801,65.141,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.893 | Acc: 47.332,65.168,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.909 | Acc: 47.221,64.780,70.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.442 | Acc: 50.000,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.484 | Acc: 52.493,78.237,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.497 | Acc: 51.734,77.668,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.483 | Acc: 51.473,78.279,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.480 | Acc: 51.331,78.405,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.482 | Acc: 51.168,78.380,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.478 | Acc: 50.975,78.590,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 50.970,78.452,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.479 | Acc: 51.038,78.503,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.474 | Acc: 51.053,78.544,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.474 | Acc: 51.119,78.560,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.473 | Acc: 51.138,78.606,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.471 | Acc: 51.141,78.569,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.472 | Acc: 51.075,78.547,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.472 | Acc: 51.084,78.511,95.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.468 | Acc: 51.121,78.686,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.468 | Acc: 51.137,78.677,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.466 | Acc: 51.171,78.698,95.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.467 | Acc: 51.179,78.694,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.468 | Acc: 51.144,78.705,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.678 | Acc: 46.094,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.873 | Acc: 46.912,65.290,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.908 | Acc: 47.256,65.168,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.919 | Acc: 47.054,64.639,70.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.402 | Acc: 48.438,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.416 | Acc: 51.897,80.208,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.434 | Acc: 51.220,79.230,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.447 | Acc: 51.230,79.009,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.444 | Acc: 51.350,79.080,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.443 | Acc: 51.338,79.061,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.444 | Acc: 51.485,79.035,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.447 | Acc: 51.385,79.006,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.446 | Acc: 51.470,79.032,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.445 | Acc: 51.433,79.053,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.444 | Acc: 51.419,79.038,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.444 | Acc: 51.393,78.995,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.445 | Acc: 51.374,79.042,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.447 | Acc: 51.368,79.011,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.451 | Acc: 51.268,78.881,96.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.453 | Acc: 51.264,78.776,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.454 | Acc: 51.217,78.789,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.453 | Acc: 51.244,78.815,96.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.456 | Acc: 51.182,78.718,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.457 | Acc: 51.163,78.761,96.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.619 | Acc: 46.875,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.876 | Acc: 47.359,65.141,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.902 | Acc: 47.694,65.053,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.917 | Acc: 47.400,64.728,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.201 | Acc: 61.719,84.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.431 | Acc: 52.009,79.241,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.444 | Acc: 51.010,79.021,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.445 | Acc: 50.884,79.419,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.436 | Acc: 51.071,79.427,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.442 | Acc: 50.890,79.378,96.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.449 | Acc: 50.949,79.307,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.443 | Acc: 51.130,79.394,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.448 | Acc: 50.932,79.110,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.452 | Acc: 50.829,79.157,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.450 | Acc: 50.851,79.237,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.447 | Acc: 51.004,79.193,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.453 | Acc: 50.901,78.880,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.454 | Acc: 50.967,78.909,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.453 | Acc: 51.029,78.915,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.454 | Acc: 51.049,78.782,96.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.457 | Acc: 50.993,78.692,96.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.458 | Acc: 51.015,78.716,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.457 | Acc: 51.026,78.770,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.454 | Acc: 51.091,78.800,96.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.613 | Acc: 46.094,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.877 | Acc: 47.210,64.695,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.908 | Acc: 47.713,64.939,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.920 | Acc: 47.426,64.690,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.328 | Acc: 57.812,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.438 | Acc: 52.158,79.129,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.436 | Acc: 52.363,79.249,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.436 | Acc: 51.831,79.201,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.436 | Acc: 51.977,79.099,96.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.440 | Acc: 51.570,78.899,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.440 | Acc: 51.524,78.939,96.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.440 | Acc: 51.490,79.045,96.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.440 | Acc: 51.524,79.100,96.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.441 | Acc: 51.390,79.118,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.440 | Acc: 51.368,79.233,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.443 | Acc: 51.283,79.164,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.444 | Acc: 51.203,79.114,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.442 | Acc: 51.272,79.086,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.441 | Acc: 51.340,79.076,96.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.442 | Acc: 51.248,79.065,96.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.445 | Acc: 51.161,79.021,96.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.444 | Acc: 51.242,79.073,96.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.444 | Acc: 51.225,79.090,96.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.444 | Acc: 51.292,79.083,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.636 | Acc: 47.656,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.876 | Acc: 47.507,65.327,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.906 | Acc: 47.809,65.339,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.913 | Acc: 47.439,64.972,70.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.355 | Acc: 53.906,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.451 | Acc: 51.749,78.609,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.456 | Acc: 51.315,79.059,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.451 | Acc: 51.345,79.060,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.448 | Acc: 51.321,79.244,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.444 | Acc: 51.578,79.146,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.444 | Acc: 51.556,79.132,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.445 | Acc: 51.590,79.028,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.447 | Acc: 51.465,78.901,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.450 | Acc: 51.386,78.794,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.445 | Acc: 51.590,78.976,96.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.445 | Acc: 51.456,78.988,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.444 | Acc: 51.537,79.000,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.445 | Acc: 51.398,78.939,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.449 | Acc: 51.304,78.826,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.449 | Acc: 51.337,78.834,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.451 | Acc: 51.300,78.816,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.449 | Acc: 51.290,78.764,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.451 | Acc: 51.234,78.761,96.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.450 | Acc: 51.257,78.804,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.613 | Acc: 47.656,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.884 | Acc: 47.582,65.253,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.902 | Acc: 47.885,65.244,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.915 | Acc: 47.374,65.010,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.554 | Acc: 53.125,73.438,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.428 | Acc: 51.488,79.390,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.434 | Acc: 51.239,79.116,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.432 | Acc: 51.114,79.073,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.435 | Acc: 51.090,79.157,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 51.013,79.208,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.436 | Acc: 51.027,79.126,96.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.433 | Acc: 51.086,79.322,96.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.438 | Acc: 51.000,79.134,96.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.438 | Acc: 51.040,79.092,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.437 | Acc: 51.061,79.143,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.440 | Acc: 51.036,79.002,96.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.441 | Acc: 51.079,79.004,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.443 | Acc: 51.000,78.960,96.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.443 | Acc: 51.026,78.912,96.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.448 | Acc: 50.950,78.834,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.447 | Acc: 50.961,78.853,96.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.446 | Acc: 51.063,78.911,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.443 | Acc: 51.199,78.954,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.443 | Acc: 51.161,78.966,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.613 | Acc: 46.094,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 46.801,65.476,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.904 | Acc: 47.447,65.263,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.917 | Acc: 47.080,64.997,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.529 | Acc: 53.906,75.000,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.426 | Acc: 52.716,79.055,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.440 | Acc: 52.058,79.364,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.426 | Acc: 52.100,79.559,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.428 | Acc: 51.900,79.562,96.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.430 | Acc: 52.150,79.308,96.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.429 | Acc: 52.021,79.416,96.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.430 | Acc: 51.978,79.333,96.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.435 | Acc: 51.781,79.129,96.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.441 | Acc: 51.537,79.113,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.439 | Acc: 51.644,79.213,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.436 | Acc: 51.637,79.260,96.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.436 | Acc: 51.699,79.208,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.439 | Acc: 51.619,79.152,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.440 | Acc: 51.504,79.062,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.438 | Acc: 51.547,79.057,96.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.439 | Acc: 51.497,78.982,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.439 | Acc: 51.439,78.970,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.437 | Acc: 51.508,79.036,96.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.436 | Acc: 51.456,79.109,96.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.641 | Acc: 45.312,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.863 | Acc: 47.545,65.216,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.892 | Acc: 47.485,65.206,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.907 | Acc: 47.234,64.959,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.372 | Acc: 54.688,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.474 | Acc: 51.339,77.604,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.449 | Acc: 51.315,78.354,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.431 | Acc: 51.729,78.765,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.430 | Acc: 51.427,78.819,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.439 | Acc: 51.284,78.767,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.438 | Acc: 51.324,78.777,96.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.440 | Acc: 51.463,78.768,96.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.445 | Acc: 51.184,78.528,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.446 | Acc: 51.174,78.565,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.445 | Acc: 51.104,78.650,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.440 | Acc: 51.213,78.790,96.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.440 | Acc: 51.216,78.786,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.437 | Acc: 51.245,78.876,96.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.438 | Acc: 51.257,78.845,96.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.438 | Acc: 51.233,78.873,96.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.437 | Acc: 51.249,78.909,96.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.437 | Acc: 51.313,78.913,96.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.439 | Acc: 51.244,78.841,96.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.441 | Acc: 51.257,78.818,96.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.667 | Acc: 45.312,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.870 | Acc: 47.135,65.513,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.902 | Acc: 47.447,65.301,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.915 | Acc: 47.157,65.010,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.460 | Acc: 51.562,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.433 | Acc: 50.632,79.948,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.415 | Acc: 51.601,80.126,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.411 | Acc: 51.230,79.905,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.424 | Acc: 50.945,79.765,96.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.426 | Acc: 50.851,79.664,96.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.424 | Acc: 50.839,79.513,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.426 | Acc: 50.981,79.438,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.423 | Acc: 51.262,79.489,96.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.430 | Acc: 51.006,79.342,96.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.433 | Acc: 50.941,79.174,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.434 | Acc: 51.043,79.210,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.434 | Acc: 51.070,79.120,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.434 | Acc: 51.075,79.110,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.435 | Acc: 51.184,79.101,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.436 | Acc: 51.059,79.127,96.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.438 | Acc: 50.942,79.106,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.438 | Acc: 50.932,79.057,96.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.438 | Acc: 51.019,79.017,96.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.436 | Acc: 51.101,79.011,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.669 | Acc: 46.094,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.873 | Acc: 47.210,65.253,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.902 | Acc: 47.752,65.225,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.919 | Acc: 47.349,64.908,70.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.377 | Acc: 53.906,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 50.112,79.204,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 50.610,78.373,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.446 | Acc: 50.602,78.471,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.432 | Acc: 51.119,79.032,96.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.431 | Acc: 51.106,79.216,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.435 | Acc: 51.111,79.203,96.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.432 | Acc: 51.097,79.117,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.432 | Acc: 51.237,79.256,96.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.436 | Acc: 51.165,79.113,96.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.429 | Acc: 51.368,79.198,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.428 | Acc: 51.495,79.207,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.434 | Acc: 51.352,79.123,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.433 | Acc: 51.395,79.101,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.434 | Acc: 51.449,79.095,96.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.432 | Acc: 51.492,79.104,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.432 | Acc: 51.526,79.091,96.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.433 | Acc: 51.558,79.028,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.431 | Acc: 51.582,79.062,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.433 | Acc: 51.454,78.966,96.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.659 | Acc: 47.656,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.871 | Acc: 46.987,64.732,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.905 | Acc: 47.637,64.939,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.916 | Acc: 47.170,64.728,70.850,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.469 | Acc: 47.656,75.000,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.457 | Acc: 50.186,78.423,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.458 | Acc: 49.600,78.258,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.439 | Acc: 50.640,78.817,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.429 | Acc: 51.071,79.041,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.429 | Acc: 51.183,79.053,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.421 | Acc: 51.569,79.429,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.422 | Acc: 51.418,79.471,96.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.424 | Acc: 51.354,79.333,96.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.424 | Acc: 51.472,79.308,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.419 | Acc: 51.671,79.408,96.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.419 | Acc: 51.782,79.327,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.425 | Acc: 51.715,79.130,96.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.427 | Acc: 51.631,79.056,96.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.433 | Acc: 51.501,78.973,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.433 | Acc: 51.451,79.046,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.432 | Acc: 51.482,79.074,96.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.431 | Acc: 51.482,79.064,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.436 | Acc: 51.305,78.919,96.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.437 | Acc: 51.312,78.857,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.645 | Acc: 46.875,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.868 | Acc: 47.433,65.439,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.899 | Acc: 47.752,65.377,71.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.913 | Acc: 47.323,65.061,70.863,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.552 | Acc: 51.562,71.094,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.438 | Acc: 51.079,79.092,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.443 | Acc: 51.753,78.373,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.449 | Acc: 51.575,78.804,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.443 | Acc: 51.505,78.993,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.435 | Acc: 51.818,79.169,96.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.430 | Acc: 51.847,79.236,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.434 | Acc: 51.651,79.410,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.435 | Acc: 51.436,79.280,96.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.432 | Acc: 51.541,79.195,96.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.428 | Acc: 51.632,79.415,96.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.428 | Acc: 51.633,79.376,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.428 | Acc: 51.669,79.383,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.429 | Acc: 51.592,79.334,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.430 | Acc: 51.532,79.262,96.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.428 | Acc: 51.557,79.327,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.429 | Acc: 51.572,79.281,96.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.428 | Acc: 51.558,79.236,96.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.429 | Acc: 51.452,79.227,96.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.430 | Acc: 51.411,79.197,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.651 | Acc: 49.219,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.889 | Acc: 47.098,65.179,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.915 | Acc: 47.466,65.377,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.927 | Acc: 47.093,64.972,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.253 | Acc: 55.469,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.399 | Acc: 51.153,79.278,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.423 | Acc: 50.800,79.021,97.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.422 | Acc: 51.204,79.367,97.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.424 | Acc: 50.936,79.379,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.430 | Acc: 50.982,79.278,97.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.425 | Acc: 50.897,79.345,97.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.432 | Acc: 50.853,79.183,97.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.436 | Acc: 50.927,79.115,97.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.433 | Acc: 51.152,79.126,97.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.435 | Acc: 51.244,79.073,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.433 | Acc: 51.135,79.207,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.437 | Acc: 51.050,79.088,96.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.437 | Acc: 51.108,79.053,96.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.439 | Acc: 51.165,79.056,96.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.437 | Acc: 51.186,79.057,96.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.438 | Acc: 51.224,79.023,96.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.435 | Acc: 51.333,79.115,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.434 | Acc: 51.370,79.159,96.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.435 | Acc: 51.306,79.105,96.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.667 | Acc: 46.875,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.870 | Acc: 47.731,65.625,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 47.771,65.301,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.910 | Acc: 47.374,65.010,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.404 | Acc: 49.219,81.250,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.406 | Acc: 51.935,79.501,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.411 | Acc: 51.677,80.202,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.417 | Acc: 51.550,79.547,97.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.421 | Acc: 51.726,79.630,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.417 | Acc: 51.880,79.525,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.424 | Acc: 51.866,79.513,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.425 | Acc: 51.928,79.399,96.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.427 | Acc: 51.820,79.440,96.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.431 | Acc: 51.597,79.308,96.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.429 | Acc: 51.745,79.272,96.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.431 | Acc: 51.601,79.101,96.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.429 | Acc: 51.673,79.256,96.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.429 | Acc: 51.661,79.262,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.425 | Acc: 51.802,79.348,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.428 | Acc: 51.713,79.314,96.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.430 | Acc: 51.597,79.274,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.430 | Acc: 51.592,79.264,96.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.432 | Acc: 51.461,79.153,96.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.432 | Acc: 51.452,79.138,96.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.632 | Acc: 46.875,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.879 | Acc: 47.656,65.439,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.903 | Acc: 47.866,65.396,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.916 | Acc: 47.413,65.190,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.447 | Acc: 52.344,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.473 | Acc: 50.335,78.534,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.439 | Acc: 51.277,79.325,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.433 | Acc: 51.255,79.393,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.427 | Acc: 51.466,79.427,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 51.060,79.278,96.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.436 | Acc: 51.052,79.319,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.431 | Acc: 51.119,79.211,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.431 | Acc: 51.092,79.173,96.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.428 | Acc: 51.278,79.308,96.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.427 | Acc: 51.419,79.373,96.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.427 | Acc: 51.552,79.451,96.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.431 | Acc: 51.472,79.308,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.431 | Acc: 51.500,79.328,96.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.434 | Acc: 51.362,79.215,96.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.435 | Acc: 51.357,79.176,96.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.434 | Acc: 51.329,79.152,96.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.433 | Acc: 51.434,79.236,96.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.431 | Acc: 51.472,79.253,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.433 | Acc: 51.411,79.224,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.656 | Acc: 47.656,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.883 | Acc: 47.693,65.662,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.905 | Acc: 48.056,65.511,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.920 | Acc: 47.503,65.190,70.415,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.372 | Acc: 58.594,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.456 | Acc: 50.632,78.795,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.444 | Acc: 50.781,79.154,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.427 | Acc: 50.794,79.431,97.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.426 | Acc: 50.887,79.360,97.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.418 | Acc: 51.253,79.595,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.420 | Acc: 51.285,79.371,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.420 | Acc: 51.197,79.372,97.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.420 | Acc: 51.266,79.440,96.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.417 | Acc: 51.286,79.498,97.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.418 | Acc: 51.345,79.295,97.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.420 | Acc: 51.294,79.207,97.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.421 | Acc: 51.439,79.269,96.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.422 | Acc: 51.380,79.271,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.421 | Acc: 51.440,79.371,97.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.419 | Acc: 51.542,79.420,97.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.424 | Acc: 51.307,79.318,97.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.426 | Acc: 51.214,79.220,97.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.426 | Acc: 51.268,79.205,97.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.425 | Acc: 51.271,79.228,96.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.674 | Acc: 46.094,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.881 | Acc: 47.247,65.699,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 47.542,65.434,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.926 | Acc: 47.170,65.074,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.439 | Acc: 53.125,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.421 | Acc: 51.674,79.018,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.414 | Acc: 51.543,79.402,96.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.417 | Acc: 51.191,79.201,96.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.430 | Acc: 50.714,78.945,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.423 | Acc: 51.091,78.922,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.419 | Acc: 51.298,79.145,97.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.424 | Acc: 51.280,78.995,97.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.425 | Acc: 51.368,79.003,97.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.420 | Acc: 51.575,79.044,97.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.421 | Acc: 51.516,79.007,97.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.422 | Acc: 51.502,79.023,96.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.423 | Acc: 51.449,78.939,97.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.424 | Acc: 51.509,78.969,96.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.425 | Acc: 51.446,78.928,96.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.426 | Acc: 51.404,78.982,96.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.426 | Acc: 51.390,78.982,96.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.426 | Acc: 51.265,78.991,97.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.425 | Acc: 51.337,79.077,96.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.425 | Acc: 51.380,79.050,96.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.654 | Acc: 46.875,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.874 | Acc: 47.210,65.960,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.907 | Acc: 47.694,65.492,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.922 | Acc: 47.208,65.010,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.372 | Acc: 55.469,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 49.554,78.609,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.427 | Acc: 50.324,79.306,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.437 | Acc: 50.640,78.996,96.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.441 | Acc: 50.694,78.868,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.444 | Acc: 50.619,78.697,96.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.440 | Acc: 50.762,78.913,96.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.436 | Acc: 50.931,79.039,96.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.435 | Acc: 50.878,79.105,96.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.433 | Acc: 50.915,79.221,96.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.432 | Acc: 51.007,79.229,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.433 | Acc: 51.064,79.256,96.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.430 | Acc: 51.225,79.425,96.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.429 | Acc: 51.125,79.400,96.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.428 | Acc: 51.154,79.412,96.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.429 | Acc: 51.256,79.353,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.428 | Acc: 51.246,79.305,96.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.431 | Acc: 51.278,79.254,96.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.430 | Acc: 51.264,79.255,96.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.429 | Acc: 51.296,79.298,96.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.627 | Acc: 46.094,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.870 | Acc: 47.247,65.476,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.906 | Acc: 47.542,65.206,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.922 | Acc: 47.221,64.703,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.545 | Acc: 51.562,72.656,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.414 | Acc: 52.195,79.092,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.406 | Acc: 51.905,79.649,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.414 | Acc: 52.036,79.431,97.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.411 | Acc: 51.765,79.360,97.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.412 | Acc: 51.617,79.525,97.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.408 | Acc: 51.601,79.655,97.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.416 | Acc: 51.479,79.438,97.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.421 | Acc: 51.373,79.396,97.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.423 | Acc: 51.364,79.424,97.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.425 | Acc: 51.337,79.361,97.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.425 | Acc: 51.223,79.405,97.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.423 | Acc: 51.336,79.470,97.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.422 | Acc: 51.332,79.466,97.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.422 | Acc: 51.298,79.434,97.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.423 | Acc: 51.267,79.431,97.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.423 | Acc: 51.312,79.400,97.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.423 | Acc: 51.288,79.452,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.422 | Acc: 51.389,79.456,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.423 | Acc: 51.411,79.374,96.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.680 | Acc: 47.656,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.888 | Acc: 47.433,65.588,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.915 | Acc: 47.904,65.434,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.934 | Acc: 47.336,65.113,70.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.414 | Acc: 50.781,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.417 | Acc: 51.004,79.836,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.447 | Acc: 50.857,79.040,97.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.448 | Acc: 50.961,79.060,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.439 | Acc: 51.167,78.858,97.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 51.354,78.945,97.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.432 | Acc: 51.246,79.074,96.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.428 | Acc: 51.418,79.189,96.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.430 | Acc: 51.514,79.193,96.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.427 | Acc: 51.619,79.342,96.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.423 | Acc: 51.699,79.423,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.423 | Acc: 51.693,79.295,96.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.425 | Acc: 51.507,79.286,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.426 | Acc: 51.392,79.340,96.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.425 | Acc: 51.435,79.312,96.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.423 | Acc: 51.487,79.345,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.424 | Acc: 51.375,79.378,96.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.423 | Acc: 51.430,79.385,96.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.424 | Acc: 51.435,79.367,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.423 | Acc: 51.446,79.421,96.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.670 | Acc: 45.312,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.880 | Acc: 47.545,65.253,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.914 | Acc: 48.056,64.977,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.928 | Acc: 47.490,64.728,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.430 | Acc: 54.688,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.426 | Acc: 51.823,78.423,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.434 | Acc: 50.915,78.811,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.432 | Acc: 51.473,79.047,97.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.426 | Acc: 51.630,79.090,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.424 | Acc: 51.423,79.278,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.425 | Acc: 51.104,79.068,96.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.422 | Acc: 51.230,79.255,96.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.419 | Acc: 51.422,79.319,96.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.415 | Acc: 51.545,79.385,97.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.412 | Acc: 51.613,79.571,97.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.412 | Acc: 51.619,79.532,97.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.411 | Acc: 51.595,79.467,97.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.413 | Acc: 51.482,79.415,97.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.414 | Acc: 51.529,79.473,97.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.416 | Acc: 51.417,79.425,97.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.417 | Acc: 51.414,79.437,97.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.419 | Acc: 51.315,79.364,97.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.421 | Acc: 51.238,79.322,97.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.421 | Acc: 51.290,79.335,97.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.654 | Acc: 46.094,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.877 | Acc: 47.024,65.290,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 47.542,65.263,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.928 | Acc: 47.323,65.061,70.620,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.362 | Acc: 55.469,81.250,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.387 | Acc: 52.083,80.506,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.385 | Acc: 53.258,80.393,97.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.399 | Acc: 52.638,79.854,97.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.405 | Acc: 52.527,79.765,97.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.411 | Acc: 52.321,79.564,97.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.409 | Acc: 52.228,79.655,96.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.412 | Acc: 52.111,79.588,96.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.411 | Acc: 52.091,79.518,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.415 | Acc: 51.977,79.467,96.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.417 | Acc: 51.819,79.474,96.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.416 | Acc: 51.739,79.451,96.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.419 | Acc: 51.666,79.363,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.420 | Acc: 51.691,79.340,96.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.418 | Acc: 51.860,79.409,97.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.419 | Acc: 51.892,79.296,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.420 | Acc: 51.945,79.264,96.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.421 | Acc: 51.886,79.220,96.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.422 | Acc: 51.792,79.188,96.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.422 | Acc: 51.755,79.249,96.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.637 | Acc: 45.312,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.883 | Acc: 47.470,65.402,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.913 | Acc: 47.866,65.034,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.927 | Acc: 47.579,64.741,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.277 | Acc: 54.688,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.435 | Acc: 51.786,78.423,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.422 | Acc: 51.467,79.192,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.434 | Acc: 51.063,79.047,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.431 | Acc: 50.955,79.379,96.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 50.835,79.463,96.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.435 | Acc: 50.872,79.307,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.432 | Acc: 51.125,79.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.429 | Acc: 51.087,79.270,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.430 | Acc: 51.131,79.200,96.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.433 | Acc: 51.092,79.116,96.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.433 | Acc: 51.160,79.168,96.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.432 | Acc: 51.245,79.114,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.430 | Acc: 51.254,79.197,96.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.427 | Acc: 51.321,79.148,96.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.428 | Acc: 51.324,79.101,96.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.428 | Acc: 51.322,79.135,96.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.426 | Acc: 51.304,79.124,96.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.427 | Acc: 51.264,79.112,96.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.425 | Acc: 51.321,79.204,96.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.659 | Acc: 46.875,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.888 | Acc: 47.470,65.141,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.924 | Acc: 47.790,65.015,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 47.541,64.831,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.521 | Acc: 43.750,75.781,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.397 | Acc: 51.153,80.283,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.397 | Acc: 52.287,80.316,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.401 | Acc: 51.793,80.149,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.408 | Acc: 51.707,80.112,96.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.416 | Acc: 51.330,79.788,96.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.417 | Acc: 51.356,79.520,96.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.414 | Acc: 51.202,79.555,96.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.418 | Acc: 51.111,79.348,96.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.415 | Acc: 51.247,79.312,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.414 | Acc: 51.306,79.338,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.416 | Acc: 51.357,79.189,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.417 | Acc: 51.264,79.221,96.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.421 | Acc: 51.245,79.158,96.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.422 | Acc: 51.207,79.145,96.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.421 | Acc: 51.243,79.127,96.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.420 | Acc: 51.234,79.162,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.422 | Acc: 51.198,79.135,96.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.420 | Acc: 51.279,79.201,96.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.422 | Acc: 51.259,79.199,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.622 | Acc: 45.312,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.882 | Acc: 47.135,65.625,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.915 | Acc: 47.656,65.625,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.933 | Acc: 47.400,65.266,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.370 | Acc: 50.781,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.430 | Acc: 50.298,79.167,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.430 | Acc: 50.438,79.497,97.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.419 | Acc: 51.050,79.662,96.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.420 | Acc: 51.264,79.504,97.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.417 | Acc: 51.338,79.386,97.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.415 | Acc: 51.556,79.384,97.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.414 | Acc: 51.502,79.521,97.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.420 | Acc: 51.262,79.387,97.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.414 | Acc: 51.519,79.403,97.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.420 | Acc: 51.493,79.248,97.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.420 | Acc: 51.502,79.309,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.415 | Acc: 51.605,79.480,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.415 | Acc: 51.634,79.445,97.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.416 | Acc: 51.571,79.415,97.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.415 | Acc: 51.609,79.353,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.414 | Acc: 51.618,79.322,97.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.413 | Acc: 51.741,79.316,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.416 | Acc: 51.632,79.285,97.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.417 | Acc: 51.645,79.236,97.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.642 | Acc: 46.094,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.878 | Acc: 47.507,65.551,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.906 | Acc: 47.771,65.434,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.931 | Acc: 47.374,65.138,70.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.510 | Acc: 50.000,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.372 | Acc: 51.451,80.134,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.390 | Acc: 52.248,80.164,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.402 | Acc: 51.985,79.816,97.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.405 | Acc: 51.698,79.861,97.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.408 | Acc: 51.849,79.649,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.415 | Acc: 51.801,79.545,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.416 | Acc: 51.917,79.549,96.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.411 | Acc: 52.101,79.532,96.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.411 | Acc: 52.055,79.390,96.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.410 | Acc: 51.932,79.458,97.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.406 | Acc: 52.061,79.475,97.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.407 | Acc: 52.068,79.451,97.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.406 | Acc: 52.077,79.445,97.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.409 | Acc: 52.088,79.382,97.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.410 | Acc: 51.957,79.410,97.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.412 | Acc: 51.935,79.349,96.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.412 | Acc: 51.782,79.392,96.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.413 | Acc: 51.738,79.324,96.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.415 | Acc: 51.624,79.275,96.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.677 | Acc: 46.094,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.875 | Acc: 47.210,64.918,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 47.656,65.034,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 47.426,64.767,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.274 | Acc: 51.562,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.424 | Acc: 50.484,79.911,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.416 | Acc: 51.029,80.373,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.403 | Acc: 51.460,80.379,97.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.405 | Acc: 51.312,80.199,97.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.405 | Acc: 51.400,79.881,97.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.407 | Acc: 51.491,79.888,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.404 | Acc: 51.518,79.859,97.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.412 | Acc: 51.228,79.673,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.414 | Acc: 51.174,79.705,97.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.411 | Acc: 51.337,79.684,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.410 | Acc: 51.375,79.712,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.413 | Acc: 51.277,79.668,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.411 | Acc: 51.437,79.619,97.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.410 | Acc: 51.376,79.618,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.411 | Acc: 51.378,79.586,97.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.414 | Acc: 51.353,79.503,97.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.414 | Acc: 51.345,79.442,97.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.414 | Acc: 51.305,79.430,97.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.415 | Acc: 51.323,79.394,97.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.633 | Acc: 46.094,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.879 | Acc: 47.917,65.774,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.913 | Acc: 48.056,65.320,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.932 | Acc: 47.605,64.985,70.850,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.695 | Acc: 47.656,75.000,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.425 | Acc: 50.186,79.353,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.414 | Acc: 50.667,79.459,97.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.416 | Acc: 51.114,79.252,97.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.427 | Acc: 51.514,78.964,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.428 | Acc: 51.764,78.999,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.427 | Acc: 51.466,79.068,96.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.425 | Acc: 51.374,79.122,97.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.425 | Acc: 51.242,79.115,97.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.421 | Acc: 51.355,79.062,97.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.419 | Acc: 51.298,79.209,97.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.417 | Acc: 51.541,79.231,97.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.419 | Acc: 51.452,79.123,97.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.421 | Acc: 51.329,79.161,97.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.421 | Acc: 51.365,79.098,97.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.420 | Acc: 51.492,79.116,97.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.418 | Acc: 51.489,79.172,97.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.419 | Acc: 51.402,79.165,97.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.418 | Acc: 51.428,79.162,97.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.417 | Acc: 51.526,79.220,97.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.624 | Acc: 44.531,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.896 | Acc: 47.321,65.216,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.934 | Acc: 47.904,65.168,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.951 | Acc: 47.567,64.780,70.569,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.393 | Acc: 49.219,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 50.818,78.795,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.446 | Acc: 50.972,78.544,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.432 | Acc: 51.178,78.893,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.422 | Acc: 51.485,79.099,97.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.423 | Acc: 51.300,79.324,97.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.418 | Acc: 51.388,79.203,97.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.417 | Acc: 51.291,79.194,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.420 | Acc: 51.364,79.163,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.420 | Acc: 51.403,79.100,97.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.420 | Acc: 51.360,79.058,97.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.419 | Acc: 51.478,79.129,97.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.415 | Acc: 51.543,79.088,97.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.416 | Acc: 51.437,79.164,97.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.414 | Acc: 51.554,79.176,97.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.417 | Acc: 51.453,79.091,97.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.416 | Acc: 51.380,79.077,97.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.418 | Acc: 51.336,79.083,97.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.417 | Acc: 51.435,79.136,97.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.418 | Acc: 51.331,79.142,97.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.678 | Acc: 47.656,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.911 | Acc: 47.210,65.699,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.937 | Acc: 47.713,65.282,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.949 | Acc: 47.374,64.895,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.227 | Acc: 56.250,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.395 | Acc: 52.418,79.948,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.418 | Acc: 52.344,79.383,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.411 | Acc: 52.049,79.483,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.419 | Acc: 52.054,79.196,96.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.423 | Acc: 51.825,79.100,97.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.422 | Acc: 51.666,78.951,97.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.425 | Acc: 51.402,78.834,97.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.429 | Acc: 51.281,78.969,97.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.425 | Acc: 51.325,79.113,97.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.421 | Acc: 51.298,79.237,97.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.421 | Acc: 51.202,79.281,97.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.420 | Acc: 51.242,79.250,97.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.419 | Acc: 51.371,79.265,97.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.419 | Acc: 51.343,79.209,97.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.419 | Acc: 51.319,79.174,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.418 | Acc: 51.373,79.257,97.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.416 | Acc: 51.434,79.312,97.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.414 | Acc: 51.467,79.330,97.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.415 | Acc: 51.435,79.304,97.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.684 | Acc: 46.094,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.895 | Acc: 47.507,65.476,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.919 | Acc: 47.752,65.225,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 47.387,64.844,70.620,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.295 | Acc: 52.344,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.391 | Acc: 51.972,80.878,97.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.408 | Acc: 51.524,80.278,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.416 | Acc: 51.037,79.905,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.410 | Acc: 51.109,79.890,97.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.408 | Acc: 51.122,80.012,97.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.407 | Acc: 51.001,80.017,97.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.410 | Acc: 51.258,79.942,97.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.406 | Acc: 51.300,80.027,97.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.408 | Acc: 51.282,79.990,97.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.411 | Acc: 51.267,79.827,97.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.409 | Acc: 51.403,79.786,97.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.410 | Acc: 51.345,79.629,97.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.407 | Acc: 51.455,79.696,97.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.410 | Acc: 51.318,79.593,97.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.411 | Acc: 51.350,79.529,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.412 | Acc: 51.348,79.468,97.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.412 | Acc: 51.455,79.371,97.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.412 | Acc: 51.418,79.391,97.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.410 | Acc: 51.460,79.413,97.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.738 | Acc: 47.656,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.893 | Acc: 47.545,65.141,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 47.752,65.206,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.945 | Acc: 47.234,64.946,70.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.476 | Acc: 50.000,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.403 | Acc: 51.711,80.506,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.414 | Acc: 51.848,79.707,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.404 | Acc: 52.203,80.136,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.411 | Acc: 52.093,79.765,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.413 | Acc: 51.764,79.834,96.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.413 | Acc: 51.866,79.836,97.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.415 | Acc: 51.923,79.593,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.413 | Acc: 51.810,79.576,97.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.413 | Acc: 51.826,79.584,97.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.413 | Acc: 51.718,79.583,97.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.415 | Acc: 51.732,79.507,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.414 | Acc: 51.770,79.487,97.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.411 | Acc: 51.820,79.592,97.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.411 | Acc: 51.785,79.568,97.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.412 | Acc: 51.692,79.521,97.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.411 | Acc: 51.672,79.510,97.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.411 | Acc: 51.645,79.465,97.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.412 | Acc: 51.619,79.488,97.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.413 | Acc: 51.552,79.482,97.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.677 | Acc: 46.094,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.889 | Acc: 47.061,65.588,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.919 | Acc: 47.580,65.530,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 47.259,64.908,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.433 | Acc: 49.219,75.781,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.401 | Acc: 52.827,78.981,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.384 | Acc: 52.420,79.992,97.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.398 | Acc: 51.614,79.470,97.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.409 | Acc: 51.109,79.389,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.411 | Acc: 51.269,79.432,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.410 | Acc: 51.498,79.307,97.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.405 | Acc: 51.701,79.405,97.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.401 | Acc: 51.747,79.590,97.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.402 | Acc: 51.800,79.627,97.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.400 | Acc: 51.940,79.695,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.403 | Acc: 51.838,79.599,97.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.404 | Acc: 51.754,79.597,97.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.407 | Acc: 51.652,79.523,97.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.407 | Acc: 51.643,79.560,97.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.408 | Acc: 51.640,79.516,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.409 | Acc: 51.684,79.476,97.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.409 | Acc: 51.750,79.539,97.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.409 | Acc: 51.664,79.568,97.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.409 | Acc: 51.626,79.573,97.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.716 | Acc: 46.094,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.902 | Acc: 47.545,65.662,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.936 | Acc: 47.847,65.396,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.948 | Acc: 47.503,65.010,70.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.362 | Acc: 51.562,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.403 | Acc: 52.158,78.460,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.402 | Acc: 51.886,79.059,97.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.416 | Acc: 51.050,79.034,97.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.413 | Acc: 51.283,79.543,97.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.417 | Acc: 50.835,79.177,97.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.422 | Acc: 50.775,79.113,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.424 | Acc: 50.947,79.161,96.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.421 | Acc: 51.014,79.309,96.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.424 | Acc: 51.019,79.286,96.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.424 | Acc: 51.014,79.310,96.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.423 | Acc: 51.043,79.242,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.421 | Acc: 51.148,79.214,96.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.419 | Acc: 51.200,79.376,97.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.416 | Acc: 51.354,79.387,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.417 | Acc: 51.373,79.347,97.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.418 | Acc: 51.370,79.320,97.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.415 | Acc: 51.471,79.378,97.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.416 | Acc: 51.472,79.393,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.414 | Acc: 51.542,79.417,97.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.709 | Acc: 45.312,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.888 | Acc: 47.433,65.699,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.916 | Acc: 47.866,65.511,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.931 | Acc: 47.631,65.164,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.463 | Acc: 54.688,75.781,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.422 | Acc: 51.339,78.460,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.417 | Acc: 51.582,79.192,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.409 | Acc: 51.703,79.278,97.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.411 | Acc: 51.842,79.446,97.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.418 | Acc: 51.663,79.216,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.413 | Acc: 51.659,79.236,97.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.413 | Acc: 51.762,79.316,97.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.411 | Acc: 51.757,79.411,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.411 | Acc: 51.800,79.329,97.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.407 | Acc: 51.807,79.513,97.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.408 | Acc: 51.828,79.440,97.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.410 | Acc: 51.770,79.357,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.410 | Acc: 51.805,79.352,97.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.412 | Acc: 51.749,79.359,97.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.412 | Acc: 51.752,79.350,97.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.413 | Acc: 51.721,79.313,97.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.412 | Acc: 51.771,79.303,97.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.413 | Acc: 51.690,79.298,97.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.413 | Acc: 51.628,79.361,97.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.734 | Acc: 45.312,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.904 | Acc: 47.545,65.030,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.930 | Acc: 47.809,65.111,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.945 | Acc: 47.400,64.664,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.412 | Acc: 54.688,78.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.340 | Acc: 54.092,81.287,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.381 | Acc: 52.591,80.564,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.388 | Acc: 52.139,79.905,97.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.392 | Acc: 51.881,79.919,97.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.395 | Acc: 51.887,79.865,97.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.393 | Acc: 51.898,79.952,97.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.396 | Acc: 51.917,79.809,97.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.394 | Acc: 51.859,79.726,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.397 | Acc: 51.860,79.614,97.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.400 | Acc: 51.718,79.594,97.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.400 | Acc: 51.778,79.627,97.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.402 | Acc: 51.725,79.545,97.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.402 | Acc: 51.784,79.532,97.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.402 | Acc: 51.774,79.576,97.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.404 | Acc: 51.812,79.472,97.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.405 | Acc: 51.777,79.403,97.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.405 | Acc: 51.723,79.447,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.404 | Acc: 51.703,79.475,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.404 | Acc: 51.671,79.501,97.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.720 | Acc: 46.094,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.911 | Acc: 47.582,65.439,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.928 | Acc: 47.847,65.358,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.948 | Acc: 47.387,65.010,70.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.568 | Acc: 42.188,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.397 | Acc: 50.744,80.208,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.394 | Acc: 51.658,79.821,97.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.386 | Acc: 52.126,80.341,97.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.391 | Acc: 52.141,80.073,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.396 | Acc: 52.058,79.981,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.397 | Acc: 52.079,79.901,97.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.395 | Acc: 52.233,79.859,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.394 | Acc: 52.028,79.867,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.398 | Acc: 51.873,79.765,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.399 | Acc: 51.815,79.656,97.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.398 | Acc: 51.828,79.666,97.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.397 | Acc: 51.955,79.720,97.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.399 | Acc: 51.856,79.744,97.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.400 | Acc: 51.774,79.643,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.399 | Acc: 51.799,79.662,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.400 | Acc: 51.745,79.685,97.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.400 | Acc: 51.670,79.665,97.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.401 | Acc: 51.660,79.629,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.402 | Acc: 51.729,79.642,97.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.720 | Acc: 45.312,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.908 | Acc: 47.470,64.993,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.931 | Acc: 47.637,65.091,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.948 | Acc: 47.323,64.818,70.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.344 | Acc: 53.125,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.393 | Acc: 53.199,79.576,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.407 | Acc: 51.944,79.516,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.406 | Acc: 51.985,79.470,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.408 | Acc: 51.775,79.253,97.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.405 | Acc: 51.702,79.370,97.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.405 | Acc: 51.705,79.429,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.401 | Acc: 51.817,79.549,97.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.402 | Acc: 51.752,79.440,97.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.402 | Acc: 51.709,79.593,97.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.401 | Acc: 51.811,79.629,97.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.403 | Acc: 51.711,79.567,97.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.406 | Acc: 51.550,79.438,97.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.406 | Acc: 51.494,79.421,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.405 | Acc: 51.613,79.482,97.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.406 | Acc: 51.648,79.493,97.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.400 | Acc: 51.723,79.644,97.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.400 | Acc: 51.700,79.683,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.402 | Acc: 51.653,79.612,97.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.402 | Acc: 51.620,79.583,97.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.741 | Acc: 47.656,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.905 | Acc: 47.805,64.844,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.932 | Acc: 47.790,65.187,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.952 | Acc: 47.387,64.805,70.415,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.412 | Acc: 57.031,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.388 | Acc: 52.307,79.278,97.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.374 | Acc: 52.954,80.088,97.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.389 | Acc: 52.344,80.110,97.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.393 | Acc: 52.315,80.266,97.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.392 | Acc: 52.243,79.981,97.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.402 | Acc: 51.840,79.901,97.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.404 | Acc: 51.817,79.787,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.406 | Acc: 51.752,79.571,97.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.405 | Acc: 51.834,79.683,97.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.403 | Acc: 51.803,79.754,97.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.406 | Acc: 51.842,79.744,97.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.404 | Acc: 51.974,79.756,97.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.402 | Acc: 51.922,79.735,97.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.404 | Acc: 51.885,79.660,97.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.406 | Acc: 51.739,79.591,97.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.405 | Acc: 51.723,79.629,97.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.407 | Acc: 51.606,79.605,97.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.407 | Acc: 51.554,79.618,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.407 | Acc: 51.521,79.659,97.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.711 | Acc: 46.875,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.897 | Acc: 47.545,65.699,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.922 | Acc: 47.923,65.511,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.938 | Acc: 47.605,65.177,70.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.251 | Acc: 54.688,81.250,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.432 | Acc: 50.409,78.981,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.424 | Acc: 50.877,78.639,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.419 | Acc: 50.807,78.842,97.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.423 | Acc: 50.646,79.012,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.420 | Acc: 51.013,79.262,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.406 | Acc: 51.362,79.707,97.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.400 | Acc: 51.396,79.893,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.402 | Acc: 51.407,79.799,97.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.405 | Acc: 51.351,79.813,97.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.403 | Acc: 51.454,79.722,97.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.405 | Acc: 51.403,79.695,97.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.406 | Acc: 51.371,79.600,97.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.406 | Acc: 51.374,79.619,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.408 | Acc: 51.293,79.618,97.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.407 | Acc: 51.433,79.633,97.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.404 | Acc: 51.526,79.705,97.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.404 | Acc: 51.501,79.731,97.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.404 | Acc: 51.506,79.657,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.404 | Acc: 51.548,79.646,97.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.710 | Acc: 47.656,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.897 | Acc: 47.545,65.290,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 47.885,65.053,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.946 | Acc: 47.541,64.844,70.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.465 | Acc: 50.781,77.344,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.398 | Acc: 51.786,79.539,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.411 | Acc: 51.582,79.021,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.424 | Acc: 51.639,78.919,97.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.428 | Acc: 51.206,78.810,97.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.428 | Acc: 50.866,78.914,97.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.421 | Acc: 51.072,79.229,97.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.414 | Acc: 51.341,79.327,97.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.411 | Acc: 51.364,79.367,97.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.410 | Acc: 51.463,79.355,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.408 | Acc: 51.438,79.435,97.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.407 | Acc: 51.485,79.412,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.405 | Acc: 51.423,79.529,97.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.403 | Acc: 51.586,79.517,97.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.401 | Acc: 51.638,79.590,97.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.400 | Acc: 51.760,79.623,97.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.398 | Acc: 51.801,79.673,97.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.397 | Acc: 51.776,79.651,97.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.399 | Acc: 51.710,79.638,97.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.399 | Acc: 51.731,79.642,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.721 | Acc: 47.656,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.922 | Acc: 47.693,65.141,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.934 | Acc: 47.904,65.320,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.953 | Acc: 47.605,65.074,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.280 | Acc: 57.812,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.378 | Acc: 52.865,80.804,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.396 | Acc: 51.467,80.526,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.394 | Acc: 51.960,80.443,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.410 | Acc: 51.389,79.900,96.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.408 | Acc: 51.470,79.981,96.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.414 | Acc: 51.311,79.739,97.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.415 | Acc: 51.363,79.660,97.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.412 | Acc: 51.664,79.702,97.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.412 | Acc: 51.575,79.618,97.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.413 | Acc: 51.555,79.489,97.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.409 | Acc: 51.661,79.680,97.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.407 | Acc: 51.657,79.642,97.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.406 | Acc: 51.661,79.589,97.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.404 | Acc: 51.710,79.649,97.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.406 | Acc: 51.713,79.589,97.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.405 | Acc: 51.740,79.576,97.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.403 | Acc: 51.727,79.607,97.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.404 | Acc: 51.742,79.638,97.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.403 | Acc: 51.737,79.618,97.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.715 | Acc: 47.656,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.907 | Acc: 47.321,65.104,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 47.752,65.111,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.945 | Acc: 47.362,64.741,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.455 | Acc: 53.906,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.444 | Acc: 50.260,78.385,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.433 | Acc: 51.048,79.173,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.431 | Acc: 50.551,79.162,97.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.425 | Acc: 50.781,79.282,97.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.419 | Acc: 50.951,79.455,97.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.421 | Acc: 51.020,79.416,97.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.418 | Acc: 51.097,79.466,97.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.413 | Acc: 51.228,79.445,97.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.411 | Acc: 51.204,79.467,97.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.410 | Acc: 51.197,79.431,97.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.407 | Acc: 51.269,79.592,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.405 | Acc: 51.420,79.649,97.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.404 | Acc: 51.425,79.643,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.403 | Acc: 51.499,79.704,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.403 | Acc: 51.518,79.706,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.403 | Acc: 51.570,79.756,97.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.404 | Acc: 51.512,79.731,97.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.404 | Acc: 51.517,79.716,97.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.403 | Acc: 51.575,79.745,97.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.724 | Acc: 45.312,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.905 | Acc: 47.247,65.030,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.932 | Acc: 47.809,65.206,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.950 | Acc: 47.413,64.844,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.456 | Acc: 49.219,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.395 | Acc: 52.121,80.543,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.386 | Acc: 52.420,80.297,97.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.388 | Acc: 52.792,80.225,97.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.390 | Acc: 52.334,80.228,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.387 | Acc: 52.375,80.322,97.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.394 | Acc: 51.924,80.107,97.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.390 | Acc: 52.211,80.070,97.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.393 | Acc: 51.965,80.056,97.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.395 | Acc: 51.791,80.028,97.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.401 | Acc: 51.718,79.870,97.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.402 | Acc: 51.760,79.794,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.405 | Acc: 51.520,79.717,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.405 | Acc: 51.533,79.726,97.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.404 | Acc: 51.674,79.643,97.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.402 | Acc: 51.697,79.623,97.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.400 | Acc: 51.670,79.632,97.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.400 | Acc: 51.689,79.715,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.400 | Acc: 51.604,79.761,97.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.400 | Acc: 51.593,79.726,97.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.692 | Acc: 45.312,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.901 | Acc: 47.507,65.365,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 47.713,65.225,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.941 | Acc: 47.374,64.946,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.448 | Acc: 43.750,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.390 | Acc: 52.269,79.911,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.412 | Acc: 51.105,79.707,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.408 | Acc: 51.101,79.688,97.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.406 | Acc: 50.945,79.784,97.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.396 | Acc: 51.385,79.788,97.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.396 | Acc: 51.466,79.817,97.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.394 | Acc: 51.441,79.826,97.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.395 | Acc: 51.529,79.731,97.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.398 | Acc: 51.377,79.657,97.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.400 | Acc: 51.376,79.602,97.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.399 | Acc: 51.566,79.666,97.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.398 | Acc: 51.614,79.678,97.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 51.586,79.661,97.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.404 | Acc: 51.501,79.523,97.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.402 | Acc: 51.521,79.586,97.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.402 | Acc: 51.470,79.678,97.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.400 | Acc: 51.549,79.722,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.398 | Acc: 51.630,79.735,97.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.397 | Acc: 51.581,79.782,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.683 | Acc: 46.875,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.900 | Acc: 47.359,65.327,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.927 | Acc: 47.923,65.244,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.943 | Acc: 47.464,64.933,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.489 | Acc: 45.312,78.125,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.398 | Acc: 51.786,80.320,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.388 | Acc: 51.391,80.011,97.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.397 | Acc: 51.434,79.483,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.404 | Acc: 51.804,79.369,97.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.407 | Acc: 51.609,79.386,97.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.408 | Acc: 51.582,79.403,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.413 | Acc: 51.319,79.366,96.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.413 | Acc: 51.291,79.270,96.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.409 | Acc: 51.472,79.433,96.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.404 | Acc: 51.570,79.505,97.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.406 | Acc: 51.495,79.451,97.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.402 | Acc: 51.676,79.564,97.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.402 | Acc: 51.577,79.613,97.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.403 | Acc: 51.638,79.635,97.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.404 | Acc: 51.568,79.586,97.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.402 | Acc: 51.572,79.602,97.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.403 | Acc: 51.526,79.637,97.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.402 | Acc: 51.508,79.655,97.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.401 | Acc: 51.495,79.663,97.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.711 | Acc: 47.656,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.890 | Acc: 47.656,65.365,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.917 | Acc: 47.961,65.187,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.937 | Acc: 47.618,64.882,70.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.233 | Acc: 54.688,86.719,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.437 | Acc: 50.409,79.315,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.422 | Acc: 50.743,79.364,97.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.411 | Acc: 51.345,79.713,97.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.404 | Acc: 51.408,79.514,97.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.401 | Acc: 51.539,79.347,97.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.397 | Acc: 51.672,79.591,97.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.396 | Acc: 51.729,79.671,97.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.395 | Acc: 51.655,79.867,97.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.399 | Acc: 51.688,79.778,97.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.399 | Acc: 51.570,79.820,97.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.397 | Acc: 51.651,79.786,97.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.400 | Acc: 51.634,79.798,97.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.398 | Acc: 51.646,79.903,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.401 | Acc: 51.601,79.721,97.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.400 | Acc: 51.677,79.786,97.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.400 | Acc: 51.699,79.761,97.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.399 | Acc: 51.746,79.726,97.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.398 | Acc: 51.764,79.726,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.398 | Acc: 51.694,79.718,97.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.635 | Acc: 46.875,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.885 | Acc: 47.582,65.402,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.916 | Acc: 48.018,65.111,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.934 | Acc: 47.579,64.805,70.415,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.463 | Acc: 49.219,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.406 | Acc: 52.418,79.427,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.391 | Acc: 52.515,80.107,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.389 | Acc: 52.254,80.161,97.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.393 | Acc: 52.141,80.102,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.395 | Acc: 51.895,80.128,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.397 | Acc: 51.653,79.901,97.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.401 | Acc: 51.424,79.782,97.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.402 | Acc: 51.359,79.736,97.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.402 | Acc: 51.459,79.692,97.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.397 | Acc: 51.570,79.812,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.399 | Acc: 51.587,79.783,97.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.398 | Acc: 51.624,79.840,97.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.399 | Acc: 51.604,79.786,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.399 | Acc: 51.651,79.788,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.400 | Acc: 51.601,79.804,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.402 | Acc: 51.521,79.714,97.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.403 | Acc: 51.613,79.667,97.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.403 | Acc: 51.677,79.584,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.402 | Acc: 51.776,79.554,97.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.708 | Acc: 46.094,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.900 | Acc: 47.173,65.327,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 47.599,65.168,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.945 | Acc: 47.323,64.882,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.491 | Acc: 43.750,77.344,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.359 | Acc: 52.232,80.729,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.403 | Acc: 50.667,79.783,97.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.410 | Acc: 50.961,79.214,97.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.404 | Acc: 51.196,79.311,97.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.410 | Acc: 51.075,79.347,97.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.413 | Acc: 51.007,79.339,97.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.409 | Acc: 51.285,79.532,97.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.401 | Acc: 51.504,79.620,97.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.402 | Acc: 51.468,79.623,97.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.401 | Acc: 51.528,79.684,97.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.401 | Acc: 51.534,79.638,97.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.398 | Acc: 51.653,79.675,97.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.399 | Acc: 51.571,79.625,97.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.397 | Acc: 51.704,79.660,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.400 | Acc: 51.601,79.695,97.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.402 | Acc: 51.570,79.663,97.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.402 | Acc: 51.599,79.662,97.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.401 | Acc: 51.675,79.696,97.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.401 | Acc: 51.624,79.735,97.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.716 | Acc: 45.312,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.906 | Acc: 47.805,65.551,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.934 | Acc: 48.075,65.244,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.947 | Acc: 47.695,64.908,70.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.442 | Acc: 52.344,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 49.256,79.501,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.425 | Acc: 49.886,79.535,97.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.415 | Acc: 50.231,79.521,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.412 | Acc: 50.309,79.446,97.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.411 | Acc: 50.240,79.718,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.412 | Acc: 50.433,79.655,97.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.408 | Acc: 50.742,79.798,97.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.404 | Acc: 50.927,79.950,97.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.404 | Acc: 50.941,79.942,97.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.404 | Acc: 50.925,79.921,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.405 | Acc: 50.958,79.854,97.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.402 | Acc: 51.157,79.827,97.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 51.278,79.813,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.398 | Acc: 51.435,79.838,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.396 | Acc: 51.529,79.830,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.396 | Acc: 51.582,79.782,97.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.396 | Acc: 51.585,79.742,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.398 | Acc: 51.528,79.700,97.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.401 | Acc: 51.521,79.620,97.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.720 | Acc: 46.875,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.897 | Acc: 47.433,65.290,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.923 | Acc: 47.942,65.225,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.940 | Acc: 47.605,64.831,70.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.481 | Acc: 55.469,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.438 | Acc: 50.595,78.720,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.413 | Acc: 51.639,79.497,97.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.419 | Acc: 51.217,79.265,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.414 | Acc: 51.379,79.495,97.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.414 | Acc: 51.261,79.425,97.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.417 | Acc: 51.369,79.190,97.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.407 | Acc: 51.646,79.311,97.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.406 | Acc: 51.572,79.358,97.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.402 | Acc: 51.679,79.614,97.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.400 | Acc: 51.621,79.703,97.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.399 | Acc: 51.587,79.769,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.398 | Acc: 51.566,79.827,97.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 51.527,79.798,97.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.401 | Acc: 51.560,79.815,97.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.399 | Acc: 51.578,79.859,97.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.398 | Acc: 51.689,79.792,97.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.396 | Acc: 51.723,79.832,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.397 | Acc: 51.682,79.820,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.398 | Acc: 51.622,79.798,97.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.684 | Acc: 47.656,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.902 | Acc: 47.507,65.625,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.928 | Acc: 47.828,65.263,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.942 | Acc: 47.477,64.946,70.569,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.461 | Acc: 47.656,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.409 | Acc: 49.702,79.129,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.423 | Acc: 50.057,79.173,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.416 | Acc: 50.269,79.623,97.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.405 | Acc: 50.781,79.649,97.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.400 | Acc: 51.075,79.726,97.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.397 | Acc: 51.033,79.739,97.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.393 | Acc: 51.119,79.931,97.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.394 | Acc: 51.189,79.920,97.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.393 | Acc: 51.247,79.916,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.397 | Acc: 51.279,79.808,97.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.401 | Acc: 51.223,79.794,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.398 | Acc: 51.271,79.960,97.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.397 | Acc: 51.290,79.939,97.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.397 | Acc: 51.410,79.966,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.396 | Acc: 51.477,79.970,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.395 | Acc: 51.499,79.938,97.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.394 | Acc: 51.521,79.907,97.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.397 | Acc: 51.446,79.807,97.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.396 | Acc: 51.503,79.815,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.737 | Acc: 46.094,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.904 | Acc: 47.656,65.030,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.931 | Acc: 47.809,65.072,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.949 | Acc: 47.400,64.767,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.607 | Acc: 46.875,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.416 | Acc: 51.190,79.427,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.399 | Acc: 51.677,79.478,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.397 | Acc: 51.332,79.393,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.401 | Acc: 51.264,79.446,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.395 | Acc: 51.300,79.664,97.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.396 | Acc: 51.382,79.746,97.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.396 | Acc: 51.574,79.732,97.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.394 | Acc: 51.621,79.852,97.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.395 | Acc: 51.614,79.718,97.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.394 | Acc: 51.691,79.672,97.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.394 | Acc: 51.739,79.726,97.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.395 | Acc: 51.676,79.791,97.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.397 | Acc: 51.521,79.777,97.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.396 | Acc: 51.557,79.774,97.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.395 | Acc: 51.653,79.794,97.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.396 | Acc: 51.706,79.741,97.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.396 | Acc: 51.760,79.763,97.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.395 | Acc: 51.757,79.768,97.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.395 | Acc: 51.724,79.772,97.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.737 | Acc: 46.094,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.904 | Acc: 47.396,65.067,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 47.771,65.111,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.944 | Acc: 47.387,64.882,70.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.268 | Acc: 54.688,76.562,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.385 | Acc: 51.004,79.613,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.377 | Acc: 52.001,80.202,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.387 | Acc: 52.062,79.790,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.391 | Acc: 52.363,79.803,97.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.396 | Acc: 51.810,79.726,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.395 | Acc: 51.956,79.784,97.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.401 | Acc: 51.851,79.505,97.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.400 | Acc: 51.732,79.566,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.403 | Acc: 51.718,79.593,97.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.402 | Acc: 51.710,79.668,97.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.402 | Acc: 51.623,79.642,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.403 | Acc: 51.481,79.610,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 51.557,79.631,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.401 | Acc: 51.490,79.657,97.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.404 | Acc: 51.300,79.576,97.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.404 | Acc: 51.317,79.571,97.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.404 | Acc: 51.363,79.584,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.403 | Acc: 51.452,79.588,97.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.404 | Acc: 51.398,79.573,97.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.705 | Acc: 46.094,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.902 | Acc: 47.693,65.476,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.932 | Acc: 47.961,65.320,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.947 | Acc: 47.541,64.972,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.391 | Acc: 51.562,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.397 | Acc: 51.190,79.762,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.400 | Acc: 51.353,79.383,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.400 | Acc: 51.294,79.367,97.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.413 | Acc: 50.993,79.282,97.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.405 | Acc: 51.176,79.425,97.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.408 | Acc: 51.233,79.345,97.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.402 | Acc: 51.463,79.566,97.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.402 | Acc: 51.383,79.629,97.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.404 | Acc: 51.217,79.610,97.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.405 | Acc: 51.182,79.629,97.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.402 | Acc: 51.326,79.680,97.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.399 | Acc: 51.559,79.691,97.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 51.500,79.559,97.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.402 | Acc: 51.460,79.635,97.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.398 | Acc: 51.609,79.690,97.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.399 | Acc: 51.628,79.624,97.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.402 | Acc: 51.574,79.619,97.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.401 | Acc: 51.562,79.594,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.400 | Acc: 51.604,79.634,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.668 | Acc: 45.312,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.901 | Acc: 47.321,65.067,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.926 | Acc: 47.599,65.149,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.945 | Acc: 47.336,64.831,70.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.515 | Acc: 53.125,73.438,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.407 | Acc: 51.265,79.018,97.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.401 | Acc: 52.001,79.345,97.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.411 | Acc: 52.088,79.175,97.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.418 | Acc: 51.813,78.868,97.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.422 | Acc: 51.640,78.860,97.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.416 | Acc: 51.892,78.984,97.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.412 | Acc: 51.923,79.139,97.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.406 | Acc: 51.922,79.304,97.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.407 | Acc: 51.903,79.243,97.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.408 | Acc: 51.792,79.241,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.408 | Acc: 51.803,79.295,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.409 | Acc: 51.757,79.373,97.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.409 | Acc: 51.760,79.364,97.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.409 | Acc: 51.796,79.398,97.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.408 | Acc: 51.840,79.368,97.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.407 | Acc: 51.777,79.437,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.406 | Acc: 51.727,79.447,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.403 | Acc: 51.749,79.523,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.403 | Acc: 51.802,79.519,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.685 | Acc: 46.875,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.892 | Acc: 47.321,65.551,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 47.694,65.454,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.942 | Acc: 47.426,65.164,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.471 | Acc: 45.312,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.430 | Acc: 49.963,78.348,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.407 | Acc: 50.838,78.982,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.393 | Acc: 51.780,79.559,97.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.386 | Acc: 52.025,80.006,97.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.397 | Acc: 51.980,79.734,97.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.393 | Acc: 52.176,79.791,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.398 | Acc: 51.989,79.693,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.402 | Acc: 51.951,79.629,97.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.401 | Acc: 51.938,79.696,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.402 | Acc: 51.850,79.660,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.400 | Acc: 51.845,79.709,97.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.401 | Acc: 51.825,79.684,97.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 51.841,79.699,97.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.401 | Acc: 51.793,79.671,97.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.401 | Acc: 51.869,79.651,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.401 | Acc: 51.913,79.661,97.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.402 | Acc: 51.904,79.594,97.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.401 | Acc: 51.870,79.605,97.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.401 | Acc: 51.882,79.628,97.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.685 | Acc: 45.312,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.890 | Acc: 47.768,65.179,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.917 | Acc: 47.885,65.149,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 47.426,64.754,70.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.381 | Acc: 50.781,76.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.411 | Acc: 51.339,79.315,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.429 | Acc: 50.819,79.383,97.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.419 | Acc: 51.037,79.688,97.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.413 | Acc: 51.235,79.408,97.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.408 | Acc: 51.416,79.641,97.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.405 | Acc: 51.608,79.830,97.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.402 | Acc: 51.485,79.904,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.403 | Acc: 51.407,79.775,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.399 | Acc: 51.610,79.959,97.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.398 | Acc: 51.621,79.979,97.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.400 | Acc: 51.467,79.903,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.402 | Acc: 51.462,79.905,97.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 51.500,79.891,97.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.401 | Acc: 51.487,79.877,97.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.401 | Acc: 51.474,79.830,97.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.400 | Acc: 51.485,79.790,97.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.398 | Acc: 51.496,79.745,97.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.397 | Acc: 51.608,79.791,97.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.396 | Acc: 51.634,79.804,97.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.702 | Acc: 46.875,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.902 | Acc: 47.545,65.439,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 47.771,65.415,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.944 | Acc: 47.400,65.164,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.425 | Acc: 47.656,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.429 | Acc: 51.972,78.869,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.429 | Acc: 51.391,79.059,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.413 | Acc: 51.447,79.495,97.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.407 | Acc: 51.852,79.697,97.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.406 | Acc: 52.011,79.610,97.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.402 | Acc: 51.963,79.713,97.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.403 | Acc: 51.978,79.704,97.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.404 | Acc: 51.946,79.673,97.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.400 | Acc: 52.016,79.903,97.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.399 | Acc: 52.087,79.960,97.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.397 | Acc: 52.029,80.016,97.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.400 | Acc: 51.744,79.966,97.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.397 | Acc: 51.817,80.035,97.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.400 | Acc: 51.816,79.977,97.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.402 | Acc: 51.879,79.864,97.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.406 | Acc: 51.709,79.743,97.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.403 | Acc: 51.812,79.770,97.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.403 | Acc: 51.779,79.765,97.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.404 | Acc: 51.679,79.753,97.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.692 | Acc: 46.094,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.881 | Acc: 47.842,65.476,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.915 | Acc: 48.075,65.187,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.932 | Acc: 47.797,64.946,70.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.426 | Acc: 53.906,76.562,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.402 | Acc: 52.567,80.283,97.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.410 | Acc: 51.715,79.992,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.406 | Acc: 51.627,79.662,97.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.408 | Acc: 51.611,79.688,97.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.413 | Acc: 51.501,79.657,97.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.411 | Acc: 51.543,79.616,97.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.407 | Acc: 51.673,79.760,97.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.408 | Acc: 51.635,79.721,97.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.406 | Acc: 51.657,79.614,97.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.404 | Acc: 51.745,79.649,97.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.403 | Acc: 51.757,79.663,97.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.403 | Acc: 51.728,79.613,97.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.404 | Acc: 51.631,79.655,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.402 | Acc: 51.707,79.738,97.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.401 | Acc: 51.721,79.724,97.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.401 | Acc: 51.774,79.717,97.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.401 | Acc: 51.760,79.676,97.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.399 | Acc: 51.807,79.716,97.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.398 | Acc: 51.780,79.741,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.699 | Acc: 47.656,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.900 | Acc: 47.396,65.625,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 47.923,65.244,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.942 | Acc: 47.490,65.049,70.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.313 | Acc: 50.000,80.469,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.401 | Acc: 49.963,80.022,97.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.396 | Acc: 50.819,79.973,97.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.393 | Acc: 51.242,79.969,97.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.382 | Acc: 51.919,80.353,97.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.378 | Acc: 52.150,80.360,97.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.378 | Acc: 52.286,80.417,97.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.380 | Acc: 52.327,80.408,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.377 | Acc: 52.290,80.435,97.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.378 | Acc: 52.232,80.460,97.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.378 | Acc: 52.204,80.527,97.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.380 | Acc: 52.033,80.416,97.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.382 | Acc: 51.984,80.362,97.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.385 | Acc: 51.973,80.334,97.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.388 | Acc: 51.863,80.174,97.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.389 | Acc: 51.877,80.152,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.388 | Acc: 51.823,80.135,97.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.389 | Acc: 51.760,80.066,97.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.391 | Acc: 51.710,80.038,97.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.391 | Acc: 51.749,80.044,97.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.694 | Acc: 48.438,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.900 | Acc: 47.321,65.662,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.927 | Acc: 47.675,65.282,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.941 | Acc: 47.285,64.972,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.456 | Acc: 46.094,81.250,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.374 | Acc: 51.600,80.729,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.403 | Acc: 50.972,80.088,97.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.404 | Acc: 51.191,79.803,97.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.406 | Acc: 51.225,79.745,97.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.404 | Acc: 51.284,79.587,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.406 | Acc: 51.453,79.591,97.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.407 | Acc: 51.385,79.610,97.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.408 | Acc: 51.300,79.537,97.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.410 | Acc: 51.226,79.394,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.412 | Acc: 51.275,79.431,97.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.409 | Acc: 51.269,79.479,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.410 | Acc: 51.342,79.461,97.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.411 | Acc: 51.380,79.373,97.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.410 | Acc: 51.465,79.490,97.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.409 | Acc: 51.500,79.516,97.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.410 | Acc: 51.558,79.481,97.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.408 | Acc: 51.546,79.445,97.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.406 | Acc: 51.597,79.519,97.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.407 | Acc: 51.636,79.517,97.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.695 | Acc: 46.875,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.898 | Acc: 47.582,65.513,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.921 | Acc: 47.923,65.244,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.941 | Acc: 47.541,64.933,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.378 | Acc: 50.000,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.400 | Acc: 52.418,80.171,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.394 | Acc: 52.401,79.802,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.381 | Acc: 52.254,80.085,97.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.389 | Acc: 52.344,80.112,97.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.390 | Acc: 52.181,79.858,97.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.387 | Acc: 52.447,79.713,97.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.388 | Acc: 52.394,79.782,97.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.388 | Acc: 52.300,79.891,97.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.385 | Acc: 52.318,79.977,97.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.387 | Acc: 52.371,79.971,97.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.389 | Acc: 52.262,79.938,97.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.392 | Acc: 52.217,79.807,97.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.392 | Acc: 52.260,79.825,97.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.394 | Acc: 52.130,79.776,97.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.394 | Acc: 52.110,79.830,97.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.394 | Acc: 52.030,79.812,97.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.395 | Acc: 51.931,79.786,97.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.395 | Acc: 51.904,79.856,97.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.396 | Acc: 51.870,79.823,97.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.666 | Acc: 46.094,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.902 | Acc: 47.433,65.439,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.933 | Acc: 47.904,65.339,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.948 | Acc: 47.400,65.100,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.738 | Acc: 43.750,71.875,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.439 | Acc: 51.451,78.385,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.405 | Acc: 52.268,79.764,96.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.400 | Acc: 51.844,79.713,96.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.398 | Acc: 51.611,79.610,97.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.400 | Acc: 51.508,79.780,97.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.400 | Acc: 51.659,79.817,97.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.400 | Acc: 51.668,79.699,97.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.396 | Acc: 51.825,79.692,97.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.405 | Acc: 51.541,79.532,97.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.406 | Acc: 51.586,79.450,97.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.405 | Acc: 51.619,79.521,97.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.404 | Acc: 51.524,79.538,97.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.400 | Acc: 51.613,79.619,97.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.401 | Acc: 51.654,79.582,97.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.400 | Acc: 51.562,79.578,97.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.399 | Acc: 51.526,79.651,97.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.400 | Acc: 51.585,79.706,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.401 | Acc: 51.619,79.653,97.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.401 | Acc: 51.673,79.659,97.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.679 | Acc: 46.875,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.903 | Acc: 47.210,65.476,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.930 | Acc: 47.637,65.377,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.946 | Acc: 47.349,65.049,70.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.356 | Acc: 51.562,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.393 | Acc: 52.232,81.250,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.401 | Acc: 51.734,80.507,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.411 | Acc: 51.614,79.559,97.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.396 | Acc: 52.170,79.929,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.394 | Acc: 52.282,80.121,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.395 | Acc: 52.040,80.185,97.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.393 | Acc: 51.912,80.164,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.394 | Acc: 51.980,80.047,97.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.396 | Acc: 51.908,79.912,97.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.398 | Acc: 51.718,79.816,97.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.397 | Acc: 51.644,79.850,97.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.395 | Acc: 51.861,79.908,97.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.394 | Acc: 51.910,79.930,97.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.395 | Acc: 51.832,79.871,97.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.395 | Acc: 51.806,79.825,97.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.397 | Acc: 51.803,79.792,97.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.396 | Acc: 51.762,79.802,97.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.396 | Acc: 51.766,79.830,97.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.396 | Acc: 51.710,79.868,97.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.695 | Acc: 47.656,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.893 | Acc: 47.396,65.551,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.921 | Acc: 47.790,65.339,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.939 | Acc: 47.387,64.985,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.427 | Acc: 46.094,75.000,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.426 | Acc: 50.037,80.022,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.427 | Acc: 50.705,79.554,97.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.408 | Acc: 51.434,79.777,97.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.418 | Acc: 51.331,79.475,97.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.419 | Acc: 51.122,79.471,97.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.420 | Acc: 51.111,79.397,97.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.413 | Acc: 51.103,79.543,97.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.405 | Acc: 51.364,79.649,97.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.404 | Acc: 51.558,79.692,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.406 | Acc: 51.415,79.606,97.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.407 | Acc: 51.393,79.578,97.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.408 | Acc: 51.365,79.506,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.407 | Acc: 51.524,79.526,97.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.406 | Acc: 51.624,79.557,97.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.404 | Acc: 51.614,79.641,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.402 | Acc: 51.604,79.729,97.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.402 | Acc: 51.624,79.809,97.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.402 | Acc: 51.580,79.798,97.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.401 | Acc: 51.593,79.778,97.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.697 | Acc: 46.875,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.903 | Acc: 47.656,65.513,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 47.961,65.111,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.944 | Acc: 47.631,64.818,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.411 | Acc: 49.219,75.000,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.412 | Acc: 50.818,78.571,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.402 | Acc: 50.972,79.402,97.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.390 | Acc: 51.447,79.470,97.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.396 | Acc: 51.630,79.475,97.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.399 | Acc: 51.416,79.455,97.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.404 | Acc: 51.278,79.481,97.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.399 | Acc: 51.635,79.615,97.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.400 | Acc: 51.548,79.600,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.398 | Acc: 51.645,79.588,97.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.395 | Acc: 51.796,79.695,97.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.394 | Acc: 51.845,79.772,97.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.395 | Acc: 51.786,79.717,97.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.392 | Acc: 51.892,79.771,97.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.394 | Acc: 51.871,79.738,97.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.396 | Acc: 51.843,79.745,97.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.397 | Acc: 51.757,79.702,97.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.395 | Acc: 51.847,79.694,97.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.396 | Acc: 51.772,79.713,97.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.396 | Acc: 51.755,79.753,97.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.729 | Acc: 46.875,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.893 | Acc: 47.768,65.290,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.924 | Acc: 47.904,65.149,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.941 | Acc: 47.541,64.857,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.349 | Acc: 47.656,80.469,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.372 | Acc: 50.930,80.394,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.385 | Acc: 50.781,80.602,97.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.395 | Acc: 50.922,80.187,97.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.404 | Acc: 50.627,80.112,97.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.411 | Acc: 50.549,79.943,97.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.410 | Acc: 50.775,79.784,97.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.408 | Acc: 50.831,79.676,97.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.407 | Acc: 50.927,79.673,97.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.404 | Acc: 51.109,79.670,97.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.402 | Acc: 51.217,79.621,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.403 | Acc: 51.188,79.712,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.400 | Acc: 51.342,79.756,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.400 | Acc: 51.377,79.813,97.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.399 | Acc: 51.382,79.799,97.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.396 | Acc: 51.581,79.906,97.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.397 | Acc: 51.604,79.907,97.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.395 | Acc: 51.677,79.926,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.396 | Acc: 51.666,79.852,97.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.396 | Acc: 51.671,79.858,97.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.684 | Acc: 47.656,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.909 | Acc: 47.656,65.662,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 47.885,65.473,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.944 | Acc: 47.413,65.087,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.487 | Acc: 38.281,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.444 | Acc: 50.186,78.423,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.439 | Acc: 50.171,78.830,97.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.428 | Acc: 50.525,78.932,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.429 | Acc: 50.907,78.897,97.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.422 | Acc: 51.160,79.154,97.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.421 | Acc: 51.395,79.139,97.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.415 | Acc: 51.502,79.189,97.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.414 | Acc: 51.553,79.144,97.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.408 | Acc: 51.597,79.351,97.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.409 | Acc: 51.586,79.384,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.405 | Acc: 51.626,79.472,97.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.406 | Acc: 51.673,79.480,97.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.404 | Acc: 51.664,79.568,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.400 | Acc: 51.754,79.643,97.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.397 | Acc: 51.812,79.729,97.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.398 | Acc: 51.752,79.658,97.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.395 | Acc: 51.789,79.736,97.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.397 | Acc: 51.710,79.692,97.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.398 | Acc: 51.642,79.722,97.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.736 | Acc: 46.875,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.910 | Acc: 47.656,65.253,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.931 | Acc: 47.923,65.225,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.948 | Acc: 47.490,64.933,70.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.449 | Acc: 46.875,79.688,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.398 | Acc: 51.042,79.688,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.387 | Acc: 51.467,80.373,97.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.407 | Acc: 51.050,79.611,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.398 | Acc: 51.370,79.842,97.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.400 | Acc: 51.307,80.074,97.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.398 | Acc: 51.369,80.146,97.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.402 | Acc: 51.352,80.059,97.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.404 | Acc: 51.417,79.916,97.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.403 | Acc: 51.489,79.964,97.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.403 | Acc: 51.640,79.882,97.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.398 | Acc: 51.895,79.914,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.397 | Acc: 51.913,79.940,97.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.399 | Acc: 51.808,79.825,97.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.400 | Acc: 51.729,79.874,97.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.399 | Acc: 51.646,79.856,97.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.400 | Acc: 51.701,79.843,97.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.399 | Acc: 51.617,79.791,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.399 | Acc: 51.606,79.794,97.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.397 | Acc: 51.581,79.804,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.687 | Acc: 46.875,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.896 | Acc: 47.545,65.476,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.919 | Acc: 48.075,65.320,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.937 | Acc: 47.695,65.023,70.812,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.478 | Acc: 50.781,75.781,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.415 | Acc: 51.749,78.460,97.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.411 | Acc: 51.658,79.021,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.401 | Acc: 51.972,79.137,97.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.408 | Acc: 51.823,79.186,97.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.396 | Acc: 52.143,79.541,97.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.401 | Acc: 51.808,79.604,97.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.399 | Acc: 51.734,79.676,97.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.397 | Acc: 51.664,79.833,97.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.401 | Acc: 51.580,79.744,97.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.399 | Acc: 51.625,79.894,97.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.396 | Acc: 51.729,79.949,97.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.397 | Acc: 51.692,79.866,97.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.399 | Acc: 51.640,79.864,97.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.401 | Acc: 51.562,79.827,97.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.403 | Acc: 51.404,79.703,97.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.400 | Acc: 51.465,79.761,97.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.400 | Acc: 51.475,79.827,97.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.400 | Acc: 51.437,79.830,97.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.399 | Acc: 51.478,79.856,97.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.625 | Acc: 46.875,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.893 | Acc: 47.619,65.439,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.922 | Acc: 47.904,65.225,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.937 | Acc: 47.579,65.023,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.476 | Acc: 46.875,81.250,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.423 | Acc: 50.521,79.167,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.414 | Acc: 51.200,79.516,97.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.410 | Acc: 50.961,79.816,97.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.393 | Acc: 51.283,80.285,97.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.399 | Acc: 51.307,80.059,97.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.395 | Acc: 51.504,80.114,97.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.399 | Acc: 51.302,80.009,97.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.394 | Acc: 51.490,80.173,97.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.399 | Acc: 51.368,80.016,97.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.399 | Acc: 51.380,80.084,97.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.396 | Acc: 51.460,80.094,97.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.394 | Acc: 51.575,80.154,97.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.394 | Acc: 51.574,80.089,97.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.398 | Acc: 51.465,80.004,97.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.398 | Acc: 51.407,79.986,97.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.397 | Acc: 51.470,80.014,97.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.399 | Acc: 51.448,79.907,97.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.399 | Acc: 51.543,79.928,97.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.399 | Acc: 51.601,79.864,97.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.661 | Acc: 47.656,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.905 | Acc: 47.359,65.402,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.927 | Acc: 47.866,65.282,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.945 | Acc: 47.451,64.972,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.598 | Acc: 45.312,75.781,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.396 | Acc: 51.488,79.464,97.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.404 | Acc: 51.562,79.840,97.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.401 | Acc: 51.691,79.944,97.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.412 | Acc: 51.427,79.774,97.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.416 | Acc: 51.307,79.657,97.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.416 | Acc: 50.968,79.700,97.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.414 | Acc: 51.236,79.704,97.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.411 | Acc: 51.242,79.639,97.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.407 | Acc: 51.321,79.605,97.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.407 | Acc: 51.185,79.649,97.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.404 | Acc: 51.276,79.695,97.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.401 | Acc: 51.319,79.769,97.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.399 | Acc: 51.404,79.837,97.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.396 | Acc: 51.479,79.838,97.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.395 | Acc: 51.503,79.825,97.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.395 | Acc: 51.489,79.778,97.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.396 | Acc: 51.453,79.779,97.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.395 | Acc: 51.593,79.776,97.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.397 | Acc: 51.622,79.780,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.681 | Acc: 46.094,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.899 | Acc: 47.359,65.588,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.927 | Acc: 47.790,65.263,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.945 | Acc: 47.515,64.921,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 1.394 | Acc: 53.125,84.375,97.656,% | Adaptive Acc: 93.750% | clf_exit: 0.266 0.453 0.281
Batch: 20 | Loss: 1.390 | Acc: 52.083,79.501,97.247,% | Adaptive Acc: 89.881% | clf_exit: 0.297 0.448 0.255
Batch: 40 | Loss: 1.400 | Acc: 52.287,79.478,97.142,% | Adaptive Acc: 89.558% | clf_exit: 0.300 0.447 0.253
Batch: 60 | Loss: 1.392 | Acc: 52.754,79.700,97.080,% | Adaptive Acc: 89.511% | clf_exit: 0.303 0.447 0.250
Batch: 80 | Loss: 1.399 | Acc: 52.392,79.736,97.270,% | Adaptive Acc: 89.525% | clf_exit: 0.299 0.450 0.251
Batch: 100 | Loss: 1.398 | Acc: 52.143,79.873,97.269,% | Adaptive Acc: 89.318% | clf_exit: 0.299 0.451 0.250
Batch: 120 | Loss: 1.407 | Acc: 51.750,79.804,97.204,% | Adaptive Acc: 89.198% | clf_exit: 0.301 0.447 0.253
Batch: 140 | Loss: 1.401 | Acc: 51.912,79.848,97.252,% | Adaptive Acc: 89.173% | clf_exit: 0.303 0.446 0.251
Batch: 160 | Loss: 1.400 | Acc: 51.786,79.848,97.224,% | Adaptive Acc: 89.024% | clf_exit: 0.303 0.447 0.250
Batch: 180 | Loss: 1.401 | Acc: 51.856,79.670,97.255,% | Adaptive Acc: 88.916% | clf_exit: 0.303 0.447 0.249
Batch: 200 | Loss: 1.399 | Acc: 51.975,79.664,97.244,% | Adaptive Acc: 88.891% | clf_exit: 0.305 0.445 0.250
Batch: 220 | Loss: 1.399 | Acc: 51.810,79.688,97.278,% | Adaptive Acc: 88.865% | clf_exit: 0.304 0.446 0.250
Batch: 240 | Loss: 1.398 | Acc: 51.838,79.707,97.290,% | Adaptive Acc: 88.962% | clf_exit: 0.305 0.445 0.249
Batch: 260 | Loss: 1.399 | Acc: 51.781,79.720,97.300,% | Adaptive Acc: 89.036% | clf_exit: 0.305 0.445 0.250
Batch: 280 | Loss: 1.399 | Acc: 51.754,79.679,97.300,% | Adaptive Acc: 89.007% | clf_exit: 0.304 0.446 0.249
Batch: 300 | Loss: 1.399 | Acc: 51.760,79.721,97.251,% | Adaptive Acc: 89.005% | clf_exit: 0.305 0.446 0.250
Batch: 320 | Loss: 1.396 | Acc: 51.840,79.768,97.277,% | Adaptive Acc: 89.033% | clf_exit: 0.305 0.446 0.249
Batch: 340 | Loss: 1.395 | Acc: 51.876,79.800,97.271,% | Adaptive Acc: 88.991% | clf_exit: 0.305 0.446 0.249
Batch: 360 | Loss: 1.395 | Acc: 51.861,79.852,97.275,% | Adaptive Acc: 88.976% | clf_exit: 0.305 0.446 0.249
Batch: 380 | Loss: 1.396 | Acc: 51.841,79.821,97.291,% | Adaptive Acc: 88.958% | clf_exit: 0.305 0.446 0.249
Batch: 0 | Loss: 2.628 | Acc: 46.875,70.312,73.438,% | Adaptive Acc: 71.094% | clf_exit: 0.383 0.406 0.211
Batch: 20 | Loss: 2.911 | Acc: 47.470,65.551,71.317,% | Adaptive Acc: 66.518% | clf_exit: 0.374 0.378 0.248
Batch: 40 | Loss: 2.933 | Acc: 47.942,65.415,70.617,% | Adaptive Acc: 66.044% | clf_exit: 0.377 0.372 0.251
Batch: 60 | Loss: 2.946 | Acc: 47.528,65.228,70.505,% | Adaptive Acc: 65.868% | clf_exit: 0.373 0.377 0.250
model is save as models/resnet56_2con3_conv_cifar100_adaptive0_circles5_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 6.817 | Acc: 46.875,6.250,15.625,% | Adaptive Acc: 42.969% | clf_exit: 0.383 0.023 0.594
Batch: 20 | Loss: 6.893 | Acc: 47.470,6.399,15.067,% | Adaptive Acc: 38.021% | clf_exit: 0.374 0.013 0.613
Batch: 40 | Loss: 6.910 | Acc: 47.942,6.212,15.492,% | Adaptive Acc: 38.510% | clf_exit: 0.377 0.014 0.610
Batch: 60 | Loss: 6.894 | Acc: 47.528,6.263,16.112,% | Adaptive Acc: 38.525% | clf_exit: 0.373 0.014 0.613
Batch: 0 | Loss: 4.795 | Acc: 46.875,31.250,49.219,% | Adaptive Acc: 54.688% | clf_exit: 0.383 0.023 0.594
Batch: 20 | Loss: 5.026 | Acc: 47.470,29.799,45.722,% | Adaptive Acc: 52.716% | clf_exit: 0.374 0.037 0.589
Batch: 40 | Loss: 5.060 | Acc: 47.942,29.306,45.274,% | Adaptive Acc: 52.287% | clf_exit: 0.377 0.035 0.589
Batch: 60 | Loss: 5.047 | Acc: 47.528,29.252,45.505,% | Adaptive Acc: 52.459% | clf_exit: 0.373 0.036 0.591
Batch: 0 | Loss: 3.638 | Acc: 46.875,50.781,64.844,% | Adaptive Acc: 67.188% | clf_exit: 0.383 0.180 0.438
Batch: 20 | Loss: 3.842 | Acc: 47.470,51.451,61.719,% | Adaptive Acc: 60.677% | clf_exit: 0.374 0.113 0.513
Batch: 40 | Loss: 3.880 | Acc: 47.942,50.419,60.328,% | Adaptive Acc: 59.489% | clf_exit: 0.377 0.109 0.515
Batch: 60 | Loss: 3.871 | Acc: 47.528,50.128,60.656,% | Adaptive Acc: 59.349% | clf_exit: 0.373 0.111 0.516
Batch: 0 | Loss: 3.008 | Acc: 46.875,62.500,71.875,% | Adaptive Acc: 69.531% | clf_exit: 0.383 0.289 0.328
Batch: 20 | Loss: 3.169 | Acc: 47.470,60.863,68.378,% | Adaptive Acc: 64.732% | clf_exit: 0.374 0.228 0.398
Batch: 40 | Loss: 3.195 | Acc: 47.942,60.499,66.673,% | Adaptive Acc: 63.834% | clf_exit: 0.377 0.221 0.402
Batch: 60 | Loss: 3.194 | Acc: 47.528,60.015,66.650,% | Adaptive Acc: 63.691% | clf_exit: 0.373 0.225 0.403
Batch: 0 | Loss: 2.704 | Acc: 46.875,65.625,72.656,% | Adaptive Acc: 71.094% | clf_exit: 0.383 0.391 0.227
Batch: 20 | Loss: 2.896 | Acc: 47.470,64.769,70.722,% | Adaptive Acc: 66.332% | clf_exit: 0.374 0.319 0.307
Batch: 40 | Loss: 2.914 | Acc: 47.942,64.710,69.817,% | Adaptive Acc: 65.758% | clf_exit: 0.377 0.315 0.308
Batch: 60 | Loss: 2.923 | Acc: 47.528,64.242,69.659,% | Adaptive Acc: 65.561% | clf_exit: 0.373 0.316 0.311
Batch: 0 | Loss: 2.628 | Acc: 46.875,70.312,73.438,% | Adaptive Acc: 71.094% | clf_exit: 0.383 0.406 0.211
Batch: 20 | Loss: 2.911 | Acc: 47.470,65.551,71.317,% | Adaptive Acc: 66.518% | clf_exit: 0.374 0.378 0.248
Batch: 40 | Loss: 2.933 | Acc: 47.942,65.415,70.617,% | Adaptive Acc: 66.044% | clf_exit: 0.377 0.372 0.251
Batch: 60 | Loss: 2.946 | Acc: 47.528,65.228,70.505,% | Adaptive Acc: 65.868% | clf_exit: 0.373 0.377 0.250







Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 8.790 |  Acc: 3.402,3.470,5.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 8.410 |  Acc: 5.360,4.180,7.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 8.011 |  Acc: 6.820,6.502,10.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 7.879 |  Acc: 8.220,7.210,11.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 7.549 |  Acc: 9.394,9.986,14.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 7.357 |  Acc: 11.040,10.790,15.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 7.124 |  Acc: 11.964,13.222,18.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 7.265 |  Acc: 10.910,11.090,15.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 6.768 |  Acc: 14.418,15.928,21.256,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 6.748 |  Acc: 14.040,14.730,21.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 6.442 |  Acc: 16.388,18.584,24.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 6.544 |  Acc: 14.990,18.690,22.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 6.169 |  Acc: 18.442,20.672,26.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 6.313 |  Acc: 17.520,18.750,25.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 5.928 |  Acc: 20.178,22.728,29.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 6.165 |  Acc: 19.810,19.990,25.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 5.707 |  Acc: 21.820,24.628,32.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 6.017 |  Acc: 20.090,21.840,28.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 5.508 |  Acc: 23.178,26.398,34.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 6.019 |  Acc: 18.990,21.240,29.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 5.332 |  Acc: 24.358,28.274,36.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 6.412 |  Acc: 15.160,20.410,26.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.191 |  Acc: 25.254,29.038,38.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 6.269 |  Acc: 18.420,20.470,28.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.019 |  Acc: 26.324,31.004,40.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 5.365 |  Acc: 24.120,27.990,36.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 4.908 |  Acc: 26.958,32.120,41.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 5.623 |  Acc: 22.050,28.330,32.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 4.789 |  Acc: 27.892,33.476,43.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 6.056 |  Acc: 20.020,22.470,33.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 4.683 |  Acc: 28.536,34.608,45.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 5.368 |  Acc: 21.130,28.390,39.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 4.586 |  Acc: 29.344,35.588,46.250,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 5.840 |  Acc: 19.220,25.240,34.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 4.489 |  Acc: 29.830,36.848,47.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 4.819 |  Acc: 25.690,33.130,44.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.401 |  Acc: 30.552,37.680,49.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 5.171 |  Acc: 23.030,31.860,42.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.329 |  Acc: 30.836,38.740,49.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 4.542 |  Acc: 27.770,37.430,47.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.253 |  Acc: 31.238,39.802,50.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 5.234 |  Acc: 22.780,29.790,41.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.172 |  Acc: 31.876,40.924,52.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 4.819 |  Acc: 24.770,35.780,46.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.117 |  Acc: 32.322,41.416,52.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 4.738 |  Acc: 25.090,36.450,44.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.056 |  Acc: 32.704,42.322,53.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 4.869 |  Acc: 28.390,34.290,43.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 3.993 |  Acc: 32.840,42.924,54.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 5.623 |  Acc: 20.180,27.950,40.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 3.935 |  Acc: 33.262,43.694,55.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 4.976 |  Acc: 22.720,35.650,45.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 3.892 |  Acc: 33.588,44.478,55.892,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 4.455 |  Acc: 26.860,38.690,50.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 3.843 |  Acc: 33.800,45.092,56.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 4.540 |  Acc: 25.730,38.750,48.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 3.793 |  Acc: 33.936,45.846,57.608,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 5.202 |  Acc: 21.160,31.120,45.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 3.756 |  Acc: 34.074,46.296,58.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 4.361 |  Acc: 27.240,38.990,50.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 3.732 |  Acc: 34.282,47.004,58.318,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 4.758 |  Acc: 22.790,38.530,49.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 3.681 |  Acc: 34.760,47.414,59.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 4.753 |  Acc: 27.480,36.860,47.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 3.639 |  Acc: 35.008,47.820,59.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 4.834 |  Acc: 25.010,34.570,48.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 3.618 |  Acc: 35.312,48.326,60.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 4.727 |  Acc: 21.080,38.870,50.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 3.572 |  Acc: 35.624,49.332,60.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 4.642 |  Acc: 28.110,36.800,48.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.550 |  Acc: 35.672,49.034,61.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 4.832 |  Acc: 22.630,34.450,49.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.525 |  Acc: 35.742,49.586,61.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 4.277 |  Acc: 29.600,40.400,52.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.510 |  Acc: 35.762,49.868,61.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 4.193 |  Acc: 31.170,41.460,53.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.472 |  Acc: 36.082,50.276,62.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 4.787 |  Acc: 22.610,38.470,50.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.453 |  Acc: 36.200,50.654,62.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 4.668 |  Acc: 26.280,37.880,48.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.428 |  Acc: 36.198,51.116,62.942,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 4.217 |  Acc: 29.040,43.480,52.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.413 |  Acc: 36.302,50.996,63.256,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 4.651 |  Acc: 24.210,40.550,49.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.381 |  Acc: 36.596,51.690,63.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 4.999 |  Acc: 24.260,35.050,47.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.367 |  Acc: 36.798,51.874,63.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 4.548 |  Acc: 22.730,41.590,54.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.337 |  Acc: 36.716,52.376,63.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 4.836 |  Acc: 21.570,36.910,50.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.331 |  Acc: 36.758,52.428,64.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 4.408 |  Acc: 23.860,41.090,54.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.307 |  Acc: 36.974,52.544,64.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 4.620 |  Acc: 28.860,39.630,49.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.291 |  Acc: 37.200,52.922,64.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 4.387 |  Acc: 24.480,42.310,53.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.276 |  Acc: 37.268,53.094,65.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 4.286 |  Acc: 29.650,41.900,53.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.265 |  Acc: 37.496,53.598,65.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 4.731 |  Acc: 25.670,38.130,48.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.252 |  Acc: 37.288,53.574,65.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 4.151 |  Acc: 30.280,44.690,54.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.230 |  Acc: 37.544,53.762,65.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 4.269 |  Acc: 28.880,40.330,54.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.210 |  Acc: 37.728,54.110,66.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 4.442 |  Acc: 28.260,41.770,53.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.180 |  Acc: 37.740,54.794,66.626,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 3.985 |  Acc: 30.880,44.920,56.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.174 |  Acc: 37.912,54.810,66.508,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 4.236 |  Acc: 24.030,44.080,56.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.161 |  Acc: 37.814,54.848,66.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 4.160 |  Acc: 27.700,43.740,55.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.148 |  Acc: 37.930,55.180,66.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 4.980 |  Acc: 22.110,38.120,49.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.150 |  Acc: 37.814,55.030,66.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 4.471 |  Acc: 28.320,41.780,52.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.124 |  Acc: 38.228,55.458,67.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 4.245 |  Acc: 25.580,47.030,55.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.119 |  Acc: 38.318,55.494,67.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 4.301 |  Acc: 28.070,45.220,53.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.096 |  Acc: 38.306,56.054,67.942,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 4.054 |  Acc: 31.430,45.870,56.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.094 |  Acc: 38.300,55.924,67.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 3.989 |  Acc: 30.730,47.930,57.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.076 |  Acc: 38.428,56.282,67.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 4.574 |  Acc: 24.110,41.760,54.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.069 |  Acc: 38.510,56.598,68.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 3.929 |  Acc: 31.180,47.510,57.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.063 |  Acc: 38.600,56.302,68.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 3.935 |  Acc: 30.480,46.810,58.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.039 |  Acc: 38.854,56.512,68.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 4.139 |  Acc: 32.110,42.680,55.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.033 |  Acc: 38.664,56.814,68.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 4.508 |  Acc: 25.450,43.160,53.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 3.026 |  Acc: 39.090,56.752,68.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 3.978 |  Acc: 30.360,47.150,57.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 3.022 |  Acc: 38.982,57.022,68.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 4.380 |  Acc: 28.760,43.550,55.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 3.008 |  Acc: 38.740,57.446,68.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 4.285 |  Acc: 28.180,44.100,55.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 2.997 |  Acc: 39.082,57.496,69.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 5.333 |  Acc: 18.370,34.120,50.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 2.992 |  Acc: 39.136,57.528,69.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 4.284 |  Acc: 27.090,43.660,56.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 2.980 |  Acc: 39.186,57.662,69.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 4.672 |  Acc: 24.280,39.160,52.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 2.974 |  Acc: 39.272,57.692,69.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 4.272 |  Acc: 26.590,44.640,55.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 2.962 |  Acc: 39.336,57.846,69.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 4.194 |  Acc: 27.760,46.110,57.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 2.937 |  Acc: 39.734,58.114,69.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 4.257 |  Acc: 29.390,43.950,55.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 2.946 |  Acc: 39.438,58.152,69.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 4.302 |  Acc: 25.960,46.240,57.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 2.931 |  Acc: 39.452,58.106,70.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 3.907 |  Acc: 30.650,47.980,57.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 2.934 |  Acc: 39.358,58.198,70.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 4.452 |  Acc: 27.790,41.670,53.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 2.920 |  Acc: 39.560,58.566,70.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 4.813 |  Acc: 25.450,40.030,52.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 2.903 |  Acc: 39.956,58.808,70.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 4.594 |  Acc: 27.000,40.930,52.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 2.908 |  Acc: 39.808,58.650,70.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 4.429 |  Acc: 23.690,44.180,55.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 2.913 |  Acc: 39.488,58.710,70.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 3.891 |  Acc: 30.790,48.010,59.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 2.895 |  Acc: 39.848,58.978,70.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 4.107 |  Acc: 26.660,46.880,57.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 2.897 |  Acc: 39.628,58.498,70.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 3.948 |  Acc: 31.560,46.280,58.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 2.889 |  Acc: 39.938,59.014,71.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 4.064 |  Acc: 28.670,47.810,56.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 2.880 |  Acc: 39.790,59.012,70.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 4.254 |  Acc: 30.140,43.280,54.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 2.867 |  Acc: 40.110,59.578,71.150,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 4.604 |  Acc: 24.960,41.330,53.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 2.869 |  Acc: 40.130,59.302,71.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 4.101 |  Acc: 28.610,44.940,57.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 2.858 |  Acc: 40.102,59.362,71.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 4.503 |  Acc: 27.070,42.810,52.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 2.855 |  Acc: 40.044,59.498,71.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 4.025 |  Acc: 27.730,47.430,57.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 2.841 |  Acc: 40.154,59.292,71.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 3.853 |  Acc: 33.750,49.860,58.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 2.829 |  Acc: 40.338,59.734,71.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 4.732 |  Acc: 21.420,41.900,54.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 2.834 |  Acc: 40.270,59.674,71.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 4.070 |  Acc: 31.150,46.820,56.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 2.836 |  Acc: 40.392,59.554,71.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 4.994 |  Acc: 20.120,38.950,51.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 2.828 |  Acc: 40.342,59.706,71.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 3.913 |  Acc: 31.080,48.730,57.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 2.821 |  Acc: 40.368,59.620,71.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 4.243 |  Acc: 26.740,47.300,55.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 2.815 |  Acc: 40.520,60.108,71.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 4.075 |  Acc: 29.250,46.150,58.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 2.801 |  Acc: 40.750,60.102,71.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 3.958 |  Acc: 31.950,47.440,57.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 2.802 |  Acc: 40.448,60.212,72.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 4.620 |  Acc: 26.330,42.400,52.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 2.807 |  Acc: 40.508,59.996,72.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 3.947 |  Acc: 30.280,47.980,58.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 2.789 |  Acc: 40.784,60.054,72.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 4.417 |  Acc: 29.120,43.360,53.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 2.795 |  Acc: 40.940,60.304,72.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 4.047 |  Acc: 28.070,47.020,57.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.778 |  Acc: 40.778,60.660,72.322,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 3.980 |  Acc: 27.870,47.580,60.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.794 |  Acc: 40.896,60.292,72.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 3.950 |  Acc: 30.960,48.330,57.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.762 |  Acc: 41.092,60.872,72.500,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 5.030 |  Acc: 16.640,39.980,53.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.774 |  Acc: 41.002,60.624,72.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 4.197 |  Acc: 26.350,46.940,58.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.771 |  Acc: 40.898,60.824,72.376,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 4.651 |  Acc: 23.470,43.700,54.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.771 |  Acc: 41.098,60.502,72.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 4.280 |  Acc: 25.300,45.510,57.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.746 |  Acc: 40.912,60.996,72.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 4.301 |  Acc: 28.250,45.930,56.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.751 |  Acc: 41.258,60.778,72.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 3.505 |  Acc: 35.070,53.160,62.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 2.742 |  Acc: 41.374,60.828,72.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 4.557 |  Acc: 26.200,42.390,53.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.749 |  Acc: 41.240,60.800,72.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 4.220 |  Acc: 27.940,46.240,55.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.746 |  Acc: 41.290,60.656,72.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 4.423 |  Acc: 26.040,44.440,55.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.740 |  Acc: 41.194,60.742,72.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 4.039 |  Acc: 26.300,48.030,58.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.727 |  Acc: 41.526,60.930,73.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 4.329 |  Acc: 25.340,45.110,56.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 2.737 |  Acc: 41.400,60.970,72.912,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 3.994 |  Acc: 30.140,47.030,59.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 2.721 |  Acc: 41.604,61.250,73.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 4.438 |  Acc: 23.100,43.270,56.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 2.724 |  Acc: 41.726,61.364,72.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 4.190 |  Acc: 29.530,47.280,57.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 2.714 |  Acc: 41.532,61.412,73.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 3.850 |  Acc: 31.200,50.990,59.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 2.711 |  Acc: 41.706,61.510,73.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 3.903 |  Acc: 28.350,49.760,59.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 2.729 |  Acc: 41.310,60.878,72.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 4.012 |  Acc: 30.550,49.460,58.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 2.718 |  Acc: 41.704,61.102,72.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 4.892 |  Acc: 18.960,37.840,53.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 2.702 |  Acc: 41.596,61.576,73.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 3.861 |  Acc: 31.800,49.210,60.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 2.699 |  Acc: 41.722,61.386,73.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 4.074 |  Acc: 27.590,47.900,58.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 2.704 |  Acc: 41.986,61.196,73.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 4.063 |  Acc: 28.340,47.670,59.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 2.703 |  Acc: 41.850,61.400,73.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 4.257 |  Acc: 28.140,45.770,56.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 2.682 |  Acc: 42.130,61.768,73.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 3.957 |  Acc: 27.240,48.660,61.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 2.680 |  Acc: 42.086,61.856,73.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 4.135 |  Acc: 26.460,47.110,57.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 2.682 |  Acc: 42.110,61.718,73.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 4.468 |  Acc: 27.510,43.980,54.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 2.683 |  Acc: 41.814,61.824,73.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 4.063 |  Acc: 27.720,48.860,58.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 2.669 |  Acc: 42.112,61.992,73.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 4.025 |  Acc: 28.990,48.020,58.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 2.681 |  Acc: 42.606,61.848,73.432,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 3.928 |  Acc: 32.690,49.070,57.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 2.674 |  Acc: 42.464,61.602,73.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 4.239 |  Acc: 28.370,45.720,56.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 2.657 |  Acc: 42.462,61.884,74.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 3.835 |  Acc: 33.010,50.220,59.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 2.667 |  Acc: 42.130,61.762,73.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 3.930 |  Acc: 28.790,50.790,60.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 2.665 |  Acc: 42.204,61.754,73.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 4.122 |  Acc: 27.440,46.970,58.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 2.651 |  Acc: 42.386,62.004,73.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 3.879 |  Acc: 34.220,49.260,58.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 2.657 |  Acc: 42.362,61.956,73.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 3.678 |  Acc: 32.400,52.800,61.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 2.666 |  Acc: 42.280,62.044,73.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 3.826 |  Acc: 33.600,50.170,59.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 2.640 |  Acc: 42.458,62.240,74.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 3.971 |  Acc: 26.060,49.560,61.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 2.653 |  Acc: 42.222,62.374,74.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 4.337 |  Acc: 27.390,44.600,55.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 2.656 |  Acc: 42.466,62.126,73.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 4.573 |  Acc: 26.770,41.840,54.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 2.645 |  Acc: 42.616,62.048,73.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 4.099 |  Acc: 29.080,46.350,57.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 2.636 |  Acc: 42.434,62.242,74.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 3.843 |  Acc: 35.330,49.490,58.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 2.633 |  Acc: 42.850,62.202,74.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 4.370 |  Acc: 24.330,42.680,56.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 2.638 |  Acc: 42.802,62.372,74.090,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 3.948 |  Acc: 30.620,48.300,59.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 2.642 |  Acc: 42.592,62.272,73.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 4.281 |  Acc: 28.460,46.350,56.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 2.628 |  Acc: 42.812,62.548,74.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 4.225 |  Acc: 27.320,46.490,56.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 2.629 |  Acc: 42.602,62.272,74.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 3.893 |  Acc: 30.120,49.240,60.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.165 |  Acc: 46.508,69.186,82.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 2.738 |  Acc: 44.300,62.870,71.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.024 |  Acc: 47.302,71.294,85.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 2.726 |  Acc: 44.710,63.420,71.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.978 |  Acc: 47.354,72.008,86.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 2.742 |  Acc: 44.250,63.800,71.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.940 |  Acc: 47.666,72.206,86.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 2.729 |  Acc: 44.980,63.900,72.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.926 |  Acc: 48.076,72.446,87.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 2.722 |  Acc: 45.210,64.050,71.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.896 |  Acc: 48.140,72.760,87.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 2.742 |  Acc: 44.920,63.870,71.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.879 |  Acc: 48.126,72.968,88.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 2.726 |  Acc: 45.690,64.240,72.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.867 |  Acc: 48.198,73.108,88.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 2.730 |  Acc: 45.480,63.970,71.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.846 |  Acc: 48.368,73.442,88.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 2.754 |  Acc: 45.480,63.850,71.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.832 |  Acc: 48.318,73.612,89.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 2.724 |  Acc: 45.570,64.890,71.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.829 |  Acc: 48.626,73.494,89.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 2.755 |  Acc: 45.270,64.120,72.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.811 |  Acc: 48.500,73.744,89.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 2.763 |  Acc: 45.420,64.020,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.806 |  Acc: 48.654,73.818,89.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 2.782 |  Acc: 44.840,64.330,71.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.786 |  Acc: 48.850,73.996,90.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 2.753 |  Acc: 45.540,64.040,72.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.777 |  Acc: 48.668,74.122,90.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 2.780 |  Acc: 44.870,64.160,71.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.776 |  Acc: 48.720,74.050,90.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 2.766 |  Acc: 45.820,64.310,71.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.767 |  Acc: 48.656,74.158,90.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 2.776 |  Acc: 45.090,64.070,71.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.761 |  Acc: 48.758,74.312,90.636,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 2.776 |  Acc: 45.750,64.300,71.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.749 |  Acc: 48.970,74.342,90.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 2.796 |  Acc: 45.510,63.820,71.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.743 |  Acc: 48.920,74.428,90.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 2.796 |  Acc: 45.110,64.220,71.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.732 |  Acc: 48.998,74.536,91.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 2.838 |  Acc: 45.130,64.270,70.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.729 |  Acc: 49.136,74.668,91.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 2.797 |  Acc: 45.760,64.150,71.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.722 |  Acc: 48.898,74.806,91.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 2.838 |  Acc: 45.220,63.970,71.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.709 |  Acc: 49.074,74.752,91.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 2.835 |  Acc: 45.380,63.810,71.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.717 |  Acc: 49.060,74.572,91.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 2.826 |  Acc: 45.270,64.520,71.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.704 |  Acc: 49.188,74.746,91.766,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 2.843 |  Acc: 44.730,64.290,71.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.691 |  Acc: 49.162,74.996,91.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 2.819 |  Acc: 45.430,64.460,71.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.690 |  Acc: 49.222,75.012,92.036,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 2.851 |  Acc: 45.400,64.000,70.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.689 |  Acc: 49.220,75.104,92.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 2.875 |  Acc: 45.130,64.210,71.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.681 |  Acc: 49.420,75.044,92.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 2.869 |  Acc: 45.680,64.210,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.675 |  Acc: 49.424,75.214,92.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 2.931 |  Acc: 44.660,63.350,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.668 |  Acc: 49.302,75.196,92.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 2.866 |  Acc: 45.690,64.120,70.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.670 |  Acc: 49.482,75.206,92.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 2.860 |  Acc: 45.600,64.000,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.664 |  Acc: 49.592,75.290,92.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 2.898 |  Acc: 44.420,63.910,70.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.666 |  Acc: 49.566,74.982,92.304,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 2.899 |  Acc: 45.070,64.140,70.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.656 |  Acc: 49.534,75.492,92.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 2.890 |  Acc: 44.970,63.560,70.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.655 |  Acc: 49.318,75.170,92.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 2.884 |  Acc: 46.000,63.900,70.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.648 |  Acc: 49.650,75.352,92.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 2.913 |  Acc: 45.480,63.640,70.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.643 |  Acc: 49.472,75.548,92.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 2.871 |  Acc: 46.050,64.500,70.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.641 |  Acc: 49.766,75.404,93.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 2.884 |  Acc: 46.080,64.240,70.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.630 |  Acc: 49.850,75.870,93.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 2.961 |  Acc: 45.300,63.580,70.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.632 |  Acc: 49.672,75.750,93.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 2.955 |  Acc: 44.960,63.200,69.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.637 |  Acc: 49.708,75.574,92.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 2.934 |  Acc: 45.720,63.170,70.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.630 |  Acc: 49.752,75.748,93.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 2.927 |  Acc: 45.700,63.930,69.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.627 |  Acc: 49.790,75.654,93.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 2.913 |  Acc: 46.150,64.190,70.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.620 |  Acc: 49.706,75.814,93.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 2.979 |  Acc: 44.020,63.680,69.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.620 |  Acc: 49.816,75.850,93.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 2.998 |  Acc: 45.020,63.540,69.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.614 |  Acc: 49.758,75.872,93.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 2.929 |  Acc: 46.150,63.940,70.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.619 |  Acc: 49.610,75.822,93.230,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 2.985 |  Acc: 44.840,63.400,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.617 |  Acc: 49.548,75.812,93.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 2.974 |  Acc: 45.080,63.420,69.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.612 |  Acc: 49.930,75.846,93.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 3.048 |  Acc: 44.630,62.590,69.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.607 |  Acc: 49.922,75.976,93.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 2.952 |  Acc: 46.440,63.830,69.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.609 |  Acc: 50.016,75.892,93.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 2.985 |  Acc: 45.140,63.420,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.603 |  Acc: 49.640,76.012,93.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 2.970 |  Acc: 45.290,63.560,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.595 |  Acc: 49.796,76.232,93.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 2.980 |  Acc: 45.060,63.550,69.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.598 |  Acc: 50.038,76.158,93.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 2.982 |  Acc: 45.870,63.210,69.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.598 |  Acc: 49.736,75.962,93.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 2.957 |  Acc: 45.710,63.730,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.606 |  Acc: 49.746,76.010,93.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 2.992 |  Acc: 45.120,63.330,69.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.594 |  Acc: 49.856,76.094,93.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 2.975 |  Acc: 45.770,63.480,69.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.594 |  Acc: 50.036,76.286,93.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 2.980 |  Acc: 45.220,63.810,70.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.590 |  Acc: 50.148,76.188,93.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 3.008 |  Acc: 45.460,63.220,69.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.588 |  Acc: 49.982,76.162,93.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 2.961 |  Acc: 46.060,63.840,69.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.592 |  Acc: 50.116,76.216,93.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 3.020 |  Acc: 45.520,62.910,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.581 |  Acc: 50.170,76.448,94.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 3.058 |  Acc: 44.190,63.250,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.586 |  Acc: 50.066,76.522,93.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 3.024 |  Acc: 45.120,62.830,68.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.581 |  Acc: 50.072,76.382,93.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 3.066 |  Acc: 43.940,62.220,69.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.587 |  Acc: 50.088,76.162,93.662,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 3.047 |  Acc: 44.970,62.980,69.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.585 |  Acc: 50.040,76.296,93.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 3.069 |  Acc: 45.070,62.900,69.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.585 |  Acc: 50.184,76.534,93.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 3.013 |  Acc: 45.470,63.780,69.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.581 |  Acc: 50.136,76.414,93.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 3.032 |  Acc: 45.540,62.970,69.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.582 |  Acc: 49.882,76.574,93.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 3.006 |  Acc: 45.830,63.190,69.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.581 |  Acc: 49.944,76.394,93.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 3.028 |  Acc: 46.390,63.100,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.578 |  Acc: 50.244,76.514,93.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 3.011 |  Acc: 45.740,63.630,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.572 |  Acc: 49.980,76.498,93.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 3.042 |  Acc: 45.450,63.010,69.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.565 |  Acc: 50.098,76.764,94.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 3.025 |  Acc: 46.090,63.540,69.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.498 |  Acc: 50.722,77.996,95.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 2.871 |  Acc: 47.090,65.110,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.468 |  Acc: 51.166,78.704,96.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 2.876 |  Acc: 47.020,64.840,70.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.456 |  Acc: 51.164,78.710,96.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 2.880 |  Acc: 47.430,64.970,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.455 |  Acc: 51.070,78.770,96.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 2.880 |  Acc: 47.530,64.920,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.445 |  Acc: 51.296,79.042,96.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 2.875 |  Acc: 47.450,65.180,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.449 |  Acc: 51.304,78.820,96.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 2.876 |  Acc: 47.390,65.200,70.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.444 |  Acc: 51.154,78.972,96.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 2.878 |  Acc: 47.100,65.240,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.440 |  Acc: 51.340,79.022,96.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 2.870 |  Acc: 47.220,65.180,70.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.442 |  Acc: 51.232,78.806,96.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 2.879 |  Acc: 47.250,65.250,70.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.437 |  Acc: 51.060,78.992,96.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 2.883 |  Acc: 47.370,65.130,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.435 |  Acc: 51.386,78.952,96.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 2.877 |  Acc: 47.270,64.890,70.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.437 |  Acc: 51.298,78.854,96.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 2.875 |  Acc: 47.420,65.200,71.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.430 |  Acc: 51.370,79.222,96.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 2.891 |  Acc: 47.200,65.190,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.433 |  Acc: 51.354,79.154,96.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 2.873 |  Acc: 47.400,65.190,70.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.431 |  Acc: 51.444,79.164,96.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 2.879 |  Acc: 47.370,65.310,70.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.433 |  Acc: 51.390,79.218,96.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 2.884 |  Acc: 47.510,65.360,70.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.425 |  Acc: 51.310,79.270,96.954,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 2.889 |  Acc: 47.260,65.280,70.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.424 |  Acc: 51.374,79.086,96.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 2.882 |  Acc: 47.270,65.210,70.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.429 |  Acc: 51.332,79.320,96.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 2.883 |  Acc: 47.360,64.940,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.423 |  Acc: 51.378,79.354,96.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 2.896 |  Acc: 47.400,65.260,70.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.424 |  Acc: 51.414,79.374,96.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 2.888 |  Acc: 47.570,65.070,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.421 |  Acc: 51.282,79.342,97.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 2.891 |  Acc: 47.490,65.230,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.421 |  Acc: 51.746,79.264,96.994,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 2.893 |  Acc: 47.550,64.950,70.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.426 |  Acc: 51.308,79.184,96.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 2.900 |  Acc: 47.540,65.020,70.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.423 |  Acc: 51.264,79.198,96.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 2.898 |  Acc: 47.540,65.430,70.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.419 |  Acc: 51.628,79.246,97.146,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 2.897 |  Acc: 47.490,65.360,70.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.416 |  Acc: 51.608,79.236,96.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 2.900 |  Acc: 47.550,65.070,70.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.415 |  Acc: 51.350,79.404,97.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 2.896 |  Acc: 47.690,65.140,70.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.416 |  Acc: 51.534,79.238,97.150,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 2.913 |  Acc: 47.550,65.020,70.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.417 |  Acc: 51.322,79.192,97.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 2.911 |  Acc: 47.370,65.080,70.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.416 |  Acc: 51.424,79.234,97.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 2.900 |  Acc: 47.450,65.020,70.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.410 |  Acc: 51.456,79.442,97.152,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 2.907 |  Acc: 47.300,65.230,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.414 |  Acc: 51.520,79.450,97.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 2.897 |  Acc: 47.400,65.220,70.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.410 |  Acc: 51.648,79.606,97.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 2.909 |  Acc: 47.590,65.350,70.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.416 |  Acc: 51.446,79.386,97.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 2.894 |  Acc: 47.830,65.400,70.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.413 |  Acc: 51.646,79.350,97.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 2.906 |  Acc: 47.500,64.950,70.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.406 |  Acc: 51.638,79.472,97.292,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 2.911 |  Acc: 47.460,65.180,70.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.401 |  Acc: 51.736,79.630,97.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 2.913 |  Acc: 47.440,65.070,70.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.402 |  Acc: 51.596,79.606,97.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 2.914 |  Acc: 47.520,65.030,70.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.406 |  Acc: 51.558,79.676,97.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 2.901 |  Acc: 47.680,65.410,70.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.403 |  Acc: 51.592,79.678,97.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 2.908 |  Acc: 47.590,65.120,70.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.398 |  Acc: 51.760,79.692,97.318,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 2.918 |  Acc: 47.690,65.300,70.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.403 |  Acc: 51.694,79.604,97.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 2.912 |  Acc: 47.410,65.000,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.403 |  Acc: 51.580,79.766,97.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 2.912 |  Acc: 47.550,65.230,70.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.401 |  Acc: 51.570,79.672,97.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 2.903 |  Acc: 47.510,65.160,70.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.399 |  Acc: 51.552,79.734,97.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 2.904 |  Acc: 47.540,65.260,70.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.402 |  Acc: 51.456,79.650,97.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 2.900 |  Acc: 47.780,65.090,70.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.400 |  Acc: 51.648,79.680,97.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 2.897 |  Acc: 47.590,65.100,70.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.401 |  Acc: 51.788,79.602,97.292,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 2.908 |  Acc: 47.450,65.180,70.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.401 |  Acc: 51.614,79.754,97.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 2.907 |  Acc: 47.760,65.270,70.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.400 |  Acc: 51.552,79.642,97.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 2.906 |  Acc: 47.650,65.120,70.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.400 |  Acc: 51.590,79.736,97.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 2.906 |  Acc: 47.520,65.170,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.396 |  Acc: 51.466,79.806,97.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 2.913 |  Acc: 47.540,64.960,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.394 |  Acc: 51.792,79.782,97.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 2.908 |  Acc: 47.540,65.050,70.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.402 |  Acc: 51.470,79.598,97.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 2.910 |  Acc: 47.710,65.250,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.400 |  Acc: 51.598,79.622,97.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 2.909 |  Acc: 47.520,65.050,70.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.403 |  Acc: 51.828,79.490,97.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 2.905 |  Acc: 47.610,65.370,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.400 |  Acc: 51.898,79.638,97.278,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 2.898 |  Acc: 47.500,64.980,70.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.396 |  Acc: 51.602,79.814,97.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 2.909 |  Acc: 47.570,65.410,70.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.404 |  Acc: 51.694,79.746,97.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 2.894 |  Acc: 47.840,65.270,70.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.400 |  Acc: 51.748,79.710,97.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 2.906 |  Acc: 47.550,65.190,70.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.392 |  Acc: 51.728,79.994,97.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 2.905 |  Acc: 47.320,65.140,70.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.408 |  Acc: 51.592,79.544,97.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 2.904 |  Acc: 47.560,65.210,70.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.397 |  Acc: 51.848,79.836,97.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 2.913 |  Acc: 47.460,65.330,70.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.401 |  Acc: 51.680,79.686,97.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 2.912 |  Acc: 47.480,65.290,70.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.396 |  Acc: 51.722,79.838,97.432,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 2.903 |  Acc: 47.500,65.160,70.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.401 |  Acc: 51.526,79.798,97.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 2.909 |  Acc: 47.620,65.030,70.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.396 |  Acc: 51.746,79.740,97.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 2.906 |  Acc: 47.600,65.150,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.396 |  Acc: 51.626,79.842,97.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 2.908 |  Acc: 47.520,65.220,70.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.399 |  Acc: 51.674,79.694,97.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 2.913 |  Acc: 47.530,65.140,70.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.398 |  Acc: 51.590,79.804,97.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 2.901 |  Acc: 47.740,65.290,70.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.399 |  Acc: 51.476,79.816,97.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 2.900 |  Acc: 47.610,65.260,70.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.400 |  Acc: 51.640,79.862,97.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 2.909 |  Acc: 47.570,65.220,70.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.397 |  Acc: 51.634,79.778,97.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 2.910 |  Acc: 47.600,65.140,70.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=2.0, adaptive=0, attention='no', backend='resnet56_2con3_conv', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.397 |  Acc: 51.822,79.790,97.298,% | Adaptive Acc:88.928% | clf_exit: 0.305 0.447 0.249
Testing: Epoch=299 | Loss: 2.912 |  Acc: 47.550,65.500,70.660,% | Adaptive Acc:65.990% | clf_exit: 0.377 0.374 0.249

circles: 0
Testing: Epoch=299 | Loss: 6.872 |  Acc: 47.550,6.390,16.350,% | Adaptive Acc:38.660% | clf_exit: 0.377 0.013 0.610
circles: 1
Testing: Epoch=299 | Loss: 5.025 |  Acc: 47.550,29.520,45.550,% | Adaptive Acc:52.430% | clf_exit: 0.377 0.034 0.589
circles: 2
Testing: Epoch=299 | Loss: 3.846 |  Acc: 47.550,50.390,60.780,% | Adaptive Acc:59.580% | clf_exit: 0.377 0.111 0.512
circles: 3
Testing: Epoch=299 | Loss: 3.166 |  Acc: 47.550,60.390,66.850,% | Adaptive Acc:63.870% | clf_exit: 0.377 0.224 0.400
circles: 4
Testing: Epoch=299 | Loss: 2.891 |  Acc: 47.550,64.490,69.800,% | Adaptive Acc:65.720% | clf_exit: 0.377 0.312 0.311
circles: 5
Testing: Epoch=299 | Loss: 2.912 |  Acc: 47.550,65.500,70.660,% | Adaptive Acc:65.990% | clf_exit: 0.377 0.374 0.249
