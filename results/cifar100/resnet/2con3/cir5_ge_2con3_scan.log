==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=16, out_features=16, bias=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (BN1d): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): ScanLayer(
        (conv): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (deconv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
        (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_h): Linear(in_features=48, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=48, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=96, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=96, out_features=100, bias=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.137 | Acc: 0.781,0.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.578 | Acc: 0.707,1.600,1.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.372 | Acc: 0.934,1.296,1.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.271 | Acc: 1.204,1.165,1.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.198 | Acc: 1.273,1.244,1.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.145 | Acc: 1.377,1.207,1.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 14.105 | Acc: 1.427,1.220,1.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 14.068 | Acc: 1.463,1.285,1.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 14.032 | Acc: 1.524,1.334,1.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.991 | Acc: 1.502,1.437,2.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.950 | Acc: 1.578,1.512,2.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.907 | Acc: 1.644,1.672,2.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.867 | Acc: 1.763,1.789,2.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.826 | Acc: 1.841,1.868,2.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.789 | Acc: 1.891,1.941,2.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.750 | Acc: 1.923,2.014,3.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.711 | Acc: 1.976,2.093,3.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.674 | Acc: 2.007,2.181,3.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.640 | Acc: 2.047,2.290,3.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.606 | Acc: 2.075,2.387,3.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.946 | Acc: 0.781,5.469,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.066 | Acc: 2.418,3.609,6.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.058 | Acc: 2.706,3.582,6.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.070 | Acc: 2.728,3.765,6.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 12.900 | Acc: 3.906,1.562,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.892 | Acc: 2.530,4.241,7.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.874 | Acc: 2.668,4.135,7.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.867 | Acc: 2.638,4.290,8.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.844 | Acc: 2.836,4.360,8.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.813 | Acc: 2.986,4.641,8.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.805 | Acc: 2.957,4.720,8.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.777 | Acc: 3.086,4.898,8.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.750 | Acc: 3.251,5.066,8.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.728 | Acc: 3.289,5.214,8.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.704 | Acc: 3.448,5.329,8.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.687 | Acc: 3.471,5.395,8.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.670 | Acc: 3.475,5.433,8.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.650 | Acc: 3.517,5.541,9.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.628 | Acc: 3.564,5.677,9.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.610 | Acc: 3.584,5.759,9.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.592 | Acc: 3.612,5.846,9.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.571 | Acc: 3.675,5.945,9.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.553 | Acc: 3.714,6.012,9.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.534 | Acc: 3.777,6.088,9.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.225 | Acc: 3.906,6.250,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.367 | Acc: 4.650,6.622,7.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.341 | Acc: 4.268,6.574,8.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.341 | Acc: 4.380,6.685,8.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 12.247 | Acc: 3.906,8.594,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.179 | Acc: 4.129,7.068,12.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.105 | Acc: 4.364,7.527,12.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.100 | Acc: 4.393,7.825,12.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.077 | Acc: 4.659,7.899,12.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.067 | Acc: 4.788,7.905,12.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.058 | Acc: 4.952,8.038,12.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.032 | Acc: 5.053,8.150,12.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.020 | Acc: 5.100,8.138,12.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.015 | Acc: 5.184,8.132,12.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.999 | Acc: 5.236,8.302,12.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.995 | Acc: 5.317,8.346,12.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.986 | Acc: 5.307,8.377,12.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.981 | Acc: 5.331,8.387,12.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.963 | Acc: 5.396,8.435,12.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.954 | Acc: 5.466,8.495,12.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.946 | Acc: 5.527,8.552,12.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.937 | Acc: 5.551,8.557,12.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.927 | Acc: 5.627,8.553,12.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.917 | Acc: 5.641,8.608,12.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.795 | Acc: 5.469,10.156,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.770 | Acc: 7.552,7.812,11.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.740 | Acc: 7.412,8.460,11.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.745 | Acc: 7.390,8.581,12.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 11.320 | Acc: 11.719,14.062,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.607 | Acc: 7.254,9.784,14.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.628 | Acc: 7.279,9.204,14.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.610 | Acc: 7.454,9.644,14.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.592 | Acc: 7.581,9.809,14.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.598 | Acc: 7.580,9.785,14.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.591 | Acc: 7.567,9.588,14.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.573 | Acc: 7.657,9.641,14.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.568 | Acc: 7.648,9.569,14.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.542 | Acc: 7.748,9.781,14.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.516 | Acc: 7.824,9.942,14.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.501 | Acc: 7.954,10.043,14.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.490 | Acc: 7.968,10.056,14.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.469 | Acc: 8.004,10.135,15.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.451 | Acc: 8.124,10.259,15.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.435 | Acc: 8.220,10.364,15.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.427 | Acc: 8.207,10.412,15.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.409 | Acc: 8.278,10.546,15.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.395 | Acc: 8.323,10.648,15.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.382 | Acc: 8.362,10.689,15.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.588 | Acc: 10.156,11.719,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.424 | Acc: 7.850,10.528,15.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.397 | Acc: 7.927,9.680,15.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.391 | Acc: 7.825,9.939,15.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 11.071 | Acc: 7.812,15.625,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.054 | Acc: 9.152,11.830,18.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.032 | Acc: 9.432,11.852,18.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.072 | Acc: 9.465,11.527,17.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.033 | Acc: 9.587,11.883,17.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.999 | Acc: 9.862,12.106,17.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.992 | Acc: 10.021,12.035,17.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.968 | Acc: 10.162,12.267,18.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.943 | Acc: 10.355,12.476,18.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.930 | Acc: 10.381,12.517,18.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.923 | Acc: 10.463,12.488,18.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.913 | Acc: 10.535,12.493,18.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.900 | Acc: 10.587,12.613,18.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.892 | Acc: 10.635,12.611,18.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.885 | Acc: 10.676,12.608,18.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.875 | Acc: 10.735,12.661,18.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.863 | Acc: 10.804,12.768,18.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.847 | Acc: 10.894,12.796,18.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.834 | Acc: 10.942,12.840,18.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.814 | Acc: 11.050,12.951,18.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.965 | Acc: 11.719,10.938,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.074 | Acc: 11.012,11.756,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.064 | Acc: 10.823,11.300,16.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.064 | Acc: 10.707,11.155,15.945,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 9.845 | Acc: 16.406,21.094,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.429 | Acc: 12.723,14.844,20.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.440 | Acc: 12.862,14.444,20.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.436 | Acc: 12.756,14.613,20.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.403 | Acc: 12.876,14.882,20.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.396 | Acc: 12.964,15.014,20.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.395 | Acc: 13.055,15.096,20.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.386 | Acc: 13.154,15.165,20.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.378 | Acc: 13.310,15.203,21.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.378 | Acc: 13.225,15.224,21.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.364 | Acc: 13.421,15.178,21.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.363 | Acc: 13.391,15.208,21.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.349 | Acc: 13.414,15.327,21.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.335 | Acc: 13.401,15.412,21.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.318 | Acc: 13.512,15.511,21.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.304 | Acc: 13.590,15.586,21.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.303 | Acc: 13.588,15.625,21.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.287 | Acc: 13.678,15.737,21.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.279 | Acc: 13.692,15.692,21.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.266 | Acc: 13.780,15.707,21.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.604 | Acc: 16.406,10.156,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.520 | Acc: 14.881,11.310,21.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.472 | Acc: 14.996,11.395,20.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.487 | Acc: 15.343,11.424,20.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 9.915 | Acc: 15.625,20.312,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.856 | Acc: 16.109,17.597,24.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.924 | Acc: 15.492,16.978,23.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.961 | Acc: 15.292,16.714,23.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.923 | Acc: 15.374,16.917,23.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.916 | Acc: 15.455,17.149,23.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.881 | Acc: 15.670,17.504,24.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.882 | Acc: 15.664,17.514,24.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.878 | Acc: 15.707,17.697,24.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.874 | Acc: 15.638,17.680,24.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.872 | Acc: 15.594,17.732,24.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.870 | Acc: 15.590,17.771,24.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.862 | Acc: 15.680,17.868,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.851 | Acc: 15.847,17.936,24.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.833 | Acc: 15.986,18.052,24.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.826 | Acc: 15.965,18.096,24.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.823 | Acc: 16.031,18.159,24.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.807 | Acc: 16.134,18.196,24.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.796 | Acc: 16.160,18.250,24.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.789 | Acc: 16.162,18.270,24.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.086 | Acc: 13.281,14.062,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.015 | Acc: 13.579,15.551,23.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.976 | Acc: 13.681,16.292,23.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.993 | Acc: 13.691,16.406,23.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 9.594 | Acc: 15.625,18.750,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.595 | Acc: 16.927,19.308,25.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.591 | Acc: 16.711,18.902,25.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.558 | Acc: 16.586,19.109,26.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.543 | Acc: 16.946,19.502,26.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.540 | Acc: 17.017,19.500,26.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.516 | Acc: 17.233,19.589,26.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.502 | Acc: 17.293,19.747,26.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.505 | Acc: 17.202,19.837,26.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.504 | Acc: 17.326,19.795,26.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.509 | Acc: 17.324,19.729,26.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.497 | Acc: 17.308,19.871,26.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.481 | Acc: 17.482,20.047,26.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.463 | Acc: 17.583,20.181,27.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.448 | Acc: 17.649,20.249,27.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.437 | Acc: 17.621,20.261,27.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.431 | Acc: 17.686,20.264,27.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.422 | Acc: 17.733,20.333,27.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.418 | Acc: 17.731,20.321,27.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.406 | Acc: 17.825,20.411,27.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.145 | Acc: 16.406,17.969,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.421 | Acc: 13.356,16.443,24.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.383 | Acc: 13.700,15.892,24.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.376 | Acc: 13.614,16.163,23.873,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 9.111 | Acc: 16.406,23.438,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.193 | Acc: 18.341,22.061,29.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.197 | Acc: 18.102,22.027,29.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.148 | Acc: 18.494,21.977,29.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.126 | Acc: 18.991,22.367,29.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.116 | Acc: 19.121,21.983,29.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.123 | Acc: 19.002,21.965,29.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.116 | Acc: 18.972,21.969,29.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.113 | Acc: 18.964,21.987,29.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.090 | Acc: 19.082,22.272,29.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.082 | Acc: 19.104,22.341,29.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.100 | Acc: 19.086,22.229,29.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.113 | Acc: 19.032,22.144,29.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.111 | Acc: 19.157,22.219,29.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.102 | Acc: 19.214,22.289,29.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.091 | Acc: 19.259,22.381,29.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.077 | Acc: 19.434,22.520,29.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.069 | Acc: 19.453,22.567,30.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.061 | Acc: 19.468,22.606,30.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.050 | Acc: 19.593,22.736,30.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.583 | Acc: 24.219,22.656,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.477 | Acc: 19.159,18.787,26.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.462 | Acc: 19.436,18.559,26.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.480 | Acc: 19.480,18.545,26.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 8.386 | Acc: 25.781,28.906,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.764 | Acc: 21.280,23.847,31.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.781 | Acc: 21.456,23.666,31.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.760 | Acc: 21.440,23.847,32.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.785 | Acc: 21.046,23.949,32.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.787 | Acc: 21.117,24.110,32.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.757 | Acc: 21.346,24.283,32.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.755 | Acc: 21.343,24.413,32.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.747 | Acc: 21.288,24.369,32.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.742 | Acc: 21.327,24.417,32.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.741 | Acc: 21.331,24.374,32.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.745 | Acc: 21.324,24.346,32.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.741 | Acc: 21.382,24.439,32.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.739 | Acc: 21.354,24.389,32.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.742 | Acc: 21.277,24.338,32.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.731 | Acc: 21.382,24.346,32.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.726 | Acc: 21.422,24.365,32.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.720 | Acc: 21.360,24.349,32.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.715 | Acc: 21.388,24.405,32.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.708 | Acc: 21.455,24.483,32.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.685 | Acc: 15.625,22.656,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.533 | Acc: 16.667,19.680,29.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.527 | Acc: 16.521,19.245,29.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.589 | Acc: 16.086,19.032,28.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 8.765 | Acc: 21.094,24.219,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.500 | Acc: 21.689,25.372,35.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.436 | Acc: 22.237,25.934,35.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.458 | Acc: 22.118,25.743,35.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.521 | Acc: 22.010,25.569,34.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.497 | Acc: 22.517,26.067,35.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.496 | Acc: 22.566,26.065,35.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.476 | Acc: 22.645,26.241,34.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.458 | Acc: 22.729,26.441,34.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.452 | Acc: 22.829,26.459,34.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.445 | Acc: 22.757,26.438,34.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.442 | Acc: 22.794,26.340,34.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.438 | Acc: 22.805,26.456,34.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.434 | Acc: 22.845,26.383,34.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.434 | Acc: 22.809,26.340,34.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.429 | Acc: 22.773,26.383,34.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.423 | Acc: 22.839,26.443,34.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.419 | Acc: 22.874,26.439,34.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.420 | Acc: 22.892,26.480,34.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.421 | Acc: 22.902,26.509,34.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.476 | Acc: 17.969,25.781,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.355 | Acc: 18.713,20.424,28.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.338 | Acc: 19.112,20.465,28.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.380 | Acc: 19.032,19.839,28.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 8.131 | Acc: 25.781,23.438,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.345 | Acc: 24.293,27.455,36.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.303 | Acc: 23.857,26.925,36.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.275 | Acc: 23.950,27.280,36.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.268 | Acc: 23.736,27.382,36.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.280 | Acc: 23.484,27.452,36.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.266 | Acc: 23.799,27.712,36.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.253 | Acc: 23.969,27.737,36.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.229 | Acc: 24.112,27.984,36.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.224 | Acc: 24.089,28.000,36.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.211 | Acc: 24.180,28.063,36.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.205 | Acc: 24.282,28.107,36.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.197 | Acc: 24.335,28.093,36.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.193 | Acc: 24.279,28.053,36.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.191 | Acc: 24.230,27.972,36.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.186 | Acc: 24.281,27.946,36.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.183 | Acc: 24.348,28.015,36.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.175 | Acc: 24.388,28.125,36.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.171 | Acc: 24.355,28.151,36.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.160 | Acc: 24.407,28.197,36.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.908 | Acc: 23.438,27.344,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.032 | Acc: 18.787,22.917,34.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.008 | Acc: 19.150,22.599,34.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.057 | Acc: 19.057,22.964,33.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 8.691 | Acc: 22.656,25.781,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.003 | Acc: 26.004,30.208,38.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.070 | Acc: 25.819,29.497,38.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.067 | Acc: 25.115,28.996,37.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.041 | Acc: 24.990,29.253,38.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.022 | Acc: 24.985,29.278,38.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.006 | Acc: 25.116,29.352,38.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.004 | Acc: 25.039,29.494,38.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.983 | Acc: 25.097,29.542,38.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.976 | Acc: 25.276,29.709,38.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.974 | Acc: 25.210,29.571,38.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.960 | Acc: 25.216,29.627,38.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.950 | Acc: 25.363,29.778,38.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.949 | Acc: 25.440,29.867,38.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.944 | Acc: 25.495,29.882,38.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.956 | Acc: 25.493,29.833,38.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.950 | Acc: 25.533,29.773,38.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.943 | Acc: 25.559,29.846,38.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.936 | Acc: 25.550,29.863,38.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.931 | Acc: 25.562,29.907,38.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.591 | Acc: 20.312,24.219,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.915 | Acc: 18.601,25.372,32.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.879 | Acc: 18.712,24.867,32.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.904 | Acc: 18.750,24.654,32.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 7.316 | Acc: 28.125,33.594,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.661 | Acc: 27.009,32.254,39.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.740 | Acc: 26.925,31.479,39.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.785 | Acc: 26.089,30.725,39.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.775 | Acc: 26.157,30.642,39.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.803 | Acc: 26.006,30.492,39.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.774 | Acc: 26.091,30.624,39.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.773 | Acc: 26.247,30.818,39.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.771 | Acc: 26.334,30.973,39.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.763 | Acc: 26.355,30.991,39.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.742 | Acc: 26.547,31.153,39.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.757 | Acc: 26.524,31.147,39.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.759 | Acc: 26.446,31.214,39.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.750 | Acc: 26.488,31.232,39.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.748 | Acc: 26.496,31.222,39.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.742 | Acc: 26.518,31.310,39.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.740 | Acc: 26.604,31.374,39.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.729 | Acc: 26.654,31.539,39.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.724 | Acc: 26.695,31.596,39.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.727 | Acc: 26.673,31.566,39.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.015 | Acc: 28.906,34.375,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.173 | Acc: 23.810,28.311,37.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.158 | Acc: 23.761,27.801,37.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.157 | Acc: 23.719,27.907,37.410,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 7.927 | Acc: 24.219,31.250,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.687 | Acc: 26.525,32.440,41.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.561 | Acc: 27.058,33.327,41.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.524 | Acc: 27.216,33.261,42.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.519 | Acc: 27.527,33.295,42.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.534 | Acc: 27.197,32.805,41.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.514 | Acc: 27.447,32.993,41.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.515 | Acc: 27.394,33.078,41.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.493 | Acc: 27.596,33.327,42.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.505 | Acc: 27.534,33.257,41.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.512 | Acc: 27.495,33.252,41.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.526 | Acc: 27.524,33.223,41.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.513 | Acc: 27.584,33.325,41.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.500 | Acc: 27.736,33.456,42.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.501 | Acc: 27.691,33.427,41.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.496 | Acc: 27.697,33.456,42.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.491 | Acc: 27.699,33.586,42.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.499 | Acc: 27.662,33.525,42.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.502 | Acc: 27.632,33.473,42.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.505 | Acc: 27.629,33.444,41.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.545 | Acc: 25.781,25.781,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.646 | Acc: 23.400,25.260,37.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.598 | Acc: 23.438,23.990,37.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.595 | Acc: 23.015,24.091,36.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 7.298 | Acc: 28.125,35.938,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.209 | Acc: 29.129,35.491,43.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.309 | Acc: 28.659,34.356,43.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.325 | Acc: 28.432,34.375,43.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.331 | Acc: 28.193,34.394,43.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.341 | Acc: 28.171,34.127,42.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.334 | Acc: 28.073,34.291,42.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.328 | Acc: 28.191,34.342,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.330 | Acc: 28.392,34.210,42.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.352 | Acc: 28.250,34.060,42.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.350 | Acc: 28.343,34.091,43.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.355 | Acc: 28.273,34.082,42.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.358 | Acc: 28.303,34.138,42.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.358 | Acc: 28.332,34.231,42.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.375 | Acc: 28.186,34.097,42.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.370 | Acc: 28.169,34.154,42.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.373 | Acc: 28.198,34.231,42.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.360 | Acc: 28.311,34.405,42.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.354 | Acc: 28.413,34.464,42.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.342 | Acc: 28.492,34.588,43.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.640 | Acc: 31.250,32.812,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.812 | Acc: 26.079,32.664,41.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.815 | Acc: 25.076,32.184,41.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.835 | Acc: 24.769,31.903,40.689,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 8.301 | Acc: 27.344,33.594,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.135 | Acc: 29.315,36.570,45.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.144 | Acc: 28.792,36.090,44.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.211 | Acc: 28.701,35.912,44.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.201 | Acc: 29.061,36.314,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.197 | Acc: 29.076,36.162,44.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.177 | Acc: 29.294,36.364,44.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.196 | Acc: 29.012,36.065,44.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.198 | Acc: 29.125,35.976,44.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.186 | Acc: 29.075,35.989,44.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.167 | Acc: 29.221,36.252,44.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.167 | Acc: 29.263,36.337,44.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.163 | Acc: 29.263,36.349,44.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.161 | Acc: 29.247,36.303,44.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.168 | Acc: 29.223,36.318,44.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.169 | Acc: 29.225,36.283,44.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.165 | Acc: 29.186,36.300,44.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.163 | Acc: 29.200,36.373,44.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.159 | Acc: 29.268,36.427,44.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.156 | Acc: 29.368,36.469,44.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.246 | Acc: 28.125,30.469,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.986 | Acc: 24.330,30.990,40.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.000 | Acc: 24.219,30.335,39.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.992 | Acc: 24.091,30.251,39.447,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 6.858 | Acc: 33.594,29.688,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.141 | Acc: 29.948,35.491,44.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.068 | Acc: 30.145,37.062,45.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.093 | Acc: 29.726,36.975,45.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.099 | Acc: 29.919,37.047,45.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.067 | Acc: 29.950,37.144,45.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.043 | Acc: 30.075,37.526,45.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.029 | Acc: 30.136,37.611,45.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.020 | Acc: 30.313,37.704,45.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.024 | Acc: 30.223,37.647,45.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.025 | Acc: 30.092,37.539,45.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.015 | Acc: 30.225,37.684,45.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.003 | Acc: 30.206,37.779,45.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.998 | Acc: 30.232,37.853,45.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.005 | Acc: 30.141,37.820,45.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.004 | Acc: 30.100,37.824,45.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.998 | Acc: 30.167,37.885,45.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.998 | Acc: 30.141,37.841,45.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.986 | Acc: 30.153,37.879,46.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.987 | Acc: 30.108,37.865,46.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.359 | Acc: 28.125,42.969,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.499 | Acc: 25.856,35.119,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.499 | Acc: 25.514,34.318,43.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.506 | Acc: 25.423,33.722,42.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 6.328 | Acc: 36.719,41.406,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.809 | Acc: 31.027,40.365,48.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.781 | Acc: 31.307,40.149,47.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.807 | Acc: 31.327,39.882,47.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.830 | Acc: 31.067,39.583,47.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.836 | Acc: 30.948,39.457,47.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.818 | Acc: 30.972,39.230,47.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.827 | Acc: 30.812,39.074,47.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.819 | Acc: 31.051,39.242,47.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.838 | Acc: 30.965,39.183,47.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.835 | Acc: 31.005,39.206,47.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.837 | Acc: 30.925,39.080,47.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.839 | Acc: 30.913,39.050,47.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.830 | Acc: 30.945,39.125,47.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.833 | Acc: 30.989,39.146,47.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.835 | Acc: 31.022,39.148,47.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.853 | Acc: 30.926,38.989,47.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.858 | Acc: 31.019,39.026,47.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.853 | Acc: 31.012,39.011,47.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.850 | Acc: 31.094,39.058,47.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.545 | Acc: 28.125,39.844,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.787 | Acc: 27.269,33.594,38.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.820 | Acc: 27.382,33.155,38.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.896 | Acc: 27.305,33.069,37.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 6.832 | Acc: 35.156,41.406,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.696 | Acc: 31.473,40.811,48.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.718 | Acc: 30.640,40.301,48.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.741 | Acc: 30.277,40.100,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.776 | Acc: 30.363,39.680,48.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.758 | Acc: 30.840,39.844,48.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.734 | Acc: 31.244,40.050,48.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.732 | Acc: 31.106,39.977,48.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.726 | Acc: 31.095,39.965,48.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.740 | Acc: 30.991,39.896,48.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.733 | Acc: 31.157,39.960,48.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.729 | Acc: 31.229,40.028,48.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.716 | Acc: 31.312,40.148,48.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.718 | Acc: 31.301,40.185,48.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.720 | Acc: 31.283,40.113,48.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.734 | Acc: 31.167,40.025,48.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.739 | Acc: 31.116,40.029,48.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.741 | Acc: 31.149,40.034,48.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.740 | Acc: 31.252,40.086,48.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.742 | Acc: 31.250,40.110,48.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.089 | Acc: 25.781,39.844,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.726 | Acc: 23.661,33.408,42.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.825 | Acc: 23.190,32.508,41.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.856 | Acc: 23.527,32.159,41.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 6.036 | Acc: 32.031,43.750,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.406 | Acc: 32.589,42.932,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.433 | Acc: 32.260,42.550,50.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.480 | Acc: 31.801,42.072,50.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.524 | Acc: 31.858,41.898,50.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.547 | Acc: 31.861,41.739,50.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.549 | Acc: 32.193,41.587,50.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.562 | Acc: 32.170,41.334,49.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.568 | Acc: 32.254,41.295,49.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.569 | Acc: 32.182,41.359,49.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.570 | Acc: 32.245,41.344,49.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.586 | Acc: 32.159,41.258,49.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.590 | Acc: 32.047,41.179,49.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.591 | Acc: 32.025,41.173,49.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.598 | Acc: 31.906,41.223,49.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.604 | Acc: 31.917,41.305,49.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.598 | Acc: 31.934,41.423,49.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.591 | Acc: 32.004,41.516,49.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.592 | Acc: 31.940,41.547,49.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.589 | Acc: 31.931,41.554,49.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.280 | Acc: 29.688,35.156,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.450 | Acc: 27.344,35.528,44.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.458 | Acc: 26.886,34.737,44.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.452 | Acc: 27.024,34.964,44.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 6.885 | Acc: 32.812,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.481 | Acc: 33.333,42.894,51.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.444 | Acc: 33.346,42.931,51.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.412 | Acc: 33.389,43.161,51.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.426 | Acc: 33.382,42.824,51.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.461 | Acc: 32.998,42.768,50.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.472 | Acc: 33.103,42.523,50.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.481 | Acc: 32.763,42.298,50.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.489 | Acc: 32.638,42.246,50.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.496 | Acc: 32.705,42.244,50.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.500 | Acc: 32.805,42.257,50.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.497 | Acc: 32.724,42.272,50.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.499 | Acc: 32.667,42.282,50.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.495 | Acc: 32.594,42.259,50.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.504 | Acc: 32.518,42.218,50.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.500 | Acc: 32.491,42.273,50.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.505 | Acc: 32.404,42.163,50.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.496 | Acc: 32.494,42.259,50.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.498 | Acc: 32.531,42.328,50.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.494 | Acc: 32.523,42.360,50.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.737 | Acc: 24.219,32.812,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.556 | Acc: 21.987,32.626,41.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.571 | Acc: 22.218,32.012,41.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.560 | Acc: 22.195,31.826,41.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 6.480 | Acc: 33.594,41.406,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.453 | Acc: 31.808,42.188,51.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.455 | Acc: 32.336,42.588,51.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.368 | Acc: 33.210,43.519,51.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.373 | Acc: 33.092,43.818,51.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.374 | Acc: 33.246,43.874,51.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.381 | Acc: 33.122,43.608,51.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.412 | Acc: 32.918,43.368,51.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.406 | Acc: 32.759,43.372,51.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.412 | Acc: 32.670,43.241,51.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.417 | Acc: 32.731,43.179,51.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.418 | Acc: 32.837,43.241,51.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.422 | Acc: 32.803,43.215,51.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.412 | Acc: 32.935,43.268,51.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.414 | Acc: 32.910,43.308,51.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.421 | Acc: 32.919,43.210,51.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.411 | Acc: 32.966,43.331,51.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.411 | Acc: 32.984,43.324,51.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.411 | Acc: 33.003,43.334,51.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.407 | Acc: 33.040,43.379,51.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.724 | Acc: 23.438,41.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.764 | Acc: 25.521,38.095,43.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.766 | Acc: 24.695,37.652,42.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.801 | Acc: 24.552,36.655,42.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 6.035 | Acc: 41.406,47.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.283 | Acc: 34.561,45.722,52.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.216 | Acc: 34.299,45.884,52.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.313 | Acc: 33.491,44.698,52.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.285 | Acc: 33.497,44.753,52.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.280 | Acc: 33.764,44.694,52.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.296 | Acc: 33.716,44.383,52.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.314 | Acc: 33.610,44.166,52.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.312 | Acc: 33.579,44.143,52.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.306 | Acc: 33.568,44.061,52.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.322 | Acc: 33.438,43.937,52.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.333 | Acc: 33.368,43.803,52.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.338 | Acc: 33.321,43.714,52.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.335 | Acc: 33.270,43.702,52.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.329 | Acc: 33.238,43.744,52.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.325 | Acc: 33.254,43.688,52.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.328 | Acc: 33.226,43.745,52.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.328 | Acc: 33.305,43.794,52.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.321 | Acc: 33.345,43.845,52.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.323 | Acc: 33.444,43.894,52.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.247 | Acc: 32.031,40.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.273 | Acc: 26.376,38.728,47.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.289 | Acc: 26.601,37.805,46.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.333 | Acc: 26.178,37.359,46.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 6.045 | Acc: 35.938,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.154 | Acc: 34.784,45.647,54.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.098 | Acc: 34.889,46.532,54.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.125 | Acc: 34.516,46.324,54.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.139 | Acc: 34.327,46.036,54.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.130 | Acc: 34.197,45.955,54.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.165 | Acc: 34.013,45.681,53.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.175 | Acc: 33.893,45.490,53.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.183 | Acc: 33.895,45.356,53.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.190 | Acc: 33.797,45.330,53.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.199 | Acc: 33.811,45.289,53.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.203 | Acc: 33.855,45.231,53.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.208 | Acc: 33.843,45.228,53.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.213 | Acc: 33.890,45.172,53.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.215 | Acc: 33.886,45.085,53.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.222 | Acc: 33.838,45.045,53.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.227 | Acc: 33.810,44.957,53.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.231 | Acc: 33.814,44.898,53.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.238 | Acc: 33.806,44.901,53.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.241 | Acc: 33.819,44.886,52.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.905 | Acc: 32.031,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.062 | Acc: 26.414,39.881,49.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.087 | Acc: 26.296,39.444,48.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.126 | Acc: 26.204,39.075,48.540,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 6.319 | Acc: 26.562,38.281,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.150 | Acc: 33.705,45.201,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.112 | Acc: 33.841,45.446,54.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.097 | Acc: 34.042,45.517,54.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.114 | Acc: 34.028,45.380,54.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.112 | Acc: 33.919,45.444,54.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.085 | Acc: 34.052,45.674,54.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.109 | Acc: 34.037,45.601,54.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.106 | Acc: 34.079,45.575,54.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.115 | Acc: 34.164,45.576,54.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.132 | Acc: 34.169,45.670,54.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.130 | Acc: 34.202,45.638,54.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.130 | Acc: 34.061,45.565,54.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.130 | Acc: 33.944,45.615,54.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.124 | Acc: 34.011,45.727,54.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.137 | Acc: 33.926,45.673,53.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.143 | Acc: 33.908,45.729,53.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.148 | Acc: 33.933,45.702,53.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.148 | Acc: 33.964,45.722,53.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.149 | Acc: 34.016,45.741,53.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.050 | Acc: 25.781,39.062,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.164 | Acc: 27.046,38.653,46.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.186 | Acc: 26.886,38.453,46.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.205 | Acc: 26.550,38.281,46.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 7.017 | Acc: 26.562,36.719,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.033 | Acc: 35.045,47.061,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.042 | Acc: 35.042,46.704,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.066 | Acc: 34.644,46.709,54.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.046 | Acc: 34.828,46.923,54.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.027 | Acc: 35.002,47.115,54.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.033 | Acc: 34.827,46.752,54.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.040 | Acc: 34.846,46.637,54.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.045 | Acc: 34.875,46.574,54.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.052 | Acc: 34.958,46.620,54.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.055 | Acc: 34.853,46.618,54.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.062 | Acc: 34.750,46.451,54.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.073 | Acc: 34.693,46.340,54.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.071 | Acc: 34.638,46.312,54.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.074 | Acc: 34.622,46.302,54.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.071 | Acc: 34.590,46.382,54.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.074 | Acc: 34.623,46.403,54.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.071 | Acc: 34.634,46.506,54.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.073 | Acc: 34.659,46.494,54.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.076 | Acc: 34.629,46.455,54.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.991 | Acc: 32.031,42.188,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.000 | Acc: 28.460,40.997,48.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.045 | Acc: 27.725,40.225,48.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.049 | Acc: 27.907,39.985,48.053,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 6.078 | Acc: 35.156,47.656,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.056 | Acc: 35.268,46.503,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.973 | Acc: 34.451,47.866,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.929 | Acc: 34.887,48.169,56.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.967 | Acc: 34.934,48.071,55.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.973 | Acc: 34.793,47.734,55.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.967 | Acc: 34.917,47.779,55.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.985 | Acc: 34.735,47.401,55.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.004 | Acc: 34.763,47.355,55.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.000 | Acc: 34.824,47.432,55.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.007 | Acc: 34.690,47.349,55.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.005 | Acc: 34.668,47.356,55.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.016 | Acc: 34.641,47.138,55.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.026 | Acc: 34.629,47.001,55.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.031 | Acc: 34.678,46.945,54.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.038 | Acc: 34.741,46.839,54.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.043 | Acc: 34.674,46.800,54.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.037 | Acc: 34.719,46.797,54.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.033 | Acc: 34.743,46.825,54.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.028 | Acc: 34.744,46.826,54.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.168 | Acc: 30.469,36.719,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.033 | Acc: 23.847,35.677,43.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.033 | Acc: 23.952,35.061,42.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.044 | Acc: 24.244,35.054,42.802,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 5.264 | Acc: 34.375,57.031,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.831 | Acc: 35.045,48.624,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.835 | Acc: 35.595,48.780,57.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.844 | Acc: 35.118,48.988,57.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.844 | Acc: 35.368,48.843,57.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.874 | Acc: 35.210,48.414,56.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.858 | Acc: 35.292,48.412,56.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.877 | Acc: 35.284,48.321,56.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.899 | Acc: 35.166,48.088,56.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.915 | Acc: 35.212,47.915,56.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.918 | Acc: 35.331,47.816,56.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.917 | Acc: 35.245,47.819,56.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.919 | Acc: 35.276,47.825,56.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.924 | Acc: 35.291,47.674,56.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.934 | Acc: 35.220,47.601,56.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.935 | Acc: 35.182,47.654,56.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.941 | Acc: 35.232,47.627,56.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.940 | Acc: 35.241,47.604,55.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.944 | Acc: 35.236,47.641,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.943 | Acc: 35.212,47.615,55.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.507 | Acc: 27.344,37.500,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.192 | Acc: 27.269,40.030,48.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.215 | Acc: 26.048,39.901,48.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.205 | Acc: 26.063,39.844,48.079,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 5.445 | Acc: 40.625,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.826 | Acc: 34.561,48.475,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.890 | Acc: 34.756,48.228,56.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.869 | Acc: 35.272,48.578,57.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.845 | Acc: 35.841,48.794,57.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.829 | Acc: 35.821,48.832,57.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.835 | Acc: 35.938,48.928,57.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.828 | Acc: 35.982,48.748,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.828 | Acc: 36.073,48.767,57.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.828 | Acc: 35.955,48.692,56.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.819 | Acc: 35.984,48.807,56.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.825 | Acc: 35.899,48.745,56.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.834 | Acc: 35.886,48.622,56.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.845 | Acc: 35.746,48.509,56.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.838 | Acc: 35.815,48.563,56.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.852 | Acc: 35.714,48.463,56.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.861 | Acc: 35.684,48.399,56.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.867 | Acc: 35.704,48.341,56.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.868 | Acc: 35.728,48.362,56.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.875 | Acc: 35.683,48.325,56.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.386 | Acc: 25.000,38.281,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.373 | Acc: 26.637,37.277,47.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.466 | Acc: 25.705,36.528,46.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.449 | Acc: 25.576,36.552,46.888,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 6.385 | Acc: 26.562,44.531,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.709 | Acc: 35.826,49.144,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.730 | Acc: 35.499,49.314,57.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.758 | Acc: 35.707,49.488,57.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.782 | Acc: 35.677,49.190,56.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.812 | Acc: 35.651,48.878,57.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.797 | Acc: 35.686,49.032,57.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.779 | Acc: 35.766,49.003,57.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.790 | Acc: 35.719,49.025,57.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.805 | Acc: 35.683,48.951,56.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.798 | Acc: 35.805,49.028,57.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.789 | Acc: 35.785,49.084,57.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.792 | Acc: 35.785,49.040,57.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.791 | Acc: 35.779,48.961,56.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.802 | Acc: 35.684,48.763,56.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.811 | Acc: 35.649,48.759,56.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.819 | Acc: 35.675,48.657,56.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.815 | Acc: 35.747,48.680,56.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.825 | Acc: 35.715,48.621,56.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.829 | Acc: 35.687,48.569,56.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.122 | Acc: 31.250,39.844,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.499 | Acc: 27.381,38.876,47.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.510 | Acc: 27.325,38.986,46.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.526 | Acc: 26.806,38.614,46.311,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 5.889 | Acc: 38.281,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.768 | Acc: 34.896,48.475,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.708 | Acc: 35.671,49.466,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.722 | Acc: 35.515,49.244,58.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.686 | Acc: 35.899,49.633,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.680 | Acc: 36.069,49.551,58.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.679 | Acc: 36.092,49.658,58.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.669 | Acc: 36.165,49.623,58.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.686 | Acc: 36.112,49.461,58.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.688 | Acc: 36.102,49.504,58.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.682 | Acc: 36.163,49.642,58.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.683 | Acc: 36.174,49.593,58.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.700 | Acc: 36.103,49.472,58.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.714 | Acc: 36.042,49.368,57.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.721 | Acc: 36.026,49.277,57.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.732 | Acc: 35.971,49.203,57.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.734 | Acc: 35.952,49.199,57.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.748 | Acc: 35.910,49.191,57.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.756 | Acc: 35.905,49.141,57.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.759 | Acc: 35.849,49.126,57.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.316 | Acc: 26.562,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.663 | Acc: 24.219,37.760,50.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.770 | Acc: 23.800,36.947,48.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.777 | Acc: 23.489,36.847,48.181,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 5.828 | Acc: 35.938,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.599 | Acc: 37.054,49.851,58.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.588 | Acc: 36.604,50.171,58.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.638 | Acc: 35.835,49.923,58.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.637 | Acc: 36.053,50.077,58.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.657 | Acc: 36.108,49.853,58.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.672 | Acc: 35.815,49.755,58.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.671 | Acc: 36.137,49.917,58.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.659 | Acc: 36.136,49.971,58.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.664 | Acc: 36.058,49.961,58.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.666 | Acc: 35.930,49.949,58.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.667 | Acc: 36.051,49.897,58.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.674 | Acc: 35.957,49.763,58.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.678 | Acc: 35.991,49.749,58.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.680 | Acc: 36.013,49.786,58.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.690 | Acc: 35.987,49.727,58.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.699 | Acc: 35.955,49.679,58.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.703 | Acc: 36.034,49.686,58.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.710 | Acc: 36.041,49.567,58.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.709 | Acc: 36.147,49.594,58.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.424 | Acc: 28.125,35.156,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.183 | Acc: 28.088,40.365,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.193 | Acc: 27.268,39.729,49.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.182 | Acc: 27.305,40.138,50.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 5.375 | Acc: 41.406,50.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.559 | Acc: 37.091,51.637,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.494 | Acc: 37.500,51.925,60.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.497 | Acc: 37.449,51.230,60.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.525 | Acc: 37.326,51.119,60.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.540 | Acc: 37.051,51.060,59.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.577 | Acc: 36.803,50.607,59.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.586 | Acc: 36.575,50.565,59.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.608 | Acc: 36.486,50.359,59.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.625 | Acc: 36.542,50.315,59.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.627 | Acc: 36.443,50.307,58.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.617 | Acc: 36.560,50.382,59.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.623 | Acc: 36.618,50.327,58.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.634 | Acc: 36.590,50.338,58.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.635 | Acc: 36.635,50.395,58.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.639 | Acc: 36.485,50.309,58.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.635 | Acc: 36.514,50.353,58.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.638 | Acc: 36.437,50.318,58.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.635 | Acc: 36.496,50.314,58.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.640 | Acc: 36.448,50.310,58.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.347 | Acc: 27.344,42.969,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.816 | Acc: 24.814,38.095,48.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.882 | Acc: 24.276,36.814,47.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.891 | Acc: 24.142,36.616,48.117,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.578 | Acc: 39.062,52.344,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.629 | Acc: 34.412,50.967,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.646 | Acc: 35.309,50.400,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.583 | Acc: 36.450,50.679,60.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.571 | Acc: 36.728,50.762,60.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.574 | Acc: 36.634,50.859,59.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.574 | Acc: 36.467,50.755,59.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.556 | Acc: 36.619,50.853,60.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.556 | Acc: 36.627,50.631,60.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.563 | Acc: 36.585,50.578,59.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.566 | Acc: 36.497,50.564,59.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.578 | Acc: 36.556,50.513,59.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.589 | Acc: 36.618,50.522,59.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.598 | Acc: 36.530,50.545,59.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.601 | Acc: 36.535,50.581,59.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.602 | Acc: 36.537,50.659,59.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.608 | Acc: 36.519,50.582,59.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.602 | Acc: 36.616,50.625,59.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.598 | Acc: 36.673,50.651,59.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.601 | Acc: 36.743,50.578,59.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.696 | Acc: 33.594,38.281,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.451 | Acc: 27.530,39.249,47.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.483 | Acc: 26.925,38.281,47.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.573 | Acc: 26.665,37.731,47.067,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 6.065 | Acc: 35.156,40.625,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.462 | Acc: 38.430,51.786,61.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.549 | Acc: 37.386,50.896,60.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.508 | Acc: 37.423,51.537,60.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.497 | Acc: 37.326,51.678,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.506 | Acc: 37.206,51.764,60.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.522 | Acc: 36.964,51.485,60.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.552 | Acc: 36.702,51.092,59.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.561 | Acc: 36.675,51.111,59.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.579 | Acc: 36.460,51.001,59.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.580 | Acc: 36.404,50.921,59.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.586 | Acc: 36.404,50.894,59.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.570 | Acc: 36.537,50.989,59.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.575 | Acc: 36.521,50.910,59.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.571 | Acc: 36.535,50.929,59.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.576 | Acc: 36.514,50.927,59.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.573 | Acc: 36.548,50.956,59.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.577 | Acc: 36.533,50.937,59.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.574 | Acc: 36.539,50.952,59.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.575 | Acc: 36.563,50.986,59.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.334 | Acc: 26.562,46.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.125 | Acc: 27.195,43.192,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.200 | Acc: 26.620,42.016,50.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.185 | Acc: 26.639,41.765,49.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 6.142 | Acc: 32.031,50.781,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.415 | Acc: 37.426,52.307,61.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.461 | Acc: 37.424,51.639,60.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.441 | Acc: 37.321,51.908,60.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.429 | Acc: 37.625,52.151,60.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.449 | Acc: 37.376,52.135,60.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.460 | Acc: 37.300,52.208,60.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.476 | Acc: 37.129,52.105,60.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.471 | Acc: 37.277,52.305,60.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.475 | Acc: 37.280,52.301,60.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.493 | Acc: 37.259,52.107,60.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.494 | Acc: 37.221,51.994,60.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.503 | Acc: 37.176,51.942,60.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.516 | Acc: 37.072,51.811,60.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.506 | Acc: 37.180,51.846,60.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.508 | Acc: 37.131,51.794,60.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.513 | Acc: 37.184,51.833,60.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.521 | Acc: 37.111,51.746,59.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.528 | Acc: 37.087,51.593,59.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.528 | Acc: 37.088,51.575,59.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.506 | Acc: 23.438,36.719,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.706 | Acc: 24.926,39.323,46.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.852 | Acc: 24.295,37.957,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.821 | Acc: 24.219,37.795,44.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 5.366 | Acc: 32.812,43.750,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.302 | Acc: 36.719,52.604,62.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.405 | Acc: 36.852,52.363,62.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.355 | Acc: 37.334,52.523,62.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.357 | Acc: 37.375,52.662,62.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.377 | Acc: 37.330,52.800,61.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.397 | Acc: 37.274,52.809,61.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.413 | Acc: 37.151,52.704,61.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.434 | Acc: 36.913,52.504,61.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.440 | Acc: 36.982,52.378,61.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.444 | Acc: 37.045,52.371,61.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.450 | Acc: 37.058,52.301,61.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.461 | Acc: 37.027,52.182,60.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.470 | Acc: 37.033,52.086,60.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.485 | Acc: 36.986,51.927,60.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.489 | Acc: 36.895,51.825,60.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.494 | Acc: 36.918,51.835,60.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.490 | Acc: 36.978,51.881,60.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.488 | Acc: 37.024,51.915,60.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.490 | Acc: 36.975,51.915,60.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.059 | Acc: 19.531,37.500,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.820 | Acc: 21.019,37.909,49.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.874 | Acc: 21.227,37.405,48.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.883 | Acc: 20.940,37.257,48.335,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 5.634 | Acc: 30.469,46.094,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.390 | Acc: 36.942,52.567,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.349 | Acc: 37.519,53.258,62.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.396 | Acc: 37.500,53.163,61.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.428 | Acc: 37.105,52.652,61.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.437 | Acc: 36.959,52.444,61.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.437 | Acc: 36.912,52.415,61.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.439 | Acc: 36.896,52.443,60.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.420 | Acc: 37.165,52.538,60.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.410 | Acc: 37.254,52.598,60.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.433 | Acc: 37.158,52.390,60.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.443 | Acc: 37.210,52.291,60.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.438 | Acc: 37.215,52.392,60.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.443 | Acc: 37.117,52.341,60.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.446 | Acc: 37.116,52.244,60.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.444 | Acc: 37.165,52.326,60.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.451 | Acc: 37.069,52.283,60.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.450 | Acc: 37.117,52.289,60.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.462 | Acc: 37.095,52.164,60.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.462 | Acc: 37.186,52.147,60.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.064 | Acc: 28.125,39.062,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.089 | Acc: 28.497,42.262,49.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.123 | Acc: 27.973,41.425,49.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.151 | Acc: 27.933,41.265,49.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 5.621 | Acc: 43.750,47.656,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.295 | Acc: 37.760,54.464,63.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.315 | Acc: 37.481,53.563,62.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.313 | Acc: 37.423,53.291,62.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.297 | Acc: 37.973,53.356,62.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.314 | Acc: 38.134,53.388,62.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.338 | Acc: 37.913,53.119,61.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.351 | Acc: 37.794,53.009,61.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.347 | Acc: 37.709,52.892,61.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.374 | Acc: 37.418,52.775,61.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.381 | Acc: 37.414,52.705,61.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.398 | Acc: 37.366,52.542,61.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.401 | Acc: 37.302,52.506,61.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.390 | Acc: 37.350,52.562,61.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.391 | Acc: 37.453,52.527,61.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.393 | Acc: 37.573,52.562,61.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.399 | Acc: 37.549,52.558,61.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.415 | Acc: 37.491,52.385,60.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.417 | Acc: 37.513,52.437,60.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.423 | Acc: 37.484,52.393,60.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.086 | Acc: 28.906,37.500,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.305 | Acc: 29.464,39.844,48.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.363 | Acc: 28.811,38.948,47.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.406 | Acc: 27.946,39.127,47.182,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 5.408 | Acc: 36.719,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.400 | Acc: 37.128,52.567,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.319 | Acc: 37.691,53.449,62.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.268 | Acc: 38.678,54.214,62.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.305 | Acc: 38.088,53.916,62.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.321 | Acc: 37.740,53.976,61.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.313 | Acc: 37.958,54.093,62.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.318 | Acc: 37.832,54.061,61.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.320 | Acc: 37.806,53.984,61.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.328 | Acc: 37.906,53.876,61.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.336 | Acc: 37.912,53.642,61.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.346 | Acc: 37.885,53.532,61.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.351 | Acc: 37.886,53.381,61.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.362 | Acc: 37.790,53.200,61.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.367 | Acc: 37.739,53.017,61.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.364 | Acc: 37.892,53.063,61.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.367 | Acc: 37.875,53.059,61.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.376 | Acc: 37.832,53.045,61.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.377 | Acc: 37.773,53.030,61.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.380 | Acc: 37.719,52.936,61.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.783 | Acc: 20.312,40.625,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.569 | Acc: 20.833,34.784,46.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.549 | Acc: 21.189,34.242,45.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.506 | Acc: 20.902,33.991,45.927,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 5.585 | Acc: 39.062,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.331 | Acc: 37.872,52.641,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.247 | Acc: 37.671,53.411,62.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.300 | Acc: 37.116,52.587,62.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.302 | Acc: 37.162,52.942,62.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.280 | Acc: 37.515,53.342,62.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.292 | Acc: 37.758,53.319,62.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.300 | Acc: 37.749,53.347,62.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.306 | Acc: 37.728,53.091,62.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.314 | Acc: 37.759,53.142,62.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.325 | Acc: 37.690,53.098,62.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.324 | Acc: 37.691,53.125,62.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.336 | Acc: 37.669,53.099,62.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.337 | Acc: 37.683,53.083,62.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.337 | Acc: 37.656,53.128,62.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.335 | Acc: 37.619,53.104,62.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.336 | Acc: 37.685,53.132,62.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.343 | Acc: 37.660,53.098,62.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.343 | Acc: 37.643,53.110,61.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.359 | Acc: 37.603,53.010,61.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.619 | Acc: 36.719,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.750 | Acc: 30.134,42.374,52.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.761 | Acc: 30.202,42.226,52.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.783 | Acc: 30.456,42.200,51.793,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 5.490 | Acc: 30.469,49.219,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.278 | Acc: 37.798,53.869,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.293 | Acc: 37.538,53.563,63.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.280 | Acc: 37.654,53.727,62.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.300 | Acc: 37.548,53.694,63.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.290 | Acc: 37.771,53.860,63.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.289 | Acc: 37.849,53.855,63.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.286 | Acc: 38.115,53.668,62.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.274 | Acc: 38.252,53.678,63.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.274 | Acc: 38.242,53.721,63.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.288 | Acc: 38.231,53.661,62.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.298 | Acc: 37.998,53.528,62.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.303 | Acc: 37.908,53.501,62.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.307 | Acc: 37.955,53.439,62.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.314 | Acc: 37.920,53.400,62.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.329 | Acc: 37.775,53.304,62.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.334 | Acc: 37.758,53.230,62.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.333 | Acc: 37.812,53.175,62.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.342 | Acc: 37.732,53.123,62.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.342 | Acc: 37.652,53.193,62.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.616 | Acc: 33.594,43.750,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.706 | Acc: 32.031,42.820,50.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.725 | Acc: 30.850,42.950,49.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.764 | Acc: 30.622,42.828,49.142,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 4.988 | Acc: 42.188,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.245 | Acc: 38.951,53.683,62.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.296 | Acc: 38.377,53.754,61.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.280 | Acc: 38.934,53.945,62.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.298 | Acc: 38.310,53.260,61.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.312 | Acc: 38.343,53.171,61.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.333 | Acc: 38.126,53.241,61.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.324 | Acc: 38.204,53.225,61.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.319 | Acc: 38.043,53.314,61.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.323 | Acc: 37.828,53.298,61.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.322 | Acc: 37.912,53.413,61.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.330 | Acc: 37.815,53.440,61.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.323 | Acc: 37.834,53.472,61.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.324 | Acc: 37.799,53.391,61.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.330 | Acc: 37.658,53.261,61.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.319 | Acc: 37.739,53.330,61.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.319 | Acc: 37.765,53.283,61.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.313 | Acc: 37.823,53.322,61.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.311 | Acc: 37.868,53.350,61.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.319 | Acc: 37.806,53.271,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.103 | Acc: 28.125,42.969,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.261 | Acc: 25.484,40.253,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.336 | Acc: 24.619,40.091,52.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.343 | Acc: 24.347,40.036,52.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 5.568 | Acc: 40.625,50.781,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.265 | Acc: 38.132,55.022,63.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.231 | Acc: 37.843,54.268,63.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.239 | Acc: 38.422,54.355,63.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.185 | Acc: 39.062,54.745,63.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.201 | Acc: 38.954,54.688,63.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.207 | Acc: 38.940,54.616,63.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.202 | Acc: 38.968,54.920,63.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.201 | Acc: 38.859,54.780,63.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.205 | Acc: 38.929,54.584,63.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.205 | Acc: 38.946,54.618,63.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.204 | Acc: 38.836,54.613,63.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.218 | Acc: 38.797,54.396,63.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.226 | Acc: 38.823,54.322,63.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.232 | Acc: 38.740,54.215,62.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.239 | Acc: 38.658,54.124,62.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.243 | Acc: 38.607,54.108,62.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.248 | Acc: 38.533,54.076,62.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.261 | Acc: 38.415,53.995,62.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.264 | Acc: 38.376,53.980,62.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.304 | Acc: 28.906,42.188,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.379 | Acc: 26.265,40.625,49.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.448 | Acc: 26.029,40.130,49.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.469 | Acc: 25.961,40.382,49.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 5.400 | Acc: 35.156,54.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.234 | Acc: 36.942,53.646,62.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.203 | Acc: 37.081,54.135,63.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.158 | Acc: 38.179,54.918,64.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.202 | Acc: 37.905,54.437,63.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.211 | Acc: 38.142,54.332,63.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.228 | Acc: 38.113,53.984,63.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.214 | Acc: 38.364,54.228,63.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.229 | Acc: 38.121,53.964,63.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.234 | Acc: 38.212,54.139,63.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.243 | Acc: 38.207,54.093,63.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.248 | Acc: 38.172,54.058,63.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.257 | Acc: 38.090,53.984,62.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.252 | Acc: 38.197,53.954,63.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.248 | Acc: 38.362,54.087,63.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.249 | Acc: 38.318,54.036,63.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.253 | Acc: 38.250,53.945,62.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.254 | Acc: 38.240,53.888,62.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.250 | Acc: 38.301,53.930,62.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.253 | Acc: 38.257,53.935,62.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.307 | Acc: 32.031,45.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.224 | Acc: 27.344,42.597,49.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.250 | Acc: 27.191,40.968,49.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.229 | Acc: 27.203,41.457,49.193,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 4.916 | Acc: 39.844,55.469,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.039 | Acc: 39.695,55.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.100 | Acc: 40.034,55.183,64.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.112 | Acc: 39.549,54.713,65.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.149 | Acc: 38.918,54.639,64.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.143 | Acc: 38.877,54.471,64.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.159 | Acc: 38.694,54.397,64.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.157 | Acc: 38.564,54.593,64.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.173 | Acc: 38.301,54.416,64.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.160 | Acc: 38.294,54.575,64.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.163 | Acc: 38.204,54.769,63.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.172 | Acc: 38.225,54.634,63.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.185 | Acc: 38.174,54.561,63.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.184 | Acc: 38.159,54.571,63.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.195 | Acc: 38.053,54.446,63.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.199 | Acc: 38.120,54.503,63.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.208 | Acc: 38.070,54.476,63.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.222 | Acc: 38.004,54.383,63.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.228 | Acc: 37.950,54.304,63.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.227 | Acc: 37.918,54.263,63.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.085 | Acc: 25.000,46.875,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.307 | Acc: 24.702,42.969,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.358 | Acc: 24.028,42.264,51.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.359 | Acc: 23.681,41.803,51.050,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 5.181 | Acc: 29.688,53.906,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.075 | Acc: 38.653,55.580,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.119 | Acc: 38.014,55.030,65.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.176 | Acc: 38.128,54.752,64.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.169 | Acc: 38.493,54.755,64.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.153 | Acc: 38.653,55.082,64.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.170 | Acc: 38.701,54.991,64.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.162 | Acc: 38.680,55.081,64.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.159 | Acc: 38.504,55.042,64.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.145 | Acc: 38.683,55.141,64.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.141 | Acc: 38.853,55.204,64.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.150 | Acc: 38.865,55.098,64.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.152 | Acc: 38.800,55.034,63.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.156 | Acc: 38.799,54.909,63.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.166 | Acc: 38.709,54.865,63.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.180 | Acc: 38.626,54.794,63.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.180 | Acc: 38.661,54.739,63.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.182 | Acc: 38.609,54.697,63.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.182 | Acc: 38.563,54.685,63.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.181 | Acc: 38.628,54.685,63.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.808 | Acc: 27.344,45.312,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.975 | Acc: 28.497,43.304,51.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.975 | Acc: 28.220,42.969,50.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.035 | Acc: 28.023,42.969,49.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 5.601 | Acc: 29.688,57.031,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.126 | Acc: 37.723,55.134,63.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.103 | Acc: 38.700,54.954,64.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.106 | Acc: 38.755,54.739,64.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.118 | Acc: 38.841,55.064,64.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.104 | Acc: 38.931,55.515,64.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.088 | Acc: 38.882,55.624,65.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.104 | Acc: 38.719,55.568,64.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.107 | Acc: 39.019,55.435,64.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.114 | Acc: 39.075,55.374,64.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.109 | Acc: 39.008,55.480,64.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.117 | Acc: 38.981,55.359,64.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.120 | Acc: 38.862,55.294,64.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.129 | Acc: 38.817,55.256,64.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.131 | Acc: 38.826,55.199,64.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.139 | Acc: 38.819,55.098,63.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.149 | Acc: 38.724,54.936,63.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.151 | Acc: 38.648,54.818,63.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.164 | Acc: 38.545,54.664,63.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.164 | Acc: 38.548,54.710,63.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.110 | Acc: 22.656,39.844,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.459 | Acc: 23.586,35.714,43.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.407 | Acc: 23.361,35.309,44.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.372 | Acc: 23.425,35.605,44.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 5.284 | Acc: 37.500,53.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.012 | Acc: 38.876,55.320,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.118 | Acc: 38.548,54.421,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.107 | Acc: 38.294,54.828,64.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.048 | Acc: 38.860,55.517,64.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.050 | Acc: 39.240,55.623,64.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.045 | Acc: 39.159,55.656,64.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.053 | Acc: 39.212,55.568,64.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.056 | Acc: 38.941,55.381,64.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.051 | Acc: 38.985,55.616,64.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.075 | Acc: 38.783,55.372,64.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.089 | Acc: 38.603,55.281,64.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.102 | Acc: 38.683,55.242,64.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.102 | Acc: 38.697,55.241,64.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.110 | Acc: 38.690,55.166,64.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.124 | Acc: 38.632,55.069,64.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.130 | Acc: 38.705,54.955,63.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.131 | Acc: 38.682,54.988,63.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.131 | Acc: 38.807,54.997,63.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.132 | Acc: 38.814,54.999,63.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.386 | Acc: 28.906,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.490 | Acc: 29.018,47.396,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.562 | Acc: 28.525,45.979,53.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.596 | Acc: 28.714,45.966,53.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 4.722 | Acc: 42.188,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.179 | Acc: 37.760,54.948,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.135 | Acc: 38.338,54.707,65.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.062 | Acc: 39.267,55.443,65.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.083 | Acc: 38.947,55.498,65.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.081 | Acc: 38.861,55.709,64.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.089 | Acc: 38.940,55.475,64.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.108 | Acc: 38.813,55.153,64.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.098 | Acc: 38.995,55.294,64.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.095 | Acc: 38.976,55.443,64.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.095 | Acc: 39.074,55.449,64.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.098 | Acc: 38.921,55.490,64.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.112 | Acc: 38.761,55.401,64.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.121 | Acc: 38.667,55.268,64.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.126 | Acc: 38.734,55.199,64.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.125 | Acc: 38.759,55.144,64.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.133 | Acc: 38.729,55.074,64.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.131 | Acc: 38.781,55.164,64.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.116 | Acc: 38.889,55.315,64.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.124 | Acc: 38.782,55.210,64.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.378 | Acc: 32.812,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.663 | Acc: 31.101,44.494,53.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.788 | Acc: 30.774,43.617,50.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.823 | Acc: 30.443,43.468,50.474,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.778 | Acc: 35.156,60.156,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.046 | Acc: 38.542,56.845,63.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.038 | Acc: 39.463,56.784,64.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.030 | Acc: 39.447,56.775,65.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.038 | Acc: 39.767,56.626,65.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.051 | Acc: 39.403,56.250,65.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.084 | Acc: 39.082,55.695,65.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.089 | Acc: 38.935,55.663,64.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.081 | Acc: 39.024,55.469,64.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.069 | Acc: 39.101,55.555,65.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.078 | Acc: 39.012,55.313,65.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.073 | Acc: 39.112,55.334,64.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.078 | Acc: 39.069,55.226,64.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.072 | Acc: 39.128,55.304,65.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.077 | Acc: 39.163,55.291,64.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.098 | Acc: 38.979,55.207,64.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.100 | Acc: 38.916,55.172,64.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.103 | Acc: 38.895,55.235,64.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.108 | Acc: 38.850,55.174,64.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.111 | Acc: 38.833,55.176,64.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.915 | Acc: 25.781,39.844,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.952 | Acc: 30.320,44.085,51.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.022 | Acc: 29.154,43.445,50.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.072 | Acc: 28.893,43.135,49.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 4.760 | Acc: 44.531,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.976 | Acc: 39.435,57.031,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.016 | Acc: 38.739,56.307,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.001 | Acc: 38.691,56.084,66.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.997 | Acc: 38.850,56.105,66.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.019 | Acc: 38.475,55.871,65.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.004 | Acc: 38.552,56.198,65.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.022 | Acc: 38.641,56.217,65.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.046 | Acc: 38.543,55.774,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.046 | Acc: 38.601,55.874,65.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.045 | Acc: 38.736,55.889,65.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.063 | Acc: 38.663,55.851,64.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.077 | Acc: 38.570,55.731,64.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.068 | Acc: 38.619,55.702,64.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.066 | Acc: 38.784,55.702,64.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.072 | Acc: 38.837,55.684,64.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.076 | Acc: 38.848,55.632,64.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.078 | Acc: 38.808,55.615,64.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.075 | Acc: 38.876,55.692,64.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.075 | Acc: 38.884,55.686,64.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.824 | Acc: 35.938,50.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.037 | Acc: 30.692,44.196,51.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.049 | Acc: 29.592,43.350,51.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.048 | Acc: 29.534,43.494,50.986,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 4.777 | Acc: 42.188,58.594,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.175 | Acc: 38.728,53.757,64.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.093 | Acc: 39.177,54.821,64.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.114 | Acc: 39.191,54.534,64.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.078 | Acc: 39.255,54.890,64.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.082 | Acc: 39.233,54.927,64.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.064 | Acc: 39.321,55.152,64.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.069 | Acc: 39.024,55.308,64.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.077 | Acc: 38.834,55.236,64.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.090 | Acc: 38.864,55.072,64.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.084 | Acc: 38.891,55.220,64.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.080 | Acc: 38.914,55.303,64.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.076 | Acc: 38.858,55.303,64.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.066 | Acc: 38.979,55.358,64.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.076 | Acc: 38.935,55.349,64.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.073 | Acc: 38.953,55.417,64.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.073 | Acc: 38.992,55.420,64.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.072 | Acc: 39.065,55.466,64.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.070 | Acc: 39.220,55.553,64.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.072 | Acc: 39.214,55.532,64.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.153 | Acc: 32.031,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.652 | Acc: 30.469,44.978,55.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.798 | Acc: 29.688,44.284,53.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.853 | Acc: 29.316,43.891,53.087,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 4.025 | Acc: 45.312,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.830 | Acc: 41.518,57.738,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.847 | Acc: 40.816,57.317,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.869 | Acc: 40.228,57.095,67.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.877 | Acc: 40.046,57.079,66.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.869 | Acc: 40.377,57.410,66.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.882 | Acc: 40.225,57.212,66.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.907 | Acc: 39.811,56.810,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.951 | Acc: 39.596,56.556,66.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.968 | Acc: 39.580,56.522,65.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.995 | Acc: 39.385,56.347,65.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.011 | Acc: 39.367,56.268,65.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.020 | Acc: 39.387,56.331,65.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.022 | Acc: 39.497,56.265,65.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.035 | Acc: 39.338,56.103,65.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.031 | Acc: 39.374,56.105,65.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.031 | Acc: 39.447,56.121,65.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.037 | Acc: 39.406,56.009,65.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.046 | Acc: 39.340,55.899,65.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.049 | Acc: 39.282,55.903,65.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.189 | Acc: 38.281,53.125,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.262 | Acc: 33.110,47.917,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.271 | Acc: 32.736,47.313,55.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.291 | Acc: 32.415,46.875,54.316,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 4.830 | Acc: 39.844,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.015 | Acc: 40.104,55.134,64.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.971 | Acc: 40.168,56.079,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.985 | Acc: 39.857,55.879,65.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.986 | Acc: 40.133,56.028,65.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.989 | Acc: 40.068,56.242,65.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.014 | Acc: 39.740,55.966,65.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.006 | Acc: 39.766,56.156,65.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.999 | Acc: 39.747,56.226,65.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.998 | Acc: 39.732,56.069,65.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.009 | Acc: 39.665,55.990,65.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.004 | Acc: 39.543,56.087,65.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.007 | Acc: 39.552,56.004,65.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.011 | Acc: 39.500,56.055,65.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.017 | Acc: 39.499,56.067,65.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.021 | Acc: 39.488,56.123,65.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.020 | Acc: 39.513,56.128,65.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.022 | Acc: 39.434,56.145,65.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.024 | Acc: 39.333,56.036,65.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.028 | Acc: 39.325,56.029,65.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.627 | Acc: 31.250,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.949 | Acc: 25.670,45.015,52.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.048 | Acc: 24.314,43.255,52.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.061 | Acc: 24.526,43.455,51.639,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 5.213 | Acc: 39.844,55.469,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.863 | Acc: 39.397,56.994,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.804 | Acc: 40.263,57.450,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.859 | Acc: 39.613,56.890,67.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.897 | Acc: 39.574,56.761,67.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.897 | Acc: 39.712,56.807,67.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.904 | Acc: 39.715,56.902,66.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.907 | Acc: 39.860,56.920,66.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.915 | Acc: 39.756,56.915,66.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.921 | Acc: 39.736,56.872,66.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.931 | Acc: 39.715,56.837,66.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.935 | Acc: 39.727,56.844,66.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.943 | Acc: 39.659,56.827,66.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.953 | Acc: 39.571,56.846,66.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.952 | Acc: 39.663,56.914,66.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.955 | Acc: 39.631,56.886,66.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.966 | Acc: 39.552,56.722,66.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.971 | Acc: 39.553,56.699,66.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.973 | Acc: 39.532,56.698,66.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.984 | Acc: 39.442,56.572,65.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.939 | Acc: 17.188,40.625,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.277 | Acc: 19.085,37.165,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.337 | Acc: 18.521,37.157,49.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.359 | Acc: 18.327,37.257,49.155,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 4.913 | Acc: 50.000,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.919 | Acc: 38.802,56.362,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.868 | Acc: 39.101,56.460,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.899 | Acc: 38.665,56.442,66.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.917 | Acc: 38.667,56.289,66.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.920 | Acc: 38.916,56.706,66.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.918 | Acc: 39.088,56.805,66.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.941 | Acc: 39.040,56.782,66.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.937 | Acc: 39.121,56.774,66.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.942 | Acc: 39.214,56.923,66.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.938 | Acc: 39.354,56.891,66.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.945 | Acc: 39.356,56.830,66.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.960 | Acc: 39.231,56.701,65.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.965 | Acc: 39.299,56.609,65.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.964 | Acc: 39.371,56.628,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.968 | Acc: 39.449,56.624,65.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.980 | Acc: 39.369,56.591,65.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.979 | Acc: 39.365,56.566,65.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.987 | Acc: 39.251,56.484,65.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.991 | Acc: 39.321,56.480,65.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.374 | Acc: 37.500,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.815 | Acc: 30.580,43.452,54.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.781 | Acc: 29.935,43.331,53.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.863 | Acc: 28.906,42.226,53.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 4.301 | Acc: 40.625,60.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.810 | Acc: 39.658,58.110,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.788 | Acc: 40.034,58.251,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.835 | Acc: 39.319,57.582,67.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.839 | Acc: 39.709,57.716,67.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.837 | Acc: 39.929,57.519,67.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.888 | Acc: 39.553,57.025,67.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.882 | Acc: 39.589,57.192,67.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.888 | Acc: 39.475,57.235,67.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.911 | Acc: 39.283,56.867,66.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.907 | Acc: 39.443,56.860,66.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.930 | Acc: 39.289,56.819,66.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.941 | Acc: 39.302,56.639,66.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.949 | Acc: 39.251,56.582,66.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.944 | Acc: 39.290,56.714,66.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.945 | Acc: 39.348,56.769,66.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.949 | Acc: 39.284,56.776,66.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.946 | Acc: 39.250,56.827,66.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.950 | Acc: 39.270,56.791,66.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.950 | Acc: 39.366,56.824,66.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.721 | Acc: 32.812,46.094,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.770 | Acc: 30.283,44.568,53.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.857 | Acc: 29.230,43.540,53.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.842 | Acc: 28.855,43.584,53.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 4.367 | Acc: 41.406,60.156,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.956 | Acc: 38.281,57.068,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.980 | Acc: 38.739,56.936,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.925 | Acc: 39.331,57.326,67.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.907 | Acc: 39.535,57.687,66.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.889 | Acc: 39.596,57.658,66.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.869 | Acc: 39.728,57.825,67.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.857 | Acc: 39.628,57.702,67.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.865 | Acc: 39.582,57.575,67.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.879 | Acc: 39.503,57.441,66.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.885 | Acc: 39.513,57.261,66.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.895 | Acc: 39.519,57.257,66.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.898 | Acc: 39.568,57.223,66.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.899 | Acc: 39.646,57.238,66.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.910 | Acc: 39.552,57.170,66.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.915 | Acc: 39.550,57.119,66.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.923 | Acc: 39.437,57.043,66.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.934 | Acc: 39.496,57.031,66.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.939 | Acc: 39.539,57.007,66.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.947 | Acc: 39.571,56.935,65.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.869 | Acc: 28.906,48.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.127 | Acc: 25.744,44.308,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.165 | Acc: 25.210,44.055,53.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.203 | Acc: 25.154,43.827,53.176,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 5.267 | Acc: 41.406,60.156,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.887 | Acc: 38.914,57.775,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.840 | Acc: 39.806,58.327,68.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.849 | Acc: 39.639,58.158,67.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.865 | Acc: 39.796,57.687,66.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.879 | Acc: 39.766,57.596,66.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.894 | Acc: 39.695,57.515,66.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.898 | Acc: 39.716,57.303,66.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.896 | Acc: 39.611,57.279,66.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.909 | Acc: 39.464,57.096,66.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.923 | Acc: 39.424,57.027,66.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.930 | Acc: 39.303,57.003,66.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.921 | Acc: 39.432,57.073,66.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.926 | Acc: 39.362,57.073,66.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.926 | Acc: 39.393,57.109,66.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.935 | Acc: 39.358,57.086,66.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.951 | Acc: 39.187,56.917,65.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.947 | Acc: 39.321,56.965,66.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.952 | Acc: 39.346,56.923,65.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.955 | Acc: 39.366,56.937,65.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.891 | Acc: 34.375,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.046 | Acc: 32.924,46.912,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.097 | Acc: 32.336,46.513,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.140 | Acc: 32.147,46.235,56.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 4.621 | Acc: 38.281,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.768 | Acc: 39.881,59.189,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.759 | Acc: 40.606,58.956,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.775 | Acc: 40.702,58.927,68.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.781 | Acc: 40.461,58.854,68.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.823 | Acc: 40.107,58.122,67.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.819 | Acc: 40.179,58.232,67.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.841 | Acc: 40.093,58.223,67.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.850 | Acc: 40.043,58.162,67.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.855 | Acc: 39.908,58.007,67.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.860 | Acc: 39.863,57.851,67.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.860 | Acc: 39.872,57.749,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.869 | Acc: 39.889,57.761,66.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.874 | Acc: 39.859,57.654,67.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.876 | Acc: 39.933,57.660,66.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.890 | Acc: 39.872,57.517,66.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.887 | Acc: 39.834,57.567,66.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.900 | Acc: 39.736,57.441,66.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.916 | Acc: 39.653,57.278,66.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.920 | Acc: 39.616,57.277,66.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.288 | Acc: 28.906,46.094,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.587 | Acc: 29.427,47.396,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.635 | Acc: 28.963,46.532,54.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.675 | Acc: 28.343,46.311,54.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 4.619 | Acc: 39.844,56.250,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.833 | Acc: 38.170,56.957,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.786 | Acc: 39.253,57.374,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.764 | Acc: 39.857,57.710,68.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.799 | Acc: 39.593,57.880,67.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.809 | Acc: 39.612,57.666,67.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.785 | Acc: 40.147,57.838,67.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.816 | Acc: 39.927,57.613,67.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.822 | Acc: 39.868,57.599,67.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.840 | Acc: 39.788,57.519,67.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.851 | Acc: 39.805,57.377,67.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.859 | Acc: 39.770,57.335,66.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.866 | Acc: 39.795,57.323,66.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.869 | Acc: 39.766,57.319,66.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.872 | Acc: 39.824,57.418,66.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.876 | Acc: 39.818,57.418,66.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.885 | Acc: 39.783,57.445,66.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.892 | Acc: 39.805,57.375,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.898 | Acc: 39.766,57.317,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.904 | Acc: 39.739,57.263,66.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.590 | Acc: 30.469,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.831 | Acc: 28.981,45.350,54.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.919 | Acc: 28.582,44.093,54.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.963 | Acc: 28.266,43.648,53.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.949 | Acc: 35.938,53.906,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.776 | Acc: 39.732,57.999,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.729 | Acc: 40.930,58.613,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.749 | Acc: 40.971,58.338,68.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.785 | Acc: 40.596,58.054,68.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.810 | Acc: 40.277,57.874,67.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.825 | Acc: 40.076,57.696,67.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.834 | Acc: 39.943,57.641,67.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.831 | Acc: 39.941,57.604,67.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.834 | Acc: 40.073,57.510,67.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.839 | Acc: 40.081,57.455,67.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.829 | Acc: 40.218,57.611,67.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.844 | Acc: 40.045,57.436,67.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.850 | Acc: 40.077,57.519,67.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.857 | Acc: 40.022,57.465,67.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.857 | Acc: 40.106,57.480,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.861 | Acc: 40.146,57.408,67.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.864 | Acc: 40.137,57.361,66.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.867 | Acc: 40.134,57.393,66.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.867 | Acc: 40.213,57.400,66.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.492 | Acc: 28.906,46.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.540 | Acc: 28.571,45.499,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.577 | Acc: 28.373,45.046,55.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.577 | Acc: 28.279,44.915,55.789,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 5.106 | Acc: 37.500,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.753 | Acc: 40.699,59.152,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.791 | Acc: 40.492,59.337,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.786 | Acc: 40.587,59.132,68.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.781 | Acc: 40.615,59.047,67.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.798 | Acc: 40.416,58.640,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.787 | Acc: 40.612,58.536,67.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.812 | Acc: 40.392,58.223,67.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.826 | Acc: 40.329,58.050,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.829 | Acc: 40.500,57.985,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.832 | Acc: 40.435,57.956,67.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.842 | Acc: 40.339,57.830,67.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.845 | Acc: 40.401,57.822,67.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.857 | Acc: 40.242,57.786,66.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.862 | Acc: 40.191,57.751,66.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.861 | Acc: 40.225,57.703,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.859 | Acc: 40.116,57.793,66.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.866 | Acc: 40.135,57.666,66.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.878 | Acc: 40.041,57.579,66.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.881 | Acc: 40.063,57.575,66.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.029 | Acc: 31.250,45.312,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.844 | Acc: 31.324,43.973,51.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.960 | Acc: 30.621,43.121,50.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.992 | Acc: 30.149,42.930,50.551,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 4.512 | Acc: 39.844,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.800 | Acc: 39.918,58.259,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.754 | Acc: 40.758,58.632,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.736 | Acc: 40.715,58.940,68.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.761 | Acc: 40.355,58.681,68.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.783 | Acc: 40.416,58.431,67.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.802 | Acc: 40.405,58.187,67.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.804 | Acc: 40.503,58.056,67.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.807 | Acc: 40.625,57.992,67.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.823 | Acc: 40.448,57.977,67.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.838 | Acc: 40.357,57.929,67.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.842 | Acc: 40.169,57.890,66.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.847 | Acc: 40.087,57.816,66.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.852 | Acc: 40.071,57.774,66.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.850 | Acc: 40.163,57.793,66.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.850 | Acc: 40.194,57.901,66.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.851 | Acc: 40.172,57.946,67.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.859 | Acc: 40.105,57.872,66.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.853 | Acc: 40.179,57.916,66.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.858 | Acc: 40.196,57.837,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.329 | Acc: 32.812,50.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.553 | Acc: 34.449,45.238,52.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.551 | Acc: 34.013,45.084,52.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.592 | Acc: 33.325,45.082,52.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 5.072 | Acc: 41.406,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.761 | Acc: 40.104,59.152,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.724 | Acc: 40.549,59.242,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.709 | Acc: 40.932,59.682,68.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.733 | Acc: 40.702,59.182,68.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.753 | Acc: 40.463,58.663,68.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.752 | Acc: 40.386,58.555,68.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.764 | Acc: 40.237,58.538,68.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.791 | Acc: 40.111,58.317,67.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.804 | Acc: 39.939,58.162,67.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.809 | Acc: 40.100,58.197,67.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.821 | Acc: 40.042,58.028,67.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.822 | Acc: 40.103,58.033,67.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.830 | Acc: 40.038,58.028,67.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.835 | Acc: 39.963,57.935,67.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.836 | Acc: 40.005,57.877,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.839 | Acc: 40.080,57.830,67.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.842 | Acc: 40.059,57.785,67.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.846 | Acc: 40.036,57.735,67.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.846 | Acc: 40.098,57.728,67.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.907 | Acc: 31.250,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.174 | Acc: 33.891,49.070,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.246 | Acc: 33.022,48.190,56.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.301 | Acc: 32.915,47.861,56.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 4.833 | Acc: 35.938,58.594,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.672 | Acc: 39.769,58.929,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.708 | Acc: 40.111,58.708,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.705 | Acc: 40.856,58.619,69.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.717 | Acc: 40.866,58.777,69.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.707 | Acc: 41.275,58.880,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.717 | Acc: 41.290,58.671,69.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.746 | Acc: 41.090,58.383,68.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.751 | Acc: 41.037,58.550,68.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.765 | Acc: 40.720,58.529,68.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.776 | Acc: 40.656,58.547,68.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.771 | Acc: 40.643,58.629,68.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.772 | Acc: 40.479,58.500,68.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.785 | Acc: 40.374,58.384,68.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.792 | Acc: 40.400,58.405,67.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.807 | Acc: 40.337,58.311,67.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.815 | Acc: 40.321,58.285,67.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.822 | Acc: 40.277,58.227,67.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.821 | Acc: 40.246,58.252,67.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.819 | Acc: 40.307,58.290,67.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.125 | Acc: 26.562,42.969,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.339 | Acc: 26.414,42.485,51.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.305 | Acc: 26.829,42.664,51.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.349 | Acc: 26.998,42.316,50.730,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 4.995 | Acc: 42.969,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.785 | Acc: 40.402,58.333,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.731 | Acc: 40.549,58.861,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.733 | Acc: 40.561,59.324,68.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.750 | Acc: 40.384,58.883,68.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.758 | Acc: 40.200,58.764,68.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.768 | Acc: 40.057,58.452,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.776 | Acc: 40.115,58.361,68.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.793 | Acc: 39.781,58.244,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.799 | Acc: 39.921,58.188,68.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.793 | Acc: 39.960,58.158,68.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.805 | Acc: 39.784,57.989,67.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.809 | Acc: 39.935,58.020,67.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.808 | Acc: 40.008,58.037,67.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.803 | Acc: 40.094,58.107,67.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.810 | Acc: 40.062,58.010,67.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.824 | Acc: 40.043,57.988,67.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.819 | Acc: 40.137,58.028,67.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.821 | Acc: 40.112,57.986,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.825 | Acc: 40.164,57.983,67.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.059 | Acc: 17.969,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.978 | Acc: 20.499,42.448,51.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.030 | Acc: 20.027,42.054,51.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.059 | Acc: 19.813,42.098,51.383,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 4.355 | Acc: 44.531,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.641 | Acc: 40.699,60.119,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.642 | Acc: 41.406,59.966,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.663 | Acc: 41.009,60.067,69.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.686 | Acc: 40.982,59.558,68.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.727 | Acc: 40.764,59.244,68.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.758 | Acc: 40.225,58.942,68.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.757 | Acc: 40.376,58.732,68.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.769 | Acc: 40.348,58.623,68.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.769 | Acc: 40.452,58.650,68.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.775 | Acc: 40.574,58.532,67.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.780 | Acc: 40.445,58.428,67.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.766 | Acc: 40.521,58.493,68.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.774 | Acc: 40.493,58.414,67.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.785 | Acc: 40.405,58.255,67.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.793 | Acc: 40.404,58.129,67.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.800 | Acc: 40.367,58.095,67.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.804 | Acc: 40.332,58.026,67.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.809 | Acc: 40.339,57.992,67.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.818 | Acc: 40.317,57.956,67.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.790 | Acc: 36.719,49.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.989 | Acc: 35.305,47.507,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.010 | Acc: 34.261,46.856,58.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.062 | Acc: 33.888,46.568,57.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 4.334 | Acc: 43.750,57.031,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.766 | Acc: 39.025,59.189,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.672 | Acc: 40.091,59.889,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.687 | Acc: 40.394,59.964,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.685 | Acc: 40.625,59.491,69.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.685 | Acc: 40.633,59.228,69.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.701 | Acc: 40.548,59.110,69.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.709 | Acc: 40.547,59.109,68.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.723 | Acc: 40.455,58.958,68.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.748 | Acc: 40.331,58.753,68.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.746 | Acc: 40.403,58.675,68.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.756 | Acc: 40.328,58.604,68.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.757 | Acc: 40.343,58.519,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.764 | Acc: 40.260,58.525,68.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.768 | Acc: 40.272,58.413,68.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.765 | Acc: 40.360,58.402,68.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.772 | Acc: 40.194,58.358,68.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.770 | Acc: 40.288,58.378,68.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.782 | Acc: 40.251,58.319,67.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.781 | Acc: 40.315,58.317,67.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.296 | Acc: 26.562,50.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.661 | Acc: 24.740,43.750,54.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.566 | Acc: 24.104,43.883,54.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.553 | Acc: 23.886,43.929,54.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.662 | Acc: 40.625,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.719 | Acc: 39.546,58.668,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.753 | Acc: 40.149,58.403,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.707 | Acc: 40.087,58.658,69.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.704 | Acc: 39.892,58.902,69.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.750 | Acc: 39.705,58.261,69.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.731 | Acc: 40.199,58.587,69.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.732 | Acc: 40.603,58.644,69.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.751 | Acc: 40.640,58.710,68.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.760 | Acc: 40.439,58.641,68.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.759 | Acc: 40.337,58.617,68.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.757 | Acc: 40.374,58.629,68.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.752 | Acc: 40.495,58.665,68.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.750 | Acc: 40.457,58.719,68.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.757 | Acc: 40.500,58.708,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.756 | Acc: 40.570,58.692,68.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.746 | Acc: 40.654,58.781,68.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.751 | Acc: 40.630,58.772,68.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.757 | Acc: 40.655,58.745,68.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.764 | Acc: 40.576,58.715,68.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.727 | Acc: 26.562,46.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.984 | Acc: 25.000,45.461,54.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.027 | Acc: 24.447,44.931,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.050 | Acc: 24.155,45.261,53.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.530 | Acc: 43.750,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.648 | Acc: 40.625,59.301,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 41.120,59.375,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.640 | Acc: 40.843,59.567,70.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.620 | Acc: 41.117,60.060,70.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.629 | Acc: 41.027,59.847,69.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.656 | Acc: 41.096,59.491,69.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.679 | Acc: 40.969,59.137,68.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.692 | Acc: 40.897,59.035,68.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.705 | Acc: 40.819,58.879,68.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.709 | Acc: 40.850,58.885,68.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.715 | Acc: 40.865,58.859,68.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.715 | Acc: 40.891,58.973,68.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.715 | Acc: 40.852,59.037,68.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.723 | Acc: 40.820,58.991,68.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.729 | Acc: 40.926,59.009,68.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.734 | Acc: 40.927,58.993,68.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.740 | Acc: 40.850,58.935,68.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.741 | Acc: 40.831,58.979,68.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.748 | Acc: 40.779,58.910,68.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.092 | Acc: 37.500,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.303 | Acc: 34.487,48.028,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.353 | Acc: 33.841,46.665,54.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.402 | Acc: 32.992,46.350,53.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 5.258 | Acc: 39.844,53.125,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.653 | Acc: 41.443,57.589,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.644 | Acc: 41.578,58.956,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 41.829,59.503,69.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.634 | Acc: 41.377,59.471,69.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.662 | Acc: 41.321,59.213,69.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.687 | Acc: 41.322,58.865,69.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.720 | Acc: 40.996,58.699,68.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.731 | Acc: 40.887,58.783,68.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.724 | Acc: 40.919,58.831,68.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.728 | Acc: 40.796,58.753,68.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.732 | Acc: 40.738,58.710,68.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.724 | Acc: 40.820,58.840,68.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.734 | Acc: 40.679,58.770,68.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.736 | Acc: 40.589,58.786,68.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.740 | Acc: 40.602,58.713,68.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.750 | Acc: 40.520,58.633,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.751 | Acc: 40.632,58.674,68.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.751 | Acc: 40.647,58.674,68.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.754 | Acc: 40.643,58.627,67.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.453 | Acc: 34.375,47.656,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.555 | Acc: 30.432,45.945,54.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.582 | Acc: 30.183,45.370,53.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.618 | Acc: 30.187,45.492,53.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 4.625 | Acc: 39.062,67.188,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.654 | Acc: 39.472,59.784,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.654 | Acc: 39.863,59.527,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.714 | Acc: 39.741,58.645,69.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.708 | Acc: 39.911,58.574,69.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.671 | Acc: 40.579,58.926,69.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.677 | Acc: 40.522,58.833,69.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.706 | Acc: 40.453,58.577,68.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.713 | Acc: 40.276,58.608,69.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.721 | Acc: 40.336,58.671,68.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.724 | Acc: 40.186,58.691,68.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.719 | Acc: 40.289,58.785,68.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.728 | Acc: 40.191,58.652,68.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.726 | Acc: 40.332,58.684,68.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.727 | Acc: 40.305,58.705,68.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.735 | Acc: 40.373,58.617,68.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.732 | Acc: 40.496,58.672,68.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.745 | Acc: 40.506,58.603,68.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.752 | Acc: 40.445,58.540,68.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.749 | Acc: 40.481,58.565,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.103 | Acc: 28.906,49.219,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.988 | Acc: 28.311,44.271,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.042 | Acc: 27.287,42.893,52.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.111 | Acc: 26.537,42.405,51.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.219 | Acc: 40.625,59.375,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.665 | Acc: 40.737,58.631,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.641 | Acc: 41.444,59.489,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.672 | Acc: 40.740,59.503,69.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.659 | Acc: 40.914,59.606,69.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.626 | Acc: 41.368,60.040,70.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.654 | Acc: 41.542,59.588,69.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.668 | Acc: 41.257,59.563,69.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.669 | Acc: 41.212,59.487,69.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.668 | Acc: 41.350,59.487,69.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.669 | Acc: 41.395,59.371,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.672 | Acc: 41.307,59.318,69.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.679 | Acc: 41.264,59.249,69.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.687 | Acc: 41.152,59.198,69.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.692 | Acc: 41.084,59.186,68.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.692 | Acc: 41.058,59.167,68.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.694 | Acc: 41.007,59.146,68.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.694 | Acc: 41.033,59.228,68.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.702 | Acc: 40.967,59.135,68.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.710 | Acc: 40.851,59.067,68.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.649 | Acc: 35.938,46.094,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.118 | Acc: 29.576,42.560,51.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.089 | Acc: 29.345,41.597,51.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.052 | Acc: 29.086,41.470,51.498,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.159 | Acc: 44.531,64.844,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.483 | Acc: 43.043,61.012,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 42.149,60.575,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 41.957,60.771,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.574 | Acc: 41.821,60.330,70.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.590 | Acc: 41.963,60.195,70.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.596 | Acc: 42.097,60.298,69.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.603 | Acc: 41.800,60.034,69.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.614 | Acc: 41.639,59.880,69.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.612 | Acc: 41.708,59.997,69.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.625 | Acc: 41.480,59.896,69.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.646 | Acc: 41.466,59.697,69.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.654 | Acc: 41.452,59.670,69.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.668 | Acc: 41.212,59.465,68.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.672 | Acc: 41.287,59.453,68.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.681 | Acc: 41.206,59.318,68.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.683 | Acc: 41.151,59.275,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.690 | Acc: 41.067,59.286,68.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.700 | Acc: 40.917,59.154,68.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.711 | Acc: 40.807,59.014,68.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.877 | Acc: 33.594,46.094,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.173 | Acc: 27.604,42.708,51.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.246 | Acc: 27.210,42.435,51.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.220 | Acc: 27.485,42.469,51.793,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 5.098 | Acc: 36.719,51.562,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.699 | Acc: 42.188,59.152,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.667 | Acc: 41.578,59.623,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.656 | Acc: 41.406,59.823,69.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.616 | Acc: 41.252,59.973,70.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.621 | Acc: 41.136,59.971,70.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.606 | Acc: 41.271,60.027,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.634 | Acc: 40.952,59.896,69.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.640 | Acc: 40.863,59.817,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.634 | Acc: 41.078,59.940,69.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.649 | Acc: 40.812,59.764,69.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.668 | Acc: 40.791,59.495,69.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.670 | Acc: 40.719,59.475,69.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.682 | Acc: 40.727,59.393,69.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.678 | Acc: 40.747,59.361,69.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.684 | Acc: 40.674,59.274,69.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.691 | Acc: 40.642,59.190,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.689 | Acc: 40.630,59.171,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.693 | Acc: 40.644,59.128,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.695 | Acc: 40.742,59.121,68.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.039 | Acc: 35.938,50.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.035 | Acc: 34.896,50.298,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.110 | Acc: 34.508,49.981,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.137 | Acc: 34.196,49.885,54.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 5.024 | Acc: 37.500,58.594,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.662 | Acc: 40.179,59.226,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 40.701,60.099,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.590 | Acc: 41.586,60.143,70.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.589 | Acc: 41.590,60.224,69.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.573 | Acc: 41.739,60.265,70.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.596 | Acc: 41.535,60.014,70.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.618 | Acc: 41.229,59.824,69.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.644 | Acc: 40.955,59.555,69.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.638 | Acc: 41.074,59.617,69.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.650 | Acc: 41.029,59.519,69.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.656 | Acc: 41.056,59.287,69.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.674 | Acc: 40.910,59.197,69.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.676 | Acc: 40.876,59.198,69.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.678 | Acc: 40.928,59.147,69.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.686 | Acc: 40.864,59.019,68.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.687 | Acc: 40.912,58.964,68.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.689 | Acc: 40.872,59.004,69.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.691 | Acc: 40.919,59.072,68.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.694 | Acc: 40.926,59.012,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.018 | Acc: 28.125,49.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.360 | Acc: 27.716,45.052,53.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.436 | Acc: 26.829,44.379,53.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.494 | Acc: 26.460,44.019,52.280,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 4.613 | Acc: 37.500,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.656 | Acc: 39.732,59.859,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 40.320,59.699,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.597 | Acc: 41.035,59.939,69.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.591 | Acc: 41.483,60.156,69.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.595 | Acc: 41.375,60.149,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.617 | Acc: 41.296,59.801,69.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.629 | Acc: 41.273,59.635,69.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.666 | Acc: 40.931,59.181,69.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.685 | Acc: 40.660,59.116,69.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.702 | Acc: 40.520,59.130,68.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.699 | Acc: 40.614,59.166,68.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.704 | Acc: 40.586,59.031,68.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.701 | Acc: 40.625,59.121,68.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.704 | Acc: 40.675,59.150,68.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.716 | Acc: 40.563,59.045,68.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.729 | Acc: 40.460,58.893,68.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.725 | Acc: 40.515,58.942,68.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.722 | Acc: 40.463,59.018,68.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.722 | Acc: 40.555,59.022,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.132 | Acc: 35.156,46.094,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.290 | Acc: 31.585,47.731,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.274 | Acc: 31.764,47.675,57.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.274 | Acc: 31.224,48.015,57.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 4.701 | Acc: 43.750,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.444 | Acc: 41.071,61.347,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.512 | Acc: 41.216,60.614,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.549 | Acc: 41.163,60.528,71.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.548 | Acc: 41.628,60.455,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.572 | Acc: 41.282,60.087,70.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.613 | Acc: 41.103,59.536,70.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.624 | Acc: 40.896,59.630,70.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.638 | Acc: 40.902,59.501,69.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.641 | Acc: 41.013,59.448,69.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.636 | Acc: 40.967,59.628,69.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.628 | Acc: 41.092,59.721,69.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.644 | Acc: 40.998,59.437,69.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.662 | Acc: 40.912,59.324,69.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.665 | Acc: 40.864,59.358,69.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.665 | Acc: 41.022,59.365,69.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.664 | Acc: 41.014,59.363,69.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.665 | Acc: 40.994,59.364,69.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.669 | Acc: 41.002,59.312,69.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.669 | Acc: 41.037,59.354,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.089 | Acc: 39.062,48.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.458 | Acc: 31.957,46.726,54.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.537 | Acc: 30.469,45.732,54.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.517 | Acc: 30.789,45.594,53.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.097 | Acc: 50.000,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 41.704,59.821,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 41.559,59.832,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 41.803,59.670,70.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.621 | Acc: 41.715,59.693,69.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.636 | Acc: 41.476,59.545,69.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.650 | Acc: 41.355,59.304,69.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.649 | Acc: 41.162,59.441,69.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.661 | Acc: 41.013,59.516,69.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.658 | Acc: 41.087,59.578,69.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.648 | Acc: 41.146,59.771,69.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.648 | Acc: 41.166,59.799,69.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.662 | Acc: 40.988,59.709,69.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.676 | Acc: 40.903,59.614,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.681 | Acc: 40.864,59.470,69.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.682 | Acc: 40.885,59.492,69.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.678 | Acc: 40.888,59.502,69.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.681 | Acc: 40.898,59.471,69.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.690 | Acc: 40.837,59.394,68.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.693 | Acc: 40.797,59.430,68.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.058 | Acc: 33.594,59.375,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.317 | Acc: 32.664,49.182,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.349 | Acc: 32.184,49.295,56.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.361 | Acc: 31.685,49.590,56.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 4.671 | Acc: 46.094,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.541 | Acc: 42.411,61.570,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 41.997,61.109,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 41.470,60.605,70.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.571 | Acc: 41.445,60.089,70.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.556 | Acc: 41.422,60.125,70.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.571 | Acc: 41.303,60.053,70.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.582 | Acc: 41.345,60.034,69.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.591 | Acc: 41.532,60.059,69.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.592 | Acc: 41.475,60.186,69.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.590 | Acc: 41.616,60.296,69.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.597 | Acc: 41.477,60.209,69.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.603 | Acc: 41.306,60.017,69.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.615 | Acc: 41.149,59.848,69.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.618 | Acc: 41.189,59.862,69.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.636 | Acc: 41.058,59.772,69.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.648 | Acc: 40.963,59.614,69.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.650 | Acc: 40.973,59.625,69.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.653 | Acc: 40.945,59.589,69.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.660 | Acc: 40.906,59.545,69.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.002 | Acc: 27.344,46.094,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.093 | Acc: 24.740,44.345,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.162 | Acc: 24.733,44.684,55.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.208 | Acc: 24.488,44.224,55.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 4.291 | Acc: 42.969,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 40.179,62.649,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.552 | Acc: 40.835,61.833,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.581 | Acc: 41.393,61.091,70.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.577 | Acc: 41.368,61.034,70.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.569 | Acc: 41.669,60.922,70.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.581 | Acc: 41.548,60.776,70.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.590 | Acc: 41.334,60.433,70.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.609 | Acc: 41.159,60.312,70.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.619 | Acc: 41.001,60.234,69.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.645 | Acc: 40.909,60.090,69.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.653 | Acc: 40.837,59.944,69.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.644 | Acc: 40.907,59.887,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.657 | Acc: 40.796,59.788,69.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.653 | Acc: 40.859,59.770,69.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.650 | Acc: 40.968,59.770,69.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.652 | Acc: 41.017,59.650,69.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.662 | Acc: 40.921,59.613,69.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.667 | Acc: 40.999,59.559,69.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.671 | Acc: 40.996,59.531,68.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.653 | Acc: 28.125,42.188,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.550 | Acc: 30.766,44.271,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.553 | Acc: 31.269,44.360,55.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.601 | Acc: 30.840,44.224,54.688,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 4.333 | Acc: 39.062,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 40.104,59.189,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.508 | Acc: 40.835,60.042,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.511 | Acc: 41.675,60.246,71.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.516 | Acc: 41.618,60.340,71.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.551 | Acc: 41.460,60.048,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.553 | Acc: 41.535,60.092,70.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.569 | Acc: 41.240,59.940,70.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.575 | Acc: 41.227,59.996,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.582 | Acc: 41.186,60.096,70.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.602 | Acc: 41.084,59.756,70.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.599 | Acc: 41.194,59.838,70.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.605 | Acc: 41.089,59.770,70.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.612 | Acc: 41.059,59.761,70.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.609 | Acc: 41.162,59.775,70.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.621 | Acc: 41.126,59.689,69.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.627 | Acc: 41.095,59.650,69.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.638 | Acc: 41.019,59.574,69.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.639 | Acc: 41.056,59.598,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.642 | Acc: 41.029,59.605,69.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.267 | Acc: 31.250,50.000,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.567 | Acc: 33.296,44.606,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.617 | Acc: 33.670,44.245,55.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.647 | Acc: 32.736,43.981,55.187,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 4.789 | Acc: 36.719,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 41.853,60.379,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.482 | Acc: 41.540,61.185,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.519 | Acc: 41.342,60.566,70.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.554 | Acc: 41.435,60.243,70.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.549 | Acc: 41.352,59.940,70.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.568 | Acc: 41.348,59.917,69.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.580 | Acc: 41.445,59.929,69.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.589 | Acc: 41.382,59.758,69.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.596 | Acc: 41.311,59.733,69.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.601 | Acc: 41.344,59.597,69.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.598 | Acc: 41.374,59.661,69.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.597 | Acc: 41.422,59.761,69.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.606 | Acc: 41.349,59.680,69.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.606 | Acc: 41.384,59.709,69.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.615 | Acc: 41.266,59.616,69.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.623 | Acc: 41.243,59.579,69.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.631 | Acc: 41.136,59.586,69.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.637 | Acc: 41.058,59.514,69.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.640 | Acc: 41.125,59.494,69.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.746 | Acc: 40.625,53.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.009 | Acc: 34.263,50.037,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.056 | Acc: 33.956,49.771,58.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.059 | Acc: 33.350,49.513,58.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 4.708 | Acc: 41.406,58.594,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.675 | Acc: 40.067,58.519,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.620 | Acc: 41.139,59.604,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 41.624,60.131,70.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.576 | Acc: 41.821,60.301,70.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.562 | Acc: 41.839,60.427,70.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.566 | Acc: 41.936,60.389,70.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.552 | Acc: 41.988,60.555,70.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.549 | Acc: 41.945,60.656,70.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.556 | Acc: 41.959,60.575,70.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.565 | Acc: 41.861,60.588,70.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.572 | Acc: 41.869,60.513,70.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.584 | Acc: 41.857,60.425,70.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.587 | Acc: 41.771,60.441,69.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.602 | Acc: 41.593,60.262,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.603 | Acc: 41.616,60.283,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.614 | Acc: 41.487,60.198,69.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.620 | Acc: 41.425,60.110,69.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.630 | Acc: 41.313,60.042,69.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.640 | Acc: 41.232,59.908,69.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.679 | Acc: 35.156,47.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.613 | Acc: 29.762,47.879,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.651 | Acc: 29.802,47.485,55.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.668 | Acc: 29.905,47.490,55.635,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 4.843 | Acc: 42.969,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.465 | Acc: 42.634,62.612,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.492 | Acc: 42.264,62.462,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.517 | Acc: 41.867,61.693,70.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.512 | Acc: 41.618,61.468,70.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.542 | Acc: 41.267,60.992,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.543 | Acc: 41.535,60.989,70.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.538 | Acc: 41.406,60.949,70.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.547 | Acc: 41.469,60.646,70.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.552 | Acc: 41.402,60.545,70.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.556 | Acc: 41.577,60.459,70.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.563 | Acc: 41.470,60.365,70.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.571 | Acc: 41.468,60.373,69.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.576 | Acc: 41.457,60.378,69.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.593 | Acc: 41.501,60.240,69.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.596 | Acc: 41.469,60.268,69.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.607 | Acc: 41.324,60.173,69.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.613 | Acc: 41.285,60.165,69.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.610 | Acc: 41.311,60.232,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.612 | Acc: 41.326,60.150,69.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.412 | Acc: 30.469,42.969,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.667 | Acc: 30.618,44.420,53.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.736 | Acc: 30.507,43.960,52.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.714 | Acc: 30.443,44.262,53.125,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 4.297 | Acc: 39.062,60.156,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 41.481,60.603,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.509 | Acc: 41.521,60.328,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.510 | Acc: 41.714,60.451,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.517 | Acc: 41.667,60.475,70.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.515 | Acc: 41.762,60.203,71.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.526 | Acc: 41.878,60.227,70.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.531 | Acc: 41.700,60.173,70.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.544 | Acc: 41.426,60.079,70.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.564 | Acc: 41.363,59.910,70.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.589 | Acc: 41.290,59.826,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.598 | Acc: 41.258,59.739,70.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.605 | Acc: 41.309,59.715,69.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.613 | Acc: 41.173,59.617,69.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.621 | Acc: 41.178,59.556,69.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.624 | Acc: 41.149,59.575,69.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.633 | Acc: 41.078,59.509,69.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.639 | Acc: 41.010,59.409,69.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.644 | Acc: 41.019,59.414,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.638 | Acc: 41.117,59.500,69.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.323 | Acc: 24.219,46.094,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.711 | Acc: 25.223,40.365,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.720 | Acc: 25.152,40.149,51.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.764 | Acc: 24.821,39.818,51.114,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 4.434 | Acc: 42.969,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.466 | Acc: 42.150,61.384,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.459 | Acc: 41.540,61.871,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.475 | Acc: 41.726,61.347,71.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.468 | Acc: 41.927,61.362,71.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.515 | Acc: 41.700,61.139,71.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.524 | Acc: 41.774,60.912,70.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.537 | Acc: 41.827,60.771,70.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.560 | Acc: 41.663,60.544,70.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.565 | Acc: 41.695,60.618,70.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.574 | Acc: 41.647,60.389,70.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.581 | Acc: 41.583,60.375,70.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.586 | Acc: 41.588,60.250,69.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.581 | Acc: 41.547,60.237,69.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.586 | Acc: 41.559,60.153,69.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.591 | Acc: 41.422,60.091,69.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.605 | Acc: 41.292,59.983,69.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.614 | Acc: 41.273,59.852,69.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.617 | Acc: 41.276,59.914,69.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.616 | Acc: 41.375,59.908,69.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.837 | Acc: 25.781,39.844,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.081 | Acc: 27.716,39.955,48.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.202 | Acc: 26.620,39.463,47.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.210 | Acc: 26.627,39.754,47.477,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 4.881 | Acc: 35.938,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.436 | Acc: 42.746,61.830,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.567 | Acc: 41.139,61.033,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.551 | Acc: 41.137,60.912,70.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.541 | Acc: 41.310,61.053,71.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.532 | Acc: 41.499,61.038,70.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.536 | Acc: 41.464,60.841,70.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.575 | Acc: 41.157,60.561,70.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.576 | Acc: 41.363,60.593,70.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.570 | Acc: 41.350,60.687,70.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.572 | Acc: 41.348,60.634,70.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.577 | Acc: 41.339,60.552,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.577 | Acc: 41.429,60.545,70.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.566 | Acc: 41.514,60.629,70.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.569 | Acc: 41.556,60.582,69.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.567 | Acc: 41.585,60.623,70.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.573 | Acc: 41.521,60.580,69.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.586 | Acc: 41.425,60.452,69.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.599 | Acc: 41.408,60.334,69.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.604 | Acc: 41.447,60.310,69.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.975 | Acc: 18.750,42.188,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.999 | Acc: 27.716,42.522,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.041 | Acc: 28.163,42.054,52.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.068 | Acc: 27.677,41.829,51.921,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 4.468 | Acc: 39.844,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 41.071,60.640,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 40.777,60.480,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 41.278,60.169,70.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.515 | Acc: 41.696,60.841,70.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.556 | Acc: 40.996,60.427,70.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.542 | Acc: 41.264,60.615,70.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.554 | Acc: 41.079,60.539,70.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.564 | Acc: 41.047,60.428,70.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.558 | Acc: 41.229,60.515,70.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.558 | Acc: 41.243,60.568,70.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.567 | Acc: 41.201,60.584,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.576 | Acc: 41.163,60.545,70.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.571 | Acc: 41.257,60.611,70.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.573 | Acc: 41.273,60.529,70.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.572 | Acc: 41.323,60.499,69.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.581 | Acc: 41.287,60.380,69.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.589 | Acc: 41.228,60.291,69.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.587 | Acc: 41.237,60.284,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.590 | Acc: 41.246,60.285,69.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.796 | Acc: 35.156,56.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.168 | Acc: 34.896,47.656,58.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.141 | Acc: 34.813,47.199,57.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.174 | Acc: 34.503,47.554,56.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 4.932 | Acc: 39.062,57.812,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.443 | Acc: 43.006,61.719,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.482 | Acc: 42.207,61.528,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.518 | Acc: 41.855,61.258,71.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.547 | Acc: 41.512,60.841,70.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.558 | Acc: 41.414,60.667,70.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.563 | Acc: 41.296,60.544,70.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.560 | Acc: 41.379,60.566,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.551 | Acc: 41.542,60.685,70.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.555 | Acc: 41.592,60.575,70.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.572 | Acc: 41.476,60.448,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.572 | Acc: 41.551,60.496,70.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.578 | Acc: 41.542,60.526,70.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.581 | Acc: 41.460,60.503,70.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.593 | Acc: 41.356,60.318,70.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.593 | Acc: 41.360,60.255,70.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.602 | Acc: 41.306,60.147,70.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.604 | Acc: 41.342,60.115,69.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.603 | Acc: 41.354,60.128,69.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.605 | Acc: 41.357,60.082,69.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.910 | Acc: 19.531,43.750,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.158 | Acc: 22.693,40.699,50.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.238 | Acc: 22.218,39.977,50.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.245 | Acc: 22.208,39.857,50.653,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 4.454 | Acc: 43.750,57.031,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.527 | Acc: 41.369,60.231,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.464 | Acc: 42.188,60.556,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.517 | Acc: 41.880,60.438,71.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.514 | Acc: 41.696,60.812,71.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.519 | Acc: 41.600,60.783,71.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.509 | Acc: 41.729,60.957,71.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.519 | Acc: 41.905,60.865,71.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.515 | Acc: 41.843,60.870,71.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.513 | Acc: 41.929,60.912,71.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.529 | Acc: 41.772,60.747,70.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.539 | Acc: 41.721,60.655,70.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.551 | Acc: 41.685,60.610,70.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.557 | Acc: 41.741,60.530,70.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.565 | Acc: 41.668,60.462,70.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.562 | Acc: 41.671,60.483,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.563 | Acc: 41.662,60.463,70.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.569 | Acc: 41.690,60.486,70.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.566 | Acc: 41.627,60.531,70.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.567 | Acc: 41.515,60.499,70.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.243 | Acc: 27.344,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.707 | Acc: 29.055,45.945,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.773 | Acc: 28.392,45.770,56.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.809 | Acc: 28.176,45.671,55.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 4.550 | Acc: 49.219,57.031,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.367 | Acc: 42.411,61.979,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.441 | Acc: 42.245,61.719,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.448 | Acc: 42.264,61.501,71.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.446 | Acc: 42.458,61.516,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.425 | Acc: 42.690,61.804,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.466 | Acc: 42.355,61.454,71.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.473 | Acc: 42.221,61.403,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.466 | Acc: 42.314,61.549,71.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.481 | Acc: 42.304,61.438,71.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.490 | Acc: 42.141,61.272,70.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.505 | Acc: 42.057,61.174,70.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.514 | Acc: 42.029,61.077,70.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.519 | Acc: 41.936,60.967,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.525 | Acc: 41.926,60.887,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.539 | Acc: 41.840,60.740,70.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.552 | Acc: 41.737,60.701,70.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.563 | Acc: 41.647,60.559,70.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.563 | Acc: 41.683,60.535,70.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.580 | Acc: 41.583,60.347,70.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.872 | Acc: 36.719,57.812,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.340 | Acc: 32.961,48.251,55.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.352 | Acc: 32.946,48.247,55.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.394 | Acc: 32.223,47.695,55.546,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 4.256 | Acc: 50.000,61.719,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 41.481,60.193,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.488 | Acc: 41.482,60.156,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.528 | Acc: 41.381,59.695,71.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.491 | Acc: 41.522,60.311,71.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.489 | Acc: 41.623,60.226,71.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.499 | Acc: 41.445,60.221,70.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.496 | Acc: 41.589,60.588,70.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.506 | Acc: 41.659,60.506,70.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.516 | Acc: 41.678,60.458,70.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.509 | Acc: 41.834,60.545,70.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.516 | Acc: 41.682,60.566,70.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.533 | Acc: 41.601,60.474,70.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.537 | Acc: 41.583,60.444,70.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.536 | Acc: 41.529,60.484,70.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.548 | Acc: 41.489,60.385,70.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.547 | Acc: 41.484,60.458,70.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.552 | Acc: 41.523,60.420,70.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.559 | Acc: 41.510,60.375,70.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.574 | Acc: 41.386,60.300,70.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.579 | Acc: 35.938,40.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.642 | Acc: 30.357,35.045,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.699 | Acc: 29.707,34.985,49.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.710 | Acc: 29.342,35.220,49.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 4.421 | Acc: 42.188,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.401 | Acc: 40.774,61.049,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 41.387,61.223,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.420 | Acc: 41.496,61.335,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.452 | Acc: 41.734,61.111,71.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.454 | Acc: 41.870,61.170,71.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.466 | Acc: 41.819,61.067,71.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.468 | Acc: 41.700,61.032,71.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.478 | Acc: 41.625,61.044,70.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.496 | Acc: 41.536,60.994,70.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.501 | Acc: 41.853,61.015,70.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.514 | Acc: 41.859,60.877,70.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.519 | Acc: 41.938,60.928,70.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.520 | Acc: 41.861,60.997,70.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.516 | Acc: 41.884,60.926,70.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.525 | Acc: 41.798,60.844,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.528 | Acc: 41.825,60.818,70.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.545 | Acc: 41.672,60.718,70.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.557 | Acc: 41.543,60.615,70.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.560 | Acc: 41.556,60.626,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.860 | Acc: 32.031,54.688,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.997 | Acc: 34.152,49.293,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.069 | Acc: 34.013,48.609,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.097 | Acc: 33.414,47.912,55.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 4.876 | Acc: 40.625,60.156,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.760 | Acc: 39.286,58.557,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.520 | Acc: 41.349,61.223,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.488 | Acc: 41.586,61.706,72.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.491 | Acc: 41.454,61.497,72.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.467 | Acc: 41.886,61.688,72.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.485 | Acc: 41.787,61.357,71.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.480 | Acc: 41.949,61.198,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.482 | Acc: 41.896,61.069,71.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.490 | Acc: 41.929,60.972,71.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.503 | Acc: 41.908,60.918,71.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.507 | Acc: 41.922,60.821,71.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.520 | Acc: 41.873,60.578,71.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.522 | Acc: 41.792,60.599,70.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.528 | Acc: 41.737,60.629,70.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.523 | Acc: 41.819,60.668,70.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.528 | Acc: 41.730,60.638,70.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.531 | Acc: 41.681,60.525,70.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.536 | Acc: 41.644,60.524,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.543 | Acc: 41.556,60.398,70.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.051 | Acc: 35.938,50.781,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.738 | Acc: 30.283,47.321,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.725 | Acc: 29.973,46.799,55.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.740 | Acc: 29.841,46.401,55.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 4.419 | Acc: 43.750,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.365 | Acc: 44.643,61.458,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.367 | Acc: 43.979,61.871,72.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.417 | Acc: 43.379,61.155,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.431 | Acc: 42.911,61.188,72.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.475 | Acc: 42.621,60.791,71.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.495 | Acc: 42.246,60.628,71.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.499 | Acc: 42.332,60.705,71.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.506 | Acc: 42.168,60.685,71.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.516 | Acc: 42.028,60.584,71.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.519 | Acc: 41.993,60.700,71.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.525 | Acc: 41.944,60.690,71.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.532 | Acc: 41.961,60.519,70.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.534 | Acc: 41.906,60.542,70.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.534 | Acc: 42.035,60.554,70.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.544 | Acc: 41.967,60.444,70.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.551 | Acc: 41.905,60.424,70.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.552 | Acc: 41.990,60.356,70.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.558 | Acc: 41.988,60.368,70.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.560 | Acc: 41.937,60.345,70.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.187 | Acc: 32.031,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.653 | Acc: 28.943,46.615,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.668 | Acc: 29.306,47.104,56.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.692 | Acc: 28.996,46.952,55.866,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 4.294 | Acc: 40.625,60.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.456 | Acc: 41.406,60.826,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.479 | Acc: 41.044,61.433,71.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.501 | Acc: 41.560,61.002,71.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.474 | Acc: 41.879,61.246,71.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.458 | Acc: 42.497,61.278,71.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.473 | Acc: 42.407,61.092,71.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.468 | Acc: 42.221,61.037,71.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.483 | Acc: 42.183,60.797,71.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.484 | Acc: 42.136,60.959,71.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.490 | Acc: 42.168,60.883,71.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.498 | Acc: 42.057,60.778,71.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.498 | Acc: 42.071,60.740,71.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.504 | Acc: 42.029,60.728,70.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.506 | Acc: 42.021,60.690,70.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.504 | Acc: 42.193,60.787,70.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.519 | Acc: 42.107,60.633,70.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.524 | Acc: 41.917,60.589,70.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.535 | Acc: 41.820,60.483,70.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.535 | Acc: 41.898,60.445,70.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.902 | Acc: 26.562,44.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.849 | Acc: 22.619,41.369,55.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.948 | Acc: 22.618,40.701,54.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.925 | Acc: 22.259,41.060,54.854,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.295 | Acc: 38.281,62.500,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.406 | Acc: 42.076,61.198,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.447 | Acc: 41.997,61.242,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.451 | Acc: 41.995,60.938,71.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.441 | Acc: 42.226,61.188,71.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.486 | Acc: 41.801,60.566,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.495 | Acc: 41.697,60.473,71.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.522 | Acc: 41.633,60.311,70.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.514 | Acc: 41.557,60.491,71.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.519 | Acc: 41.592,60.432,70.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.529 | Acc: 41.651,60.382,70.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.535 | Acc: 41.601,60.284,70.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.543 | Acc: 41.575,60.390,70.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.530 | Acc: 41.652,60.605,70.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.535 | Acc: 41.626,60.554,70.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.539 | Acc: 41.539,60.590,70.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.548 | Acc: 41.552,60.521,70.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.544 | Acc: 41.640,60.564,70.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.543 | Acc: 41.653,60.554,70.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.543 | Acc: 41.667,60.579,70.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.923 | Acc: 31.250,50.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.244 | Acc: 31.510,47.507,57.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.233 | Acc: 32.450,47.409,57.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.266 | Acc: 32.287,47.234,56.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 4.358 | Acc: 43.750,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 42.039,60.751,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.473 | Acc: 42.340,60.556,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.472 | Acc: 42.572,60.438,71.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.448 | Acc: 42.429,61.217,71.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.436 | Acc: 42.559,61.324,71.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.430 | Acc: 42.614,61.370,71.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.444 | Acc: 42.548,61.253,71.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.482 | Acc: 42.221,60.923,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.476 | Acc: 42.188,60.920,71.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.493 | Acc: 41.989,60.731,71.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.495 | Acc: 42.057,60.764,71.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.491 | Acc: 42.106,60.850,71.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.500 | Acc: 42.149,60.884,70.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.506 | Acc: 42.101,60.843,70.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.509 | Acc: 41.972,60.839,70.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.517 | Acc: 41.810,60.770,70.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.521 | Acc: 41.796,60.768,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.526 | Acc: 41.772,60.751,70.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.531 | Acc: 41.740,60.730,70.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.092 | Acc: 28.906,59.375,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.603 | Acc: 27.009,48.624,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.594 | Acc: 26.982,47.828,57.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.617 | Acc: 26.383,47.144,57.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 4.803 | Acc: 39.062,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 41.741,61.682,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.496 | Acc: 41.482,61.585,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.473 | Acc: 42.072,61.668,71.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.440 | Acc: 42.544,61.709,71.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.450 | Acc: 42.412,61.564,71.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.457 | Acc: 42.368,61.693,71.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.440 | Acc: 42.437,61.868,71.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.443 | Acc: 42.343,61.816,71.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.463 | Acc: 42.123,61.654,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.460 | Acc: 42.110,61.614,71.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.471 | Acc: 41.961,61.418,71.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.489 | Acc: 41.902,61.210,71.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.489 | Acc: 41.906,61.123,71.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.509 | Acc: 41.829,61.010,71.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.511 | Acc: 41.842,60.927,70.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.519 | Acc: 41.847,60.818,70.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.524 | Acc: 41.777,60.738,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.531 | Acc: 41.724,60.680,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.536 | Acc: 41.663,60.687,70.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.256 | Acc: 34.375,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.717 | Acc: 30.469,45.610,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.708 | Acc: 29.878,44.912,55.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.720 | Acc: 29.803,45.325,55.853,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 4.484 | Acc: 41.406,58.594,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.394 | Acc: 42.932,61.830,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 43.426,62.271,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.390 | Acc: 42.853,61.424,72.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.434 | Acc: 42.564,61.130,71.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.416 | Acc: 42.659,61.193,71.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.435 | Acc: 42.459,61.209,71.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.440 | Acc: 42.503,61.165,71.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.467 | Acc: 42.479,60.874,71.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.479 | Acc: 42.295,60.825,71.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.470 | Acc: 42.339,60.945,71.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.466 | Acc: 42.350,60.973,71.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.466 | Acc: 42.421,61.083,71.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.470 | Acc: 42.367,61.150,71.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.473 | Acc: 42.282,61.185,71.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.475 | Acc: 42.289,61.130,71.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.475 | Acc: 42.256,61.193,71.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.485 | Acc: 42.206,61.132,71.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.493 | Acc: 42.045,61.037,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.498 | Acc: 42.030,60.952,71.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.806 | Acc: 33.594,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.995 | Acc: 34.301,49.628,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.048 | Acc: 34.413,49.600,57.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.067 | Acc: 33.901,49.654,57.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 4.246 | Acc: 42.188,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.321 | Acc: 43.862,62.649,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.319 | Acc: 43.216,62.500,73.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.370 | Acc: 43.071,61.808,72.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.423 | Acc: 42.380,61.651,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.409 | Acc: 42.543,62.013,71.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.411 | Acc: 42.568,61.816,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.419 | Acc: 42.542,61.846,71.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.430 | Acc: 42.309,61.656,71.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.430 | Acc: 42.239,61.689,71.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.441 | Acc: 42.211,61.773,71.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.446 | Acc: 42.145,61.712,71.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.454 | Acc: 42.158,61.557,71.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.457 | Acc: 42.155,61.581,71.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.470 | Acc: 42.124,61.457,71.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.482 | Acc: 42.029,61.389,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.482 | Acc: 42.112,61.397,70.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.485 | Acc: 42.192,61.430,70.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.492 | Acc: 42.105,61.360,70.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.499 | Acc: 42.069,61.296,70.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.369 | Acc: 31.250,50.000,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.393 | Acc: 31.882,48.549,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.431 | Acc: 30.716,48.476,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.440 | Acc: 30.635,48.489,55.392,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 4.804 | Acc: 38.281,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.366 | Acc: 43.713,61.830,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.377 | Acc: 43.350,61.585,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.373 | Acc: 42.969,61.744,72.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.394 | Acc: 42.323,61.497,72.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.446 | Acc: 42.304,61.278,72.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.450 | Acc: 42.433,61.351,72.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.469 | Acc: 42.176,61.115,71.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.479 | Acc: 42.095,61.093,71.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.489 | Acc: 42.023,60.994,71.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.502 | Acc: 42.040,60.848,71.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.508 | Acc: 42.004,60.846,71.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.500 | Acc: 42.016,60.970,71.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.506 | Acc: 41.930,60.884,71.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.493 | Acc: 42.054,61.018,71.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.492 | Acc: 42.003,60.956,71.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.499 | Acc: 41.903,60.945,71.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.499 | Acc: 41.876,61.011,71.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.500 | Acc: 41.865,61.022,71.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.505 | Acc: 41.808,60.976,71.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.714 | Acc: 30.469,46.094,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.035 | Acc: 32.217,44.866,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.994 | Acc: 31.898,44.569,53.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.999 | Acc: 31.698,44.454,52.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 4.538 | Acc: 40.625,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.460 | Acc: 40.216,61.533,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.451 | Acc: 41.197,61.814,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.420 | Acc: 41.470,62.013,72.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.426 | Acc: 41.715,61.728,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.407 | Acc: 42.025,61.866,72.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.422 | Acc: 41.697,61.745,71.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.411 | Acc: 41.883,61.951,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.413 | Acc: 41.969,61.908,71.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.424 | Acc: 41.881,61.689,71.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.425 | Acc: 41.904,61.707,71.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.431 | Acc: 41.975,61.690,71.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.441 | Acc: 41.886,61.586,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.443 | Acc: 41.957,61.617,71.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.462 | Acc: 41.934,61.402,71.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.473 | Acc: 41.910,61.314,71.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.478 | Acc: 41.959,61.310,71.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.489 | Acc: 41.945,61.155,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.490 | Acc: 41.995,61.197,71.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.491 | Acc: 41.982,61.159,71.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.114 | Acc: 33.594,48.438,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.478 | Acc: 26.414,44.866,48.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.496 | Acc: 25.305,44.150,47.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.458 | Acc: 25.051,44.634,48.066,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 3.932 | Acc: 41.406,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.505 | Acc: 40.885,61.012,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.419 | Acc: 42.207,61.204,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.433 | Acc: 41.816,60.848,72.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.419 | Acc: 42.236,61.333,72.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.457 | Acc: 42.095,61.177,71.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.449 | Acc: 42.155,61.235,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.444 | Acc: 42.160,61.408,71.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.438 | Acc: 42.192,61.457,71.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.458 | Acc: 42.218,61.360,71.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.460 | Acc: 42.269,61.330,71.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.465 | Acc: 42.322,61.312,71.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.473 | Acc: 42.239,61.236,71.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.483 | Acc: 42.113,61.189,71.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.479 | Acc: 42.213,61.299,71.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.478 | Acc: 42.226,61.236,71.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.485 | Acc: 42.175,61.181,71.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.487 | Acc: 42.096,61.137,71.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.488 | Acc: 42.097,61.145,71.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.488 | Acc: 42.126,61.099,70.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.180 | Acc: 26.562,48.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.342 | Acc: 31.324,47.098,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.339 | Acc: 30.888,47.027,56.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.371 | Acc: 30.507,46.824,56.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 4.648 | Acc: 40.625,56.250,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.453 | Acc: 43.155,61.644,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.454 | Acc: 42.340,61.338,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.428 | Acc: 42.213,61.629,72.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.411 | Acc: 42.168,61.671,72.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.432 | Acc: 41.948,61.580,71.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.443 | Acc: 41.839,61.467,71.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.443 | Acc: 41.905,61.425,71.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.430 | Acc: 41.921,61.432,71.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.441 | Acc: 41.885,61.443,71.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.448 | Acc: 41.888,61.299,71.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.452 | Acc: 41.947,61.256,71.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.459 | Acc: 41.938,61.203,71.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.466 | Acc: 41.828,61.105,71.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.476 | Acc: 41.782,60.946,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.476 | Acc: 41.790,60.956,71.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.474 | Acc: 41.903,60.955,71.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.476 | Acc: 41.938,60.896,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.474 | Acc: 41.945,61.011,71.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.483 | Acc: 41.917,60.892,71.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.463 | Acc: 27.344,45.312,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.157 | Acc: 26.860,43.713,53.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.217 | Acc: 26.467,43.921,52.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.225 | Acc: 26.332,43.238,52.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 4.080 | Acc: 41.406,63.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.405 | Acc: 42.597,62.016,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.414 | Acc: 42.759,62.062,73.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.431 | Acc: 42.200,61.847,73.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.444 | Acc: 42.081,61.497,72.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.426 | Acc: 42.288,61.549,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.420 | Acc: 42.168,61.751,72.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.435 | Acc: 42.121,61.580,72.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.442 | Acc: 42.139,61.301,71.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.453 | Acc: 41.885,61.261,71.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.443 | Acc: 42.040,61.513,71.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.438 | Acc: 42.177,61.482,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.451 | Acc: 41.996,61.301,71.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.458 | Acc: 42.011,61.300,71.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.458 | Acc: 41.932,61.349,71.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.456 | Acc: 41.897,61.361,71.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.463 | Acc: 41.878,61.310,71.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.466 | Acc: 41.828,61.283,71.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.468 | Acc: 41.841,61.269,71.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.470 | Acc: 41.866,61.235,71.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.232 | Acc: 20.312,44.531,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.383 | Acc: 22.359,46.615,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.337 | Acc: 22.104,46.951,56.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.372 | Acc: 21.721,46.657,56.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 4.533 | Acc: 34.375,59.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.452 | Acc: 42.374,62.798,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.377 | Acc: 43.236,62.462,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.393 | Acc: 42.982,61.911,72.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.413 | Acc: 42.573,61.458,71.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.414 | Acc: 42.420,61.742,71.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.423 | Acc: 42.478,61.564,71.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.453 | Acc: 42.370,61.298,71.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.458 | Acc: 42.197,61.136,71.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.465 | Acc: 42.144,61.184,71.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.468 | Acc: 42.219,61.175,71.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.477 | Acc: 42.156,61.090,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.478 | Acc: 42.012,61.103,71.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.487 | Acc: 41.972,61.072,71.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.489 | Acc: 41.934,61.102,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.492 | Acc: 41.933,61.072,70.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.494 | Acc: 41.995,61.025,70.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.495 | Acc: 41.970,61.038,70.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.491 | Acc: 41.980,61.100,70.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.493 | Acc: 42.026,61.048,70.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.929 | Acc: 35.938,50.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.090 | Acc: 35.826,49.851,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.152 | Acc: 35.347,49.371,56.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.194 | Acc: 34.990,49.091,55.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 3.684 | Acc: 46.875,71.094,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.242 | Acc: 44.420,63.690,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.283 | Acc: 43.255,63.300,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.320 | Acc: 42.597,62.923,73.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.363 | Acc: 42.438,62.307,73.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.350 | Acc: 42.667,62.469,73.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.386 | Acc: 42.336,62.326,72.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.409 | Acc: 42.260,62.068,72.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.400 | Acc: 42.372,62.044,72.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.420 | Acc: 42.390,61.870,72.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.414 | Acc: 42.460,61.999,72.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.427 | Acc: 42.350,61.853,72.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.431 | Acc: 42.398,61.861,71.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.438 | Acc: 42.388,61.812,71.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.446 | Acc: 42.315,61.760,71.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.454 | Acc: 42.242,61.690,71.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.462 | Acc: 42.168,61.636,71.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.456 | Acc: 42.183,61.629,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.463 | Acc: 42.218,61.559,71.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.470 | Acc: 42.169,61.510,71.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.828 | Acc: 35.938,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.473 | Acc: 32.738,48.735,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.461 | Acc: 32.698,48.266,55.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.461 | Acc: 32.134,47.887,55.789,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 5.057 | Acc: 37.500,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.472 | Acc: 42.411,61.012,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.421 | Acc: 42.473,61.319,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.398 | Acc: 43.046,61.655,72.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.407 | Acc: 42.834,61.584,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.420 | Acc: 42.582,61.525,72.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.443 | Acc: 42.207,61.389,71.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.437 | Acc: 42.215,61.331,71.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.451 | Acc: 42.037,61.166,71.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.445 | Acc: 42.054,61.266,71.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.442 | Acc: 42.106,61.338,71.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.454 | Acc: 42.124,61.227,71.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.450 | Acc: 42.207,61.317,71.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.443 | Acc: 42.196,61.339,71.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.456 | Acc: 42.099,61.238,71.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.469 | Acc: 42.073,61.194,71.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.470 | Acc: 42.127,61.247,71.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.471 | Acc: 42.153,61.265,71.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.468 | Acc: 42.278,61.334,71.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.474 | Acc: 42.163,61.325,71.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.233 | Acc: 27.344,53.125,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.910 | Acc: 28.869,47.247,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.985 | Acc: 28.087,46.684,54.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.048 | Acc: 27.677,45.966,54.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 4.154 | Acc: 43.750,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.333 | Acc: 41.815,62.240,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.391 | Acc: 41.730,61.604,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.417 | Acc: 41.816,61.411,72.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.428 | Acc: 41.551,61.516,72.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.422 | Acc: 41.584,61.518,72.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.403 | Acc: 41.671,61.770,72.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.410 | Acc: 41.872,61.547,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.413 | Acc: 41.969,61.525,72.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.417 | Acc: 42.110,61.576,72.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.427 | Acc: 42.195,61.478,71.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.438 | Acc: 42.156,61.401,71.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.452 | Acc: 41.996,61.255,71.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.459 | Acc: 41.942,61.168,71.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.461 | Acc: 41.954,61.182,71.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.465 | Acc: 42.019,61.124,71.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.469 | Acc: 42.046,61.118,71.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.474 | Acc: 42.036,61.075,71.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.482 | Acc: 41.928,61.028,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.485 | Acc: 41.917,60.964,71.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.958 | Acc: 34.375,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.511 | Acc: 30.915,48.140,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.491 | Acc: 30.278,48.018,57.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.485 | Acc: 30.020,48.028,56.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 4.345 | Acc: 41.406,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.367 | Acc: 41.964,63.542,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.349 | Acc: 42.607,62.786,73.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.357 | Acc: 42.623,62.436,72.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.365 | Acc: 42.641,62.201,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.364 | Acc: 42.737,62.059,72.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.367 | Acc: 42.891,62.016,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.384 | Acc: 42.681,61.891,72.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.397 | Acc: 42.682,61.772,72.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.394 | Acc: 42.701,61.710,72.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.392 | Acc: 42.743,61.703,72.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.406 | Acc: 42.728,61.655,71.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.420 | Acc: 42.583,61.492,71.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.426 | Acc: 42.636,61.431,71.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.420 | Acc: 42.671,61.580,71.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.432 | Acc: 42.496,61.534,71.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.427 | Acc: 42.518,61.619,71.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.439 | Acc: 42.401,61.499,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.448 | Acc: 42.343,61.392,71.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.453 | Acc: 42.308,61.300,71.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.954 | Acc: 32.031,50.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.353 | Acc: 30.060,49.479,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.369 | Acc: 29.078,48.742,59.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.401 | Acc: 28.945,48.706,58.952,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 4.314 | Acc: 40.625,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.253 | Acc: 44.717,63.728,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.302 | Acc: 43.445,62.976,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.326 | Acc: 42.994,63.166,73.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.361 | Acc: 42.921,62.703,73.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.384 | Acc: 42.930,62.616,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.365 | Acc: 43.240,62.687,72.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.380 | Acc: 42.958,62.395,72.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.388 | Acc: 42.833,62.253,72.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.391 | Acc: 42.740,62.042,72.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.394 | Acc: 42.751,61.905,72.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.408 | Acc: 42.492,61.814,72.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.422 | Acc: 42.473,61.696,71.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.433 | Acc: 42.460,61.527,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.433 | Acc: 42.571,61.466,71.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.442 | Acc: 42.439,61.464,71.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.447 | Acc: 42.409,61.441,71.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.448 | Acc: 42.387,61.494,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.454 | Acc: 42.307,61.409,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.458 | Acc: 42.245,61.421,71.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.720 | Acc: 33.594,55.469,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.160 | Acc: 31.473,50.856,57.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.166 | Acc: 31.726,50.800,57.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.164 | Acc: 31.839,50.487,57.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 4.595 | Acc: 38.281,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.280 | Acc: 43.824,63.765,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 43.255,62.976,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 43.379,62.859,73.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.298 | Acc: 43.383,62.963,73.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.307 | Acc: 43.394,62.864,73.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.342 | Acc: 42.704,62.519,72.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.328 | Acc: 42.808,62.511,72.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.349 | Acc: 42.532,62.311,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.359 | Acc: 42.563,62.263,72.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.373 | Acc: 42.471,62.123,72.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.395 | Acc: 42.195,61.984,72.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.408 | Acc: 42.152,61.845,72.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.410 | Acc: 42.262,61.719,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.416 | Acc: 42.293,61.599,72.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.421 | Acc: 42.312,61.540,71.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.431 | Acc: 42.207,61.519,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.430 | Acc: 42.261,61.577,71.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.436 | Acc: 42.281,61.492,71.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.440 | Acc: 42.290,61.426,71.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.951 | Acc: 26.562,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.463 | Acc: 27.158,46.466,54.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.505 | Acc: 25.705,46.265,54.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.539 | Acc: 25.499,45.786,54.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 4.013 | Acc: 49.219,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.412 | Acc: 42.411,62.574,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.355 | Acc: 43.026,62.538,72.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.358 | Acc: 42.572,62.423,72.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.366 | Acc: 42.448,62.548,72.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.361 | Acc: 42.528,62.717,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.364 | Acc: 42.665,62.610,72.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.381 | Acc: 42.581,62.511,72.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.378 | Acc: 42.658,62.442,72.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.385 | Acc: 42.697,62.444,72.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.378 | Acc: 42.837,62.481,72.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.384 | Acc: 42.788,62.376,72.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.397 | Acc: 42.638,62.296,72.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.400 | Acc: 42.505,62.189,71.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.401 | Acc: 42.549,62.139,71.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.409 | Acc: 42.509,62.080,71.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.417 | Acc: 42.351,61.969,71.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.420 | Acc: 42.297,61.936,71.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.422 | Acc: 42.300,61.903,71.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.428 | Acc: 42.200,61.862,71.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.672 | Acc: 28.125,55.469,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.233 | Acc: 26.860,45.610,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.195 | Acc: 26.448,44.417,55.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.240 | Acc: 26.025,44.134,54.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 4.498 | Acc: 42.188,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.383 | Acc: 40.625,60.528,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.299 | Acc: 42.569,62.710,72.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.298 | Acc: 42.969,62.180,73.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.313 | Acc: 42.795,62.027,72.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.329 | Acc: 42.543,62.090,72.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.341 | Acc: 42.452,62.113,72.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.351 | Acc: 42.465,62.090,72.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.370 | Acc: 42.391,61.961,72.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.391 | Acc: 42.300,61.896,72.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.405 | Acc: 41.993,61.746,72.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.422 | Acc: 41.855,61.630,72.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.419 | Acc: 41.867,61.673,71.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.426 | Acc: 41.900,61.662,71.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.435 | Acc: 41.782,61.571,71.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.432 | Acc: 41.954,61.610,71.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.430 | Acc: 42.005,61.714,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.437 | Acc: 41.942,61.694,71.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.439 | Acc: 42.017,61.682,71.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.446 | Acc: 41.974,61.610,71.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.214 | Acc: 34.375,49.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.118 | Acc: 30.432,48.958,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.200 | Acc: 30.354,48.780,58.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.218 | Acc: 30.200,48.745,58.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 4.219 | Acc: 43.750,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.368 | Acc: 41.592,61.607,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.339 | Acc: 42.550,61.719,72.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 43.199,62.013,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.312 | Acc: 43.007,62.211,73.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.318 | Acc: 43.170,62.167,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.330 | Acc: 42.988,61.932,72.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.343 | Acc: 42.791,61.935,72.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.355 | Acc: 42.615,61.903,72.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.375 | Acc: 42.477,61.667,72.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.389 | Acc: 42.588,61.610,72.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.384 | Acc: 42.587,61.683,72.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.389 | Acc: 42.564,61.673,72.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.393 | Acc: 42.598,61.635,72.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.402 | Acc: 42.580,61.596,72.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.407 | Acc: 42.525,61.563,72.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.420 | Acc: 42.477,61.456,71.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.422 | Acc: 42.472,61.503,71.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.427 | Acc: 42.348,61.455,71.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.430 | Acc: 42.265,61.397,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.003 | Acc: 30.469,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.350 | Acc: 30.692,50.744,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.399 | Acc: 30.126,50.000,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.446 | Acc: 30.558,49.680,57.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 4.914 | Acc: 42.188,60.156,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.335 | Acc: 42.188,62.277,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.316 | Acc: 42.283,62.614,72.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 42.841,63.102,73.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.335 | Acc: 42.631,62.404,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.332 | Acc: 42.652,62.724,73.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.350 | Acc: 42.736,62.565,73.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.371 | Acc: 42.487,62.328,72.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.369 | Acc: 42.474,62.384,73.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.363 | Acc: 42.360,62.470,73.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.371 | Acc: 42.366,62.306,72.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.386 | Acc: 42.258,62.118,72.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.403 | Acc: 42.239,61.910,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.421 | Acc: 42.149,61.740,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.409 | Acc: 42.360,61.866,72.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.411 | Acc: 42.393,61.802,72.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.420 | Acc: 42.404,61.731,71.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.411 | Acc: 42.476,61.847,72.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.423 | Acc: 42.397,61.712,71.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.427 | Acc: 42.333,61.729,71.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.852 | Acc: 23.438,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.233 | Acc: 21.801,43.601,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.261 | Acc: 21.627,42.969,56.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.313 | Acc: 21.491,42.661,55.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 4.310 | Acc: 39.844,60.156,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.401 | Acc: 42.857,61.421,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.393 | Acc: 43.178,61.433,73.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.358 | Acc: 43.289,62.218,73.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.370 | Acc: 42.699,62.355,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.356 | Acc: 42.860,62.361,73.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.380 | Acc: 42.833,61.945,72.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.410 | Acc: 42.404,61.508,72.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.399 | Acc: 42.416,61.748,72.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.392 | Acc: 42.455,61.753,72.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.401 | Acc: 42.277,61.758,72.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.399 | Acc: 42.456,61.835,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.408 | Acc: 42.437,61.780,72.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.410 | Acc: 42.427,61.662,72.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.408 | Acc: 42.382,61.674,72.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.414 | Acc: 42.385,61.581,72.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.419 | Acc: 42.278,61.570,72.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.421 | Acc: 42.213,61.604,72.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.424 | Acc: 42.149,61.613,72.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.420 | Acc: 42.179,61.639,72.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.979 | Acc: 28.125,40.625,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.177 | Acc: 25.595,44.978,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.159 | Acc: 25.934,45.198,55.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.132 | Acc: 25.384,45.159,55.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 5.051 | Acc: 28.125,53.906,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.268 | Acc: 43.155,64.025,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.263 | Acc: 43.331,63.815,73.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.252 | Acc: 43.097,63.397,74.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.293 | Acc: 42.766,62.886,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.293 | Acc: 43.062,62.995,73.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.285 | Acc: 42.885,63.017,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.298 | Acc: 42.941,62.943,73.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.315 | Acc: 42.857,62.616,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.314 | Acc: 43.077,62.617,73.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.318 | Acc: 42.922,62.620,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.328 | Acc: 42.827,62.482,73.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.339 | Acc: 42.765,62.361,72.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.353 | Acc: 42.559,62.210,72.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.364 | Acc: 42.591,62.208,72.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.374 | Acc: 42.574,62.173,72.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.383 | Acc: 42.550,62.145,72.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.382 | Acc: 42.527,62.172,72.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.392 | Acc: 42.551,62.119,72.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.404 | Acc: 42.518,61.959,71.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.672 | Acc: 37.500,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.235 | Acc: 32.106,48.177,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.293 | Acc: 31.421,47.828,57.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.273 | Acc: 31.122,47.964,57.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 3.964 | Acc: 42.969,62.500,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.353 | Acc: 43.713,62.091,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.389 | Acc: 43.178,61.357,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.359 | Acc: 43.058,61.796,73.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.354 | Acc: 43.084,61.854,72.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.361 | Acc: 43.069,61.750,72.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.368 | Acc: 43.020,61.603,72.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.371 | Acc: 43.096,61.619,72.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.380 | Acc: 43.017,61.748,72.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.379 | Acc: 42.934,61.870,72.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.390 | Acc: 42.720,61.668,72.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.388 | Acc: 42.661,61.683,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.390 | Acc: 42.580,61.780,72.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.394 | Acc: 42.601,61.773,71.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.386 | Acc: 42.680,61.927,72.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.390 | Acc: 42.535,61.908,71.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.395 | Acc: 42.528,61.909,71.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.397 | Acc: 42.561,61.904,71.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.412 | Acc: 42.356,61.691,71.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.418 | Acc: 42.393,61.672,71.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.904 | Acc: 34.375,52.344,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.213 | Acc: 32.552,48.735,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.216 | Acc: 32.355,48.666,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.246 | Acc: 32.339,48.809,56.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 4.290 | Acc: 42.969,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.318 | Acc: 42.708,62.165,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.309 | Acc: 42.397,62.062,73.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.291 | Acc: 42.866,62.641,73.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.320 | Acc: 42.872,62.211,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.330 | Acc: 42.907,62.144,73.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.347 | Acc: 42.743,61.906,72.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.370 | Acc: 42.381,61.686,72.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.359 | Acc: 42.663,61.748,73.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.364 | Acc: 42.554,61.848,72.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.366 | Acc: 42.561,61.765,72.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.364 | Acc: 42.601,61.652,72.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.362 | Acc: 42.541,61.706,72.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.365 | Acc: 42.592,61.779,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.359 | Acc: 42.635,61.955,72.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.370 | Acc: 42.569,61.851,72.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.381 | Acc: 42.518,61.753,72.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.381 | Acc: 42.575,61.735,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.391 | Acc: 42.490,61.680,72.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.398 | Acc: 42.436,61.575,72.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.043 | Acc: 33.594,53.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.286 | Acc: 31.027,48.810,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.326 | Acc: 30.507,49.505,57.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.334 | Acc: 30.622,48.975,57.646,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 3.973 | Acc: 48.438,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.299 | Acc: 43.750,63.504,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.295 | Acc: 44.150,63.167,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.289 | Acc: 44.057,63.473,73.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.338 | Acc: 43.345,63.117,73.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.350 | Acc: 43.147,62.825,73.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.336 | Acc: 43.279,62.823,73.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.339 | Acc: 43.163,62.727,73.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.344 | Acc: 43.037,62.646,73.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.347 | Acc: 42.982,62.478,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.357 | Acc: 43.046,62.492,72.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.361 | Acc: 43.092,62.429,72.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.368 | Acc: 43.108,62.400,72.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.371 | Acc: 43.091,62.362,72.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.382 | Acc: 42.899,62.250,72.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.391 | Acc: 42.740,62.139,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.395 | Acc: 42.701,62.150,72.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.395 | Acc: 42.710,62.140,72.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.403 | Acc: 42.605,61.994,71.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.409 | Acc: 42.532,61.899,71.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.526 | Acc: 28.906,52.344,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.115 | Acc: 25.260,47.879,56.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.099 | Acc: 25.057,46.856,56.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.118 | Acc: 24.577,46.337,55.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 3.961 | Acc: 44.531,63.281,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.231 | Acc: 42.894,61.756,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.272 | Acc: 43.617,62.576,73.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.276 | Acc: 42.905,62.551,73.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.306 | Acc: 42.921,62.211,73.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.299 | Acc: 42.868,62.531,73.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.307 | Acc: 42.969,62.461,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.307 | Acc: 43.013,62.589,73.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.315 | Acc: 42.944,62.437,73.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.326 | Acc: 42.869,62.327,73.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.342 | Acc: 42.747,62.174,73.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.339 | Acc: 42.912,62.178,72.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.345 | Acc: 42.878,62.049,72.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.358 | Acc: 42.786,61.925,72.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.359 | Acc: 42.819,61.972,72.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.368 | Acc: 42.748,61.867,72.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.370 | Acc: 42.767,61.904,72.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.380 | Acc: 42.708,61.787,72.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.394 | Acc: 42.547,61.721,72.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.396 | Acc: 42.458,61.721,72.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.431 | Acc: 29.688,47.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.515 | Acc: 30.283,48.400,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.551 | Acc: 29.554,48.723,57.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.572 | Acc: 29.290,48.412,57.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 4.840 | Acc: 39.844,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.303 | Acc: 43.415,63.356,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.242 | Acc: 44.169,63.948,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 43.532,63.601,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.275 | Acc: 43.210,63.493,74.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.286 | Acc: 43.209,63.142,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.302 | Acc: 42.962,62.836,73.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.320 | Acc: 42.753,62.871,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.290 | Acc: 43.255,63.063,73.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.303 | Acc: 42.956,62.962,73.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.324 | Acc: 42.840,62.687,73.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.342 | Acc: 42.682,62.461,72.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.344 | Acc: 42.790,62.523,72.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.347 | Acc: 42.849,62.488,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.361 | Acc: 42.702,62.422,72.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.368 | Acc: 42.662,62.298,72.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.379 | Acc: 42.475,62.240,72.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.382 | Acc: 42.495,62.188,72.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.382 | Acc: 42.551,62.186,72.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.389 | Acc: 42.550,62.186,72.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.559 | Acc: 32.812,46.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.605 | Acc: 33.408,47.321,57.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.678 | Acc: 32.279,47.180,57.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.697 | Acc: 32.057,47.439,57.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 4.194 | Acc: 46.094,60.938,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.243 | Acc: 42.820,62.054,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.272 | Acc: 43.331,63.205,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.263 | Acc: 43.443,63.320,74.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.307 | Acc: 42.795,62.722,73.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.325 | Acc: 42.721,62.252,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.324 | Acc: 42.639,62.242,73.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.328 | Acc: 42.791,62.361,72.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.331 | Acc: 42.828,62.388,72.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.325 | Acc: 42.813,62.409,72.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.335 | Acc: 42.724,62.352,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.337 | Acc: 42.725,62.369,72.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.334 | Acc: 42.807,62.471,72.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.347 | Acc: 42.631,62.347,72.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.354 | Acc: 42.599,62.319,72.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.348 | Acc: 42.551,62.383,72.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.354 | Acc: 42.506,62.337,72.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.358 | Acc: 42.536,62.312,72.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.360 | Acc: 42.590,62.277,72.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.370 | Acc: 42.530,62.188,72.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.483 | Acc: 33.594,53.125,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.555 | Acc: 31.027,48.698,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.614 | Acc: 30.297,48.704,55.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.660 | Acc: 29.854,48.553,55.366,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 4.240 | Acc: 46.094,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.219 | Acc: 43.750,62.984,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.303 | Acc: 43.026,62.614,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 42.623,62.321,73.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.338 | Acc: 42.930,62.133,73.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.367 | Acc: 42.791,61.873,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.352 | Acc: 43.007,62.113,72.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.350 | Acc: 43.068,62.123,72.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.350 | Acc: 43.226,62.092,72.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.350 | Acc: 43.124,62.137,72.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.341 | Acc: 43.175,62.356,72.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.340 | Acc: 43.121,62.465,72.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.338 | Acc: 43.072,62.487,72.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.339 | Acc: 42.936,62.467,72.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.350 | Acc: 42.849,62.472,72.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.357 | Acc: 42.808,62.412,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.373 | Acc: 42.769,62.254,72.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.379 | Acc: 42.685,62.156,72.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.393 | Acc: 42.579,62.046,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.396 | Acc: 42.524,61.948,72.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.530 | Acc: 39.062,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.967 | Acc: 34.449,51.079,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.938 | Acc: 34.604,50.915,58.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.971 | Acc: 34.221,50.448,58.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 4.261 | Acc: 42.969,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.272 | Acc: 43.006,62.500,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.273 | Acc: 43.121,62.595,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.336 | Acc: 42.380,62.141,72.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.349 | Acc: 42.274,62.220,72.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.354 | Acc: 42.319,62.028,73.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.357 | Acc: 42.304,61.990,73.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.344 | Acc: 42.381,62.118,73.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.350 | Acc: 42.299,62.301,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.357 | Acc: 42.300,62.254,72.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.370 | Acc: 42.149,62.251,72.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.374 | Acc: 42.212,62.136,72.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.378 | Acc: 42.262,62.156,72.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.379 | Acc: 42.235,62.150,72.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.387 | Acc: 42.346,61.997,72.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.385 | Acc: 42.473,61.942,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.386 | Acc: 42.414,61.986,72.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.385 | Acc: 42.483,61.952,72.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.382 | Acc: 42.456,61.950,72.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.383 | Acc: 42.528,61.946,72.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.582 | Acc: 38.281,46.875,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.126 | Acc: 35.975,48.661,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.077 | Acc: 35.461,49.123,57.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.115 | Acc: 35.169,48.694,56.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 4.426 | Acc: 43.750,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 42.932,62.537,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.341 | Acc: 42.912,62.424,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.328 | Acc: 43.174,63.076,73.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.310 | Acc: 43.268,63.175,73.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.321 | Acc: 42.953,62.817,73.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.323 | Acc: 42.833,62.803,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.342 | Acc: 42.686,62.478,73.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.339 | Acc: 42.716,62.466,73.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.334 | Acc: 42.779,62.401,73.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.341 | Acc: 42.510,62.387,73.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.365 | Acc: 42.389,61.984,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.376 | Acc: 42.431,61.819,72.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.378 | Acc: 42.550,61.901,72.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.376 | Acc: 42.618,61.952,72.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.369 | Acc: 42.608,62.012,72.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.380 | Acc: 42.482,61.994,72.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.382 | Acc: 42.538,61.918,72.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.387 | Acc: 42.475,61.888,72.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.387 | Acc: 42.516,62.000,72.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.919 | Acc: 34.375,51.562,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.890 | Acc: 29.688,46.429,56.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.917 | Acc: 29.078,45.217,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.951 | Acc: 28.509,45.325,56.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 3.993 | Acc: 50.000,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.269 | Acc: 43.341,61.905,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.288 | Acc: 42.950,62.443,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 42.943,62.180,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.327 | Acc: 42.901,61.989,73.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.336 | Acc: 42.675,61.873,73.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.322 | Acc: 42.665,62.242,72.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.326 | Acc: 42.708,62.206,73.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.323 | Acc: 42.712,62.340,72.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.318 | Acc: 42.753,62.457,72.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.325 | Acc: 42.669,62.329,72.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.330 | Acc: 42.636,62.242,72.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.339 | Acc: 42.648,62.098,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.344 | Acc: 42.723,62.150,72.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.343 | Acc: 42.888,62.233,72.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.345 | Acc: 42.839,62.189,72.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.355 | Acc: 42.789,62.047,72.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.371 | Acc: 42.687,61.966,72.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.375 | Acc: 42.720,61.974,72.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.379 | Acc: 42.719,61.969,72.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.247 | Acc: 26.562,44.531,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.576 | Acc: 25.558,41.369,52.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.654 | Acc: 24.848,40.530,51.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.576 | Acc: 24.449,40.830,51.972,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 4.219 | Acc: 42.188,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.309 | Acc: 42.485,61.719,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.192 | Acc: 43.312,63.453,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.250 | Acc: 43.135,63.192,74.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.284 | Acc: 42.901,62.799,73.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.309 | Acc: 42.636,62.686,73.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.303 | Acc: 42.517,62.855,73.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.317 | Acc: 42.531,62.738,73.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.316 | Acc: 42.542,62.762,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.315 | Acc: 42.641,62.608,73.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.337 | Acc: 42.417,62.348,73.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.341 | Acc: 42.467,62.451,73.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.341 | Acc: 42.460,62.545,73.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.350 | Acc: 42.454,62.452,72.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.349 | Acc: 42.507,62.458,72.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.358 | Acc: 42.463,62.435,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.363 | Acc: 42.424,62.429,72.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.357 | Acc: 42.511,62.429,72.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.365 | Acc: 42.441,62.338,72.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.369 | Acc: 42.483,62.289,72.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.058 | Acc: 27.344,53.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.408 | Acc: 31.696,48.921,56.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.470 | Acc: 31.784,48.571,56.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.477 | Acc: 31.481,48.514,56.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 4.215 | Acc: 37.500,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.264 | Acc: 43.006,64.286,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.249 | Acc: 42.969,63.510,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.252 | Acc: 42.918,63.691,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.253 | Acc: 42.901,63.368,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.269 | Acc: 42.938,63.196,73.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.281 | Acc: 43.001,63.062,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.293 | Acc: 43.046,62.799,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.285 | Acc: 43.095,62.815,73.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.284 | Acc: 43.103,62.815,73.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.303 | Acc: 43.012,62.722,73.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.294 | Acc: 43.153,62.832,73.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.298 | Acc: 43.076,62.844,73.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.311 | Acc: 42.888,62.817,73.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.320 | Acc: 42.855,62.781,73.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.327 | Acc: 42.839,62.718,72.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.341 | Acc: 42.803,62.519,72.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.350 | Acc: 42.714,62.346,72.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.355 | Acc: 42.614,62.275,72.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.363 | Acc: 42.497,62.162,72.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.268 | Acc: 32.031,50.781,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.551 | Acc: 31.659,47.470,55.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.562 | Acc: 31.536,47.294,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.530 | Acc: 31.404,47.631,55.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 4.336 | Acc: 50.000,63.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.197 | Acc: 43.192,63.542,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.280 | Acc: 42.321,62.462,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.327 | Acc: 41.803,62.180,73.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.325 | Acc: 42.371,62.162,73.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.333 | Acc: 42.087,62.268,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.324 | Acc: 42.129,62.423,73.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.347 | Acc: 41.982,62.323,73.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.351 | Acc: 42.090,62.451,73.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.343 | Acc: 42.261,62.440,73.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.360 | Acc: 42.172,62.329,72.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.358 | Acc: 42.212,62.302,72.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.354 | Acc: 42.418,62.335,72.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.354 | Acc: 42.409,62.261,72.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.361 | Acc: 42.321,62.253,72.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.363 | Acc: 42.390,62.212,72.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.379 | Acc: 42.316,62.042,72.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.381 | Acc: 42.336,61.975,72.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.381 | Acc: 42.363,62.002,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.379 | Acc: 42.384,62.131,72.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.023 | Acc: 30.469,53.125,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.468 | Acc: 31.250,50.112,57.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.402 | Acc: 31.498,50.419,57.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.419 | Acc: 31.276,50.205,57.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 4.418 | Acc: 41.406,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.287 | Acc: 43.043,63.318,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.334 | Acc: 42.321,62.252,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.335 | Acc: 42.392,62.116,73.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.322 | Acc: 42.602,62.269,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.290 | Acc: 42.505,62.523,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.293 | Acc: 42.439,62.636,73.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.292 | Acc: 42.830,62.533,73.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.296 | Acc: 42.775,62.582,73.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.304 | Acc: 42.723,62.552,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 42.860,62.477,73.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.312 | Acc: 42.824,62.454,73.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.317 | Acc: 42.777,62.474,73.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.342 | Acc: 42.556,62.332,72.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.338 | Acc: 42.707,62.467,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.335 | Acc: 42.759,62.549,72.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.347 | Acc: 42.657,62.417,72.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.350 | Acc: 42.616,62.392,72.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.355 | Acc: 42.646,62.374,72.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.357 | Acc: 42.680,62.379,72.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.915 | Acc: 26.562,48.438,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.369 | Acc: 28.013,44.345,49.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.472 | Acc: 27.458,43.864,48.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.497 | Acc: 27.228,43.904,48.553,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 3.999 | Acc: 42.188,64.062,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.262 | Acc: 42.076,61.644,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.231 | Acc: 43.407,62.329,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.257 | Acc: 43.327,62.372,73.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.233 | Acc: 43.625,62.828,73.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.260 | Acc: 43.224,62.763,73.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.273 | Acc: 43.363,62.610,73.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.288 | Acc: 43.346,62.605,73.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.297 | Acc: 43.187,62.602,72.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.295 | Acc: 43.176,62.638,72.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.310 | Acc: 43.136,62.481,72.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.318 | Acc: 43.032,62.475,72.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.326 | Acc: 42.982,62.500,72.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.325 | Acc: 43.044,62.473,72.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.329 | Acc: 43.069,62.405,72.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.340 | Acc: 43.000,62.388,72.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.354 | Acc: 42.862,62.208,72.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.360 | Acc: 42.797,62.143,72.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.363 | Acc: 42.791,62.128,72.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.366 | Acc: 42.815,62.164,72.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.909 | Acc: 27.344,46.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.179 | Acc: 26.562,43.973,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.126 | Acc: 26.448,43.883,55.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.140 | Acc: 26.153,43.840,55.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 4.266 | Acc: 49.219,58.594,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.380 | Acc: 41.778,60.454,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.344 | Acc: 41.978,62.005,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.307 | Acc: 42.687,62.910,73.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.318 | Acc: 42.612,62.818,73.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.345 | Acc: 42.536,62.539,72.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.335 | Acc: 42.581,62.468,72.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.352 | Acc: 42.730,62.356,72.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.334 | Acc: 42.726,62.515,72.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.336 | Acc: 42.839,62.530,72.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.334 | Acc: 42.774,62.508,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.329 | Acc: 42.870,62.574,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.319 | Acc: 42.878,62.607,72.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.323 | Acc: 42.807,62.647,72.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.335 | Acc: 42.760,62.525,72.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.339 | Acc: 42.751,62.492,72.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.344 | Acc: 42.759,62.451,72.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.346 | Acc: 42.783,62.459,72.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.351 | Acc: 42.744,62.403,72.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.355 | Acc: 42.698,62.309,72.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.920 | Acc: 22.656,42.969,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.977 | Acc: 23.103,39.807,52.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.040 | Acc: 22.790,39.291,52.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.033 | Acc: 22.733,39.869,52.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 4.257 | Acc: 46.094,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.330 | Acc: 43.080,62.946,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 42.931,63.510,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.305 | Acc: 42.905,63.281,72.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.278 | Acc: 43.191,63.522,73.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.273 | Acc: 43.023,63.405,73.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.265 | Acc: 43.085,63.197,73.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.288 | Acc: 42.836,62.960,73.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.298 | Acc: 42.847,62.689,72.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.302 | Acc: 42.891,62.677,72.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.294 | Acc: 42.980,62.842,73.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.297 | Acc: 42.993,62.846,73.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.309 | Acc: 42.943,62.613,72.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.326 | Acc: 42.816,62.467,72.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.333 | Acc: 42.788,62.481,72.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.329 | Acc: 42.893,62.497,72.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.328 | Acc: 42.947,62.444,72.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.331 | Acc: 42.895,62.392,72.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.329 | Acc: 42.925,62.478,72.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.339 | Acc: 42.881,62.461,72.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.127 | Acc: 34.375,42.969,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.661 | Acc: 27.641,42.671,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.712 | Acc: 27.268,42.207,51.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.707 | Acc: 27.241,41.957,51.255,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 4.461 | Acc: 40.625,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.515 | Acc: 40.476,60.491,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.375 | Acc: 41.139,61.662,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.328 | Acc: 41.765,62.116,73.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.314 | Acc: 42.380,62.500,73.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.307 | Acc: 42.512,62.655,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.318 | Acc: 42.446,62.519,73.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.333 | Acc: 42.376,62.350,73.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.339 | Acc: 42.323,62.345,73.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.332 | Acc: 42.459,62.366,72.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.348 | Acc: 42.440,62.337,72.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.342 | Acc: 42.481,62.440,72.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.346 | Acc: 42.411,62.318,72.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.355 | Acc: 42.331,62.329,72.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.351 | Acc: 42.349,62.456,72.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.355 | Acc: 42.390,62.368,72.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.361 | Acc: 42.319,62.293,72.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.358 | Acc: 42.323,62.349,72.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.363 | Acc: 42.356,62.323,72.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.365 | Acc: 42.407,62.352,72.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.980 | Acc: 30.469,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.553 | Acc: 30.246,48.214,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.586 | Acc: 30.488,47.466,55.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.565 | Acc: 30.776,47.810,55.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 4.270 | Acc: 43.750,64.062,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.256 | Acc: 42.374,63.058,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.307 | Acc: 42.416,62.710,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.281 | Acc: 42.853,62.846,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.313 | Acc: 42.718,62.529,73.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.317 | Acc: 42.814,62.028,73.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.306 | Acc: 43.014,62.319,73.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.299 | Acc: 43.113,62.566,73.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.321 | Acc: 42.881,62.573,73.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.312 | Acc: 42.956,62.673,73.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.307 | Acc: 42.961,62.768,73.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.308 | Acc: 42.831,62.885,73.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.308 | Acc: 42.978,62.908,73.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.315 | Acc: 42.948,62.760,73.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.316 | Acc: 42.997,62.692,72.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.322 | Acc: 42.935,62.656,72.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.332 | Acc: 42.786,62.539,72.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.334 | Acc: 42.790,62.509,72.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.342 | Acc: 42.774,62.433,72.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.343 | Acc: 42.780,62.453,72.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.394 | Acc: 31.250,49.219,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.379 | Acc: 33.333,50.558,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.398 | Acc: 32.165,50.019,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.437 | Acc: 31.711,49.693,56.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 4.451 | Acc: 46.875,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.324 | Acc: 40.737,61.607,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.263 | Acc: 42.016,62.595,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.265 | Acc: 42.482,62.987,74.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.280 | Acc: 42.506,63.011,74.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.257 | Acc: 42.868,62.972,74.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.271 | Acc: 43.046,62.900,74.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.280 | Acc: 42.897,62.733,73.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.273 | Acc: 43.008,62.942,73.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.286 | Acc: 42.995,62.806,73.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.281 | Acc: 43.078,62.757,73.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.287 | Acc: 43.025,62.733,73.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.286 | Acc: 43.004,62.636,73.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.287 | Acc: 43.032,62.656,73.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.297 | Acc: 42.997,62.533,73.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.311 | Acc: 42.883,62.433,73.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.315 | Acc: 42.862,62.393,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.323 | Acc: 42.815,62.328,73.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.329 | Acc: 42.817,62.361,73.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.336 | Acc: 42.809,62.305,72.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.084 | Acc: 32.812,55.469,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.685 | Acc: 30.357,46.838,53.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.736 | Acc: 30.050,45.884,52.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.753 | Acc: 29.880,45.697,52.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 4.663 | Acc: 42.969,57.031,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.256 | Acc: 43.638,62.277,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.323 | Acc: 42.931,62.138,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.257 | Acc: 43.289,62.731,74.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.278 | Acc: 43.287,62.645,73.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.284 | Acc: 43.062,62.655,73.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.272 | Acc: 43.388,62.952,73.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.285 | Acc: 43.251,62.816,73.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.290 | Acc: 43.304,62.743,73.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.293 | Acc: 43.206,62.690,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.305 | Acc: 43.124,62.617,73.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.311 | Acc: 43.114,62.617,73.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.314 | Acc: 42.982,62.503,73.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.322 | Acc: 42.948,62.383,73.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.330 | Acc: 42.924,62.230,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.329 | Acc: 42.940,62.383,72.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.334 | Acc: 42.944,62.332,72.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.335 | Acc: 42.994,62.337,72.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.329 | Acc: 43.038,62.381,72.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.338 | Acc: 42.911,62.279,72.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.043 | Acc: 39.062,52.344,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.162 | Acc: 33.929,49.814,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.237 | Acc: 34.089,48.876,56.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.316 | Acc: 33.914,48.117,56.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.233 | Acc: 42.969,62.500,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.255 | Acc: 42.894,61.942,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.262 | Acc: 43.350,62.290,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.228 | Acc: 43.660,62.961,74.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.243 | Acc: 43.586,62.934,74.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.263 | Acc: 43.580,62.539,73.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.271 | Acc: 43.401,62.590,74.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.294 | Acc: 43.285,62.439,73.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.307 | Acc: 43.153,62.223,73.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.303 | Acc: 43.310,62.276,73.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.311 | Acc: 43.287,62.294,73.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.320 | Acc: 43.241,62.253,73.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.329 | Acc: 43.121,62.270,73.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.332 | Acc: 43.184,62.287,73.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.329 | Acc: 43.174,62.275,73.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.334 | Acc: 43.114,62.230,73.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.335 | Acc: 43.020,62.347,72.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.340 | Acc: 43.019,62.303,72.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.340 | Acc: 42.993,62.281,72.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.342 | Acc: 43.014,62.287,72.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.321 | Acc: 26.562,48.438,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.728 | Acc: 25.670,47.545,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.763 | Acc: 26.162,46.113,56.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.759 | Acc: 26.370,45.991,55.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 4.568 | Acc: 42.969,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 41.927,62.426,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.347 | Acc: 41.425,61.776,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.310 | Acc: 42.136,61.693,73.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.308 | Acc: 42.371,61.564,73.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.294 | Acc: 42.342,62.044,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.305 | Acc: 42.200,62.048,73.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.301 | Acc: 42.232,62.201,73.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.313 | Acc: 42.304,62.083,73.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.315 | Acc: 42.399,62.124,73.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.321 | Acc: 42.312,62.100,72.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.321 | Acc: 42.385,62.157,72.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.318 | Acc: 42.398,62.250,72.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.331 | Acc: 42.355,62.159,72.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.332 | Acc: 42.338,62.177,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.332 | Acc: 42.431,62.139,72.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.343 | Acc: 42.441,62.096,72.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.339 | Acc: 42.499,62.172,72.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.346 | Acc: 42.590,62.095,72.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.346 | Acc: 42.561,62.102,72.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.513 | Acc: 42.188,52.344,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.901 | Acc: 37.202,49.963,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.902 | Acc: 37.195,50.076,58.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.902 | Acc: 36.821,49.898,58.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 4.800 | Acc: 45.312,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.157 | Acc: 41.778,64.546,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.220 | Acc: 42.511,63.643,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.209 | Acc: 42.892,63.435,74.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.222 | Acc: 43.162,63.436,74.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.211 | Acc: 43.363,63.506,74.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.207 | Acc: 43.253,63.546,74.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.215 | Acc: 43.196,63.514,74.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.221 | Acc: 43.299,63.291,74.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.236 | Acc: 43.301,63.178,73.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.258 | Acc: 43.144,63.001,73.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.275 | Acc: 42.937,62.747,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.277 | Acc: 42.936,62.798,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.279 | Acc: 42.861,62.674,73.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.295 | Acc: 42.810,62.539,73.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.302 | Acc: 42.707,62.518,73.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.303 | Acc: 42.706,62.485,73.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.309 | Acc: 42.721,62.491,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.323 | Acc: 42.622,62.344,72.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.327 | Acc: 42.680,62.293,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.275 | Acc: 28.125,56.250,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.470 | Acc: 31.473,49.740,58.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.466 | Acc: 31.174,49.257,57.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.486 | Acc: 31.212,49.052,57.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 5.135 | Acc: 35.938,53.125,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.389 | Acc: 42.597,62.202,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.306 | Acc: 43.274,62.710,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.278 | Acc: 43.110,62.795,73.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.274 | Acc: 42.911,62.780,74.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.265 | Acc: 42.930,62.771,74.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.271 | Acc: 43.072,62.739,74.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.294 | Acc: 42.996,62.633,73.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.307 | Acc: 42.964,62.519,73.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.313 | Acc: 42.770,62.517,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.319 | Acc: 42.809,62.407,73.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.327 | Acc: 42.838,62.493,73.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.325 | Acc: 42.891,62.562,73.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.318 | Acc: 43.008,62.620,73.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.310 | Acc: 43.080,62.728,73.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.313 | Acc: 43.075,62.593,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.310 | Acc: 43.246,62.644,73.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.319 | Acc: 43.177,62.484,73.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.320 | Acc: 43.166,62.407,73.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.326 | Acc: 43.178,62.422,73.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.369 | Acc: 36.719,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.797 | Acc: 32.701,45.945,54.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.858 | Acc: 31.174,45.446,54.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.854 | Acc: 30.930,45.312,54.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 3.913 | Acc: 54.688,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 44.010,63.281,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.265 | Acc: 43.274,63.129,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 43.007,63.128,74.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.274 | Acc: 43.065,63.127,74.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.269 | Acc: 43.170,63.366,74.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.251 | Acc: 43.130,63.346,74.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.268 | Acc: 42.947,63.093,73.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.282 | Acc: 42.741,63.029,73.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.283 | Acc: 42.822,62.854,73.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.289 | Acc: 42.786,62.826,73.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.297 | Acc: 42.735,62.747,73.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.305 | Acc: 42.816,62.727,73.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.308 | Acc: 42.840,62.671,73.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.308 | Acc: 42.807,62.636,73.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.312 | Acc: 42.826,62.638,73.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.308 | Acc: 42.886,62.702,73.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.312 | Acc: 42.840,62.656,73.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.315 | Acc: 42.867,62.597,73.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.318 | Acc: 42.848,62.607,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.553 | Acc: 23.438,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.879 | Acc: 23.958,43.638,53.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.018 | Acc: 23.323,43.178,52.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.041 | Acc: 22.874,42.725,51.947,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 4.522 | Acc: 45.312,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.372 | Acc: 42.820,62.946,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.314 | Acc: 42.607,62.424,73.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.288 | Acc: 43.186,62.846,73.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.299 | Acc: 43.104,62.895,73.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.304 | Acc: 42.984,62.771,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.298 | Acc: 43.007,62.920,73.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.288 | Acc: 43.091,62.943,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.288 | Acc: 43.270,62.893,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.273 | Acc: 43.267,63.147,73.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.268 | Acc: 43.272,63.157,73.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.264 | Acc: 43.418,63.147,73.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.271 | Acc: 43.484,63.129,73.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.270 | Acc: 43.534,63.159,73.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.266 | Acc: 43.592,63.181,73.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.275 | Acc: 43.493,63.048,73.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.285 | Acc: 43.424,63.060,73.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.290 | Acc: 43.434,62.988,73.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.307 | Acc: 43.280,62.777,72.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.313 | Acc: 43.235,62.754,72.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.270 | Acc: 34.375,53.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.601 | Acc: 31.808,50.149,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.573 | Acc: 31.098,50.000,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.586 | Acc: 30.879,49.731,55.725,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 4.006 | Acc: 48.438,64.844,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.117 | Acc: 43.601,64.435,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.929 | Acc: 44.970,66.521,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.825 | Acc: 46.299,67.853,78.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.795 | Acc: 46.142,67.959,78.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.769 | Acc: 46.334,68.185,79.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.762 | Acc: 46.404,68.427,79.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.747 | Acc: 46.382,68.501,79.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.725 | Acc: 46.497,68.731,79.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.716 | Acc: 46.512,68.875,79.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.701 | Acc: 46.576,69.073,80.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.690 | Acc: 46.624,69.287,80.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.685 | Acc: 46.651,69.311,80.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.676 | Acc: 46.794,69.340,80.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.666 | Acc: 46.942,69.495,80.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.666 | Acc: 46.948,69.542,80.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.659 | Acc: 47.006,69.636,80.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.652 | Acc: 47.017,69.678,80.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.642 | Acc: 47.100,69.780,80.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.636 | Acc: 47.176,69.804,80.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.052 | Acc: 47.656,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.348 | Acc: 46.019,64.472,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.365 | Acc: 45.027,63.853,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.381 | Acc: 44.723,63.320,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.756 | Acc: 44.531,70.312,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.464 | Acc: 48.177,72.061,83.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.494 | Acc: 48.342,71.570,83.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.471 | Acc: 48.207,71.504,83.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.478 | Acc: 47.955,71.316,83.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.467 | Acc: 48.151,71.194,83.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.452 | Acc: 48.431,71.643,83.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.457 | Acc: 48.526,71.581,83.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.468 | Acc: 48.452,71.399,83.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.461 | Acc: 48.407,71.461,83.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.456 | Acc: 48.453,71.568,83.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.453 | Acc: 48.536,71.702,83.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.452 | Acc: 48.444,71.690,83.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.452 | Acc: 48.324,71.683,83.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.447 | Acc: 48.449,71.761,83.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.445 | Acc: 48.269,71.836,83.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.439 | Acc: 48.316,71.863,83.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.440 | Acc: 48.346,71.795,83.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.441 | Acc: 48.338,71.728,83.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.441 | Acc: 48.325,71.664,83.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.057 | Acc: 50.781,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.320 | Acc: 46.057,64.249,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.346 | Acc: 45.522,64.120,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.365 | Acc: 45.274,63.461,70.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.019 | Acc: 53.906,77.344,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.408 | Acc: 47.917,71.801,83.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.411 | Acc: 48.304,71.627,84.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.405 | Acc: 48.847,72.067,83.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.378 | Acc: 49.055,72.415,84.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.365 | Acc: 48.902,72.478,84.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.375 | Acc: 48.825,72.249,84.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.375 | Acc: 48.809,72.207,84.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.383 | Acc: 48.539,72.210,84.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.373 | Acc: 48.627,72.371,84.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.363 | Acc: 48.651,72.516,84.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.369 | Acc: 48.586,72.416,84.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.368 | Acc: 48.629,72.410,84.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.371 | Acc: 48.563,72.360,84.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.367 | Acc: 48.635,72.334,84.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.364 | Acc: 48.611,72.337,84.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.371 | Acc: 48.540,72.184,84.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.365 | Acc: 48.664,72.253,84.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.373 | Acc: 48.470,72.200,84.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.379 | Acc: 48.345,72.146,84.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.123 | Acc: 45.312,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.330 | Acc: 46.354,64.695,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.332 | Acc: 46.056,64.539,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.343 | Acc: 45.671,63.960,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 3.044 | Acc: 47.656,75.781,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.276 | Acc: 49.107,74.070,85.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.254 | Acc: 49.809,73.800,86.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.263 | Acc: 49.667,73.425,85.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.274 | Acc: 49.691,73.466,85.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.293 | Acc: 49.134,73.113,85.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.307 | Acc: 48.767,72.863,85.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.291 | Acc: 48.792,72.906,85.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.293 | Acc: 48.991,72.913,85.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.303 | Acc: 48.817,72.812,85.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.297 | Acc: 49.013,72.812,85.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.308 | Acc: 48.830,72.663,85.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.312 | Acc: 48.700,72.647,85.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.313 | Acc: 48.746,72.620,85.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.316 | Acc: 48.760,72.617,85.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.325 | Acc: 48.710,72.498,85.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.321 | Acc: 48.666,72.554,85.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.323 | Acc: 48.673,72.519,85.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.322 | Acc: 48.643,72.542,85.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.318 | Acc: 48.665,72.564,85.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.065 | Acc: 47.656,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.372 | Acc: 45.610,63.839,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.365 | Acc: 45.332,63.872,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.384 | Acc: 45.031,63.473,70.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 3.027 | Acc: 50.000,76.562,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.372 | Acc: 48.065,71.912,84.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.355 | Acc: 48.056,72.294,84.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.321 | Acc: 48.156,72.541,85.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.301 | Acc: 48.225,72.618,86.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.272 | Acc: 48.476,73.190,86.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.267 | Acc: 48.618,73.237,86.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.271 | Acc: 48.548,73.027,86.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.268 | Acc: 48.690,73.103,85.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.266 | Acc: 48.800,73.183,86.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.263 | Acc: 48.822,73.142,86.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.263 | Acc: 48.918,73.165,86.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.270 | Acc: 48.933,73.185,86.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.276 | Acc: 48.839,73.147,85.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.277 | Acc: 48.880,73.096,85.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.277 | Acc: 48.910,73.079,85.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.278 | Acc: 48.876,73.038,85.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.276 | Acc: 48.960,73.059,85.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.279 | Acc: 48.911,73.009,85.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.284 | Acc: 48.885,73.015,85.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.930 | Acc: 46.875,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.365 | Acc: 46.689,63.542,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.367 | Acc: 45.846,63.891,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.392 | Acc: 45.543,63.281,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.096 | Acc: 57.031,73.438,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.243 | Acc: 49.554,72.470,86.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.217 | Acc: 50.324,72.732,86.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.228 | Acc: 49.744,72.912,86.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.266 | Acc: 49.363,72.676,86.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.243 | Acc: 49.443,73.082,86.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.240 | Acc: 49.257,73.192,86.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.243 | Acc: 49.169,73.166,86.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.249 | Acc: 49.059,73.117,86.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.245 | Acc: 49.111,73.261,86.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.250 | Acc: 48.935,73.301,86.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.255 | Acc: 48.901,73.165,86.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.262 | Acc: 48.869,73.139,86.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.256 | Acc: 48.976,73.243,86.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.259 | Acc: 48.907,73.146,86.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.257 | Acc: 48.907,73.061,86.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.258 | Acc: 48.895,73.075,86.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.259 | Acc: 48.852,73.076,86.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.257 | Acc: 48.983,73.096,86.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.253 | Acc: 48.985,73.132,86.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.082 | Acc: 50.000,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.358 | Acc: 46.391,64.323,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.365 | Acc: 45.865,64.082,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.375 | Acc: 45.569,63.717,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 3.296 | Acc: 47.656,73.438,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.208 | Acc: 48.921,74.070,87.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.212 | Acc: 49.104,74.333,86.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.206 | Acc: 49.027,74.244,86.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.203 | Acc: 48.978,74.035,86.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.211 | Acc: 48.817,73.840,86.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.210 | Acc: 48.889,73.657,86.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.215 | Acc: 48.775,73.587,86.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.215 | Acc: 48.937,73.734,86.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.211 | Acc: 49.085,73.722,86.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.217 | Acc: 49.087,73.690,86.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.213 | Acc: 49.236,73.717,86.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.220 | Acc: 49.131,73.616,86.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.226 | Acc: 49.039,73.500,86.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.231 | Acc: 48.963,73.435,86.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.224 | Acc: 49.034,73.528,86.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.223 | Acc: 49.151,73.491,86.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.228 | Acc: 49.086,73.383,86.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.221 | Acc: 49.158,73.446,86.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.225 | Acc: 49.178,73.429,86.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.987 | Acc: 49.219,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.365 | Acc: 46.801,64.211,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.370 | Acc: 45.941,64.234,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.382 | Acc: 45.505,63.717,70.569,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.231 | Acc: 49.219,72.656,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.150 | Acc: 49.182,74.628,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.129 | Acc: 49.409,74.924,87.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.162 | Acc: 49.244,74.334,87.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.151 | Acc: 49.633,74.392,87.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.142 | Acc: 49.714,74.528,87.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.159 | Acc: 49.619,74.180,87.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.164 | Acc: 49.518,73.986,87.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.166 | Acc: 49.651,73.996,87.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.190 | Acc: 49.370,73.658,87.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.185 | Acc: 49.417,73.702,87.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.184 | Acc: 49.374,73.604,87.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.194 | Acc: 49.400,73.554,87.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.192 | Acc: 49.452,73.584,86.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.195 | Acc: 49.444,73.582,86.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.196 | Acc: 49.468,73.570,86.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.188 | Acc: 49.581,73.640,86.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.193 | Acc: 49.432,73.596,86.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.196 | Acc: 49.381,73.600,86.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.201 | Acc: 49.282,73.497,86.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.085 | Acc: 50.781,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.357 | Acc: 46.057,64.769,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.378 | Acc: 45.541,64.215,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.387 | Acc: 45.364,63.845,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 3.232 | Acc: 46.094,72.656,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.143 | Acc: 49.516,74.405,88.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.150 | Acc: 49.257,73.895,87.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.171 | Acc: 49.052,73.668,87.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.149 | Acc: 49.344,74.035,87.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.148 | Acc: 49.482,74.056,87.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.148 | Acc: 49.554,73.999,87.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.153 | Acc: 49.795,73.925,87.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.164 | Acc: 49.777,73.879,87.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.154 | Acc: 49.763,73.990,87.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.159 | Acc: 49.712,73.877,87.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.163 | Acc: 49.664,73.830,87.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.168 | Acc: 49.605,73.749,87.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.179 | Acc: 49.374,73.692,87.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.182 | Acc: 49.308,73.702,87.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.183 | Acc: 49.224,73.663,87.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.180 | Acc: 49.224,73.671,87.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.182 | Acc: 49.168,73.641,87.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.185 | Acc: 49.236,73.544,87.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.191 | Acc: 49.141,73.538,87.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.120 | Acc: 47.656,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.366 | Acc: 47.024,64.583,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.388 | Acc: 46.627,64.425,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.404 | Acc: 46.145,64.139,70.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 2.693 | Acc: 55.469,82.031,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.093 | Acc: 50.409,74.442,88.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.150 | Acc: 49.981,73.514,87.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.166 | Acc: 49.168,73.489,87.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.171 | Acc: 49.248,73.630,87.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.165 | Acc: 49.404,73.476,87.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.175 | Acc: 49.296,73.399,87.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.182 | Acc: 49.335,73.438,87.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.181 | Acc: 49.209,73.471,87.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.174 | Acc: 49.219,73.450,87.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.165 | Acc: 49.483,73.577,87.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.162 | Acc: 49.487,73.529,87.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.167 | Acc: 49.439,73.616,87.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.173 | Acc: 49.398,73.620,87.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.176 | Acc: 49.252,73.565,87.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.173 | Acc: 49.297,73.650,87.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.172 | Acc: 49.216,73.705,87.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.173 | Acc: 49.171,73.653,87.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.170 | Acc: 49.286,73.678,87.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.171 | Acc: 49.299,73.698,87.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.117 | Acc: 48.438,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.373 | Acc: 47.470,64.732,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.389 | Acc: 46.589,64.482,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.409 | Acc: 46.247,64.101,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 2.932 | Acc: 51.562,77.344,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.124 | Acc: 49.516,74.182,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.142 | Acc: 49.752,74.257,88.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.133 | Acc: 49.449,74.385,88.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.149 | Acc: 49.325,74.257,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.159 | Acc: 49.381,73.948,88.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.164 | Acc: 49.477,74.057,87.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.149 | Acc: 49.607,74.075,87.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.148 | Acc: 49.680,74.068,87.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.144 | Acc: 49.577,74.193,87.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.141 | Acc: 49.623,74.223,87.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.137 | Acc: 49.625,74.243,87.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.136 | Acc: 49.595,74.274,87.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.129 | Acc: 49.632,74.353,87.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.133 | Acc: 49.686,74.288,87.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.137 | Acc: 49.631,74.227,87.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.144 | Acc: 49.601,74.190,87.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.147 | Acc: 49.620,74.178,87.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.153 | Acc: 49.559,74.063,87.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.150 | Acc: 49.594,74.075,87.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.096 | Acc: 47.656,70.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.420 | Acc: 46.391,63.616,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.426 | Acc: 45.922,63.396,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.443 | Acc: 45.569,62.935,69.429,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 3.035 | Acc: 50.781,74.219,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.073 | Acc: 49.628,74.479,88.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.082 | Acc: 49.924,74.371,88.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.100 | Acc: 49.757,74.219,88.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.104 | Acc: 49.701,74.093,88.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.117 | Acc: 49.482,73.994,88.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.125 | Acc: 49.483,73.825,88.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.124 | Acc: 49.501,73.969,87.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.119 | Acc: 49.670,73.942,87.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.109 | Acc: 49.672,74.124,88.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.120 | Acc: 49.518,73.954,87.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.120 | Acc: 49.477,74.017,87.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.122 | Acc: 49.348,74.060,87.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.128 | Acc: 49.291,74.018,87.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.128 | Acc: 49.322,74.007,87.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.124 | Acc: 49.445,74.076,87.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.124 | Acc: 49.479,74.056,87.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.125 | Acc: 49.496,74.063,87.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.128 | Acc: 49.459,73.983,87.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.132 | Acc: 49.350,73.964,87.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.132 | Acc: 46.875,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.445 | Acc: 46.615,64.397,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.452 | Acc: 46.132,63.910,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.468 | Acc: 45.620,63.550,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 3.209 | Acc: 46.094,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.103 | Acc: 48.326,74.888,88.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.085 | Acc: 49.028,74.771,88.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.071 | Acc: 49.565,75.026,88.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.090 | Acc: 49.711,74.662,88.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.106 | Acc: 49.551,74.590,88.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.095 | Acc: 49.851,74.613,88.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.096 | Acc: 49.934,74.440,88.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.097 | Acc: 49.859,74.413,88.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.101 | Acc: 49.810,74.430,88.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.101 | Acc: 49.860,74.491,88.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.104 | Acc: 49.781,74.466,88.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.103 | Acc: 49.789,74.494,88.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.103 | Acc: 49.793,74.443,88.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.106 | Acc: 49.711,74.438,88.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.108 | Acc: 49.738,74.434,88.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.113 | Acc: 49.664,74.406,88.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.113 | Acc: 49.643,74.333,88.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.113 | Acc: 49.649,74.288,88.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.113 | Acc: 49.680,74.354,88.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.106 | Acc: 46.094,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.445 | Acc: 46.243,63.765,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.446 | Acc: 45.579,63.967,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.452 | Acc: 45.415,63.870,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 3.008 | Acc: 53.906,71.875,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.044 | Acc: 51.004,75.372,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.101 | Acc: 49.886,74.771,89.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.107 | Acc: 49.654,74.398,88.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.120 | Acc: 49.228,74.508,88.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.139 | Acc: 49.118,74.157,88.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.131 | Acc: 49.064,74.057,88.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.126 | Acc: 49.241,73.864,88.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.130 | Acc: 49.194,73.903,88.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.138 | Acc: 49.089,73.891,88.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.130 | Acc: 49.207,74.017,88.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.120 | Acc: 49.251,74.127,88.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.125 | Acc: 49.180,74.015,88.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.125 | Acc: 49.177,74.060,88.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.123 | Acc: 49.258,74.038,88.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.123 | Acc: 49.260,74.037,88.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.114 | Acc: 49.409,74.165,88.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.114 | Acc: 49.361,74.136,88.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.117 | Acc: 49.342,74.074,88.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.116 | Acc: 49.299,74.073,88.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.099 | Acc: 50.781,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.429 | Acc: 46.429,64.249,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 45.770,64.177,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.449 | Acc: 45.415,63.781,69.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 3.062 | Acc: 47.656,75.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.989 | Acc: 50.595,75.707,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.090 | Acc: 49.295,74.619,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.082 | Acc: 49.475,74.296,88.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.066 | Acc: 49.547,74.373,89.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.065 | Acc: 49.783,74.273,88.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.062 | Acc: 49.780,74.458,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.071 | Acc: 49.723,74.446,89.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.059 | Acc: 49.961,74.660,88.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.073 | Acc: 49.875,74.590,88.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.066 | Acc: 50.012,74.654,88.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.070 | Acc: 50.049,74.615,88.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.076 | Acc: 50.019,74.637,88.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.079 | Acc: 50.003,74.581,88.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.083 | Acc: 50.028,74.513,88.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.087 | Acc: 49.990,74.455,88.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.092 | Acc: 49.939,74.445,88.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.097 | Acc: 49.904,74.386,88.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.095 | Acc: 49.857,74.427,88.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.098 | Acc: 49.832,74.401,88.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.241 | Acc: 50.000,72.656,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.413 | Acc: 46.763,64.807,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.445 | Acc: 46.037,64.043,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.458 | Acc: 45.645,63.730,69.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 2.780 | Acc: 55.469,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.027 | Acc: 51.190,75.707,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.029 | Acc: 51.277,76.048,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 51.422,75.653,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.027 | Acc: 50.685,75.511,88.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.019 | Acc: 50.944,75.425,89.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.037 | Acc: 50.607,75.355,88.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.053 | Acc: 50.327,75.199,88.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.060 | Acc: 50.194,75.107,88.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.061 | Acc: 50.117,75.086,88.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.060 | Acc: 49.957,75.066,88.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.059 | Acc: 49.982,74.965,88.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.062 | Acc: 49.909,74.919,88.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.057 | Acc: 49.919,74.964,88.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.061 | Acc: 49.836,74.958,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.065 | Acc: 49.878,74.927,88.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.076 | Acc: 49.839,74.827,88.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.073 | Acc: 49.899,74.803,88.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.075 | Acc: 49.868,74.738,88.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.075 | Acc: 49.904,74.729,88.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.153 | Acc: 46.875,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.396 | Acc: 46.838,64.435,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.418 | Acc: 46.341,64.024,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.440 | Acc: 46.030,63.614,69.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 3.349 | Acc: 49.219,75.781,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.024 | Acc: 50.409,76.265,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.016 | Acc: 50.400,75.686,88.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.035 | Acc: 50.602,75.423,88.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.019 | Acc: 50.569,75.656,88.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.009 | Acc: 50.774,75.634,88.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.033 | Acc: 50.478,75.329,88.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.041 | Acc: 50.438,75.316,88.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.057 | Acc: 50.214,75.281,88.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.053 | Acc: 50.147,75.216,88.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.052 | Acc: 50.062,75.109,88.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.055 | Acc: 49.996,74.958,88.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.057 | Acc: 49.896,74.909,88.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.062 | Acc: 49.919,74.835,88.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.064 | Acc: 49.847,74.744,88.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.069 | Acc: 49.785,74.600,88.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.071 | Acc: 49.710,74.552,88.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.077 | Acc: 49.679,74.473,88.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.078 | Acc: 49.671,74.461,88.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.075 | Acc: 49.707,74.487,88.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.047 | Acc: 46.875,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.489 | Acc: 47.098,63.616,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.522 | Acc: 45.751,62.881,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 45.338,62.654,69.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 3.155 | Acc: 46.094,73.438,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.037 | Acc: 49.628,75.223,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.004 | Acc: 50.152,75.629,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.028 | Acc: 50.077,75.192,89.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.037 | Acc: 49.778,74.942,89.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.026 | Acc: 50.232,75.201,89.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.026 | Acc: 50.168,75.136,89.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.027 | Acc: 50.205,74.917,89.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.024 | Acc: 50.175,75.150,89.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.031 | Acc: 50.065,75.112,89.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.040 | Acc: 49.895,75.054,89.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.047 | Acc: 49.880,74.954,88.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.051 | Acc: 49.780,74.851,88.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.045 | Acc: 49.773,74.934,88.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.057 | Acc: 49.683,74.814,88.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.059 | Acc: 49.637,74.766,88.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.060 | Acc: 49.659,74.742,88.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.062 | Acc: 49.707,74.716,88.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.061 | Acc: 49.732,74.693,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.062 | Acc: 49.686,74.709,88.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.162 | Acc: 48.438,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.505 | Acc: 45.647,64.435,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 45.312,63.891,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.526 | Acc: 45.005,63.550,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.955 | Acc: 49.219,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.992 | Acc: 49.405,74.926,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.967 | Acc: 50.133,75.324,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.960 | Acc: 50.026,75.461,89.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.997 | Acc: 49.826,75.125,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.981 | Acc: 50.070,75.418,89.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.994 | Acc: 49.806,75.071,89.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.999 | Acc: 49.823,75.216,89.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.013 | Acc: 49.602,75.136,89.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.014 | Acc: 49.581,75.160,89.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.013 | Acc: 49.689,75.066,89.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.019 | Acc: 49.611,75.074,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.015 | Acc: 49.640,75.149,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.025 | Acc: 49.545,75.036,89.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.026 | Acc: 49.600,75.042,89.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.035 | Acc: 49.530,74.927,89.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.037 | Acc: 49.501,74.873,89.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.043 | Acc: 49.608,74.794,89.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.046 | Acc: 49.610,74.695,89.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.046 | Acc: 49.631,74.692,89.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.316 | Acc: 45.312,71.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 45.982,64.472,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.484 | Acc: 45.694,64.024,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.496 | Acc: 45.530,63.640,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 2.587 | Acc: 51.562,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.996 | Acc: 49.628,74.888,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.007 | Acc: 49.143,75.095,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.011 | Acc: 49.103,75.166,90.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.017 | Acc: 48.978,75.039,90.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.013 | Acc: 49.196,74.977,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.033 | Acc: 48.980,74.839,89.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.028 | Acc: 49.241,75.000,89.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.019 | Acc: 49.529,75.121,89.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.030 | Acc: 49.430,75.047,89.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.035 | Acc: 49.366,75.004,89.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.029 | Acc: 49.410,75.095,89.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.033 | Acc: 49.433,75.094,89.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.045 | Acc: 49.315,74.904,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.046 | Acc: 49.322,74.836,89.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.048 | Acc: 49.372,74.826,89.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.048 | Acc: 49.323,74.827,89.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.046 | Acc: 49.317,74.867,89.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.044 | Acc: 49.398,74.844,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.046 | Acc: 49.379,74.832,89.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.158 | Acc: 42.969,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.425 | Acc: 46.763,64.807,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.446 | Acc: 46.513,64.120,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.463 | Acc: 45.966,63.768,69.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 2.636 | Acc: 52.344,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 50.595,76.228,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.997 | Acc: 49.790,75.419,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 49.974,75.346,89.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.988 | Acc: 50.010,75.357,89.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.988 | Acc: 49.869,75.387,89.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.982 | Acc: 49.910,75.439,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.984 | Acc: 49.861,75.604,89.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.996 | Acc: 49.733,75.432,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.995 | Acc: 49.892,75.531,89.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.996 | Acc: 49.856,75.463,89.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.000 | Acc: 49.908,75.361,89.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.006 | Acc: 49.948,75.188,89.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.005 | Acc: 49.991,75.230,89.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.004 | Acc: 50.011,75.178,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.015 | Acc: 49.868,75.062,89.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.018 | Acc: 49.866,75.027,89.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.026 | Acc: 49.892,74.963,89.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.029 | Acc: 49.853,74.944,89.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.029 | Acc: 49.846,74.914,89.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.145 | Acc: 45.312,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.470 | Acc: 46.168,64.472,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.501 | Acc: 45.655,63.834,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.525 | Acc: 45.210,63.537,69.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 3.580 | Acc: 41.406,67.188,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 50.298,75.335,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.982 | Acc: 50.381,75.705,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.012 | Acc: 49.910,75.564,89.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.020 | Acc: 50.010,75.328,89.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.024 | Acc: 50.224,75.178,89.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.009 | Acc: 50.426,75.316,89.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.993 | Acc: 50.609,75.371,89.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.004 | Acc: 50.408,75.306,89.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.009 | Acc: 50.350,75.246,89.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.012 | Acc: 50.377,75.307,89.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.006 | Acc: 50.364,75.396,89.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.006 | Acc: 50.350,75.357,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.995 | Acc: 50.395,75.527,89.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.993 | Acc: 50.386,75.520,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.995 | Acc: 50.353,75.501,89.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.996 | Acc: 50.329,75.518,89.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.001 | Acc: 50.280,75.355,89.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.007 | Acc: 50.188,75.288,89.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.011 | Acc: 50.094,75.254,89.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.166 | Acc: 45.312,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.486 | Acc: 45.871,63.467,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.520 | Acc: 45.846,63.167,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.526 | Acc: 45.697,63.038,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 2.898 | Acc: 50.781,78.906,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.991 | Acc: 50.967,74.814,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.048 | Acc: 50.171,74.428,89.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 50.038,75.141,89.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.017 | Acc: 49.836,75.068,89.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.016 | Acc: 50.000,75.155,89.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.994 | Acc: 50.542,75.394,89.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.003 | Acc: 50.477,75.277,89.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.998 | Acc: 50.471,75.209,89.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.007 | Acc: 50.354,75.168,89.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.018 | Acc: 50.245,74.918,89.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.026 | Acc: 50.212,74.795,89.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.031 | Acc: 49.997,74.728,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.030 | Acc: 50.096,74.865,89.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.024 | Acc: 50.214,74.939,89.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.013 | Acc: 50.361,75.005,89.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.011 | Acc: 50.358,75.051,89.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.011 | Acc: 50.266,75.080,89.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.012 | Acc: 50.190,75.091,89.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.012 | Acc: 50.109,75.057,89.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.336 | Acc: 45.312,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 46.317,64.062,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.549 | Acc: 45.408,63.586,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.564 | Acc: 45.351,63.345,69.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 3.022 | Acc: 49.219,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.041 | Acc: 50.670,74.926,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.988 | Acc: 50.781,75.514,89.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.980 | Acc: 50.423,75.346,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.992 | Acc: 50.222,75.145,90.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.982 | Acc: 50.147,75.232,90.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.985 | Acc: 50.155,75.258,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.989 | Acc: 50.044,75.277,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.987 | Acc: 50.000,75.340,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.985 | Acc: 49.948,75.294,90.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.986 | Acc: 50.128,75.257,89.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.992 | Acc: 50.127,75.304,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.991 | Acc: 50.201,75.305,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.990 | Acc: 50.192,75.314,89.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.995 | Acc: 50.120,75.247,89.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.999 | Acc: 50.049,75.135,89.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.998 | Acc: 50.061,75.163,89.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.002 | Acc: 49.998,75.080,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.003 | Acc: 50.063,75.091,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.003 | Acc: 50.049,75.098,89.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.267 | Acc: 48.438,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 46.094,64.509,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 45.427,64.272,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.553 | Acc: 45.389,63.781,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 3.039 | Acc: 56.250,78.906,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.909 | Acc: 50.967,76.972,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.940 | Acc: 50.667,75.972,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.955 | Acc: 50.384,76.242,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.940 | Acc: 50.338,76.427,90.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.944 | Acc: 50.240,76.091,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.972 | Acc: 50.006,75.788,90.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.982 | Acc: 49.873,75.698,90.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.982 | Acc: 49.976,75.708,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.976 | Acc: 49.978,75.811,90.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.971 | Acc: 50.019,75.828,90.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.978 | Acc: 50.060,75.520,90.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.980 | Acc: 49.974,75.558,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.981 | Acc: 50.039,75.476,90.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.977 | Acc: 50.128,75.425,90.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.977 | Acc: 50.127,75.431,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.983 | Acc: 50.080,75.321,90.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.989 | Acc: 49.959,75.254,89.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.989 | Acc: 49.922,75.216,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.989 | Acc: 49.951,75.187,89.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.393 | Acc: 47.656,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 46.503,63.690,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 45.770,63.491,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.595 | Acc: 45.441,63.294,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 2.961 | Acc: 48.438,72.656,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.969 | Acc: 49.628,76.042,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.957 | Acc: 49.638,75.953,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.943 | Acc: 50.179,75.794,90.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.976 | Acc: 49.759,75.357,90.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.971 | Acc: 49.946,75.503,90.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.990 | Acc: 49.948,75.142,90.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.994 | Acc: 49.967,75.266,90.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.979 | Acc: 50.102,75.543,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.971 | Acc: 50.216,75.617,90.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.973 | Acc: 50.105,75.595,90.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.967 | Acc: 50.085,75.597,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.971 | Acc: 49.971,75.502,90.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.976 | Acc: 50.012,75.425,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.985 | Acc: 49.889,75.267,90.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.989 | Acc: 49.868,75.236,90.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.994 | Acc: 49.810,75.207,90.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.001 | Acc: 49.707,75.103,89.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.997 | Acc: 49.723,75.160,89.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.998 | Acc: 49.789,75.098,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.322 | Acc: 48.438,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.540 | Acc: 45.759,64.100,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.585 | Acc: 45.827,63.262,68.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.597 | Acc: 45.466,62.795,68.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 2.809 | Acc: 46.094,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.006 | Acc: 49.665,75.446,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.974 | Acc: 50.057,75.400,89.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.958 | Acc: 50.333,75.602,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.936 | Acc: 50.309,75.762,90.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.937 | Acc: 50.526,75.681,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.934 | Acc: 50.684,75.710,90.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.937 | Acc: 50.737,75.704,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.934 | Acc: 50.796,75.636,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.944 | Acc: 50.514,75.514,90.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.951 | Acc: 50.463,75.536,90.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.959 | Acc: 50.428,75.368,90.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.967 | Acc: 50.444,75.305,90.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.972 | Acc: 50.377,75.260,90.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.973 | Acc: 50.320,75.336,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.977 | Acc: 50.286,75.262,90.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.980 | Acc: 50.294,75.256,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.983 | Acc: 50.332,75.208,89.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.985 | Acc: 50.318,75.199,89.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.983 | Acc: 50.369,75.189,89.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.228 | Acc: 49.219,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.589 | Acc: 45.722,64.062,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 45.122,63.929,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 44.992,63.307,69.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.905 | Acc: 51.562,76.562,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 49.851,76.674,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.935 | Acc: 50.286,76.086,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.991 | Acc: 49.705,75.026,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.982 | Acc: 49.826,75.039,90.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.963 | Acc: 49.985,75.286,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.966 | Acc: 49.916,75.420,90.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.966 | Acc: 49.884,75.499,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.969 | Acc: 49.791,75.524,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.975 | Acc: 49.719,75.432,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.964 | Acc: 50.031,75.521,90.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.968 | Acc: 50.078,75.587,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.966 | Acc: 50.013,75.535,90.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.971 | Acc: 50.018,75.464,90.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.973 | Acc: 50.036,75.420,90.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.983 | Acc: 49.896,75.311,89.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.978 | Acc: 49.903,75.387,89.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.974 | Acc: 49.922,75.408,89.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.975 | Acc: 49.946,75.379,90.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.977 | Acc: 49.893,75.349,90.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.342 | Acc: 44.531,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.561 | Acc: 46.243,64.472,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 45.636,63.891,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 45.018,63.576,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 2.934 | Acc: 43.750,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.885 | Acc: 49.182,76.042,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.920 | Acc: 49.486,75.896,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.936 | Acc: 49.334,75.320,91.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.937 | Acc: 49.932,75.386,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.946 | Acc: 49.536,75.302,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.956 | Acc: 49.626,75.258,90.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.952 | Acc: 49.789,75.283,90.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.956 | Acc: 49.922,75.330,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.961 | Acc: 49.922,75.285,90.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.962 | Acc: 49.934,75.214,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.969 | Acc: 49.965,75.113,90.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.966 | Acc: 49.968,75.224,90.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.969 | Acc: 49.991,75.135,90.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.970 | Acc: 49.961,75.117,90.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.970 | Acc: 49.938,75.049,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.965 | Acc: 49.978,75.156,90.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.960 | Acc: 50.124,75.268,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.968 | Acc: 50.024,75.169,90.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.964 | Acc: 50.012,75.256,90.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.509 | Acc: 47.656,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.597 | Acc: 45.982,64.546,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 45.732,63.224,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.620 | Acc: 45.159,63.115,68.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 2.623 | Acc: 52.344,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.932 | Acc: 50.521,75.260,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.958 | Acc: 50.191,75.152,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.924 | Acc: 50.730,75.756,91.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.920 | Acc: 50.656,75.762,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.951 | Acc: 50.201,75.750,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.954 | Acc: 50.097,75.581,90.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.953 | Acc: 50.133,75.526,90.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.958 | Acc: 49.981,75.412,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.955 | Acc: 49.914,75.445,90.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.961 | Acc: 49.794,75.412,90.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.955 | Acc: 49.855,75.626,90.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.956 | Acc: 49.838,75.571,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.957 | Acc: 49.835,75.653,90.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.952 | Acc: 49.900,75.698,90.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.961 | Acc: 49.888,75.633,90.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.962 | Acc: 49.847,75.630,90.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.964 | Acc: 49.867,75.612,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.959 | Acc: 49.896,75.643,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.960 | Acc: 49.912,75.564,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.225 | Acc: 46.094,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.489 | Acc: 46.354,64.993,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.486 | Acc: 45.713,64.672,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.511 | Acc: 45.658,63.858,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 2.817 | Acc: 53.906,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.027 | Acc: 48.140,74.554,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.978 | Acc: 49.371,75.362,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.923 | Acc: 50.243,75.973,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.892 | Acc: 50.704,76.524,90.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.904 | Acc: 50.642,76.330,90.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.912 | Acc: 50.588,76.240,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.914 | Acc: 50.543,76.230,90.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.910 | Acc: 50.689,76.310,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.917 | Acc: 50.514,76.118,90.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.920 | Acc: 50.424,75.929,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.928 | Acc: 50.173,75.848,90.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.935 | Acc: 50.172,75.859,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.932 | Acc: 50.180,75.892,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.934 | Acc: 50.108,75.892,90.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.938 | Acc: 50.070,75.893,90.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.939 | Acc: 50.119,75.803,90.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.944 | Acc: 50.041,75.685,90.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.947 | Acc: 50.039,75.671,90.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.953 | Acc: 50.004,75.527,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.359 | Acc: 46.094,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 46.280,64.472,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 45.827,63.834,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 45.556,63.486,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 2.814 | Acc: 54.688,78.125,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.923 | Acc: 50.223,76.153,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.921 | Acc: 50.248,75.476,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.926 | Acc: 50.499,75.218,91.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.920 | Acc: 50.656,75.540,90.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.904 | Acc: 50.804,75.820,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.914 | Acc: 50.575,75.639,90.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.918 | Acc: 50.554,75.637,90.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.925 | Acc: 50.490,75.650,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.928 | Acc: 50.483,75.678,90.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.934 | Acc: 50.439,75.637,90.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.934 | Acc: 50.308,75.661,90.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.941 | Acc: 50.253,75.616,90.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.939 | Acc: 50.284,75.608,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.939 | Acc: 50.267,75.617,90.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.941 | Acc: 50.205,75.542,90.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.937 | Acc: 50.273,75.601,90.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.936 | Acc: 50.344,75.550,90.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.945 | Acc: 50.238,75.509,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.947 | Acc: 50.152,75.498,90.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.287 | Acc: 46.094,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.529 | Acc: 47.061,64.025,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 45.884,63.720,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.621 | Acc: 45.581,63.140,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.739 | Acc: 53.906,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 50.372,76.414,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.921 | Acc: 50.724,75.667,90.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.940 | Acc: 50.512,75.986,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.928 | Acc: 50.280,76.148,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.916 | Acc: 50.472,76.292,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.912 | Acc: 50.407,76.175,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.924 | Acc: 50.216,76.080,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.926 | Acc: 50.092,76.135,90.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.919 | Acc: 50.199,76.174,90.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.913 | Acc: 50.249,76.147,90.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.925 | Acc: 50.131,76.029,90.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.932 | Acc: 50.075,75.914,90.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.936 | Acc: 50.093,75.907,90.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.939 | Acc: 50.103,75.840,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.937 | Acc: 50.109,75.825,90.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.938 | Acc: 50.122,75.781,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.940 | Acc: 50.089,75.754,90.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.939 | Acc: 50.119,75.712,90.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.936 | Acc: 50.168,75.783,90.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.321 | Acc: 47.656,71.875,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 47.024,63.951,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 46.341,63.377,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.546 | Acc: 45.978,63.064,68.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 2.640 | Acc: 50.781,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.805 | Acc: 51.525,76.562,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.874 | Acc: 50.857,76.315,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.857 | Acc: 50.909,76.857,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.890 | Acc: 50.145,76.505,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.885 | Acc: 50.155,76.632,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.898 | Acc: 50.149,76.362,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.898 | Acc: 50.316,76.219,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.906 | Acc: 50.272,76.126,91.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.910 | Acc: 50.268,76.027,91.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.915 | Acc: 50.194,75.956,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.926 | Acc: 50.053,75.845,90.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.926 | Acc: 50.013,75.846,90.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.930 | Acc: 50.060,75.733,90.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.929 | Acc: 50.039,75.698,90.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.934 | Acc: 50.047,75.698,90.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.942 | Acc: 50.112,75.628,90.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.945 | Acc: 50.060,75.614,90.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.947 | Acc: 50.035,75.571,90.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.947 | Acc: 50.018,75.537,90.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.328 | Acc: 48.438,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.538 | Acc: 46.540,63.988,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 45.998,63.605,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 45.402,63.307,68.712,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 2.560 | Acc: 48.438,82.031,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.867 | Acc: 50.186,76.525,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.951 | Acc: 48.990,75.305,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.936 | Acc: 49.385,75.564,91.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.941 | Acc: 49.228,75.694,91.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.939 | Acc: 49.281,75.874,91.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.921 | Acc: 49.638,76.123,91.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.927 | Acc: 49.712,75.870,90.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.918 | Acc: 49.956,75.990,90.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.918 | Acc: 50.065,75.971,90.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.924 | Acc: 50.089,75.999,90.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.932 | Acc: 49.986,75.930,90.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.931 | Acc: 50.078,75.853,90.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.931 | Acc: 49.985,75.817,90.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.934 | Acc: 49.950,75.751,90.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.930 | Acc: 50.000,75.820,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.932 | Acc: 49.939,75.827,90.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.934 | Acc: 49.945,75.777,90.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.931 | Acc: 50.080,75.818,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.935 | Acc: 49.992,75.771,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.252 | Acc: 50.781,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.544 | Acc: 47.173,64.472,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.558 | Acc: 46.380,64.082,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 45.889,63.717,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 2.868 | Acc: 48.438,78.906,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.904 | Acc: 50.260,75.558,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.886 | Acc: 49.886,75.553,91.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.853 | Acc: 50.410,76.153,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.864 | Acc: 50.511,75.993,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.884 | Acc: 50.162,75.874,91.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.888 | Acc: 50.336,75.865,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.900 | Acc: 50.127,75.814,91.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.907 | Acc: 49.956,75.806,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.904 | Acc: 49.961,75.824,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.908 | Acc: 49.953,75.676,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.919 | Acc: 49.951,75.576,91.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.914 | Acc: 50.233,75.681,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.913 | Acc: 50.210,75.736,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.919 | Acc: 50.209,75.667,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.914 | Acc: 50.226,75.701,90.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.912 | Acc: 50.234,75.699,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.915 | Acc: 50.204,75.648,90.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.916 | Acc: 50.279,75.647,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.916 | Acc: 50.285,75.675,90.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.125 | Acc: 50.000,71.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.561 | Acc: 46.801,64.769,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 46.151,63.929,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 45.735,63.384,68.635,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.608 | Acc: 53.125,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.880 | Acc: 50.446,76.302,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.890 | Acc: 50.400,76.848,91.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.911 | Acc: 50.653,76.409,91.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.931 | Acc: 50.367,76.013,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.941 | Acc: 50.046,75.812,90.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.932 | Acc: 49.987,75.775,90.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.931 | Acc: 50.050,75.726,90.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.918 | Acc: 50.199,75.932,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.924 | Acc: 50.091,75.889,90.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.927 | Acc: 50.128,75.816,90.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.929 | Acc: 50.120,75.764,90.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.932 | Acc: 50.081,75.836,90.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.926 | Acc: 50.084,75.811,90.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.930 | Acc: 50.044,75.840,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.930 | Acc: 49.982,75.760,90.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.927 | Acc: 50.056,75.684,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.925 | Acc: 50.037,75.742,90.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.929 | Acc: 49.939,75.695,90.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.930 | Acc: 50.033,75.671,90.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.293 | Acc: 49.219,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.600 | Acc: 45.573,63.765,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.608 | Acc: 45.312,63.243,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.637 | Acc: 44.967,62.859,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 2.676 | Acc: 49.219,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.862 | Acc: 50.930,75.893,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.814 | Acc: 51.925,77.096,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.826 | Acc: 51.729,76.985,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.842 | Acc: 51.341,76.659,91.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.854 | Acc: 50.890,76.516,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.845 | Acc: 51.059,76.440,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.848 | Acc: 50.964,76.490,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.849 | Acc: 50.903,76.616,91.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.859 | Acc: 50.842,76.528,91.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.866 | Acc: 50.704,76.419,91.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.878 | Acc: 50.562,76.308,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.889 | Acc: 50.571,76.170,90.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.892 | Acc: 50.560,76.167,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.895 | Acc: 50.503,76.173,90.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.899 | Acc: 50.452,76.132,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.900 | Acc: 50.494,76.039,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.896 | Acc: 50.502,76.072,90.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.899 | Acc: 50.487,76.056,90.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.904 | Acc: 50.390,76.015,90.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.315 | Acc: 44.531,71.875,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.606 | Acc: 46.317,63.765,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.642 | Acc: 45.694,63.129,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.665 | Acc: 45.325,62.769,68.558,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 3.066 | Acc: 50.000,73.438,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.009 | Acc: 48.884,75.298,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.899 | Acc: 50.114,75.934,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.885 | Acc: 50.666,75.961,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.883 | Acc: 50.550,76.292,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.887 | Acc: 50.588,76.222,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.880 | Acc: 50.329,76.278,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.883 | Acc: 50.471,76.291,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.886 | Acc: 50.548,76.257,91.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.898 | Acc: 50.483,76.070,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.891 | Acc: 50.560,76.182,91.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.889 | Acc: 50.551,76.138,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.896 | Acc: 50.395,76.144,90.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.895 | Acc: 50.410,76.116,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.904 | Acc: 50.272,75.976,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.907 | Acc: 50.254,75.950,90.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.901 | Acc: 50.348,75.952,90.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 50.316,76.036,90.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.904 | Acc: 50.320,75.967,90.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.907 | Acc: 50.248,75.941,90.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.272 | Acc: 48.438,74.219,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 45.982,65.439,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 46.132,64.863,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 46.017,64.485,68.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 2.719 | Acc: 54.688,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.785 | Acc: 52.009,77.232,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.834 | Acc: 50.762,76.486,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.827 | Acc: 50.602,76.691,91.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.853 | Acc: 50.473,76.495,91.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.854 | Acc: 50.480,76.446,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.865 | Acc: 50.504,76.433,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 50.526,76.424,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.877 | Acc: 50.490,76.291,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.883 | Acc: 50.276,76.234,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.886 | Acc: 50.381,76.162,91.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.880 | Acc: 50.523,76.205,91.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.881 | Acc: 50.447,76.161,91.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.877 | Acc: 50.476,76.152,91.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.880 | Acc: 50.492,76.143,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.881 | Acc: 50.452,76.155,91.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.882 | Acc: 50.448,76.151,91.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.885 | Acc: 50.312,76.107,91.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.889 | Acc: 50.268,76.024,91.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.894 | Acc: 50.226,75.988,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.367 | Acc: 49.219,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.687 | Acc: 44.494,62.723,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.748 | Acc: 44.245,62.329,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.751 | Acc: 44.211,62.052,68.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 2.701 | Acc: 51.562,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.835 | Acc: 49.702,76.190,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 49.886,76.258,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.865 | Acc: 49.949,76.370,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.862 | Acc: 50.125,76.264,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.864 | Acc: 50.302,76.176,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 50.439,76.207,91.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.879 | Acc: 50.338,76.103,91.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.876 | Acc: 50.451,76.160,91.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.881 | Acc: 50.583,76.234,91.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.880 | Acc: 50.622,76.244,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.875 | Acc: 50.601,76.333,91.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.881 | Acc: 50.587,76.203,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.891 | Acc: 50.419,76.054,91.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 50.364,76.076,91.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.900 | Acc: 50.252,75.976,91.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.906 | Acc: 50.119,75.942,91.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.908 | Acc: 50.151,75.923,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.909 | Acc: 50.212,75.946,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.907 | Acc: 50.258,76.009,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.577 | Acc: 45.312,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.879 | Acc: 44.122,62.537,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.875 | Acc: 43.674,62.081,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.891 | Acc: 43.186,61.949,67.623,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 2.740 | Acc: 49.219,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.908 | Acc: 49.888,75.595,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.913 | Acc: 49.581,76.162,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.918 | Acc: 49.513,76.217,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.881 | Acc: 50.376,76.669,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.882 | Acc: 50.541,76.501,91.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.879 | Acc: 50.355,76.433,91.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.885 | Acc: 50.188,76.496,91.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.887 | Acc: 50.233,76.344,91.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.879 | Acc: 50.363,76.442,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.879 | Acc: 50.373,76.508,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.884 | Acc: 50.325,76.425,91.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.889 | Acc: 50.272,76.368,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.891 | Acc: 50.180,76.401,91.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.890 | Acc: 50.239,76.401,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.889 | Acc: 50.184,76.399,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.889 | Acc: 50.258,76.397,91.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.893 | Acc: 50.280,76.320,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.897 | Acc: 50.288,76.262,91.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.901 | Acc: 50.301,76.169,91.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.367 | Acc: 47.656,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.708 | Acc: 46.429,63.802,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.733 | Acc: 45.236,63.319,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.760 | Acc: 45.133,62.590,67.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.551 | Acc: 52.344,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.752 | Acc: 50.037,78.237,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.835 | Acc: 49.505,76.143,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.871 | Acc: 49.629,75.807,91.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.871 | Acc: 50.251,75.801,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.883 | Acc: 50.271,75.897,91.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.879 | Acc: 50.226,76.188,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.870 | Acc: 50.299,76.330,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.883 | Acc: 50.214,76.252,91.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 50.574,76.407,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.877 | Acc: 50.630,76.325,91.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.889 | Acc: 50.636,76.174,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.895 | Acc: 50.584,76.089,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.888 | Acc: 50.620,76.197,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.882 | Acc: 50.706,76.193,91.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.889 | Acc: 50.662,76.062,91.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.887 | Acc: 50.662,76.139,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.898 | Acc: 50.438,76.116,91.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.900 | Acc: 50.405,76.158,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.902 | Acc: 50.474,76.132,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.287 | Acc: 50.781,71.875,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 47.433,63.728,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 46.532,63.434,68.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.622 | Acc: 46.158,63.038,68.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 2.716 | Acc: 50.781,75.000,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.899 | Acc: 50.074,75.930,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.834 | Acc: 50.362,76.772,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.834 | Acc: 50.692,76.908,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.851 | Acc: 50.530,76.707,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.865 | Acc: 50.557,76.655,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.879 | Acc: 50.329,76.491,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.887 | Acc: 50.139,76.485,91.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.895 | Acc: 50.010,76.393,91.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.903 | Acc: 49.810,76.243,91.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.902 | Acc: 49.856,76.271,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.903 | Acc: 49.852,76.124,91.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.898 | Acc: 49.887,76.138,91.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.894 | Acc: 49.952,76.179,91.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.896 | Acc: 49.956,76.168,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.905 | Acc: 49.844,76.062,91.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.899 | Acc: 49.888,76.144,91.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.897 | Acc: 49.963,76.070,91.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.894 | Acc: 50.039,76.028,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.896 | Acc: 50.062,76.001,91.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.357 | Acc: 49.219,69.531,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.623 | Acc: 47.024,63.988,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.656 | Acc: 45.979,63.510,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.685 | Acc: 45.453,62.782,68.481,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.821 | Acc: 56.250,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.839 | Acc: 51.153,76.749,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.871 | Acc: 50.438,76.582,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.865 | Acc: 50.589,76.742,91.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.856 | Acc: 50.916,76.698,91.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.855 | Acc: 50.890,76.570,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.863 | Acc: 50.930,76.453,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.861 | Acc: 50.898,76.435,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 50.810,76.504,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.854 | Acc: 50.669,76.636,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.861 | Acc: 50.676,76.520,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.862 | Acc: 50.682,76.552,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.865 | Acc: 50.678,76.430,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.860 | Acc: 50.682,76.565,91.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.863 | Acc: 50.703,76.607,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 50.722,76.485,91.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.870 | Acc: 50.640,76.492,91.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.870 | Acc: 50.630,76.404,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.875 | Acc: 50.606,76.335,91.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.876 | Acc: 50.607,76.362,91.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.472 | Acc: 50.000,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.618 | Acc: 45.685,64.100,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.682 | Acc: 44.760,63.243,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 44.582,62.948,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 2.606 | Acc: 50.000,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.885 | Acc: 50.744,75.595,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.873 | Acc: 50.553,76.048,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.880 | Acc: 50.807,76.498,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.886 | Acc: 50.521,76.196,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.882 | Acc: 50.534,75.874,91.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.876 | Acc: 50.807,75.749,91.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 50.875,75.820,91.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.866 | Acc: 50.844,75.912,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.874 | Acc: 50.699,75.803,91.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.866 | Acc: 50.738,75.976,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.872 | Acc: 50.810,75.937,91.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.864 | Acc: 50.823,76.076,91.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.862 | Acc: 50.802,76.164,91.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.865 | Acc: 50.748,76.182,91.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.870 | Acc: 50.610,76.163,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.875 | Acc: 50.506,76.107,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.873 | Acc: 50.548,76.107,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.875 | Acc: 50.485,76.019,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.876 | Acc: 50.414,76.017,91.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.407 | Acc: 51.562,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.680 | Acc: 45.833,64.174,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.696 | Acc: 45.160,63.491,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.720 | Acc: 44.851,63.358,68.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 3.136 | Acc: 51.562,70.312,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.802 | Acc: 53.051,77.269,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 52.039,77.191,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 51.537,76.908,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.833 | Acc: 51.090,76.630,91.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 50.735,76.555,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 50.859,76.562,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.844 | Acc: 50.654,76.690,91.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.843 | Acc: 50.650,76.698,91.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.850 | Acc: 50.552,76.571,91.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 50.634,76.516,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.841 | Acc: 50.820,76.647,91.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.839 | Acc: 50.840,76.657,91.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.844 | Acc: 50.856,76.533,91.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.852 | Acc: 50.662,76.371,91.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.861 | Acc: 50.638,76.251,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.868 | Acc: 50.509,76.146,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.875 | Acc: 50.417,76.086,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.878 | Acc: 50.359,76.153,91.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.873 | Acc: 50.353,76.226,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.418 | Acc: 47.656,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.692 | Acc: 46.057,63.058,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.747 | Acc: 45.522,63.205,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.758 | Acc: 45.095,62.641,67.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.987 | Acc: 46.094,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.782 | Acc: 50.521,76.525,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.864 | Acc: 49.790,76.277,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.877 | Acc: 49.667,76.101,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.856 | Acc: 49.981,76.264,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.868 | Acc: 49.799,76.300,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.874 | Acc: 49.787,76.453,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.869 | Acc: 49.834,76.601,91.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.870 | Acc: 49.947,76.592,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.871 | Acc: 50.052,76.515,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.869 | Acc: 50.047,76.493,91.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.873 | Acc: 50.035,76.400,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 50.246,76.362,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.868 | Acc: 50.257,76.476,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.869 | Acc: 50.228,76.373,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.867 | Acc: 50.236,76.428,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.871 | Acc: 50.204,76.287,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.875 | Acc: 50.199,76.320,91.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.880 | Acc: 50.171,76.268,91.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.878 | Acc: 50.178,76.253,91.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.370 | Acc: 47.656,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.587 | Acc: 46.205,63.690,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.644 | Acc: 45.484,63.529,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.662 | Acc: 45.428,63.166,68.801,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 2.937 | Acc: 55.469,75.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.887 | Acc: 50.781,76.302,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.871 | Acc: 50.476,76.048,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.873 | Acc: 50.525,76.076,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.853 | Acc: 50.858,76.283,91.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.864 | Acc: 50.719,76.183,91.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.859 | Acc: 50.936,76.446,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.853 | Acc: 50.848,76.407,92.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.852 | Acc: 50.801,76.543,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.850 | Acc: 50.656,76.636,91.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.862 | Acc: 50.451,76.528,91.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.861 | Acc: 50.407,76.548,91.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.854 | Acc: 50.438,76.644,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.860 | Acc: 50.332,76.616,91.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.870 | Acc: 50.170,76.526,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.870 | Acc: 50.164,76.526,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.876 | Acc: 50.200,76.438,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.880 | Acc: 50.263,76.384,91.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.881 | Acc: 50.247,76.331,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.876 | Acc: 50.262,76.366,91.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.285 | Acc: 49.219,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.570 | Acc: 46.652,64.323,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.654 | Acc: 45.827,63.396,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.659 | Acc: 45.838,63.281,68.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 3.146 | Acc: 37.500,70.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.811 | Acc: 51.004,76.935,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.813 | Acc: 50.819,77.153,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.822 | Acc: 51.140,76.703,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.813 | Acc: 51.080,76.698,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.820 | Acc: 51.137,76.663,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.843 | Acc: 50.801,76.414,91.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.856 | Acc: 50.493,76.213,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.861 | Acc: 50.359,76.266,91.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.859 | Acc: 50.367,76.286,91.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.860 | Acc: 50.470,76.325,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.858 | Acc: 50.548,76.350,91.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.856 | Acc: 50.600,76.449,91.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.859 | Acc: 50.527,76.479,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.851 | Acc: 50.673,76.585,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.863 | Acc: 50.519,76.518,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.861 | Acc: 50.570,76.516,91.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.860 | Acc: 50.577,76.503,91.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.862 | Acc: 50.543,76.485,91.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.862 | Acc: 50.584,76.468,91.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.273 | Acc: 43.750,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.725 | Acc: 45.461,62.872,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.747 | Acc: 44.836,62.500,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.775 | Acc: 44.698,62.001,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 2.824 | Acc: 43.750,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.824 | Acc: 49.330,76.414,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.834 | Acc: 49.714,76.429,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.814 | Acc: 50.704,76.716,92.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.810 | Acc: 51.003,76.707,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.815 | Acc: 51.114,76.617,92.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.821 | Acc: 51.078,76.595,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.832 | Acc: 50.970,76.468,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.844 | Acc: 50.820,76.446,91.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.840 | Acc: 50.811,76.515,91.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.842 | Acc: 50.781,76.481,91.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 50.785,76.580,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.838 | Acc: 50.768,76.511,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.845 | Acc: 50.739,76.431,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.850 | Acc: 50.748,76.423,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.858 | Acc: 50.623,76.396,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.860 | Acc: 50.587,76.387,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.859 | Acc: 50.651,76.420,91.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.859 | Acc: 50.718,76.394,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.864 | Acc: 50.615,76.335,91.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 46.875,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.704 | Acc: 45.945,63.728,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.715 | Acc: 45.274,63.091,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.732 | Acc: 44.941,62.705,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 2.818 | Acc: 53.125,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.794 | Acc: 51.302,76.935,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.784 | Acc: 51.505,77.801,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.793 | Acc: 51.511,77.152,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.798 | Acc: 51.206,77.180,91.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.827 | Acc: 51.129,76.957,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.829 | Acc: 50.936,76.801,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.848 | Acc: 50.615,76.673,91.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.851 | Acc: 50.514,76.616,91.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.856 | Acc: 50.414,76.558,91.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.851 | Acc: 50.365,76.485,91.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.857 | Acc: 50.180,76.393,91.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.856 | Acc: 50.227,76.423,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.855 | Acc: 50.287,76.350,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.862 | Acc: 50.200,76.254,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.866 | Acc: 50.179,76.220,91.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.869 | Acc: 50.173,76.183,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.866 | Acc: 50.202,76.242,91.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.862 | Acc: 50.277,76.260,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.866 | Acc: 50.244,76.193,91.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.583 | Acc: 45.312,69.531,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.766 | Acc: 45.312,63.318,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.773 | Acc: 45.103,63.396,68.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.788 | Acc: 44.749,62.807,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.436 | Acc: 57.812,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.776 | Acc: 51.153,77.567,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.767 | Acc: 51.162,77.725,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.770 | Acc: 51.332,77.305,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.791 | Acc: 51.157,77.141,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.775 | Acc: 51.416,77.220,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.786 | Acc: 51.111,77.060,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 50.898,77.178,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.800 | Acc: 50.747,77.155,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 50.496,76.960,92.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.810 | Acc: 50.509,76.936,92.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.819 | Acc: 50.421,76.764,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.830 | Acc: 50.327,76.650,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.836 | Acc: 50.350,76.574,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.840 | Acc: 50.403,76.521,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.842 | Acc: 50.441,76.428,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.844 | Acc: 50.397,76.482,91.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 50.467,76.542,91.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.849 | Acc: 50.459,76.461,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.851 | Acc: 50.457,76.474,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.453 | Acc: 45.312,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.689 | Acc: 46.094,64.509,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.721 | Acc: 45.617,63.834,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.731 | Acc: 45.223,63.076,68.904,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.501 | Acc: 54.688,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.792 | Acc: 51.711,76.897,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.797 | Acc: 50.896,76.867,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.771 | Acc: 51.140,77.267,92.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 50.733,77.016,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.803 | Acc: 50.418,77.127,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.798 | Acc: 50.730,77.286,92.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.808 | Acc: 50.587,77.117,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.829 | Acc: 50.315,76.965,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.841 | Acc: 50.220,76.916,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.840 | Acc: 50.194,76.850,91.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.839 | Acc: 50.184,76.867,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.843 | Acc: 50.016,76.832,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.840 | Acc: 50.042,76.817,91.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.844 | Acc: 50.061,76.782,91.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.841 | Acc: 50.145,76.755,91.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.845 | Acc: 50.175,76.738,91.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.845 | Acc: 50.284,76.695,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.846 | Acc: 50.286,76.695,91.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 50.320,76.698,91.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.343 | Acc: 49.219,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.680 | Acc: 46.912,63.876,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.700 | Acc: 45.713,63.453,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.708 | Acc: 45.530,62.871,68.609,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.509 | Acc: 60.156,79.688,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 51.562,77.046,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.791 | Acc: 50.819,76.677,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.816 | Acc: 50.448,76.614,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.825 | Acc: 50.318,76.755,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.842 | Acc: 49.930,76.586,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.826 | Acc: 50.194,76.931,91.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.840 | Acc: 50.033,76.873,91.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.843 | Acc: 50.034,76.708,91.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.837 | Acc: 50.207,76.869,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.845 | Acc: 50.222,76.691,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.851 | Acc: 50.159,76.552,91.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.847 | Acc: 50.331,76.533,91.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.852 | Acc: 50.260,76.470,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.856 | Acc: 50.203,76.496,91.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.854 | Acc: 50.210,76.625,91.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.853 | Acc: 50.248,76.643,91.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 50.252,76.556,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 50.223,76.472,91.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.851 | Acc: 50.271,76.480,91.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.514 | Acc: 47.656,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.695 | Acc: 45.833,64.025,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.715 | Acc: 45.465,63.472,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.731 | Acc: 45.082,62.807,68.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 3.223 | Acc: 39.062,70.312,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.759 | Acc: 50.484,78.311,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 50.781,78.011,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.757 | Acc: 51.332,77.907,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.755 | Acc: 50.965,77.826,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.785 | Acc: 50.596,77.444,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.796 | Acc: 50.717,77.273,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.792 | Acc: 50.892,77.366,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.793 | Acc: 50.796,77.504,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.801 | Acc: 50.781,77.344,92.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.811 | Acc: 50.591,77.243,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.823 | Acc: 50.399,77.167,92.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.823 | Acc: 50.502,77.107,92.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 50.500,77.095,92.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.823 | Acc: 50.506,77.016,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.824 | Acc: 50.532,76.967,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.822 | Acc: 50.552,76.937,92.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.826 | Acc: 50.538,76.936,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.835 | Acc: 50.513,76.781,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.844 | Acc: 50.424,76.614,91.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.547 | Acc: 48.438,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.711 | Acc: 46.726,63.690,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.718 | Acc: 46.284,63.338,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.726 | Acc: 45.914,62.769,67.866,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 2.349 | Acc: 60.938,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.795 | Acc: 51.525,76.042,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.777 | Acc: 51.429,76.905,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.789 | Acc: 50.897,77.126,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.773 | Acc: 51.071,77.103,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.790 | Acc: 51.029,76.810,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.802 | Acc: 50.762,76.808,92.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.796 | Acc: 50.920,76.828,92.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.812 | Acc: 50.825,76.684,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 50.790,76.748,92.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.814 | Acc: 50.805,76.769,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.819 | Acc: 50.760,76.736,92.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.818 | Acc: 50.713,76.796,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.814 | Acc: 50.844,76.826,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.821 | Acc: 50.781,76.763,92.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.820 | Acc: 50.841,76.825,91.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.825 | Acc: 50.774,76.777,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.834 | Acc: 50.575,76.682,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.841 | Acc: 50.530,76.565,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.840 | Acc: 50.455,76.579,91.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.341 | Acc: 50.000,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.721 | Acc: 46.057,62.463,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.758 | Acc: 45.503,62.176,67.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.770 | Acc: 45.197,61.911,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.776 | Acc: 48.438,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.799 | Acc: 51.972,77.381,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.788 | Acc: 52.153,77.344,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.791 | Acc: 51.473,77.216,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.813 | Acc: 51.273,76.968,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.815 | Acc: 51.129,76.849,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.804 | Acc: 51.220,76.989,92.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.810 | Acc: 51.152,76.939,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.819 | Acc: 50.854,76.844,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.831 | Acc: 50.833,76.787,92.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.838 | Acc: 50.762,76.730,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.826 | Acc: 50.873,76.838,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.822 | Acc: 50.862,77.000,92.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 50.796,76.961,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.827 | Acc: 50.634,76.916,92.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.832 | Acc: 50.605,76.856,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.837 | Acc: 50.633,76.835,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.840 | Acc: 50.575,76.776,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.845 | Acc: 50.450,76.675,92.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 50.482,76.675,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.559 | Acc: 48.438,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.741 | Acc: 45.536,63.430,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.774 | Acc: 44.531,62.729,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.789 | Acc: 44.249,62.359,67.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 2.358 | Acc: 54.688,78.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.776 | Acc: 50.000,76.265,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.828 | Acc: 49.352,76.829,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.810 | Acc: 49.808,76.998,92.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.803 | Acc: 50.289,77.286,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.816 | Acc: 50.263,76.825,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.807 | Acc: 50.523,77.014,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 50.720,77.089,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.800 | Acc: 50.951,77.188,92.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.794 | Acc: 51.101,77.266,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.805 | Acc: 50.999,77.126,92.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 50.969,77.114,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.819 | Acc: 50.739,76.994,92.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.821 | Acc: 50.709,77.020,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.829 | Acc: 50.626,76.974,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.829 | Acc: 50.662,76.928,91.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.838 | Acc: 50.630,76.845,91.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.842 | Acc: 50.644,76.762,91.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.841 | Acc: 50.699,76.781,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.846 | Acc: 50.550,76.729,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.617 | Acc: 48.438,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.846 | Acc: 45.536,62.723,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.871 | Acc: 45.008,61.947,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.888 | Acc: 44.839,61.872,67.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 2.990 | Acc: 46.875,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.746 | Acc: 49.814,77.269,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.785 | Acc: 49.848,77.363,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.776 | Acc: 50.435,77.459,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.782 | Acc: 50.530,77.141,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.773 | Acc: 50.719,77.460,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.787 | Acc: 50.626,77.324,92.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.793 | Acc: 50.565,77.327,92.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.807 | Acc: 50.354,77.072,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.811 | Acc: 50.423,77.016,92.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.817 | Acc: 50.455,76.940,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 50.414,76.902,92.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.815 | Acc: 50.545,76.958,92.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.819 | Acc: 50.443,76.955,92.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.820 | Acc: 50.439,76.924,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.827 | Acc: 50.395,76.827,91.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.826 | Acc: 50.426,76.867,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.831 | Acc: 50.401,76.782,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.832 | Acc: 50.441,76.720,91.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.834 | Acc: 50.416,76.745,91.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.532 | Acc: 46.094,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.685 | Acc: 46.280,64.583,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.686 | Acc: 45.922,64.024,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.692 | Acc: 45.633,63.601,68.558,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 2.961 | Acc: 50.781,69.531,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 52.753,77.679,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.753 | Acc: 52.401,77.115,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 51.755,77.036,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.800 | Acc: 51.505,77.045,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.800 | Acc: 51.183,77.034,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.828 | Acc: 50.859,76.788,91.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.821 | Acc: 51.213,76.779,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.817 | Acc: 51.281,76.723,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.817 | Acc: 51.148,76.666,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.818 | Acc: 50.991,76.660,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.822 | Acc: 51.004,76.644,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.821 | Acc: 50.982,76.718,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 50.895,76.754,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.828 | Acc: 50.809,76.732,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.830 | Acc: 50.742,76.775,91.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.834 | Acc: 50.699,76.735,91.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.836 | Acc: 50.648,76.684,91.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.843 | Acc: 50.539,76.588,91.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.843 | Acc: 50.541,76.614,91.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.884 | Acc: 47.656,68.750,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.930 | Acc: 44.159,61.830,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.983 | Acc: 43.140,61.414,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.981 | Acc: 43.058,60.809,67.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 3.227 | Acc: 42.969,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.853 | Acc: 49.888,77.641,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.817 | Acc: 51.315,77.553,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.828 | Acc: 50.948,77.446,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.823 | Acc: 50.984,77.305,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.813 | Acc: 51.129,77.359,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.806 | Acc: 51.065,77.279,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.810 | Acc: 50.875,77.283,92.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.811 | Acc: 50.941,77.266,92.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.819 | Acc: 50.820,77.003,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.818 | Acc: 50.863,76.963,92.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.819 | Acc: 50.788,76.888,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.825 | Acc: 50.716,76.828,92.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.830 | Acc: 50.676,76.748,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.830 | Acc: 50.734,76.785,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.828 | Acc: 50.724,76.809,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.831 | Acc: 50.696,76.777,91.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.831 | Acc: 50.623,76.769,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.830 | Acc: 50.608,76.746,91.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.833 | Acc: 50.552,76.755,91.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.607 | Acc: 49.219,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.857 | Acc: 45.945,63.132,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.888 | Acc: 45.122,62.938,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.888 | Acc: 44.506,62.449,67.687,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.641 | Acc: 54.688,78.125,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.748 | Acc: 51.488,77.530,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.744 | Acc: 51.086,77.877,92.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.753 | Acc: 50.961,77.818,92.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.771 | Acc: 50.916,77.614,92.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.770 | Acc: 50.990,77.692,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.783 | Acc: 51.014,77.628,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.786 | Acc: 50.887,77.565,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.791 | Acc: 50.825,77.509,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.798 | Acc: 50.609,77.357,92.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 50.587,77.157,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 50.608,77.103,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.817 | Acc: 50.629,77.049,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.818 | Acc: 50.587,77.023,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.828 | Acc: 50.537,76.843,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 50.439,76.765,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.831 | Acc: 50.596,76.825,91.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.836 | Acc: 50.573,76.755,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.837 | Acc: 50.630,76.727,91.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 50.632,76.718,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.784 | Acc: 46.094,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.866 | Acc: 45.312,62.128,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.892 | Acc: 44.703,61.643,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.897 | Acc: 44.198,61.501,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 2.653 | Acc: 53.906,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.748 | Acc: 50.484,77.827,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 50.248,76.944,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.781 | Acc: 50.538,76.780,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 50.723,76.948,92.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.785 | Acc: 50.866,77.027,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.789 | Acc: 50.794,77.215,92.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 50.526,77.144,92.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.806 | Acc: 50.495,77.096,92.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 50.565,77.080,92.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.810 | Acc: 50.521,77.118,92.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 50.590,77.114,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 50.525,77.023,92.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.816 | Acc: 50.377,76.964,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.821 | Acc: 50.448,76.879,92.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.825 | Acc: 50.400,76.845,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.824 | Acc: 50.531,76.838,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.826 | Acc: 50.532,76.858,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.827 | Acc: 50.571,76.818,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.831 | Acc: 50.541,76.741,92.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 44.531,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.903 | Acc: 44.345,62.277,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.938 | Acc: 43.921,61.280,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.938 | Acc: 43.788,61.181,67.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 2.903 | Acc: 42.969,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.765 | Acc: 49.888,76.228,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.791 | Acc: 49.371,77.077,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.778 | Acc: 50.115,77.254,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 50.135,76.804,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.804 | Acc: 50.039,76.972,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.801 | Acc: 50.265,77.008,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 50.693,77.161,92.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.805 | Acc: 50.563,77.155,92.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.805 | Acc: 50.570,77.115,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 50.564,77.064,92.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.812 | Acc: 50.435,77.036,92.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 50.558,76.971,92.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.814 | Acc: 50.458,76.922,92.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.818 | Acc: 50.434,76.902,92.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.815 | Acc: 50.457,76.980,91.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.815 | Acc: 50.394,76.893,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 50.458,76.947,91.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.817 | Acc: 50.405,76.907,91.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.821 | Acc: 50.400,76.886,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.695 | Acc: 45.312,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.741 | Acc: 46.652,62.984,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.770 | Acc: 45.960,62.614,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.777 | Acc: 45.594,62.385,67.764,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 3.134 | Acc: 46.094,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.714 | Acc: 52.790,78.348,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.744 | Acc: 52.229,77.725,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.750 | Acc: 52.100,77.600,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.744 | Acc: 51.881,77.672,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.765 | Acc: 51.632,77.421,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.772 | Acc: 51.349,77.157,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.777 | Acc: 51.236,77.355,92.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.775 | Acc: 51.296,77.436,92.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.778 | Acc: 51.105,77.413,92.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.792 | Acc: 50.925,77.254,92.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.799 | Acc: 50.891,77.206,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.803 | Acc: 50.765,77.146,92.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.806 | Acc: 50.790,77.107,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.810 | Acc: 50.784,77.046,92.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.808 | Acc: 50.818,77.084,91.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.813 | Acc: 50.798,77.018,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.814 | Acc: 50.761,76.984,91.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.815 | Acc: 50.734,76.922,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.821 | Acc: 50.632,76.880,91.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.656 | Acc: 46.875,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.918 | Acc: 45.424,61.235,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.895 | Acc: 45.351,60.766,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.897 | Acc: 44.711,60.899,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.710 | Acc: 52.344,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.782 | Acc: 51.897,76.488,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.818 | Acc: 50.857,76.944,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.801 | Acc: 51.383,77.152,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 51.042,77.083,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.809 | Acc: 50.812,77.119,92.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.808 | Acc: 50.743,77.085,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.809 | Acc: 50.731,76.961,92.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.798 | Acc: 51.000,77.101,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.799 | Acc: 51.032,77.089,92.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 50.999,76.955,92.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.806 | Acc: 50.877,77.019,92.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.806 | Acc: 50.830,77.101,92.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.804 | Acc: 50.706,77.044,92.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 50.506,76.910,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.821 | Acc: 50.436,76.887,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.816 | Acc: 50.523,76.942,91.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.822 | Acc: 50.479,76.867,91.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.824 | Acc: 50.446,76.792,91.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.823 | Acc: 50.543,76.776,91.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.772 | Acc: 46.094,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.860 | Acc: 45.350,63.281,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.840 | Acc: 44.627,62.710,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.845 | Acc: 44.390,62.487,67.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 2.962 | Acc: 44.531,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.745 | Acc: 51.302,77.493,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.770 | Acc: 50.800,77.515,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.790 | Acc: 50.666,77.177,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.824 | Acc: 50.395,76.881,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.817 | Acc: 50.634,76.818,92.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.808 | Acc: 50.736,76.931,92.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.807 | Acc: 50.543,76.923,92.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.809 | Acc: 50.432,76.815,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.815 | Acc: 50.341,76.852,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.808 | Acc: 50.412,76.959,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.801 | Acc: 50.742,77.015,92.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.802 | Acc: 50.778,77.058,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.807 | Acc: 50.724,77.000,92.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.811 | Acc: 50.645,76.949,92.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.808 | Acc: 50.732,76.978,92.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.810 | Acc: 50.713,76.903,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.815 | Acc: 50.683,76.874,92.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.820 | Acc: 50.554,76.777,92.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 50.586,76.770,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.598 | Acc: 49.219,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.866 | Acc: 45.536,63.170,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.866 | Acc: 45.198,62.862,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.869 | Acc: 44.839,62.820,67.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 2.554 | Acc: 56.250,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.748 | Acc: 51.749,77.902,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.751 | Acc: 51.448,77.668,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.780 | Acc: 51.268,77.344,92.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.783 | Acc: 51.003,77.054,92.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.782 | Acc: 51.137,77.058,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.780 | Acc: 51.078,77.047,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 51.075,76.961,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.796 | Acc: 50.912,76.999,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.800 | Acc: 50.760,76.860,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.800 | Acc: 50.770,76.823,92.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.798 | Acc: 50.806,76.916,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 50.817,76.952,92.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.804 | Acc: 50.856,76.919,92.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.806 | Acc: 50.781,76.946,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.807 | Acc: 50.742,76.944,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.813 | Acc: 50.701,76.820,92.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.818 | Acc: 50.653,76.760,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.819 | Acc: 50.597,76.707,92.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.815 | Acc: 50.664,76.712,92.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.659 | Acc: 50.000,71.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.889 | Acc: 44.717,62.686,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.915 | Acc: 43.979,61.795,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.922 | Acc: 43.673,61.360,67.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 2.643 | Acc: 54.688,76.562,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.722 | Acc: 52.083,77.939,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.750 | Acc: 51.296,77.668,93.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.757 | Acc: 51.037,77.382,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.764 | Acc: 51.080,77.643,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.773 | Acc: 50.642,77.545,92.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.773 | Acc: 50.962,77.518,92.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 50.604,77.499,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.782 | Acc: 50.772,77.484,92.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.784 | Acc: 50.773,77.529,92.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 50.727,77.472,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.791 | Acc: 50.693,77.326,92.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.799 | Acc: 50.652,77.185,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.802 | Acc: 50.662,77.062,92.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.803 | Acc: 50.701,77.102,92.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 50.766,77.100,92.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.805 | Acc: 50.757,77.074,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.807 | Acc: 50.710,77.025,92.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.812 | Acc: 50.706,76.941,92.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.811 | Acc: 50.699,76.977,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.567 | Acc: 50.781,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.803 | Acc: 46.094,63.690,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.810 | Acc: 45.446,62.729,68.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.805 | Acc: 44.839,62.538,68.186,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.606 | Acc: 52.344,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.777 | Acc: 50.818,78.237,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.822 | Acc: 50.419,77.534,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.811 | Acc: 50.922,77.126,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.805 | Acc: 50.839,77.093,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.791 | Acc: 51.060,77.321,92.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.786 | Acc: 50.994,77.395,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.782 | Acc: 50.809,77.383,92.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.786 | Acc: 50.713,77.305,92.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 50.440,77.206,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.810 | Acc: 50.416,77.126,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 50.481,77.171,92.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.810 | Acc: 50.512,77.133,92.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 50.518,77.137,92.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.816 | Acc: 50.456,77.096,91.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 50.478,77.069,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.815 | Acc: 50.616,77.076,91.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 50.658,77.071,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.816 | Acc: 50.608,77.002,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.816 | Acc: 50.656,77.048,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.482 | Acc: 53.125,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.703 | Acc: 47.247,64.286,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.718 | Acc: 46.932,63.834,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.734 | Acc: 46.004,63.281,68.481,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.423 | Acc: 60.156,86.719,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.727 | Acc: 51.860,78.981,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.758 | Acc: 51.467,78.335,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.773 | Acc: 50.794,78.061,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.788 | Acc: 50.415,77.720,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.786 | Acc: 50.580,77.785,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.799 | Acc: 50.633,77.589,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.805 | Acc: 50.632,77.344,92.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.803 | Acc: 50.772,77.421,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.811 | Acc: 50.876,77.305,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.821 | Acc: 50.770,77.173,92.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.817 | Acc: 50.757,77.096,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 50.804,77.195,92.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 50.844,77.176,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.808 | Acc: 50.803,77.233,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.805 | Acc: 50.942,77.237,92.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.807 | Acc: 50.918,77.246,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.810 | Acc: 50.845,77.222,91.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.815 | Acc: 50.816,77.052,91.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.817 | Acc: 50.816,77.010,91.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.450 | Acc: 47.656,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.741 | Acc: 45.722,63.281,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.769 | Acc: 45.027,62.462,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.768 | Acc: 44.762,62.065,68.186,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.343 | Acc: 65.625,84.375,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.776 | Acc: 50.260,76.897,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.801 | Acc: 50.019,76.334,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.822 | Acc: 50.218,76.217,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 50.540,76.427,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.780 | Acc: 50.951,76.942,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.790 | Acc: 50.962,76.924,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.784 | Acc: 51.008,76.900,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.774 | Acc: 51.097,76.936,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 50.824,76.813,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.781 | Acc: 50.929,76.881,92.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 50.739,76.743,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.795 | Acc: 50.665,76.747,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.800 | Acc: 50.685,76.733,92.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.804 | Acc: 50.559,76.735,92.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.811 | Acc: 50.501,76.682,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 50.465,76.679,91.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.821 | Acc: 50.454,76.617,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.817 | Acc: 50.550,76.664,91.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.820 | Acc: 50.498,76.653,91.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.582 | Acc: 44.531,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.784 | Acc: 45.312,62.649,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.834 | Acc: 44.798,61.795,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.841 | Acc: 44.185,61.719,67.636,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 3.221 | Acc: 45.312,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.818 | Acc: 49.330,77.865,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.777 | Acc: 50.381,77.839,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.779 | Acc: 50.282,77.984,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.783 | Acc: 50.656,77.826,92.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.783 | Acc: 50.920,77.932,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.789 | Acc: 50.801,77.783,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 50.798,77.732,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.797 | Acc: 50.791,77.606,92.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 50.868,77.503,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 50.843,77.394,92.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.803 | Acc: 50.806,77.216,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.800 | Acc: 50.723,77.198,92.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.804 | Acc: 50.730,77.173,92.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.806 | Acc: 50.651,77.180,92.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.813 | Acc: 50.548,77.084,92.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.806 | Acc: 50.672,77.169,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 50.690,77.076,92.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.813 | Acc: 50.651,77.049,92.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.812 | Acc: 50.693,77.038,92.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.543 | Acc: 50.781,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.968 | Acc: 44.271,61.868,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.971 | Acc: 43.921,61.528,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.967 | Acc: 43.788,61.219,66.534,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.765 | Acc: 54.688,84.375,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 51.674,78.423,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.766 | Acc: 50.457,77.172,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.759 | Acc: 50.371,77.549,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.768 | Acc: 50.511,77.431,92.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.772 | Acc: 50.480,77.514,92.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.768 | Acc: 50.620,77.537,92.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.779 | Acc: 50.488,77.299,92.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.782 | Acc: 50.374,77.261,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.784 | Acc: 50.470,77.180,92.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.782 | Acc: 50.622,77.235,92.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.779 | Acc: 50.668,77.319,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.781 | Acc: 50.603,77.341,92.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.784 | Acc: 50.632,77.299,92.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.782 | Acc: 50.664,77.316,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.785 | Acc: 50.649,77.271,92.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.788 | Acc: 50.730,77.190,92.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.801 | Acc: 50.603,77.078,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.801 | Acc: 50.671,77.112,92.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.804 | Acc: 50.697,77.022,92.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.744 | Acc: 42.969,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.047 | Acc: 42.522,61.868,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.988 | Acc: 43.064,61.757,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.995 | Acc: 42.713,61.527,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.427 | Acc: 53.906,85.938,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.749 | Acc: 50.781,77.195,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.776 | Acc: 50.610,77.306,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.735 | Acc: 50.807,77.959,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.743 | Acc: 50.598,78.173,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.731 | Acc: 50.433,78.241,93.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.727 | Acc: 50.588,78.235,93.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.724 | Acc: 50.759,78.480,93.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.714 | Acc: 50.970,78.537,93.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.711 | Acc: 51.101,78.539,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.706 | Acc: 51.244,78.603,93.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.697 | Acc: 51.350,78.627,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.692 | Acc: 51.287,78.673,93.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.684 | Acc: 51.314,78.790,93.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.678 | Acc: 51.309,78.892,93.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.675 | Acc: 51.311,78.932,93.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.671 | Acc: 51.358,78.914,93.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.669 | Acc: 51.313,78.954,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.666 | Acc: 51.389,79.008,93.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.663 | Acc: 51.435,79.019,93.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.336 | Acc: 47.656,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 48.363,65.327,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 47.828,64.653,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.541 | Acc: 47.298,64.447,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.474 | Acc: 51.562,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.511 | Acc: 52.604,80.804,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.532 | Acc: 52.611,80.621,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.566 | Acc: 52.228,80.328,94.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.582 | Acc: 52.103,80.150,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.580 | Acc: 52.050,80.152,94.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.582 | Acc: 52.137,80.262,94.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.597 | Acc: 52.061,79.953,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.595 | Acc: 52.135,80.061,94.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.606 | Acc: 51.968,79.886,94.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.609 | Acc: 51.920,79.862,94.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.602 | Acc: 51.997,79.896,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.605 | Acc: 51.887,79.927,94.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.600 | Acc: 51.952,79.948,94.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.601 | Acc: 51.952,79.865,94.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.609 | Acc: 51.765,79.763,94.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.606 | Acc: 51.859,79.756,94.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.603 | Acc: 51.915,79.816,94.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.606 | Acc: 51.935,79.783,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.609 | Acc: 51.850,79.755,94.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 48.438,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.538 | Acc: 47.954,65.365,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 47.618,64.920,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.558 | Acc: 47.246,64.383,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.587 | Acc: 64.062,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.591 | Acc: 51.525,79.613,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.572 | Acc: 51.601,79.954,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.580 | Acc: 51.895,79.905,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.591 | Acc: 51.736,79.755,94.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.594 | Acc: 51.663,79.703,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.600 | Acc: 51.711,79.726,94.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.609 | Acc: 51.723,79.482,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.598 | Acc: 51.951,79.556,94.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.590 | Acc: 52.050,79.688,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.585 | Acc: 52.165,79.835,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.587 | Acc: 52.100,79.878,94.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.583 | Acc: 52.188,79.872,94.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.585 | Acc: 52.245,79.756,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.582 | Acc: 52.294,79.821,95.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.586 | Acc: 52.235,79.838,94.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.588 | Acc: 52.181,79.809,95.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.585 | Acc: 52.172,79.843,95.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.588 | Acc: 52.093,79.852,95.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.588 | Acc: 52.048,79.876,94.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.341 | Acc: 46.094,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 47.991,65.476,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.518 | Acc: 47.523,65.091,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.533 | Acc: 47.259,64.664,69.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.781 | Acc: 42.969,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.553 | Acc: 52.195,80.246,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.560 | Acc: 52.020,80.145,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.554 | Acc: 51.934,80.379,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.554 | Acc: 52.132,80.189,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.547 | Acc: 52.382,80.275,95.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.563 | Acc: 52.240,80.107,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.561 | Acc: 52.178,80.325,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.553 | Acc: 52.290,80.352,95.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.554 | Acc: 52.266,80.361,95.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.548 | Acc: 52.441,80.461,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.551 | Acc: 52.376,80.419,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.556 | Acc: 52.321,80.368,95.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.560 | Acc: 52.266,80.184,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.558 | Acc: 52.383,80.160,95.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.563 | Acc: 52.294,80.118,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.576 | Acc: 52.125,79.955,95.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.583 | Acc: 52.108,79.891,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.582 | Acc: 52.134,79.928,95.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.582 | Acc: 52.165,79.925,95.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.311 | Acc: 47.656,71.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 48.400,65.179,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.520 | Acc: 48.056,64.691,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 47.515,64.370,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 2.133 | Acc: 57.031,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.540 | Acc: 52.381,79.576,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.565 | Acc: 52.630,79.745,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.549 | Acc: 52.651,80.085,95.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.551 | Acc: 52.267,80.006,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.546 | Acc: 52.251,80.043,95.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.552 | Acc: 52.428,80.081,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.549 | Acc: 52.527,80.153,95.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.548 | Acc: 52.538,80.231,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.553 | Acc: 52.339,80.262,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.559 | Acc: 52.278,80.146,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.559 | Acc: 52.273,80.165,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.556 | Acc: 52.256,80.193,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.561 | Acc: 52.230,80.244,95.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.563 | Acc: 52.163,80.235,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.566 | Acc: 52.108,80.207,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.570 | Acc: 52.003,80.240,95.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.572 | Acc: 51.977,80.194,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.577 | Acc: 51.963,80.094,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.576 | Acc: 52.046,80.137,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.378 | Acc: 49.219,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.533 | Acc: 48.140,65.290,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 47.675,64.901,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 47.323,64.524,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.651 | Acc: 56.250,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.619 | Acc: 52.083,79.129,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.583 | Acc: 52.134,79.821,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.574 | Acc: 52.139,80.136,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.560 | Acc: 52.546,80.122,95.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.558 | Acc: 52.212,80.183,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.561 | Acc: 52.002,80.579,95.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.564 | Acc: 51.984,80.530,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.567 | Acc: 51.985,80.542,95.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.576 | Acc: 51.839,80.434,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.574 | Acc: 52.048,80.410,95.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.577 | Acc: 51.987,80.285,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.583 | Acc: 51.880,80.180,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.581 | Acc: 51.910,80.131,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.578 | Acc: 51.929,80.160,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.578 | Acc: 51.936,80.157,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.577 | Acc: 51.962,80.199,95.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.567 | Acc: 52.213,80.302,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.571 | Acc: 52.147,80.179,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.571 | Acc: 52.087,80.182,95.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.287 | Acc: 48.438,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 48.214,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.546 | Acc: 47.809,65.091,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 47.323,64.639,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.343 | Acc: 53.906,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.520 | Acc: 52.567,81.324,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.519 | Acc: 52.344,80.602,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.550 | Acc: 51.960,80.392,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.576 | Acc: 51.302,79.977,95.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.559 | Acc: 51.833,80.268,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.564 | Acc: 51.963,80.049,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.565 | Acc: 52.011,79.992,95.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.580 | Acc: 51.771,79.945,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.575 | Acc: 51.787,79.959,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.572 | Acc: 51.924,79.967,95.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.570 | Acc: 52.050,80.020,95.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.569 | Acc: 52.120,80.054,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.573 | Acc: 52.062,80.011,95.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.574 | Acc: 52.102,79.999,95.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.574 | Acc: 52.188,80.033,95.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.574 | Acc: 52.215,80.006,95.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.573 | Acc: 52.225,80.045,95.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.570 | Acc: 52.233,80.077,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.572 | Acc: 52.165,80.059,95.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.296 | Acc: 47.656,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.534 | Acc: 48.326,65.216,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.536 | Acc: 48.018,64.729,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 47.464,64.498,69.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.442 | Acc: 52.344,85.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 50.670,80.543,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.580 | Acc: 51.562,80.259,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.585 | Acc: 51.294,79.956,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.562 | Acc: 51.534,80.228,95.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.564 | Acc: 51.810,80.121,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.564 | Acc: 52.021,80.223,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.562 | Acc: 52.122,80.319,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.572 | Acc: 52.028,80.241,95.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.578 | Acc: 51.960,80.244,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.575 | Acc: 52.017,80.271,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.568 | Acc: 52.213,80.341,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.563 | Acc: 52.259,80.391,95.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.559 | Acc: 52.260,80.337,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.558 | Acc: 52.227,80.360,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.558 | Acc: 52.271,80.339,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.560 | Acc: 52.237,80.357,95.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.557 | Acc: 52.284,80.398,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.557 | Acc: 52.236,80.376,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.559 | Acc: 52.225,80.366,95.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.381 | Acc: 48.438,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.549 | Acc: 48.363,65.439,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 47.618,64.825,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 47.259,64.395,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.043 | Acc: 55.469,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.512 | Acc: 52.493,80.580,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.507 | Acc: 52.744,80.697,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.517 | Acc: 52.357,80.558,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.515 | Acc: 52.662,80.720,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.523 | Acc: 52.800,80.515,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.538 | Acc: 52.460,80.430,95.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.540 | Acc: 52.504,80.319,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.539 | Acc: 52.698,80.449,95.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.546 | Acc: 52.560,80.387,95.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.550 | Acc: 52.577,80.337,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.552 | Acc: 52.510,80.338,95.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.554 | Acc: 52.389,80.384,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.558 | Acc: 52.365,80.274,95.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.559 | Acc: 52.302,80.216,95.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.556 | Acc: 52.326,80.178,95.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.555 | Acc: 52.317,80.172,95.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.559 | Acc: 52.293,80.132,95.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.558 | Acc: 52.318,80.125,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.557 | Acc: 52.278,80.198,95.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.371 | Acc: 46.875,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.549 | Acc: 47.842,65.476,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.547 | Acc: 47.504,64.806,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.557 | Acc: 47.221,64.485,69.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.654 | Acc: 53.125,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.605 | Acc: 51.860,80.134,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.580 | Acc: 52.001,79.840,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.560 | Acc: 52.651,80.328,95.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.522 | Acc: 53.212,80.739,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.531 | Acc: 52.963,80.639,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.540 | Acc: 52.679,80.566,95.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.543 | Acc: 52.593,80.358,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.540 | Acc: 52.431,80.377,95.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.540 | Acc: 52.417,80.309,95.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.538 | Acc: 52.332,80.294,95.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.541 | Acc: 52.188,80.310,95.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.541 | Acc: 52.185,80.294,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.538 | Acc: 52.260,80.412,95.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.543 | Acc: 52.277,80.307,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.546 | Acc: 52.268,80.313,95.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.548 | Acc: 52.217,80.318,95.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.550 | Acc: 52.151,80.283,95.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.554 | Acc: 52.078,80.196,95.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.555 | Acc: 52.044,80.214,95.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.322 | Acc: 48.438,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 48.251,65.848,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 47.752,64.901,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 47.310,64.549,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.405 | Acc: 57.031,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.613 | Acc: 51.972,78.609,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 52.896,79.611,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.535 | Acc: 52.869,80.200,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.537 | Acc: 52.556,80.054,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.552 | Acc: 52.034,80.097,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.561 | Acc: 52.047,80.075,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.547 | Acc: 52.299,80.303,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.541 | Acc: 52.470,80.391,95.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.541 | Acc: 52.283,80.313,95.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.546 | Acc: 52.192,80.247,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.549 | Acc: 52.224,80.168,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.549 | Acc: 52.253,80.119,95.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.549 | Acc: 52.170,80.125,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.548 | Acc: 52.235,80.224,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.550 | Acc: 52.211,80.121,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.552 | Acc: 52.237,80.111,95.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.556 | Acc: 52.124,80.061,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.558 | Acc: 52.060,80.135,95.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.556 | Acc: 52.085,80.155,95.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.396 | Acc: 48.438,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 48.028,65.588,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.558 | Acc: 47.694,64.977,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 47.221,64.383,69.390,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.296 | Acc: 53.125,85.938,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 50.967,81.659,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.520 | Acc: 51.905,80.697,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 51.767,80.469,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.560 | Acc: 51.553,80.218,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.551 | Acc: 51.880,80.330,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.544 | Acc: 52.079,80.301,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.541 | Acc: 51.961,80.419,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.535 | Acc: 52.130,80.459,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.536 | Acc: 52.128,80.387,95.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.537 | Acc: 52.095,80.243,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.545 | Acc: 51.898,80.243,95.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.545 | Acc: 51.896,80.294,95.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.549 | Acc: 51.874,80.271,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.551 | Acc: 51.893,80.232,95.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.548 | Acc: 51.890,80.269,95.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.547 | Acc: 52.003,80.259,95.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.543 | Acc: 52.138,80.320,95.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.541 | Acc: 52.155,80.330,95.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.543 | Acc: 52.159,80.266,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.332 | Acc: 46.875,71.875,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 48.028,65.365,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 47.675,64.710,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 47.272,64.139,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.893 | Acc: 42.188,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.602 | Acc: 51.525,80.692,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.602 | Acc: 50.877,80.354,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.583 | Acc: 51.294,80.149,95.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.570 | Acc: 51.370,80.189,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.556 | Acc: 51.470,80.190,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.550 | Acc: 51.717,80.178,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.553 | Acc: 51.851,80.086,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.553 | Acc: 51.844,80.144,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.557 | Acc: 51.826,80.201,95.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.555 | Acc: 51.765,80.208,95.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.554 | Acc: 51.838,80.317,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.554 | Acc: 51.802,80.307,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.555 | Acc: 51.790,80.322,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.552 | Acc: 51.857,80.377,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.547 | Acc: 51.915,80.347,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.548 | Acc: 51.937,80.330,95.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.544 | Acc: 51.998,80.464,95.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.543 | Acc: 51.991,80.480,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.541 | Acc: 52.096,80.516,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.370 | Acc: 48.438,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 47.917,65.513,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 47.504,64.996,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 47.157,64.485,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.236 | Acc: 60.938,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.608 | Acc: 50.856,80.841,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.564 | Acc: 51.848,81.364,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.541 | Acc: 51.921,81.186,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.536 | Acc: 52.054,81.057,95.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.521 | Acc: 52.351,81.142,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 52.363,80.979,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.532 | Acc: 52.166,80.729,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.539 | Acc: 52.247,80.639,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.540 | Acc: 52.180,80.646,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.544 | Acc: 52.153,80.655,95.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.550 | Acc: 52.068,80.483,95.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.543 | Acc: 52.156,80.576,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.544 | Acc: 52.134,80.514,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.545 | Acc: 52.107,80.519,95.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.539 | Acc: 52.201,80.578,95.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.541 | Acc: 52.224,80.551,95.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.545 | Acc: 52.165,80.519,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.544 | Acc: 52.160,80.514,95.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.542 | Acc: 52.147,80.557,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.390 | Acc: 48.438,69.531,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 48.326,65.476,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.549 | Acc: 47.942,64.920,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.559 | Acc: 47.567,64.511,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.395 | Acc: 51.562,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.501 | Acc: 52.307,81.622,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.504 | Acc: 51.886,81.460,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.521 | Acc: 52.190,81.019,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.518 | Acc: 52.112,81.076,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.527 | Acc: 51.841,81.018,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.533 | Acc: 52.085,80.876,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.541 | Acc: 51.950,80.690,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.538 | Acc: 51.999,80.668,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.544 | Acc: 51.856,80.529,95.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.549 | Acc: 51.800,80.480,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.552 | Acc: 51.732,80.486,95.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.547 | Acc: 51.773,80.611,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.542 | Acc: 51.799,80.585,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.542 | Acc: 51.871,80.577,95.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.539 | Acc: 51.858,80.640,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.541 | Acc: 51.940,80.622,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.539 | Acc: 51.952,80.599,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.539 | Acc: 51.963,80.583,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.542 | Acc: 51.964,80.522,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.366 | Acc: 47.656,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 48.326,65.179,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 47.656,64.367,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 47.259,64.062,69.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.538 | Acc: 56.250,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.548 | Acc: 51.935,79.985,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.529 | Acc: 51.753,80.736,95.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.545 | Acc: 51.691,80.443,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 51.823,80.720,95.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.536 | Acc: 51.640,80.422,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.538 | Acc: 51.743,80.340,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.535 | Acc: 51.790,80.380,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.536 | Acc: 51.829,80.318,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.532 | Acc: 51.895,80.352,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.534 | Acc: 51.971,80.333,95.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 52.075,80.313,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.534 | Acc: 52.156,80.401,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.536 | Acc: 52.107,80.427,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.536 | Acc: 52.155,80.472,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.537 | Acc: 52.232,80.438,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.536 | Acc: 52.215,80.410,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.538 | Acc: 52.151,80.373,95.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.537 | Acc: 52.229,80.365,95.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.537 | Acc: 52.217,80.381,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.387 | Acc: 46.094,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.545 | Acc: 48.475,65.662,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 47.923,64.787,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 47.503,64.421,69.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.346 | Acc: 54.688,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.507 | Acc: 53.423,81.101,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.526 | Acc: 52.858,80.907,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.537 | Acc: 52.433,80.456,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.532 | Acc: 52.440,81.009,95.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.538 | Acc: 52.444,80.809,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.541 | Acc: 52.253,80.901,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.542 | Acc: 52.250,80.740,95.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.544 | Acc: 52.169,80.707,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.544 | Acc: 52.249,80.689,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.544 | Acc: 52.181,80.616,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.539 | Acc: 52.231,80.638,95.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.540 | Acc: 52.204,80.634,95.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.539 | Acc: 52.167,80.609,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.537 | Acc: 52.196,80.563,95.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.535 | Acc: 52.297,80.599,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.534 | Acc: 52.280,80.581,95.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.536 | Acc: 52.371,80.503,95.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.538 | Acc: 52.346,80.553,95.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.536 | Acc: 52.313,80.625,95.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.293 | Acc: 47.656,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 47.619,65.104,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 47.104,64.425,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 46.709,64.062,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 2.434 | Acc: 47.656,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.534 | Acc: 51.600,80.729,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.515 | Acc: 51.505,80.736,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 52.472,80.981,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.477 | Acc: 52.778,80.739,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.496 | Acc: 52.390,80.716,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 52.357,80.708,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.504 | Acc: 52.227,80.613,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.507 | Acc: 51.994,80.716,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.513 | Acc: 52.007,80.620,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.523 | Acc: 51.901,80.465,95.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 51.916,80.433,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 51.990,80.501,95.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.529 | Acc: 52.053,80.559,95.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 52.119,80.541,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.528 | Acc: 52.172,80.500,95.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.532 | Acc: 52.093,80.393,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 52.057,80.363,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.536 | Acc: 52.060,80.352,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.539 | Acc: 52.057,80.350,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.387 | Acc: 50.000,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 47.954,64.993,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 47.523,64.882,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 47.144,64.485,69.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.369 | Acc: 56.250,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.604 | Acc: 52.418,80.543,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.605 | Acc: 51.753,80.507,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.581 | Acc: 51.985,80.533,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.554 | Acc: 52.035,80.691,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.554 | Acc: 51.926,80.523,95.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.559 | Acc: 51.937,80.449,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.568 | Acc: 51.734,80.225,95.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.564 | Acc: 51.626,80.280,95.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.558 | Acc: 51.739,80.283,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.561 | Acc: 51.753,80.321,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.558 | Acc: 51.806,80.257,95.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.551 | Acc: 51.896,80.333,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.548 | Acc: 51.922,80.382,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.543 | Acc: 51.968,80.438,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.538 | Acc: 52.056,80.479,95.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.537 | Acc: 51.996,80.539,95.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.532 | Acc: 52.177,80.602,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.535 | Acc: 52.119,80.573,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.539 | Acc: 52.057,80.553,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.407 | Acc: 48.438,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 48.140,65.551,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 47.828,64.825,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.579 | Acc: 47.387,64.460,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.698 | Acc: 49.219,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.544 | Acc: 52.604,81.027,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.559 | Acc: 51.372,80.774,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.553 | Acc: 51.409,81.160,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.556 | Acc: 51.591,80.816,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.561 | Acc: 51.369,80.732,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.553 | Acc: 51.608,80.579,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.548 | Acc: 51.729,80.485,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.542 | Acc: 51.766,80.483,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.537 | Acc: 51.865,80.503,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 51.842,80.519,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.539 | Acc: 51.859,80.486,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.540 | Acc: 51.883,80.436,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.543 | Acc: 51.889,80.421,95.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.541 | Acc: 51.949,80.394,95.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.541 | Acc: 51.962,80.432,95.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.540 | Acc: 51.935,80.459,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.540 | Acc: 51.970,80.478,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.537 | Acc: 52.010,80.540,95.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.537 | Acc: 52.038,80.563,95.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.371 | Acc: 48.438,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 48.363,65.179,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 47.675,64.672,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 47.182,64.357,69.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.461 | Acc: 53.125,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.494 | Acc: 52.381,80.804,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.477 | Acc: 53.296,80.888,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.504 | Acc: 53.125,80.443,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.509 | Acc: 52.527,80.440,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.520 | Acc: 52.243,80.461,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.518 | Acc: 52.234,80.604,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.512 | Acc: 52.394,80.801,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.533 | Acc: 52.256,80.668,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.530 | Acc: 52.266,80.637,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.532 | Acc: 52.212,80.648,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.527 | Acc: 52.153,80.744,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 52.114,80.754,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.524 | Acc: 52.251,80.867,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.525 | Acc: 52.327,80.902,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.525 | Acc: 52.414,80.897,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.529 | Acc: 52.373,80.807,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.532 | Acc: 52.314,80.748,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.528 | Acc: 52.348,80.860,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.526 | Acc: 52.370,80.883,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.363 | Acc: 49.219,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 48.400,65.104,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 47.656,64.520,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.590 | Acc: 47.272,64.191,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.189 | Acc: 57.812,88.281,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.493 | Acc: 52.679,81.771,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.516 | Acc: 51.677,80.945,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.514 | Acc: 51.601,80.738,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.517 | Acc: 51.977,80.662,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 51.756,80.639,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.531 | Acc: 51.821,80.643,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.545 | Acc: 51.884,80.258,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.528 | Acc: 52.116,80.352,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 52.111,80.391,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.528 | Acc: 52.099,80.344,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 52.114,80.398,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 52.224,80.462,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.529 | Acc: 52.221,80.409,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.528 | Acc: 52.285,80.419,96.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.526 | Acc: 52.352,80.435,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.527 | Acc: 52.329,80.474,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.530 | Acc: 52.197,80.453,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.531 | Acc: 52.212,80.404,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.531 | Acc: 52.143,80.436,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.385 | Acc: 49.219,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 48.438,65.402,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.566 | Acc: 47.504,64.958,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 47.144,64.600,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 2.533 | Acc: 53.906,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.502 | Acc: 51.749,81.287,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.507 | Acc: 52.630,81.650,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.510 | Acc: 52.408,81.621,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 52.450,81.327,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.513 | Acc: 52.537,81.134,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.518 | Acc: 52.602,80.908,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 52.588,80.801,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.522 | Acc: 52.514,80.736,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.525 | Acc: 52.508,80.715,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.522 | Acc: 52.511,80.760,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.526 | Acc: 52.418,80.713,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.524 | Acc: 52.409,80.735,96.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.527 | Acc: 52.302,80.717,96.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.528 | Acc: 52.324,80.758,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 52.414,80.785,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.525 | Acc: 52.451,80.824,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.523 | Acc: 52.474,80.902,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.524 | Acc: 52.419,80.912,96.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.525 | Acc: 52.436,80.893,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.382 | Acc: 49.219,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 47.954,65.327,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.576 | Acc: 47.637,64.958,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.587 | Acc: 47.298,64.524,69.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.769 | Acc: 45.312,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.556 | Acc: 53.199,80.320,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.534 | Acc: 52.896,80.755,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.534 | Acc: 52.677,80.494,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.537 | Acc: 52.874,80.806,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.523 | Acc: 52.908,80.848,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.513 | Acc: 52.931,81.056,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.513 | Acc: 52.898,81.145,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.516 | Acc: 52.936,81.061,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.514 | Acc: 52.857,80.922,95.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 52.639,80.900,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 52.556,80.812,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 52.636,80.777,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.524 | Acc: 52.613,80.756,95.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.522 | Acc: 52.549,80.713,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 52.525,80.733,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.523 | Acc: 52.485,80.688,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.522 | Acc: 52.456,80.661,95.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.523 | Acc: 52.463,80.700,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.527 | Acc: 52.377,80.684,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.425 | Acc: 49.219,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 48.326,65.253,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 47.752,64.615,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.588 | Acc: 47.336,64.485,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 2.241 | Acc: 52.344,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.514 | Acc: 51.972,81.138,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.488 | Acc: 52.591,81.898,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.491 | Acc: 52.408,81.557,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 52.469,81.433,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 52.088,81.180,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.497 | Acc: 52.144,80.953,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.504 | Acc: 52.056,80.901,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 52.145,80.896,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.497 | Acc: 52.188,80.939,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 52.266,80.974,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.506 | Acc: 52.202,80.861,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 52.020,80.773,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.510 | Acc: 52.029,80.852,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.514 | Acc: 51.974,80.788,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 51.983,80.710,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 51.908,80.595,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 52.053,80.615,96.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.518 | Acc: 52.138,80.612,96.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.516 | Acc: 52.130,80.655,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.474 | Acc: 49.219,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 48.177,65.216,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 47.599,64.863,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.588 | Acc: 47.157,64.280,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.579 | Acc: 43.750,82.031,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.435 | Acc: 52.827,82.850,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.491 | Acc: 52.992,81.212,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.512 | Acc: 52.651,80.622,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.499 | Acc: 52.932,80.710,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 53.094,80.856,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.488 | Acc: 53.228,80.888,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.498 | Acc: 53.092,80.906,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.500 | Acc: 52.892,80.935,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 52.711,80.969,95.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.508 | Acc: 52.620,80.854,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.501 | Acc: 52.810,80.911,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.507 | Acc: 52.538,80.825,95.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.510 | Acc: 52.428,80.885,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.509 | Acc: 52.444,80.908,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.512 | Acc: 52.310,80.843,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.516 | Acc: 52.293,80.827,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.519 | Acc: 52.280,80.789,95.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.517 | Acc: 52.290,80.791,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.517 | Acc: 52.303,80.741,95.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.405 | Acc: 49.219,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 48.289,65.067,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 47.923,64.501,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.584 | Acc: 47.567,64.062,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.317 | Acc: 51.562,88.281,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.493 | Acc: 52.679,81.324,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.531 | Acc: 52.096,80.335,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.515 | Acc: 52.254,80.776,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.512 | Acc: 51.987,80.951,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.507 | Acc: 52.088,80.979,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.503 | Acc: 52.208,81.211,96.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 52.238,81.150,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.509 | Acc: 52.150,80.998,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.514 | Acc: 52.020,80.918,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 51.971,80.795,96.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.520 | Acc: 52.185,80.918,96.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 52.162,80.942,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.523 | Acc: 52.128,80.861,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 52.230,80.858,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.528 | Acc: 52.074,80.767,96.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 52.193,80.807,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 52.115,80.808,96.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.525 | Acc: 52.095,80.780,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 52.128,80.807,96.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.388 | Acc: 50.781,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 48.103,65.327,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.576 | Acc: 47.866,64.977,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 47.374,64.575,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.232 | Acc: 55.469,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.461 | Acc: 52.939,81.957,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.455 | Acc: 53.125,81.974,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.486 | Acc: 52.587,81.929,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.487 | Acc: 52.392,81.655,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.496 | Acc: 52.282,81.412,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 52.014,81.334,96.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.500 | Acc: 52.056,81.316,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.504 | Acc: 52.193,81.201,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.510 | Acc: 52.020,81.215,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.509 | Acc: 52.107,81.192,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.503 | Acc: 52.209,81.254,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.506 | Acc: 52.237,81.107,96.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.514 | Acc: 52.191,80.951,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 52.227,80.939,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 52.318,80.881,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.514 | Acc: 52.383,80.863,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.516 | Acc: 52.374,80.886,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.515 | Acc: 52.359,80.869,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.515 | Acc: 52.356,80.887,96.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 46.875,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 48.140,65.067,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 47.618,64.615,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.592 | Acc: 47.182,64.216,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.686 | Acc: 46.094,78.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.571 | Acc: 50.707,79.836,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.571 | Acc: 51.010,79.897,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.550 | Acc: 51.486,79.867,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.544 | Acc: 51.505,80.150,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 51.911,80.515,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.531 | Acc: 51.911,80.372,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.525 | Acc: 51.978,80.524,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.518 | Acc: 52.169,80.600,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.518 | Acc: 52.024,80.611,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.509 | Acc: 52.336,80.791,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 52.383,80.801,96.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 52.140,80.761,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 52.101,80.849,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.522 | Acc: 52.057,80.830,96.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.521 | Acc: 52.134,80.850,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 52.154,80.814,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 52.096,80.762,96.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.520 | Acc: 52.104,80.800,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 52.122,80.776,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 50.000,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 48.475,64.918,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.574 | Acc: 47.904,64.405,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 47.387,64.088,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.919 | Acc: 46.875,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.526 | Acc: 50.818,81.101,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.535 | Acc: 51.353,80.202,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.519 | Acc: 51.895,80.533,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.523 | Acc: 52.025,80.449,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 52.143,80.794,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 52.279,80.992,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.521 | Acc: 52.056,80.857,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.507 | Acc: 52.329,80.935,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.508 | Acc: 52.158,80.931,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.504 | Acc: 52.266,80.881,96.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.503 | Acc: 52.287,80.935,96.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.502 | Acc: 52.253,81.023,96.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.502 | Acc: 52.284,81.023,96.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.507 | Acc: 52.288,80.947,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.511 | Acc: 52.214,80.881,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.515 | Acc: 52.166,80.822,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.516 | Acc: 52.147,80.844,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.516 | Acc: 52.229,80.880,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.519 | Acc: 52.213,80.836,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.436 | Acc: 50.000,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.577 | Acc: 48.140,64.918,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 47.752,64.596,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 47.221,64.267,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.501 | Acc: 53.125,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.502 | Acc: 52.865,81.324,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.470 | Acc: 52.992,81.479,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.497 | Acc: 52.369,80.686,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 52.662,80.498,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.500 | Acc: 52.723,80.562,95.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.519 | Acc: 52.286,80.456,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.515 | Acc: 52.366,80.624,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.520 | Acc: 52.256,80.590,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.525 | Acc: 52.175,80.542,95.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.532 | Acc: 52.188,80.512,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 52.178,80.561,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 52.188,80.592,95.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.528 | Acc: 52.233,80.553,95.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.524 | Acc: 52.383,80.574,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.523 | Acc: 52.396,80.619,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 52.259,80.639,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 52.275,80.558,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.522 | Acc: 52.264,80.588,95.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 52.262,80.567,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.431 | Acc: 49.219,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 48.289,64.881,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.614 | Acc: 47.694,64.463,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 47.272,64.011,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.270 | Acc: 57.812,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.468 | Acc: 52.827,81.399,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 52.287,80.755,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 52.203,80.776,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.505 | Acc: 52.247,80.855,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.492 | Acc: 52.630,81.049,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.492 | Acc: 52.505,80.914,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 52.610,80.912,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.488 | Acc: 52.611,80.838,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.489 | Acc: 52.642,80.784,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.500 | Acc: 52.519,80.636,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.502 | Acc: 52.443,80.706,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.499 | Acc: 52.503,80.855,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 52.410,80.873,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.500 | Acc: 52.408,80.822,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.508 | Acc: 52.344,80.702,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 52.295,80.705,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.513 | Acc: 52.234,80.691,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.520 | Acc: 52.177,80.616,96.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 52.210,80.635,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.438 | Acc: 47.656,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.593 | Acc: 48.103,65.141,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 47.523,64.691,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 47.208,64.357,68.865,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.506 | Acc: 52.344,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.530 | Acc: 52.009,81.138,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.477 | Acc: 53.392,81.784,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.491 | Acc: 52.754,81.506,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.493 | Acc: 52.508,81.375,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.501 | Acc: 52.444,81.327,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.501 | Acc: 52.305,81.379,96.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.490 | Acc: 52.676,81.350,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 52.654,81.332,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.492 | Acc: 52.542,81.285,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.488 | Acc: 52.503,81.223,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.497 | Acc: 52.513,81.126,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.506 | Acc: 52.460,81.010,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.503 | Acc: 52.502,81.026,96.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.504 | Acc: 52.491,81.030,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.506 | Acc: 52.471,80.933,96.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 52.385,80.846,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.508 | Acc: 52.458,80.925,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 52.465,80.979,96.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.509 | Acc: 52.340,80.908,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.433 | Acc: 46.875,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 48.177,65.104,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 47.618,64.748,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 47.310,64.472,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.298 | Acc: 57.812,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.519 | Acc: 52.307,79.836,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.513 | Acc: 52.649,80.335,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.514 | Acc: 52.536,80.315,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.505 | Acc: 52.633,80.421,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.510 | Acc: 52.328,80.446,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 52.299,80.695,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.510 | Acc: 52.200,80.646,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.522 | Acc: 51.917,80.406,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.522 | Acc: 52.050,80.361,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.518 | Acc: 52.056,80.465,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.509 | Acc: 52.259,80.564,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 52.289,80.514,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.512 | Acc: 52.266,80.499,96.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.511 | Acc: 52.205,80.588,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 52.256,80.645,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.511 | Acc: 52.259,80.676,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.509 | Acc: 52.266,80.709,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 52.290,80.720,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.510 | Acc: 52.254,80.768,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.437 | Acc: 47.656,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 48.400,64.732,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 47.828,64.253,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 47.374,64.165,69.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.619 | Acc: 48.438,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.550 | Acc: 52.269,80.357,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.556 | Acc: 52.725,81.079,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.530 | Acc: 52.536,80.917,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 52.614,80.797,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.510 | Acc: 52.622,80.639,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 52.505,80.772,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.516 | Acc: 52.183,80.652,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.513 | Acc: 52.198,80.726,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.513 | Acc: 52.279,80.736,96.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 52.336,80.741,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.519 | Acc: 52.206,80.748,96.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 52.162,80.634,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.514 | Acc: 52.362,80.750,96.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.513 | Acc: 52.424,80.788,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.514 | Acc: 52.326,80.798,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.514 | Acc: 52.356,80.790,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.509 | Acc: 52.417,80.824,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 52.372,80.832,96.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.515 | Acc: 52.311,80.799,96.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.401 | Acc: 48.438,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.581 | Acc: 48.326,65.365,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 47.752,64.825,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 47.336,64.383,68.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.271 | Acc: 58.594,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.458 | Acc: 52.716,81.250,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.468 | Acc: 52.744,81.002,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.458 | Acc: 53.445,81.186,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.468 | Acc: 53.086,81.375,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.472 | Acc: 52.978,81.312,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.490 | Acc: 52.673,81.134,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.498 | Acc: 52.355,81.123,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.508 | Acc: 52.179,81.100,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.508 | Acc: 52.093,81.125,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 52.002,81.095,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 52.181,81.066,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.515 | Acc: 52.269,80.916,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.516 | Acc: 52.263,80.810,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 52.194,80.775,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.521 | Acc: 52.118,80.785,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.519 | Acc: 52.139,80.800,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.519 | Acc: 52.193,80.748,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 52.028,80.724,95.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.517 | Acc: 52.094,80.782,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.420 | Acc: 47.656,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 48.214,65.030,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 47.523,64.386,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.597 | Acc: 47.003,64.075,68.904,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.521 | Acc: 58.594,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.577 | Acc: 51.600,80.097,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.518 | Acc: 52.325,81.117,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.528 | Acc: 52.062,80.776,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.539 | Acc: 51.910,80.652,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.555 | Acc: 51.996,80.407,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.546 | Acc: 51.924,80.430,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.537 | Acc: 52.011,80.447,96.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 52.053,80.668,96.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 52.132,80.633,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.526 | Acc: 52.134,80.628,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.523 | Acc: 52.103,80.653,96.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.518 | Acc: 52.240,80.744,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 52.176,80.804,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.515 | Acc: 52.221,80.830,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.514 | Acc: 52.310,80.874,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.511 | Acc: 52.383,80.865,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.508 | Acc: 52.449,80.904,96.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.510 | Acc: 52.422,80.988,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.514 | Acc: 52.315,80.949,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.366 | Acc: 48.438,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 47.693,65.327,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 47.466,64.710,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 47.106,64.280,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.623 | Acc: 53.125,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.537 | Acc: 52.827,80.580,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.520 | Acc: 52.420,80.583,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.517 | Acc: 52.152,80.840,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 52.305,80.768,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.511 | Acc: 52.305,80.778,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.508 | Acc: 52.389,80.940,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 52.333,80.890,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.517 | Acc: 52.319,80.925,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.510 | Acc: 52.456,81.056,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.506 | Acc: 52.468,81.067,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.504 | Acc: 52.658,81.098,96.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.501 | Acc: 52.597,81.120,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.499 | Acc: 52.613,81.124,96.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.498 | Acc: 52.547,81.128,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.493 | Acc: 52.583,81.141,96.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.493 | Acc: 52.599,81.165,96.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 52.536,81.129,96.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.499 | Acc: 52.461,81.148,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 52.448,81.119,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.407 | Acc: 48.438,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 48.103,65.067,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 47.694,64.291,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 47.272,64.062,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.413 | Acc: 54.688,77.344,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.466 | Acc: 51.674,81.734,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.479 | Acc: 52.268,80.869,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 52.203,80.494,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.467 | Acc: 52.556,80.903,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.473 | Acc: 52.645,81.165,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.474 | Acc: 52.525,81.282,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.468 | Acc: 52.781,81.189,96.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.482 | Acc: 52.625,80.988,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.488 | Acc: 52.400,81.021,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.492 | Acc: 52.324,81.013,96.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.481 | Acc: 52.499,81.102,96.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 52.509,81.166,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 52.392,81.085,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.479 | Acc: 52.383,81.192,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.484 | Acc: 52.328,81.157,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.483 | Acc: 52.388,81.213,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.482 | Acc: 52.431,81.232,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.480 | Acc: 52.523,81.183,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.481 | Acc: 52.522,81.225,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.407 | Acc: 48.438,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.569 | Acc: 48.251,65.476,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.590 | Acc: 47.752,64.710,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 47.259,64.370,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.559 | Acc: 54.688,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.545 | Acc: 51.935,80.766,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.520 | Acc: 52.134,81.364,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.494 | Acc: 52.690,81.596,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.513 | Acc: 52.151,81.404,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 52.073,81.002,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.523 | Acc: 52.189,80.966,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.512 | Acc: 52.427,80.906,96.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.506 | Acc: 52.601,80.910,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.497 | Acc: 52.629,80.935,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 52.651,80.955,96.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.505 | Acc: 52.556,80.882,96.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.504 | Acc: 52.457,80.913,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.502 | Acc: 52.416,81.014,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.500 | Acc: 52.383,81.008,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 52.448,81.079,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.502 | Acc: 52.397,81.002,96.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 52.449,81.067,96.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.494 | Acc: 52.502,81.170,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 52.409,81.104,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.390 | Acc: 48.438,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.596 | Acc: 47.731,64.993,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 47.561,64.691,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.616 | Acc: 47.170,64.434,68.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.144 | Acc: 61.719,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.422 | Acc: 52.902,81.882,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.468 | Acc: 52.839,80.907,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.517 | Acc: 52.459,80.277,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 52.421,80.700,96.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.481 | Acc: 52.468,80.840,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.476 | Acc: 52.576,80.882,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.479 | Acc: 52.565,80.906,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.478 | Acc: 52.625,80.969,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.476 | Acc: 52.473,81.077,96.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.478 | Acc: 52.425,81.203,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.480 | Acc: 52.277,81.080,96.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 52.337,81.101,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.483 | Acc: 52.263,81.076,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.488 | Acc: 52.246,81.142,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.486 | Acc: 52.318,81.206,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 52.298,81.223,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 52.305,81.241,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.300,81.293,96.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 52.393,81.271,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.416 | Acc: 47.656,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 47.768,64.844,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 47.504,64.463,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 47.106,64.216,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.455 | Acc: 51.562,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.405 | Acc: 52.790,81.436,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.452 | Acc: 52.115,81.593,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.491 | Acc: 51.691,81.199,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.487 | Acc: 51.890,81.125,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 52.034,81.242,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.481 | Acc: 52.221,81.263,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.474 | Acc: 52.615,81.461,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.474 | Acc: 52.601,81.415,96.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.476 | Acc: 52.650,81.423,96.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.478 | Acc: 52.581,81.398,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 52.545,81.434,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 52.493,81.373,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 52.544,81.262,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.480 | Acc: 52.552,81.350,96.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.486 | Acc: 52.432,81.299,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 52.492,81.313,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 52.536,81.367,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.590,81.347,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.485 | Acc: 52.608,81.355,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.371 | Acc: 48.438,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.577 | Acc: 48.177,64.993,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 47.790,64.672,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 47.310,64.319,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.589 | Acc: 47.656,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.428 | Acc: 52.530,82.143,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.447 | Acc: 52.229,81.726,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.442 | Acc: 52.805,81.737,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.467 | Acc: 52.353,81.549,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.459 | Acc: 52.731,81.567,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.467 | Acc: 52.466,81.224,96.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.479 | Acc: 52.432,81.167,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.485 | Acc: 52.208,81.124,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.490 | Acc: 52.111,80.974,96.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 52.079,80.912,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 52.262,80.865,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.498 | Acc: 52.295,80.880,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 52.233,80.861,96.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.496 | Acc: 52.249,80.944,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 52.243,81.022,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.495 | Acc: 52.312,81.119,96.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.497 | Acc: 52.286,81.147,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.419,81.159,96.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 52.516,81.248,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.410 | Acc: 49.219,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 48.028,64.955,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 47.542,64.367,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 47.285,64.139,68.904,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.299 | Acc: 59.375,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.424 | Acc: 54.315,81.027,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 52.973,80.335,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.497 | Acc: 52.664,80.558,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 52.874,80.710,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 52.638,80.902,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.496 | Acc: 52.570,80.940,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 52.599,81.023,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.496 | Acc: 52.514,81.100,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.495 | Acc: 52.551,81.108,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 52.554,81.087,96.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 52.559,81.119,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.499 | Acc: 52.587,81.055,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.504 | Acc: 52.619,81.043,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.502 | Acc: 52.583,81.055,96.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.507 | Acc: 52.383,80.949,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.503 | Acc: 52.419,80.999,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.503 | Acc: 52.374,81.051,96.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 52.417,80.990,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.501 | Acc: 52.430,81.057,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.385 | Acc: 48.438,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.585 | Acc: 48.214,64.732,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 47.732,64.291,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.613 | Acc: 47.323,64.050,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.714 | Acc: 53.906,83.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.489 | Acc: 53.571,81.324,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.434 | Acc: 54.135,81.517,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.452 | Acc: 53.817,81.352,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.465 | Acc: 53.492,81.318,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.474 | Acc: 53.210,81.211,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.475 | Acc: 53.060,81.315,96.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.476 | Acc: 52.804,81.294,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.496 | Acc: 52.465,81.032,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.500 | Acc: 52.296,80.879,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.500 | Acc: 52.375,80.861,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.495 | Acc: 52.393,81.027,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.493 | Acc: 52.519,81.127,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.493 | Acc: 52.529,81.055,96.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 52.561,81.133,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 52.733,81.125,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 52.629,81.094,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.485 | Acc: 52.648,81.126,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.486 | Acc: 52.638,81.146,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.539,81.133,96.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.419 | Acc: 48.438,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.593 | Acc: 48.326,64.658,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 47.942,64.329,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 47.349,64.203,69.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.461 | Acc: 49.219,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.460 | Acc: 53.051,81.027,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.474 | Acc: 52.954,81.002,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 52.305,80.943,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.468 | Acc: 52.614,80.864,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.482 | Acc: 52.413,80.794,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.483 | Acc: 52.202,80.882,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 52.366,80.762,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.478 | Acc: 52.528,80.842,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.483 | Acc: 52.301,80.818,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.487 | Acc: 52.103,80.850,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.482 | Acc: 52.132,80.981,96.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 52.000,80.965,96.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 51.970,80.963,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 51.982,80.908,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 52.082,81.037,96.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 52.139,81.029,96.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 52.163,81.005,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.486 | Acc: 52.316,81.079,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.485 | Acc: 52.317,81.076,96.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 46.094,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.582 | Acc: 48.140,65.179,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 47.713,64.634,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 47.272,64.267,68.724,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.736 | Acc: 46.875,74.219,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.479 | Acc: 52.046,81.808,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.462 | Acc: 52.954,81.879,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.475 | Acc: 52.510,81.583,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.493 | Acc: 52.199,81.501,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.490 | Acc: 52.143,81.559,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.486 | Acc: 52.189,81.463,96.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 52.155,81.588,96.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.482 | Acc: 52.256,81.507,96.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.495 | Acc: 52.150,81.142,96.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.490 | Acc: 52.247,81.133,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 52.315,81.211,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 52.321,81.302,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.485 | Acc: 52.389,81.358,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.480 | Acc: 52.544,81.375,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.482 | Acc: 52.585,81.388,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 52.446,81.323,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.487 | Acc: 52.495,81.280,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 52.515,81.287,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.486 | Acc: 52.551,81.326,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.419 | Acc: 48.438,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.576 | Acc: 48.065,65.290,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 47.599,64.463,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 47.195,64.216,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.413 | Acc: 57.031,76.562,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.423 | Acc: 54.762,81.436,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.428 | Acc: 53.411,81.803,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.429 | Acc: 53.304,81.826,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.459 | Acc: 52.980,81.607,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.470 | Acc: 52.947,81.343,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.480 | Acc: 52.673,81.340,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 52.743,81.272,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.484 | Acc: 52.596,81.284,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.482 | Acc: 52.680,81.328,96.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.483 | Acc: 52.639,81.332,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.480 | Acc: 52.630,81.303,96.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.485 | Acc: 52.522,81.137,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 52.490,81.124,96.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 52.427,81.094,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.489 | Acc: 52.468,81.094,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 52.541,81.050,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 52.520,81.106,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 52.476,81.153,96.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 52.467,81.184,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.398 | Acc: 48.438,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.582 | Acc: 48.028,65.104,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 47.732,64.653,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 47.362,64.472,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.200 | Acc: 57.812,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.504 | Acc: 52.716,79.762,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.473 | Acc: 53.011,80.621,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.458 | Acc: 52.971,81.301,96.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.464 | Acc: 52.479,81.462,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.472 | Acc: 52.336,81.258,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.475 | Acc: 52.428,81.302,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.470 | Acc: 52.582,81.300,96.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.478 | Acc: 52.363,81.216,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.581,81.349,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.479 | Acc: 52.371,81.254,96.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.481 | Acc: 52.376,81.155,96.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.478 | Acc: 52.447,81.289,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.480 | Acc: 52.419,81.241,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.484 | Acc: 52.360,81.269,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.487 | Acc: 52.346,81.258,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 52.402,81.260,96.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 52.383,81.232,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.482 | Acc: 52.439,81.295,96.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.481 | Acc: 52.506,81.279,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.391 | Acc: 47.656,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 48.065,64.769,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 47.885,64.386,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.592 | Acc: 47.439,64.319,69.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.131 | Acc: 57.812,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.457 | Acc: 52.195,82.068,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.445 | Acc: 52.515,82.393,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.440 | Acc: 52.177,82.159,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.462 | Acc: 51.958,81.790,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.488 | Acc: 51.818,81.598,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.492 | Acc: 52.027,81.386,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.493 | Acc: 51.934,81.244,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.494 | Acc: 51.980,81.168,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.499 | Acc: 51.903,81.125,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.497 | Acc: 51.947,81.106,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.497 | Acc: 51.980,81.084,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.498 | Acc: 51.932,80.994,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.499 | Acc: 51.937,80.969,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.500 | Acc: 51.938,81.005,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.496 | Acc: 52.019,81.009,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 52.052,81.038,96.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.491 | Acc: 52.119,81.135,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.490 | Acc: 52.192,81.111,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 52.204,81.104,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.373 | Acc: 48.438,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.576 | Acc: 48.214,65.513,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 47.732,64.729,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 47.310,64.460,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.397 | Acc: 52.344,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.453 | Acc: 53.348,82.068,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.476 | Acc: 52.915,81.764,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.497 | Acc: 52.779,81.327,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 52.633,81.154,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.484 | Acc: 52.831,81.235,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.481 | Acc: 52.847,81.463,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 52.471,81.350,96.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.491 | Acc: 52.451,81.269,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.483 | Acc: 52.724,81.354,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.482 | Acc: 52.771,81.324,96.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.481 | Acc: 52.761,81.307,96.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 52.532,81.140,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 52.583,81.115,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 52.513,81.069,96.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.497 | Acc: 52.427,81.040,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 52.534,81.102,96.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.491 | Acc: 52.548,81.113,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.487 | Acc: 52.580,81.198,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.520,81.240,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.423 | Acc: 48.438,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 47.842,65.253,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 47.752,64.748,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.597 | Acc: 47.387,64.293,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.617 | Acc: 52.344,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.490 | Acc: 52.530,81.734,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.529 | Acc: 52.268,80.526,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.511 | Acc: 52.088,81.045,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 52.180,80.729,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 52.127,80.825,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.494 | Acc: 52.228,80.921,96.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.487 | Acc: 52.172,81.106,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.491 | Acc: 52.067,81.032,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.488 | Acc: 52.201,81.064,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.488 | Acc: 52.262,81.110,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.489 | Acc: 52.107,81.155,96.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 52.253,81.201,96.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.488 | Acc: 52.347,81.214,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.485 | Acc: 52.347,81.233,96.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 52.302,81.234,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.482 | Acc: 52.400,81.243,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.486 | Acc: 52.378,81.177,96.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.368,81.237,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.485 | Acc: 52.426,81.213,96.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.423 | Acc: 49.219,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.581 | Acc: 48.363,64.881,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 47.694,64.386,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 47.246,64.114,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.457 | Acc: 53.906,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.448 | Acc: 53.906,80.692,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.469 | Acc: 52.992,81.059,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 52.856,81.263,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.489 | Acc: 52.286,80.845,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.487 | Acc: 52.444,80.956,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.497 | Acc: 52.253,80.914,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.483 | Acc: 52.527,81.145,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 52.349,81.104,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.489 | Acc: 52.344,81.241,96.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.482 | Acc: 52.441,81.297,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 52.517,81.430,96.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 52.506,81.412,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.480 | Acc: 52.460,81.463,96.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.480 | Acc: 52.494,81.395,96.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.484 | Acc: 52.331,81.395,96.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 52.312,81.415,96.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.261,81.394,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.490 | Acc: 52.292,81.293,96.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.487 | Acc: 52.333,81.287,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.448 | Acc: 48.438,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.588 | Acc: 47.656,65.216,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 47.504,64.520,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.614 | Acc: 47.144,64.139,68.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.625 | Acc: 49.219,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.489 | Acc: 52.418,81.287,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.505 | Acc: 52.401,80.945,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.516 | Acc: 51.767,80.712,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.516 | Acc: 52.016,80.720,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.505 | Acc: 52.328,80.863,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.504 | Acc: 52.382,80.908,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.503 | Acc: 52.349,80.990,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.496 | Acc: 52.358,81.075,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.496 | Acc: 52.430,81.177,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 52.328,81.215,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.500 | Acc: 52.255,81.271,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.501 | Acc: 52.110,81.185,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.224,81.265,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 52.269,81.247,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 52.126,81.201,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 52.156,81.311,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.485 | Acc: 52.190,81.335,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 52.220,81.347,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.266,81.303,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.377 | Acc: 49.219,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.576 | Acc: 48.549,65.030,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 48.075,64.482,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 47.567,64.203,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.706 | Acc: 47.656,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.522 | Acc: 52.269,80.580,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.532 | Acc: 52.229,80.145,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 51.908,80.802,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.493 | Acc: 52.537,81.038,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.485 | Acc: 52.653,81.258,96.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.481 | Acc: 52.641,81.173,96.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 52.626,81.084,96.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.480 | Acc: 52.611,81.027,96.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.477 | Acc: 52.680,81.060,96.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.476 | Acc: 52.635,81.028,96.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.480 | Acc: 52.467,81.084,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.478 | Acc: 52.538,81.192,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.474 | Acc: 52.568,81.193,96.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.477 | Acc: 52.547,81.200,96.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.482 | Acc: 52.450,81.170,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.481 | Acc: 52.448,81.206,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.481 | Acc: 52.456,81.209,96.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 52.419,81.220,96.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 52.461,81.188,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.437 | Acc: 46.875,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.583 | Acc: 48.214,65.141,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 47.885,64.463,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 47.451,64.319,68.712,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 2.722 | Acc: 46.094,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.433 | Acc: 51.451,81.510,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.473 | Acc: 51.734,81.402,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.480 | Acc: 52.062,81.212,96.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.461 | Acc: 52.440,81.549,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.466 | Acc: 52.638,81.459,96.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.462 | Acc: 52.847,81.528,96.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.466 | Acc: 52.704,81.449,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.475 | Acc: 52.480,81.366,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.475 | Acc: 52.452,81.297,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.472 | Acc: 52.569,81.336,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.473 | Acc: 52.535,81.246,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.475 | Acc: 52.545,81.247,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.476 | Acc: 52.502,81.241,96.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.479 | Acc: 52.424,81.219,96.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.478 | Acc: 52.494,81.247,96.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.481 | Acc: 52.507,81.196,96.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 52.481,81.172,96.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.483 | Acc: 52.422,81.166,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.486 | Acc: 52.379,81.141,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.402 | Acc: 48.438,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.571 | Acc: 48.177,65.402,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.585 | Acc: 47.866,64.977,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.597 | Acc: 47.400,64.613,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.977 | Acc: 59.375,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.486 | Acc: 52.902,81.548,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.506 | Acc: 52.763,81.212,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.508 | Acc: 52.997,81.032,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 53.067,81.202,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.501 | Acc: 52.854,81.351,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.510 | Acc: 52.570,81.211,96.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 52.272,81.189,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.506 | Acc: 52.242,81.163,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.500 | Acc: 52.257,81.280,96.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.500 | Acc: 52.289,81.316,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.502 | Acc: 52.188,81.299,96.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.491 | Acc: 52.392,81.409,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.493 | Acc: 52.347,81.370,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 52.377,81.353,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 52.427,81.297,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 52.431,81.306,96.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 52.408,81.245,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 52.461,81.293,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.495,81.289,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.440 | Acc: 48.438,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 48.363,65.216,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 47.885,64.482,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 47.464,64.191,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.323 | Acc: 50.000,84.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.479 | Acc: 52.121,81.101,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.476 | Acc: 52.248,81.345,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 53.112,81.455,96.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.500 | Acc: 52.469,81.086,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.510 | Acc: 52.228,80.925,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.503 | Acc: 52.402,80.979,96.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.508 | Acc: 52.261,80.790,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.509 | Acc: 52.412,80.828,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.501 | Acc: 52.417,80.948,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.491 | Acc: 52.647,81.044,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.491 | Acc: 52.648,81.116,96.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 52.691,81.192,96.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 52.691,81.187,96.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.489 | Acc: 52.638,81.153,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.489 | Acc: 52.619,81.183,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.487 | Acc: 52.621,81.209,96.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 52.655,81.220,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.619,81.205,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.484 | Acc: 52.635,81.158,96.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.386 | Acc: 49.219,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 48.438,65.104,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 47.732,64.596,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 47.362,64.255,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.330 | Acc: 55.469,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 52.716,81.027,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.480 | Acc: 52.191,81.383,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.498 | Acc: 51.755,81.224,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.474 | Acc: 52.402,81.626,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.478 | Acc: 52.421,81.598,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.466 | Acc: 52.421,81.767,96.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.465 | Acc: 52.443,81.538,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.468 | Acc: 52.504,81.430,96.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.470 | Acc: 52.529,81.418,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.473 | Acc: 52.604,81.320,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.475 | Acc: 52.549,81.289,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 52.584,81.263,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.480 | Acc: 52.511,81.172,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.479 | Acc: 52.472,81.214,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 52.435,81.042,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.484 | Acc: 52.536,81.046,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 52.504,81.083,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.469,81.038,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.436,81.008,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.460 | Acc: 48.438,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 48.586,65.402,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 47.904,64.691,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 47.349,64.395,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.210 | Acc: 57.812,82.031,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.535 | Acc: 52.046,80.246,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.505 | Acc: 52.896,80.736,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.493 | Acc: 52.830,80.904,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 52.836,80.980,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.487 | Acc: 52.746,80.972,96.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 52.815,81.114,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.478 | Acc: 52.726,81.161,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.470 | Acc: 52.562,81.226,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.476 | Acc: 52.357,81.155,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.477 | Acc: 52.348,81.126,96.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.485 | Acc: 52.216,80.967,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.487 | Acc: 52.221,81.072,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.485 | Acc: 52.200,81.130,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.490 | Acc: 52.199,81.108,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.487 | Acc: 52.305,81.144,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 52.293,81.116,96.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.487 | Acc: 52.312,81.206,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.486 | Acc: 52.346,81.170,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.315,81.168,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.420 | Acc: 48.438,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.583 | Acc: 48.586,64.955,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 48.228,64.520,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 47.541,64.191,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.422 | Acc: 50.000,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.512 | Acc: 52.083,80.692,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.466 | Acc: 52.954,81.212,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.470 | Acc: 52.754,81.557,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.471 | Acc: 52.508,81.481,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.466 | Acc: 52.754,81.126,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.458 | Acc: 52.776,81.347,96.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.456 | Acc: 52.754,81.455,96.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.466 | Acc: 52.480,81.352,96.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.374,81.285,96.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.470 | Acc: 52.278,81.301,96.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.480 | Acc: 52.185,81.215,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 52.289,81.185,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.482 | Acc: 52.203,81.154,96.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.484 | Acc: 52.266,81.130,96.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 52.235,81.170,96.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.483 | Acc: 52.332,81.196,96.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 52.268,81.241,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.484 | Acc: 52.251,81.263,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.484 | Acc: 52.301,81.295,96.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.408 | Acc: 48.438,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.581 | Acc: 48.326,64.881,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 47.694,64.425,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 47.221,64.165,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.361 | Acc: 56.250,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.504 | Acc: 52.493,80.952,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 53.335,80.926,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.470 | Acc: 53.074,81.557,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.459 | Acc: 52.932,81.655,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.472 | Acc: 52.746,81.614,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.476 | Acc: 52.518,81.508,96.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.478 | Acc: 52.549,81.416,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.462 | Acc: 52.674,81.609,96.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.471 | Acc: 52.624,81.470,96.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.473 | Acc: 52.612,81.409,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.475 | Acc: 52.616,81.413,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.469 | Acc: 52.704,81.513,96.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.473 | Acc: 52.718,81.489,96.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.473 | Acc: 52.711,81.439,96.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.476 | Acc: 52.723,81.406,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.475 | Acc: 52.738,81.408,96.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.474 | Acc: 52.710,81.417,96.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.479 | Acc: 52.662,81.347,96.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.484 | Acc: 52.590,81.320,96.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.423 | Acc: 48.438,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.584 | Acc: 48.028,65.030,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 47.618,64.520,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 47.285,64.165,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.389 | Acc: 56.250,85.938,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.410 | Acc: 53.943,81.882,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.441 | Acc: 53.487,81.307,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.447 | Acc: 53.061,81.109,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.456 | Acc: 53.318,81.173,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.453 | Acc: 53.249,81.242,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.460 | Acc: 53.002,81.327,96.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.468 | Acc: 52.848,81.195,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.470 | Acc: 52.756,81.206,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.474 | Acc: 52.784,81.336,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.476 | Acc: 52.775,81.293,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.466 | Acc: 52.856,81.494,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.467 | Acc: 52.843,81.441,96.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.466 | Acc: 52.790,81.519,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.471 | Acc: 52.758,81.395,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.474 | Acc: 52.676,81.351,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.480 | Acc: 52.646,81.345,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 52.662,81.296,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.608,81.282,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 52.575,81.322,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.425 | Acc: 48.438,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.585 | Acc: 48.326,64.807,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 47.961,64.386,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 47.490,64.101,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.547 | Acc: 48.438,78.906,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.501 | Acc: 51.488,81.138,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.475 | Acc: 52.210,81.898,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.479 | Acc: 52.190,81.839,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.462 | Acc: 52.334,81.867,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.467 | Acc: 52.189,81.815,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.477 | Acc: 51.976,81.541,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.473 | Acc: 52.089,81.610,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 51.922,81.454,96.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 52.050,81.427,96.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.481 | Acc: 52.231,81.347,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.482 | Acc: 52.171,81.381,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.482 | Acc: 52.224,81.354,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 52.466,81.397,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.470 | Acc: 52.524,81.472,96.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.471 | Acc: 52.614,81.356,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.472 | Acc: 52.667,81.340,96.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.473 | Acc: 52.612,81.369,96.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.473 | Acc: 52.569,81.356,96.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.477 | Acc: 52.543,81.312,96.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 48.438,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.584 | Acc: 48.363,65.030,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 47.790,64.520,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 47.259,64.191,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 2.362 | Acc: 57.812,85.938,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.475 | Acc: 53.609,82.254,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.481 | Acc: 53.239,81.745,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.512 | Acc: 52.574,81.186,96.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.499 | Acc: 52.459,81.289,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.490 | Acc: 52.599,81.405,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.501 | Acc: 52.447,81.231,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.510 | Acc: 52.272,81.006,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 52.334,81.211,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.503 | Acc: 52.417,81.181,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.503 | Acc: 52.305,81.215,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.500 | Acc: 52.238,81.218,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.494 | Acc: 52.263,81.363,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.233,81.373,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 52.269,81.300,96.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 52.313,81.375,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 52.278,81.389,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.369,81.387,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.490 | Acc: 52.357,81.358,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.329,81.394,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.435 | Acc: 47.656,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.577 | Acc: 48.438,65.551,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 48.095,64.844,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 47.695,64.447,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.596 | Acc: 50.000,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.552 | Acc: 51.376,80.060,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.508 | Acc: 52.420,80.393,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.491 | Acc: 53.138,80.763,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.487 | Acc: 52.874,80.855,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.488 | Acc: 52.816,80.987,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.487 | Acc: 52.763,80.992,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.483 | Acc: 52.765,81.100,96.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.488 | Acc: 52.664,80.954,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.490 | Acc: 52.503,81.017,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.492 | Acc: 52.491,81.063,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 52.383,81.130,96.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 52.305,81.273,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 52.191,81.274,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.495 | Acc: 52.219,81.186,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 52.352,81.245,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 52.353,81.233,96.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 52.289,81.200,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 52.391,81.233,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.401,81.281,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 49.219,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 48.438,65.476,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 48.056,64.901,69.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 47.579,64.408,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.417 | Acc: 54.688,84.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.415 | Acc: 53.832,81.734,97.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.467 | Acc: 52.706,81.479,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 52.741,81.109,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.470 | Acc: 52.527,80.980,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.471 | Acc: 52.669,81.026,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.469 | Acc: 52.621,81.153,96.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.470 | Acc: 52.643,81.100,96.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 52.509,81.022,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.477 | Acc: 52.611,81.039,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.480 | Acc: 52.701,81.071,96.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.480 | Acc: 52.605,81.158,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 52.587,81.244,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.482 | Acc: 52.529,81.205,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.481 | Acc: 52.463,81.231,96.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.482 | Acc: 52.419,81.343,96.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.479 | Acc: 52.417,81.391,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.481 | Acc: 52.426,81.422,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.480 | Acc: 52.491,81.449,96.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 52.409,81.494,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.424 | Acc: 48.438,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 48.326,65.067,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 47.942,64.615,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 47.579,64.216,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.942 | Acc: 61.719,89.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.507 | Acc: 51.935,81.362,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.481 | Acc: 52.325,81.764,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.483 | Acc: 52.216,81.711,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.488 | Acc: 52.247,81.636,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.482 | Acc: 52.452,81.567,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 52.583,81.573,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.493 | Acc: 52.349,81.472,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.494 | Acc: 52.368,81.449,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.500 | Acc: 52.331,81.444,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.502 | Acc: 52.355,81.382,96.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.492 | Acc: 52.542,81.466,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 52.538,81.448,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.487 | Acc: 52.562,81.492,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.488 | Acc: 52.472,81.509,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 52.445,81.543,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.479 | Acc: 52.500,81.603,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.482 | Acc: 52.467,81.523,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 52.504,81.559,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 52.483,81.556,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.430 | Acc: 47.656,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 48.549,64.955,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 48.018,64.444,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.617 | Acc: 47.439,64.075,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.404 | Acc: 51.562,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.451 | Acc: 53.311,81.362,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.500 | Acc: 52.382,80.583,96.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 52.754,80.379,96.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.478 | Acc: 52.672,80.700,96.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.479 | Acc: 52.522,80.948,96.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 52.299,80.927,96.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.492 | Acc: 52.288,80.929,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.487 | Acc: 52.378,81.003,96.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.487 | Acc: 52.434,80.935,96.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.477 | Acc: 52.713,81.118,96.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.480 | Acc: 52.584,81.105,96.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.483 | Acc: 52.616,81.127,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.482 | Acc: 52.613,81.181,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 52.619,81.133,96.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.487 | Acc: 52.668,81.086,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 52.670,81.160,96.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 52.642,81.223,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.642,81.222,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.484 | Acc: 52.606,81.215,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.445 | Acc: 47.656,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 48.028,65.253,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 47.675,64.634,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 47.310,64.267,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.530 | Acc: 48.438,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.504 | Acc: 51.153,82.403,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 51.905,81.936,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.485 | Acc: 52.446,81.647,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.476 | Acc: 52.739,81.838,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 52.413,81.559,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 52.447,81.340,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.480 | Acc: 52.521,81.400,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.485 | Acc: 52.407,81.347,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.478 | Acc: 52.555,81.479,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.478 | Acc: 52.507,81.417,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.472 | Acc: 52.680,81.459,96.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.474 | Acc: 52.584,81.412,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 52.559,81.343,96.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 52.558,81.336,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 52.544,81.432,96.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.474 | Acc: 52.573,81.377,96.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.475 | Acc: 52.500,81.429,96.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.476 | Acc: 52.558,81.397,96.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 52.504,81.422,96.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.402 | Acc: 47.656,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 48.289,65.216,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 47.942,64.558,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 47.528,64.191,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.917 | Acc: 49.219,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.518 | Acc: 51.302,81.399,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 52.153,81.307,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.461 | Acc: 52.280,81.250,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.482 | Acc: 52.074,81.125,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.488 | Acc: 51.996,80.995,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 52.027,81.134,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.495 | Acc: 51.889,81.100,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 51.902,81.056,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.494 | Acc: 52.184,81.073,96.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.492 | Acc: 52.142,81.133,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.490 | Acc: 52.192,81.077,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.484 | Acc: 52.266,81.182,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 52.332,81.283,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.477 | Acc: 52.363,81.311,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.475 | Acc: 52.393,81.367,96.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.478 | Acc: 52.310,81.335,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.475 | Acc: 52.410,81.360,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.478 | Acc: 52.389,81.315,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.481 | Acc: 52.438,81.355,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.408 | Acc: 47.656,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.604 | Acc: 48.214,64.807,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 47.656,64.501,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.623 | Acc: 47.182,64.293,68.865,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.791 | Acc: 45.312,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.450 | Acc: 52.902,80.915,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.450 | Acc: 52.782,81.307,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.454 | Acc: 52.523,81.557,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.462 | Acc: 52.575,81.346,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.483 | Acc: 52.351,81.134,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.477 | Acc: 52.499,81.173,96.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.485 | Acc: 52.194,81.316,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 52.397,81.386,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.479 | Acc: 52.486,81.449,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.480 | Acc: 52.550,81.398,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.476 | Acc: 52.559,81.473,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.482 | Acc: 52.532,81.448,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.478 | Acc: 52.592,81.474,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.480 | Acc: 52.658,81.489,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.476 | Acc: 52.730,81.471,96.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.475 | Acc: 52.719,81.457,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.476 | Acc: 52.697,81.484,96.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.482 | Acc: 52.573,81.404,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.480 | Acc: 52.565,81.430,96.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.422 | Acc: 49.219,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.577 | Acc: 48.065,64.881,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 47.694,64.501,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.595 | Acc: 47.298,64.331,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.564 | Acc: 47.656,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.491 | Acc: 53.274,80.655,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.523 | Acc: 52.363,80.469,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.515 | Acc: 52.139,80.392,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.512 | Acc: 52.276,80.748,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.495 | Acc: 52.475,80.964,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.494 | Acc: 52.466,81.101,96.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.494 | Acc: 52.532,81.045,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.485 | Acc: 52.591,81.075,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 52.573,81.125,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.483 | Acc: 52.620,81.219,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 52.605,81.147,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.487 | Acc: 52.600,81.169,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 52.511,81.220,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.488 | Acc: 52.527,81.242,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 52.411,81.299,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 52.414,81.301,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.485 | Acc: 52.463,81.287,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.487 | Acc: 52.432,81.246,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 52.405,81.186,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 48.438,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 48.475,65.067,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 48.037,64.577,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.607 | Acc: 47.579,64.319,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 2.405 | Acc: 56.250,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.442 | Acc: 53.795,82.552,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.417 | Acc: 53.506,81.955,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 52.702,81.314,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.474 | Acc: 52.672,81.182,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 52.351,81.188,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.510 | Acc: 51.872,81.024,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.520 | Acc: 51.939,80.912,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.516 | Acc: 51.829,81.046,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.512 | Acc: 51.960,81.000,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.500 | Acc: 52.200,81.157,96.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.497 | Acc: 52.132,81.172,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.502 | Acc: 52.016,81.085,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.499 | Acc: 52.107,81.136,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.499 | Acc: 52.105,81.130,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.493 | Acc: 52.136,81.266,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.492 | Acc: 52.164,81.287,96.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.491 | Acc: 52.158,81.296,96.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.486 | Acc: 52.216,81.352,96.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.484 | Acc: 52.249,81.375,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.443 | Acc: 49.219,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 48.400,65.327,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 48.037,64.844,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 47.503,64.357,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.324 | Acc: 56.250,83.594,96.094,% | Adaptive Acc: 87.500% | clf_exit: 0.375 0.383 0.242
Batch: 20 | Loss: 2.383 | Acc: 54.353,81.696,96.652,% | Adaptive Acc: 87.202% | clf_exit: 0.381 0.420 0.199
Batch: 40 | Loss: 2.421 | Acc: 53.487,82.069,96.589,% | Adaptive Acc: 87.081% | clf_exit: 0.370 0.429 0.201
Batch: 60 | Loss: 2.428 | Acc: 53.356,81.890,96.683,% | Adaptive Acc: 87.052% | clf_exit: 0.370 0.426 0.204
Batch: 80 | Loss: 2.436 | Acc: 53.424,81.838,96.586,% | Adaptive Acc: 87.008% | clf_exit: 0.368 0.429 0.202
Batch: 100 | Loss: 2.452 | Acc: 53.094,81.652,96.558,% | Adaptive Acc: 86.881% | clf_exit: 0.366 0.431 0.203
Batch: 120 | Loss: 2.464 | Acc: 52.673,81.560,96.572,% | Adaptive Acc: 86.732% | clf_exit: 0.366 0.429 0.204
Batch: 140 | Loss: 2.466 | Acc: 52.709,81.472,96.520,% | Adaptive Acc: 86.818% | clf_exit: 0.366 0.429 0.204
Batch: 160 | Loss: 2.477 | Acc: 52.552,81.323,96.482,% | Adaptive Acc: 86.665% | clf_exit: 0.365 0.431 0.204
Batch: 180 | Loss: 2.479 | Acc: 52.521,81.310,96.504,% | Adaptive Acc: 86.766% | clf_exit: 0.364 0.431 0.205
Batch: 200 | Loss: 2.482 | Acc: 52.387,81.289,96.517,% | Adaptive Acc: 86.715% | clf_exit: 0.364 0.433 0.204
Batch: 220 | Loss: 2.486 | Acc: 52.460,81.285,96.518,% | Adaptive Acc: 86.754% | clf_exit: 0.364 0.433 0.203
Batch: 240 | Loss: 2.484 | Acc: 52.551,81.269,96.441,% | Adaptive Acc: 86.693% | clf_exit: 0.365 0.432 0.203
Batch: 260 | Loss: 2.482 | Acc: 52.541,81.313,96.444,% | Adaptive Acc: 86.644% | clf_exit: 0.366 0.432 0.202
Batch: 280 | Loss: 2.479 | Acc: 52.566,81.370,96.461,% | Adaptive Acc: 86.702% | clf_exit: 0.365 0.432 0.203
Batch: 300 | Loss: 2.481 | Acc: 52.442,81.437,96.514,% | Adaptive Acc: 86.693% | clf_exit: 0.366 0.432 0.203
Batch: 320 | Loss: 2.484 | Acc: 52.380,81.386,96.515,% | Adaptive Acc: 86.658% | clf_exit: 0.366 0.431 0.202
Batch: 340 | Loss: 2.484 | Acc: 52.426,81.413,96.513,% | Adaptive Acc: 86.639% | clf_exit: 0.366 0.431 0.202
Batch: 360 | Loss: 2.483 | Acc: 52.409,81.391,96.535,% | Adaptive Acc: 86.697% | clf_exit: 0.366 0.432 0.202
Batch: 380 | Loss: 2.482 | Acc: 52.411,81.375,96.535,% | Adaptive Acc: 86.643% | clf_exit: 0.366 0.432 0.202
Batch: 0 | Loss: 4.443 | Acc: 49.219,68.750,71.094,% | Adaptive Acc: 65.625% | clf_exit: 0.445 0.375 0.180
Batch: 20 | Loss: 4.582 | Acc: 48.400,64.807,69.568,% | Adaptive Acc: 63.504% | clf_exit: 0.433 0.355 0.212
Batch: 40 | Loss: 4.594 | Acc: 48.018,64.348,69.093,% | Adaptive Acc: 63.510% | clf_exit: 0.433 0.353 0.214
Batch: 60 | Loss: 4.603 | Acc: 47.554,64.050,68.865,% | Adaptive Acc: 63.281% | clf_exit: 0.434 0.355 0.211
model is save as models/resnet56_2con3_att_cifar100_adaptive0_circles5_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 10.025 | Acc: 49.219,17.188,11.719,% | Adaptive Acc: 39.062% | clf_exit: 0.445 0.164 0.391
Batch: 20 | Loss: 10.833 | Acc: 48.400,10.975,13.356,% | Adaptive Acc: 37.277% | clf_exit: 0.433 0.168 0.400
Batch: 40 | Loss: 10.843 | Acc: 48.018,10.652,13.300,% | Adaptive Acc: 37.214% | clf_exit: 0.433 0.166 0.401
Batch: 60 | Loss: 10.827 | Acc: 47.554,10.976,13.601,% | Adaptive Acc: 37.077% | clf_exit: 0.434 0.169 0.397
Batch: 0 | Loss: 7.646 | Acc: 49.219,26.562,42.969,% | Adaptive Acc: 51.562% | clf_exit: 0.445 0.195 0.359
Batch: 20 | Loss: 8.449 | Acc: 48.400,20.685,39.509,% | Adaptive Acc: 45.573% | clf_exit: 0.433 0.201 0.366
Batch: 40 | Loss: 8.438 | Acc: 48.018,20.503,39.539,% | Adaptive Acc: 45.941% | clf_exit: 0.433 0.190 0.377
Batch: 60 | Loss: 8.438 | Acc: 47.554,20.492,39.395,% | Adaptive Acc: 45.774% | clf_exit: 0.434 0.192 0.374
Batch: 0 | Loss: 5.910 | Acc: 49.219,44.531,59.375,% | Adaptive Acc: 58.594% | clf_exit: 0.445 0.219 0.336
Batch: 20 | Loss: 6.553 | Acc: 48.400,37.314,57.366,% | Adaptive Acc: 53.832% | clf_exit: 0.433 0.211 0.357
Batch: 40 | Loss: 6.542 | Acc: 48.018,37.557,56.955,% | Adaptive Acc: 53.811% | clf_exit: 0.433 0.208 0.359
Batch: 60 | Loss: 6.556 | Acc: 47.554,37.013,56.865,% | Adaptive Acc: 53.650% | clf_exit: 0.434 0.206 0.360
Batch: 0 | Loss: 4.889 | Acc: 49.219,59.375,66.406,% | Adaptive Acc: 58.594% | clf_exit: 0.445 0.281 0.273
Batch: 20 | Loss: 5.250 | Acc: 48.400,54.762,65.588,% | Adaptive Acc: 60.119% | clf_exit: 0.433 0.258 0.310
Batch: 40 | Loss: 5.249 | Acc: 48.018,54.002,65.015,% | Adaptive Acc: 59.947% | clf_exit: 0.433 0.257 0.310
Batch: 60 | Loss: 5.266 | Acc: 47.554,53.330,65.254,% | Adaptive Acc: 59.567% | clf_exit: 0.434 0.257 0.309
Batch: 0 | Loss: 4.433 | Acc: 49.219,64.062,67.969,% | Adaptive Acc: 61.719% | clf_exit: 0.445 0.344 0.211
Batch: 20 | Loss: 4.630 | Acc: 48.400,63.244,68.676,% | Adaptive Acc: 63.021% | clf_exit: 0.433 0.316 0.251
Batch: 40 | Loss: 4.635 | Acc: 48.018,62.271,68.521,% | Adaptive Acc: 63.053% | clf_exit: 0.433 0.313 0.254
Batch: 60 | Loss: 4.649 | Acc: 47.554,61.949,68.532,% | Adaptive Acc: 62.564% | clf_exit: 0.434 0.315 0.251
Batch: 0 | Loss: 4.443 | Acc: 49.219,68.750,71.094,% | Adaptive Acc: 65.625% | clf_exit: 0.445 0.375 0.180
Batch: 20 | Loss: 4.582 | Acc: 48.400,64.807,69.568,% | Adaptive Acc: 63.504% | clf_exit: 0.433 0.355 0.212
Batch: 40 | Loss: 4.594 | Acc: 48.018,64.348,69.093,% | Adaptive Acc: 63.510% | clf_exit: 0.433 0.353 0.214
Batch: 60 | Loss: 4.603 | Acc: 47.554,64.050,68.865,% | Adaptive Acc: 63.281% | clf_exit: 0.434 0.355 0.211







Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.587 |  Acc: 2.082,2.412,3.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 13.061 |  Acc: 2.910,3.700,6.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 12.529 |  Acc: 3.794,6.104,9.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 12.316 |  Acc: 4.550,6.810,8.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 11.910 |  Acc: 5.660,8.664,12.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 11.741 |  Acc: 7.510,8.590,12.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 11.373 |  Acc: 8.386,10.700,15.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 11.391 |  Acc: 7.790,9.920,15.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 10.807 |  Acc: 11.046,12.960,18.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 11.071 |  Acc: 10.640,11.190,16.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 10.262 |  Acc: 13.810,15.694,21.654,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 10.478 |  Acc: 15.120,11.220,20.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 9.788 |  Acc: 16.156,18.236,24.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 9.979 |  Acc: 13.660,16.210,23.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 9.398 |  Acc: 17.894,20.466,27.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 10.348 |  Acc: 13.730,16.400,23.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 9.049 |  Acc: 19.552,22.750,30.154,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 9.466 |  Acc: 19.370,18.490,26.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 8.709 |  Acc: 21.462,24.430,32.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 9.556 |  Acc: 16.070,19.010,28.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 8.421 |  Acc: 22.892,26.532,34.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 9.344 |  Acc: 19.260,20.050,28.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 8.158 |  Acc: 24.408,28.176,36.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 9.028 |  Acc: 19.000,22.970,33.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 7.934 |  Acc: 25.542,29.876,38.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 8.890 |  Acc: 18.750,24.780,31.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 7.724 |  Acc: 26.662,31.576,39.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 8.137 |  Acc: 24.260,27.810,37.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 7.506 |  Acc: 27.620,33.450,41.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 8.572 |  Acc: 23.180,24.310,36.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 7.337 |  Acc: 28.560,34.674,43.152,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 7.797 |  Acc: 25.010,32.110,40.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 7.157 |  Acc: 29.390,36.478,44.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 7.933 |  Acc: 24.500,30.430,39.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 6.990 |  Acc: 30.076,37.842,46.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 7.477 |  Acc: 25.580,33.980,43.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 6.850 |  Acc: 31.054,39.026,47.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 7.873 |  Acc: 27.370,33.190,37.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 6.742 |  Acc: 31.224,40.102,48.238,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 7.827 |  Acc: 23.610,32.510,41.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 6.593 |  Acc: 31.910,41.576,49.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 7.416 |  Acc: 27.020,35.130,44.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 6.495 |  Acc: 32.516,42.312,50.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 8.557 |  Acc: 22.190,31.810,41.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 6.407 |  Acc: 33.120,43.394,51.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 7.787 |  Acc: 24.520,36.680,42.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 6.324 |  Acc: 33.418,43.866,52.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 7.320 |  Acc: 25.990,37.490,46.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 6.237 |  Acc: 33.806,44.904,53.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 7.116 |  Acc: 26.400,38.800,48.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 6.145 |  Acc: 34.058,45.756,53.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 7.183 |  Acc: 26.650,38.130,46.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 6.073 |  Acc: 34.634,46.450,54.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 7.023 |  Acc: 28.050,39.810,48.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 6.030 |  Acc: 34.712,46.800,54.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 8.002 |  Acc: 24.330,35.210,43.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 5.949 |  Acc: 35.176,47.604,55.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 7.152 |  Acc: 26.280,40.150,48.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 5.878 |  Acc: 35.690,48.324,56.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 7.422 |  Acc: 25.650,36.680,47.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 5.828 |  Acc: 35.696,48.636,56.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 7.514 |  Acc: 26.610,38.430,46.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 5.758 |  Acc: 35.858,49.128,57.376,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 7.730 |  Acc: 23.840,37.160,48.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 5.712 |  Acc: 36.110,49.586,57.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 7.145 |  Acc: 27.440,40.410,50.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 5.642 |  Acc: 36.442,50.302,58.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 7.895 |  Acc: 24.170,36.850,48.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 5.602 |  Acc: 36.708,50.604,59.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 7.549 |  Acc: 26.430,38.000,47.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.578 |  Acc: 36.574,51.026,59.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 7.154 |  Acc: 26.540,41.820,49.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.528 |  Acc: 37.090,51.552,59.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 7.785 |  Acc: 24.410,38.140,44.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.498 |  Acc: 36.934,51.830,60.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 7.849 |  Acc: 20.820,37.380,48.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.459 |  Acc: 37.196,52.192,60.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 7.141 |  Acc: 27.680,41.330,49.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.428 |  Acc: 37.460,52.340,60.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 7.359 |  Acc: 28.050,39.600,47.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.384 |  Acc: 37.678,52.864,61.140,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 8.470 |  Acc: 21.020,33.990,46.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.360 |  Acc: 37.632,53.008,61.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 6.766 |  Acc: 30.390,42.380,52.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.343 |  Acc: 37.670,53.158,62.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 6.745 |  Acc: 30.550,43.060,49.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.325 |  Acc: 37.802,53.246,61.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 7.321 |  Acc: 24.180,39.850,52.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.271 |  Acc: 38.346,53.958,62.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 7.393 |  Acc: 26.310,40.600,49.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 5.255 |  Acc: 38.274,53.936,62.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 7.200 |  Acc: 27.240,41.530,49.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 5.231 |  Acc: 37.916,54.222,63.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 7.293 |  Acc: 23.780,41.930,51.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 5.186 |  Acc: 38.550,54.642,63.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 7.009 |  Acc: 27.810,42.990,50.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 5.168 |  Acc: 38.532,54.676,63.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 8.332 |  Acc: 23.390,35.670,44.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 5.136 |  Acc: 38.778,54.976,63.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 6.544 |  Acc: 29.010,46.320,53.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 5.122 |  Acc: 38.778,55.230,64.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 6.764 |  Acc: 30.550,43.950,50.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 5.117 |  Acc: 38.828,55.148,64.494,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 7.078 |  Acc: 28.550,42.850,49.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 5.072 |  Acc: 38.924,55.734,64.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 7.056 |  Acc: 29.260,43.260,51.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 5.074 |  Acc: 39.230,55.522,64.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 6.814 |  Acc: 29.200,43.940,53.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 5.048 |  Acc: 39.304,55.938,65.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 6.267 |  Acc: 32.290,46.970,54.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 5.031 |  Acc: 39.272,56.038,65.308,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 7.036 |  Acc: 24.610,43.600,51.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 4.983 |  Acc: 39.446,56.584,65.892,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 8.330 |  Acc: 18.360,37.590,49.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 4.993 |  Acc: 39.312,56.456,65.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.826 |  Acc: 28.860,42.410,53.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 4.957 |  Acc: 39.340,56.752,65.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 6.820 |  Acc: 28.900,43.930,53.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 4.947 |  Acc: 39.608,56.966,66.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 7.202 |  Acc: 25.240,43.920,53.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 4.958 |  Acc: 39.312,56.920,65.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 6.113 |  Acc: 31.830,46.570,57.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.921 |  Acc: 39.616,57.294,66.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 6.640 |  Acc: 28.270,46.480,55.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.906 |  Acc: 39.690,57.242,66.554,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 6.904 |  Acc: 28.550,43.760,54.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.871 |  Acc: 40.216,57.386,66.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 6.549 |  Acc: 28.140,45.150,55.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.880 |  Acc: 40.082,57.578,66.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 6.976 |  Acc: 29.670,43.560,51.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.862 |  Acc: 40.174,57.802,66.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 6.547 |  Acc: 33.180,45.420,53.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.851 |  Acc: 40.074,57.710,67.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 6.257 |  Acc: 33.040,48.480,56.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.819 |  Acc: 40.278,58.266,67.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 7.285 |  Acc: 27.210,42.250,50.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.828 |  Acc: 40.136,57.960,67.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 8.035 |  Acc: 19.900,42.420,51.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.814 |  Acc: 40.410,58.012,67.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 6.027 |  Acc: 33.830,46.790,58.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.785 |  Acc: 40.272,58.298,67.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 7.523 |  Acc: 23.630,44.110,54.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.765 |  Acc: 40.546,58.652,68.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 7.004 |  Acc: 24.050,45.600,54.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.753 |  Acc: 40.748,58.830,68.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 6.394 |  Acc: 32.780,46.570,53.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.759 |  Acc: 40.668,58.606,67.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.569 |  Acc: 30.360,45.980,54.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.749 |  Acc: 40.504,58.584,68.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 7.074 |  Acc: 26.420,42.800,51.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.715 |  Acc: 40.812,59.010,68.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 6.986 |  Acc: 29.340,41.800,51.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.717 |  Acc: 40.804,58.954,68.346,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 7.140 |  Acc: 27.560,42.550,52.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.696 |  Acc: 40.770,59.140,68.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 6.125 |  Acc: 34.110,50.080,55.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.702 |  Acc: 40.882,58.974,68.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 7.495 |  Acc: 26.110,44.110,52.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.719 |  Acc: 40.574,59.094,68.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 6.213 |  Acc: 31.370,48.250,58.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.671 |  Acc: 41.062,59.344,69.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 6.484 |  Acc: 30.600,45.810,54.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.692 |  Acc: 40.830,59.466,68.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.329 |  Acc: 31.910,49.830,57.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.659 |  Acc: 40.952,59.564,69.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 7.155 |  Acc: 24.480,44.940,55.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.673 |  Acc: 40.972,59.492,68.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 6.575 |  Acc: 31.060,44.900,55.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.646 |  Acc: 41.042,59.592,69.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 6.591 |  Acc: 32.910,44.170,55.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.645 |  Acc: 41.080,59.482,68.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 6.018 |  Acc: 33.380,49.800,58.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.643 |  Acc: 41.236,59.868,69.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 6.607 |  Acc: 29.990,47.730,56.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.618 |  Acc: 41.310,60.104,69.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 6.679 |  Acc: 30.250,44.680,53.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.643 |  Acc: 41.062,59.456,69.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 7.714 |  Acc: 25.000,40.250,51.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.619 |  Acc: 41.344,59.912,69.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 8.216 |  Acc: 26.560,39.980,47.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.605 |  Acc: 41.422,60.326,69.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 7.048 |  Acc: 27.520,42.010,52.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.595 |  Acc: 41.230,60.226,69.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 6.136 |  Acc: 34.330,47.990,57.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.606 |  Acc: 41.392,60.070,69.912,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 8.194 |  Acc: 22.050,39.760,51.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.573 |  Acc: 41.470,60.384,70.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 6.753 |  Acc: 28.220,45.900,55.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.579 |  Acc: 41.592,60.358,70.128,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 6.348 |  Acc: 32.270,48.160,55.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.577 |  Acc: 41.404,60.294,70.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 7.647 |  Acc: 29.590,35.850,50.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.558 |  Acc: 41.592,60.620,70.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 6.033 |  Acc: 33.700,48.350,56.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.544 |  Acc: 41.548,60.388,70.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 6.718 |  Acc: 29.870,46.630,54.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.555 |  Acc: 41.994,60.388,70.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 6.694 |  Acc: 28.580,46.940,56.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.537 |  Acc: 41.872,60.450,70.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 7.819 |  Acc: 22.630,41.360,55.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.543 |  Acc: 41.604,60.614,70.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 6.227 |  Acc: 32.150,47.420,56.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.536 |  Acc: 41.742,60.692,70.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 6.568 |  Acc: 26.790,47.340,57.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.539 |  Acc: 41.674,60.682,70.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.698 |  Acc: 29.820,45.510,55.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.499 |  Acc: 41.996,60.956,70.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 6.051 |  Acc: 33.860,49.880,57.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.503 |  Acc: 42.008,61.236,70.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 6.404 |  Acc: 30.510,48.640,55.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.510 |  Acc: 41.748,60.912,70.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 6.931 |  Acc: 31.870,44.940,53.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.492 |  Acc: 42.038,61.166,71.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 7.424 |  Acc: 25.180,45.080,48.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.493 |  Acc: 42.124,61.040,70.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 6.340 |  Acc: 30.470,47.100,56.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.483 |  Acc: 41.946,60.908,71.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 7.182 |  Acc: 26.530,43.810,52.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.475 |  Acc: 41.858,61.206,71.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 7.359 |  Acc: 21.760,46.750,56.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.493 |  Acc: 42.084,61.054,70.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 6.175 |  Acc: 34.940,49.170,55.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.473 |  Acc: 42.122,61.468,71.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 6.391 |  Acc: 31.970,48.360,56.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.479 |  Acc: 42.140,61.292,71.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 7.017 |  Acc: 27.700,46.270,54.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.486 |  Acc: 41.928,60.966,71.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 6.460 |  Acc: 29.640,48.190,57.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.452 |  Acc: 42.346,61.302,71.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 6.359 |  Acc: 28.890,49.090,59.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.458 |  Acc: 42.216,61.440,71.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.132 |  Acc: 31.520,50.720,57.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.442 |  Acc: 42.324,61.370,71.726,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 7.493 |  Acc: 25.460,45.870,54.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.435 |  Acc: 42.188,61.808,71.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 7.242 |  Acc: 26.110,44.390,55.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.443 |  Acc: 42.036,61.664,71.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 6.172 |  Acc: 30.520,49.110,59.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.432 |  Acc: 42.306,61.428,71.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 6.419 |  Acc: 30.660,49.930,58.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.432 |  Acc: 42.262,61.712,71.886,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 7.297 |  Acc: 21.460,42.760,55.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.427 |  Acc: 42.148,61.586,72.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 7.094 |  Acc: 25.430,45.220,55.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.406 |  Acc: 42.522,61.940,71.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 6.229 |  Acc: 31.280,48.150,57.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.417 |  Acc: 42.382,61.666,71.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 6.226 |  Acc: 32.370,48.780,56.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.404 |  Acc: 42.416,61.576,71.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 6.291 |  Acc: 30.830,49.200,58.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.411 |  Acc: 42.518,61.864,71.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 7.063 |  Acc: 24.600,46.540,55.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.397 |  Acc: 42.412,61.708,72.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 6.566 |  Acc: 28.940,48.650,58.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.393 |  Acc: 42.520,62.156,72.172,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 6.628 |  Acc: 32.220,47.910,57.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.374 |  Acc: 42.582,62.184,72.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 6.610 |  Acc: 29.800,49.050,55.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.399 |  Acc: 42.486,61.902,72.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 5.956 |  Acc: 34.090,51.050,58.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.383 |  Acc: 42.532,61.926,72.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 6.112 |  Acc: 35.030,48.810,56.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.385 |  Acc: 42.540,62.012,72.292,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 6.949 |  Acc: 28.370,45.580,56.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.382 |  Acc: 42.762,61.916,72.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 7.538 |  Acc: 24.460,41.040,52.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.369 |  Acc: 42.460,62.314,72.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 6.439 |  Acc: 31.260,48.790,56.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.370 |  Acc: 42.458,62.096,72.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 6.504 |  Acc: 31.450,47.930,55.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.382 |  Acc: 42.370,62.116,72.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 6.405 |  Acc: 31.210,50.410,57.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.359 |  Acc: 42.662,62.312,72.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 7.464 |  Acc: 27.220,44.140,49.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.367 |  Acc: 42.828,62.146,72.152,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 7.073 |  Acc: 26.100,44.300,55.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.359 |  Acc: 42.670,62.276,72.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 7.986 |  Acc: 22.650,40.100,52.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.345 |  Acc: 42.862,62.406,72.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 7.618 |  Acc: 27.340,42.410,51.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.366 |  Acc: 42.374,62.328,72.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 6.525 |  Acc: 30.850,48.210,56.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.344 |  Acc: 42.768,62.436,72.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 6.432 |  Acc: 31.570,49.860,56.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.339 |  Acc: 42.782,62.324,72.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 6.710 |  Acc: 29.840,46.040,52.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.338 |  Acc: 42.878,62.294,72.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 6.278 |  Acc: 33.530,48.200,56.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.344 |  Acc: 42.946,62.320,72.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 6.705 |  Acc: 26.400,46.180,56.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.344 |  Acc: 42.632,62.132,72.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 5.860 |  Acc: 36.710,50.340,58.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.326 |  Acc: 42.742,62.290,72.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 6.482 |  Acc: 30.900,49.310,57.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.331 |  Acc: 43.148,62.390,73.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 6.822 |  Acc: 30.860,45.520,54.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.322 |  Acc: 42.778,62.588,72.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 8.022 |  Acc: 23.010,43.130,52.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.314 |  Acc: 43.240,62.724,72.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 6.562 |  Acc: 30.900,50.070,56.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.633 |  Acc: 47.206,69.856,80.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.367 |  Acc: 44.670,63.720,70.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.438 |  Acc: 48.328,71.744,83.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.348 |  Acc: 44.980,63.890,70.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.379 |  Acc: 48.414,72.154,84.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.323 |  Acc: 45.530,64.260,70.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.316 |  Acc: 48.690,72.572,85.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.367 |  Acc: 44.830,63.950,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.286 |  Acc: 48.858,72.948,85.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.375 |  Acc: 45.330,63.670,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.254 |  Acc: 48.986,73.138,86.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.357 |  Acc: 45.660,64.190,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.226 |  Acc: 49.194,73.464,86.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.374 |  Acc: 45.280,63.990,70.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.201 |  Acc: 49.302,73.490,86.726,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.369 |  Acc: 45.280,64.150,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.189 |  Acc: 49.154,73.554,87.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.384 |  Acc: 45.810,64.380,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.168 |  Acc: 49.336,73.734,87.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.389 |  Acc: 45.930,64.510,70.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.151 |  Acc: 49.538,74.078,87.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.425 |  Acc: 45.460,63.500,69.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.134 |  Acc: 49.320,73.962,87.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.466 |  Acc: 45.480,63.830,70.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.115 |  Acc: 49.700,74.340,87.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.431 |  Acc: 45.470,64.110,70.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.115 |  Acc: 49.326,74.080,88.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.432 |  Acc: 45.300,64.230,70.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.101 |  Acc: 49.810,74.398,88.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.451 |  Acc: 45.500,64.080,70.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.076 |  Acc: 49.892,74.688,88.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.422 |  Acc: 45.970,63.970,70.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.078 |  Acc: 49.670,74.468,88.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.525 |  Acc: 45.250,63.030,69.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 3.065 |  Acc: 49.688,74.686,88.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.508 |  Acc: 44.860,63.800,69.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 3.046 |  Acc: 49.620,74.734,89.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.484 |  Acc: 45.340,63.890,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 3.045 |  Acc: 49.410,74.826,89.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.457 |  Acc: 45.780,64.160,69.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 3.028 |  Acc: 49.858,74.904,89.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.509 |  Acc: 45.200,63.790,69.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 3.013 |  Acc: 50.042,75.248,89.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.509 |  Acc: 45.500,63.480,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 3.013 |  Acc: 50.076,75.044,89.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.548 |  Acc: 45.210,63.540,69.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 3.003 |  Acc: 50.012,75.084,89.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.545 |  Acc: 45.370,63.830,69.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 2.991 |  Acc: 49.910,75.182,89.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.580 |  Acc: 45.430,63.620,69.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 3.000 |  Acc: 49.772,75.090,89.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.586 |  Acc: 45.360,63.100,69.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.983 |  Acc: 50.368,75.218,89.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.602 |  Acc: 44.850,63.540,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.979 |  Acc: 49.896,75.352,90.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.573 |  Acc: 44.910,63.760,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.965 |  Acc: 50.030,75.282,90.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.603 |  Acc: 45.030,63.370,68.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.955 |  Acc: 49.988,75.596,90.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.498 |  Acc: 45.550,64.100,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.953 |  Acc: 50.006,75.510,90.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.575 |  Acc: 45.590,63.580,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.951 |  Acc: 50.122,75.458,90.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.608 |  Acc: 45.510,63.550,69.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.938 |  Acc: 50.138,75.766,90.614,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.540 |  Acc: 46.050,63.580,69.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.943 |  Acc: 50.064,75.532,90.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.589 |  Acc: 45.390,63.530,69.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.937 |  Acc: 50.022,75.756,90.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.563 |  Acc: 45.760,64.000,69.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.917 |  Acc: 50.362,75.628,90.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.577 |  Acc: 45.490,63.480,68.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.933 |  Acc: 50.032,75.620,90.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.635 |  Acc: 44.760,62.910,69.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.907 |  Acc: 50.346,76.024,90.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.656 |  Acc: 45.100,63.040,68.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.908 |  Acc: 50.248,75.912,90.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.544 |  Acc: 46.060,64.450,69.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.894 |  Acc: 50.202,75.978,91.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.735 |  Acc: 44.370,62.390,68.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.908 |  Acc: 50.268,75.986,91.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.872 |  Acc: 43.110,62.280,67.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.902 |  Acc: 50.266,76.180,90.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.736 |  Acc: 45.160,62.930,68.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.900 |  Acc: 50.492,76.162,91.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.603 |  Acc: 45.910,63.250,69.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.897 |  Acc: 50.060,75.966,91.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.682 |  Acc: 44.990,63.000,68.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.882 |  Acc: 50.578,76.296,91.322,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.681 |  Acc: 44.510,63.150,68.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.876 |  Acc: 50.434,76.016,91.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.703 |  Acc: 44.690,63.480,68.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.875 |  Acc: 50.356,76.206,91.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.757 |  Acc: 44.730,62.570,68.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.880 |  Acc: 50.182,76.258,91.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.654 |  Acc: 45.310,63.280,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.877 |  Acc: 50.252,76.358,91.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.650 |  Acc: 45.840,63.530,68.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.864 |  Acc: 50.622,76.490,91.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.776 |  Acc: 44.690,62.050,68.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.864 |  Acc: 50.572,76.344,91.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.713 |  Acc: 44.890,62.900,68.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.864 |  Acc: 50.266,76.216,91.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.787 |  Acc: 44.700,63.160,68.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.854 |  Acc: 50.396,76.432,91.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.729 |  Acc: 45.100,63.230,69.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.847 |  Acc: 50.342,76.682,91.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.707 |  Acc: 45.470,63.290,68.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.854 |  Acc: 50.266,76.452,91.654,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.734 |  Acc: 44.920,62.990,68.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.845 |  Acc: 50.436,76.576,91.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.722 |  Acc: 45.640,63.080,68.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.839 |  Acc: 50.502,76.598,91.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.760 |  Acc: 45.120,62.300,67.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.845 |  Acc: 50.490,76.688,91.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.773 |  Acc: 44.330,62.730,68.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.850 |  Acc: 50.548,76.688,91.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.869 |  Acc: 44.630,61.860,67.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.836 |  Acc: 50.416,76.726,91.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.678 |  Acc: 45.460,63.860,68.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.844 |  Acc: 50.550,76.588,91.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.977 |  Acc: 42.860,61.210,67.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.835 |  Acc: 50.556,76.728,91.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.890 |  Acc: 44.360,62.380,67.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.836 |  Acc: 50.632,76.754,91.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.884 |  Acc: 44.190,61.700,67.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.834 |  Acc: 50.554,76.678,92.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.929 |  Acc: 43.550,61.530,67.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.822 |  Acc: 50.390,76.850,91.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.781 |  Acc: 45.360,62.790,67.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.822 |  Acc: 50.602,76.862,91.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.873 |  Acc: 44.560,61.260,67.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.823 |  Acc: 50.508,76.780,91.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.826 |  Acc: 44.370,62.810,67.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.828 |  Acc: 50.576,76.764,91.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.867 |  Acc: 44.730,62.990,67.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.816 |  Acc: 50.608,76.736,92.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.907 |  Acc: 43.530,61.630,67.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.811 |  Acc: 50.678,76.948,92.230,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.791 |  Acc: 44.610,62.770,68.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.819 |  Acc: 50.644,77.010,91.914,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.715 |  Acc: 45.930,63.470,68.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.819 |  Acc: 50.818,76.988,91.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.774 |  Acc: 44.820,62.270,68.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.823 |  Acc: 50.488,76.646,91.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.857 |  Acc: 44.130,62.030,67.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.812 |  Acc: 50.714,76.980,92.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.967 |  Acc: 43.630,61.450,66.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.806 |  Acc: 50.696,77.004,92.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.988 |  Acc: 42.460,61.880,67.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.665 |  Acc: 51.376,79.014,93.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.535 |  Acc: 47.110,64.620,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.607 |  Acc: 51.868,79.802,94.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.552 |  Acc: 47.070,64.510,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.589 |  Acc: 52.044,79.880,94.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.534 |  Acc: 47.100,64.810,69.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.582 |  Acc: 52.120,79.968,95.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.532 |  Acc: 47.290,64.560,69.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.579 |  Acc: 51.956,80.098,95.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.540 |  Acc: 47.180,64.710,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.572 |  Acc: 52.078,80.148,95.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.552 |  Acc: 47.230,64.740,69.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.571 |  Acc: 52.152,80.074,95.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.540 |  Acc: 47.380,64.680,69.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.559 |  Acc: 52.276,80.346,95.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.559 |  Acc: 47.160,64.650,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.557 |  Acc: 52.330,80.202,95.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.547 |  Acc: 47.130,64.690,69.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.555 |  Acc: 52.022,80.228,95.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.543 |  Acc: 47.180,64.760,69.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.557 |  Acc: 52.052,80.148,95.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.566 |  Acc: 47.080,64.570,69.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.543 |  Acc: 52.182,80.258,95.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.579 |  Acc: 47.240,64.410,69.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.541 |  Acc: 52.104,80.532,95.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.569 |  Acc: 47.160,64.670,69.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.544 |  Acc: 52.112,80.534,95.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.556 |  Acc: 47.370,64.720,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.544 |  Acc: 52.006,80.508,95.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.571 |  Acc: 47.250,64.340,69.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.539 |  Acc: 52.198,80.380,95.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.569 |  Acc: 47.440,64.540,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.537 |  Acc: 52.296,80.614,95.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.582 |  Acc: 46.780,64.260,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.539 |  Acc: 52.038,80.370,95.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.570 |  Acc: 47.000,64.630,69.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.539 |  Acc: 52.070,80.582,95.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.576 |  Acc: 47.280,64.570,69.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.536 |  Acc: 52.128,80.596,95.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.586 |  Acc: 47.230,64.510,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.530 |  Acc: 52.310,80.848,95.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.585 |  Acc: 47.180,64.320,69.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.534 |  Acc: 52.122,80.430,96.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.573 |  Acc: 47.170,64.680,69.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.531 |  Acc: 52.310,80.784,95.986,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.581 |  Acc: 47.200,64.570,69.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.528 |  Acc: 52.334,80.714,95.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.582 |  Acc: 47.270,64.620,69.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.517 |  Acc: 52.120,80.654,96.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.581 |  Acc: 47.190,64.470,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.518 |  Acc: 52.322,80.748,95.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.577 |  Acc: 47.400,64.310,69.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.523 |  Acc: 52.132,80.828,96.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.580 |  Acc: 47.390,64.760,69.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.516 |  Acc: 52.326,80.874,96.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.587 |  Acc: 47.090,64.370,69.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.522 |  Acc: 52.082,80.764,95.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.582 |  Acc: 47.310,64.380,69.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.520 |  Acc: 52.202,80.838,95.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.585 |  Acc: 47.190,64.490,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.523 |  Acc: 52.270,80.598,95.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.619 |  Acc: 47.190,64.230,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.519 |  Acc: 52.224,80.616,96.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.601 |  Acc: 47.180,64.560,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.510 |  Acc: 52.402,80.870,96.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.584 |  Acc: 47.270,64.620,69.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.509 |  Acc: 52.266,80.794,96.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.596 |  Acc: 47.380,64.450,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.515 |  Acc: 52.228,80.780,96.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.597 |  Acc: 47.160,64.560,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.518 |  Acc: 52.102,80.792,96.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.592 |  Acc: 47.010,64.240,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.513 |  Acc: 52.300,80.982,96.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.597 |  Acc: 47.030,64.510,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.496 |  Acc: 52.470,81.174,96.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.601 |  Acc: 47.210,64.250,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.481 |  Acc: 52.518,81.208,96.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.601 |  Acc: 47.250,64.540,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.497 |  Acc: 52.410,81.148,96.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.613 |  Acc: 47.100,64.600,69.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.483 |  Acc: 52.368,81.224,96.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.605 |  Acc: 47.060,64.440,69.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.483 |  Acc: 52.682,81.344,96.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.608 |  Acc: 47.300,64.530,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.488 |  Acc: 52.524,81.248,96.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.592 |  Acc: 47.180,64.450,69.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.500 |  Acc: 52.432,81.040,96.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.608 |  Acc: 47.240,64.290,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.490 |  Acc: 52.546,81.142,96.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.604 |  Acc: 47.250,64.370,69.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.487 |  Acc: 52.316,81.060,96.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.599 |  Acc: 47.250,64.490,69.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.487 |  Acc: 52.536,81.290,96.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.595 |  Acc: 47.180,64.420,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.487 |  Acc: 52.490,81.206,96.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.590 |  Acc: 47.230,64.690,69.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.479 |  Acc: 52.540,81.280,96.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.591 |  Acc: 47.360,64.400,69.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.489 |  Acc: 52.220,81.092,96.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.599 |  Acc: 47.290,64.580,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.488 |  Acc: 52.538,81.220,96.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.594 |  Acc: 47.340,64.510,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.486 |  Acc: 52.420,81.198,96.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.599 |  Acc: 47.210,64.440,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.487 |  Acc: 52.356,81.298,96.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.614 |  Acc: 47.050,64.350,69.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.487 |  Acc: 52.316,81.330,96.394,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.597 |  Acc: 47.470,64.430,69.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.482 |  Acc: 52.392,81.166,96.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.601 |  Acc: 47.310,64.460,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.487 |  Acc: 52.374,81.120,96.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.595 |  Acc: 47.320,64.710,69.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.487 |  Acc: 52.502,81.308,96.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.590 |  Acc: 47.340,64.490,69.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.485 |  Acc: 52.626,81.142,96.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.595 |  Acc: 47.340,64.450,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.492 |  Acc: 52.390,80.994,96.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.602 |  Acc: 47.320,64.540,69.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.488 |  Acc: 52.362,81.142,96.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.603 |  Acc: 47.450,64.300,69.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.486 |  Acc: 52.262,81.258,96.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.598 |  Acc: 47.210,64.330,69.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.482 |  Acc: 52.602,81.334,96.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.601 |  Acc: 47.240,64.370,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.483 |  Acc: 52.524,81.286,96.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.599 |  Acc: 47.400,64.390,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.480 |  Acc: 52.520,81.260,96.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.595 |  Acc: 47.230,64.420,69.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.489 |  Acc: 52.314,81.400,96.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.605 |  Acc: 47.460,64.610,69.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.489 |  Acc: 52.362,81.290,96.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.601 |  Acc: 47.450,64.580,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.480 |  Acc: 52.456,81.498,96.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.582 |  Acc: 47.520,64.420,69.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.481 |  Acc: 52.466,81.562,96.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.613 |  Acc: 47.290,64.330,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.484 |  Acc: 52.660,81.150,96.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.587 |  Acc: 47.330,64.490,69.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.482 |  Acc: 52.396,81.374,96.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.589 |  Acc: 47.490,64.420,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.482 |  Acc: 52.452,81.356,96.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.618 |  Acc: 47.100,64.420,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.481 |  Acc: 52.586,81.430,96.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.589 |  Acc: 47.300,64.530,69.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.491 |  Acc: 52.380,81.202,96.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.601 |  Acc: 47.410,64.480,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.483 |  Acc: 52.278,81.374,96.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.588 |  Acc: 47.450,64.580,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='scan', backend='resnet56_2con3_att', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.483 |  Acc: 52.350,81.350,96.522,% | Adaptive Acc:86.638% | clf_exit: 0.365 0.432 0.202
Testing: Epoch=299 | Loss: 4.596 |  Acc: 47.390,64.250,69.280,% | Adaptive Acc:63.540% | clf_exit: 0.433 0.359 0.208

circles: 0
Testing: Epoch=299 | Loss: 10.803 |  Acc: 47.390,11.320,13.950,% | Adaptive Acc:37.140% | clf_exit: 0.433 0.168 0.398
circles: 1
Testing: Epoch=299 | Loss: 8.415 |  Acc: 47.390,20.730,39.810,% | Adaptive Acc:45.880% | clf_exit: 0.433 0.194 0.372
circles: 2
Testing: Epoch=299 | Loss: 6.544 |  Acc: 47.390,37.410,57.350,% | Adaptive Acc:54.020% | clf_exit: 0.433 0.207 0.359
circles: 3
Testing: Epoch=299 | Loss: 5.263 |  Acc: 47.390,53.420,65.390,% | Adaptive Acc:59.730% | clf_exit: 0.433 0.257 0.309
circles: 4
Testing: Epoch=299 | Loss: 4.645 |  Acc: 47.390,61.850,68.750,% | Adaptive Acc:62.720% | clf_exit: 0.433 0.316 0.250
circles: 5
Testing: Epoch=299 | Loss: 4.596 |  Acc: 47.390,64.250,69.280,% | Adaptive Acc:63.540% | clf_exit: 0.433 0.359 0.208
