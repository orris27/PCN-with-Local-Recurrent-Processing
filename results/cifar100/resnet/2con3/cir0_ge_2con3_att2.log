==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=16, out_features=16, bias=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (BN1d): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=48, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (attention): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=16, out_features=4, bias=True)
          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=4, out_features=16, bias=True)
          (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=96, out_features=100, bias=True)
      (attention): LinearLayer(
        (attention): Sequential(
          (0): Linear(in_features=32, out_features=8, bias=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=8, out_features=32, bias=True)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Sigmoid()
        )
      )
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.245 | Acc: 0.000,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.890 | Acc: 0.856,0.893,1.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.589 | Acc: 0.915,0.991,1.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.405 | Acc: 1.025,1.050,1.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.263 | Acc: 1.215,1.119,1.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.181 | Acc: 1.222,1.315,2.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 14.120 | Acc: 1.207,1.440,2.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 14.059 | Acc: 1.319,1.490,2.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 14.015 | Acc: 1.344,1.504,2.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.966 | Acc: 1.394,1.610,2.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.919 | Acc: 1.415,1.737,3.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.870 | Acc: 1.460,1.983,3.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.822 | Acc: 1.488,2.143,3.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.778 | Acc: 1.548,2.299,3.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.736 | Acc: 1.596,2.408,3.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.690 | Acc: 1.627,2.497,4.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.642 | Acc: 1.689,2.665,4.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.599 | Acc: 1.748,2.765,4.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.560 | Acc: 1.783,2.867,4.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.520 | Acc: 1.856,2.945,5.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.780 | Acc: 1.562,3.125,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.789 | Acc: 3.423,5.878,9.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.757 | Acc: 3.335,5.640,9.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.767 | Acc: 3.407,5.302,9.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 12.456 | Acc: 6.250,5.469,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.695 | Acc: 3.013,5.022,9.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.674 | Acc: 3.449,5.393,10.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.645 | Acc: 3.548,5.699,10.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.638 | Acc: 3.559,5.806,10.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.610 | Acc: 3.566,6.026,10.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.573 | Acc: 3.583,6.114,10.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.556 | Acc: 3.541,6.228,10.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.535 | Acc: 3.503,6.269,11.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.512 | Acc: 3.431,6.444,11.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.494 | Acc: 3.432,6.514,11.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.463 | Acc: 3.454,6.748,11.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.440 | Acc: 3.498,6.872,11.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.419 | Acc: 3.514,7.004,11.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.392 | Acc: 3.567,7.162,11.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.365 | Acc: 3.556,7.301,12.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.346 | Acc: 3.614,7.382,12.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.325 | Acc: 3.622,7.478,12.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.296 | Acc: 3.673,7.644,12.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.273 | Acc: 3.714,7.751,12.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.695 | Acc: 1.562,10.938,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.875 | Acc: 4.353,10.082,14.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.851 | Acc: 4.478,10.137,14.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.869 | Acc: 4.290,10.131,14.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 11.701 | Acc: 4.688,10.156,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.853 | Acc: 5.022,9.747,15.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.761 | Acc: 4.630,10.194,16.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.738 | Acc: 4.636,10.092,16.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.716 | Acc: 4.601,10.349,16.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.708 | Acc: 4.703,10.288,16.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.684 | Acc: 4.778,10.595,16.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.667 | Acc: 4.887,10.694,16.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.652 | Acc: 4.984,10.792,16.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.631 | Acc: 5.011,10.942,16.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.618 | Acc: 5.092,11.042,16.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.591 | Acc: 5.182,11.157,16.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.577 | Acc: 5.193,11.158,17.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.553 | Acc: 5.271,11.306,17.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.533 | Acc: 5.371,11.441,17.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.508 | Acc: 5.464,11.594,17.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.494 | Acc: 5.471,11.631,17.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.474 | Acc: 5.508,11.760,17.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.454 | Acc: 5.549,11.792,17.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.436 | Acc: 5.602,11.879,17.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.463 | Acc: 2.344,8.594,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.550 | Acc: 5.841,10.975,15.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.493 | Acc: 6.079,11.833,16.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.503 | Acc: 5.968,11.744,16.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 11.027 | Acc: 3.906,13.281,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.010 | Acc: 6.548,14.249,20.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.005 | Acc: 6.860,14.748,20.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.997 | Acc: 6.916,14.511,20.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.989 | Acc: 6.944,14.477,20.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.953 | Acc: 6.969,14.558,21.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.945 | Acc: 6.883,14.502,20.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.929 | Acc: 6.976,14.605,20.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.924 | Acc: 6.988,14.621,20.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.896 | Acc: 7.018,14.719,20.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.860 | Acc: 7.175,15.007,21.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.847 | Acc: 7.300,15.052,21.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.844 | Acc: 7.359,15.016,21.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.823 | Acc: 7.411,15.164,21.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.812 | Acc: 7.496,15.189,21.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.790 | Acc: 7.719,15.381,21.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.773 | Acc: 7.791,15.508,21.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.765 | Acc: 7.865,15.581,21.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.746 | Acc: 7.981,15.690,21.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.724 | Acc: 8.048,15.797,21.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.183 | Acc: 7.031,18.750,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.660 | Acc: 8.519,15.104,22.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.624 | Acc: 8.384,15.511,22.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.627 | Acc: 8.414,15.318,22.272,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 10.183 | Acc: 10.938,17.969,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.274 | Acc: 10.677,17.708,23.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.278 | Acc: 10.518,17.588,24.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.288 | Acc: 10.438,17.277,24.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.264 | Acc: 10.301,17.728,24.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.265 | Acc: 10.187,17.683,24.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.266 | Acc: 10.331,17.743,24.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.256 | Acc: 10.417,17.825,24.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.262 | Acc: 10.355,17.712,24.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.246 | Acc: 10.376,18.003,24.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.225 | Acc: 10.393,18.089,24.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.213 | Acc: 10.428,18.241,24.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.200 | Acc: 10.477,18.270,24.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.189 | Acc: 10.375,18.355,25.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.178 | Acc: 10.409,18.475,25.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.168 | Acc: 10.418,18.540,25.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.150 | Acc: 10.490,18.650,25.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.139 | Acc: 10.511,18.787,25.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.121 | Acc: 10.593,18.962,25.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.110 | Acc: 10.677,19.138,25.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.036 | Acc: 8.594,21.094,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.410 | Acc: 9.524,18.006,24.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.334 | Acc: 9.280,18.921,24.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.341 | Acc: 9.362,18.468,24.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 9.852 | Acc: 11.719,18.750,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.773 | Acc: 11.644,21.280,28.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.735 | Acc: 12.195,21.665,28.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.707 | Acc: 12.449,22.029,29.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.678 | Acc: 12.452,21.885,28.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.685 | Acc: 12.523,21.929,28.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.682 | Acc: 12.565,22.004,28.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.661 | Acc: 12.511,22.036,28.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.665 | Acc: 12.471,21.880,28.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.648 | Acc: 12.543,22.004,29.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.641 | Acc: 12.675,22.015,28.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.639 | Acc: 12.659,22.087,28.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.633 | Acc: 12.707,21.979,28.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.621 | Acc: 12.802,22.025,29.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.612 | Acc: 12.873,22.095,29.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.601 | Acc: 12.936,22.223,29.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.596 | Acc: 12.965,22.218,29.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.584 | Acc: 13.045,22.258,29.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.576 | Acc: 13.084,22.247,29.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.567 | Acc: 13.164,22.271,29.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.656 | Acc: 11.719,24.219,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.703 | Acc: 12.537,20.833,28.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.637 | Acc: 12.443,21.322,28.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.660 | Acc: 12.474,21.209,28.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 9.147 | Acc: 11.719,17.969,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.323 | Acc: 13.504,22.582,29.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.258 | Acc: 14.672,23.761,30.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.288 | Acc: 14.716,23.566,30.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.268 | Acc: 14.352,23.669,30.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.248 | Acc: 14.705,24.064,31.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.251 | Acc: 14.682,24.038,31.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.260 | Acc: 14.556,24.014,31.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.227 | Acc: 14.863,24.267,31.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.207 | Acc: 15.029,24.426,31.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.195 | Acc: 15.162,24.642,31.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.191 | Acc: 15.183,24.590,31.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.177 | Acc: 15.255,24.763,31.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.165 | Acc: 15.392,24.880,31.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.164 | Acc: 15.436,24.889,31.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.158 | Acc: 15.524,24.883,31.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.150 | Acc: 15.581,24.934,32.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.129 | Acc: 15.630,25.066,32.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.114 | Acc: 15.705,25.141,32.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.103 | Acc: 15.777,25.232,32.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.756 | Acc: 14.844,21.094,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.978 | Acc: 12.016,20.908,28.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.863 | Acc: 11.547,20.922,29.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.866 | Acc: 11.757,20.556,28.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 8.813 | Acc: 18.750,17.188,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.780 | Acc: 16.815,27.009,34.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.809 | Acc: 16.482,26.353,33.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.820 | Acc: 16.995,27.049,33.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.819 | Acc: 17.081,27.170,34.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.810 | Acc: 17.133,26.779,34.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.799 | Acc: 17.342,26.834,34.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.789 | Acc: 17.282,26.845,34.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.780 | Acc: 17.314,27.019,34.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.786 | Acc: 17.287,27.007,34.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.778 | Acc: 17.417,27.079,34.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.764 | Acc: 17.417,27.015,34.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.751 | Acc: 17.589,26.984,34.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.737 | Acc: 17.681,27.092,34.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.734 | Acc: 17.752,27.049,34.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.725 | Acc: 17.831,27.154,34.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.717 | Acc: 17.881,27.188,34.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.709 | Acc: 17.944,27.344,34.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.702 | Acc: 17.982,27.404,34.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.701 | Acc: 17.985,27.424,34.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.316 | Acc: 15.625,27.344,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.348 | Acc: 15.811,23.251,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.333 | Acc: 15.835,24.066,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.341 | Acc: 16.291,23.873,29.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 8.452 | Acc: 24.219,30.469,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.514 | Acc: 17.820,27.716,36.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.543 | Acc: 18.674,27.801,35.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.556 | Acc: 18.699,27.485,35.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.518 | Acc: 19.117,28.057,36.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.495 | Acc: 19.199,28.628,36.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.468 | Acc: 19.447,29.074,36.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.446 | Acc: 19.620,29.289,36.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.442 | Acc: 19.667,29.188,36.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.432 | Acc: 19.669,29.152,36.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.417 | Acc: 19.679,29.163,36.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.411 | Acc: 19.842,29.228,37.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.407 | Acc: 19.888,29.269,37.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.397 | Acc: 19.923,29.322,37.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.388 | Acc: 19.926,29.396,37.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.387 | Acc: 19.954,29.467,37.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.378 | Acc: 19.972,29.522,37.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.372 | Acc: 20.058,29.598,37.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.366 | Acc: 20.079,29.690,37.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.354 | Acc: 20.151,29.815,37.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.927 | Acc: 20.312,28.125,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.750 | Acc: 17.150,27.083,37.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.735 | Acc: 17.454,27.229,36.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.743 | Acc: 17.367,27.216,36.373,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 8.386 | Acc: 20.312,24.219,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.023 | Acc: 21.912,32.366,39.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.054 | Acc: 21.665,32.260,40.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.054 | Acc: 21.709,31.993,39.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.049 | Acc: 21.856,31.993,40.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.070 | Acc: 21.937,31.861,40.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.060 | Acc: 21.668,31.921,39.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.077 | Acc: 21.454,31.876,39.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.091 | Acc: 21.380,31.726,39.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.094 | Acc: 21.482,31.686,39.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.091 | Acc: 21.529,31.588,39.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.087 | Acc: 21.490,31.607,39.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.087 | Acc: 21.437,31.561,39.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.075 | Acc: 21.459,31.642,39.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.066 | Acc: 21.575,31.789,39.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.063 | Acc: 21.615,31.774,39.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.060 | Acc: 21.639,31.727,39.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.060 | Acc: 21.669,31.694,39.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.051 | Acc: 21.656,31.808,39.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.053 | Acc: 21.676,31.836,39.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.789 | Acc: 23.438,31.250,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.281 | Acc: 19.680,29.129,39.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.273 | Acc: 19.684,28.735,38.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.273 | Acc: 19.454,29.009,38.845,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 8.730 | Acc: 19.531,26.562,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.869 | Acc: 21.763,32.738,42.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.849 | Acc: 22.256,32.870,41.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.827 | Acc: 22.426,32.941,41.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.848 | Acc: 22.328,32.899,41.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.867 | Acc: 22.300,32.820,41.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.851 | Acc: 22.566,33.071,41.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.828 | Acc: 22.529,33.223,41.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.819 | Acc: 22.549,33.201,41.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.823 | Acc: 22.479,33.205,41.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.826 | Acc: 22.431,33.275,41.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.823 | Acc: 22.384,33.304,41.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.818 | Acc: 22.361,33.328,41.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.819 | Acc: 22.429,33.318,41.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.824 | Acc: 22.431,33.266,41.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.822 | Acc: 22.436,33.132,41.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.820 | Acc: 22.462,33.204,41.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.814 | Acc: 22.487,33.376,41.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.820 | Acc: 22.492,33.299,41.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.820 | Acc: 22.511,33.286,41.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.648 | Acc: 16.406,32.031,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.685 | Acc: 19.122,28.609,37.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.649 | Acc: 19.417,28.411,37.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.674 | Acc: 19.083,28.189,37.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 7.398 | Acc: 25.000,35.156,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.507 | Acc: 25.372,35.900,44.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.589 | Acc: 24.181,35.004,43.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.637 | Acc: 23.988,34.580,42.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.641 | Acc: 23.794,34.828,42.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.640 | Acc: 23.917,34.692,42.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.614 | Acc: 23.909,34.498,42.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.600 | Acc: 24.174,34.813,42.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.612 | Acc: 24.102,34.569,42.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.602 | Acc: 24.171,34.707,42.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.615 | Acc: 24.063,34.589,42.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.612 | Acc: 24.145,34.594,42.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.598 | Acc: 24.216,34.783,42.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.592 | Acc: 24.201,34.788,42.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.593 | Acc: 24.188,34.839,43.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.583 | Acc: 24.245,34.866,43.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.589 | Acc: 24.238,34.903,43.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.589 | Acc: 24.226,34.872,43.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.586 | Acc: 24.204,34.994,43.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.578 | Acc: 24.229,35.027,43.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.060 | Acc: 17.969,32.812,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.019 | Acc: 19.754,32.254,41.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.019 | Acc: 19.760,32.317,41.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.040 | Acc: 19.659,31.929,41.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 7.414 | Acc: 28.125,34.375,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.367 | Acc: 25.484,36.012,47.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.333 | Acc: 25.114,36.795,46.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.330 | Acc: 24.757,36.898,45.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.318 | Acc: 25.174,37.008,45.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.336 | Acc: 25.186,36.696,45.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.360 | Acc: 25.187,36.551,44.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.386 | Acc: 25.050,36.514,44.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.382 | Acc: 25.078,36.631,44.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.389 | Acc: 25.147,36.581,44.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.392 | Acc: 25.167,36.594,44.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.382 | Acc: 25.212,36.609,44.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.382 | Acc: 25.185,36.628,44.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.387 | Acc: 25.063,36.584,44.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.379 | Acc: 25.131,36.580,44.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.373 | Acc: 25.189,36.560,44.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.373 | Acc: 25.214,36.609,45.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.372 | Acc: 25.181,36.655,45.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.367 | Acc: 25.214,36.691,45.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.367 | Acc: 25.127,36.706,45.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.960 | Acc: 21.094,36.719,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.191 | Acc: 19.606,30.618,42.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.164 | Acc: 18.960,30.678,42.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.209 | Acc: 18.712,30.277,42.316,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 6.861 | Acc: 28.125,50.781,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.115 | Acc: 26.451,39.397,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.177 | Acc: 25.972,37.995,48.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.181 | Acc: 25.756,37.795,47.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.146 | Acc: 26.312,38.050,48.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.144 | Acc: 26.354,38.103,47.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.162 | Acc: 26.349,37.732,47.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.170 | Acc: 26.263,37.655,47.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.166 | Acc: 26.121,37.767,47.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.199 | Acc: 25.954,37.573,46.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.203 | Acc: 25.882,37.543,46.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.206 | Acc: 25.947,37.564,46.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.210 | Acc: 26.018,37.575,46.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.205 | Acc: 25.982,37.644,46.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.206 | Acc: 25.906,37.658,46.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.207 | Acc: 25.828,37.692,46.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.213 | Acc: 25.859,37.651,46.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.206 | Acc: 25.903,37.731,46.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.208 | Acc: 25.944,37.809,46.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.200 | Acc: 25.984,37.838,46.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.996 | Acc: 16.406,26.562,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.837 | Acc: 17.969,28.720,38.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.816 | Acc: 17.893,28.754,38.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.843 | Acc: 17.815,29.034,38.525,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 7.659 | Acc: 22.656,38.281,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.077 | Acc: 26.823,38.914,48.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.022 | Acc: 26.620,39.272,48.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.033 | Acc: 26.524,39.267,48.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.007 | Acc: 26.562,39.381,48.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.020 | Acc: 26.795,39.418,48.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.004 | Acc: 26.911,39.560,48.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.025 | Acc: 26.973,39.240,48.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.034 | Acc: 26.761,39.223,48.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.041 | Acc: 26.645,39.231,48.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.055 | Acc: 26.555,39.129,48.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.047 | Acc: 26.520,39.176,48.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.039 | Acc: 26.569,39.205,48.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.039 | Acc: 26.560,39.161,48.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.038 | Acc: 26.590,39.154,48.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.031 | Acc: 26.625,39.286,48.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.034 | Acc: 26.684,39.274,48.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.031 | Acc: 26.716,39.317,48.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.029 | Acc: 26.792,39.383,48.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.040 | Acc: 26.755,39.304,48.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.026 | Acc: 30.469,40.625,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.679 | Acc: 24.740,35.193,44.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.676 | Acc: 24.829,34.909,43.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.670 | Acc: 24.488,34.529,43.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 7.027 | Acc: 29.688,39.844,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.888 | Acc: 27.083,41.109,48.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.941 | Acc: 26.715,40.644,48.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.949 | Acc: 27.011,40.305,49.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.951 | Acc: 27.363,40.172,49.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.930 | Acc: 27.506,40.053,49.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.926 | Acc: 27.583,40.147,48.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.919 | Acc: 27.576,40.104,48.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.914 | Acc: 27.577,40.154,49.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.909 | Acc: 27.508,40.167,49.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.900 | Acc: 27.639,40.388,49.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.886 | Acc: 27.662,40.409,49.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.890 | Acc: 27.684,40.427,49.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.889 | Acc: 27.727,40.353,49.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.888 | Acc: 27.636,40.353,49.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.892 | Acc: 27.518,40.394,49.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.890 | Acc: 27.524,40.401,49.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.884 | Acc: 27.660,40.469,49.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.880 | Acc: 27.725,40.560,49.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.886 | Acc: 27.674,40.566,49.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.230 | Acc: 25.000,29.688,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.163 | Acc: 24.702,32.515,40.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.130 | Acc: 24.867,32.241,40.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.144 | Acc: 24.321,31.801,39.985,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 7.318 | Acc: 22.656,29.688,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.879 | Acc: 27.009,40.290,49.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.802 | Acc: 28.087,41.654,49.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.765 | Acc: 27.754,41.650,50.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.788 | Acc: 27.614,41.638,50.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.790 | Acc: 27.529,41.453,50.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.788 | Acc: 27.802,41.600,50.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.788 | Acc: 27.831,41.367,50.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.785 | Acc: 27.984,41.460,50.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.796 | Acc: 27.987,41.346,50.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.787 | Acc: 28.020,41.410,50.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.776 | Acc: 28.167,41.597,50.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.769 | Acc: 28.167,41.711,50.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.768 | Acc: 28.098,41.771,50.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.768 | Acc: 28.175,41.901,50.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.768 | Acc: 28.172,41.894,50.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.760 | Acc: 28.286,41.910,50.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.762 | Acc: 28.315,41.901,50.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.756 | Acc: 28.378,41.975,50.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.753 | Acc: 28.353,41.987,50.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.842 | Acc: 26.562,34.375,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.992 | Acc: 23.103,32.738,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.957 | Acc: 23.152,32.984,42.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.965 | Acc: 23.220,32.761,42.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 6.744 | Acc: 22.656,37.500,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.651 | Acc: 27.679,42.522,51.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.597 | Acc: 28.849,43.407,51.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.613 | Acc: 28.343,43.033,52.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.619 | Acc: 28.578,42.969,52.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.621 | Acc: 28.651,42.961,52.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.610 | Acc: 28.984,42.969,52.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.633 | Acc: 28.945,42.936,52.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.627 | Acc: 29.047,42.944,52.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.609 | Acc: 29.161,43.223,52.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.611 | Acc: 29.093,43.097,52.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.612 | Acc: 29.062,43.054,52.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.613 | Acc: 29.004,43.030,52.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.619 | Acc: 28.999,42.912,52.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.628 | Acc: 28.798,42.841,52.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.630 | Acc: 28.792,42.777,52.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.633 | Acc: 28.816,42.820,51.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.633 | Acc: 28.789,42.820,51.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.631 | Acc: 28.874,42.854,51.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.631 | Acc: 28.900,42.854,51.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.533 | Acc: 25.000,39.844,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.517 | Acc: 22.731,36.384,47.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.531 | Acc: 22.713,36.242,46.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.536 | Acc: 22.515,36.309,46.849,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 6.434 | Acc: 31.250,42.969,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.540 | Acc: 28.534,44.345,53.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.493 | Acc: 28.849,44.055,53.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.515 | Acc: 28.714,44.032,53.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.525 | Acc: 28.511,44.165,52.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.520 | Acc: 28.682,44.144,52.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.521 | Acc: 28.855,44.008,52.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.501 | Acc: 29.150,44.193,53.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.498 | Acc: 29.173,44.235,53.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.489 | Acc: 29.221,44.389,53.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.494 | Acc: 29.233,44.337,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.500 | Acc: 29.196,44.277,52.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.507 | Acc: 29.250,44.269,52.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.518 | Acc: 29.194,44.076,52.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.525 | Acc: 29.201,44.053,52.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.518 | Acc: 29.220,44.074,52.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.511 | Acc: 29.259,44.076,52.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.513 | Acc: 29.289,43.954,52.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.507 | Acc: 29.276,43.960,52.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.508 | Acc: 29.261,43.963,52.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.755 | Acc: 29.688,42.188,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.091 | Acc: 21.094,35.082,44.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.082 | Acc: 20.903,34.204,44.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.017 | Acc: 20.671,34.362,45.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 6.710 | Acc: 30.469,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.505 | Acc: 29.390,43.973,52.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.494 | Acc: 28.982,44.360,52.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.468 | Acc: 29.329,44.224,53.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.429 | Acc: 29.244,44.358,53.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.431 | Acc: 29.347,44.740,53.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.415 | Acc: 29.642,44.809,53.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.401 | Acc: 29.588,44.936,53.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.406 | Acc: 29.581,45.016,53.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.399 | Acc: 29.605,45.127,53.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.388 | Acc: 29.551,45.215,54.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.387 | Acc: 29.691,45.277,54.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.399 | Acc: 29.561,45.189,53.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.410 | Acc: 29.699,45.106,53.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.418 | Acc: 29.707,44.998,53.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.420 | Acc: 29.729,44.957,53.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.424 | Acc: 29.709,44.930,53.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.425 | Acc: 29.603,44.932,53.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.425 | Acc: 29.668,44.955,53.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.426 | Acc: 29.638,44.915,53.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.440 | Acc: 27.344,36.719,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.505 | Acc: 22.545,37.760,47.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.495 | Acc: 22.275,37.348,46.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.477 | Acc: 22.490,37.372,46.785,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 6.296 | Acc: 28.125,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.233 | Acc: 29.985,47.656,55.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.224 | Acc: 29.516,47.409,55.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.229 | Acc: 29.636,47.093,55.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.227 | Acc: 29.794,47.039,55.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.227 | Acc: 30.376,47.192,55.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.256 | Acc: 30.139,46.810,55.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.264 | Acc: 30.131,46.775,55.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.271 | Acc: 30.144,46.661,55.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.280 | Acc: 30.231,46.564,55.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.286 | Acc: 30.309,46.587,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.286 | Acc: 30.352,46.387,55.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.267 | Acc: 30.472,46.518,55.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.283 | Acc: 30.379,46.312,54.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.295 | Acc: 30.363,46.286,54.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.310 | Acc: 30.284,46.192,54.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.316 | Acc: 30.147,46.155,54.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.316 | Acc: 30.153,46.156,54.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.308 | Acc: 30.196,46.219,54.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.316 | Acc: 30.157,46.135,54.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.504 | Acc: 25.000,42.188,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.507 | Acc: 24.963,37.872,46.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.510 | Acc: 25.019,37.614,46.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.502 | Acc: 24.360,37.628,46.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 6.458 | Acc: 29.688,40.625,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.218 | Acc: 30.580,46.577,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.221 | Acc: 30.583,46.761,55.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.189 | Acc: 30.866,46.785,56.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.212 | Acc: 30.613,46.663,56.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.242 | Acc: 30.391,46.357,55.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.221 | Acc: 30.385,46.584,55.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.243 | Acc: 30.142,46.432,55.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.239 | Acc: 30.163,46.429,55.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.244 | Acc: 30.180,46.499,55.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.240 | Acc: 30.243,46.525,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.228 | Acc: 30.317,46.649,55.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.233 | Acc: 30.355,46.599,55.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.244 | Acc: 30.322,46.546,55.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.235 | Acc: 30.402,46.705,55.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.230 | Acc: 30.412,46.750,55.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.230 | Acc: 30.413,46.773,55.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.229 | Acc: 30.439,46.733,55.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.228 | Acc: 30.512,46.773,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.228 | Acc: 30.549,46.834,55.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.843 | Acc: 27.344,38.281,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.850 | Acc: 24.479,35.863,47.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.902 | Acc: 24.238,35.252,46.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.891 | Acc: 23.450,34.862,46.324,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 6.366 | Acc: 34.375,46.094,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.010 | Acc: 32.924,48.586,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.104 | Acc: 32.660,47.523,55.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.097 | Acc: 32.262,47.477,56.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.123 | Acc: 31.838,47.232,56.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.108 | Acc: 31.761,47.432,56.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.101 | Acc: 31.702,47.527,56.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.107 | Acc: 31.666,47.496,56.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.115 | Acc: 31.565,47.341,56.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.133 | Acc: 31.276,47.233,55.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.139 | Acc: 31.157,47.221,55.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.137 | Acc: 31.204,47.246,55.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.135 | Acc: 31.347,47.202,55.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.135 | Acc: 31.343,47.162,55.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.133 | Acc: 31.328,47.281,55.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.132 | Acc: 31.286,47.308,55.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.135 | Acc: 31.277,47.238,55.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.133 | Acc: 31.300,47.301,55.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.138 | Acc: 31.248,47.282,55.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.141 | Acc: 31.273,47.347,55.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.314 | Acc: 28.906,39.844,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.226 | Acc: 25.037,40.439,48.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.264 | Acc: 24.981,39.329,47.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.308 | Acc: 24.654,38.896,47.080,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 5.453 | Acc: 33.594,54.688,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.906 | Acc: 31.287,49.665,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.015 | Acc: 30.812,49.200,57.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.046 | Acc: 30.418,48.348,56.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.036 | Acc: 30.575,48.524,57.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.052 | Acc: 30.531,48.252,57.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.048 | Acc: 30.856,48.069,56.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.052 | Acc: 30.962,48.027,56.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.059 | Acc: 31.022,47.933,56.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.057 | Acc: 31.233,47.846,56.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.048 | Acc: 31.242,47.959,56.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.053 | Acc: 31.151,47.918,56.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.050 | Acc: 31.114,48.000,56.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.050 | Acc: 31.151,48.066,56.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.058 | Acc: 31.114,48.037,56.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.070 | Acc: 31.058,48.004,56.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.071 | Acc: 31.082,48.038,56.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.070 | Acc: 31.053,48.082,56.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.066 | Acc: 31.194,48.115,56.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.067 | Acc: 31.227,48.087,56.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.636 | Acc: 27.344,42.188,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.767 | Acc: 28.683,42.671,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.785 | Acc: 28.220,42.378,50.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.783 | Acc: 28.010,42.623,50.768,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 6.172 | Acc: 25.000,48.438,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.940 | Acc: 30.878,49.070,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.934 | Acc: 31.555,49.638,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.912 | Acc: 32.198,49.757,58.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.987 | Acc: 31.655,49.035,57.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.976 | Acc: 31.683,49.296,57.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.977 | Acc: 31.605,49.122,57.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.995 | Acc: 31.488,48.908,57.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.002 | Acc: 31.740,48.840,57.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.991 | Acc: 31.984,48.981,57.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.006 | Acc: 32.004,48.912,57.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.012 | Acc: 31.844,48.865,57.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.997 | Acc: 31.992,49.005,57.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.993 | Acc: 32.004,49.102,57.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.990 | Acc: 32.056,49.057,57.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.998 | Acc: 32.029,48.988,57.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.999 | Acc: 32.077,48.961,57.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.005 | Acc: 32.054,48.898,57.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.003 | Acc: 32.094,48.883,57.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.005 | Acc: 32.017,48.786,57.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.684 | Acc: 29.688,41.406,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.278 | Acc: 23.735,40.402,50.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.360 | Acc: 23.152,40.149,48.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.368 | Acc: 22.746,40.138,49.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 7.146 | Acc: 29.688,43.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.884 | Acc: 33.519,50.112,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.902 | Acc: 32.527,49.447,59.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.895 | Acc: 31.749,49.411,59.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.896 | Acc: 32.031,49.190,59.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.897 | Acc: 32.085,49.180,58.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.886 | Acc: 32.231,49.309,58.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.891 | Acc: 32.031,49.296,58.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.897 | Acc: 31.944,49.306,58.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.895 | Acc: 31.954,49.383,58.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.900 | Acc: 31.895,49.382,58.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.903 | Acc: 31.886,49.215,58.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.905 | Acc: 32.031,49.365,58.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.907 | Acc: 32.061,49.300,58.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.899 | Acc: 32.148,49.405,58.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.909 | Acc: 32.148,49.398,58.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.914 | Acc: 32.204,49.370,58.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.918 | Acc: 32.144,49.402,58.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.919 | Acc: 32.202,49.459,58.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.925 | Acc: 32.165,49.438,57.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.028 | Acc: 24.219,39.844,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.344 | Acc: 18.490,34.970,45.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.350 | Acc: 17.797,35.385,45.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.300 | Acc: 17.252,35.220,45.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 6.028 | Acc: 28.906,50.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.741 | Acc: 31.585,50.967,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.787 | Acc: 31.326,50.000,59.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.800 | Acc: 31.724,50.320,59.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.808 | Acc: 31.780,50.530,59.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.819 | Acc: 31.884,50.596,59.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.828 | Acc: 32.096,50.439,59.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.835 | Acc: 31.992,50.460,58.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.835 | Acc: 32.060,50.543,58.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.838 | Acc: 32.027,50.626,58.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.826 | Acc: 32.090,50.797,58.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.821 | Acc: 32.342,50.718,58.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.826 | Acc: 32.197,50.690,58.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.829 | Acc: 32.217,50.694,58.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.838 | Acc: 32.251,50.589,58.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.842 | Acc: 32.260,50.610,58.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.844 | Acc: 32.163,50.535,58.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.844 | Acc: 32.185,50.463,58.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.838 | Acc: 32.284,50.511,58.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.833 | Acc: 32.365,50.550,58.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.025 | Acc: 28.906,39.844,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.859 | Acc: 25.818,43.452,51.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.898 | Acc: 25.724,42.931,49.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.905 | Acc: 25.986,42.815,50.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 5.504 | Acc: 35.156,52.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.677 | Acc: 31.920,50.372,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.800 | Acc: 31.707,49.657,60.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.744 | Acc: 32.620,51.114,60.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.735 | Acc: 32.899,51.109,60.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.769 | Acc: 32.704,50.673,60.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.751 | Acc: 32.722,50.839,60.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.773 | Acc: 32.785,50.803,59.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.783 | Acc: 32.934,50.820,59.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.795 | Acc: 32.860,50.794,59.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.794 | Acc: 32.937,50.917,59.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.794 | Acc: 32.940,50.884,59.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.782 | Acc: 32.994,50.898,59.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.781 | Acc: 33.091,50.877,59.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.781 | Acc: 33.141,50.904,59.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.786 | Acc: 33.033,50.784,59.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.790 | Acc: 33.000,50.803,59.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.795 | Acc: 33.016,50.756,59.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.802 | Acc: 33.044,50.736,59.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.807 | Acc: 33.011,50.703,59.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.312 | Acc: 33.594,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.650 | Acc: 28.646,46.019,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.582 | Acc: 28.830,45.979,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.579 | Acc: 28.151,45.940,55.136,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 4.993 | Acc: 36.719,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.711 | Acc: 33.259,51.451,60.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.657 | Acc: 33.784,52.553,61.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.697 | Acc: 33.376,51.934,61.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.688 | Acc: 33.073,51.659,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.696 | Acc: 33.277,51.408,60.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.711 | Acc: 33.252,51.033,60.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.724 | Acc: 32.923,50.887,60.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.714 | Acc: 33.016,51.077,60.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.727 | Acc: 33.076,51.032,60.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.713 | Acc: 33.123,51.088,60.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.733 | Acc: 33.032,51.061,59.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.734 | Acc: 33.127,51.086,59.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.739 | Acc: 33.136,51.003,59.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.740 | Acc: 33.157,51.020,59.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.735 | Acc: 33.238,51.020,59.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.736 | Acc: 33.241,51.000,59.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.729 | Acc: 33.317,51.052,59.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.736 | Acc: 33.280,50.993,59.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.740 | Acc: 33.198,50.980,59.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.484 | Acc: 27.344,42.188,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.356 | Acc: 23.958,41.034,52.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.426 | Acc: 24.276,40.244,51.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.439 | Acc: 23.809,40.484,51.319,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 5.852 | Acc: 27.344,49.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.358 | Acc: 34.226,55.171,63.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.461 | Acc: 33.937,54.021,62.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.490 | Acc: 33.965,53.599,62.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.530 | Acc: 34.230,53.048,61.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.584 | Acc: 33.950,52.700,61.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.602 | Acc: 33.826,52.428,61.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.613 | Acc: 33.788,52.355,60.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.631 | Acc: 33.599,52.276,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.638 | Acc: 33.637,52.206,60.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.643 | Acc: 33.644,52.142,60.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.657 | Acc: 33.622,52.001,60.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.650 | Acc: 33.675,52.120,60.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.647 | Acc: 33.702,52.080,60.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.645 | Acc: 33.816,52.110,60.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.659 | Acc: 33.679,51.903,60.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.663 | Acc: 33.618,51.840,60.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.661 | Acc: 33.672,51.865,60.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.661 | Acc: 33.678,51.816,60.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.666 | Acc: 33.678,51.798,60.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.260 | Acc: 37.500,53.125,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.713 | Acc: 28.274,43.638,51.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.684 | Acc: 28.316,43.864,52.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.675 | Acc: 27.894,44.416,52.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 5.458 | Acc: 35.938,54.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.593 | Acc: 33.371,52.121,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.509 | Acc: 34.566,52.515,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.561 | Acc: 33.837,51.742,60.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.594 | Acc: 33.632,51.833,60.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.594 | Acc: 33.748,51.864,61.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.605 | Acc: 33.652,51.827,61.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.584 | Acc: 33.948,51.995,61.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.604 | Acc: 33.890,51.810,60.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.616 | Acc: 33.857,51.666,60.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.631 | Acc: 33.909,51.601,60.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.625 | Acc: 34.110,51.725,60.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.626 | Acc: 34.138,51.695,60.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.635 | Acc: 34.139,51.682,60.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.639 | Acc: 34.064,51.718,60.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.632 | Acc: 34.097,51.775,60.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.640 | Acc: 34.025,51.728,60.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.633 | Acc: 34.118,51.872,60.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.625 | Acc: 34.193,51.943,60.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.635 | Acc: 34.084,51.901,60.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.087 | Acc: 26.562,42.188,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.254 | Acc: 23.586,43.043,52.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.253 | Acc: 24.047,42.283,51.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.289 | Acc: 23.630,42.136,51.460,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 5.494 | Acc: 37.500,54.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.467 | Acc: 34.896,53.013,63.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.475 | Acc: 34.527,53.106,63.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.530 | Acc: 34.452,52.894,62.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.534 | Acc: 34.452,53.144,62.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.554 | Acc: 34.375,52.970,61.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.570 | Acc: 34.117,52.686,61.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.568 | Acc: 34.386,52.815,61.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.558 | Acc: 34.482,53.004,61.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.559 | Acc: 34.315,53.078,61.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.572 | Acc: 34.332,52.876,61.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.585 | Acc: 34.287,52.619,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.574 | Acc: 34.330,52.587,61.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.568 | Acc: 34.360,52.712,61.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.569 | Acc: 34.389,52.752,61.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.568 | Acc: 34.461,52.712,61.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.568 | Acc: 34.429,52.680,61.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.567 | Acc: 34.444,52.678,61.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.568 | Acc: 34.446,52.649,61.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.566 | Acc: 34.420,52.655,61.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.252 | Acc: 25.000,42.969,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.768 | Acc: 23.214,38.244,48.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.731 | Acc: 23.628,37.576,48.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.785 | Acc: 22.989,36.757,48.040,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 5.666 | Acc: 32.031,48.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.379 | Acc: 35.305,53.013,62.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.403 | Acc: 35.480,53.754,62.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.378 | Acc: 35.566,54.355,63.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.422 | Acc: 35.118,53.723,62.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.457 | Acc: 34.940,53.434,62.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.485 | Acc: 34.653,53.015,62.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.487 | Acc: 34.763,53.186,62.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.475 | Acc: 34.812,53.363,62.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.485 | Acc: 34.720,53.242,62.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.505 | Acc: 34.503,53.032,61.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.502 | Acc: 34.555,53.072,61.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.510 | Acc: 34.612,53.109,61.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.513 | Acc: 34.614,53.155,61.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.515 | Acc: 34.661,53.103,61.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.516 | Acc: 34.712,53.019,61.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.519 | Acc: 34.682,52.964,61.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.526 | Acc: 34.682,52.905,61.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.529 | Acc: 34.659,52.919,61.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.528 | Acc: 34.691,52.971,61.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.427 | Acc: 32.812,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.412 | Acc: 30.990,46.838,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.436 | Acc: 30.507,45.522,54.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.478 | Acc: 29.956,45.620,54.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 4.567 | Acc: 38.281,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.396 | Acc: 35.268,54.725,62.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.383 | Acc: 35.213,54.440,62.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.395 | Acc: 35.182,54.201,62.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.421 | Acc: 35.137,53.906,62.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.429 | Acc: 34.901,53.813,62.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.428 | Acc: 35.021,53.661,62.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.422 | Acc: 34.940,53.557,62.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.439 | Acc: 34.986,53.542,62.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.436 | Acc: 35.143,53.695,62.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.463 | Acc: 34.915,53.335,62.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.476 | Acc: 34.877,53.153,62.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.494 | Acc: 34.783,53.083,61.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.497 | Acc: 34.716,53.080,61.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.501 | Acc: 34.684,52.980,61.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.491 | Acc: 34.806,53.094,61.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.493 | Acc: 34.791,53.147,61.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.495 | Acc: 34.785,53.118,61.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.500 | Acc: 34.682,53.112,61.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.505 | Acc: 34.668,53.123,61.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.510 | Acc: 24.219,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.496 | Acc: 23.624,43.527,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.525 | Acc: 23.457,42.912,51.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.552 | Acc: 23.309,42.585,51.076,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.247 | Acc: 34.375,61.719,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.243 | Acc: 35.751,56.622,65.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.270 | Acc: 36.071,56.460,64.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.309 | Acc: 35.476,55.610,64.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.317 | Acc: 35.532,55.363,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.350 | Acc: 35.435,54.773,63.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.371 | Acc: 35.466,54.449,63.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.372 | Acc: 35.350,54.394,63.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.372 | Acc: 35.549,54.387,63.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.382 | Acc: 35.484,54.221,63.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.400 | Acc: 35.444,53.996,62.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.407 | Acc: 35.397,53.927,62.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.415 | Acc: 35.335,53.848,62.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.421 | Acc: 35.291,53.772,62.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.422 | Acc: 35.315,53.809,62.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.428 | Acc: 35.185,53.670,62.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.429 | Acc: 35.188,53.699,62.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.436 | Acc: 35.172,53.698,62.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.438 | Acc: 35.111,53.683,62.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.446 | Acc: 35.039,53.621,62.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.319 | Acc: 25.781,37.500,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.004 | Acc: 27.083,42.820,52.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.079 | Acc: 26.810,42.245,51.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.094 | Acc: 26.729,42.021,51.742,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 5.525 | Acc: 35.156,52.344,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.339 | Acc: 35.007,54.390,63.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.354 | Acc: 35.175,54.973,63.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.372 | Acc: 35.195,54.726,62.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.390 | Acc: 34.963,54.620,62.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.368 | Acc: 35.087,54.533,63.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.353 | Acc: 35.208,54.584,63.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.340 | Acc: 35.212,54.743,63.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.356 | Acc: 35.190,54.513,62.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.357 | Acc: 35.303,54.459,62.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.367 | Acc: 35.304,54.380,62.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.365 | Acc: 35.276,54.507,62.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.376 | Acc: 35.279,54.409,62.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.378 | Acc: 35.255,54.439,62.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.384 | Acc: 35.137,54.376,62.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.387 | Acc: 35.154,54.366,62.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.387 | Acc: 35.205,54.378,62.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.397 | Acc: 35.110,54.250,62.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.405 | Acc: 35.031,54.136,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.418 | Acc: 34.945,53.974,62.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.772 | Acc: 22.656,39.062,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.503 | Acc: 22.768,39.955,48.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.645 | Acc: 22.542,39.253,48.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.661 | Acc: 22.246,39.344,48.309,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 5.502 | Acc: 41.406,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.373 | Acc: 36.161,56.138,62.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.433 | Acc: 34.527,54.935,62.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.373 | Acc: 35.489,55.008,63.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.354 | Acc: 35.639,55.179,63.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.355 | Acc: 35.566,55.221,63.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.346 | Acc: 35.628,55.146,63.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.355 | Acc: 35.550,54.815,63.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.354 | Acc: 35.515,54.814,63.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.353 | Acc: 35.493,54.852,63.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.355 | Acc: 35.522,54.894,63.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.343 | Acc: 35.616,54.917,63.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.346 | Acc: 35.630,54.898,63.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.353 | Acc: 35.668,54.858,63.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.347 | Acc: 35.732,54.991,63.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.361 | Acc: 35.613,54.854,63.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.362 | Acc: 35.597,54.836,63.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.369 | Acc: 35.601,54.823,63.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.379 | Acc: 35.520,54.718,63.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.379 | Acc: 35.472,54.729,63.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.475 | Acc: 32.812,39.844,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.164 | Acc: 28.348,41.629,49.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.188 | Acc: 27.896,41.311,49.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.171 | Acc: 27.574,41.099,49.629,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 6.058 | Acc: 38.281,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.288 | Acc: 35.156,54.018,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.265 | Acc: 35.976,54.611,63.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.303 | Acc: 35.220,54.649,63.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.283 | Acc: 35.417,55.150,63.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.274 | Acc: 35.466,55.391,64.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.277 | Acc: 35.466,55.604,64.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.295 | Acc: 35.278,55.208,63.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.307 | Acc: 35.321,55.139,63.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.330 | Acc: 35.221,54.852,63.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.334 | Acc: 35.222,54.874,63.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.337 | Acc: 35.248,54.790,63.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.335 | Acc: 35.296,54.807,63.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.333 | Acc: 35.494,54.828,63.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.337 | Acc: 35.579,54.768,63.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.343 | Acc: 35.416,54.729,63.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.346 | Acc: 35.448,54.743,63.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.344 | Acc: 35.472,54.678,63.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.338 | Acc: 35.466,54.685,63.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.350 | Acc: 35.388,54.597,62.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.602 | Acc: 30.469,47.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.575 | Acc: 29.167,45.647,54.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.537 | Acc: 29.478,45.922,54.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.560 | Acc: 28.817,45.492,54.201,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 5.757 | Acc: 25.781,50.000,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.143 | Acc: 36.310,57.254,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.133 | Acc: 36.719,56.841,66.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.127 | Acc: 36.501,56.634,66.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.177 | Acc: 35.889,56.134,66.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.185 | Acc: 35.821,55.886,65.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.199 | Acc: 35.821,55.740,65.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.233 | Acc: 35.699,55.424,65.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.236 | Acc: 35.870,55.299,64.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.240 | Acc: 35.834,55.322,64.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.257 | Acc: 35.782,55.255,64.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.277 | Acc: 35.754,55.101,64.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.274 | Acc: 35.811,55.096,64.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.285 | Acc: 35.761,54.984,64.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.290 | Acc: 35.646,54.952,64.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.290 | Acc: 35.613,54.973,64.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.302 | Acc: 35.592,54.885,63.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.300 | Acc: 35.640,54.903,63.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.310 | Acc: 35.643,54.874,63.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.320 | Acc: 35.579,54.755,63.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.282 | Acc: 31.250,39.844,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.025 | Acc: 25.707,43.899,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.032 | Acc: 25.572,44.646,54.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.998 | Acc: 25.269,44.096,54.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 5.821 | Acc: 32.031,50.781,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.241 | Acc: 35.454,55.506,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.135 | Acc: 37.367,56.174,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.139 | Acc: 37.001,56.749,65.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.188 | Acc: 36.429,56.510,65.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.207 | Acc: 36.177,56.180,64.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.211 | Acc: 36.306,56.224,64.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.215 | Acc: 36.298,56.134,64.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.237 | Acc: 36.214,55.876,64.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.232 | Acc: 36.149,55.788,64.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.236 | Acc: 36.140,55.644,64.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.234 | Acc: 36.093,55.642,64.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.235 | Acc: 36.103,55.589,64.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.241 | Acc: 36.120,55.606,64.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.240 | Acc: 36.149,55.669,64.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.253 | Acc: 36.088,55.580,64.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.264 | Acc: 36.030,55.561,64.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.275 | Acc: 35.938,55.446,63.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.281 | Acc: 35.901,55.404,63.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.285 | Acc: 35.812,55.409,63.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.317 | Acc: 22.656,33.594,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.074 | Acc: 22.879,37.723,47.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.204 | Acc: 21.780,37.233,47.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.227 | Acc: 21.632,37.462,47.439,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 5.272 | Acc: 39.062,56.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.101 | Acc: 36.830,56.994,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.134 | Acc: 36.890,56.574,65.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.156 | Acc: 36.693,56.519,65.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.158 | Acc: 36.429,56.086,65.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.186 | Acc: 36.100,55.747,64.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.197 | Acc: 36.073,55.675,64.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.197 | Acc: 36.087,55.823,64.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.195 | Acc: 36.287,55.755,64.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.198 | Acc: 36.425,55.818,64.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.205 | Acc: 36.330,55.795,64.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.211 | Acc: 36.249,55.822,64.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.208 | Acc: 36.284,55.842,64.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.215 | Acc: 36.207,55.678,64.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.239 | Acc: 36.079,55.427,64.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.244 | Acc: 36.013,55.342,63.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.247 | Acc: 35.940,55.298,63.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.253 | Acc: 35.889,55.324,63.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.252 | Acc: 35.918,55.330,63.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.252 | Acc: 35.999,55.379,63.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.593 | Acc: 27.344,42.188,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.466 | Acc: 29.985,46.317,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.542 | Acc: 30.335,45.941,53.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.557 | Acc: 30.251,45.389,52.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 5.018 | Acc: 35.938,57.031,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.194 | Acc: 36.533,56.213,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.184 | Acc: 36.700,55.774,64.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.172 | Acc: 36.360,56.301,65.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.215 | Acc: 36.217,55.835,64.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.206 | Acc: 36.154,55.856,64.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.217 | Acc: 36.267,55.804,64.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.211 | Acc: 36.364,55.990,64.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.209 | Acc: 36.340,56.032,64.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.207 | Acc: 36.417,56.021,65.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.216 | Acc: 36.369,56.036,64.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.224 | Acc: 36.157,55.904,64.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.214 | Acc: 36.333,56.052,64.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.208 | Acc: 36.279,56.097,64.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.212 | Acc: 36.332,56.055,64.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.217 | Acc: 36.265,55.923,64.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.221 | Acc: 36.300,55.870,64.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.220 | Acc: 36.313,55.835,64.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.223 | Acc: 36.308,55.865,64.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.229 | Acc: 36.270,55.776,64.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.276 | Acc: 30.469,49.219,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.872 | Acc: 25.856,45.424,54.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.837 | Acc: 25.667,45.236,54.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.843 | Acc: 25.141,45.248,53.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 4.847 | Acc: 31.250,54.688,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.143 | Acc: 35.677,55.022,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.074 | Acc: 36.966,56.669,66.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.094 | Acc: 36.975,56.788,66.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.154 | Acc: 36.410,56.269,65.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.165 | Acc: 36.239,56.080,65.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.167 | Acc: 36.344,55.947,65.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.165 | Acc: 36.447,56.039,65.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.158 | Acc: 36.476,56.036,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.165 | Acc: 36.339,55.991,65.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.164 | Acc: 36.326,55.982,65.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.160 | Acc: 36.280,56.020,65.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.166 | Acc: 36.349,55.916,65.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.169 | Acc: 36.339,55.864,65.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.181 | Acc: 36.302,55.802,64.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.191 | Acc: 36.252,55.656,64.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.198 | Acc: 36.191,55.615,64.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.191 | Acc: 36.283,55.712,64.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.187 | Acc: 36.336,55.787,64.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.184 | Acc: 36.389,55.758,64.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.671 | Acc: 17.969,38.281,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.268 | Acc: 20.945,38.356,48.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.181 | Acc: 21.132,39.367,49.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.208 | Acc: 21.260,39.588,49.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 5.371 | Acc: 33.594,56.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.067 | Acc: 35.751,57.775,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.013 | Acc: 36.338,58.308,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.068 | Acc: 35.771,57.287,66.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.065 | Acc: 36.169,57.552,66.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.063 | Acc: 36.394,57.426,66.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.072 | Acc: 36.486,57.354,66.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.072 | Acc: 36.469,57.170,65.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.092 | Acc: 36.428,56.968,65.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.108 | Acc: 36.386,56.790,65.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.133 | Acc: 36.322,56.627,65.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.139 | Acc: 36.284,56.543,65.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.142 | Acc: 36.411,56.526,65.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.150 | Acc: 36.288,56.466,65.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.144 | Acc: 36.382,56.556,65.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.139 | Acc: 36.462,56.663,65.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.138 | Acc: 36.509,56.727,65.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.139 | Acc: 36.574,56.756,65.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.143 | Acc: 36.563,56.648,65.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.151 | Acc: 36.528,56.566,65.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.605 | Acc: 25.000,44.531,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.405 | Acc: 26.488,40.179,51.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.325 | Acc: 26.620,40.816,51.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.329 | Acc: 26.729,41.060,51.409,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 4.576 | Acc: 38.281,54.688,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.150 | Acc: 37.165,56.920,64.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.138 | Acc: 37.024,56.936,66.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.119 | Acc: 36.322,56.609,66.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.111 | Acc: 36.613,56.588,66.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.094 | Acc: 36.634,56.536,66.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.084 | Acc: 36.661,56.670,66.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.086 | Acc: 36.669,56.632,66.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.091 | Acc: 36.758,56.595,66.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.107 | Acc: 36.632,56.505,66.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.114 | Acc: 36.567,56.472,66.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.123 | Acc: 36.500,56.391,65.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.135 | Acc: 36.414,56.334,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.137 | Acc: 36.386,56.295,65.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.138 | Acc: 36.452,56.372,65.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.139 | Acc: 36.532,56.424,65.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.137 | Acc: 36.592,56.479,65.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.137 | Acc: 36.595,56.452,65.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.142 | Acc: 36.671,56.417,65.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.148 | Acc: 36.528,56.365,65.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.919 | Acc: 30.469,42.188,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.181 | Acc: 25.000,43.750,52.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.173 | Acc: 25.457,43.502,51.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.150 | Acc: 25.231,43.712,51.921,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 4.874 | Acc: 35.156,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.100 | Acc: 35.565,57.031,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.031 | Acc: 36.052,57.793,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.079 | Acc: 36.270,57.108,66.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.084 | Acc: 36.545,57.195,66.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.072 | Acc: 36.750,57.047,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.095 | Acc: 36.732,56.863,66.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.100 | Acc: 36.885,57.070,66.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.080 | Acc: 37.029,57.148,66.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.086 | Acc: 37.051,57.036,66.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.104 | Acc: 36.793,56.732,65.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.112 | Acc: 36.800,56.642,65.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.111 | Acc: 36.741,56.600,65.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.121 | Acc: 36.728,56.489,65.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.130 | Acc: 36.660,56.420,65.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.129 | Acc: 36.745,56.390,65.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.129 | Acc: 36.763,56.454,65.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.138 | Acc: 36.703,56.374,65.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.142 | Acc: 36.706,56.345,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.143 | Acc: 36.776,56.314,65.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.866 | Acc: 28.906,40.625,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.173 | Acc: 25.260,43.415,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.169 | Acc: 25.114,43.598,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.215 | Acc: 24.872,43.263,54.355,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 4.705 | Acc: 38.281,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.025 | Acc: 37.016,56.994,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.027 | Acc: 38.053,57.107,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.073 | Acc: 37.551,56.519,66.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.048 | Acc: 37.500,56.887,66.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.029 | Acc: 37.539,56.938,66.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.072 | Acc: 37.242,56.702,66.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.075 | Acc: 37.273,56.682,66.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.061 | Acc: 37.340,56.774,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.076 | Acc: 37.137,56.703,66.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.083 | Acc: 37.107,56.701,65.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.088 | Acc: 37.076,56.671,65.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.094 | Acc: 37.033,56.658,65.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.086 | Acc: 37.126,56.756,65.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.083 | Acc: 37.189,56.817,65.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.084 | Acc: 37.186,56.754,65.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.081 | Acc: 37.283,56.829,65.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.079 | Acc: 37.253,56.889,65.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.083 | Acc: 37.169,56.858,65.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.083 | Acc: 37.139,56.869,65.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.523 | Acc: 31.250,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.303 | Acc: 31.362,48.586,57.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.333 | Acc: 31.174,48.342,56.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.349 | Acc: 31.160,48.181,56.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 4.788 | Acc: 42.969,59.375,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.902 | Acc: 37.909,58.333,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.009 | Acc: 36.452,57.184,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.017 | Acc: 36.539,57.415,67.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.030 | Acc: 36.728,57.706,67.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.049 | Acc: 36.572,57.712,67.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.032 | Acc: 36.841,57.909,67.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.041 | Acc: 37.001,57.824,67.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.033 | Acc: 37.209,57.973,67.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.034 | Acc: 37.250,57.886,66.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.032 | Acc: 37.189,57.844,66.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.030 | Acc: 37.235,57.834,66.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.044 | Acc: 37.280,57.728,66.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.058 | Acc: 37.168,57.594,66.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.071 | Acc: 37.041,57.398,66.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.076 | Acc: 36.968,57.332,66.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.072 | Acc: 36.938,57.314,66.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.076 | Acc: 36.911,57.187,66.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.074 | Acc: 36.916,57.287,66.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.072 | Acc: 36.916,57.335,66.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.344 | Acc: 33.594,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.176 | Acc: 31.920,48.698,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.182 | Acc: 31.536,48.418,55.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.197 | Acc: 31.660,48.258,55.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 5.417 | Acc: 38.281,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.946 | Acc: 37.723,58.222,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.967 | Acc: 36.928,57.927,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.925 | Acc: 37.513,58.837,67.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.932 | Acc: 37.606,58.700,67.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.923 | Acc: 37.423,58.679,67.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.945 | Acc: 37.435,58.426,67.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.975 | Acc: 37.411,58.106,67.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.974 | Acc: 37.544,58.152,66.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.986 | Acc: 37.599,58.015,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.992 | Acc: 37.628,57.952,66.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.988 | Acc: 37.592,57.982,66.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.982 | Acc: 37.562,58.075,66.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.988 | Acc: 37.575,58.022,66.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.993 | Acc: 37.650,57.904,66.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.002 | Acc: 37.518,57.823,66.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.005 | Acc: 37.539,57.742,66.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.019 | Acc: 37.466,57.654,66.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.030 | Acc: 37.374,57.516,66.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.039 | Acc: 37.404,57.456,66.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.318 | Acc: 33.594,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.234 | Acc: 30.804,48.326,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.307 | Acc: 30.088,47.999,55.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.329 | Acc: 30.136,47.695,55.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 5.065 | Acc: 34.375,56.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.892 | Acc: 37.723,58.891,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.888 | Acc: 37.576,58.136,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.920 | Acc: 37.961,58.030,67.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.906 | Acc: 38.175,58.362,67.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.906 | Acc: 38.057,58.369,67.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.925 | Acc: 37.952,58.290,67.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.949 | Acc: 37.788,58.134,67.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.954 | Acc: 37.815,58.113,67.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.958 | Acc: 37.906,58.145,67.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.967 | Acc: 37.877,58.077,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.979 | Acc: 37.737,57.943,66.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.985 | Acc: 37.685,57.926,67.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.990 | Acc: 37.632,57.860,67.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.988 | Acc: 37.570,57.940,67.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.002 | Acc: 37.503,57.787,67.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.009 | Acc: 37.481,57.696,66.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.009 | Acc: 37.548,57.659,66.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.005 | Acc: 37.584,57.730,66.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.005 | Acc: 37.555,57.679,66.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.774 | Acc: 28.906,42.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.624 | Acc: 29.576,45.164,52.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.615 | Acc: 29.840,44.760,52.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.635 | Acc: 29.355,44.813,52.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 5.085 | Acc: 42.188,60.156,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.863 | Acc: 39.397,59.673,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.840 | Acc: 39.520,59.909,68.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.849 | Acc: 39.075,59.849,68.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.896 | Acc: 38.600,59.192,67.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.913 | Acc: 38.567,58.818,67.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.901 | Acc: 38.682,58.704,67.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.927 | Acc: 38.398,58.439,67.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.939 | Acc: 38.320,58.303,67.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.942 | Acc: 38.173,58.201,67.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.953 | Acc: 38.095,58.162,66.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.978 | Acc: 37.800,57.830,66.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.989 | Acc: 37.643,57.693,66.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.994 | Acc: 37.533,57.597,66.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.004 | Acc: 37.372,57.501,66.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.003 | Acc: 37.355,57.498,66.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.003 | Acc: 37.451,57.491,66.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.012 | Acc: 37.374,57.375,66.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.011 | Acc: 37.448,57.419,66.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.004 | Acc: 37.502,57.505,66.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.264 | Acc: 20.312,44.531,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.356 | Acc: 22.693,43.750,54.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.430 | Acc: 21.932,42.740,53.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.480 | Acc: 21.785,42.456,52.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.885 | Acc: 39.844,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.971 | Acc: 38.132,58.185,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.906 | Acc: 37.843,58.384,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.972 | Acc: 37.654,57.441,67.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.939 | Acc: 37.751,57.784,67.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.934 | Acc: 37.987,57.959,67.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.968 | Acc: 37.881,57.651,67.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.972 | Acc: 37.855,57.746,67.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.982 | Acc: 37.646,57.681,67.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.977 | Acc: 37.686,57.782,67.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.967 | Acc: 37.687,57.754,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.968 | Acc: 37.673,57.763,67.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.976 | Acc: 37.617,57.667,66.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.970 | Acc: 37.623,57.747,66.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.974 | Acc: 37.647,57.779,66.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.978 | Acc: 37.656,57.729,66.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.984 | Acc: 37.578,57.654,66.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.985 | Acc: 37.665,57.719,66.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.989 | Acc: 37.593,57.685,66.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.993 | Acc: 37.598,57.661,66.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.955 | Acc: 31.250,46.094,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.228 | Acc: 26.042,42.113,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.316 | Acc: 25.877,40.701,52.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.356 | Acc: 25.205,40.190,52.267,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 4.968 | Acc: 41.406,57.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.059 | Acc: 37.202,59.263,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.957 | Acc: 37.100,59.165,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.962 | Acc: 37.346,58.568,68.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.954 | Acc: 37.452,58.478,67.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.935 | Acc: 37.717,58.571,68.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.932 | Acc: 37.584,58.613,68.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.953 | Acc: 37.561,58.206,67.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.954 | Acc: 37.490,58.317,67.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.949 | Acc: 37.634,58.227,67.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.946 | Acc: 37.624,58.427,67.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.958 | Acc: 37.514,58.314,67.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.958 | Acc: 37.490,58.192,67.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.959 | Acc: 37.443,58.193,67.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.965 | Acc: 37.508,58.174,67.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.964 | Acc: 37.557,58.114,67.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.962 | Acc: 37.539,58.100,67.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.950 | Acc: 37.580,58.243,67.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.957 | Acc: 37.576,58.161,67.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.960 | Acc: 37.572,58.147,67.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.480 | Acc: 33.594,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.551 | Acc: 28.199,48.065,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.558 | Acc: 27.954,47.694,55.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.592 | Acc: 27.715,47.387,55.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 5.170 | Acc: 35.156,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.805 | Acc: 37.686,58.519,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.826 | Acc: 37.081,58.556,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.863 | Acc: 37.513,58.158,68.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.869 | Acc: 38.146,58.237,68.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.879 | Acc: 38.018,58.416,68.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.905 | Acc: 37.836,58.084,67.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.913 | Acc: 37.816,58.018,67.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.919 | Acc: 37.777,58.036,67.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.920 | Acc: 37.824,58.123,67.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.911 | Acc: 37.955,58.244,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.929 | Acc: 37.762,58.007,67.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.923 | Acc: 37.785,58.056,67.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.924 | Acc: 37.826,58.157,67.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.934 | Acc: 37.706,58.082,67.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.930 | Acc: 37.656,58.059,67.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.936 | Acc: 37.590,58.058,67.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.934 | Acc: 37.608,58.149,67.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.938 | Acc: 37.610,58.137,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.945 | Acc: 37.586,58.106,67.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.313 | Acc: 25.000,43.750,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.220 | Acc: 22.991,45.908,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.316 | Acc: 22.237,44.646,54.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.313 | Acc: 22.041,44.915,54.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 4.604 | Acc: 41.406,59.375,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.866 | Acc: 37.574,58.966,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.900 | Acc: 37.462,58.880,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.872 | Acc: 37.705,58.876,68.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.865 | Acc: 37.510,58.951,68.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.870 | Acc: 37.724,58.818,68.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.861 | Acc: 37.661,58.826,68.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.871 | Acc: 37.771,58.777,68.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.872 | Acc: 38.034,58.715,68.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.880 | Acc: 37.940,58.723,67.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.902 | Acc: 37.869,58.570,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.917 | Acc: 37.857,58.399,67.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.925 | Acc: 37.857,58.341,67.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.928 | Acc: 37.892,58.378,67.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.919 | Acc: 38.012,58.496,67.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.929 | Acc: 37.905,58.404,67.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.921 | Acc: 37.906,58.479,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.916 | Acc: 37.956,58.534,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.922 | Acc: 37.980,58.475,67.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.926 | Acc: 37.894,58.434,67.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.506 | Acc: 32.812,47.656,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.762 | Acc: 28.869,45.871,53.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.732 | Acc: 29.078,45.770,53.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.764 | Acc: 29.150,45.902,53.458,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 4.114 | Acc: 40.625,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.851 | Acc: 37.426,59.263,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.856 | Acc: 38.262,58.727,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.876 | Acc: 38.153,58.799,68.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.885 | Acc: 38.175,58.652,68.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.906 | Acc: 38.111,58.369,68.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.904 | Acc: 38.055,58.413,67.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.896 | Acc: 38.021,58.610,67.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.891 | Acc: 38.155,58.647,68.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.887 | Acc: 38.294,58.628,68.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.891 | Acc: 38.258,58.567,67.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.885 | Acc: 38.331,58.774,67.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.882 | Acc: 38.330,58.782,67.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.884 | Acc: 38.227,58.690,67.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.893 | Acc: 38.184,58.630,67.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.903 | Acc: 38.175,58.534,67.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.908 | Acc: 38.050,58.504,67.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.910 | Acc: 38.022,58.493,67.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.912 | Acc: 38.125,58.492,67.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.912 | Acc: 38.093,58.524,67.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.098 | Acc: 34.375,50.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.304 | Acc: 31.510,47.247,55.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.288 | Acc: 31.707,47.161,55.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.311 | Acc: 31.365,46.901,55.699,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 4.282 | Acc: 42.188,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.781 | Acc: 38.765,59.412,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.776 | Acc: 39.062,58.937,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.715 | Acc: 39.357,59.541,69.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.740 | Acc: 39.169,59.423,69.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.761 | Acc: 38.869,59.414,69.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.788 | Acc: 38.707,59.181,69.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.820 | Acc: 38.520,59.009,68.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.806 | Acc: 38.602,59.210,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.815 | Acc: 38.592,59.133,68.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.834 | Acc: 38.588,59.118,68.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.853 | Acc: 38.387,58.891,67.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.859 | Acc: 38.434,58.798,67.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.852 | Acc: 38.461,58.884,67.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.861 | Acc: 38.337,58.752,67.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.869 | Acc: 38.219,58.672,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.879 | Acc: 38.174,58.647,67.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.884 | Acc: 38.167,58.651,67.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.896 | Acc: 38.063,58.535,67.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.891 | Acc: 38.136,58.653,67.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.976 | Acc: 25.000,42.969,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.704 | Acc: 26.228,46.838,58.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.808 | Acc: 26.086,46.341,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.863 | Acc: 25.871,46.017,56.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 4.463 | Acc: 39.844,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.769 | Acc: 37.984,59.784,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.818 | Acc: 38.014,59.413,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.807 | Acc: 37.961,59.388,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.817 | Acc: 38.050,59.452,68.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.799 | Acc: 38.049,59.607,69.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.804 | Acc: 38.094,59.588,68.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.829 | Acc: 37.949,59.209,68.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.838 | Acc: 37.864,59.064,68.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.838 | Acc: 37.863,59.099,68.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.840 | Acc: 37.896,59.107,68.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.851 | Acc: 37.984,59.043,68.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.857 | Acc: 37.951,58.921,68.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.867 | Acc: 37.880,58.920,68.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.872 | Acc: 37.792,58.841,68.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.875 | Acc: 37.840,58.814,68.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.877 | Acc: 37.802,58.813,67.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.878 | Acc: 37.763,58.747,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.875 | Acc: 37.874,58.797,67.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.880 | Acc: 37.867,58.707,67.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.407 | Acc: 37.500,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.406 | Acc: 30.543,49.442,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.426 | Acc: 30.755,48.152,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.414 | Acc: 30.289,48.040,55.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 4.685 | Acc: 40.625,58.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.761 | Acc: 38.356,58.966,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.757 | Acc: 38.929,59.585,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.754 | Acc: 38.986,59.810,69.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.766 | Acc: 38.918,59.664,69.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.778 | Acc: 38.722,59.661,69.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.787 | Acc: 38.649,59.446,68.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.790 | Acc: 38.747,59.325,68.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.790 | Acc: 38.669,59.424,68.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.788 | Acc: 38.808,59.397,68.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.800 | Acc: 38.577,59.336,68.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.812 | Acc: 38.472,59.145,68.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.826 | Acc: 38.476,59.061,68.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.827 | Acc: 38.473,59.070,68.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.828 | Acc: 38.415,59.041,68.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.835 | Acc: 38.346,58.973,68.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.836 | Acc: 38.345,59.015,68.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.844 | Acc: 38.309,58.942,68.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.843 | Acc: 38.262,58.938,68.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.848 | Acc: 38.269,58.901,68.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.091 | Acc: 39.844,45.312,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.598 | Acc: 31.622,45.126,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.635 | Acc: 31.383,44.684,54.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.682 | Acc: 30.776,44.211,54.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 5.240 | Acc: 39.844,57.031,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.715 | Acc: 39.695,59.710,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.649 | Acc: 39.577,60.461,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 38.973,59.785,70.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.676 | Acc: 38.966,59.886,70.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.698 | Acc: 39.325,59.986,70.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.737 | Acc: 39.037,59.562,69.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.739 | Acc: 39.146,59.646,69.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.744 | Acc: 39.043,59.690,69.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.752 | Acc: 38.920,59.522,69.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.762 | Acc: 38.814,59.492,69.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.778 | Acc: 38.826,59.350,69.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.779 | Acc: 38.910,59.385,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.797 | Acc: 38.751,59.234,69.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.803 | Acc: 38.765,59.172,68.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.826 | Acc: 38.590,59.051,68.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.838 | Acc: 38.459,58.998,68.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.836 | Acc: 38.444,59.063,68.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.837 | Acc: 38.415,59.068,68.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.837 | Acc: 38.408,59.092,68.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.639 | Acc: 35.156,50.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.420 | Acc: 30.022,49.219,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.448 | Acc: 30.259,48.476,55.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.477 | Acc: 29.931,47.976,55.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 4.907 | Acc: 34.375,57.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.658 | Acc: 38.690,60.565,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.697 | Acc: 38.510,59.966,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.749 | Acc: 38.268,59.529,69.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.745 | Acc: 38.426,59.722,69.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.768 | Acc: 38.281,59.623,68.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.784 | Acc: 38.365,59.543,69.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.779 | Acc: 38.392,59.752,69.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.767 | Acc: 38.519,59.632,69.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.789 | Acc: 38.437,59.530,69.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.796 | Acc: 38.538,59.499,68.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.800 | Acc: 38.483,59.485,68.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.802 | Acc: 38.505,59.521,68.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.810 | Acc: 38.362,59.471,68.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.818 | Acc: 38.267,59.447,68.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.817 | Acc: 38.240,59.541,68.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.822 | Acc: 38.172,59.482,68.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.828 | Acc: 38.128,59.501,68.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.835 | Acc: 38.050,59.451,68.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.834 | Acc: 38.136,59.463,68.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.391 | Acc: 37.500,50.000,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.313 | Acc: 32.329,48.326,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.360 | Acc: 30.678,47.447,55.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.391 | Acc: 30.840,47.029,55.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 4.215 | Acc: 46.094,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.621 | Acc: 40.699,62.016,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.692 | Acc: 40.053,61.090,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.677 | Acc: 39.767,60.822,70.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.720 | Acc: 39.323,60.397,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.724 | Acc: 39.032,60.326,69.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.750 | Acc: 38.675,60.201,69.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.766 | Acc: 38.520,60.007,69.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.772 | Acc: 38.339,59.860,69.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.783 | Acc: 38.303,59.720,69.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.789 | Acc: 38.277,59.616,69.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.794 | Acc: 38.214,59.562,69.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.801 | Acc: 38.184,59.453,68.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.801 | Acc: 38.191,59.450,68.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.793 | Acc: 38.337,59.495,69.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.796 | Acc: 38.346,59.507,68.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.799 | Acc: 38.354,59.582,68.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.806 | Acc: 38.350,59.485,68.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.808 | Acc: 38.368,59.516,68.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.807 | Acc: 38.355,59.451,68.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.871 | Acc: 26.562,44.531,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.889 | Acc: 27.158,44.085,54.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.962 | Acc: 26.677,42.530,53.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.972 | Acc: 26.319,43.135,53.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 4.808 | Acc: 35.156,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.821 | Acc: 37.165,59.449,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.713 | Acc: 38.377,60.309,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.727 | Acc: 38.934,59.862,69.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.716 | Acc: 38.937,60.060,69.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.730 | Acc: 38.931,60.071,69.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.750 | Acc: 38.759,59.801,69.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.727 | Acc: 38.963,60.057,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.716 | Acc: 38.980,60.341,69.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.726 | Acc: 39.050,60.234,69.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.740 | Acc: 38.973,60.094,69.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.746 | Acc: 38.854,60.001,69.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.749 | Acc: 38.836,59.874,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.748 | Acc: 38.817,59.869,69.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.760 | Acc: 38.709,59.714,69.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.763 | Acc: 38.697,59.736,69.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.771 | Acc: 38.595,59.689,68.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.774 | Acc: 38.648,59.675,68.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.780 | Acc: 38.690,59.697,68.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.791 | Acc: 38.679,59.572,68.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.397 | Acc: 25.781,42.969,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.528 | Acc: 25.037,42.262,51.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.528 | Acc: 24.790,42.302,51.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.619 | Acc: 24.436,41.931,51.076,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.208 | Acc: 44.531,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.709 | Acc: 38.690,59.152,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.710 | Acc: 37.976,59.299,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.711 | Acc: 38.128,59.375,70.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.724 | Acc: 38.021,59.549,70.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.724 | Acc: 38.405,59.499,70.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.730 | Acc: 38.165,59.511,70.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.730 | Acc: 38.375,59.619,70.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.724 | Acc: 38.412,59.778,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.732 | Acc: 38.428,59.768,69.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.741 | Acc: 38.495,59.791,69.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.746 | Acc: 38.596,59.817,69.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.761 | Acc: 38.570,59.612,69.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.758 | Acc: 38.670,59.632,69.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.770 | Acc: 38.668,59.614,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.776 | Acc: 38.593,59.445,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.780 | Acc: 38.578,59.356,69.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.786 | Acc: 38.581,59.270,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.794 | Acc: 38.647,59.312,68.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.796 | Acc: 38.638,59.379,68.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.575 | Acc: 33.594,40.625,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.640 | Acc: 33.371,43.378,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.611 | Acc: 33.670,43.902,54.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.616 | Acc: 33.261,44.160,54.764,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 4.733 | Acc: 39.844,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.716 | Acc: 39.807,61.012,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.706 | Acc: 39.501,60.804,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.668 | Acc: 39.331,60.707,70.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.669 | Acc: 39.207,60.581,70.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.684 | Acc: 39.140,60.636,69.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.685 | Acc: 39.211,60.589,69.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.701 | Acc: 39.090,60.378,69.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.720 | Acc: 39.004,60.200,69.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.730 | Acc: 39.101,60.130,69.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.736 | Acc: 39.016,59.954,69.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.754 | Acc: 38.790,59.739,68.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.756 | Acc: 38.897,59.745,68.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.752 | Acc: 38.820,59.785,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.754 | Acc: 38.876,59.842,68.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.755 | Acc: 38.894,59.884,68.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.766 | Acc: 38.746,59.818,68.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.777 | Acc: 38.714,59.751,68.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.784 | Acc: 38.658,59.611,68.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.785 | Acc: 38.702,59.592,68.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.988 | Acc: 30.469,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.752 | Acc: 28.943,47.954,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.743 | Acc: 29.059,48.018,55.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.808 | Acc: 28.791,47.618,55.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 4.382 | Acc: 43.750,63.281,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.652 | Acc: 39.509,60.938,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.675 | Acc: 39.653,60.861,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.668 | Acc: 39.600,60.400,70.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.685 | Acc: 39.410,60.320,69.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.681 | Acc: 39.264,60.234,69.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.708 | Acc: 38.869,60.021,69.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.698 | Acc: 39.046,60.278,70.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.710 | Acc: 39.009,60.122,69.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.709 | Acc: 38.937,60.191,69.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.708 | Acc: 39.070,60.273,69.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.704 | Acc: 39.179,60.414,69.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.712 | Acc: 39.157,60.390,69.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.716 | Acc: 39.116,60.408,69.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.719 | Acc: 39.076,60.318,69.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.725 | Acc: 39.021,60.265,69.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.737 | Acc: 38.992,60.217,69.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.742 | Acc: 38.985,60.147,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.748 | Acc: 39.013,60.106,68.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.750 | Acc: 39.085,60.072,68.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.131 | Acc: 32.031,46.875,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.937 | Acc: 28.571,46.726,56.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.964 | Acc: 27.992,46.303,55.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.003 | Acc: 27.766,46.350,55.328,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 4.311 | Acc: 36.719,65.625,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.701 | Acc: 39.323,60.789,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.723 | Acc: 39.120,60.880,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.688 | Acc: 39.408,61.181,70.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.665 | Acc: 39.342,61.034,70.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.695 | Acc: 39.256,60.984,69.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.713 | Acc: 39.301,60.770,69.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.707 | Acc: 39.334,60.721,69.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.725 | Acc: 39.194,60.632,69.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.725 | Acc: 39.157,60.545,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.716 | Acc: 39.140,60.459,69.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.722 | Acc: 39.048,60.425,69.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.718 | Acc: 39.153,60.422,69.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.729 | Acc: 39.104,60.333,69.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.728 | Acc: 39.079,60.437,69.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.735 | Acc: 38.987,60.325,69.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.743 | Acc: 38.965,60.258,69.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.747 | Acc: 38.936,60.202,69.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.749 | Acc: 38.976,60.111,69.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.754 | Acc: 38.919,60.043,69.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.955 | Acc: 32.031,48.438,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.319 | Acc: 32.292,48.847,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.253 | Acc: 32.527,48.647,56.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.266 | Acc: 32.774,48.348,55.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 5.159 | Acc: 34.375,57.031,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 40.476,60.975,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 39.310,60.728,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.649 | Acc: 38.768,60.630,69.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.651 | Acc: 38.783,60.735,70.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.684 | Acc: 38.730,60.504,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.697 | Acc: 38.791,60.311,69.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.693 | Acc: 38.891,60.400,69.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.706 | Acc: 38.902,60.457,69.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.724 | Acc: 38.950,60.316,69.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.726 | Acc: 39.097,60.343,69.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.723 | Acc: 39.147,60.216,69.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.718 | Acc: 39.166,60.309,69.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.719 | Acc: 39.155,60.342,69.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.727 | Acc: 39.015,60.281,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.733 | Acc: 39.034,60.203,69.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.736 | Acc: 38.982,60.142,69.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.738 | Acc: 38.920,60.110,69.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.739 | Acc: 38.935,60.100,69.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.736 | Acc: 38.884,60.158,69.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.470 | Acc: 34.375,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.168 | Acc: 31.324,50.744,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.204 | Acc: 31.307,49.695,57.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.225 | Acc: 31.148,49.513,57.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 4.693 | Acc: 39.062,59.375,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 39.435,60.975,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.560 | Acc: 39.768,60.366,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 39.728,60.822,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.575 | Acc: 39.882,60.889,71.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.584 | Acc: 39.952,61.046,70.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.608 | Acc: 39.779,60.899,70.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.633 | Acc: 39.589,60.616,70.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.639 | Acc: 39.392,60.622,70.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.644 | Acc: 39.395,60.536,70.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.665 | Acc: 39.226,60.374,69.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.678 | Acc: 39.370,60.329,69.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.681 | Acc: 39.461,60.357,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.687 | Acc: 39.398,60.336,69.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.702 | Acc: 39.260,60.156,69.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.704 | Acc: 39.226,60.203,69.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.712 | Acc: 39.162,60.120,69.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.721 | Acc: 39.074,60.088,69.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.727 | Acc: 38.993,60.046,69.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.728 | Acc: 39.038,60.076,69.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.388 | Acc: 35.938,50.781,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.633 | Acc: 30.618,47.619,53.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.558 | Acc: 30.774,47.294,54.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.595 | Acc: 30.738,46.888,54.303,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 4.109 | Acc: 41.406,65.625,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.621 | Acc: 39.769,60.975,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.629 | Acc: 39.158,60.785,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.659 | Acc: 38.794,60.169,70.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.662 | Acc: 39.246,60.349,70.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.688 | Acc: 39.356,60.125,70.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.688 | Acc: 39.185,60.298,70.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.677 | Acc: 39.268,60.494,70.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.678 | Acc: 39.101,60.472,70.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.684 | Acc: 39.106,60.350,70.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.691 | Acc: 38.954,60.250,69.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.700 | Acc: 38.879,60.216,69.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.701 | Acc: 38.946,60.198,69.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.703 | Acc: 38.943,60.237,69.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.703 | Acc: 39.060,60.281,69.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.713 | Acc: 38.943,60.180,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.722 | Acc: 38.887,60.098,69.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.720 | Acc: 38.902,60.058,69.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.717 | Acc: 39.002,60.031,69.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.718 | Acc: 39.060,60.072,69.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.980 | Acc: 28.906,50.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.129 | Acc: 31.027,49.777,58.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.142 | Acc: 31.193,49.409,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.192 | Acc: 30.917,48.860,58.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 3.953 | Acc: 40.625,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.672 | Acc: 39.025,60.826,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.617 | Acc: 39.634,61.109,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.617 | Acc: 39.485,61.322,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.617 | Acc: 39.516,61.227,70.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.603 | Acc: 39.519,61.324,70.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.618 | Acc: 39.495,61.241,70.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.638 | Acc: 39.301,61.004,70.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.654 | Acc: 39.431,60.845,70.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.637 | Acc: 39.516,61.097,70.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.625 | Acc: 39.634,61.221,70.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.644 | Acc: 39.412,60.987,70.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.659 | Acc: 39.263,60.918,70.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.667 | Acc: 39.170,60.833,70.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.656 | Acc: 39.321,60.801,70.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.674 | Acc: 39.257,60.696,70.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.683 | Acc: 39.260,60.560,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.687 | Acc: 39.260,60.553,69.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.685 | Acc: 39.277,60.609,69.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.689 | Acc: 39.337,60.525,69.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.994 | Acc: 35.938,43.750,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.862 | Acc: 31.808,45.052,52.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.919 | Acc: 31.364,43.636,51.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.941 | Acc: 31.237,43.174,51.422,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.380 | Acc: 35.156,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.423 | Acc: 39.732,61.086,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.482 | Acc: 39.596,61.071,71.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.533 | Acc: 39.933,61.014,71.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.582 | Acc: 39.535,61.217,70.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.615 | Acc: 39.380,60.783,70.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.627 | Acc: 39.495,60.608,70.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.635 | Acc: 39.312,60.583,70.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.633 | Acc: 39.354,60.583,70.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.639 | Acc: 39.274,60.739,70.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.632 | Acc: 39.335,60.996,70.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.638 | Acc: 39.448,60.902,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.646 | Acc: 39.552,60.759,70.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.657 | Acc: 39.353,60.662,69.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.652 | Acc: 39.441,60.793,69.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.658 | Acc: 39.473,60.803,69.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.672 | Acc: 39.347,60.645,69.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.675 | Acc: 39.317,60.612,69.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.686 | Acc: 39.220,60.492,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.693 | Acc: 39.224,60.454,69.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.477 | Acc: 31.250,46.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.293 | Acc: 30.915,50.260,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.351 | Acc: 30.011,49.162,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.353 | Acc: 30.033,49.052,57.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.822 | Acc: 37.500,56.250,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.661 | Acc: 39.658,60.007,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.658 | Acc: 39.139,60.480,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.645 | Acc: 39.203,60.489,70.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.615 | Acc: 39.660,60.503,70.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.604 | Acc: 39.735,60.675,70.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.617 | Acc: 39.682,60.602,70.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.618 | Acc: 39.628,60.799,70.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.639 | Acc: 39.392,60.714,70.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.662 | Acc: 39.028,60.545,70.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.652 | Acc: 39.086,60.712,70.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.658 | Acc: 39.161,60.722,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.660 | Acc: 39.111,60.649,70.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.661 | Acc: 39.128,60.614,70.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.662 | Acc: 39.115,60.679,70.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.663 | Acc: 39.104,60.660,70.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.666 | Acc: 39.148,60.624,70.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.662 | Acc: 39.260,60.702,70.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.673 | Acc: 39.080,60.602,70.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.676 | Acc: 39.101,60.593,69.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.564 | Acc: 31.250,48.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.693 | Acc: 27.976,46.540,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.783 | Acc: 26.886,45.541,55.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.833 | Acc: 26.793,44.851,55.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 4.076 | Acc: 47.656,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.526 | Acc: 39.435,63.653,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 39.253,61.814,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 38.960,61.539,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.600 | Acc: 39.178,61.381,71.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.601 | Acc: 39.070,61.440,70.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.617 | Acc: 39.166,61.299,70.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.611 | Acc: 39.312,61.364,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.615 | Acc: 39.363,61.166,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.626 | Acc: 39.352,61.063,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.627 | Acc: 39.455,60.984,70.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.629 | Acc: 39.511,60.952,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.641 | Acc: 39.461,60.808,70.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.650 | Acc: 39.362,60.845,70.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.664 | Acc: 39.246,60.648,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.679 | Acc: 39.120,60.501,70.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.680 | Acc: 39.118,60.487,70.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.684 | Acc: 39.083,60.525,70.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.685 | Acc: 39.145,60.522,69.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.690 | Acc: 39.108,60.464,69.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.118 | Acc: 33.594,47.656,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.132 | Acc: 30.208,49.293,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.168 | Acc: 30.373,48.857,58.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.186 | Acc: 30.097,48.642,58.222,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 5.175 | Acc: 33.594,52.344,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.685 | Acc: 38.244,61.384,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.631 | Acc: 38.567,61.623,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.565 | Acc: 39.152,61.962,71.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.533 | Acc: 39.786,62.211,71.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.559 | Acc: 39.728,61.920,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.568 | Acc: 39.547,61.861,71.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.570 | Acc: 39.600,61.741,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.578 | Acc: 39.557,61.622,70.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.595 | Acc: 39.425,61.473,70.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.598 | Acc: 39.397,61.392,70.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.609 | Acc: 39.317,61.358,70.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.618 | Acc: 39.302,61.210,70.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.618 | Acc: 39.332,61.207,70.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.619 | Acc: 39.421,61.257,70.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.622 | Acc: 39.447,61.187,70.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.633 | Acc: 39.393,61.103,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.634 | Acc: 39.402,61.070,70.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.635 | Acc: 39.391,60.998,70.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.646 | Acc: 39.311,60.935,70.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.715 | Acc: 32.031,46.875,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.962 | Acc: 26.488,45.685,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.926 | Acc: 26.963,45.636,55.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.920 | Acc: 26.627,45.838,55.136,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.560 | Acc: 36.719,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 38.839,61.533,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 40.053,61.128,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 39.728,61.014,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.533 | Acc: 39.796,61.314,71.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.530 | Acc: 39.890,61.533,71.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.529 | Acc: 40.083,61.615,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.529 | Acc: 39.916,61.807,71.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.538 | Acc: 40.111,61.811,71.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.548 | Acc: 40.038,61.693,71.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.564 | Acc: 40.011,61.688,71.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.583 | Acc: 39.957,61.507,70.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.590 | Acc: 39.860,61.495,70.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.610 | Acc: 39.778,61.267,70.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.618 | Acc: 39.669,61.199,70.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.613 | Acc: 39.774,61.293,70.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.620 | Acc: 39.749,61.249,70.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.635 | Acc: 39.667,61.118,70.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.636 | Acc: 39.723,61.124,70.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.637 | Acc: 39.743,61.081,70.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.314 | Acc: 34.375,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.042 | Acc: 31.696,52.939,58.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.051 | Acc: 30.793,52.287,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.053 | Acc: 30.597,52.190,58.965,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.358 | Acc: 46.875,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.614 | Acc: 39.286,61.049,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 39.501,61.795,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 39.959,61.732,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.582 | Acc: 39.651,61.246,71.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.581 | Acc: 39.596,61.433,71.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.589 | Acc: 39.657,61.351,71.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.591 | Acc: 39.866,61.292,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.595 | Acc: 39.805,61.369,71.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.604 | Acc: 39.619,61.360,71.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.609 | Acc: 39.614,61.299,70.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.631 | Acc: 39.405,61.075,70.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.635 | Acc: 39.390,61.035,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.636 | Acc: 39.538,61.000,70.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.625 | Acc: 39.613,61.054,70.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.626 | Acc: 39.641,61.091,70.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.628 | Acc: 39.544,61.066,70.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.625 | Acc: 39.505,61.121,70.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.633 | Acc: 39.443,61.037,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.638 | Acc: 39.343,60.976,70.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.438 | Acc: 31.250,42.969,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.456 | Acc: 27.455,49.628,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.442 | Acc: 27.782,49.276,56.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.483 | Acc: 27.433,48.963,56.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 4.457 | Acc: 46.875,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 39.174,63.170,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.552 | Acc: 38.586,62.100,72.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.532 | Acc: 38.986,61.911,72.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.564 | Acc: 38.773,61.690,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.570 | Acc: 39.179,61.742,71.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.556 | Acc: 39.288,61.848,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.567 | Acc: 39.334,61.719,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.573 | Acc: 39.325,61.656,71.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.564 | Acc: 39.490,61.753,71.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.568 | Acc: 39.436,61.723,70.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.562 | Acc: 39.480,61.747,70.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.584 | Acc: 39.335,61.537,70.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.591 | Acc: 39.338,61.464,70.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.595 | Acc: 39.349,61.424,70.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.596 | Acc: 39.353,61.436,70.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.604 | Acc: 39.306,61.310,70.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.611 | Acc: 39.333,61.304,70.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.621 | Acc: 39.301,61.206,70.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.618 | Acc: 39.331,61.235,70.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.553 | Acc: 36.719,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.932 | Acc: 31.473,51.190,59.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.011 | Acc: 31.574,50.629,58.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.054 | Acc: 31.468,50.435,57.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 4.723 | Acc: 38.281,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.614 | Acc: 39.472,61.272,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.600 | Acc: 38.910,61.166,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 38.870,61.668,71.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.555 | Acc: 39.651,62.278,71.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.571 | Acc: 39.480,61.959,71.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.589 | Acc: 39.437,61.777,71.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.581 | Acc: 39.622,61.891,70.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.591 | Acc: 39.640,61.748,70.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.598 | Acc: 39.580,61.581,70.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.603 | Acc: 39.311,61.552,70.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.610 | Acc: 39.363,61.447,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.620 | Acc: 39.286,61.291,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.627 | Acc: 39.182,61.210,70.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.634 | Acc: 39.129,61.121,70.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.640 | Acc: 39.107,61.065,70.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.632 | Acc: 39.201,61.161,70.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.635 | Acc: 39.246,61.153,70.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.631 | Acc: 39.350,61.156,70.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.632 | Acc: 39.389,61.169,70.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.243 | Acc: 34.375,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.080 | Acc: 30.357,50.521,58.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.093 | Acc: 30.469,50.057,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.095 | Acc: 30.751,50.205,58.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 4.450 | Acc: 35.156,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 38.653,62.426,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.517 | Acc: 40.244,61.890,72.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.498 | Acc: 40.113,61.975,72.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.499 | Acc: 39.921,61.806,72.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.511 | Acc: 39.882,61.982,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.538 | Acc: 39.831,61.706,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.542 | Acc: 39.611,61.630,71.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.548 | Acc: 39.538,61.505,71.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.555 | Acc: 39.593,61.576,71.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.558 | Acc: 39.611,61.649,71.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.564 | Acc: 39.642,61.616,71.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.560 | Acc: 39.701,61.764,71.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.572 | Acc: 39.607,61.659,71.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.580 | Acc: 39.560,61.516,71.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.590 | Acc: 39.537,61.309,71.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.588 | Acc: 39.698,61.256,70.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.597 | Acc: 39.679,61.164,70.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.599 | Acc: 39.733,61.139,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.608 | Acc: 39.684,61.104,70.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.369 | Acc: 28.125,42.969,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.795 | Acc: 28.571,45.573,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.855 | Acc: 28.525,44.093,54.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.876 | Acc: 28.432,44.109,54.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 4.827 | Acc: 39.062,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.440 | Acc: 40.067,62.686,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.484 | Acc: 39.787,61.871,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.499 | Acc: 39.588,62.026,72.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.485 | Acc: 39.468,62.027,72.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.495 | Acc: 39.496,62.067,72.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.505 | Acc: 39.224,62.171,72.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.501 | Acc: 39.484,62.328,72.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.499 | Acc: 39.616,62.374,72.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.503 | Acc: 39.555,62.306,71.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.511 | Acc: 39.560,62.205,71.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.513 | Acc: 39.586,62.228,71.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.523 | Acc: 39.520,62.082,71.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.530 | Acc: 39.559,62.039,71.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.540 | Acc: 39.660,61.899,71.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.547 | Acc: 39.610,61.830,71.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.553 | Acc: 39.588,61.782,71.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.557 | Acc: 39.601,61.813,71.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.568 | Acc: 39.655,61.745,71.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.580 | Acc: 39.637,61.667,70.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.362 | Acc: 32.812,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.094 | Acc: 29.018,43.899,52.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.109 | Acc: 29.097,43.007,51.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.127 | Acc: 28.791,43.379,51.729,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.248 | Acc: 42.969,65.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 39.769,62.463,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.480 | Acc: 40.149,62.424,72.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.489 | Acc: 39.434,62.321,72.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.487 | Acc: 40.191,62.461,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.506 | Acc: 40.053,62.090,72.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.523 | Acc: 39.773,62.080,72.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.537 | Acc: 39.711,61.957,71.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.543 | Acc: 39.548,61.893,71.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.556 | Acc: 39.507,61.719,71.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.548 | Acc: 39.599,61.843,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.560 | Acc: 39.575,61.789,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.554 | Acc: 39.656,61.835,71.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.556 | Acc: 39.607,61.767,71.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.566 | Acc: 39.638,61.635,71.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.567 | Acc: 39.688,61.651,71.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.563 | Acc: 39.778,61.699,71.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.566 | Acc: 39.848,61.641,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.571 | Acc: 39.846,61.517,70.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.580 | Acc: 39.760,61.409,70.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.415 | Acc: 31.250,48.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.658 | Acc: 26.823,48.772,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.669 | Acc: 26.886,48.304,56.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.721 | Acc: 26.396,47.836,56.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 4.902 | Acc: 36.719,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.492 | Acc: 39.695,62.351,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 39.615,62.157,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.496 | Acc: 40.369,62.090,71.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.512 | Acc: 40.162,61.834,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.552 | Acc: 40.006,61.463,71.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.567 | Acc: 39.921,61.163,71.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.568 | Acc: 39.993,61.226,71.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.561 | Acc: 39.999,61.413,71.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.569 | Acc: 40.064,61.382,71.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.577 | Acc: 40.050,61.338,71.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.587 | Acc: 39.985,61.394,71.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.599 | Acc: 39.892,61.284,71.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.593 | Acc: 39.886,61.318,71.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.599 | Acc: 39.785,61.232,70.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.609 | Acc: 39.600,61.088,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.610 | Acc: 39.593,61.200,70.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.605 | Acc: 39.633,61.261,70.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.613 | Acc: 39.575,61.191,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.616 | Acc: 39.507,61.202,70.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.177 | Acc: 32.812,47.656,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.093 | Acc: 26.525,44.382,53.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.203 | Acc: 26.200,42.969,53.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.191 | Acc: 25.615,42.956,53.279,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 4.147 | Acc: 46.875,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.416 | Acc: 40.476,62.128,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.380 | Acc: 41.444,63.129,73.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.472 | Acc: 40.625,62.244,72.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.504 | Acc: 40.095,62.076,72.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.513 | Acc: 40.138,62.067,71.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.534 | Acc: 39.889,61.835,71.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.526 | Acc: 39.971,61.913,71.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.531 | Acc: 39.960,61.859,71.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.544 | Acc: 40.107,61.753,71.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.557 | Acc: 40.007,61.602,71.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.566 | Acc: 39.861,61.546,71.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.554 | Acc: 40.152,61.748,71.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.572 | Acc: 40.047,61.599,71.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.584 | Acc: 40.022,61.494,70.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.583 | Acc: 40.072,61.400,70.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.594 | Acc: 40.099,61.227,70.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.596 | Acc: 40.080,61.279,70.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.595 | Acc: 40.073,61.286,70.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.592 | Acc: 40.032,61.282,70.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.197 | Acc: 38.281,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.038 | Acc: 32.217,52.455,58.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.016 | Acc: 31.784,52.306,58.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.020 | Acc: 31.340,52.549,58.235,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 4.444 | Acc: 42.969,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.406 | Acc: 41.295,63.058,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.462 | Acc: 40.549,62.862,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.477 | Acc: 40.651,62.551,71.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.469 | Acc: 40.451,62.799,72.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.474 | Acc: 40.548,62.492,71.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.467 | Acc: 40.599,62.513,71.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.476 | Acc: 40.481,62.306,71.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.494 | Acc: 40.479,62.102,71.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.516 | Acc: 40.193,61.930,71.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.521 | Acc: 40.178,62.010,71.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.530 | Acc: 40.190,61.811,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.546 | Acc: 40.038,61.638,70.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.559 | Acc: 39.955,61.485,70.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.569 | Acc: 39.924,61.441,70.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.566 | Acc: 39.974,61.519,70.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.569 | Acc: 39.934,61.502,70.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.572 | Acc: 39.919,61.476,70.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.579 | Acc: 39.870,61.457,70.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.580 | Acc: 39.848,61.473,70.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.758 | Acc: 32.031,50.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.885 | Acc: 26.004,47.396,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.995 | Acc: 25.495,46.494,54.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.013 | Acc: 25.077,46.427,54.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 4.552 | Acc: 35.156,57.812,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.403 | Acc: 41.481,62.054,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.454 | Acc: 40.606,61.833,72.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.488 | Acc: 40.958,61.488,71.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.502 | Acc: 40.606,61.478,71.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.505 | Acc: 40.401,61.332,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.505 | Acc: 40.238,61.422,71.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.488 | Acc: 40.337,61.586,71.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.509 | Acc: 40.276,61.379,71.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.518 | Acc: 40.133,61.317,71.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.520 | Acc: 40.034,61.486,71.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.525 | Acc: 39.999,61.482,71.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.531 | Acc: 40.074,61.433,71.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.532 | Acc: 40.086,61.470,71.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.534 | Acc: 40.113,61.410,71.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.538 | Acc: 40.054,61.366,71.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.539 | Acc: 40.141,61.427,71.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.548 | Acc: 40.100,61.334,71.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.551 | Acc: 40.153,61.327,71.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.546 | Acc: 40.170,61.442,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.412 | Acc: 28.906,46.094,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.778 | Acc: 27.939,47.210,56.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.731 | Acc: 27.630,46.894,56.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.765 | Acc: 27.126,46.811,55.943,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 4.916 | Acc: 31.250,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.396 | Acc: 40.885,63.095,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.387 | Acc: 41.387,62.786,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.414 | Acc: 41.393,62.436,72.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.416 | Acc: 41.011,62.423,72.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.436 | Acc: 40.911,62.222,72.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.438 | Acc: 40.664,62.358,72.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.464 | Acc: 40.503,62.361,72.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.482 | Acc: 40.334,62.122,71.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.467 | Acc: 40.297,62.176,72.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.463 | Acc: 40.205,62.341,71.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.475 | Acc: 40.173,62.171,71.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.473 | Acc: 40.265,62.218,71.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.483 | Acc: 40.224,62.060,71.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.488 | Acc: 40.227,62.086,71.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.492 | Acc: 40.272,61.989,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.506 | Acc: 40.172,61.848,71.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.524 | Acc: 40.055,61.751,71.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.537 | Acc: 39.956,61.643,71.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.545 | Acc: 39.930,61.594,71.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.570 | Acc: 35.938,47.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.726 | Acc: 28.795,49.219,57.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.738 | Acc: 27.858,48.533,57.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.762 | Acc: 27.318,48.258,56.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 4.226 | Acc: 44.531,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.449 | Acc: 39.658,61.830,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.422 | Acc: 41.006,62.786,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.484 | Acc: 40.484,61.898,72.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.465 | Acc: 40.664,61.728,72.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.498 | Acc: 40.238,61.796,72.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.514 | Acc: 40.089,61.654,72.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.521 | Acc: 40.137,61.652,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.531 | Acc: 40.043,61.651,71.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.533 | Acc: 40.068,61.619,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.533 | Acc: 39.984,61.633,71.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.533 | Acc: 40.056,61.680,71.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.536 | Acc: 40.045,61.690,71.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.538 | Acc: 39.955,61.803,71.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.536 | Acc: 39.994,61.802,71.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.535 | Acc: 40.036,61.825,71.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.534 | Acc: 40.002,61.809,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.539 | Acc: 40.089,61.765,71.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.541 | Acc: 40.084,61.704,71.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.543 | Acc: 40.145,61.670,71.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.111 | Acc: 30.469,47.656,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.315 | Acc: 27.232,50.484,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.394 | Acc: 26.601,50.457,58.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.396 | Acc: 26.639,50.154,58.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 4.134 | Acc: 39.062,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.447 | Acc: 38.430,62.351,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.424 | Acc: 39.748,62.938,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.457 | Acc: 39.703,62.359,71.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.461 | Acc: 39.612,62.269,72.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.462 | Acc: 39.929,62.198,72.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.470 | Acc: 40.031,61.867,72.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.465 | Acc: 40.182,62.057,72.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.470 | Acc: 40.183,62.102,72.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.479 | Acc: 40.103,61.982,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.478 | Acc: 40.011,62.045,71.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.481 | Acc: 40.081,62.069,71.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.488 | Acc: 40.016,62.017,71.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.508 | Acc: 39.919,61.901,71.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.520 | Acc: 39.883,61.866,71.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.528 | Acc: 39.810,61.833,71.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.542 | Acc: 39.759,61.677,71.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.546 | Acc: 39.761,61.620,71.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.546 | Acc: 39.891,61.695,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.549 | Acc: 39.868,61.717,71.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.291 | Acc: 29.688,45.312,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.537 | Acc: 26.935,40.923,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.468 | Acc: 27.782,41.540,51.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.441 | Acc: 27.305,41.675,51.345,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 4.739 | Acc: 36.719,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.329 | Acc: 40.365,63.430,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.362 | Acc: 40.949,63.739,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.400 | Acc: 41.201,63.525,73.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.415 | Acc: 40.847,63.194,72.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.435 | Acc: 40.486,62.902,72.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.448 | Acc: 40.425,62.720,72.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.451 | Acc: 40.226,62.794,72.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.466 | Acc: 40.077,62.553,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.474 | Acc: 40.150,62.707,72.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.502 | Acc: 39.929,62.333,71.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.507 | Acc: 39.861,62.309,71.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.515 | Acc: 39.789,62.156,71.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.512 | Acc: 39.898,62.216,71.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.514 | Acc: 39.877,62.144,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.526 | Acc: 39.768,61.991,71.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.539 | Acc: 39.688,61.879,71.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.539 | Acc: 39.690,61.838,71.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.541 | Acc: 39.718,61.868,71.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.548 | Acc: 39.706,61.854,71.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.218 | Acc: 37.500,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.152 | Acc: 34.152,51.488,58.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.091 | Acc: 34.527,50.915,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.139 | Acc: 33.965,50.410,58.094,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 4.710 | Acc: 36.719,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.429 | Acc: 39.658,62.798,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.394 | Acc: 40.511,63.529,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.359 | Acc: 40.932,63.294,73.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.400 | Acc: 40.490,62.818,73.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.413 | Acc: 40.633,62.925,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.434 | Acc: 40.735,62.874,73.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.436 | Acc: 40.614,62.727,73.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.436 | Acc: 40.659,62.670,72.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.438 | Acc: 40.759,62.595,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.448 | Acc: 40.812,62.512,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.457 | Acc: 40.682,62.429,72.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.476 | Acc: 40.502,62.276,72.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.476 | Acc: 40.538,62.302,72.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.485 | Acc: 40.475,62.289,72.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.496 | Acc: 40.490,62.212,72.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.509 | Acc: 40.355,62.094,72.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.510 | Acc: 40.318,62.076,72.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.509 | Acc: 40.264,62.065,72.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.513 | Acc: 40.203,62.022,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.935 | Acc: 21.875,38.281,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.630 | Acc: 21.503,43.378,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.757 | Acc: 21.513,42.969,53.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.801 | Acc: 20.991,42.444,53.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 3.856 | Acc: 40.625,64.844,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.485 | Acc: 40.104,61.756,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.414 | Acc: 40.930,62.405,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.414 | Acc: 40.920,62.398,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.406 | Acc: 41.136,62.510,73.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.403 | Acc: 41.290,62.678,73.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.421 | Acc: 40.987,62.526,73.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.412 | Acc: 41.029,62.699,73.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.430 | Acc: 40.911,62.510,72.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.439 | Acc: 40.737,62.401,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.450 | Acc: 40.660,62.380,72.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.451 | Acc: 40.657,62.348,72.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.464 | Acc: 40.443,62.302,72.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.472 | Acc: 40.448,62.431,72.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.480 | Acc: 40.369,62.383,72.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.492 | Acc: 40.205,62.287,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.491 | Acc: 40.245,62.300,71.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.504 | Acc: 40.142,62.220,71.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.514 | Acc: 40.041,62.141,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.514 | Acc: 40.034,62.174,71.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.787 | Acc: 38.281,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.818 | Acc: 33.408,52.679,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.836 | Acc: 32.908,52.115,59.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.904 | Acc: 33.056,51.460,58.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 3.607 | Acc: 44.531,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.419 | Acc: 40.588,62.760,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.372 | Acc: 40.511,63.281,73.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.382 | Acc: 40.369,62.935,73.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.408 | Acc: 40.336,62.635,73.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.438 | Acc: 40.076,62.539,73.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.447 | Acc: 40.134,62.384,72.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.446 | Acc: 40.193,62.539,72.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.442 | Acc: 40.382,62.602,72.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.449 | Acc: 40.418,62.457,72.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.455 | Acc: 40.520,62.352,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.461 | Acc: 40.374,62.355,72.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.463 | Acc: 40.207,62.299,72.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.474 | Acc: 40.191,62.299,72.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.475 | Acc: 40.225,62.319,72.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.487 | Acc: 40.192,62.256,72.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.491 | Acc: 40.289,62.184,72.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.494 | Acc: 40.192,62.161,72.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.497 | Acc: 40.207,62.145,71.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.501 | Acc: 40.211,62.133,71.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.680 | Acc: 32.812,42.969,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.060 | Acc: 29.576,43.341,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.038 | Acc: 30.202,43.807,54.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.096 | Acc: 29.675,43.135,54.150,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 4.032 | Acc: 51.562,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 42.150,64.025,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.277 | Acc: 42.207,64.043,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.326 | Acc: 41.624,63.601,74.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 41.233,63.262,73.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.367 | Acc: 41.190,63.157,73.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.379 | Acc: 41.038,62.803,73.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.411 | Acc: 40.642,62.639,72.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.409 | Acc: 40.746,62.680,72.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.432 | Acc: 40.539,62.444,72.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.441 | Acc: 40.400,62.519,72.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.463 | Acc: 40.296,62.306,72.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.465 | Acc: 40.093,62.309,72.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.471 | Acc: 40.089,62.281,72.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.483 | Acc: 39.961,62.097,71.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.486 | Acc: 39.981,62.041,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.488 | Acc: 40.034,62.101,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.499 | Acc: 40.057,62.046,71.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.507 | Acc: 40.103,61.968,71.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.505 | Acc: 40.213,62.008,71.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.887 | Acc: 27.344,39.844,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.611 | Acc: 22.210,42.671,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.524 | Acc: 23.342,43.845,54.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.593 | Acc: 23.028,43.481,54.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 4.580 | Acc: 35.156,53.125,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.419 | Acc: 39.955,62.314,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.457 | Acc: 39.768,62.538,72.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.406 | Acc: 40.049,63.435,72.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.410 | Acc: 39.988,63.532,72.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.438 | Acc: 40.145,63.003,72.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.443 | Acc: 40.089,62.868,72.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.447 | Acc: 40.215,62.733,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.451 | Acc: 40.057,62.519,72.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.457 | Acc: 39.965,62.573,72.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.454 | Acc: 40.217,62.644,72.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.456 | Acc: 40.282,62.581,72.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.461 | Acc: 40.275,62.613,72.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.460 | Acc: 40.401,62.596,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.471 | Acc: 40.403,62.506,71.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.469 | Acc: 40.417,62.518,71.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.483 | Acc: 40.335,62.356,71.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.493 | Acc: 40.279,62.239,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.502 | Acc: 40.227,62.178,71.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.503 | Acc: 40.248,62.203,71.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.034 | Acc: 35.938,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.388 | Acc: 30.692,48.549,58.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.447 | Acc: 30.850,47.923,57.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.461 | Acc: 30.123,48.348,57.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 4.112 | Acc: 42.969,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.187 | Acc: 40.290,65.476,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.275 | Acc: 40.854,64.329,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.330 | Acc: 40.791,63.717,74.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.349 | Acc: 41.059,63.648,73.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.381 | Acc: 40.803,63.250,73.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.402 | Acc: 40.786,63.004,73.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.403 | Acc: 40.791,62.999,73.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.419 | Acc: 40.644,62.762,73.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.439 | Acc: 40.552,62.604,72.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.440 | Acc: 40.613,62.690,72.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.456 | Acc: 40.522,62.617,72.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.456 | Acc: 40.602,62.639,72.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.464 | Acc: 40.502,62.602,72.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.471 | Acc: 40.461,62.525,72.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.481 | Acc: 40.376,62.451,71.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.492 | Acc: 40.287,62.330,71.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.486 | Acc: 40.320,62.312,71.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.487 | Acc: 40.333,62.394,71.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.494 | Acc: 40.295,62.309,71.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.142 | Acc: 39.844,51.562,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.089 | Acc: 33.594,51.339,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.115 | Acc: 33.746,50.629,58.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.152 | Acc: 33.312,50.602,58.094,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 4.216 | Acc: 40.625,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.444 | Acc: 39.137,63.393,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.348 | Acc: 40.816,63.624,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.366 | Acc: 40.446,63.345,73.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.394 | Acc: 40.432,63.166,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.414 | Acc: 40.470,63.065,73.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.413 | Acc: 40.509,63.139,73.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.415 | Acc: 40.420,63.165,73.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.414 | Acc: 40.596,63.238,73.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.417 | Acc: 40.681,63.165,73.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.419 | Acc: 40.761,62.924,73.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.434 | Acc: 40.643,62.747,72.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.446 | Acc: 40.612,62.620,72.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.449 | Acc: 40.622,62.581,72.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.453 | Acc: 40.606,62.519,72.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.465 | Acc: 40.498,62.404,72.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.465 | Acc: 40.501,62.405,72.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.469 | Acc: 40.439,62.356,72.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.478 | Acc: 40.419,62.297,72.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.477 | Acc: 40.395,62.279,72.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.439 | Acc: 35.156,56.250,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.440 | Acc: 27.009,52.455,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.519 | Acc: 26.620,51.353,59.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.536 | Acc: 25.986,51.294,59.209,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 4.539 | Acc: 39.062,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.385 | Acc: 42.448,63.244,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.419 | Acc: 41.444,62.957,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.387 | Acc: 41.304,63.525,73.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.370 | Acc: 41.483,63.542,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.378 | Acc: 41.553,63.281,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.394 | Acc: 41.464,63.126,72.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.395 | Acc: 41.456,63.098,72.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.410 | Acc: 41.212,63.024,72.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.401 | Acc: 41.221,63.040,72.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.404 | Acc: 41.037,63.044,72.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.412 | Acc: 41.010,63.037,72.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.424 | Acc: 40.884,62.921,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.440 | Acc: 40.730,62.805,72.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.451 | Acc: 40.770,62.628,72.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.452 | Acc: 40.674,62.708,72.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.461 | Acc: 40.571,62.668,72.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.462 | Acc: 40.648,62.761,72.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.460 | Acc: 40.681,62.760,72.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.466 | Acc: 40.666,62.664,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.818 | Acc: 32.812,42.969,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.747 | Acc: 29.464,46.689,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.711 | Acc: 29.440,46.627,57.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.734 | Acc: 29.239,46.824,57.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 4.257 | Acc: 41.406,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.312 | Acc: 41.146,63.951,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.304 | Acc: 41.806,64.348,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 41.342,63.832,73.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.373 | Acc: 40.982,63.166,73.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.394 | Acc: 40.787,62.809,72.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.421 | Acc: 40.573,62.791,72.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.408 | Acc: 40.647,62.910,72.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.410 | Acc: 40.751,62.903,72.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.431 | Acc: 40.517,62.729,72.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.442 | Acc: 40.555,62.632,72.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.441 | Acc: 40.639,62.677,72.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.436 | Acc: 40.609,62.801,72.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.442 | Acc: 40.493,62.784,72.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.449 | Acc: 40.522,62.670,72.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.461 | Acc: 40.394,62.609,72.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.462 | Acc: 40.304,62.619,72.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.469 | Acc: 40.300,62.523,71.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.480 | Acc: 40.251,62.444,71.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.479 | Acc: 40.248,62.400,71.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.983 | Acc: 29.688,42.969,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.983 | Acc: 26.897,46.131,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.016 | Acc: 26.315,45.655,57.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.051 | Acc: 25.884,45.338,56.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 4.210 | Acc: 41.406,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.381 | Acc: 39.435,62.984,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.371 | Acc: 39.901,63.491,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.377 | Acc: 40.574,63.345,73.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.396 | Acc: 40.557,63.040,73.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.387 | Acc: 40.896,63.351,72.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.401 | Acc: 40.651,63.100,72.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.410 | Acc: 40.675,63.176,73.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.436 | Acc: 40.475,62.912,72.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.446 | Acc: 40.526,62.781,72.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.447 | Acc: 40.442,62.788,72.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.453 | Acc: 40.349,62.783,72.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.453 | Acc: 40.437,62.811,72.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.456 | Acc: 40.374,62.739,72.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.458 | Acc: 40.411,62.695,72.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.462 | Acc: 40.365,62.708,71.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.464 | Acc: 40.352,62.653,71.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.468 | Acc: 40.336,62.564,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.468 | Acc: 40.352,62.571,71.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.467 | Acc: 40.324,62.566,71.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.215 | Acc: 28.125,50.781,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.770 | Acc: 28.497,46.019,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.770 | Acc: 28.620,45.998,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.801 | Acc: 28.458,45.428,55.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.434 | Acc: 37.500,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.319 | Acc: 40.848,62.798,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.343 | Acc: 41.139,62.786,73.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 40.676,62.346,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.376 | Acc: 40.384,62.423,73.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.389 | Acc: 40.548,62.631,72.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.399 | Acc: 40.644,62.655,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.415 | Acc: 40.586,62.367,72.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.401 | Acc: 40.868,62.592,72.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.402 | Acc: 40.854,62.504,72.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.400 | Acc: 40.932,62.535,72.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.408 | Acc: 40.964,62.525,72.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.410 | Acc: 40.904,62.643,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.428 | Acc: 40.730,62.596,72.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.434 | Acc: 40.720,62.531,72.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.439 | Acc: 40.734,62.521,72.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.451 | Acc: 40.547,62.361,71.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.459 | Acc: 40.508,62.305,71.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.459 | Acc: 40.543,62.323,71.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.466 | Acc: 40.484,62.250,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.149 | Acc: 34.375,46.875,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.698 | Acc: 28.274,48.772,58.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.679 | Acc: 27.649,48.418,57.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.690 | Acc: 27.190,48.233,57.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 5.161 | Acc: 37.500,54.688,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.452 | Acc: 41.443,62.649,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.381 | Acc: 41.254,63.091,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.345 | Acc: 41.560,63.512,73.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.370 | Acc: 40.943,63.281,73.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.389 | Acc: 40.934,63.111,73.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.401 | Acc: 40.877,63.068,72.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.408 | Acc: 40.797,62.999,72.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.402 | Acc: 40.805,63.005,72.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.416 | Acc: 40.599,62.897,72.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.428 | Acc: 40.423,62.749,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.439 | Acc: 40.385,62.744,72.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.439 | Acc: 40.392,62.594,72.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.451 | Acc: 40.278,62.497,72.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.454 | Acc: 40.400,62.539,72.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.468 | Acc: 40.347,62.409,72.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.471 | Acc: 40.287,62.390,72.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.465 | Acc: 40.313,62.500,72.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.463 | Acc: 40.372,62.515,72.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.467 | Acc: 40.391,62.475,72.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.575 | Acc: 35.156,44.531,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.047 | Acc: 27.009,44.196,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.023 | Acc: 26.829,44.607,55.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.019 | Acc: 27.049,45.005,55.558,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 4.383 | Acc: 45.312,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.263 | Acc: 41.927,64.918,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.335 | Acc: 40.796,63.739,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.357 | Acc: 40.843,63.422,73.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.354 | Acc: 40.828,63.320,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.375 | Acc: 40.687,63.165,73.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.377 | Acc: 40.651,63.230,73.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.390 | Acc: 40.481,63.104,73.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.408 | Acc: 40.397,63.048,72.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.398 | Acc: 40.530,63.221,72.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.402 | Acc: 40.582,63.204,72.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.393 | Acc: 40.883,63.228,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.404 | Acc: 40.884,63.181,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.413 | Acc: 40.838,63.179,72.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.417 | Acc: 40.853,63.114,72.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.429 | Acc: 40.765,63.017,72.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.431 | Acc: 40.795,62.914,72.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.436 | Acc: 40.678,62.791,72.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.444 | Acc: 40.655,62.719,72.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.447 | Acc: 40.678,62.728,72.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.704 | Acc: 37.500,50.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.190 | Acc: 29.055,51.637,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.180 | Acc: 28.773,51.010,59.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.202 | Acc: 28.676,50.973,59.029,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 4.095 | Acc: 44.531,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.271 | Acc: 40.960,63.914,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.351 | Acc: 41.521,63.472,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.368 | Acc: 40.958,63.332,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.368 | Acc: 41.088,63.291,73.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.364 | Acc: 41.120,63.219,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.370 | Acc: 40.954,63.062,73.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.376 | Acc: 40.974,63.132,73.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.372 | Acc: 40.960,63.121,73.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.391 | Acc: 40.802,62.970,73.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.396 | Acc: 40.990,62.939,72.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.406 | Acc: 40.918,62.956,72.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.420 | Acc: 40.761,62.814,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.422 | Acc: 40.730,62.772,72.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.422 | Acc: 40.675,62.658,72.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.426 | Acc: 40.750,62.578,72.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.442 | Acc: 40.657,62.405,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.441 | Acc: 40.687,62.440,72.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.443 | Acc: 40.725,62.459,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.448 | Acc: 40.623,62.436,72.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.548 | Acc: 41.406,50.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.691 | Acc: 34.747,51.749,61.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.739 | Acc: 34.680,51.696,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.761 | Acc: 34.721,51.460,60.707,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 4.537 | Acc: 41.406,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.262 | Acc: 40.885,63.616,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.294 | Acc: 40.720,63.453,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.345 | Acc: 40.510,63.064,73.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.363 | Acc: 40.683,62.818,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.368 | Acc: 40.718,62.995,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.358 | Acc: 40.857,63.184,73.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.380 | Acc: 40.691,62.977,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.373 | Acc: 40.678,62.976,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.378 | Acc: 40.711,62.958,72.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.381 | Acc: 40.777,63.001,72.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.398 | Acc: 40.667,62.899,72.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.405 | Acc: 40.729,62.879,72.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.409 | Acc: 40.739,62.910,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.411 | Acc: 40.778,62.892,72.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.425 | Acc: 40.643,62.775,72.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.419 | Acc: 40.635,62.875,72.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.427 | Acc: 40.586,62.741,72.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.441 | Acc: 40.474,62.658,72.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.442 | Acc: 40.551,62.631,72.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.532 | Acc: 35.938,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.619 | Acc: 34.189,54.650,61.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.654 | Acc: 34.299,53.296,60.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.717 | Acc: 33.940,52.971,60.566,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 4.191 | Acc: 42.188,65.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 40.179,63.244,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.374 | Acc: 39.882,62.671,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.406 | Acc: 40.177,62.334,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.389 | Acc: 40.336,62.510,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.389 | Acc: 40.749,62.639,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.396 | Acc: 40.832,62.610,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.417 | Acc: 40.847,62.522,73.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.394 | Acc: 41.037,62.680,73.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.383 | Acc: 41.130,62.763,73.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.402 | Acc: 40.831,62.605,73.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.399 | Acc: 40.816,62.691,73.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.407 | Acc: 40.836,62.662,73.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.415 | Acc: 40.712,62.596,72.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.416 | Acc: 40.642,62.575,73.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.416 | Acc: 40.687,62.708,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.427 | Acc: 40.620,62.563,72.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.435 | Acc: 40.600,62.468,72.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.436 | Acc: 40.595,62.552,72.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.445 | Acc: 40.484,62.492,72.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.528 | Acc: 33.594,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.597 | Acc: 27.269,48.624,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.655 | Acc: 26.258,48.438,58.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.719 | Acc: 26.012,48.258,57.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 4.490 | Acc: 39.844,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.332 | Acc: 40.960,63.356,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.354 | Acc: 40.625,63.434,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.331 | Acc: 41.150,63.461,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.332 | Acc: 41.474,63.580,74.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.333 | Acc: 41.298,63.552,73.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.345 | Acc: 41.051,63.462,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.362 | Acc: 40.869,63.381,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.364 | Acc: 40.819,63.456,73.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.373 | Acc: 40.776,63.281,73.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.374 | Acc: 40.761,63.227,73.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.381 | Acc: 40.636,63.158,73.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.389 | Acc: 40.573,63.200,72.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.399 | Acc: 40.487,63.117,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.407 | Acc: 40.592,63.098,72.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.416 | Acc: 40.641,62.939,72.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.418 | Acc: 40.530,62.936,72.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.422 | Acc: 40.529,62.873,72.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.424 | Acc: 40.482,62.805,72.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.428 | Acc: 40.475,62.781,72.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.628 | Acc: 39.062,51.562,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.112 | Acc: 31.882,51.376,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.198 | Acc: 31.117,50.400,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.193 | Acc: 30.955,50.141,58.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 4.103 | Acc: 42.188,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.356 | Acc: 41.555,63.281,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.326 | Acc: 41.997,63.434,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.339 | Acc: 41.368,63.473,74.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.317 | Acc: 41.358,63.667,74.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.312 | Acc: 41.476,63.846,74.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.324 | Acc: 41.284,63.765,73.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.323 | Acc: 41.262,63.675,73.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.328 | Acc: 41.295,63.558,73.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.346 | Acc: 41.221,63.519,73.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.351 | Acc: 41.068,63.487,73.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.367 | Acc: 41.049,63.331,73.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.363 | Acc: 41.059,63.453,73.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.370 | Acc: 40.984,63.326,73.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.373 | Acc: 41.017,63.248,73.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.371 | Acc: 41.040,63.351,73.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.381 | Acc: 40.966,63.237,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.389 | Acc: 40.916,63.210,72.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.398 | Acc: 40.772,63.104,72.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.401 | Acc: 40.783,62.998,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.916 | Acc: 32.031,53.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.311 | Acc: 30.394,49.851,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.300 | Acc: 30.354,50.038,57.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.317 | Acc: 30.353,49.782,57.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 3.700 | Acc: 40.625,69.531,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.293 | Acc: 41.295,65.402,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.391 | Acc: 40.415,63.872,73.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.386 | Acc: 40.049,63.973,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.368 | Acc: 40.210,63.985,73.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.387 | Acc: 40.261,63.993,73.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.404 | Acc: 40.154,63.604,73.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.412 | Acc: 40.182,63.619,72.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.409 | Acc: 40.111,63.597,72.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.415 | Acc: 39.982,63.652,72.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.408 | Acc: 40.042,63.713,72.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.426 | Acc: 40.013,63.571,72.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.420 | Acc: 40.110,63.479,72.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.423 | Acc: 40.041,63.344,72.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.424 | Acc: 40.075,63.348,72.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.414 | Acc: 40.262,63.398,72.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.410 | Acc: 40.396,63.408,72.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.421 | Acc: 40.417,63.258,72.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.427 | Acc: 40.443,63.214,72.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.436 | Acc: 40.358,63.134,72.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.246 | Acc: 27.344,39.062,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.267 | Acc: 24.926,41.741,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.293 | Acc: 25.019,42.569,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.337 | Acc: 24.385,42.777,54.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 4.386 | Acc: 42.969,60.156,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 41.815,62.984,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 41.806,63.415,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.302 | Acc: 41.855,63.730,73.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.290 | Acc: 41.744,64.024,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.305 | Acc: 41.878,63.962,74.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.313 | Acc: 41.671,63.882,73.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.330 | Acc: 41.595,63.852,73.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.340 | Acc: 41.338,63.616,73.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.333 | Acc: 41.268,63.501,73.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.340 | Acc: 41.317,63.507,73.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.362 | Acc: 41.141,63.359,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.371 | Acc: 41.053,63.317,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.391 | Acc: 40.861,63.120,72.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.398 | Acc: 40.731,63.056,72.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.405 | Acc: 40.734,62.967,72.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.409 | Acc: 40.849,62.919,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.408 | Acc: 40.902,62.938,72.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.409 | Acc: 40.852,62.948,72.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.414 | Acc: 40.871,62.896,72.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.095 | Acc: 42.969,48.438,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.671 | Acc: 32.440,44.866,56.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.587 | Acc: 32.622,45.274,56.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.635 | Acc: 32.223,44.877,56.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 4.403 | Acc: 39.062,58.594,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.324 | Acc: 40.848,63.207,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.301 | Acc: 40.873,63.396,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.273 | Acc: 41.189,63.960,74.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.307 | Acc: 40.924,63.648,74.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.305 | Acc: 41.197,63.482,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.301 | Acc: 41.238,63.527,73.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.308 | Acc: 41.240,63.597,73.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.322 | Acc: 41.406,63.335,73.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.339 | Acc: 41.316,63.428,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.342 | Acc: 41.317,63.347,73.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.353 | Acc: 41.283,63.295,73.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.367 | Acc: 41.189,63.190,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.374 | Acc: 41.089,63.105,73.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.379 | Acc: 41.106,63.031,73.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.386 | Acc: 41.108,63.027,72.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.387 | Acc: 41.097,63.062,72.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.392 | Acc: 41.138,63.059,72.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.401 | Acc: 41.015,62.957,72.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.406 | Acc: 40.980,62.883,72.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.567 | Acc: 24.219,40.625,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.515 | Acc: 23.363,45.312,55.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.560 | Acc: 23.647,44.741,55.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.605 | Acc: 23.322,44.787,55.328,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 4.360 | Acc: 43.750,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.466 | Acc: 40.402,61.533,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.424 | Acc: 40.206,62.386,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.376 | Acc: 40.369,62.974,73.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.326 | Acc: 40.394,63.773,74.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.323 | Acc: 40.463,63.699,73.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.342 | Acc: 40.554,63.527,73.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.356 | Acc: 40.464,63.375,73.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.372 | Acc: 40.421,63.306,73.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.378 | Acc: 40.590,63.273,73.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.372 | Acc: 40.765,63.394,73.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.380 | Acc: 40.735,63.225,73.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.395 | Acc: 40.683,63.174,73.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.395 | Acc: 40.721,63.129,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.387 | Acc: 40.733,63.164,73.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.383 | Acc: 40.690,63.214,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.387 | Acc: 40.598,63.245,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.383 | Acc: 40.623,63.304,73.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.396 | Acc: 40.551,63.167,73.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.404 | Acc: 40.514,63.148,72.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.363 | Acc: 25.781,49.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.761 | Acc: 26.116,45.647,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.731 | Acc: 26.886,45.713,56.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.726 | Acc: 26.639,45.748,56.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 4.307 | Acc: 39.844,60.938,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.276 | Acc: 41.629,64.249,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.303 | Acc: 41.082,64.234,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.303 | Acc: 41.432,63.870,74.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.329 | Acc: 41.107,63.638,73.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.329 | Acc: 41.360,63.475,73.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.340 | Acc: 41.296,63.352,73.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.339 | Acc: 41.362,63.470,73.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.342 | Acc: 41.086,63.451,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.353 | Acc: 41.022,63.281,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.356 | Acc: 41.021,63.188,73.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.356 | Acc: 40.975,63.246,73.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.359 | Acc: 40.969,63.317,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.367 | Acc: 40.972,63.377,73.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.378 | Acc: 40.903,63.295,73.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.384 | Acc: 40.809,63.294,73.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.381 | Acc: 40.898,63.296,73.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.384 | Acc: 40.847,63.313,73.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.387 | Acc: 40.839,63.195,72.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.383 | Acc: 40.908,63.300,72.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.472 | Acc: 28.906,36.719,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.550 | Acc: 24.442,42.448,50.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.569 | Acc: 24.657,41.444,50.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.598 | Acc: 24.398,41.573,50.538,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 3.933 | Acc: 40.625,71.875,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.237 | Acc: 41.629,65.365,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.242 | Acc: 41.597,64.558,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.272 | Acc: 41.227,64.075,74.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.313 | Acc: 40.856,63.725,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.322 | Acc: 41.019,63.637,73.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.332 | Acc: 40.799,63.623,73.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.333 | Acc: 40.747,63.630,73.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.334 | Acc: 40.775,63.645,73.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.357 | Acc: 40.638,63.372,73.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.366 | Acc: 40.629,63.312,73.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.373 | Acc: 40.724,63.317,73.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.389 | Acc: 40.735,63.135,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.404 | Acc: 40.706,63.030,72.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.409 | Acc: 40.731,62.995,72.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.406 | Acc: 40.781,63.009,72.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.408 | Acc: 40.795,63.091,72.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.409 | Acc: 40.829,63.112,72.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.421 | Acc: 40.727,63.002,72.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.421 | Acc: 40.697,63.021,72.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.593 | Acc: 30.469,49.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.649 | Acc: 28.460,48.289,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.747 | Acc: 26.772,47.294,57.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.815 | Acc: 26.627,47.298,57.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 3.998 | Acc: 46.094,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 41.332,63.653,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.282 | Acc: 41.120,63.815,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.319 | Acc: 40.625,63.179,74.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.335 | Acc: 40.876,63.088,73.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.352 | Acc: 40.640,63.011,73.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.340 | Acc: 40.857,63.139,73.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.347 | Acc: 40.841,63.054,73.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.347 | Acc: 40.678,63.073,73.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.347 | Acc: 40.772,63.147,73.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.358 | Acc: 40.703,63.122,73.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.369 | Acc: 40.728,62.984,73.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.366 | Acc: 40.810,63.025,73.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.366 | Acc: 40.891,63.105,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.367 | Acc: 40.931,63.114,73.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.365 | Acc: 40.853,63.175,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.364 | Acc: 40.851,63.245,73.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.366 | Acc: 40.815,63.217,73.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.373 | Acc: 40.714,63.160,73.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.377 | Acc: 40.631,63.064,73.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.592 | Acc: 41.406,48.438,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.803 | Acc: 36.607,50.670,58.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.881 | Acc: 36.223,49.943,57.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.922 | Acc: 35.720,49.910,57.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 4.600 | Acc: 40.625,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.245 | Acc: 40.662,64.732,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.163 | Acc: 42.073,66.235,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.197 | Acc: 41.919,65.830,75.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.224 | Acc: 41.917,65.239,75.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.238 | Acc: 41.801,65.037,75.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.274 | Acc: 41.561,64.514,74.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.294 | Acc: 41.639,64.234,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.309 | Acc: 41.353,63.995,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.309 | Acc: 41.475,63.907,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.306 | Acc: 41.581,63.872,74.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.304 | Acc: 41.569,63.865,74.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.299 | Acc: 41.614,63.871,74.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.303 | Acc: 41.613,63.838,73.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.311 | Acc: 41.465,63.768,73.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.320 | Acc: 41.349,63.722,73.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.336 | Acc: 41.250,63.627,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.347 | Acc: 41.179,63.483,73.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.355 | Acc: 41.173,63.441,73.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.372 | Acc: 41.027,63.230,73.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.397 | Acc: 33.594,49.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.272 | Acc: 28.906,51.116,58.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.342 | Acc: 28.525,50.667,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.402 | Acc: 28.202,49.885,58.107,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 4.180 | Acc: 43.750,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.224 | Acc: 42.076,64.435,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.219 | Acc: 42.073,64.710,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.253 | Acc: 41.842,64.549,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.253 | Acc: 42.052,64.497,74.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.265 | Acc: 41.785,64.488,74.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.288 | Acc: 41.368,64.192,74.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.290 | Acc: 41.495,64.068,74.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.302 | Acc: 41.372,63.975,73.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.314 | Acc: 41.238,63.782,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.319 | Acc: 41.204,63.825,73.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.326 | Acc: 41.102,63.766,73.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.335 | Acc: 41.056,63.699,73.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.332 | Acc: 41.155,63.634,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.336 | Acc: 41.273,63.593,73.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.342 | Acc: 41.243,63.556,73.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.347 | Acc: 41.207,63.493,73.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.349 | Acc: 41.152,63.492,73.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.358 | Acc: 41.136,63.392,72.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.360 | Acc: 41.164,63.355,72.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.156 | Acc: 32.812,53.906,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.274 | Acc: 29.092,49.888,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.363 | Acc: 28.392,49.219,58.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.425 | Acc: 27.894,48.988,57.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 4.549 | Acc: 42.188,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.343 | Acc: 41.295,63.318,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.344 | Acc: 40.549,63.377,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.310 | Acc: 40.394,63.858,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.319 | Acc: 40.461,63.956,74.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.344 | Acc: 40.362,63.598,73.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.320 | Acc: 40.961,63.869,73.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.326 | Acc: 41.057,63.736,73.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.340 | Acc: 41.120,63.728,73.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.355 | Acc: 41.018,63.601,73.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.358 | Acc: 41.006,63.522,73.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.357 | Acc: 40.989,63.606,73.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.362 | Acc: 40.956,63.541,73.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.361 | Acc: 40.984,63.557,73.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.361 | Acc: 41.050,63.537,73.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.363 | Acc: 41.040,63.515,73.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.360 | Acc: 41.085,63.498,73.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.358 | Acc: 41.065,63.524,73.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.362 | Acc: 41.112,63.485,73.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.360 | Acc: 41.144,63.490,73.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.977 | Acc: 40.625,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.177 | Acc: 33.259,48.251,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.178 | Acc: 33.041,48.266,58.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.206 | Acc: 32.595,48.361,58.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 3.784 | Acc: 52.344,74.219,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.251 | Acc: 41.667,65.513,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.292 | Acc: 41.063,64.158,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.261 | Acc: 41.240,64.498,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.269 | Acc: 41.184,64.361,74.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.289 | Acc: 41.074,64.256,73.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.282 | Acc: 41.258,64.314,73.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.274 | Acc: 41.223,64.328,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.296 | Acc: 41.023,64.126,73.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.292 | Acc: 41.182,64.127,73.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.304 | Acc: 41.169,63.911,73.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.324 | Acc: 41.053,63.677,73.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.325 | Acc: 41.196,63.735,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.325 | Acc: 41.236,63.739,73.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.333 | Acc: 41.184,63.607,73.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.346 | Acc: 41.103,63.427,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.348 | Acc: 41.182,63.447,73.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.352 | Acc: 41.166,63.380,73.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.354 | Acc: 41.160,63.405,73.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.357 | Acc: 41.138,63.333,73.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.484 | Acc: 34.375,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.574 | Acc: 29.353,49.293,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.645 | Acc: 28.887,48.761,59.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.667 | Acc: 28.612,48.783,58.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 5.039 | Acc: 32.031,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.141 | Acc: 41.146,65.476,76.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.184 | Acc: 41.178,64.863,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.193 | Acc: 41.022,64.959,75.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.226 | Acc: 41.127,64.660,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.259 | Acc: 41.043,64.333,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.280 | Acc: 41.271,64.224,73.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.287 | Acc: 41.406,64.079,73.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.294 | Acc: 41.464,63.902,73.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.309 | Acc: 41.354,63.816,73.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 41.348,63.891,73.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.321 | Acc: 41.300,63.720,73.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.332 | Acc: 41.205,63.592,73.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.328 | Acc: 41.233,63.646,73.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.324 | Acc: 41.284,63.779,73.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.331 | Acc: 41.227,63.743,73.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.345 | Acc: 41.139,63.595,73.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.357 | Acc: 41.047,63.508,73.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.361 | Acc: 40.960,63.454,73.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.364 | Acc: 40.969,63.464,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.717 | Acc: 27.344,42.188,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.040 | Acc: 24.368,39.472,50.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.091 | Acc: 23.952,38.377,49.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.161 | Acc: 23.642,37.948,49.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 3.913 | Acc: 47.656,70.312,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.351 | Acc: 40.997,63.690,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.371 | Acc: 40.949,63.434,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.339 | Acc: 40.894,63.960,74.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.328 | Acc: 40.856,64.091,74.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.312 | Acc: 41.043,64.093,73.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.319 | Acc: 41.077,64.011,73.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.338 | Acc: 41.168,63.930,73.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.344 | Acc: 41.159,63.927,73.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.350 | Acc: 41.264,63.773,73.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.344 | Acc: 41.192,63.802,73.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.340 | Acc: 41.258,63.872,73.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.338 | Acc: 41.322,63.829,73.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.338 | Acc: 41.322,63.793,73.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.343 | Acc: 41.253,63.696,73.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.354 | Acc: 41.313,63.538,73.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.348 | Acc: 41.479,63.583,73.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.352 | Acc: 41.505,63.513,73.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.346 | Acc: 41.566,63.524,73.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.354 | Acc: 41.472,63.466,73.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.993 | Acc: 25.000,46.875,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.859 | Acc: 21.987,43.304,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.996 | Acc: 21.437,42.683,54.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.077 | Acc: 20.645,42.226,54.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 4.528 | Acc: 39.062,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.272 | Acc: 41.518,62.612,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.281 | Acc: 41.330,62.976,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 40.907,63.256,74.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.321 | Acc: 40.664,63.185,73.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.298 | Acc: 41.236,63.598,73.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.295 | Acc: 41.213,63.527,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.303 | Acc: 41.129,63.470,73.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.301 | Acc: 41.188,63.470,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.304 | Acc: 41.272,63.562,73.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.301 | Acc: 41.410,63.608,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.306 | Acc: 41.470,63.582,73.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.312 | Acc: 41.461,63.625,73.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.328 | Acc: 41.370,63.389,73.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.331 | Acc: 41.401,63.404,73.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.327 | Acc: 41.507,63.512,73.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.334 | Acc: 41.452,63.449,73.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.340 | Acc: 41.399,63.391,73.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.341 | Acc: 41.343,63.374,73.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.343 | Acc: 41.351,63.363,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.427 | Acc: 31.250,53.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.111 | Acc: 26.823,46.205,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.036 | Acc: 26.867,46.208,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.088 | Acc: 26.793,46.504,56.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 4.209 | Acc: 37.500,62.500,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.140 | Acc: 40.625,65.513,76.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.262 | Acc: 39.691,64.005,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.238 | Acc: 39.946,64.511,75.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.229 | Acc: 40.557,64.709,74.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.245 | Acc: 40.958,64.565,74.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.262 | Acc: 40.677,64.288,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.278 | Acc: 40.891,64.151,74.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.301 | Acc: 40.872,63.946,74.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.325 | Acc: 40.944,63.678,73.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.340 | Acc: 40.819,63.635,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.351 | Acc: 40.819,63.507,73.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.357 | Acc: 40.813,63.443,73.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.368 | Acc: 40.691,63.323,73.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.365 | Acc: 40.695,63.365,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.359 | Acc: 40.851,63.393,73.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.361 | Acc: 40.876,63.388,73.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.363 | Acc: 40.806,63.373,73.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.363 | Acc: 40.945,63.335,73.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.362 | Acc: 40.982,63.294,73.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.605 | Acc: 32.812,42.188,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.796 | Acc: 29.129,46.540,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.829 | Acc: 28.754,46.056,56.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.833 | Acc: 28.560,45.914,56.596,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 4.051 | Acc: 45.312,62.500,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.221 | Acc: 41.481,64.360,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.298 | Acc: 40.434,64.577,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.274 | Acc: 41.137,64.857,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.281 | Acc: 41.483,64.361,74.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.290 | Acc: 41.406,64.225,73.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.309 | Acc: 41.400,64.121,73.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.314 | Acc: 41.279,64.007,73.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.332 | Acc: 41.144,63.902,73.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.350 | Acc: 40.953,63.640,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.348 | Acc: 41.018,63.503,73.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.354 | Acc: 40.954,63.571,73.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.349 | Acc: 41.066,63.605,73.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.353 | Acc: 41.059,63.488,73.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.348 | Acc: 41.134,63.506,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.341 | Acc: 41.204,63.541,73.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.341 | Acc: 41.185,63.571,73.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.345 | Acc: 41.159,63.563,73.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.343 | Acc: 41.203,63.532,73.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.349 | Acc: 41.263,63.480,73.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.923 | Acc: 27.344,50.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.681 | Acc: 23.028,45.312,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.653 | Acc: 22.790,45.084,54.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.636 | Acc: 22.720,44.826,54.316,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 4.484 | Acc: 35.156,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.360 | Acc: 40.327,62.649,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.317 | Acc: 41.730,63.720,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.336 | Acc: 41.393,63.678,74.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.297 | Acc: 41.155,64.371,74.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.310 | Acc: 40.873,64.380,74.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.308 | Acc: 40.883,64.418,74.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.305 | Acc: 40.969,64.207,74.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.301 | Acc: 40.887,64.227,74.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.323 | Acc: 40.711,63.950,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.341 | Acc: 40.847,63.856,73.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.351 | Acc: 40.735,63.575,73.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.356 | Acc: 40.781,63.443,73.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.364 | Acc: 40.730,63.350,73.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.361 | Acc: 40.836,63.401,73.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.361 | Acc: 40.840,63.445,73.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.352 | Acc: 40.954,63.612,73.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.345 | Acc: 41.104,63.625,73.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.346 | Acc: 41.114,63.550,73.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.354 | Acc: 41.113,63.456,73.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.273 | Acc: 30.469,42.969,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.382 | Acc: 27.121,45.275,54.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.505 | Acc: 26.391,44.474,53.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.540 | Acc: 25.653,44.314,53.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 4.347 | Acc: 42.188,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.231 | Acc: 43.341,64.509,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.235 | Acc: 42.207,64.463,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.217 | Acc: 42.149,64.536,74.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.217 | Acc: 42.024,64.487,74.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.238 | Acc: 42.071,64.341,74.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.268 | Acc: 41.807,64.172,73.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.278 | Acc: 41.766,63.990,73.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.270 | Acc: 41.751,64.189,73.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.272 | Acc: 41.708,64.248,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.271 | Acc: 41.651,64.350,73.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.274 | Acc: 41.477,64.204,73.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.279 | Acc: 41.400,64.147,73.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.288 | Acc: 41.263,64.092,73.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.294 | Acc: 41.237,63.932,73.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.294 | Acc: 41.212,63.961,73.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.299 | Acc: 41.207,63.965,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.309 | Acc: 41.173,63.916,73.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.322 | Acc: 41.110,63.742,73.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.334 | Acc: 41.039,63.632,73.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.789 | Acc: 24.219,44.531,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.681 | Acc: 23.214,43.713,51.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.674 | Acc: 22.294,43.140,51.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.700 | Acc: 22.208,42.713,51.716,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 4.689 | Acc: 37.500,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.229 | Acc: 43.006,64.509,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.272 | Acc: 41.921,64.463,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.270 | Acc: 41.842,64.088,74.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.271 | Acc: 41.753,64.188,74.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.273 | Acc: 41.654,64.418,74.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.285 | Acc: 41.490,64.263,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.273 | Acc: 41.528,64.317,74.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.280 | Acc: 41.387,64.179,74.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.283 | Acc: 41.320,64.088,74.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.293 | Acc: 41.208,64.269,73.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.299 | Acc: 41.056,64.356,73.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.307 | Acc: 41.121,64.199,73.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.309 | Acc: 41.146,64.176,73.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.317 | Acc: 41.192,64.001,73.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.313 | Acc: 41.297,64.008,73.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.316 | Acc: 41.268,63.948,73.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.321 | Acc: 41.189,63.888,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.324 | Acc: 41.285,63.846,73.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.327 | Acc: 41.357,63.759,73.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.446 | Acc: 28.906,42.969,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.598 | Acc: 22.210,43.862,54.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.685 | Acc: 22.428,43.769,54.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.738 | Acc: 22.157,43.660,54.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 4.912 | Acc: 39.062,55.469,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.166 | Acc: 42.708,64.769,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.124 | Acc: 42.302,65.415,75.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.135 | Acc: 41.688,65.382,75.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.175 | Acc: 41.512,65.143,75.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.189 | Acc: 41.600,64.906,75.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.224 | Acc: 41.406,64.637,74.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.231 | Acc: 41.340,64.522,74.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.251 | Acc: 41.251,64.363,74.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.251 | Acc: 41.130,64.339,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.255 | Acc: 41.192,64.370,74.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.267 | Acc: 41.215,64.260,74.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.271 | Acc: 41.264,64.221,74.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.289 | Acc: 41.239,64.024,73.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.294 | Acc: 41.312,63.993,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.298 | Acc: 41.243,63.912,73.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.309 | Acc: 41.190,63.800,73.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.314 | Acc: 41.230,63.755,73.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.320 | Acc: 41.157,63.662,73.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.329 | Acc: 41.099,63.564,73.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.327 | Acc: 28.125,45.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.171 | Acc: 26.302,49.814,56.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.237 | Acc: 26.029,48.152,55.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.252 | Acc: 25.640,48.258,55.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 4.526 | Acc: 38.281,60.156,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.203 | Acc: 42.001,65.253,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.199 | Acc: 42.473,64.825,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.180 | Acc: 42.200,64.869,75.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.179 | Acc: 42.419,64.805,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.198 | Acc: 42.110,64.790,74.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.215 | Acc: 41.949,64.682,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.243 | Acc: 41.872,64.262,74.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.278 | Acc: 41.523,63.825,73.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.280 | Acc: 41.588,63.890,74.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.292 | Acc: 41.542,63.825,73.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.307 | Acc: 41.495,63.688,73.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.312 | Acc: 41.416,63.686,73.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.312 | Acc: 41.334,63.652,73.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.311 | Acc: 41.431,63.659,73.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.310 | Acc: 41.448,63.738,73.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.320 | Acc: 41.377,63.547,73.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.325 | Acc: 41.335,63.542,73.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.332 | Acc: 41.246,63.521,73.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.338 | Acc: 41.222,63.458,73.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.958 | Acc: 35.938,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.156 | Acc: 33.929,50.037,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.204 | Acc: 33.727,49.695,57.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.202 | Acc: 33.581,49.654,57.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 4.406 | Acc: 39.844,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.310 | Acc: 41.890,63.095,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.283 | Acc: 41.330,63.739,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.281 | Acc: 41.432,63.678,74.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.248 | Acc: 41.725,64.082,74.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.246 | Acc: 41.839,64.163,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.252 | Acc: 41.716,64.256,74.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.263 | Acc: 41.633,64.057,73.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.272 | Acc: 41.518,63.985,73.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.275 | Acc: 41.523,64.075,73.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.278 | Acc: 41.426,64.156,74.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.271 | Acc: 41.445,64.108,74.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.271 | Acc: 41.432,64.030,74.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.265 | Acc: 41.610,64.045,74.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.269 | Acc: 41.612,64.010,73.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.274 | Acc: 41.658,63.844,73.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.289 | Acc: 41.535,63.758,73.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.295 | Acc: 41.406,63.687,73.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.301 | Acc: 41.339,63.569,73.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.300 | Acc: 41.310,63.577,73.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.671 | Acc: 30.469,47.656,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.083 | Acc: 24.814,47.507,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.102 | Acc: 24.733,47.523,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.124 | Acc: 24.974,47.682,58.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 3.954 | Acc: 43.750,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.277 | Acc: 42.039,63.356,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.290 | Acc: 41.540,63.415,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.276 | Acc: 41.470,63.870,74.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.250 | Acc: 41.387,64.140,74.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.224 | Acc: 41.731,64.527,74.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.236 | Acc: 41.548,64.347,74.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.238 | Acc: 41.584,64.467,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.234 | Acc: 41.688,64.538,74.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.239 | Acc: 41.596,64.533,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.247 | Acc: 41.538,64.533,74.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.254 | Acc: 41.565,64.529,74.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.265 | Acc: 41.461,64.341,74.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.270 | Acc: 41.379,64.317,74.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.271 | Acc: 41.398,64.257,74.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.278 | Acc: 41.414,64.223,73.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.291 | Acc: 41.341,64.065,73.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.294 | Acc: 41.390,64.017,73.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.298 | Acc: 41.411,64.021,73.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.301 | Acc: 41.402,64.021,73.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.111 | Acc: 35.938,46.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.489 | Acc: 32.254,48.065,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.398 | Acc: 32.260,48.533,56.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.411 | Acc: 31.980,48.502,56.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 4.766 | Acc: 31.250,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.391 | Acc: 39.286,63.914,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 39.558,64.120,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.287 | Acc: 39.882,64.498,75.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.272 | Acc: 40.461,64.844,75.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.259 | Acc: 40.749,64.851,75.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.278 | Acc: 40.715,64.495,74.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.287 | Acc: 40.697,64.533,74.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.286 | Acc: 40.906,64.305,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.293 | Acc: 40.763,64.196,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.297 | Acc: 40.913,64.101,74.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.293 | Acc: 41.014,64.077,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.283 | Acc: 41.069,64.195,74.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.282 | Acc: 41.173,64.146,74.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.279 | Acc: 41.348,64.151,73.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.288 | Acc: 41.349,64.164,73.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.298 | Acc: 41.195,64.077,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.308 | Acc: 41.195,63.975,73.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.313 | Acc: 41.157,63.874,73.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.314 | Acc: 41.205,63.874,73.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.044 | Acc: 28.125,42.969,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.027 | Acc: 24.442,45.015,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.049 | Acc: 24.352,45.122,55.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.041 | Acc: 23.796,45.210,55.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 4.196 | Acc: 42.969,66.406,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.200 | Acc: 41.927,64.360,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.255 | Acc: 41.521,64.501,75.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.200 | Acc: 41.637,64.921,75.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.207 | Acc: 42.014,64.506,75.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.201 | Acc: 41.878,64.743,75.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.206 | Acc: 42.039,64.618,75.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.225 | Acc: 41.750,64.545,74.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.250 | Acc: 41.489,64.402,74.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.253 | Acc: 41.471,64.386,74.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.252 | Acc: 41.496,64.401,74.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.254 | Acc: 41.477,64.395,74.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.262 | Acc: 41.283,64.254,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.255 | Acc: 41.406,64.278,74.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.259 | Acc: 41.381,64.268,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.261 | Acc: 41.409,64.278,74.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.272 | Acc: 41.379,64.172,74.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.287 | Acc: 41.308,64.035,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.304 | Acc: 41.209,63.870,73.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.315 | Acc: 41.181,63.827,73.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.391 | Acc: 38.281,51.562,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.298 | Acc: 33.743,46.243,58.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.372 | Acc: 33.251,45.465,57.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.374 | Acc: 33.094,45.466,57.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 3.927 | Acc: 50.000,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.096 | Acc: 43.713,66.257,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.150 | Acc: 42.511,65.377,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.186 | Acc: 41.662,65.330,75.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.217 | Acc: 41.618,64.969,75.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.242 | Acc: 41.607,64.720,74.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.240 | Acc: 41.703,64.579,74.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.240 | Acc: 41.783,64.611,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.245 | Acc: 41.634,64.640,74.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.244 | Acc: 41.670,64.701,74.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.251 | Acc: 41.573,64.533,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.272 | Acc: 41.374,64.260,73.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.268 | Acc: 41.478,64.325,73.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.276 | Acc: 41.415,64.284,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.288 | Acc: 41.323,64.171,73.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.291 | Acc: 41.370,64.117,73.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.299 | Acc: 41.362,64.058,73.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.311 | Acc: 41.324,63.994,73.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.313 | Acc: 41.456,63.922,73.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.314 | Acc: 41.447,63.890,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.798 | Acc: 26.562,47.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.015 | Acc: 25.037,48.475,59.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.018 | Acc: 24.657,48.056,58.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.008 | Acc: 24.641,48.117,58.094,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 4.275 | Acc: 40.625,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.086 | Acc: 41.369,66.109,77.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 41.978,66.502,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.107 | Acc: 41.957,66.086,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.166 | Acc: 41.570,65.586,75.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.167 | Acc: 41.886,65.524,75.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.185 | Acc: 41.884,65.037,75.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.199 | Acc: 41.789,64.844,75.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.212 | Acc: 41.756,64.849,75.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.219 | Acc: 41.808,64.710,74.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.227 | Acc: 41.647,64.568,74.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.225 | Acc: 41.647,64.586,74.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.232 | Acc: 41.575,64.601,74.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.240 | Acc: 41.535,64.538,74.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.245 | Acc: 41.492,64.482,74.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.266 | Acc: 41.315,64.338,74.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.268 | Acc: 41.372,64.345,73.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.271 | Acc: 41.328,64.335,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.282 | Acc: 41.274,64.283,73.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.290 | Acc: 41.220,64.208,73.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.044 | Acc: 39.062,52.344,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.273 | Acc: 29.464,48.438,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.352 | Acc: 29.859,47.351,56.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.401 | Acc: 29.303,47.477,56.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 4.276 | Acc: 37.500,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.355 | Acc: 40.923,62.612,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.279 | Acc: 41.902,63.281,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.302 | Acc: 41.406,63.550,74.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.231 | Acc: 41.995,64.198,74.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.220 | Acc: 41.816,64.325,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.205 | Acc: 41.677,64.527,75.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.203 | Acc: 41.733,64.484,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.211 | Acc: 41.794,64.441,75.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.220 | Acc: 41.976,64.399,74.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.233 | Acc: 42.016,64.354,74.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.242 | Acc: 42.035,64.282,74.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.247 | Acc: 41.987,64.173,74.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.253 | Acc: 41.933,64.125,74.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.259 | Acc: 41.834,64.143,74.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.265 | Acc: 41.666,64.179,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.278 | Acc: 41.516,64.121,74.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.288 | Acc: 41.390,64.046,73.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.294 | Acc: 41.311,63.956,73.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.299 | Acc: 41.367,63.927,73.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.892 | Acc: 34.375,53.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.990 | Acc: 32.366,51.860,60.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.008 | Acc: 31.745,51.029,60.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.020 | Acc: 31.378,51.242,59.580,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 4.212 | Acc: 41.406,60.938,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.208 | Acc: 42.076,65.699,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.177 | Acc: 41.825,65.263,75.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.174 | Acc: 42.188,65.407,75.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.196 | Acc: 41.889,65.162,75.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.203 | Acc: 41.894,65.045,75.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.225 | Acc: 41.813,64.747,75.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.241 | Acc: 41.844,64.489,74.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.248 | Acc: 41.727,64.422,74.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.264 | Acc: 41.566,64.326,74.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.255 | Acc: 41.608,64.397,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.260 | Acc: 41.587,64.289,74.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.268 | Acc: 41.588,64.169,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.282 | Acc: 41.454,64.068,74.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.283 | Acc: 41.417,64.001,73.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.285 | Acc: 41.375,63.959,73.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.292 | Acc: 41.336,63.858,73.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.298 | Acc: 41.363,63.852,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.304 | Acc: 41.266,63.798,73.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.314 | Acc: 41.246,63.718,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.975 | Acc: 35.156,50.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.101 | Acc: 26.972,46.019,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.217 | Acc: 26.391,44.760,54.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.289 | Acc: 25.832,44.185,53.868,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 4.763 | Acc: 34.375,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.166 | Acc: 42.820,64.435,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.158 | Acc: 42.664,65.130,75.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.166 | Acc: 41.867,64.793,75.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.176 | Acc: 41.956,64.892,75.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.195 | Acc: 42.064,64.519,75.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.220 | Acc: 41.852,64.469,74.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.235 | Acc: 41.777,64.262,74.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.256 | Acc: 41.615,64.087,74.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.266 | Acc: 41.704,63.950,74.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.268 | Acc: 41.686,63.969,74.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.270 | Acc: 41.703,63.921,74.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.289 | Acc: 41.627,63.764,74.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.292 | Acc: 41.649,63.781,74.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.286 | Acc: 41.637,63.954,74.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.288 | Acc: 41.687,63.979,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.292 | Acc: 41.659,63.965,73.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.293 | Acc: 41.656,63.962,73.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.298 | Acc: 41.588,63.894,73.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.294 | Acc: 41.622,63.896,73.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.021 | Acc: 29.688,41.406,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.835 | Acc: 29.353,47.210,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.843 | Acc: 28.296,47.618,56.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.887 | Acc: 28.023,47.246,55.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 4.045 | Acc: 47.656,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.126 | Acc: 42.299,64.807,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.149 | Acc: 42.340,65.111,75.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.203 | Acc: 42.469,64.857,75.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.185 | Acc: 42.351,65.008,75.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.187 | Acc: 42.203,64.921,75.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.186 | Acc: 42.291,64.876,75.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.180 | Acc: 42.276,64.982,75.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.196 | Acc: 42.270,64.786,75.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.208 | Acc: 42.049,64.550,74.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.205 | Acc: 42.028,64.649,74.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.208 | Acc: 41.982,64.550,74.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.219 | Acc: 41.876,64.419,74.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.226 | Acc: 41.876,64.452,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.236 | Acc: 41.823,64.363,74.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.235 | Acc: 41.783,64.317,74.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.240 | Acc: 41.749,64.296,74.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.251 | Acc: 41.612,64.195,74.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.255 | Acc: 41.558,64.201,74.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.263 | Acc: 41.544,64.140,74.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.328 | Acc: 32.031,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.125 | Acc: 29.799,50.856,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.229 | Acc: 28.392,49.505,59.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.210 | Acc: 28.445,49.616,59.004,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 4.147 | Acc: 37.500,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.240 | Acc: 40.327,64.286,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.193 | Acc: 40.758,65.682,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.191 | Acc: 40.881,65.279,75.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.221 | Acc: 41.011,64.979,75.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.234 | Acc: 41.120,64.828,74.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.241 | Acc: 41.096,64.728,74.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.234 | Acc: 41.118,64.766,74.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.231 | Acc: 41.261,64.786,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.234 | Acc: 41.380,64.788,74.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.232 | Acc: 41.577,64.684,74.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.224 | Acc: 41.721,64.830,74.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.244 | Acc: 41.614,64.555,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.250 | Acc: 41.634,64.464,74.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.250 | Acc: 41.615,64.363,74.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.258 | Acc: 41.591,64.231,74.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.261 | Acc: 41.547,64.187,73.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.276 | Acc: 41.420,64.083,73.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.282 | Acc: 41.460,64.013,73.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.285 | Acc: 41.408,63.980,73.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.525 | Acc: 37.500,46.094,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.112 | Acc: 32.031,50.856,59.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.237 | Acc: 30.907,49.562,58.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.264 | Acc: 30.289,49.769,58.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 3.635 | Acc: 50.000,70.312,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.141 | Acc: 42.969,66.183,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.177 | Acc: 42.226,65.777,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.214 | Acc: 42.290,65.446,75.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.176 | Acc: 42.622,65.760,75.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.174 | Acc: 42.474,65.610,75.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.183 | Acc: 42.310,65.367,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.188 | Acc: 42.282,65.232,75.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.201 | Acc: 42.124,65.145,75.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.224 | Acc: 42.075,64.883,74.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.239 | Acc: 41.853,64.688,74.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.243 | Acc: 41.777,64.582,74.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.246 | Acc: 41.675,64.513,74.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.246 | Acc: 41.691,64.491,74.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.257 | Acc: 41.701,64.446,74.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.261 | Acc: 41.624,64.332,74.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.267 | Acc: 41.555,64.320,73.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.272 | Acc: 41.519,64.310,73.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.285 | Acc: 41.476,64.201,73.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.285 | Acc: 41.550,64.165,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.769 | Acc: 25.781,46.094,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.583 | Acc: 29.315,48.140,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.544 | Acc: 28.944,48.114,59.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.541 | Acc: 28.817,48.399,59.157,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 3.939 | Acc: 42.188,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.053 | Acc: 42.597,65.997,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.072 | Acc: 42.016,66.216,76.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.152 | Acc: 41.688,65.369,75.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.186 | Acc: 41.454,64.757,74.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.199 | Acc: 41.515,64.496,74.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.199 | Acc: 41.522,64.560,74.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.208 | Acc: 41.595,64.400,74.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.223 | Acc: 41.581,64.329,74.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.225 | Acc: 41.415,64.265,74.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.232 | Acc: 41.387,64.265,74.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.247 | Acc: 41.435,64.112,74.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.262 | Acc: 41.455,63.985,74.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.260 | Acc: 41.361,63.955,74.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.273 | Acc: 41.278,63.896,74.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.277 | Acc: 41.318,63.826,73.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.273 | Acc: 41.455,63.953,73.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.274 | Acc: 41.477,63.978,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.286 | Acc: 41.391,63.892,73.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.289 | Acc: 41.382,63.886,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.016 | Acc: 22.656,50.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.523 | Acc: 19.420,47.656,57.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.577 | Acc: 19.322,47.180,56.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.591 | Acc: 19.262,47.157,56.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 4.110 | Acc: 44.531,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.177 | Acc: 43.266,65.141,76.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.127 | Acc: 43.197,65.415,76.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.113 | Acc: 42.892,65.420,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.155 | Acc: 42.390,65.258,75.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.165 | Acc: 42.327,65.161,75.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.177 | Acc: 41.936,65.025,75.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.194 | Acc: 41.750,64.761,75.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.199 | Acc: 41.862,64.737,75.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.215 | Acc: 41.786,64.688,74.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.227 | Acc: 41.628,64.603,74.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.218 | Acc: 41.827,64.727,74.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.224 | Acc: 41.798,64.458,74.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.233 | Acc: 41.768,64.380,74.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.246 | Acc: 41.637,64.235,74.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.252 | Acc: 41.658,64.260,74.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.264 | Acc: 41.508,64.184,74.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.263 | Acc: 41.507,64.182,74.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.268 | Acc: 41.530,64.156,74.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.266 | Acc: 41.494,64.167,74.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.123 | Acc: 42.969,57.812,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.695 | Acc: 35.417,53.720,63.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.673 | Acc: 34.737,53.811,62.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.706 | Acc: 34.016,53.535,61.783,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 4.242 | Acc: 39.844,64.844,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.154 | Acc: 41.332,64.509,76.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.144 | Acc: 41.387,64.958,76.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.122 | Acc: 41.496,65.407,76.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.134 | Acc: 41.561,65.596,76.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.158 | Acc: 41.422,65.300,75.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.156 | Acc: 41.296,65.238,75.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.163 | Acc: 41.473,65.204,75.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.171 | Acc: 41.304,65.130,75.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.184 | Acc: 41.359,64.960,75.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.188 | Acc: 41.515,64.887,75.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.199 | Acc: 41.534,64.798,74.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.211 | Acc: 41.426,64.633,74.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.213 | Acc: 41.571,64.679,74.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.226 | Acc: 41.442,64.485,74.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.239 | Acc: 41.383,64.428,74.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.257 | Acc: 41.311,64.299,74.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.265 | Acc: 41.266,64.241,74.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.272 | Acc: 41.300,64.138,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.272 | Acc: 41.365,64.161,74.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.935 | Acc: 28.906,52.344,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.381 | Acc: 27.865,51.749,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.291 | Acc: 28.182,51.829,60.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.320 | Acc: 28.087,51.934,60.284,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 3.603 | Acc: 46.875,62.500,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.129 | Acc: 42.448,64.249,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.137 | Acc: 42.702,65.206,76.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.174 | Acc: 42.316,65.138,75.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.215 | Acc: 42.072,64.863,75.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.189 | Acc: 42.304,65.145,75.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.199 | Acc: 42.155,65.025,75.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.220 | Acc: 41.966,64.672,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.226 | Acc: 41.882,64.572,74.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.230 | Acc: 41.721,64.529,74.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.228 | Acc: 41.671,64.548,74.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.226 | Acc: 41.707,64.596,74.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.236 | Acc: 41.646,64.490,74.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.250 | Acc: 41.550,64.473,74.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.249 | Acc: 41.573,64.493,74.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.252 | Acc: 41.640,64.441,74.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.258 | Acc: 41.606,64.406,74.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.263 | Acc: 41.624,64.365,74.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.267 | Acc: 41.618,64.361,74.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.281 | Acc: 41.513,64.202,73.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.684 | Acc: 41.406,50.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.716 | Acc: 35.342,53.051,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.725 | Acc: 34.909,52.077,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.756 | Acc: 34.452,51.767,59.580,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 3.866 | Acc: 48.438,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.990 | Acc: 43.676,66.518,76.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.119 | Acc: 42.397,65.263,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.160 | Acc: 42.008,65.394,75.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.156 | Acc: 42.024,65.345,75.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.172 | Acc: 41.901,65.099,75.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.179 | Acc: 41.794,65.108,75.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.202 | Acc: 41.960,64.816,75.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.217 | Acc: 41.790,64.582,75.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.212 | Acc: 41.881,64.693,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.209 | Acc: 41.900,64.739,75.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.221 | Acc: 41.763,64.649,74.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.233 | Acc: 41.594,64.562,74.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.245 | Acc: 41.529,64.416,74.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.249 | Acc: 41.542,64.399,74.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.254 | Acc: 41.476,64.327,74.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.253 | Acc: 41.560,64.355,74.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.260 | Acc: 41.567,64.223,74.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.266 | Acc: 41.590,64.166,74.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.266 | Acc: 41.669,64.175,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.129 | Acc: 31.250,45.312,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.703 | Acc: 27.121,41.629,48.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.619 | Acc: 27.401,43.121,47.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.639 | Acc: 27.228,43.379,47.362,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 4.020 | Acc: 45.312,60.938,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.115 | Acc: 42.113,65.625,76.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.124 | Acc: 42.416,65.320,76.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.147 | Acc: 42.136,65.599,76.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.162 | Acc: 41.917,65.451,76.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.167 | Acc: 41.979,65.393,76.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.185 | Acc: 41.903,65.218,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.183 | Acc: 41.877,65.237,75.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.184 | Acc: 42.144,65.319,75.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.182 | Acc: 42.196,65.470,75.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.196 | Acc: 42.242,65.353,75.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.214 | Acc: 42.173,65.261,75.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.218 | Acc: 42.106,65.223,75.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.227 | Acc: 41.996,65.068,74.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.232 | Acc: 41.932,64.974,74.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.237 | Acc: 41.736,64.870,74.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.250 | Acc: 41.606,64.720,74.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.260 | Acc: 41.537,64.654,74.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.264 | Acc: 41.510,64.582,74.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.265 | Acc: 41.593,64.589,74.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.005 | Acc: 28.906,48.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.223 | Acc: 32.180,51.711,58.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.254 | Acc: 31.936,51.391,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.256 | Acc: 31.583,51.217,58.017,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 4.205 | Acc: 44.531,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.975 | Acc: 43.824,66.667,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.041 | Acc: 43.655,65.987,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.087 | Acc: 43.148,65.753,76.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.097 | Acc: 43.094,65.750,76.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.125 | Acc: 42.713,65.919,76.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.138 | Acc: 42.446,65.741,76.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.150 | Acc: 42.476,65.553,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.159 | Acc: 42.333,65.431,75.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.165 | Acc: 42.231,65.293,75.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.192 | Acc: 42.005,65.069,75.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.199 | Acc: 41.887,64.918,75.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.212 | Acc: 41.893,64.841,75.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.223 | Acc: 41.783,64.718,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.229 | Acc: 41.823,64.733,74.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.237 | Acc: 41.702,64.722,74.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.248 | Acc: 41.647,64.625,74.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.247 | Acc: 41.757,64.660,74.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.252 | Acc: 41.696,64.647,74.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.256 | Acc: 41.718,64.600,74.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.514 | Acc: 38.281,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.329 | Acc: 32.292,49.182,59.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.254 | Acc: 33.136,49.562,59.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.275 | Acc: 32.838,49.308,58.888,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 4.093 | Acc: 44.531,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.095 | Acc: 42.336,65.662,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.098 | Acc: 42.302,65.568,76.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.124 | Acc: 41.931,65.254,76.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.098 | Acc: 42.409,65.432,76.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.107 | Acc: 42.226,65.246,75.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.113 | Acc: 42.213,65.244,75.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.132 | Acc: 41.938,65.287,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.168 | Acc: 41.673,65.018,75.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.203 | Acc: 41.428,64.688,75.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.210 | Acc: 41.527,64.661,75.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.221 | Acc: 41.396,64.621,74.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.220 | Acc: 41.374,64.549,74.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.219 | Acc: 41.406,64.425,74.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.225 | Acc: 41.276,64.335,74.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.232 | Acc: 41.385,64.239,74.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.235 | Acc: 41.409,64.155,74.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.238 | Acc: 41.413,64.161,74.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.244 | Acc: 41.523,64.073,74.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.247 | Acc: 41.527,64.056,74.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.610 | Acc: 36.719,44.531,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.075 | Acc: 31.994,49.293,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.105 | Acc: 32.736,48.666,59.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.104 | Acc: 32.864,49.859,59.426,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 4.579 | Acc: 35.938,56.250,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.133 | Acc: 41.406,65.179,76.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.145 | Acc: 41.845,65.530,76.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.158 | Acc: 42.162,65.407,75.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.213 | Acc: 41.917,64.921,75.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.217 | Acc: 41.476,64.720,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.220 | Acc: 41.471,64.837,75.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.232 | Acc: 41.351,64.716,75.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.223 | Acc: 41.401,64.883,75.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.234 | Acc: 41.311,64.719,74.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.238 | Acc: 41.294,64.579,74.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.245 | Acc: 41.304,64.455,74.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.247 | Acc: 41.241,64.357,74.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.248 | Acc: 41.260,64.419,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.257 | Acc: 41.289,64.360,74.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.256 | Acc: 41.310,64.441,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.263 | Acc: 41.282,64.415,74.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.264 | Acc: 41.356,64.379,74.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.265 | Acc: 41.393,64.478,74.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.269 | Acc: 41.306,64.393,74.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.972 | Acc: 33.594,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.140 | Acc: 31.845,51.860,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.261 | Acc: 30.659,50.419,58.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.292 | Acc: 30.366,50.205,58.120,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 4.188 | Acc: 42.188,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.068 | Acc: 42.932,66.741,76.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.990 | Acc: 43.902,67.264,77.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.906 | Acc: 44.057,68.417,78.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.836 | Acc: 44.435,69.165,78.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.799 | Acc: 44.887,69.199,79.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.770 | Acc: 45.190,69.551,79.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.765 | Acc: 45.041,69.564,79.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.742 | Acc: 45.138,69.861,80.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.715 | Acc: 45.291,70.131,80.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.700 | Acc: 45.375,70.297,80.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.680 | Acc: 45.482,70.443,80.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.659 | Acc: 45.659,70.552,81.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.654 | Acc: 45.582,70.561,81.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.647 | Acc: 45.527,70.710,81.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.636 | Acc: 45.660,70.852,81.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.631 | Acc: 45.624,70.921,81.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.623 | Acc: 45.672,71.046,81.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.616 | Acc: 45.659,71.061,81.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.612 | Acc: 45.704,71.161,81.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.154 | Acc: 51.562,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.411 | Acc: 44.829,64.174,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.401 | Acc: 44.074,63.491,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.418 | Acc: 43.379,63.589,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.435 | Acc: 45.312,71.094,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.371 | Acc: 47.619,74.219,84.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.415 | Acc: 46.837,73.209,84.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.443 | Acc: 46.644,73.322,84.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.419 | Acc: 46.923,73.158,84.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.421 | Acc: 46.805,73.136,84.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.425 | Acc: 46.823,73.011,84.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.421 | Acc: 47.058,73.094,84.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.420 | Acc: 47.050,73.001,84.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.415 | Acc: 47.035,73.131,84.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.410 | Acc: 47.027,73.076,84.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.411 | Acc: 47.016,72.992,84.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.414 | Acc: 46.875,72.857,84.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.415 | Acc: 46.779,72.818,84.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.417 | Acc: 46.641,72.815,84.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.407 | Acc: 46.782,72.960,84.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.406 | Acc: 46.826,73.002,84.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.412 | Acc: 46.825,72.979,84.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.410 | Acc: 46.879,73.003,84.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.407 | Acc: 46.992,73.025,84.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.103 | Acc: 49.219,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.375 | Acc: 44.903,65.290,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.399 | Acc: 44.150,64.310,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.412 | Acc: 43.609,64.383,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.434 | Acc: 42.188,69.531,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.345 | Acc: 47.619,72.545,85.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.319 | Acc: 47.466,73.342,85.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.328 | Acc: 47.182,73.322,85.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.341 | Acc: 47.145,73.630,85.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.350 | Acc: 47.192,73.615,85.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.364 | Acc: 46.940,73.625,85.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.367 | Acc: 47.025,73.643,85.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.359 | Acc: 46.919,73.704,85.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.362 | Acc: 46.858,73.740,85.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.351 | Acc: 46.922,73.865,85.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.349 | Acc: 46.963,73.840,85.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.353 | Acc: 46.859,73.745,85.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.349 | Acc: 46.818,73.794,85.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.346 | Acc: 46.942,73.846,85.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.345 | Acc: 46.919,73.861,85.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.351 | Acc: 46.826,73.759,85.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.349 | Acc: 46.845,73.717,85.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.350 | Acc: 46.827,73.704,85.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.356 | Acc: 46.777,73.688,85.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.157 | Acc: 54.688,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.419 | Acc: 44.345,63.951,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.421 | Acc: 43.921,63.605,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.429 | Acc: 43.494,64.011,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 3.135 | Acc: 48.438,71.094,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.310 | Acc: 46.801,74.070,87.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 47.161,73.914,87.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.301 | Acc: 47.285,74.039,86.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.286 | Acc: 47.367,74.383,86.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.276 | Acc: 47.370,74.621,86.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.279 | Acc: 47.166,74.348,86.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.286 | Acc: 47.163,74.280,86.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.292 | Acc: 47.084,74.209,86.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.285 | Acc: 47.324,74.154,86.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.295 | Acc: 47.338,74.059,86.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.296 | Acc: 47.423,74.053,86.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.298 | Acc: 47.374,74.024,86.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.295 | Acc: 47.366,74.027,86.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.303 | Acc: 47.400,73.927,85.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.308 | Acc: 47.407,73.881,85.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.302 | Acc: 47.486,73.907,85.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.302 | Acc: 47.494,73.852,85.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.307 | Acc: 47.420,73.816,85.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.302 | Acc: 47.543,73.887,85.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.184 | Acc: 50.000,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.408 | Acc: 44.792,64.732,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.427 | Acc: 44.055,63.681,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.430 | Acc: 43.737,63.947,70.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 3.224 | Acc: 50.000,78.125,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.266 | Acc: 47.247,74.702,87.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.234 | Acc: 48.418,75.191,87.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.232 | Acc: 48.463,74.974,87.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.261 | Acc: 48.399,74.527,86.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.268 | Acc: 48.213,74.389,86.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.262 | Acc: 48.128,74.438,86.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.267 | Acc: 48.011,74.368,86.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.269 | Acc: 47.899,74.364,86.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.265 | Acc: 47.945,74.482,86.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.269 | Acc: 47.792,74.522,86.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.275 | Acc: 47.554,74.544,86.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.274 | Acc: 47.585,74.572,86.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.272 | Acc: 47.611,74.512,86.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.274 | Acc: 47.662,74.500,86.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.277 | Acc: 47.643,74.450,86.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.281 | Acc: 47.578,74.404,86.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.280 | Acc: 47.581,74.439,86.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.281 | Acc: 47.550,74.457,86.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.282 | Acc: 47.515,74.436,86.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.074 | Acc: 51.562,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.398 | Acc: 44.680,65.476,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.421 | Acc: 43.826,64.329,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.436 | Acc: 43.558,64.639,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.341 | Acc: 51.562,71.094,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.253 | Acc: 48.624,75.074,87.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.247 | Acc: 48.037,74.848,87.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.280 | Acc: 47.759,74.116,86.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.253 | Acc: 47.753,74.547,86.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.266 | Acc: 47.641,74.544,86.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.292 | Acc: 47.243,74.232,86.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.278 | Acc: 47.412,74.318,86.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.267 | Acc: 47.404,74.330,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.263 | Acc: 47.440,74.361,86.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.255 | Acc: 47.501,74.413,86.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.249 | Acc: 47.515,74.516,86.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.247 | Acc: 47.546,74.592,86.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.244 | Acc: 47.522,74.623,86.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.242 | Acc: 47.498,74.630,86.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.241 | Acc: 47.542,74.616,86.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.241 | Acc: 47.498,74.572,86.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.241 | Acc: 47.542,74.588,86.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.234 | Acc: 47.652,74.647,86.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.235 | Acc: 47.638,74.647,86.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.211 | Acc: 50.000,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.476 | Acc: 44.457,64.695,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.488 | Acc: 43.312,63.872,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.502 | Acc: 42.943,63.947,70.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 3.392 | Acc: 41.406,75.000,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.211 | Acc: 48.140,74.888,86.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.202 | Acc: 48.018,74.771,87.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.216 | Acc: 48.489,74.641,87.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.218 | Acc: 47.936,74.971,87.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.208 | Acc: 47.989,74.892,87.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.208 | Acc: 48.037,75.032,87.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.218 | Acc: 47.917,74.778,87.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.209 | Acc: 47.986,74.709,87.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.207 | Acc: 47.881,74.702,87.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.209 | Acc: 47.808,74.751,87.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.203 | Acc: 47.854,74.813,87.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.212 | Acc: 47.721,74.666,87.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.226 | Acc: 47.593,74.485,87.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.224 | Acc: 47.565,74.538,87.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.220 | Acc: 47.711,74.564,87.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.219 | Acc: 47.688,74.577,87.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.216 | Acc: 47.672,74.617,87.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.224 | Acc: 47.645,74.500,87.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.223 | Acc: 47.584,74.530,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.141 | Acc: 49.219,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.434 | Acc: 44.345,65.179,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.422 | Acc: 43.979,64.329,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.435 | Acc: 43.904,64.229,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.446 | Acc: 49.219,73.438,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.217 | Acc: 47.470,74.591,87.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.210 | Acc: 46.913,74.905,87.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.198 | Acc: 47.374,75.141,87.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.194 | Acc: 47.560,75.077,87.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.187 | Acc: 47.679,75.147,87.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.192 | Acc: 47.514,75.097,87.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.181 | Acc: 47.739,75.233,87.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.178 | Acc: 47.855,75.315,87.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.181 | Acc: 47.885,75.194,87.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.173 | Acc: 48.076,75.292,87.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.174 | Acc: 48.013,75.233,87.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.174 | Acc: 48.052,75.253,87.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.177 | Acc: 47.991,75.183,87.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.175 | Acc: 47.979,75.164,87.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.183 | Acc: 47.913,75.047,87.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.183 | Acc: 47.960,74.946,87.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.188 | Acc: 47.823,74.828,87.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.193 | Acc: 47.801,74.747,87.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.202 | Acc: 47.724,74.662,87.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.157 | Acc: 53.125,63.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.427 | Acc: 45.573,64.732,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.418 | Acc: 44.931,64.177,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.440 | Acc: 44.506,64.127,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 3.503 | Acc: 45.312,71.875,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.098 | Acc: 48.028,76.451,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.095 | Acc: 48.190,76.296,88.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.121 | Acc: 48.156,75.986,88.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.126 | Acc: 48.110,75.887,88.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.144 | Acc: 47.749,75.797,88.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.143 | Acc: 47.792,75.743,88.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.149 | Acc: 47.778,75.737,88.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.150 | Acc: 47.705,75.679,88.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.170 | Acc: 47.358,75.578,88.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.175 | Acc: 47.252,75.532,88.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.188 | Acc: 47.218,75.410,88.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.186 | Acc: 47.364,75.489,88.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.185 | Acc: 47.438,75.383,87.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.183 | Acc: 47.492,75.406,87.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.183 | Acc: 47.571,75.397,87.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.182 | Acc: 47.537,75.380,88.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.183 | Acc: 47.594,75.341,87.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.181 | Acc: 47.555,75.342,87.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.181 | Acc: 47.632,75.303,87.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.087 | Acc: 48.438,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.431 | Acc: 44.754,64.844,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.448 | Acc: 44.188,63.815,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.466 | Acc: 43.724,63.909,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 3.081 | Acc: 44.531,72.656,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.054 | Acc: 48.735,76.897,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.096 | Acc: 48.228,76.315,89.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.106 | Acc: 48.053,75.973,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.096 | Acc: 47.791,75.849,89.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.098 | Acc: 47.981,75.743,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.107 | Acc: 47.701,75.730,88.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.099 | Acc: 48.027,75.936,89.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.106 | Acc: 48.049,75.883,88.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.114 | Acc: 48.071,75.712,88.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.118 | Acc: 48.092,75.692,88.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.119 | Acc: 48.088,75.643,88.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.123 | Acc: 48.091,75.703,88.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.134 | Acc: 48.060,75.572,88.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.136 | Acc: 48.026,75.542,88.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.136 | Acc: 48.035,75.535,88.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.143 | Acc: 48.009,75.438,88.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.148 | Acc: 47.933,75.312,88.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.151 | Acc: 47.892,75.312,88.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.153 | Acc: 47.867,75.228,88.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.230 | Acc: 50.781,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 44.680,64.062,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.513 | Acc: 44.036,63.891,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.517 | Acc: 43.840,64.011,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 3.377 | Acc: 45.312,75.781,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.066 | Acc: 48.438,76.116,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.057 | Acc: 48.304,76.334,89.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.073 | Acc: 47.861,76.114,89.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.070 | Acc: 48.187,76.128,89.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.095 | Acc: 48.175,75.828,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.104 | Acc: 47.992,75.762,89.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.111 | Acc: 48.050,75.604,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.103 | Acc: 48.229,75.674,88.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.099 | Acc: 48.286,75.803,88.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.111 | Acc: 48.068,75.719,88.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.111 | Acc: 48.013,75.689,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.123 | Acc: 47.877,75.603,88.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.129 | Acc: 47.839,75.524,88.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.134 | Acc: 47.898,75.475,88.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.135 | Acc: 47.921,75.478,88.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.141 | Acc: 47.836,75.399,88.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.145 | Acc: 47.803,75.332,88.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.144 | Acc: 47.799,75.400,88.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.141 | Acc: 47.867,75.400,88.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.201 | Acc: 50.781,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.467 | Acc: 45.833,64.062,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.455 | Acc: 44.722,63.815,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.468 | Acc: 44.173,64.280,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 2.981 | Acc: 46.094,80.469,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.101 | Acc: 46.689,76.302,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.123 | Acc: 46.608,75.934,89.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.117 | Acc: 46.952,75.435,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.121 | Acc: 47.492,75.463,88.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.131 | Acc: 47.602,75.294,88.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.130 | Acc: 47.740,75.342,88.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.135 | Acc: 47.551,75.216,88.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.141 | Acc: 47.554,75.209,88.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.146 | Acc: 47.596,75.272,88.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.147 | Acc: 47.753,75.268,88.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.145 | Acc: 47.805,75.322,88.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.138 | Acc: 47.922,75.428,88.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.132 | Acc: 48.126,75.491,88.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.141 | Acc: 48.001,75.420,88.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.141 | Acc: 47.898,75.446,88.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.132 | Acc: 48.068,75.448,88.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.133 | Acc: 48.037,75.444,88.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.135 | Acc: 47.996,75.392,88.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.138 | Acc: 47.954,75.355,88.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.262 | Acc: 47.656,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.527 | Acc: 44.568,64.397,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.518 | Acc: 43.826,63.662,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.541 | Acc: 43.327,63.794,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 3.018 | Acc: 53.906,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.001 | Acc: 47.359,77.790,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.048 | Acc: 47.942,76.848,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.059 | Acc: 48.117,76.281,89.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.084 | Acc: 48.312,76.003,89.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.102 | Acc: 47.997,75.843,89.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.112 | Acc: 47.792,75.762,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.124 | Acc: 47.684,75.515,88.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.120 | Acc: 47.768,75.626,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.117 | Acc: 47.829,75.630,89.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.108 | Acc: 47.979,75.696,89.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.110 | Acc: 47.946,75.757,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.112 | Acc: 47.967,75.694,89.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.116 | Acc: 48.000,75.676,89.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.115 | Acc: 48.029,75.709,89.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.116 | Acc: 48.007,75.613,89.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.118 | Acc: 48.019,75.518,89.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.124 | Acc: 47.970,75.417,88.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.130 | Acc: 47.931,75.387,88.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.126 | Acc: 47.960,75.492,88.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.318 | Acc: 50.000,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 44.717,64.918,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.503 | Acc: 44.188,64.386,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.518 | Acc: 43.968,64.370,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 2.612 | Acc: 60.938,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.026 | Acc: 49.293,76.004,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.043 | Acc: 48.647,75.781,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.046 | Acc: 48.322,75.948,89.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.048 | Acc: 48.428,76.013,89.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.060 | Acc: 48.097,75.951,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.067 | Acc: 48.031,75.846,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.070 | Acc: 48.050,75.798,89.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.073 | Acc: 48.146,75.713,89.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.075 | Acc: 48.127,75.747,89.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.077 | Acc: 48.134,75.731,89.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.075 | Acc: 48.155,75.749,89.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.082 | Acc: 48.117,75.700,89.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.083 | Acc: 48.162,75.739,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.085 | Acc: 48.151,75.701,89.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.085 | Acc: 48.165,75.748,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.092 | Acc: 48.075,75.679,89.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.096 | Acc: 48.027,75.621,89.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.102 | Acc: 47.959,75.548,89.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.101 | Acc: 47.923,75.627,89.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.203 | Acc: 49.219,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 45.201,64.546,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.557 | Acc: 43.921,63.834,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 43.404,63.883,69.736,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 3.279 | Acc: 41.406,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.000 | Acc: 48.884,76.376,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.030 | Acc: 48.971,76.696,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.034 | Acc: 48.719,76.819,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.029 | Acc: 48.736,76.987,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.058 | Acc: 48.438,76.539,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.057 | Acc: 48.399,76.556,89.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.049 | Acc: 48.548,76.352,89.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.047 | Acc: 48.627,76.378,89.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.060 | Acc: 48.481,76.252,89.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.071 | Acc: 48.309,76.077,89.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.070 | Acc: 48.257,76.053,89.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.072 | Acc: 48.243,75.989,89.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.080 | Acc: 48.126,75.895,89.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.083 | Acc: 48.098,75.859,89.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.082 | Acc: 48.100,75.919,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.078 | Acc: 48.136,75.952,89.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.080 | Acc: 48.128,75.928,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.084 | Acc: 48.106,75.861,89.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.090 | Acc: 48.054,75.794,89.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.269 | Acc: 46.094,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.534 | Acc: 43.862,64.881,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 43.236,63.796,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.567 | Acc: 43.007,63.845,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 3.257 | Acc: 39.062,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.135 | Acc: 46.317,74.888,89.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.079 | Acc: 47.370,75.591,89.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.054 | Acc: 47.848,75.897,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.066 | Acc: 47.743,76.032,89.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.076 | Acc: 47.927,75.828,89.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.072 | Acc: 48.031,75.962,89.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.072 | Acc: 48.022,76.047,89.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.070 | Acc: 47.933,76.097,89.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.068 | Acc: 47.863,76.070,89.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.066 | Acc: 47.967,76.084,89.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.067 | Acc: 48.035,76.043,89.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.072 | Acc: 48.023,76.054,89.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.068 | Acc: 48.012,76.033,89.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.067 | Acc: 47.982,75.970,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.066 | Acc: 48.064,75.911,89.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.069 | Acc: 48.092,75.886,89.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.069 | Acc: 48.080,75.797,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.080 | Acc: 47.977,75.747,89.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.078 | Acc: 48.005,75.802,89.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.299 | Acc: 46.875,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 45.164,64.918,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.491 | Acc: 44.512,64.386,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.512 | Acc: 44.096,64.331,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 3.156 | Acc: 44.531,75.781,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.978 | Acc: 49.516,78.013,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 48.685,77.191,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.018 | Acc: 48.745,76.819,89.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.034 | Acc: 48.544,76.611,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.033 | Acc: 48.414,76.578,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.039 | Acc: 48.476,76.537,89.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.043 | Acc: 48.576,76.407,89.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.037 | Acc: 48.520,76.398,89.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.036 | Acc: 48.442,76.446,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.028 | Acc: 48.671,76.512,89.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.030 | Acc: 48.614,76.506,89.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.034 | Acc: 48.570,76.468,89.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.042 | Acc: 48.435,76.401,89.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.049 | Acc: 48.337,76.376,89.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.047 | Acc: 48.362,76.391,89.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.050 | Acc: 48.357,76.319,89.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.056 | Acc: 48.323,76.210,89.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.055 | Acc: 48.301,76.253,89.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.058 | Acc: 48.255,76.175,89.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.234 | Acc: 45.312,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.548 | Acc: 45.015,64.509,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.553 | Acc: 44.188,63.834,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 43.891,63.973,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 3.318 | Acc: 46.094,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.023 | Acc: 48.140,76.749,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.054 | Acc: 47.599,76.086,89.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.018 | Acc: 48.156,76.691,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.008 | Acc: 48.341,76.842,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.007 | Acc: 48.229,76.887,90.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.009 | Acc: 48.270,76.827,90.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.008 | Acc: 48.354,76.684,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.019 | Acc: 48.374,76.533,89.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.028 | Acc: 48.399,76.338,89.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.031 | Acc: 48.461,76.442,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.036 | Acc: 48.278,76.290,89.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.037 | Acc: 48.227,76.274,89.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.036 | Acc: 48.306,76.338,89.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.039 | Acc: 48.198,76.296,89.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.044 | Acc: 48.186,76.248,89.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.044 | Acc: 48.177,76.232,89.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.047 | Acc: 48.254,76.235,89.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.044 | Acc: 48.256,76.305,89.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.047 | Acc: 48.175,76.282,89.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.250 | Acc: 50.781,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.559 | Acc: 44.457,64.137,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 44.017,63.300,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 43.366,63.473,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.908 | Acc: 48.438,77.344,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.964 | Acc: 49.628,76.600,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.986 | Acc: 48.876,76.258,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.001 | Acc: 48.937,76.140,90.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.997 | Acc: 48.765,76.148,90.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.007 | Acc: 48.824,76.037,90.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.037 | Acc: 48.392,75.872,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.039 | Acc: 48.238,75.947,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.050 | Acc: 48.282,75.684,89.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.052 | Acc: 48.230,75.721,89.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.047 | Acc: 48.224,75.840,89.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.053 | Acc: 48.084,75.795,89.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.053 | Acc: 48.097,75.840,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.055 | Acc: 48.024,75.859,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.059 | Acc: 48.034,75.817,89.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.055 | Acc: 48.077,75.851,89.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.053 | Acc: 48.075,75.935,89.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.055 | Acc: 48.043,75.932,89.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.053 | Acc: 48.102,76.019,89.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.052 | Acc: 48.185,76.046,89.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.276 | Acc: 50.781,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 44.457,63.728,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.524 | Acc: 43.979,63.758,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.549 | Acc: 43.750,64.062,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 3.315 | Acc: 51.562,78.125,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.988 | Acc: 48.512,77.865,89.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.026 | Acc: 47.866,77.039,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.034 | Acc: 48.220,76.678,89.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.039 | Acc: 48.139,76.456,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.031 | Acc: 48.074,76.470,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.033 | Acc: 48.308,76.491,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.028 | Acc: 48.393,76.590,89.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.023 | Acc: 48.602,76.553,89.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.016 | Acc: 48.606,76.636,89.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.011 | Acc: 48.519,76.675,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.012 | Acc: 48.487,76.580,90.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.017 | Acc: 48.431,76.501,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.017 | Acc: 48.506,76.461,89.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.020 | Acc: 48.426,76.396,89.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.017 | Acc: 48.489,76.420,89.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.024 | Acc: 48.464,76.324,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.023 | Acc: 48.481,76.384,89.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.028 | Acc: 48.463,76.320,89.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.028 | Acc: 48.448,76.345,89.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.309 | Acc: 50.000,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.602 | Acc: 43.936,64.397,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 44.188,64.177,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 43.852,64.075,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 3.172 | Acc: 47.656,72.656,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 49.442,76.562,89.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.006 | Acc: 48.838,76.543,90.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.986 | Acc: 49.129,76.575,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.000 | Acc: 49.084,76.524,90.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.997 | Acc: 48.878,76.423,90.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.006 | Acc: 48.877,76.420,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.008 | Acc: 48.631,76.441,89.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.012 | Acc: 48.617,76.465,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.008 | Acc: 48.813,76.502,89.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.010 | Acc: 48.783,76.384,89.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.017 | Acc: 48.657,76.294,89.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.018 | Acc: 48.596,76.355,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.018 | Acc: 48.620,76.290,89.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.023 | Acc: 48.588,76.229,89.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.027 | Acc: 48.495,76.163,89.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.034 | Acc: 48.338,76.054,89.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.036 | Acc: 48.378,76.040,89.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.040 | Acc: 48.273,76.006,89.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.040 | Acc: 48.286,76.042,89.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.137 | Acc: 51.562,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.535 | Acc: 44.568,64.881,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.525 | Acc: 44.264,64.367,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.535 | Acc: 43.981,64.319,69.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 2.707 | Acc: 50.781,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.955 | Acc: 49.628,77.716,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.950 | Acc: 49.276,77.782,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.947 | Acc: 49.385,77.664,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.967 | Acc: 49.363,77.488,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.970 | Acc: 49.505,77.220,90.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.994 | Acc: 49.057,77.066,90.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.014 | Acc: 48.665,76.795,90.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.013 | Acc: 48.549,76.703,90.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.003 | Acc: 48.589,76.696,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.008 | Acc: 48.476,76.671,90.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.015 | Acc: 48.455,76.570,90.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.015 | Acc: 48.421,76.553,90.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.008 | Acc: 48.581,76.545,90.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.015 | Acc: 48.468,76.462,90.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.018 | Acc: 48.435,76.490,90.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.017 | Acc: 48.491,76.560,90.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.021 | Acc: 48.460,76.540,90.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.023 | Acc: 48.425,76.428,90.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.020 | Acc: 48.431,76.460,90.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.244 | Acc: 47.656,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.527 | Acc: 44.792,64.472,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 43.788,64.120,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 43.891,64.357,69.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 3.004 | Acc: 49.219,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.001 | Acc: 47.991,75.595,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.992 | Acc: 48.228,76.334,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 48.117,76.319,90.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.002 | Acc: 48.389,76.418,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.001 | Acc: 48.445,76.315,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.022 | Acc: 48.186,76.059,90.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.013 | Acc: 48.221,76.225,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.004 | Acc: 48.442,76.354,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.001 | Acc: 48.545,76.459,90.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.009 | Acc: 48.441,76.337,90.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.009 | Acc: 48.310,76.297,90.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.009 | Acc: 48.314,76.407,90.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.013 | Acc: 48.336,76.377,90.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.011 | Acc: 48.285,76.404,90.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.017 | Acc: 48.245,76.303,90.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.019 | Acc: 48.284,76.324,90.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.017 | Acc: 48.257,76.329,90.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.019 | Acc: 48.238,76.307,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.022 | Acc: 48.265,76.249,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.302 | Acc: 47.656,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 43.936,64.211,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.565 | Acc: 43.902,63.357,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 43.571,63.563,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.464 | Acc: 58.594,83.594,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 48.177,77.121,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.982 | Acc: 48.552,76.944,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 48.604,76.614,91.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.986 | Acc: 48.553,76.726,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.980 | Acc: 48.422,76.802,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.979 | Acc: 48.521,76.956,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.985 | Acc: 48.338,76.823,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.989 | Acc: 48.268,76.810,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.992 | Acc: 48.381,76.800,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.993 | Acc: 48.224,76.823,90.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.991 | Acc: 48.261,76.792,90.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.994 | Acc: 48.256,76.738,90.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.998 | Acc: 48.246,76.655,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.999 | Acc: 48.254,76.685,90.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.995 | Acc: 48.245,76.710,90.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.995 | Acc: 48.282,76.648,90.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.000 | Acc: 48.261,76.553,90.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.002 | Acc: 48.267,76.521,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.004 | Acc: 48.204,76.513,90.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.223 | Acc: 51.562,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.553 | Acc: 44.792,64.509,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.559 | Acc: 44.131,63.777,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 43.545,63.973,69.813,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 3.070 | Acc: 42.969,78.906,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.000 | Acc: 48.549,76.004,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.020 | Acc: 48.514,76.067,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.993 | Acc: 48.745,76.537,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.010 | Acc: 48.698,76.292,90.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.004 | Acc: 48.871,76.354,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.000 | Acc: 48.702,76.530,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.988 | Acc: 48.731,76.657,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.987 | Acc: 48.505,76.495,90.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.988 | Acc: 48.368,76.455,90.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.992 | Acc: 48.301,76.504,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.994 | Acc: 48.240,76.460,90.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.991 | Acc: 48.337,76.556,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.995 | Acc: 48.324,76.542,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.991 | Acc: 48.396,76.601,90.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.992 | Acc: 48.290,76.578,90.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.987 | Acc: 48.311,76.667,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.986 | Acc: 48.396,76.689,90.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.985 | Acc: 48.394,76.627,90.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.987 | Acc: 48.415,76.581,90.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.466 | Acc: 48.438,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.709 | Acc: 43.527,64.062,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.689 | Acc: 43.293,63.529,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.711 | Acc: 42.879,63.371,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 2.819 | Acc: 46.875,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.965 | Acc: 48.475,77.418,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.973 | Acc: 47.961,77.077,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.941 | Acc: 48.745,77.459,91.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.938 | Acc: 48.756,77.411,91.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.916 | Acc: 49.196,77.692,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.930 | Acc: 48.999,77.479,91.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.928 | Acc: 49.235,77.272,91.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.930 | Acc: 49.093,77.188,91.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.939 | Acc: 48.981,77.102,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.946 | Acc: 48.842,76.982,91.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.956 | Acc: 48.879,76.835,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.961 | Acc: 48.823,76.854,90.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.965 | Acc: 48.743,76.760,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.967 | Acc: 48.679,76.735,90.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.969 | Acc: 48.697,76.723,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.976 | Acc: 48.691,76.706,90.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.980 | Acc: 48.664,76.668,90.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.984 | Acc: 48.626,76.632,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.984 | Acc: 48.636,76.638,90.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.195 | Acc: 47.656,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 45.536,64.732,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.577 | Acc: 44.646,63.853,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 44.121,63.691,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 3.273 | Acc: 46.094,70.312,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.074 | Acc: 47.619,75.074,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.044 | Acc: 47.580,76.181,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.995 | Acc: 48.386,76.294,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.996 | Acc: 48.148,76.321,90.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.983 | Acc: 48.306,76.748,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.975 | Acc: 48.386,76.730,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.980 | Acc: 48.349,76.490,90.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.971 | Acc: 48.481,76.533,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.971 | Acc: 48.386,76.545,90.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.974 | Acc: 48.445,76.500,90.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.969 | Acc: 48.540,76.640,90.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.974 | Acc: 48.470,76.524,90.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.970 | Acc: 48.635,76.548,90.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.971 | Acc: 48.696,76.590,90.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.971 | Acc: 48.676,76.581,90.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.980 | Acc: 48.608,76.485,90.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.979 | Acc: 48.653,76.533,90.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.986 | Acc: 48.589,76.506,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.985 | Acc: 48.597,76.577,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.298 | Acc: 50.000,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.620 | Acc: 44.382,64.137,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.617 | Acc: 44.169,63.034,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.617 | Acc: 43.750,63.179,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.614 | Acc: 51.562,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.846 | Acc: 50.930,77.976,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.908 | Acc: 49.409,77.553,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.890 | Acc: 49.296,77.395,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.916 | Acc: 49.064,77.151,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.938 | Acc: 48.878,77.050,91.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.950 | Acc: 48.818,76.814,91.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.946 | Acc: 48.931,76.895,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.946 | Acc: 48.860,76.839,91.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.946 | Acc: 48.709,76.774,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.950 | Acc: 48.725,76.722,91.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.956 | Acc: 48.795,76.690,90.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.959 | Acc: 48.723,76.559,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.961 | Acc: 48.743,76.568,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.965 | Acc: 48.621,76.621,90.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.962 | Acc: 48.658,76.700,90.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.963 | Acc: 48.637,76.743,90.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.966 | Acc: 48.575,76.693,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.968 | Acc: 48.563,76.746,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.971 | Acc: 48.503,76.679,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.408 | Acc: 49.219,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.704 | Acc: 44.382,63.542,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.699 | Acc: 44.036,63.186,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.701 | Acc: 43.532,63.320,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 3.113 | Acc: 44.531,78.906,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.933 | Acc: 48.289,78.237,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.942 | Acc: 47.904,77.649,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.912 | Acc: 48.924,77.677,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.928 | Acc: 48.688,77.209,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.935 | Acc: 48.670,77.065,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.930 | Acc: 48.547,77.098,91.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.936 | Acc: 48.709,77.150,91.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.934 | Acc: 48.923,77.184,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.930 | Acc: 49.020,77.193,91.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.932 | Acc: 48.884,77.196,91.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.940 | Acc: 48.763,77.036,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.944 | Acc: 48.849,77.033,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.950 | Acc: 48.782,76.991,90.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.951 | Acc: 48.791,76.999,90.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.950 | Acc: 48.811,76.991,90.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.955 | Acc: 48.754,76.940,90.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.963 | Acc: 48.607,76.890,90.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.966 | Acc: 48.606,76.798,90.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.969 | Acc: 48.534,76.761,90.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.290 | Acc: 52.344,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.614 | Acc: 44.680,63.839,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 44.512,63.224,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.624 | Acc: 43.993,63.550,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 2.864 | Acc: 49.219,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.897 | Acc: 48.326,78.237,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 48.742,77.820,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.907 | Acc: 48.642,77.830,90.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.906 | Acc: 48.958,77.681,90.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.910 | Acc: 49.211,77.591,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.917 | Acc: 49.309,77.550,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.928 | Acc: 49.180,77.410,90.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.939 | Acc: 49.059,77.397,90.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.940 | Acc: 48.917,77.201,90.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.955 | Acc: 48.756,77.072,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.953 | Acc: 48.802,77.163,90.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.953 | Acc: 48.807,77.107,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.950 | Acc: 48.839,77.080,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.955 | Acc: 48.729,76.963,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.961 | Acc: 48.614,76.840,90.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.965 | Acc: 48.608,76.723,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.969 | Acc: 48.577,76.727,90.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.966 | Acc: 48.611,76.744,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.969 | Acc: 48.581,76.698,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.190 | Acc: 50.000,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.592 | Acc: 44.382,64.472,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 44.036,63.224,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.624 | Acc: 43.916,63.448,69.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 2.570 | Acc: 57.812,85.156,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.877 | Acc: 50.521,78.981,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.864 | Acc: 50.629,78.716,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.897 | Acc: 49.731,77.741,91.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.894 | Acc: 49.373,77.681,91.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.893 | Acc: 49.435,77.700,91.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.915 | Acc: 48.986,77.415,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.919 | Acc: 48.875,77.410,91.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.934 | Acc: 48.627,77.252,91.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.933 | Acc: 48.701,77.305,91.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.937 | Acc: 48.624,77.317,91.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.939 | Acc: 48.685,77.294,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.933 | Acc: 48.768,77.178,91.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.938 | Acc: 48.716,77.110,91.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.940 | Acc: 48.707,77.105,91.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.939 | Acc: 48.689,77.097,91.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.938 | Acc: 48.710,77.137,91.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.940 | Acc: 48.651,77.149,91.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.946 | Acc: 48.587,77.071,90.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.951 | Acc: 48.515,77.010,90.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.335 | Acc: 50.000,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.641 | Acc: 44.792,64.025,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.644 | Acc: 44.646,63.472,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.670 | Acc: 43.981,63.550,68.673,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 3.153 | Acc: 41.406,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.901 | Acc: 47.619,78.385,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.915 | Acc: 47.694,78.392,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.900 | Acc: 48.489,78.381,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.928 | Acc: 48.090,77.787,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.950 | Acc: 48.128,77.351,91.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.952 | Acc: 48.373,77.137,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.938 | Acc: 48.576,77.189,91.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.930 | Acc: 48.627,77.266,91.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.938 | Acc: 48.558,77.206,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.937 | Acc: 48.636,77.177,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.938 | Acc: 48.703,77.209,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.938 | Acc: 48.619,77.152,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.937 | Acc: 48.566,77.185,91.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.939 | Acc: 48.582,77.277,91.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.940 | Acc: 48.575,77.297,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.938 | Acc: 48.474,77.351,91.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.947 | Acc: 48.490,77.268,91.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.952 | Acc: 48.418,77.164,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.950 | Acc: 48.448,77.188,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.333 | Acc: 46.875,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.618 | Acc: 44.085,64.323,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.633 | Acc: 44.036,63.796,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.660 | Acc: 43.596,63.973,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 3.383 | Acc: 39.062,74.219,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.953 | Acc: 48.028,76.711,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.951 | Acc: 48.609,76.734,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.943 | Acc: 48.245,76.627,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.938 | Acc: 48.573,76.601,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.948 | Acc: 48.321,76.601,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.932 | Acc: 48.644,76.847,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.930 | Acc: 48.781,76.795,91.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.929 | Acc: 48.724,76.912,91.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.942 | Acc: 48.606,76.744,91.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.934 | Acc: 48.760,76.940,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.933 | Acc: 48.713,76.990,91.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.928 | Acc: 48.775,77.078,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.927 | Acc: 48.821,77.131,91.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.927 | Acc: 48.885,77.121,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.926 | Acc: 48.910,77.170,91.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.931 | Acc: 48.839,77.132,91.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.935 | Acc: 48.751,77.087,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.935 | Acc: 48.799,77.132,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.943 | Acc: 48.735,77.010,91.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.307 | Acc: 50.000,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.602 | Acc: 44.159,64.062,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.623 | Acc: 43.826,63.700,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.643 | Acc: 43.673,63.640,69.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 2.898 | Acc: 54.688,76.562,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.761 | Acc: 50.818,77.902,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.838 | Acc: 49.257,77.496,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.844 | Acc: 49.449,77.946,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.857 | Acc: 49.190,78.279,91.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.849 | Acc: 49.149,78.249,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.865 | Acc: 49.329,78.048,91.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.883 | Acc: 48.842,77.854,91.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.889 | Acc: 48.782,77.737,91.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.900 | Acc: 48.722,77.663,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.905 | Acc: 48.640,77.558,91.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.909 | Acc: 48.639,77.503,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.911 | Acc: 48.707,77.541,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.915 | Acc: 48.743,77.535,91.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.914 | Acc: 48.774,77.486,91.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.914 | Acc: 48.829,77.510,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.921 | Acc: 48.747,77.470,91.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.922 | Acc: 48.745,77.472,91.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.923 | Acc: 48.708,77.430,91.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.927 | Acc: 48.657,77.424,91.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.388 | Acc: 50.000,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.596 | Acc: 44.829,64.100,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 44.398,63.377,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.642 | Acc: 44.211,63.512,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 3.003 | Acc: 44.531,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.890 | Acc: 49.330,78.757,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.874 | Acc: 48.514,78.449,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.869 | Acc: 48.476,78.099,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.861 | Acc: 48.833,78.212,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.877 | Acc: 48.894,77.970,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.893 | Acc: 48.554,77.796,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.897 | Acc: 48.659,77.715,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.898 | Acc: 48.578,77.484,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.908 | Acc: 48.373,77.408,91.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.915 | Acc: 48.317,77.445,91.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.918 | Acc: 48.328,77.422,91.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.920 | Acc: 48.457,77.318,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.919 | Acc: 48.512,77.317,91.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.918 | Acc: 48.565,77.291,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.925 | Acc: 48.601,77.204,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 48.608,77.203,91.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.924 | Acc: 48.660,77.193,91.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.927 | Acc: 48.619,77.285,91.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.936 | Acc: 48.517,77.178,91.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.461 | Acc: 47.656,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.751 | Acc: 43.862,63.281,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.739 | Acc: 43.426,62.595,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.764 | Acc: 43.007,63.038,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 3.066 | Acc: 46.875,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.908 | Acc: 48.326,78.088,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.918 | Acc: 48.990,77.706,92.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.928 | Acc: 48.758,77.408,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.935 | Acc: 48.495,77.315,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.942 | Acc: 48.329,77.290,91.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.937 | Acc: 48.321,77.382,91.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.940 | Acc: 48.293,77.261,91.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.939 | Acc: 48.404,77.218,91.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.929 | Acc: 48.675,77.322,91.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.924 | Acc: 48.748,77.402,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.918 | Acc: 48.840,77.471,91.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.918 | Acc: 48.788,77.473,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.916 | Acc: 48.737,77.440,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.911 | Acc: 48.779,77.461,91.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.909 | Acc: 48.744,77.497,91.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.911 | Acc: 48.822,77.526,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.917 | Acc: 48.790,77.406,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.924 | Acc: 48.671,77.326,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.927 | Acc: 48.641,77.274,91.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.396 | Acc: 49.219,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.700 | Acc: 44.940,64.286,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.718 | Acc: 43.731,62.900,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.751 | Acc: 43.327,63.358,68.443,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.959 | Acc: 46.094,75.000,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.907 | Acc: 48.884,77.716,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.937 | Acc: 48.247,77.553,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.934 | Acc: 48.105,77.638,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.918 | Acc: 48.081,77.623,91.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.920 | Acc: 48.244,77.313,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.925 | Acc: 48.438,77.324,91.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.918 | Acc: 48.698,77.067,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.923 | Acc: 48.636,77.023,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.912 | Acc: 48.696,77.093,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.918 | Acc: 48.581,77.103,91.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.922 | Acc: 48.547,77.185,91.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.925 | Acc: 48.590,77.149,91.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.920 | Acc: 48.650,77.182,91.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.922 | Acc: 48.540,77.219,91.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.924 | Acc: 48.450,77.227,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.924 | Acc: 48.586,77.212,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.921 | Acc: 48.621,77.268,91.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.925 | Acc: 48.593,77.197,91.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.921 | Acc: 48.638,77.245,91.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.125 | Acc: 51.562,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 45.536,64.286,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 44.245,63.700,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 43.545,63.947,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 2.661 | Acc: 56.250,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.831 | Acc: 49.442,77.604,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.884 | Acc: 49.276,77.382,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.882 | Acc: 48.950,77.690,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.869 | Acc: 49.035,77.633,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.886 | Acc: 49.165,77.560,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.892 | Acc: 48.883,77.570,91.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.906 | Acc: 48.604,77.482,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.912 | Acc: 48.573,77.252,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.917 | Acc: 48.571,77.335,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.923 | Acc: 48.515,77.317,91.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.930 | Acc: 48.452,77.107,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.931 | Acc: 48.454,77.136,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.931 | Acc: 48.360,77.149,91.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.926 | Acc: 48.443,77.269,91.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.927 | Acc: 48.388,77.230,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.923 | Acc: 48.562,77.302,91.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.928 | Acc: 48.502,77.319,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.927 | Acc: 48.546,77.385,91.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.923 | Acc: 48.626,77.432,91.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.305 | Acc: 48.438,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.627 | Acc: 45.871,64.397,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 45.160,63.662,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.643 | Acc: 44.787,63.947,68.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 2.652 | Acc: 52.344,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.923 | Acc: 47.247,77.753,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.916 | Acc: 47.828,77.268,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.898 | Acc: 48.297,77.830,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.909 | Acc: 48.148,77.488,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.920 | Acc: 48.128,77.351,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.913 | Acc: 48.580,77.344,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.918 | Acc: 48.637,77.227,92.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.931 | Acc: 48.491,77.111,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.929 | Acc: 48.459,77.063,91.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.923 | Acc: 48.507,77.134,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.915 | Acc: 48.674,77.270,91.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.907 | Acc: 48.752,77.441,91.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.903 | Acc: 48.866,77.568,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.903 | Acc: 48.916,77.466,91.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.901 | Acc: 48.861,77.409,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.897 | Acc: 48.863,77.444,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.899 | Acc: 48.857,77.456,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.907 | Acc: 48.805,77.398,91.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.910 | Acc: 48.727,77.305,91.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.427 | Acc: 48.438,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.709 | Acc: 45.052,62.872,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.715 | Acc: 44.417,62.595,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.724 | Acc: 44.121,62.807,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 2.829 | Acc: 48.438,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.884 | Acc: 49.665,77.493,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.904 | Acc: 48.399,77.934,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.903 | Acc: 48.578,77.600,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.884 | Acc: 48.823,77.585,91.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.896 | Acc: 48.933,77.382,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.892 | Acc: 49.032,77.240,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.904 | Acc: 48.920,77.006,91.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.907 | Acc: 48.850,77.116,91.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.907 | Acc: 48.731,77.253,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.901 | Acc: 48.713,77.301,91.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 48.802,77.323,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.891 | Acc: 48.872,77.331,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.897 | Acc: 48.913,77.296,91.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.899 | Acc: 48.874,77.394,91.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.897 | Acc: 48.944,77.471,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.896 | Acc: 48.966,77.524,91.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.903 | Acc: 48.868,77.481,91.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.899 | Acc: 48.983,77.517,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.905 | Acc: 48.860,77.459,91.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.511 | Acc: 52.344,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.782 | Acc: 43.899,62.872,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.791 | Acc: 43.293,62.576,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.801 | Acc: 42.725,62.871,68.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 3.111 | Acc: 50.781,72.656,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.831 | Acc: 49.591,78.460,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.875 | Acc: 48.857,77.534,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.884 | Acc: 48.502,76.998,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.869 | Acc: 48.756,77.209,91.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.888 | Acc: 48.615,77.050,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.911 | Acc: 48.431,76.872,91.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.920 | Acc: 48.576,76.828,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.914 | Acc: 48.505,77.038,91.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.917 | Acc: 48.446,77.059,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.913 | Acc: 48.511,77.103,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.911 | Acc: 48.526,77.082,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.913 | Acc: 48.480,77.117,91.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.909 | Acc: 48.351,77.149,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.909 | Acc: 48.412,77.135,91.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.913 | Acc: 48.456,77.105,91.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.910 | Acc: 48.574,77.144,91.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.913 | Acc: 48.582,77.151,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.910 | Acc: 48.689,77.136,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.908 | Acc: 48.655,77.180,91.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.337 | Acc: 50.000,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.693 | Acc: 44.159,64.174,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.714 | Acc: 43.331,63.624,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.724 | Acc: 42.905,63.704,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 2.789 | Acc: 50.000,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.834 | Acc: 49.665,78.423,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 49.085,78.144,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.862 | Acc: 49.027,77.971,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.854 | Acc: 48.833,77.836,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.875 | Acc: 48.793,77.955,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.878 | Acc: 48.818,77.783,92.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.878 | Acc: 48.781,77.743,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.882 | Acc: 48.816,77.771,91.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.887 | Acc: 48.666,77.788,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.883 | Acc: 48.694,77.923,91.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.883 | Acc: 48.696,77.835,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.884 | Acc: 48.736,77.700,91.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.888 | Acc: 48.767,77.631,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.892 | Acc: 48.721,77.552,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 48.643,77.538,91.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.898 | Acc: 48.686,77.570,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.897 | Acc: 48.680,77.623,91.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.898 | Acc: 48.680,77.645,91.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.900 | Acc: 48.653,77.606,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 47.656,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.859 | Acc: 42.560,62.723,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.824 | Acc: 42.759,62.595,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.821 | Acc: 42.354,62.820,68.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.655 | Acc: 52.344,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.809 | Acc: 48.735,78.423,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.849 | Acc: 49.200,77.649,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.855 | Acc: 49.027,77.997,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.848 | Acc: 49.199,78.029,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.851 | Acc: 49.072,78.024,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.874 | Acc: 48.896,77.705,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.878 | Acc: 48.742,77.704,92.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.888 | Acc: 48.573,77.601,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.885 | Acc: 48.731,77.650,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.894 | Acc: 48.612,77.550,91.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.897 | Acc: 48.643,77.563,91.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.896 | Acc: 48.745,77.600,91.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.893 | Acc: 48.764,77.589,91.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.893 | Acc: 48.796,77.611,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.893 | Acc: 48.757,77.655,91.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.897 | Acc: 48.793,77.577,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.897 | Acc: 48.806,77.538,91.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.893 | Acc: 48.847,77.554,91.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.893 | Acc: 48.915,77.598,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 50.000,63.281,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.755 | Acc: 43.415,63.653,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.744 | Acc: 43.693,63.014,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.750 | Acc: 43.251,62.999,68.455,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 2.717 | Acc: 50.781,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.835 | Acc: 48.661,78.088,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.875 | Acc: 48.476,77.268,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.909 | Acc: 48.770,77.357,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.906 | Acc: 48.881,77.373,91.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.901 | Acc: 48.778,77.545,92.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.897 | Acc: 48.889,77.557,92.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.881 | Acc: 49.169,77.732,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.882 | Acc: 49.170,77.654,92.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.896 | Acc: 48.865,77.447,92.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.900 | Acc: 48.741,77.410,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.897 | Acc: 48.869,77.496,91.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.891 | Acc: 48.924,77.529,91.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.886 | Acc: 49.072,77.601,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.884 | Acc: 49.130,77.625,91.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 49.110,77.520,91.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.886 | Acc: 49.117,77.560,91.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.889 | Acc: 49.049,77.541,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.890 | Acc: 48.914,77.571,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.897 | Acc: 48.860,77.504,91.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.357 | Acc: 52.344,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.727 | Acc: 44.085,63.579,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.712 | Acc: 43.655,63.377,68.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.731 | Acc: 43.225,63.230,68.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.795 | Acc: 41.406,73.438,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.822 | Acc: 49.182,77.753,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.858 | Acc: 48.723,77.496,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.869 | Acc: 48.770,77.587,91.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.873 | Acc: 48.582,77.816,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.874 | Acc: 48.523,77.785,92.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.870 | Acc: 48.496,77.828,92.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.868 | Acc: 48.726,78.042,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.869 | Acc: 48.777,78.057,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 48.761,77.952,92.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.883 | Acc: 48.655,77.806,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.885 | Acc: 48.724,77.764,92.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.889 | Acc: 48.626,77.580,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.888 | Acc: 48.674,77.577,91.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.898 | Acc: 48.504,77.536,91.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.900 | Acc: 48.513,77.471,91.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.890 | Acc: 48.790,77.602,91.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.892 | Acc: 48.834,77.589,91.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.891 | Acc: 48.834,77.608,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.892 | Acc: 48.764,77.604,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.584 | Acc: 46.094,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.772 | Acc: 44.234,63.207,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.755 | Acc: 44.036,62.271,68.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.755 | Acc: 43.840,62.795,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 2.761 | Acc: 50.781,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.919 | Acc: 48.624,76.897,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.848 | Acc: 49.047,77.934,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.860 | Acc: 49.091,77.959,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.859 | Acc: 49.190,77.990,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.855 | Acc: 49.451,78.079,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.858 | Acc: 49.322,78.002,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.860 | Acc: 49.136,77.920,92.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.870 | Acc: 49.088,77.708,91.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.876 | Acc: 49.184,77.655,91.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.877 | Acc: 49.044,77.721,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.877 | Acc: 49.063,77.757,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 49.121,77.853,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.873 | Acc: 48.961,77.927,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.883 | Acc: 48.785,77.839,91.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.883 | Acc: 48.816,77.884,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.881 | Acc: 48.856,77.835,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.873 | Acc: 48.962,77.946,91.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.873 | Acc: 48.959,77.924,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.876 | Acc: 48.948,77.893,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.622 | Acc: 49.219,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.832 | Acc: 44.494,62.686,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.834 | Acc: 43.369,61.738,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.836 | Acc: 42.764,62.180,68.417,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.785 | Acc: 50.000,75.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.927 | Acc: 47.954,76.935,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.918 | Acc: 48.380,77.287,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.883 | Acc: 48.668,78.048,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.864 | Acc: 49.392,78.144,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.864 | Acc: 49.033,78.202,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.872 | Acc: 49.064,78.048,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.871 | Acc: 48.975,77.865,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.870 | Acc: 48.976,77.814,91.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.860 | Acc: 49.197,77.914,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.863 | Acc: 49.090,77.927,91.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.864 | Acc: 48.975,77.952,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.867 | Acc: 48.992,77.888,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.873 | Acc: 49.033,77.781,91.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.872 | Acc: 49.057,77.791,91.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.877 | Acc: 48.941,77.738,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.876 | Acc: 48.971,77.726,91.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.881 | Acc: 48.985,77.667,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.881 | Acc: 48.877,77.714,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.880 | Acc: 48.895,77.707,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.478 | Acc: 48.438,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.800 | Acc: 43.676,62.054,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.822 | Acc: 43.464,61.833,68.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.819 | Acc: 43.212,62.372,68.404,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.731 | Acc: 49.219,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 49.219,78.237,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.808 | Acc: 49.886,78.506,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.841 | Acc: 49.091,78.407,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.852 | Acc: 49.190,78.260,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.867 | Acc: 49.257,78.125,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 49.322,78.060,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.863 | Acc: 49.463,78.081,92.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.874 | Acc: 49.214,77.858,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.868 | Acc: 49.348,77.926,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.882 | Acc: 49.102,77.760,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.885 | Acc: 48.993,77.715,91.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.887 | Acc: 48.856,77.742,91.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.883 | Acc: 48.925,77.784,91.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.888 | Acc: 48.799,77.638,91.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.884 | Acc: 48.907,77.647,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.883 | Acc: 48.910,77.665,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.883 | Acc: 48.914,77.644,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.885 | Acc: 48.844,77.625,91.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.887 | Acc: 48.846,77.551,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.390 | Acc: 54.688,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.716 | Acc: 45.238,63.579,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.734 | Acc: 44.684,62.500,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.742 | Acc: 44.224,62.871,68.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 2.992 | Acc: 49.219,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.843 | Acc: 48.289,78.534,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.828 | Acc: 48.685,78.506,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.861 | Acc: 48.348,78.048,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.864 | Acc: 48.428,78.164,92.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.868 | Acc: 48.430,78.055,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.872 | Acc: 48.315,78.157,92.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.874 | Acc: 48.327,77.909,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.866 | Acc: 48.413,77.984,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.878 | Acc: 48.390,77.892,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.871 | Acc: 48.624,77.950,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.869 | Acc: 48.643,77.959,92.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 48.561,77.976,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.866 | Acc: 48.599,77.999,92.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.870 | Acc: 48.540,77.939,92.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.874 | Acc: 48.461,77.884,91.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.874 | Acc: 48.496,77.899,91.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.875 | Acc: 48.637,77.857,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.880 | Acc: 48.578,77.755,91.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.881 | Acc: 48.556,77.723,91.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.543 | Acc: 47.656,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.938 | Acc: 41.667,62.872,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.942 | Acc: 41.254,62.309,68.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.978 | Acc: 40.817,62.052,68.238,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 3.133 | Acc: 49.219,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.793 | Acc: 49.293,78.646,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.812 | Acc: 49.009,78.220,93.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.861 | Acc: 48.783,77.792,92.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.877 | Acc: 48.322,77.730,92.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.857 | Acc: 48.577,78.032,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.860 | Acc: 48.747,78.015,92.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.855 | Acc: 48.570,78.097,92.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.851 | Acc: 48.772,78.023,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.841 | Acc: 48.999,78.164,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.844 | Acc: 48.982,78.148,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.849 | Acc: 48.989,78.189,92.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.850 | Acc: 49.070,78.083,92.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.859 | Acc: 48.934,77.975,92.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.858 | Acc: 48.996,77.939,92.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.861 | Acc: 48.957,77.907,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.861 | Acc: 48.932,77.867,92.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.869 | Acc: 48.861,77.747,92.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.870 | Acc: 48.855,77.766,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.874 | Acc: 48.850,77.709,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.567 | Acc: 47.656,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.855 | Acc: 43.043,62.016,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.863 | Acc: 42.873,61.547,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.867 | Acc: 42.546,62.218,67.969,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 3.403 | Acc: 35.938,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.935 | Acc: 46.912,77.753,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 48.476,78.601,92.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.841 | Acc: 48.578,78.727,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.857 | Acc: 48.428,78.356,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.858 | Acc: 48.554,78.280,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.845 | Acc: 48.567,78.409,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.836 | Acc: 48.781,78.264,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.837 | Acc: 48.617,78.285,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.844 | Acc: 48.649,78.198,92.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.846 | Acc: 48.702,78.059,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.841 | Acc: 48.908,78.076,92.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.840 | Acc: 48.989,78.076,92.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.845 | Acc: 48.952,78.077,92.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 49.024,78.133,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.844 | Acc: 48.998,78.146,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.847 | Acc: 49.031,78.013,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.853 | Acc: 48.925,77.949,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.854 | Acc: 48.918,77.887,91.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.855 | Acc: 48.999,77.883,91.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.482 | Acc: 50.781,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.799 | Acc: 44.159,63.021,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.790 | Acc: 43.769,62.881,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.813 | Acc: 43.263,62.743,68.007,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 2.539 | Acc: 53.906,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.808 | Acc: 50.298,78.274,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.881 | Acc: 49.085,77.572,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.857 | Acc: 49.334,77.959,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.864 | Acc: 49.306,78.241,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.884 | Acc: 48.948,78.063,92.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.866 | Acc: 49.245,78.235,92.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.868 | Acc: 49.102,78.158,92.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.868 | Acc: 48.986,77.975,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.857 | Acc: 49.189,77.996,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.858 | Acc: 49.137,77.942,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.858 | Acc: 49.145,77.888,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.857 | Acc: 49.102,77.953,92.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.864 | Acc: 49.084,77.939,92.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.863 | Acc: 49.066,77.933,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 48.993,77.904,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.864 | Acc: 49.012,77.928,92.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.867 | Acc: 49.024,77.905,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.866 | Acc: 49.061,77.961,92.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.873 | Acc: 48.995,77.885,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.611 | Acc: 46.875,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.791 | Acc: 43.601,63.244,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.787 | Acc: 42.778,63.186,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.814 | Acc: 42.738,62.948,68.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.573 | Acc: 46.875,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.779 | Acc: 50.260,79.688,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.777 | Acc: 50.248,79.211,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 49.834,78.829,92.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.818 | Acc: 49.296,78.636,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.826 | Acc: 49.118,78.527,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.851 | Acc: 48.799,78.157,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.849 | Acc: 48.703,78.153,92.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.845 | Acc: 48.996,78.203,92.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.847 | Acc: 49.012,78.216,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.848 | Acc: 49.083,78.230,92.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.850 | Acc: 48.947,78.192,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.849 | Acc: 49.037,78.180,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.855 | Acc: 48.985,78.089,92.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 49.099,78.097,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 49.099,78.063,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.855 | Acc: 49.075,77.984,92.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 49.159,77.981,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 49.117,77.991,92.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.853 | Acc: 49.085,78.020,92.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.509 | Acc: 49.219,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.901 | Acc: 43.899,62.723,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.876 | Acc: 43.598,61.986,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.907 | Acc: 43.148,62.026,68.033,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.574 | Acc: 42.188,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.763 | Acc: 48.996,79.018,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.768 | Acc: 49.162,78.487,92.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.767 | Acc: 49.385,78.778,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 49.171,78.549,92.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.808 | Acc: 49.219,78.373,92.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.835 | Acc: 49.122,78.157,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.834 | Acc: 49.285,78.186,92.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.841 | Acc: 49.199,78.101,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.843 | Acc: 49.132,78.112,92.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 48.892,77.946,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.848 | Acc: 48.922,78.058,92.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.847 | Acc: 48.872,78.096,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.848 | Acc: 48.901,78.098,92.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 49.032,78.114,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.844 | Acc: 49.071,78.138,92.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.845 | Acc: 49.036,78.144,92.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 49.024,78.141,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.850 | Acc: 49.002,78.121,92.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 48.917,78.012,92.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.768 | Acc: 45.312,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.053 | Acc: 41.071,62.463,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.061 | Acc: 40.835,61.795,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.063 | Acc: 40.343,62.282,67.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.790 | Acc: 47.656,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.764 | Acc: 49.888,78.943,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.769 | Acc: 49.790,79.002,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.779 | Acc: 49.962,78.893,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.789 | Acc: 50.328,78.520,92.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.801 | Acc: 49.907,78.419,92.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.808 | Acc: 49.897,78.222,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.812 | Acc: 49.873,78.236,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.836 | Acc: 49.612,77.931,92.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.841 | Acc: 49.452,77.970,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.835 | Acc: 49.429,78.067,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.838 | Acc: 49.392,78.111,92.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.845 | Acc: 49.303,78.047,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.844 | Acc: 49.332,77.999,92.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 49.288,77.986,92.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.851 | Acc: 49.188,77.897,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.848 | Acc: 49.265,77.969,92.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.852 | Acc: 49.180,77.949,92.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.853 | Acc: 49.124,77.930,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.853 | Acc: 49.057,77.924,92.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.506 | Acc: 49.219,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.864 | Acc: 43.973,61.979,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.840 | Acc: 43.979,61.719,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.844 | Acc: 44.109,62.141,68.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 2.736 | Acc: 46.094,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.807 | Acc: 48.996,79.241,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.823 | Acc: 49.200,78.373,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.816 | Acc: 49.270,78.471,92.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.828 | Acc: 48.987,78.106,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.826 | Acc: 49.141,78.063,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.819 | Acc: 49.387,78.222,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.821 | Acc: 49.357,78.047,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.828 | Acc: 49.413,78.023,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.832 | Acc: 49.240,77.844,92.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.834 | Acc: 49.153,77.861,92.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.832 | Acc: 49.215,77.870,92.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.837 | Acc: 49.248,77.710,92.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.839 | Acc: 49.243,77.769,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.840 | Acc: 49.144,77.805,92.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.845 | Acc: 49.115,77.795,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.843 | Acc: 49.090,77.860,92.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.842 | Acc: 49.129,77.868,92.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.844 | Acc: 49.152,77.844,92.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.849 | Acc: 49.065,77.772,92.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.687 | Acc: 45.312,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.831 | Acc: 44.196,62.091,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.854 | Acc: 43.579,62.157,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.868 | Acc: 43.417,62.154,67.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 2.841 | Acc: 55.469,79.688,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.720 | Acc: 51.153,80.060,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.795 | Acc: 50.038,79.078,92.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.832 | Acc: 49.539,78.432,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.821 | Acc: 49.412,78.578,92.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.828 | Acc: 49.203,78.844,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 49.232,78.596,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.840 | Acc: 48.986,78.585,92.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.837 | Acc: 49.000,78.567,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.840 | Acc: 49.029,78.583,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.842 | Acc: 49.110,78.420,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.843 | Acc: 49.095,78.404,92.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.847 | Acc: 49.050,78.310,92.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.845 | Acc: 49.111,78.302,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.850 | Acc: 49.060,78.181,92.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 49.060,78.156,92.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.852 | Acc: 49.039,78.123,92.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 49.155,78.132,92.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.844 | Acc: 49.143,78.134,92.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 49.079,78.102,92.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.659 | Acc: 47.656,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.801 | Acc: 44.457,62.760,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.809 | Acc: 44.055,62.271,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.816 | Acc: 43.981,62.500,67.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.546 | Acc: 57.031,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.769 | Acc: 50.074,80.432,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 49.714,79.973,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.772 | Acc: 49.769,79.764,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.808 | Acc: 49.267,79.398,92.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.820 | Acc: 48.909,79.022,92.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 48.618,78.861,92.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.841 | Acc: 48.748,78.768,92.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.835 | Acc: 48.894,78.693,92.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.836 | Acc: 48.800,78.677,92.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.840 | Acc: 48.663,78.611,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.847 | Acc: 48.688,78.479,92.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.847 | Acc: 48.771,78.414,92.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.856 | Acc: 48.644,78.242,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.854 | Acc: 48.643,78.178,92.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.851 | Acc: 48.754,78.239,92.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.857 | Acc: 48.800,78.147,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.862 | Acc: 48.779,78.063,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.861 | Acc: 48.875,78.028,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 48.901,78.022,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.437 | Acc: 48.438,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.857 | Acc: 42.932,63.132,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.874 | Acc: 42.950,62.138,67.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.875 | Acc: 42.789,62.423,68.289,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 3.003 | Acc: 48.438,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.842 | Acc: 47.879,78.571,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.768 | Acc: 49.276,79.402,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.761 | Acc: 49.347,79.278,92.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 49.315,78.877,92.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.778 | Acc: 49.343,78.953,92.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.800 | Acc: 49.264,78.751,92.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.814 | Acc: 49.180,78.446,92.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.818 | Acc: 49.112,78.363,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.824 | Acc: 49.124,78.302,92.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.824 | Acc: 49.122,78.358,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.831 | Acc: 49.031,78.266,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.833 | Acc: 49.053,78.242,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.836 | Acc: 49.150,78.230,92.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.839 | Acc: 49.210,78.231,92.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.844 | Acc: 49.143,78.130,92.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.851 | Acc: 49.124,78.040,92.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 49.100,77.946,92.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.852 | Acc: 49.145,77.965,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.854 | Acc: 49.151,77.973,92.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.692 | Acc: 43.750,65.625,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.782 | Acc: 43.043,63.356,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.815 | Acc: 42.740,62.633,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.832 | Acc: 42.392,62.897,68.391,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 2.709 | Acc: 52.344,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.866 | Acc: 47.991,78.088,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.876 | Acc: 48.342,78.049,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.861 | Acc: 48.425,78.176,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.853 | Acc: 48.920,78.144,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.850 | Acc: 49.203,78.009,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.841 | Acc: 49.367,78.035,92.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.850 | Acc: 49.058,77.892,92.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 48.966,77.834,92.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.855 | Acc: 48.891,77.810,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.846 | Acc: 48.904,77.767,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.850 | Acc: 48.840,77.641,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.853 | Acc: 48.830,77.597,92.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.851 | Acc: 48.952,77.559,92.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 48.952,77.619,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.854 | Acc: 48.858,77.497,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.848 | Acc: 48.980,77.594,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.848 | Acc: 48.987,77.614,92.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.847 | Acc: 48.972,77.707,92.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.847 | Acc: 48.981,77.758,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.467 | Acc: 46.094,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.783 | Acc: 45.796,63.132,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.810 | Acc: 44.131,62.405,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.831 | Acc: 43.596,62.257,67.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 2.737 | Acc: 46.875,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.880 | Acc: 48.475,77.493,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.888 | Acc: 48.476,77.477,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.860 | Acc: 48.578,77.587,92.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.829 | Acc: 48.881,78.270,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.828 | Acc: 49.087,78.110,92.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.823 | Acc: 49.180,78.202,92.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.829 | Acc: 49.302,78.169,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.827 | Acc: 49.432,78.110,92.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.835 | Acc: 49.322,78.013,92.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.833 | Acc: 49.370,78.039,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.839 | Acc: 49.123,78.079,92.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.837 | Acc: 49.008,78.106,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.832 | Acc: 49.039,78.125,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.836 | Acc: 49.057,78.089,92.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.832 | Acc: 49.214,78.112,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.835 | Acc: 49.209,78.057,92.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.834 | Acc: 49.274,78.036,92.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.837 | Acc: 49.197,78.032,92.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.839 | Acc: 49.186,77.984,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.325 | Acc: 52.344,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.757 | Acc: 44.568,63.244,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.781 | Acc: 43.750,62.290,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.803 | Acc: 43.417,62.551,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 2.627 | Acc: 48.438,83.594,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.746 | Acc: 50.632,79.278,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.763 | Acc: 49.848,79.402,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 49.039,79.111,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.786 | Acc: 49.479,79.186,92.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.786 | Acc: 49.799,79.092,92.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.803 | Acc: 49.554,78.861,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.818 | Acc: 49.374,78.441,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.813 | Acc: 49.384,78.411,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.828 | Acc: 49.318,78.142,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.834 | Acc: 49.122,78.152,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.837 | Acc: 49.141,78.076,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.833 | Acc: 49.203,78.180,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.834 | Acc: 49.186,78.176,92.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.837 | Acc: 49.208,78.136,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.843 | Acc: 49.143,78.047,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.842 | Acc: 49.073,78.106,92.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.842 | Acc: 49.072,78.098,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.847 | Acc: 49.117,78.032,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 49.192,78.080,92.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.435 | Acc: 47.656,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.779 | Acc: 45.052,63.802,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.783 | Acc: 44.398,62.633,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.795 | Acc: 43.981,62.769,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.953 | Acc: 47.656,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.781 | Acc: 50.856,79.427,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.721 | Acc: 50.743,79.992,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.749 | Acc: 50.499,79.470,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.751 | Acc: 50.154,79.610,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 50.201,79.308,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.777 | Acc: 50.110,79.113,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.782 | Acc: 49.878,79.095,92.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.789 | Acc: 49.908,78.955,92.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.796 | Acc: 49.914,78.829,92.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 49.790,78.634,92.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 49.668,78.482,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.816 | Acc: 49.527,78.430,92.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.821 | Acc: 49.524,78.406,92.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.828 | Acc: 49.374,78.345,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 49.359,78.257,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.830 | Acc: 49.362,78.125,92.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.831 | Acc: 49.416,78.093,92.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.831 | Acc: 49.429,78.064,92.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.835 | Acc: 49.358,77.973,92.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.611 | Acc: 46.875,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.954 | Acc: 42.336,62.165,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.913 | Acc: 42.492,61.986,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.916 | Acc: 42.303,62.077,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 2.370 | Acc: 54.688,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.768 | Acc: 50.037,77.604,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 49.790,78.601,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.780 | Acc: 49.769,78.509,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.787 | Acc: 49.653,78.501,92.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.796 | Acc: 49.783,78.210,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.819 | Acc: 49.522,77.951,92.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.821 | Acc: 49.141,77.870,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.834 | Acc: 49.039,77.921,92.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.836 | Acc: 48.899,78.034,92.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.834 | Acc: 49.024,77.989,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.837 | Acc: 49.148,77.945,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.840 | Acc: 49.147,77.846,92.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.843 | Acc: 49.162,77.826,92.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.846 | Acc: 49.083,77.808,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.845 | Acc: 49.045,77.852,92.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.848 | Acc: 49.041,77.833,92.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 49.019,77.793,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.854 | Acc: 49.007,77.787,92.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.854 | Acc: 48.967,77.778,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.544 | Acc: 49.219,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.900 | Acc: 42.634,62.351,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.906 | Acc: 42.626,61.814,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.939 | Acc: 42.008,62.154,67.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 2.457 | Acc: 51.562,85.156,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.775 | Acc: 49.219,79.278,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.784 | Acc: 49.505,78.944,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.764 | Acc: 49.859,79.457,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.776 | Acc: 49.691,79.118,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.788 | Acc: 49.791,78.837,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.804 | Acc: 49.477,78.803,92.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.812 | Acc: 49.440,78.568,92.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.813 | Acc: 49.272,78.547,92.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.814 | Acc: 49.370,78.462,92.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.834 | Acc: 49.219,78.331,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.841 | Acc: 49.070,78.259,92.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.840 | Acc: 49.131,78.222,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.841 | Acc: 49.084,78.203,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.846 | Acc: 49.044,78.086,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.846 | Acc: 49.032,78.156,92.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.846 | Acc: 49.092,78.115,92.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 49.113,78.102,92.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.844 | Acc: 49.098,78.097,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.846 | Acc: 49.042,78.066,92.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.605 | Acc: 47.656,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.930 | Acc: 42.188,62.202,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.963 | Acc: 41.578,61.376,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.957 | Acc: 41.534,61.629,68.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.960 | Acc: 48.438,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 49.888,79.204,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.808 | Acc: 49.600,79.173,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.793 | Acc: 49.424,79.355,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.810 | Acc: 49.122,78.887,92.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.812 | Acc: 49.087,78.929,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.810 | Acc: 48.993,78.751,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.819 | Acc: 48.975,78.568,92.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.824 | Acc: 48.908,78.460,92.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.835 | Acc: 48.753,78.393,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.829 | Acc: 48.815,78.366,92.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.824 | Acc: 49.017,78.415,92.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.830 | Acc: 49.008,78.281,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.826 | Acc: 49.039,78.358,92.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.831 | Acc: 49.035,78.356,92.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.830 | Acc: 49.063,78.411,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.827 | Acc: 49.187,78.371,92.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.828 | Acc: 49.184,78.363,92.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.837 | Acc: 49.171,78.207,92.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 49.151,78.164,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.661 | Acc: 49.219,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.835 | Acc: 44.159,62.872,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.845 | Acc: 43.579,62.367,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.867 | Acc: 43.007,62.359,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.662 | Acc: 45.312,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.786 | Acc: 49.107,78.534,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.770 | Acc: 49.657,79.287,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.797 | Acc: 49.052,79.175,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.778 | Acc: 49.103,79.273,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.767 | Acc: 49.358,79.425,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.772 | Acc: 49.567,79.190,92.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.783 | Acc: 49.596,79.078,92.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.794 | Acc: 49.481,78.931,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.803 | Acc: 49.353,78.833,92.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 49.281,78.848,92.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.808 | Acc: 49.272,78.882,92.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 49.212,78.777,92.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.815 | Acc: 49.228,78.757,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.819 | Acc: 49.194,78.656,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.825 | Acc: 49.247,78.553,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.828 | Acc: 49.287,78.473,92.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.828 | Acc: 49.308,78.430,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.830 | Acc: 49.325,78.383,92.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.829 | Acc: 49.325,78.357,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.854 | Acc: 48.438,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.942 | Acc: 43.192,62.612,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.015 | Acc: 42.073,61.338,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.027 | Acc: 42.123,61.603,67.213,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 2.552 | Acc: 50.781,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.873 | Acc: 47.656,78.534,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.848 | Acc: 47.999,78.487,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.839 | Acc: 47.861,78.560,92.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.822 | Acc: 48.177,78.742,92.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.807 | Acc: 48.476,78.759,92.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.804 | Acc: 48.728,78.751,92.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.811 | Acc: 48.836,78.685,92.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.817 | Acc: 48.767,78.698,92.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.827 | Acc: 48.696,78.574,92.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.834 | Acc: 48.678,78.448,92.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.829 | Acc: 48.830,78.334,92.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.828 | Acc: 48.872,78.436,92.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.830 | Acc: 48.931,78.391,92.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.826 | Acc: 49.074,78.425,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.822 | Acc: 49.146,78.418,92.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.824 | Acc: 49.182,78.364,92.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 49.141,78.409,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.830 | Acc: 49.076,78.380,92.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.831 | Acc: 49.067,78.365,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.290 | Acc: 50.000,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.777 | Acc: 44.159,63.542,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.815 | Acc: 43.388,62.595,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.839 | Acc: 43.174,62.666,68.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 3.015 | Acc: 53.906,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.762 | Acc: 50.670,78.571,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.761 | Acc: 50.152,79.325,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.767 | Acc: 50.102,78.637,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.793 | Acc: 49.566,78.636,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.806 | Acc: 49.226,78.396,93.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.805 | Acc: 49.277,78.467,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.816 | Acc: 49.152,78.269,92.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.822 | Acc: 49.000,78.144,92.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.805 | Acc: 49.301,78.324,92.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.811 | Acc: 49.141,78.269,92.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 49.000,78.224,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 49.024,78.144,92.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 49.054,78.092,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.819 | Acc: 49.038,78.022,92.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.822 | Acc: 49.014,77.995,92.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.824 | Acc: 48.995,78.071,92.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 49.006,78.072,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.826 | Acc: 49.072,78.112,92.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.827 | Acc: 49.092,78.088,92.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.435 | Acc: 50.000,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.769 | Acc: 45.238,62.835,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.821 | Acc: 44.226,62.576,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.823 | Acc: 43.699,63.128,67.866,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 2.849 | Acc: 50.781,78.906,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.874 | Acc: 48.028,78.162,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.821 | Acc: 48.761,78.220,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.804 | Acc: 49.014,78.714,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 48.775,78.655,92.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.800 | Acc: 48.902,78.651,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.814 | Acc: 48.683,78.751,92.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.817 | Acc: 48.692,78.668,92.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.818 | Acc: 48.734,78.756,92.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.802 | Acc: 49.016,79.001,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.805 | Acc: 49.114,79.066,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.817 | Acc: 48.840,78.917,92.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.818 | Acc: 48.846,78.835,92.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.815 | Acc: 48.898,78.888,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.819 | Acc: 48.902,78.776,92.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 48.975,78.774,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 49.056,78.768,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.816 | Acc: 49.127,78.760,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.823 | Acc: 49.115,78.677,92.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 49.122,78.597,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.432 | Acc: 49.219,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.873 | Acc: 43.787,62.537,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.880 | Acc: 43.312,62.100,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.887 | Acc: 43.148,62.410,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.464 | Acc: 53.906,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.772 | Acc: 48.549,78.646,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.753 | Acc: 49.543,79.230,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.789 | Acc: 49.129,78.765,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.787 | Acc: 49.228,78.733,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 49.234,78.697,92.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.787 | Acc: 49.251,78.706,92.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.793 | Acc: 49.274,78.674,92.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.794 | Acc: 49.432,78.547,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.790 | Acc: 49.530,78.759,92.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.793 | Acc: 49.565,78.677,92.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.800 | Acc: 49.509,78.496,92.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.797 | Acc: 49.498,78.514,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.799 | Acc: 49.383,78.538,92.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.811 | Acc: 49.252,78.453,92.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 49.216,78.403,92.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.820 | Acc: 49.197,78.312,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.823 | Acc: 49.182,78.276,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.824 | Acc: 49.210,78.300,92.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.823 | Acc: 49.153,78.273,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.553 | Acc: 46.875,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.007 | Acc: 41.481,62.574,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.002 | Acc: 41.978,62.252,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.034 | Acc: 41.432,62.462,67.789,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.721 | Acc: 42.969,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.770 | Acc: 49.479,79.018,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.793 | Acc: 49.371,79.383,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.747 | Acc: 50.295,79.316,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.755 | Acc: 50.309,79.475,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 50.046,79.308,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.793 | Acc: 49.735,78.842,92.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.792 | Acc: 49.690,78.879,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.794 | Acc: 49.699,78.906,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.804 | Acc: 49.525,78.854,92.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.802 | Acc: 49.588,78.867,92.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 49.530,78.818,92.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.806 | Acc: 49.468,78.854,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.814 | Acc: 49.380,78.766,92.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.814 | Acc: 49.397,78.695,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.819 | Acc: 49.263,78.652,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 49.177,78.660,92.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.827 | Acc: 49.155,78.569,92.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.827 | Acc: 49.180,78.525,92.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.831 | Acc: 49.161,78.531,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.583 | Acc: 52.344,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.961 | Acc: 43.936,62.128,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.957 | Acc: 43.731,61.357,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.981 | Acc: 43.199,61.463,66.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.753 | Acc: 50.781,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.767 | Acc: 49.777,77.827,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.763 | Acc: 49.809,78.735,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.776 | Acc: 49.155,78.957,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 49.373,78.627,92.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.753 | Acc: 49.683,78.860,92.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.769 | Acc: 49.483,78.939,92.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.774 | Acc: 49.474,78.784,92.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.794 | Acc: 49.224,78.620,92.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 49.180,78.492,92.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 49.238,78.529,92.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.806 | Acc: 49.441,78.539,92.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 49.572,78.563,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.803 | Acc: 49.536,78.568,92.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.806 | Acc: 49.527,78.445,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.815 | Acc: 49.400,78.307,92.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 49.357,78.244,92.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.820 | Acc: 49.365,78.217,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.824 | Acc: 49.353,78.207,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.821 | Acc: 49.373,78.236,92.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.526 | Acc: 47.656,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.807 | Acc: 45.610,63.467,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.840 | Acc: 44.798,62.729,67.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.872 | Acc: 44.096,62.526,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 2.467 | Acc: 54.688,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.721 | Acc: 49.777,79.241,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.763 | Acc: 48.876,79.135,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.809 | Acc: 48.758,78.855,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.802 | Acc: 48.939,78.829,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.818 | Acc: 48.847,78.752,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.813 | Acc: 48.960,78.919,92.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.806 | Acc: 49.064,79.133,92.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.803 | Acc: 49.190,79.037,92.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.801 | Acc: 49.085,79.010,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.802 | Acc: 49.048,79.019,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 49.116,78.885,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.807 | Acc: 49.173,78.825,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.808 | Acc: 49.237,78.778,92.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.813 | Acc: 49.141,78.784,92.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.815 | Acc: 49.066,78.719,92.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 48.990,78.602,92.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.820 | Acc: 49.074,78.542,92.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.822 | Acc: 49.091,78.579,92.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.820 | Acc: 49.116,78.621,92.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.563 | Acc: 46.094,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.820 | Acc: 43.192,62.649,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.846 | Acc: 43.083,62.367,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.845 | Acc: 42.994,62.449,67.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.955 | Acc: 46.094,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.767 | Acc: 49.554,80.060,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.785 | Acc: 48.895,79.402,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.806 | Acc: 48.975,78.906,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.796 | Acc: 49.074,78.877,92.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 49.010,78.666,92.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.788 | Acc: 49.329,78.803,92.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.794 | Acc: 49.097,78.657,92.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.798 | Acc: 48.913,78.625,92.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.806 | Acc: 48.912,78.565,92.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 49.021,78.603,92.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.803 | Acc: 49.190,78.539,92.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.808 | Acc: 49.177,78.452,92.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.813 | Acc: 49.033,78.397,92.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 49.038,78.386,92.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.816 | Acc: 49.118,78.359,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.822 | Acc: 49.036,78.281,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 49.024,78.249,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.824 | Acc: 49.117,78.244,92.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 49.079,78.248,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.401 | Acc: 49.219,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.892 | Acc: 43.043,63.281,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.861 | Acc: 43.293,62.843,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.877 | Acc: 42.841,62.935,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.791 | Acc: 48.438,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.720 | Acc: 51.190,80.915,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 51.277,79.992,93.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.715 | Acc: 51.050,79.790,93.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.715 | Acc: 50.849,79.832,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.715 | Acc: 50.480,80.082,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.706 | Acc: 50.536,80.107,93.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.699 | Acc: 50.266,80.286,93.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.700 | Acc: 50.296,80.095,93.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.707 | Acc: 50.319,79.977,93.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.705 | Acc: 50.229,80.010,93.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.699 | Acc: 50.339,80.055,93.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.693 | Acc: 50.379,80.057,93.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.687 | Acc: 50.323,80.131,93.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.687 | Acc: 50.328,80.091,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.680 | Acc: 50.330,80.150,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.684 | Acc: 50.273,80.089,94.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.680 | Acc: 50.234,80.132,94.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.678 | Acc: 50.284,80.187,94.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.678 | Acc: 50.258,80.217,94.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.148 | Acc: 52.344,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 46.019,64.844,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 45.217,63.796,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.617 | Acc: 44.775,64.114,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.429 | Acc: 47.656,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.675 | Acc: 49.591,80.766,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.606 | Acc: 50.305,81.383,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.622 | Acc: 50.102,81.468,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.623 | Acc: 50.096,81.076,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.632 | Acc: 49.969,81.111,95.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.638 | Acc: 50.097,80.985,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.631 | Acc: 50.172,81.195,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.630 | Acc: 50.087,81.080,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.630 | Acc: 50.168,81.146,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.624 | Acc: 50.365,81.149,95.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.617 | Acc: 50.484,81.278,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.617 | Acc: 50.532,81.250,95.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.619 | Acc: 50.488,81.238,95.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.612 | Acc: 50.534,81.275,95.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.613 | Acc: 50.540,81.271,95.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.614 | Acc: 50.496,81.196,95.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.618 | Acc: 50.433,81.200,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.620 | Acc: 50.390,81.131,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.624 | Acc: 50.410,81.055,94.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.156 | Acc: 52.344,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.611 | Acc: 46.503,64.546,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 45.617,63.643,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.647 | Acc: 45.184,63.986,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.644 | Acc: 50.781,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.582 | Acc: 51.079,81.399,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.553 | Acc: 50.877,81.879,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.580 | Acc: 50.717,81.506,95.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.580 | Acc: 50.781,81.240,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.599 | Acc: 50.371,81.219,95.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.589 | Acc: 50.620,81.366,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.589 | Acc: 50.731,81.400,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.588 | Acc: 50.747,81.376,95.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.582 | Acc: 50.906,81.436,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.588 | Acc: 50.785,81.425,95.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.587 | Acc: 50.820,81.459,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.595 | Acc: 50.726,81.360,95.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.597 | Acc: 50.629,81.265,95.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.596 | Acc: 50.673,81.275,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.604 | Acc: 50.511,81.234,95.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.605 | Acc: 50.550,81.245,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.607 | Acc: 50.605,81.193,95.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.609 | Acc: 50.617,81.282,95.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.614 | Acc: 50.550,81.213,95.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.142 | Acc: 53.125,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.595 | Acc: 46.466,65.067,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 45.560,63.891,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 45.197,64.139,69.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.553 | Acc: 51.562,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.525 | Acc: 51.711,81.585,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.595 | Acc: 50.305,81.288,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.596 | Acc: 50.282,81.199,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.607 | Acc: 50.328,81.279,94.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.613 | Acc: 50.162,81.343,94.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.603 | Acc: 50.200,81.495,95.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.608 | Acc: 50.211,81.449,94.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.606 | Acc: 50.209,81.643,95.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.615 | Acc: 50.099,81.522,95.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.617 | Acc: 50.206,81.390,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.613 | Acc: 50.223,81.377,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.611 | Acc: 50.182,81.363,95.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.610 | Acc: 50.138,81.358,95.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.606 | Acc: 50.289,81.358,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.606 | Acc: 50.348,81.305,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.604 | Acc: 50.389,81.330,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.606 | Acc: 50.362,81.316,95.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.609 | Acc: 50.422,81.213,95.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.612 | Acc: 50.332,81.170,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.196 | Acc: 52.344,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.602 | Acc: 46.838,64.695,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.608 | Acc: 46.189,63.796,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.631 | Acc: 45.556,64.050,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 2.505 | Acc: 46.875,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.556 | Acc: 49.182,81.436,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.589 | Acc: 50.248,81.021,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.578 | Acc: 50.499,81.481,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.558 | Acc: 50.868,81.790,95.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.581 | Acc: 50.657,81.528,95.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.596 | Acc: 50.575,81.327,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.593 | Acc: 50.532,81.527,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.599 | Acc: 50.369,81.439,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.599 | Acc: 50.514,81.505,95.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.609 | Acc: 50.284,81.374,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.601 | Acc: 50.414,81.395,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.597 | Acc: 50.489,81.415,95.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.596 | Acc: 50.551,81.388,95.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.599 | Acc: 50.484,81.322,95.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.594 | Acc: 50.517,81.450,95.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.595 | Acc: 50.445,81.430,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.593 | Acc: 50.541,81.422,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.593 | Acc: 50.632,81.401,95.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.597 | Acc: 50.660,81.336,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.181 | Acc: 51.562,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.593 | Acc: 46.280,65.067,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 45.675,63.777,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.623 | Acc: 45.223,64.075,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 3.007 | Acc: 50.000,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.653 | Acc: 48.512,81.994,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.616 | Acc: 49.790,81.955,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.605 | Acc: 49.654,81.967,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.626 | Acc: 49.576,81.424,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.616 | Acc: 49.575,81.482,95.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.609 | Acc: 50.013,81.373,95.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.613 | Acc: 50.055,81.322,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.606 | Acc: 50.233,81.357,95.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.610 | Acc: 50.151,81.405,95.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.605 | Acc: 50.299,81.452,95.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.603 | Acc: 50.156,81.451,95.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.597 | Acc: 50.289,81.493,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.597 | Acc: 50.263,81.492,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.595 | Acc: 50.209,81.481,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.597 | Acc: 50.234,81.491,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.596 | Acc: 50.321,81.450,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.594 | Acc: 50.353,81.461,95.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.595 | Acc: 50.416,81.466,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.598 | Acc: 50.369,81.394,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.203 | Acc: 50.000,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.592 | Acc: 46.615,64.546,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 45.960,63.681,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.622 | Acc: 45.569,64.062,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.541 | Acc: 47.656,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.512 | Acc: 51.376,82.403,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.503 | Acc: 51.239,82.527,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.535 | Acc: 51.562,81.890,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.530 | Acc: 51.765,81.944,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.544 | Acc: 51.562,82.008,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.550 | Acc: 51.375,81.921,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.556 | Acc: 51.291,81.859,95.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.564 | Acc: 51.102,81.895,95.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.574 | Acc: 51.006,81.820,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.577 | Acc: 50.964,81.716,95.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.580 | Acc: 50.905,81.589,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.580 | Acc: 50.940,81.568,95.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.577 | Acc: 50.964,81.615,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.572 | Acc: 51.034,81.636,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.577 | Acc: 50.924,81.606,95.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.578 | Acc: 50.879,81.605,95.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.581 | Acc: 50.813,81.527,95.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.583 | Acc: 50.762,81.449,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.586 | Acc: 50.693,81.412,95.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.136 | Acc: 52.344,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.614 | Acc: 46.726,65.104,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 45.846,63.796,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 45.530,64.062,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.472 | Acc: 50.781,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.559 | Acc: 50.260,81.882,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.595 | Acc: 49.676,81.307,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.591 | Acc: 49.834,81.301,95.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.586 | Acc: 50.260,81.337,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.579 | Acc: 50.549,81.474,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.567 | Acc: 50.762,81.831,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.573 | Acc: 50.648,81.776,95.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.580 | Acc: 50.539,81.643,95.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.585 | Acc: 50.626,81.444,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.591 | Acc: 50.552,81.339,95.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.585 | Acc: 50.569,81.437,95.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.584 | Acc: 50.749,81.376,95.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.587 | Acc: 50.626,81.448,95.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.586 | Acc: 50.737,81.481,95.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.590 | Acc: 50.657,81.439,95.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.593 | Acc: 50.574,81.377,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.592 | Acc: 50.575,81.392,95.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.588 | Acc: 50.610,81.427,95.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.587 | Acc: 50.621,81.394,95.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.239 | Acc: 51.562,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.624 | Acc: 46.429,64.397,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.623 | Acc: 45.732,63.720,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.647 | Acc: 45.389,63.998,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.475 | Acc: 56.250,83.594,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.464 | Acc: 52.307,83.073,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.542 | Acc: 51.562,81.650,95.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.542 | Acc: 51.678,81.583,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.548 | Acc: 51.321,81.617,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.539 | Acc: 51.361,81.962,95.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.546 | Acc: 51.272,81.650,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.544 | Acc: 51.208,81.727,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.551 | Acc: 51.218,81.653,95.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.554 | Acc: 51.217,81.578,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.557 | Acc: 51.213,81.440,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.563 | Acc: 50.962,81.423,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.550 | Acc: 51.112,81.474,95.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.560 | Acc: 50.985,81.322,95.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.564 | Acc: 50.934,81.286,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.570 | Acc: 50.872,81.227,95.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.574 | Acc: 50.786,81.206,95.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.574 | Acc: 50.806,81.273,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.577 | Acc: 50.803,81.235,95.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.580 | Acc: 50.742,81.240,95.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.212 | Acc: 52.344,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.616 | Acc: 46.168,64.695,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.623 | Acc: 45.351,63.700,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 45.095,63.998,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.879 | Acc: 57.031,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.589 | Acc: 50.223,82.775,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.553 | Acc: 50.514,82.527,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.576 | Acc: 50.499,82.082,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.564 | Acc: 50.704,82.166,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.565 | Acc: 50.735,82.024,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.571 | Acc: 50.620,81.999,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.578 | Acc: 50.715,81.749,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.583 | Acc: 50.573,81.595,95.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.585 | Acc: 50.501,81.535,95.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.577 | Acc: 50.676,81.615,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.580 | Acc: 50.647,81.632,95.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.581 | Acc: 50.710,81.603,95.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.586 | Acc: 50.691,81.510,95.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.587 | Acc: 50.634,81.556,95.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.584 | Acc: 50.714,81.574,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.587 | Acc: 50.740,81.501,95.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.587 | Acc: 50.662,81.541,95.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.586 | Acc: 50.744,81.544,95.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.584 | Acc: 50.775,81.535,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.252 | Acc: 50.781,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.647 | Acc: 45.982,64.769,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.650 | Acc: 45.675,63.872,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.678 | Acc: 45.108,63.960,69.390,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.612 | Acc: 51.562,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.583 | Acc: 51.674,81.399,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.565 | Acc: 50.572,82.165,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.588 | Acc: 50.038,81.865,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.571 | Acc: 50.395,81.867,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.575 | Acc: 50.402,81.962,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.580 | Acc: 50.549,81.650,95.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.579 | Acc: 50.665,81.544,95.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.573 | Acc: 50.684,81.585,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.573 | Acc: 50.751,81.699,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.566 | Acc: 50.742,81.798,95.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.567 | Acc: 50.799,81.766,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.567 | Acc: 50.726,81.811,95.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.567 | Acc: 50.694,81.762,95.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.574 | Acc: 50.601,81.756,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.576 | Acc: 50.566,81.681,95.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.576 | Acc: 50.613,81.744,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.574 | Acc: 50.596,81.715,95.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.574 | Acc: 50.599,81.685,95.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.578 | Acc: 50.484,81.658,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.170 | Acc: 51.562,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.601 | Acc: 46.429,65.290,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 45.789,64.310,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.640 | Acc: 45.377,64.600,69.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.725 | Acc: 41.406,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.562 | Acc: 49.963,81.548,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.592 | Acc: 50.076,81.612,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.574 | Acc: 50.384,81.583,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.584 | Acc: 50.376,81.626,95.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.582 | Acc: 50.650,81.652,95.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.581 | Acc: 50.381,81.721,95.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.597 | Acc: 50.238,81.516,95.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.589 | Acc: 50.345,81.653,95.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.588 | Acc: 50.371,81.617,95.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.580 | Acc: 50.575,81.775,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.578 | Acc: 50.597,81.727,95.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.578 | Acc: 50.668,81.642,95.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.575 | Acc: 50.859,81.576,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.570 | Acc: 50.923,81.586,95.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.570 | Acc: 50.906,81.632,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.574 | Acc: 50.827,81.591,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.573 | Acc: 50.843,81.578,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.572 | Acc: 50.896,81.607,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.573 | Acc: 50.874,81.607,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.206 | Acc: 50.781,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.620 | Acc: 46.540,64.955,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.626 | Acc: 46.056,63.948,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.654 | Acc: 45.505,64.088,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.352 | Acc: 56.250,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.549 | Acc: 51.525,81.585,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.582 | Acc: 50.953,81.345,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.591 | Acc: 50.704,81.557,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.578 | Acc: 50.781,81.645,95.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.581 | Acc: 50.874,81.598,95.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.571 | Acc: 51.117,81.553,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.578 | Acc: 51.075,81.571,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.574 | Acc: 50.966,81.706,95.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.577 | Acc: 50.863,81.712,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.580 | Acc: 50.805,81.701,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.576 | Acc: 50.767,81.639,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.585 | Acc: 50.632,81.461,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.585 | Acc: 50.682,81.406,95.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.584 | Acc: 50.737,81.353,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.578 | Acc: 50.841,81.455,95.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.574 | Acc: 50.910,81.498,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.568 | Acc: 50.907,81.601,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.572 | Acc: 50.857,81.596,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.571 | Acc: 50.826,81.662,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.256 | Acc: 52.344,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.617 | Acc: 46.280,64.881,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 45.770,64.024,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 45.492,64.114,69.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.513 | Acc: 53.125,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.582 | Acc: 51.004,81.436,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.552 | Acc: 50.400,81.726,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.528 | Acc: 50.986,82.095,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 50.743,82.031,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.545 | Acc: 50.990,81.892,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.557 | Acc: 50.878,81.915,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.563 | Acc: 50.593,81.871,95.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.565 | Acc: 50.577,81.944,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.563 | Acc: 50.596,81.863,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.564 | Acc: 50.583,81.814,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.562 | Acc: 50.647,81.837,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.565 | Acc: 50.567,81.785,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.565 | Acc: 50.578,81.774,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.568 | Acc: 50.528,81.725,95.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.570 | Acc: 50.506,81.678,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.573 | Acc: 50.455,81.615,95.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.569 | Acc: 50.511,81.669,95.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.566 | Acc: 50.522,81.715,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.566 | Acc: 50.545,81.720,95.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.222 | Acc: 51.562,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.613 | Acc: 46.280,65.179,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.627 | Acc: 45.713,63.986,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.656 | Acc: 45.312,63.986,69.429,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.366 | Acc: 53.906,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.534 | Acc: 50.818,82.961,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.540 | Acc: 51.239,81.841,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.553 | Acc: 51.050,81.596,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.571 | Acc: 50.714,81.617,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.565 | Acc: 50.982,81.637,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.566 | Acc: 50.755,81.637,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.559 | Acc: 50.770,81.882,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.557 | Acc: 50.655,81.988,95.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.561 | Acc: 50.531,81.880,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.564 | Acc: 50.602,81.810,95.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.568 | Acc: 50.583,81.731,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.569 | Acc: 50.493,81.697,95.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.566 | Acc: 50.527,81.747,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.565 | Acc: 50.595,81.689,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.572 | Acc: 50.491,81.569,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.565 | Acc: 50.589,81.644,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.567 | Acc: 50.570,81.683,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.563 | Acc: 50.690,81.713,95.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.562 | Acc: 50.709,81.781,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.260 | Acc: 52.344,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.633 | Acc: 46.429,65.216,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.645 | Acc: 45.675,63.929,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.670 | Acc: 45.364,64.075,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.517 | Acc: 55.469,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.555 | Acc: 52.269,81.362,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.580 | Acc: 51.239,82.127,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.565 | Acc: 50.871,82.185,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.569 | Acc: 50.984,81.983,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.571 | Acc: 50.774,82.008,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.569 | Acc: 50.820,81.896,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.556 | Acc: 50.898,82.120,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.556 | Acc: 50.869,82.002,95.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.565 | Acc: 50.781,81.928,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.574 | Acc: 50.781,81.880,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.570 | Acc: 50.788,81.918,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.565 | Acc: 50.888,81.928,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.563 | Acc: 50.922,81.923,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.565 | Acc: 50.998,81.826,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.568 | Acc: 50.932,81.704,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.564 | Acc: 50.937,81.746,95.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.563 | Acc: 50.882,81.747,95.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.563 | Acc: 50.868,81.728,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.567 | Acc: 50.812,81.658,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.243 | Acc: 51.562,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.624 | Acc: 46.652,64.881,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.629 | Acc: 45.808,64.062,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.654 | Acc: 45.466,64.165,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.322 | Acc: 54.688,85.156,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.515 | Acc: 51.302,81.696,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.548 | Acc: 51.143,81.441,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.536 | Acc: 51.165,81.762,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.549 | Acc: 50.858,81.916,95.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.545 | Acc: 50.851,81.900,95.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.546 | Acc: 50.936,82.012,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.549 | Acc: 50.875,81.887,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.556 | Acc: 50.674,81.818,95.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.558 | Acc: 50.600,81.772,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.567 | Acc: 50.567,81.650,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.569 | Acc: 50.672,81.565,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.572 | Acc: 50.613,81.555,95.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.575 | Acc: 50.605,81.591,95.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.573 | Acc: 50.606,81.648,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.567 | Acc: 50.701,81.741,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.569 | Acc: 50.660,81.700,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.565 | Acc: 50.641,81.720,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.565 | Acc: 50.621,81.724,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.564 | Acc: 50.625,81.767,95.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.220 | Acc: 52.344,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.620 | Acc: 46.280,64.918,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.626 | Acc: 45.751,64.024,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.651 | Acc: 45.402,64.101,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 2.456 | Acc: 50.781,84.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.608 | Acc: 48.735,81.548,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.587 | Acc: 49.752,81.479,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.574 | Acc: 50.256,81.801,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.568 | Acc: 50.424,81.838,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.582 | Acc: 50.503,81.822,95.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.565 | Acc: 50.407,82.044,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.558 | Acc: 50.576,81.959,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.559 | Acc: 50.655,81.779,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.557 | Acc: 50.617,81.742,95.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.555 | Acc: 50.738,81.724,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.556 | Acc: 50.877,81.702,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.560 | Acc: 50.697,81.678,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.561 | Acc: 50.656,81.672,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.561 | Acc: 50.634,81.689,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.562 | Acc: 50.618,81.678,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.558 | Acc: 50.633,81.744,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.558 | Acc: 50.719,81.786,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.561 | Acc: 50.734,81.791,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.564 | Acc: 50.666,81.732,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.244 | Acc: 51.562,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.639 | Acc: 46.057,64.472,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.643 | Acc: 45.598,63.796,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.671 | Acc: 45.146,63.896,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.568 | Acc: 50.000,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.514 | Acc: 51.897,81.287,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.515 | Acc: 51.220,81.555,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.535 | Acc: 51.114,81.749,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.546 | Acc: 51.138,81.559,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.552 | Acc: 51.006,81.513,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.560 | Acc: 51.007,81.444,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.572 | Acc: 51.003,81.461,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.570 | Acc: 51.072,81.536,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.575 | Acc: 51.075,81.509,95.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.570 | Acc: 51.088,81.549,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.565 | Acc: 51.131,81.664,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.562 | Acc: 51.089,81.675,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.559 | Acc: 51.143,81.750,95.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.554 | Acc: 51.076,81.864,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.560 | Acc: 51.038,81.800,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.563 | Acc: 50.961,81.798,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.561 | Acc: 50.974,81.814,95.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.562 | Acc: 50.935,81.811,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.561 | Acc: 50.972,81.804,95.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.337 | Acc: 50.000,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.643 | Acc: 46.168,64.472,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.658 | Acc: 45.732,63.548,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 45.300,63.717,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.539 | Acc: 49.219,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.591 | Acc: 50.000,81.473,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.575 | Acc: 50.743,81.364,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.562 | Acc: 50.499,81.852,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.556 | Acc: 50.502,82.070,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.567 | Acc: 50.619,81.668,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.565 | Acc: 50.626,81.728,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.553 | Acc: 50.704,81.826,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.552 | Acc: 50.621,81.827,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.549 | Acc: 50.557,81.824,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.543 | Acc: 50.672,81.911,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.550 | Acc: 50.672,81.886,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.551 | Acc: 50.749,81.869,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.551 | Acc: 50.724,81.849,95.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.551 | Acc: 50.720,81.826,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.553 | Acc: 50.651,81.813,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.552 | Acc: 50.601,81.805,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.550 | Acc: 50.717,81.848,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.550 | Acc: 50.721,81.878,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.554 | Acc: 50.656,81.822,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.248 | Acc: 53.125,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.656 | Acc: 46.019,65.067,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.663 | Acc: 45.446,63.910,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.684 | Acc: 45.044,64.037,69.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.834 | Acc: 50.781,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.598 | Acc: 50.484,81.138,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.567 | Acc: 51.105,81.764,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.548 | Acc: 51.575,82.006,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.558 | Acc: 51.264,82.051,95.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.548 | Acc: 51.137,82.093,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.550 | Acc: 50.988,82.031,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.543 | Acc: 50.953,82.175,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.545 | Acc: 50.869,82.012,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.550 | Acc: 50.695,81.884,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.549 | Acc: 50.669,81.922,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.553 | Acc: 50.668,81.883,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.558 | Acc: 50.609,81.801,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.557 | Acc: 50.697,81.765,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.559 | Acc: 50.589,81.753,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.563 | Acc: 50.574,81.772,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.559 | Acc: 50.606,81.827,95.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.560 | Acc: 50.644,81.800,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.564 | Acc: 50.625,81.774,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.563 | Acc: 50.664,81.779,95.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.272 | Acc: 50.781,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.652 | Acc: 46.949,64.509,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.664 | Acc: 46.056,63.700,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 45.594,63.922,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.561 | Acc: 51.562,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.560 | Acc: 49.628,82.254,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.544 | Acc: 50.934,82.279,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.576 | Acc: 50.602,81.634,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.558 | Acc: 50.791,82.070,95.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.560 | Acc: 50.750,81.993,95.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.555 | Acc: 50.878,82.044,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.545 | Acc: 51.197,82.026,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.549 | Acc: 51.116,82.094,95.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.551 | Acc: 51.165,82.057,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.546 | Acc: 51.189,82.093,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.553 | Acc: 51.004,82.056,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.556 | Acc: 50.879,82.073,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.555 | Acc: 50.805,82.058,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.555 | Acc: 50.859,81.981,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.555 | Acc: 50.867,81.951,95.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.553 | Acc: 50.918,81.990,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.555 | Acc: 50.880,81.967,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.555 | Acc: 50.887,81.912,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.555 | Acc: 50.871,81.859,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.283 | Acc: 51.562,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.655 | Acc: 46.540,64.695,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.658 | Acc: 45.808,63.758,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.683 | Acc: 45.300,63.883,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 2.291 | Acc: 54.688,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.536 | Acc: 51.079,81.696,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.507 | Acc: 51.372,82.431,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.507 | Acc: 51.255,82.569,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.524 | Acc: 51.138,82.176,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.520 | Acc: 51.106,82.256,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.525 | Acc: 51.014,82.135,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.527 | Acc: 50.870,82.131,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.533 | Acc: 50.747,82.007,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.539 | Acc: 50.665,82.001,95.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.547 | Acc: 50.606,81.884,95.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.549 | Acc: 50.491,81.872,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.544 | Acc: 50.574,81.976,95.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.547 | Acc: 50.584,81.926,95.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.546 | Acc: 50.606,81.903,95.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.544 | Acc: 50.535,81.940,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.547 | Acc: 50.450,81.888,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.547 | Acc: 50.493,81.914,95.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.552 | Acc: 50.506,81.804,95.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.551 | Acc: 50.589,81.748,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.207 | Acc: 49.219,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.625 | Acc: 46.205,64.993,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.637 | Acc: 45.522,64.139,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 45.197,64.242,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.897 | Acc: 43.750,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.562 | Acc: 50.595,80.580,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.544 | Acc: 50.991,81.155,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 51.255,81.942,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.561 | Acc: 50.453,81.491,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.561 | Acc: 50.472,81.629,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.571 | Acc: 50.413,81.566,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.563 | Acc: 50.449,81.666,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.560 | Acc: 50.442,81.696,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.551 | Acc: 50.384,81.695,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.552 | Acc: 50.641,81.724,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.559 | Acc: 50.640,81.621,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.559 | Acc: 50.493,81.730,95.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.553 | Acc: 50.599,81.741,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.558 | Acc: 50.550,81.750,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.554 | Acc: 50.680,81.735,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.551 | Acc: 50.801,81.805,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 50.832,81.869,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.546 | Acc: 50.857,81.932,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.547 | Acc: 50.794,81.929,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.259 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.666 | Acc: 46.131,64.509,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.673 | Acc: 45.465,63.681,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.695 | Acc: 45.184,63.973,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 2.037 | Acc: 52.344,87.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.581 | Acc: 51.451,81.510,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.566 | Acc: 51.486,81.345,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.570 | Acc: 51.665,81.673,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.578 | Acc: 51.138,81.395,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.574 | Acc: 50.936,81.567,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.565 | Acc: 50.936,81.547,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.558 | Acc: 51.097,81.760,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.551 | Acc: 51.087,81.803,95.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.561 | Acc: 50.945,81.647,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.561 | Acc: 51.042,81.759,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.558 | Acc: 51.004,81.748,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.562 | Acc: 50.924,81.736,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.560 | Acc: 50.973,81.810,95.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.561 | Acc: 50.990,81.784,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.560 | Acc: 50.971,81.896,95.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.556 | Acc: 51.022,81.931,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.557 | Acc: 51.026,81.871,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.557 | Acc: 50.978,81.834,95.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.556 | Acc: 51.005,81.886,95.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.207 | Acc: 54.688,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.649 | Acc: 46.429,64.695,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.656 | Acc: 45.751,63.681,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 45.287,63.986,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.708 | Acc: 43.750,74.219,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.553 | Acc: 49.777,81.994,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.524 | Acc: 50.686,82.393,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.545 | Acc: 50.602,82.275,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.530 | Acc: 50.598,82.571,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.527 | Acc: 50.735,82.550,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.537 | Acc: 50.633,82.277,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.526 | Acc: 50.953,82.292,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.536 | Acc: 50.767,82.177,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.538 | Acc: 50.747,82.105,96.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 50.704,82.179,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.537 | Acc: 50.799,82.148,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.533 | Acc: 50.879,82.174,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.533 | Acc: 50.898,82.157,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.535 | Acc: 50.831,82.198,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.536 | Acc: 50.903,82.094,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.539 | Acc: 50.798,82.017,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.541 | Acc: 50.761,81.981,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.542 | Acc: 50.751,81.975,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.545 | Acc: 50.761,81.998,95.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.266 | Acc: 51.562,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.661 | Acc: 46.131,64.435,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.667 | Acc: 45.598,63.510,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.692 | Acc: 45.146,63.781,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.357 | Acc: 52.344,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.542 | Acc: 50.260,81.696,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.593 | Acc: 50.381,81.079,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.566 | Acc: 50.602,81.673,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.565 | Acc: 50.694,81.674,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.566 | Acc: 50.727,81.675,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.576 | Acc: 50.633,81.541,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.572 | Acc: 50.654,81.577,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.574 | Acc: 50.674,81.454,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.570 | Acc: 50.617,81.574,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.571 | Acc: 50.738,81.557,95.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.565 | Acc: 50.898,81.593,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.562 | Acc: 50.898,81.626,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.563 | Acc: 50.781,81.606,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.563 | Acc: 50.767,81.561,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.560 | Acc: 50.776,81.608,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.561 | Acc: 50.757,81.649,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.559 | Acc: 50.742,81.711,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.559 | Acc: 50.716,81.704,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.557 | Acc: 50.654,81.699,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.242 | Acc: 51.562,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.648 | Acc: 46.391,64.993,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.655 | Acc: 45.675,64.005,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.674 | Acc: 45.325,64.037,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.424 | Acc: 52.344,85.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.469 | Acc: 52.195,82.068,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.511 | Acc: 51.296,81.688,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 51.370,81.442,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.535 | Acc: 50.897,81.453,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.542 | Acc: 50.774,81.474,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.543 | Acc: 50.814,81.386,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.551 | Acc: 50.676,81.344,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.547 | Acc: 50.573,81.468,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.543 | Acc: 50.712,81.548,96.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.551 | Acc: 50.618,81.456,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.548 | Acc: 50.732,81.519,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.547 | Acc: 50.746,81.665,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.550 | Acc: 50.733,81.672,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.553 | Acc: 50.609,81.584,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.552 | Acc: 50.745,81.683,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.548 | Acc: 50.823,81.805,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.553 | Acc: 50.765,81.715,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.549 | Acc: 50.838,81.776,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.550 | Acc: 50.802,81.750,95.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.234 | Acc: 51.562,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.668 | Acc: 46.243,64.583,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.668 | Acc: 45.694,63.681,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.692 | Acc: 45.325,63.794,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.494 | Acc: 52.344,86.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.552 | Acc: 50.521,82.217,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.541 | Acc: 50.591,82.336,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.547 | Acc: 50.781,81.929,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.551 | Acc: 50.656,81.732,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.539 | Acc: 50.982,81.907,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.553 | Acc: 50.814,81.850,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.551 | Acc: 50.765,81.948,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.544 | Acc: 50.864,81.789,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.535 | Acc: 50.971,81.854,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.537 | Acc: 50.956,81.895,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.537 | Acc: 50.923,82.021,96.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.540 | Acc: 50.833,81.963,96.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.538 | Acc: 50.835,81.992,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.542 | Acc: 50.720,82.001,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.546 | Acc: 50.696,81.946,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.544 | Acc: 50.825,81.995,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 50.724,82.018,96.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.549 | Acc: 50.688,81.977,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.550 | Acc: 50.679,81.998,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.269 | Acc: 51.562,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.674 | Acc: 46.354,64.807,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.674 | Acc: 45.922,63.815,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.700 | Acc: 45.364,63.922,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.455 | Acc: 50.781,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.551 | Acc: 51.228,81.399,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.545 | Acc: 51.677,81.155,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.540 | Acc: 51.396,81.301,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 51.080,81.530,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.559 | Acc: 50.774,81.235,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.557 | Acc: 50.994,81.334,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.563 | Acc: 50.676,81.250,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.551 | Acc: 50.757,81.337,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.560 | Acc: 50.552,81.254,96.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.556 | Acc: 50.548,81.328,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.550 | Acc: 50.693,81.519,96.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.547 | Acc: 50.703,81.584,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.548 | Acc: 50.754,81.549,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.546 | Acc: 50.778,81.561,96.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.547 | Acc: 50.683,81.567,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.544 | Acc: 50.767,81.661,96.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.542 | Acc: 50.825,81.701,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.546 | Acc: 50.779,81.674,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.550 | Acc: 50.792,81.625,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.226 | Acc: 48.438,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.666 | Acc: 46.131,64.918,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.664 | Acc: 45.389,64.158,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 45.223,64.165,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.497 | Acc: 51.562,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.521 | Acc: 51.600,82.068,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.504 | Acc: 52.325,82.069,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.499 | Acc: 52.011,82.147,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 51.833,82.282,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.496 | Acc: 51.764,82.225,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.517 | Acc: 51.349,81.928,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 51.424,82.070,96.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.508 | Acc: 51.368,82.099,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 51.204,82.131,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 51.189,82.218,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.518 | Acc: 51.046,82.162,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 51.054,82.151,96.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.524 | Acc: 50.976,82.088,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 50.920,82.073,96.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.532 | Acc: 50.851,82.005,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.535 | Acc: 50.883,82.009,96.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.537 | Acc: 50.903,82.013,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.538 | Acc: 50.822,81.990,96.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.541 | Acc: 50.789,81.972,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.236 | Acc: 50.000,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.664 | Acc: 46.466,64.695,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.661 | Acc: 45.846,63.739,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.682 | Acc: 45.517,63.870,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.896 | Acc: 40.625,72.656,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.539 | Acc: 50.632,81.994,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.515 | Acc: 50.591,82.546,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 51.012,82.633,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.520 | Acc: 50.897,82.427,95.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 50.611,82.310,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.520 | Acc: 50.904,82.470,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.528 | Acc: 50.848,82.419,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.524 | Acc: 50.995,82.390,96.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.522 | Acc: 50.889,82.398,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 50.976,82.307,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 50.852,82.236,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.535 | Acc: 50.843,82.232,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.531 | Acc: 50.904,82.295,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.537 | Acc: 50.840,82.170,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.537 | Acc: 50.776,82.135,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.536 | Acc: 50.730,82.155,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 50.701,82.125,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.532 | Acc: 50.760,82.148,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.536 | Acc: 50.730,82.095,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.281 | Acc: 51.562,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.656 | Acc: 46.652,65.253,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.652 | Acc: 45.903,64.005,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.674 | Acc: 45.492,64.191,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.397 | Acc: 54.688,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.674 | Acc: 47.768,79.985,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.606 | Acc: 49.981,80.831,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.601 | Acc: 50.000,80.981,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.593 | Acc: 50.309,81.057,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.574 | Acc: 50.681,81.173,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.570 | Acc: 50.710,81.276,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.573 | Acc: 50.621,81.339,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.567 | Acc: 50.582,81.473,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.555 | Acc: 50.829,81.716,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.554 | Acc: 50.766,81.685,96.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.549 | Acc: 50.799,81.720,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.546 | Acc: 50.888,81.665,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.549 | Acc: 50.850,81.696,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.540 | Acc: 50.987,81.831,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.540 | Acc: 51.023,81.777,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.539 | Acc: 50.991,81.756,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 50.850,81.662,95.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.546 | Acc: 50.857,81.722,95.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.543 | Acc: 50.923,81.738,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.248 | Acc: 52.344,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.664 | Acc: 46.987,64.769,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.667 | Acc: 46.208,63.548,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.687 | Acc: 45.607,63.858,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.679 | Acc: 50.781,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.511 | Acc: 50.744,82.775,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.567 | Acc: 50.438,82.374,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.550 | Acc: 50.615,82.082,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.539 | Acc: 50.627,82.137,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.532 | Acc: 50.596,82.209,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.528 | Acc: 50.781,82.244,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.529 | Acc: 50.953,82.203,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.537 | Acc: 50.946,82.060,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.537 | Acc: 50.902,82.040,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 50.910,81.934,96.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.543 | Acc: 50.965,81.936,96.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.544 | Acc: 50.947,81.950,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.541 | Acc: 51.021,81.929,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.544 | Acc: 50.965,81.873,95.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.548 | Acc: 50.916,81.826,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.547 | Acc: 50.881,81.858,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.547 | Acc: 50.891,81.871,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.554 | Acc: 50.799,81.841,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.551 | Acc: 50.882,81.826,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.280 | Acc: 53.125,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.686 | Acc: 46.391,64.621,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.685 | Acc: 45.903,63.586,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.706 | Acc: 45.364,63.819,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.664 | Acc: 46.875,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.564 | Acc: 50.558,81.027,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.591 | Acc: 49.867,81.002,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.524 | Acc: 50.858,81.711,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 50.733,82.099,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.525 | Acc: 50.727,81.768,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.535 | Acc: 50.646,81.553,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.529 | Acc: 50.582,81.643,96.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.518 | Acc: 50.772,81.871,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.526 | Acc: 50.773,81.742,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.526 | Acc: 50.789,81.845,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 50.725,81.854,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.535 | Acc: 50.661,81.772,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.540 | Acc: 50.575,81.786,96.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.540 | Acc: 50.470,81.784,96.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.543 | Acc: 50.462,81.795,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.540 | Acc: 50.582,81.924,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.541 | Acc: 50.527,81.940,96.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.541 | Acc: 50.621,81.977,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.544 | Acc: 50.599,81.898,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.247 | Acc: 50.000,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.671 | Acc: 46.391,64.658,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.663 | Acc: 45.865,63.929,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.687 | Acc: 45.389,63.973,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.300 | Acc: 57.031,87.500,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.485 | Acc: 52.493,82.850,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.503 | Acc: 52.306,82.336,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 52.190,82.710,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 51.997,82.851,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.519 | Acc: 51.555,82.379,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.524 | Acc: 51.207,82.354,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.538 | Acc: 50.981,82.303,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.538 | Acc: 51.116,82.153,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.539 | Acc: 51.014,81.915,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.540 | Acc: 50.983,81.868,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.542 | Acc: 50.802,81.819,96.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.540 | Acc: 50.930,81.882,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.544 | Acc: 50.793,81.828,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.542 | Acc: 50.806,81.884,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.539 | Acc: 50.854,81.995,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.538 | Acc: 50.808,81.919,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.540 | Acc: 50.907,81.963,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.542 | Acc: 50.900,81.882,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.543 | Acc: 50.851,81.884,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.227 | Acc: 53.125,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.680 | Acc: 46.466,64.621,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.677 | Acc: 45.789,63.834,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.698 | Acc: 45.389,63.998,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.461 | Acc: 53.906,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.505 | Acc: 50.818,83.073,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.525 | Acc: 50.877,82.812,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.532 | Acc: 51.294,82.262,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.561 | Acc: 50.878,81.964,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.557 | Acc: 50.804,82.016,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.545 | Acc: 50.917,82.122,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.548 | Acc: 50.792,82.153,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.544 | Acc: 50.835,82.172,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.543 | Acc: 50.786,82.217,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.546 | Acc: 50.793,82.167,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.540 | Acc: 50.877,82.212,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.533 | Acc: 50.953,82.252,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.529 | Acc: 51.021,82.298,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.529 | Acc: 51.020,82.231,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 50.932,82.293,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.534 | Acc: 50.827,82.233,95.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 50.800,82.267,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.536 | Acc: 50.870,82.174,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.538 | Acc: 50.865,82.160,95.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.272 | Acc: 53.125,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.679 | Acc: 45.945,64.881,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.672 | Acc: 45.598,63.967,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 45.095,64.024,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.548 | Acc: 47.656,75.000,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.493 | Acc: 51.190,81.473,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.525 | Acc: 51.143,81.726,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.539 | Acc: 51.178,81.814,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.528 | Acc: 50.936,82.022,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.540 | Acc: 50.441,81.915,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.538 | Acc: 50.652,81.973,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.543 | Acc: 50.892,81.882,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.550 | Acc: 50.839,81.808,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.539 | Acc: 50.984,82.092,96.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.534 | Acc: 50.999,82.039,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 50.979,82.060,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.534 | Acc: 50.898,82.005,96.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.532 | Acc: 50.895,82.085,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.530 | Acc: 50.990,82.092,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 51.049,82.062,96.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 51.105,82.141,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.522 | Acc: 51.207,82.164,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 51.210,82.187,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.521 | Acc: 51.181,82.195,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.273 | Acc: 51.562,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.689 | Acc: 46.615,64.658,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.679 | Acc: 46.037,63.891,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.700 | Acc: 45.441,64.088,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.598 | Acc: 44.531,86.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.565 | Acc: 50.037,81.696,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.540 | Acc: 50.667,82.374,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.523 | Acc: 50.922,82.531,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.519 | Acc: 50.858,82.832,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.528 | Acc: 50.611,82.696,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.516 | Acc: 50.788,82.838,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.507 | Acc: 50.925,82.890,96.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.509 | Acc: 50.835,82.822,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 50.712,82.687,96.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.517 | Acc: 50.700,82.599,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 50.802,82.607,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 50.817,82.547,96.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 50.862,82.477,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 50.762,82.443,96.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.521 | Acc: 50.748,82.483,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 50.762,82.508,96.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.527 | Acc: 50.630,82.473,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.524 | Acc: 50.777,82.464,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.524 | Acc: 50.785,82.456,96.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.293 | Acc: 52.344,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.688 | Acc: 46.354,64.621,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.685 | Acc: 45.732,63.815,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.706 | Acc: 45.338,64.024,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.625 | Acc: 44.531,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.509 | Acc: 50.335,83.147,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.533 | Acc: 50.038,81.917,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.504 | Acc: 50.807,82.249,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.524 | Acc: 50.598,81.877,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.525 | Acc: 50.758,81.753,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 50.826,81.767,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.526 | Acc: 50.770,81.754,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.517 | Acc: 50.975,81.696,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.524 | Acc: 51.006,81.682,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 51.084,81.864,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.522 | Acc: 51.135,81.908,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.521 | Acc: 51.037,81.992,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.514 | Acc: 51.200,82.091,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.514 | Acc: 51.243,82.120,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 51.075,82.073,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 51.039,82.060,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 50.997,82.029,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.529 | Acc: 50.928,81.962,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 51.017,82.033,96.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.261 | Acc: 51.562,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.667 | Acc: 46.243,64.732,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.663 | Acc: 45.808,63.796,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.684 | Acc: 45.338,64.062,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.511 | Acc: 53.125,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.576 | Acc: 49.182,81.064,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.514 | Acc: 50.972,81.860,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.517 | Acc: 50.359,82.108,96.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.527 | Acc: 50.878,82.089,96.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 50.774,82.109,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.530 | Acc: 50.826,82.154,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.533 | Acc: 50.903,82.081,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.534 | Acc: 51.038,82.051,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.538 | Acc: 50.919,81.979,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.533 | Acc: 50.875,82.121,96.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.536 | Acc: 50.873,82.113,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.533 | Acc: 50.947,82.109,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.531 | Acc: 51.060,82.184,96.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.531 | Acc: 51.015,82.237,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.530 | Acc: 50.989,82.221,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.527 | Acc: 51.095,82.204,96.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.531 | Acc: 51.132,82.123,96.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.533 | Acc: 51.078,82.113,96.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.529 | Acc: 51.089,82.132,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.273 | Acc: 53.125,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.681 | Acc: 46.168,64.732,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.678 | Acc: 45.713,64.139,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.696 | Acc: 45.274,64.216,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 3.299 | Acc: 46.875,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.563 | Acc: 49.926,82.664,96.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.536 | Acc: 50.743,82.260,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.515 | Acc: 50.704,82.364,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 50.820,82.446,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.524 | Acc: 51.013,82.317,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.529 | Acc: 50.872,82.193,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.531 | Acc: 50.975,82.209,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.530 | Acc: 51.160,82.206,96.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.521 | Acc: 51.334,82.286,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 51.185,82.319,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 51.269,82.318,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 51.206,82.291,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.514 | Acc: 51.108,82.292,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.515 | Acc: 51.084,82.284,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 50.958,82.239,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 50.944,82.194,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 51.020,82.189,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.525 | Acc: 51.017,82.152,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.521 | Acc: 51.095,82.197,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.250 | Acc: 50.781,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.665 | Acc: 46.094,65.216,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.660 | Acc: 45.560,64.253,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.677 | Acc: 45.261,64.344,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.617 | Acc: 52.344,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.563 | Acc: 51.116,81.250,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.545 | Acc: 50.324,81.955,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.508 | Acc: 51.037,82.415,96.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.502 | Acc: 51.292,82.494,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.498 | Acc: 51.292,82.542,96.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.498 | Acc: 51.362,82.599,96.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.506 | Acc: 51.208,82.441,96.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.504 | Acc: 51.233,82.516,96.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 51.170,82.312,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 51.154,82.342,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 51.138,82.441,96.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.521 | Acc: 51.063,82.359,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.524 | Acc: 51.114,82.375,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 51.151,82.465,96.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.518 | Acc: 51.217,82.389,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.522 | Acc: 51.124,82.328,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.522 | Acc: 51.091,82.368,96.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.525 | Acc: 51.045,82.365,96.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.525 | Acc: 51.066,82.275,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.289 | Acc: 51.562,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.669 | Acc: 46.354,64.955,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.662 | Acc: 45.789,64.196,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 45.389,64.242,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.321 | Acc: 53.906,85.938,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.500 | Acc: 52.083,82.738,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.502 | Acc: 51.543,82.374,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 51.947,82.556,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 51.649,82.301,96.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 51.570,82.426,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.516 | Acc: 51.395,82.341,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.516 | Acc: 51.302,82.303,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.521 | Acc: 51.203,82.259,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.526 | Acc: 51.209,82.135,96.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.518 | Acc: 51.302,82.315,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.518 | Acc: 51.230,82.289,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 51.138,82.336,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 51.131,82.355,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 51.029,82.287,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.521 | Acc: 50.986,82.314,96.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 50.976,82.275,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.517 | Acc: 51.045,82.338,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.518 | Acc: 51.050,82.365,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.518 | Acc: 51.060,82.370,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.306 | Acc: 51.562,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.670 | Acc: 46.057,64.360,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.667 | Acc: 45.713,63.891,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.692 | Acc: 45.325,64.101,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.450 | Acc: 48.438,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.444 | Acc: 51.674,82.664,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 51.429,82.584,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.517 | Acc: 51.460,81.903,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.521 | Acc: 51.572,82.079,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.521 | Acc: 51.702,82.078,96.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.531 | Acc: 51.446,82.102,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.528 | Acc: 51.579,82.231,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.531 | Acc: 51.359,82.196,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.533 | Acc: 51.334,82.169,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 51.306,82.210,96.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.521 | Acc: 51.396,82.243,96.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.524 | Acc: 51.326,82.180,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.518 | Acc: 51.359,82.286,96.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 51.368,82.281,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 51.306,82.218,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.519 | Acc: 51.275,82.206,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.517 | Acc: 51.269,82.215,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.518 | Acc: 51.173,82.237,96.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.519 | Acc: 51.118,82.212,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.297 | Acc: 50.781,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.669 | Acc: 46.689,64.546,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.666 | Acc: 45.979,63.720,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.689 | Acc: 45.530,64.050,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.280 | Acc: 58.594,87.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.537 | Acc: 51.190,81.882,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.524 | Acc: 51.086,82.317,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.541 | Acc: 51.037,82.480,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.549 | Acc: 50.849,82.542,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.554 | Acc: 50.634,82.256,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.552 | Acc: 50.510,82.296,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.538 | Acc: 50.820,82.286,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.542 | Acc: 50.796,82.235,96.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.548 | Acc: 50.548,82.126,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.545 | Acc: 50.521,82.148,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.544 | Acc: 50.559,82.130,96.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.541 | Acc: 50.600,82.109,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.539 | Acc: 50.641,82.133,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.535 | Acc: 50.664,82.226,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.533 | Acc: 50.750,82.317,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.530 | Acc: 50.810,82.328,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.525 | Acc: 50.841,82.357,96.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.520 | Acc: 50.952,82.395,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 51.005,82.343,96.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.279 | Acc: 49.219,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.667 | Acc: 46.652,64.732,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.665 | Acc: 46.075,63.700,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.686 | Acc: 45.594,63.973,68.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.117 | Acc: 51.562,88.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.587 | Acc: 49.405,81.473,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.574 | Acc: 49.733,81.460,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.575 | Acc: 50.192,81.404,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.563 | Acc: 50.530,81.520,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.537 | Acc: 50.936,81.846,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.539 | Acc: 50.891,81.863,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.549 | Acc: 50.720,81.649,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.546 | Acc: 50.742,81.667,96.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.531 | Acc: 50.898,81.828,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.540 | Acc: 50.750,81.755,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.543 | Acc: 50.679,81.752,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.538 | Acc: 50.846,81.866,96.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.528 | Acc: 51.000,82.004,96.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.528 | Acc: 50.912,82.003,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.528 | Acc: 50.895,82.047,96.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.530 | Acc: 50.881,82.022,96.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.528 | Acc: 50.969,82.045,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.527 | Acc: 50.944,82.118,96.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.521 | Acc: 51.040,82.154,96.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.236 | Acc: 51.562,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.678 | Acc: 46.168,65.141,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.672 | Acc: 45.713,63.986,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.692 | Acc: 45.441,64.165,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.592 | Acc: 51.562,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.468 | Acc: 53.088,83.408,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.452 | Acc: 52.706,83.689,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.483 | Acc: 51.883,83.158,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 51.437,82.803,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 51.454,82.573,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 51.472,82.638,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.500 | Acc: 51.324,82.419,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.504 | Acc: 51.203,82.269,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.507 | Acc: 51.247,82.264,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.509 | Acc: 51.123,82.249,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.509 | Acc: 51.142,82.268,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.509 | Acc: 51.050,82.281,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.510 | Acc: 50.985,82.250,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.514 | Acc: 50.979,82.259,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.513 | Acc: 50.999,82.260,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.514 | Acc: 51.015,82.221,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.516 | Acc: 51.063,82.171,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.515 | Acc: 51.028,82.155,96.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.517 | Acc: 50.925,82.158,96.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.290 | Acc: 53.125,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.684 | Acc: 46.466,64.807,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.674 | Acc: 45.713,63.910,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.695 | Acc: 45.248,64.114,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.196 | Acc: 51.562,89.844,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.509 | Acc: 50.930,82.812,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.482 | Acc: 51.867,82.908,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 51.575,82.787,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.492 | Acc: 51.746,82.687,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.483 | Acc: 51.655,82.658,96.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 51.485,82.722,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.496 | Acc: 51.513,82.524,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 51.252,82.541,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 51.140,82.433,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 51.322,82.482,96.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.500 | Acc: 51.294,82.406,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.506 | Acc: 51.128,82.378,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.511 | Acc: 50.973,82.253,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 50.848,82.245,96.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 50.890,82.306,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 50.786,82.255,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 50.827,82.256,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 50.777,82.313,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.517 | Acc: 50.859,82.357,96.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.288 | Acc: 50.000,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.661 | Acc: 46.354,64.844,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.660 | Acc: 45.865,63.929,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 45.505,64.101,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.622 | Acc: 53.906,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.524 | Acc: 51.451,82.924,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.534 | Acc: 51.029,82.660,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.517 | Acc: 51.025,82.736,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.516 | Acc: 50.965,82.812,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.518 | Acc: 50.975,82.704,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 50.820,82.709,96.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 50.837,82.530,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.524 | Acc: 50.869,82.434,96.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.523 | Acc: 50.790,82.441,96.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.518 | Acc: 50.847,82.478,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 50.901,82.459,96.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.510 | Acc: 51.021,82.498,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.507 | Acc: 51.018,82.543,96.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.507 | Acc: 51.001,82.551,96.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 50.841,82.584,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.507 | Acc: 50.881,82.603,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.513 | Acc: 50.740,82.577,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.514 | Acc: 50.736,82.559,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.513 | Acc: 50.816,82.550,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.269 | Acc: 51.562,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.672 | Acc: 46.429,64.955,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.661 | Acc: 45.884,63.986,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.683 | Acc: 45.453,64.114,69.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.722 | Acc: 48.438,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.621 | Acc: 49.405,80.394,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.614 | Acc: 49.181,80.659,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.573 | Acc: 49.936,81.007,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.557 | Acc: 49.778,81.395,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.561 | Acc: 49.814,81.621,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.553 | Acc: 49.813,81.754,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.549 | Acc: 49.939,81.932,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.556 | Acc: 49.971,81.997,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.544 | Acc: 50.276,82.187,96.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.536 | Acc: 50.443,82.264,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.536 | Acc: 50.399,82.272,96.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.527 | Acc: 50.551,82.420,96.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 50.635,82.501,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.520 | Acc: 50.712,82.479,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.522 | Acc: 50.716,82.405,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 50.694,82.314,96.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.523 | Acc: 50.816,82.274,96.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 50.807,82.287,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.524 | Acc: 50.787,82.271,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.302 | Acc: 50.781,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.697 | Acc: 46.577,64.211,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.690 | Acc: 45.884,63.643,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.709 | Acc: 45.338,63.806,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.445 | Acc: 46.875,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.481 | Acc: 50.632,82.924,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.458 | Acc: 51.448,83.251,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.508 | Acc: 51.037,82.800,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.503 | Acc: 51.196,82.706,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.501 | Acc: 51.431,82.596,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.503 | Acc: 51.220,82.515,96.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 51.053,82.425,96.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.510 | Acc: 51.004,82.405,96.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 51.014,82.484,96.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.503 | Acc: 51.150,82.544,96.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.505 | Acc: 51.082,82.590,96.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.502 | Acc: 51.164,82.631,96.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.504 | Acc: 51.209,82.579,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.508 | Acc: 51.168,82.585,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.508 | Acc: 51.189,82.571,96.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.512 | Acc: 51.054,82.557,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.511 | Acc: 51.047,82.556,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.513 | Acc: 51.030,82.577,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.513 | Acc: 50.966,82.525,96.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.267 | Acc: 52.344,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.662 | Acc: 46.615,65.141,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.662 | Acc: 45.732,64.291,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 45.389,64.331,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.947 | Acc: 43.750,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.543 | Acc: 50.037,81.882,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.533 | Acc: 50.781,82.431,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.520 | Acc: 50.897,82.556,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.532 | Acc: 50.791,82.504,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 50.982,82.565,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.519 | Acc: 51.033,82.670,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.528 | Acc: 50.826,82.425,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.516 | Acc: 51.106,82.521,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 51.092,82.428,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 51.143,82.470,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.517 | Acc: 51.103,82.424,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.518 | Acc: 50.995,82.453,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 50.943,82.444,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 50.901,82.465,96.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.516 | Acc: 51.028,82.478,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.514 | Acc: 51.156,82.460,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.512 | Acc: 51.171,82.487,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.514 | Acc: 51.065,82.442,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.512 | Acc: 51.150,82.411,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.251 | Acc: 51.562,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.668 | Acc: 46.577,64.993,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.664 | Acc: 46.037,64.234,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.689 | Acc: 45.633,64.255,69.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.579 | Acc: 50.000,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.482 | Acc: 51.079,83.333,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.447 | Acc: 51.677,83.670,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.479 | Acc: 51.460,83.120,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.505 | Acc: 50.965,82.649,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.507 | Acc: 50.797,82.627,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 50.568,82.741,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.505 | Acc: 50.510,82.619,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.510 | Acc: 50.626,82.648,96.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.513 | Acc: 50.717,82.459,96.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.519 | Acc: 50.719,82.338,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.517 | Acc: 50.725,82.374,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.516 | Acc: 50.733,82.433,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.509 | Acc: 50.874,82.498,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.506 | Acc: 50.920,82.523,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.507 | Acc: 50.924,82.491,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.506 | Acc: 50.901,82.503,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.509 | Acc: 50.864,82.444,96.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.509 | Acc: 50.825,82.473,96.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.507 | Acc: 50.966,82.458,96.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 53.125,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.668 | Acc: 46.429,64.621,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.663 | Acc: 45.732,63.891,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.685 | Acc: 45.312,64.127,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.319 | Acc: 53.125,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.462 | Acc: 52.269,82.440,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.463 | Acc: 52.020,82.755,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.474 | Acc: 51.383,82.748,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.497 | Acc: 50.810,82.523,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.518 | Acc: 50.735,82.395,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.519 | Acc: 50.807,82.348,96.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.517 | Acc: 50.859,82.336,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.516 | Acc: 50.898,82.439,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 51.027,82.532,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.518 | Acc: 50.875,82.459,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.511 | Acc: 51.022,82.505,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 50.940,82.423,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.511 | Acc: 51.039,82.390,96.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 51.073,82.306,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 51.038,82.366,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.518 | Acc: 50.944,82.279,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.514 | Acc: 51.006,82.315,96.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.515 | Acc: 51.021,82.347,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.517 | Acc: 50.972,82.335,96.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.289 | Acc: 52.344,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.675 | Acc: 46.205,64.881,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.679 | Acc: 45.675,63.986,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.696 | Acc: 45.236,64.127,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 3.004 | Acc: 37.500,75.781,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.576 | Acc: 49.628,81.622,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.563 | Acc: 49.543,82.050,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.543 | Acc: 50.128,82.185,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.536 | Acc: 50.164,81.983,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.525 | Acc: 50.294,81.915,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.531 | Acc: 50.161,81.934,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.534 | Acc: 50.199,82.081,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.532 | Acc: 50.349,82.138,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.523 | Acc: 50.440,82.213,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.522 | Acc: 50.579,82.198,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.523 | Acc: 50.643,82.208,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.529 | Acc: 50.399,82.125,96.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.527 | Acc: 50.398,82.184,96.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 50.403,82.240,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.522 | Acc: 50.496,82.312,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.519 | Acc: 50.557,82.348,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 50.564,82.331,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.517 | Acc: 50.628,82.384,96.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.516 | Acc: 50.687,82.380,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.270 | Acc: 50.781,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.657 | Acc: 46.540,64.621,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.658 | Acc: 45.865,63.510,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.678 | Acc: 45.492,63.832,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.271 | Acc: 57.031,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.515 | Acc: 51.451,83.557,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.548 | Acc: 50.610,82.336,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.510 | Acc: 51.422,82.723,96.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 51.514,82.562,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 51.663,82.480,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.518 | Acc: 51.369,82.535,96.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.511 | Acc: 51.546,82.552,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.520 | Acc: 51.441,82.419,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.521 | Acc: 51.351,82.333,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.517 | Acc: 51.364,82.342,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 51.350,82.388,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.514 | Acc: 51.290,82.342,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.519 | Acc: 51.314,82.331,96.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.513 | Acc: 51.282,82.304,96.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.513 | Acc: 51.259,82.291,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.508 | Acc: 51.334,82.333,96.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.507 | Acc: 51.331,82.393,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.509 | Acc: 51.314,82.313,96.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.515 | Acc: 51.177,82.277,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.296 | Acc: 51.562,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.671 | Acc: 46.243,64.621,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.674 | Acc: 45.770,63.853,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.694 | Acc: 45.300,63.960,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.468 | Acc: 51.562,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.496 | Acc: 51.376,82.738,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.509 | Acc: 51.048,82.851,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.506 | Acc: 51.127,82.544,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.505 | Acc: 51.167,82.533,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.505 | Acc: 51.245,82.619,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 51.369,82.548,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.508 | Acc: 51.197,82.491,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.511 | Acc: 51.097,82.390,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 50.967,82.230,96.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 51.081,82.327,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.510 | Acc: 51.043,82.339,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.511 | Acc: 51.002,82.378,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.512 | Acc: 51.122,82.420,96.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 51.134,82.462,96.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.508 | Acc: 51.150,82.496,96.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.507 | Acc: 51.122,82.482,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.509 | Acc: 51.061,82.455,96.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.508 | Acc: 51.106,82.423,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.509 | Acc: 51.085,82.404,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.289 | Acc: 49.219,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.675 | Acc: 46.577,64.844,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.682 | Acc: 45.998,63.891,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.708 | Acc: 45.364,64.011,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.317 | Acc: 55.469,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.440 | Acc: 52.307,82.887,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.465 | Acc: 51.486,82.565,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.478 | Acc: 51.486,82.697,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.506 | Acc: 51.225,82.301,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 50.851,82.271,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.521 | Acc: 50.936,82.277,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 51.014,82.159,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.526 | Acc: 50.937,82.240,96.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.516 | Acc: 50.898,82.463,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 50.960,82.404,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 50.937,82.406,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.516 | Acc: 50.872,82.320,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.514 | Acc: 50.982,82.390,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.513 | Acc: 51.065,82.390,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.512 | Acc: 51.051,82.449,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.515 | Acc: 50.978,82.426,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.511 | Acc: 51.109,82.396,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 51.117,82.425,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.511 | Acc: 51.144,82.409,96.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.289 | Acc: 50.000,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.674 | Acc: 46.503,64.397,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.675 | Acc: 45.808,63.643,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.701 | Acc: 45.351,63.858,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.577 | Acc: 47.656,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.465 | Acc: 50.856,82.738,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.521 | Acc: 50.877,81.764,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.525 | Acc: 50.922,81.993,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.522 | Acc: 50.897,82.195,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.515 | Acc: 50.920,82.294,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.519 | Acc: 50.885,82.147,96.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.518 | Acc: 50.914,82.148,96.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.520 | Acc: 50.747,82.138,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.525 | Acc: 50.643,82.143,96.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.519 | Acc: 50.820,82.171,96.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.523 | Acc: 50.622,82.116,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 50.733,82.210,96.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.517 | Acc: 50.787,82.280,96.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.516 | Acc: 50.831,82.309,96.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 50.760,82.301,96.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.519 | Acc: 50.657,82.250,96.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.514 | Acc: 50.683,82.325,96.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.510 | Acc: 50.766,82.399,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.511 | Acc: 50.748,82.374,96.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.286 | Acc: 53.125,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.674 | Acc: 46.503,64.621,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.673 | Acc: 45.960,63.796,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.694 | Acc: 45.453,63.922,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.510 | Acc: 52.344,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.544 | Acc: 50.707,82.031,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.514 | Acc: 51.162,82.203,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.505 | Acc: 51.332,82.236,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.524 | Acc: 51.186,82.041,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.521 | Acc: 51.029,82.279,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.513 | Acc: 51.259,82.444,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.519 | Acc: 51.136,82.524,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.521 | Acc: 51.199,82.434,96.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.525 | Acc: 51.019,82.286,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 51.003,82.296,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.524 | Acc: 50.997,82.268,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.526 | Acc: 50.998,82.297,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.527 | Acc: 50.874,82.307,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.531 | Acc: 50.812,82.209,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 50.976,82.382,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.517 | Acc: 51.000,82.396,96.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 51.017,82.331,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.517 | Acc: 51.015,82.347,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.515 | Acc: 51.050,82.343,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.276 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.690 | Acc: 46.615,64.435,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.685 | Acc: 45.960,63.605,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.700 | Acc: 45.492,63.742,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.520 | Acc: 50.000,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.515 | Acc: 50.595,81.920,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.508 | Acc: 50.934,82.527,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.511 | Acc: 50.794,82.262,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 50.965,82.215,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.516 | Acc: 50.774,82.147,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.528 | Acc: 50.626,82.051,96.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 50.609,82.209,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.515 | Acc: 50.752,82.191,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 50.794,82.208,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.512 | Acc: 50.851,82.253,96.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 50.771,82.296,96.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 50.752,82.223,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.510 | Acc: 50.940,82.295,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.517 | Acc: 50.770,82.218,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.522 | Acc: 50.646,82.109,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 50.643,82.165,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.519 | Acc: 50.596,82.203,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.515 | Acc: 50.636,82.233,96.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.514 | Acc: 50.636,82.232,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.270 | Acc: 50.000,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.689 | Acc: 46.429,65.104,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.683 | Acc: 45.770,64.005,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.708 | Acc: 45.364,63.998,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.361 | Acc: 49.219,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.520 | Acc: 49.070,82.292,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 49.809,82.603,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 50.628,82.351,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 50.772,82.176,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.508 | Acc: 50.804,81.977,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.503 | Acc: 50.872,82.231,96.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.520 | Acc: 50.748,82.092,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.523 | Acc: 50.660,82.157,96.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.523 | Acc: 50.639,82.182,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 50.606,82.210,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.525 | Acc: 50.576,82.197,96.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.530 | Acc: 50.522,82.044,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 50.536,82.094,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.523 | Acc: 50.550,82.145,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.518 | Acc: 50.644,82.262,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.517 | Acc: 50.589,82.270,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.519 | Acc: 50.570,82.224,96.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.513 | Acc: 50.673,82.308,96.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.510 | Acc: 50.767,82.388,96.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.318 | Acc: 50.000,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.693 | Acc: 46.280,64.174,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.686 | Acc: 45.579,63.510,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.708 | Acc: 45.261,63.678,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.451 | Acc: 50.781,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 53.311,84.301,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.466 | Acc: 52.496,82.908,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 51.524,82.838,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.507 | Acc: 51.186,82.658,96.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.520 | Acc: 51.029,82.472,96.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 50.962,82.567,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.518 | Acc: 51.108,82.391,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.518 | Acc: 50.970,82.405,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.521 | Acc: 50.932,82.290,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.522 | Acc: 50.964,82.222,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 51.138,82.381,96.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 51.063,82.423,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.515 | Acc: 50.982,82.307,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.515 | Acc: 50.965,82.332,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 51.054,82.317,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 51.056,82.350,96.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.515 | Acc: 50.992,82.249,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.514 | Acc: 51.045,82.207,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.514 | Acc: 51.064,82.191,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.232 | Acc: 52.344,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.673 | Acc: 46.466,64.695,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.668 | Acc: 46.018,63.834,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.686 | Acc: 45.671,64.037,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 2.526 | Acc: 53.125,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.522 | Acc: 51.786,81.957,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.525 | Acc: 51.239,82.431,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 50.845,82.313,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 51.138,82.292,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.536 | Acc: 51.067,82.101,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.535 | Acc: 51.033,82.173,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 51.064,82.197,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.529 | Acc: 51.019,82.109,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.530 | Acc: 50.941,82.027,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.530 | Acc: 50.770,82.109,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 50.838,82.074,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.527 | Acc: 50.882,82.138,96.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.531 | Acc: 50.769,82.088,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 50.778,82.201,96.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 50.828,82.195,96.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.527 | Acc: 50.842,82.151,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 50.859,82.146,96.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.527 | Acc: 50.881,82.113,96.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.527 | Acc: 50.917,82.146,96.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.252 | Acc: 51.562,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.681 | Acc: 46.652,64.509,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.683 | Acc: 45.922,63.643,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.700 | Acc: 45.402,63.819,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.480 | Acc: 48.438,87.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.506 | Acc: 50.112,83.408,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.495 | Acc: 50.819,83.060,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.475 | Acc: 51.127,83.005,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.483 | Acc: 51.138,82.812,96.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.478 | Acc: 51.354,82.797,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.490 | Acc: 51.298,82.541,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 51.330,82.718,96.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.498 | Acc: 51.106,82.536,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.498 | Acc: 51.092,82.562,96.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.501 | Acc: 51.154,82.521,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.502 | Acc: 51.142,82.547,96.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.508 | Acc: 51.083,82.394,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.510 | Acc: 51.036,82.358,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.515 | Acc: 50.931,82.309,96.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.516 | Acc: 50.862,82.322,96.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.515 | Acc: 50.862,82.294,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.514 | Acc: 50.861,82.366,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.512 | Acc: 50.876,82.354,96.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.514 | Acc: 50.861,82.327,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.292 | Acc: 50.000,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.678 | Acc: 46.280,64.881,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.680 | Acc: 45.636,63.758,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.701 | Acc: 45.287,63.922,69.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.782 | Acc: 48.438,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.558 | Acc: 50.484,81.510,97.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.545 | Acc: 50.438,81.593,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.542 | Acc: 50.538,82.018,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.542 | Acc: 50.482,82.002,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.524 | Acc: 50.743,82.302,96.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.539 | Acc: 50.497,81.934,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.536 | Acc: 50.670,81.871,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.533 | Acc: 50.883,81.905,96.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.535 | Acc: 50.786,81.936,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.530 | Acc: 50.999,81.992,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.526 | Acc: 51.075,82.003,96.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 51.212,82.077,96.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.519 | Acc: 51.296,82.070,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 51.234,82.053,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.522 | Acc: 51.189,82.073,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 51.224,82.095,96.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.517 | Acc: 51.251,82.093,96.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.518 | Acc: 51.195,82.113,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.518 | Acc: 51.193,82.134,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.312 | Acc: 52.344,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.696 | Acc: 46.466,64.583,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.692 | Acc: 45.922,63.681,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.717 | Acc: 45.428,63.870,69.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.492 | Acc: 50.781,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.539 | Acc: 51.004,81.734,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.555 | Acc: 50.762,81.726,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.519 | Acc: 51.396,82.364,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.521 | Acc: 51.128,82.263,96.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.524 | Acc: 50.897,82.248,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.512 | Acc: 50.975,82.393,96.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.511 | Acc: 51.003,82.530,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.511 | Acc: 50.927,82.609,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.520 | Acc: 50.872,82.390,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.518 | Acc: 50.824,82.385,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.518 | Acc: 50.909,82.296,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 51.076,82.329,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.509 | Acc: 51.272,82.381,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.508 | Acc: 51.321,82.401,96.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.505 | Acc: 51.347,82.436,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.508 | Acc: 51.307,82.413,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.510 | Acc: 51.294,82.446,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.512 | Acc: 51.160,82.462,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.513 | Acc: 51.161,82.380,96.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.295 | Acc: 51.562,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.673 | Acc: 46.503,64.881,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.674 | Acc: 45.751,63.910,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.695 | Acc: 45.453,64.024,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.521 | Acc: 50.781,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.486 | Acc: 51.637,82.664,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.544 | Acc: 50.819,82.050,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.549 | Acc: 50.807,81.954,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.547 | Acc: 50.897,82.012,96.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.528 | Acc: 50.774,82.240,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.527 | Acc: 50.743,82.335,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.522 | Acc: 50.842,82.342,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.517 | Acc: 50.907,82.371,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.525 | Acc: 50.833,82.316,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.526 | Acc: 50.906,82.303,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 50.873,82.314,96.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.525 | Acc: 50.917,82.391,96.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.523 | Acc: 50.925,82.426,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.520 | Acc: 51.006,82.443,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 50.940,82.485,96.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.517 | Acc: 50.993,82.494,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.513 | Acc: 51.118,82.476,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.512 | Acc: 51.145,82.492,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.510 | Acc: 51.161,82.486,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.278 | Acc: 50.781,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.677 | Acc: 46.652,64.546,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.680 | Acc: 45.770,63.700,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.700 | Acc: 45.364,63.934,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.574 | Acc: 51.562,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.505 | Acc: 50.670,82.292,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.499 | Acc: 51.353,82.146,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.520 | Acc: 50.461,82.031,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.509 | Acc: 50.617,82.041,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.519 | Acc: 50.402,81.954,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.514 | Acc: 50.362,82.180,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.519 | Acc: 50.438,82.137,96.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.514 | Acc: 50.631,82.245,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.510 | Acc: 50.803,82.221,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.508 | Acc: 50.688,82.206,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.509 | Acc: 50.785,82.286,96.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.508 | Acc: 50.924,82.313,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.510 | Acc: 50.898,82.325,96.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 50.887,82.262,96.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.511 | Acc: 50.942,82.254,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.514 | Acc: 50.920,82.236,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.513 | Acc: 51.001,82.253,96.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.512 | Acc: 50.995,82.254,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.514 | Acc: 51.001,82.271,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.274 | Acc: 50.000,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.670 | Acc: 46.429,64.844,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.673 | Acc: 45.751,63.891,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.695 | Acc: 45.351,64.139,69.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.560 | Acc: 51.562,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.484 | Acc: 51.488,83.185,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.511 | Acc: 51.086,82.812,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.522 | Acc: 50.615,82.505,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.508 | Acc: 51.235,82.629,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.513 | Acc: 51.145,82.642,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.520 | Acc: 51.065,82.670,96.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.517 | Acc: 51.086,82.469,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 50.835,82.439,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.525 | Acc: 50.863,82.446,96.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 50.855,82.389,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.525 | Acc: 50.802,82.321,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.523 | Acc: 50.778,82.313,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 50.820,82.420,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.517 | Acc: 50.862,82.451,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.518 | Acc: 50.844,82.454,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.517 | Acc: 50.862,82.408,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.515 | Acc: 51.001,82.398,96.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.515 | Acc: 51.021,82.399,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.515 | Acc: 50.925,82.398,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.265 | Acc: 52.344,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.677 | Acc: 46.280,64.546,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.673 | Acc: 45.655,63.720,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.692 | Acc: 45.466,64.037,69.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.352 | Acc: 55.469,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.471 | Acc: 51.562,83.445,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.497 | Acc: 51.848,82.793,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 51.793,82.941,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.504 | Acc: 51.196,82.600,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.512 | Acc: 50.967,82.418,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.506 | Acc: 51.091,82.490,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.510 | Acc: 51.064,82.336,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 51.029,82.240,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.510 | Acc: 51.066,82.342,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.508 | Acc: 51.228,82.358,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.508 | Acc: 51.205,82.342,96.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.506 | Acc: 51.261,82.427,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.504 | Acc: 51.242,82.459,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.507 | Acc: 51.251,82.412,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.508 | Acc: 51.075,82.423,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 51.073,82.413,96.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.512 | Acc: 51.081,82.398,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.513 | Acc: 51.052,82.360,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.508 | Acc: 51.142,82.441,96.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.236 | Acc: 50.781,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.680 | Acc: 46.131,64.807,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.678 | Acc: 45.694,64.062,68.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.695 | Acc: 45.351,64.139,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.338 | Acc: 50.781,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.530 | Acc: 51.302,80.841,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.511 | Acc: 51.562,81.726,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 50.820,81.980,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.508 | Acc: 51.225,82.234,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.507 | Acc: 50.975,82.426,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.515 | Acc: 50.788,82.335,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.504 | Acc: 50.942,82.513,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.506 | Acc: 51.068,82.478,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.507 | Acc: 51.161,82.364,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.511 | Acc: 51.053,82.257,96.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 51.220,82.438,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.507 | Acc: 51.105,82.423,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.512 | Acc: 50.925,82.361,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.516 | Acc: 50.829,82.270,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.519 | Acc: 50.947,82.156,96.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 50.942,82.131,96.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 51.001,82.127,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.519 | Acc: 51.011,82.189,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.517 | Acc: 51.017,82.201,96.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.271 | Acc: 50.781,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.674 | Acc: 47.173,64.881,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.677 | Acc: 46.246,63.720,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.697 | Acc: 45.633,63.947,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 2.310 | Acc: 54.688,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.481 | Acc: 52.009,82.999,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.525 | Acc: 51.086,82.489,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.525 | Acc: 51.127,82.403,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.531 | Acc: 51.119,82.157,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.525 | Acc: 51.346,82.132,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 51.440,82.128,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.515 | Acc: 51.302,82.192,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.515 | Acc: 51.325,82.342,96.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.513 | Acc: 51.170,82.385,96.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.514 | Acc: 51.166,82.350,96.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 51.237,82.455,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 51.151,82.404,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.515 | Acc: 51.200,82.387,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.516 | Acc: 51.157,82.345,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 51.163,82.338,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.513 | Acc: 51.251,82.338,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.514 | Acc: 51.260,82.306,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.515 | Acc: 51.197,82.267,96.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.516 | Acc: 51.183,82.240,96.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.286 | Acc: 53.906,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.699 | Acc: 46.540,64.769,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.689 | Acc: 45.960,63.910,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.706 | Acc: 45.556,63.986,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.648 | Acc: 45.312,81.250,93.750,% | Adaptive Acc: 81.250% | clf_exit: 0.383 0.445 0.172
Batch: 20 | Loss: 2.484 | Acc: 52.455,82.143,96.019,% | Adaptive Acc: 86.421% | clf_exit: 0.363 0.448 0.189
Batch: 40 | Loss: 2.491 | Acc: 51.620,82.374,96.246,% | Adaptive Acc: 86.871% | clf_exit: 0.353 0.458 0.190
Batch: 60 | Loss: 2.490 | Acc: 52.062,82.390,96.094,% | Adaptive Acc: 87.308% | clf_exit: 0.349 0.459 0.192
Batch: 80 | Loss: 2.514 | Acc: 51.505,82.234,96.190,% | Adaptive Acc: 87.182% | clf_exit: 0.349 0.459 0.192
Batch: 100 | Loss: 2.508 | Acc: 51.477,82.248,96.272,% | Adaptive Acc: 87.252% | clf_exit: 0.346 0.462 0.192
Batch: 120 | Loss: 2.510 | Acc: 51.414,82.361,96.255,% | Adaptive Acc: 87.313% | clf_exit: 0.344 0.462 0.194
Batch: 140 | Loss: 2.509 | Acc: 51.496,82.475,96.282,% | Adaptive Acc: 87.173% | clf_exit: 0.347 0.461 0.192
Batch: 160 | Loss: 2.518 | Acc: 51.310,82.395,96.239,% | Adaptive Acc: 87.039% | clf_exit: 0.346 0.461 0.192
Batch: 180 | Loss: 2.514 | Acc: 51.278,82.424,96.271,% | Adaptive Acc: 87.107% | clf_exit: 0.346 0.462 0.192
Batch: 200 | Loss: 2.514 | Acc: 51.123,82.362,96.265,% | Adaptive Acc: 87.092% | clf_exit: 0.345 0.463 0.192
Batch: 220 | Loss: 2.503 | Acc: 51.343,82.537,96.334,% | Adaptive Acc: 87.132% | clf_exit: 0.346 0.463 0.191
Batch: 240 | Loss: 2.503 | Acc: 51.290,82.553,96.340,% | Adaptive Acc: 87.228% | clf_exit: 0.346 0.463 0.191
Batch: 260 | Loss: 2.505 | Acc: 51.087,82.537,96.375,% | Adaptive Acc: 87.186% | clf_exit: 0.347 0.461 0.192
Batch: 280 | Loss: 2.504 | Acc: 51.184,82.540,96.405,% | Adaptive Acc: 87.219% | clf_exit: 0.347 0.461 0.192
Batch: 300 | Loss: 2.508 | Acc: 51.111,82.444,96.405,% | Adaptive Acc: 87.222% | clf_exit: 0.346 0.461 0.193
Batch: 320 | Loss: 2.504 | Acc: 51.178,82.477,96.417,% | Adaptive Acc: 87.257% | clf_exit: 0.345 0.463 0.192
Batch: 340 | Loss: 2.504 | Acc: 51.088,82.471,96.421,% | Adaptive Acc: 87.239% | clf_exit: 0.345 0.463 0.192
Batch: 360 | Loss: 2.507 | Acc: 50.983,82.503,96.408,% | Adaptive Acc: 87.266% | clf_exit: 0.344 0.463 0.193
Batch: 380 | Loss: 2.507 | Acc: 50.997,82.503,96.416,% | Adaptive Acc: 87.318% | clf_exit: 0.343 0.464 0.193
Batch: 0 | Loss: 4.265 | Acc: 51.562,67.969,72.656,% | Adaptive Acc: 67.188% | clf_exit: 0.477 0.328 0.195
Batch: 20 | Loss: 4.661 | Acc: 46.838,64.472,69.829,% | Adaptive Acc: 63.951% | clf_exit: 0.418 0.377 0.205
Batch: 40 | Loss: 4.663 | Acc: 45.979,63.853,68.960,% | Adaptive Acc: 62.957% | clf_exit: 0.417 0.371 0.212
Batch: 60 | Loss: 4.683 | Acc: 45.466,64.165,69.109,% | Adaptive Acc: 63.051% | clf_exit: 0.413 0.375 0.211
model is save as models/resnet56_2con3_att2_cifar100_adaptive0_circles0_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 4.265 | Acc: 51.562,67.969,72.656,% | Adaptive Acc: 67.188% | clf_exit: 0.477 0.328 0.195
Batch: 20 | Loss: 4.661 | Acc: 46.838,64.472,69.829,% | Adaptive Acc: 63.951% | clf_exit: 0.418 0.377 0.205
Batch: 40 | Loss: 4.663 | Acc: 45.979,63.853,68.960,% | Adaptive Acc: 62.957% | clf_exit: 0.417 0.371 0.212
Batch: 60 | Loss: 4.683 | Acc: 45.466,64.165,69.109,% | Adaptive Acc: 63.051% | clf_exit: 0.413 0.375 0.211







Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.501 |  Acc: 1.880,3.014,5.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 12.744 |  Acc: 3.340,5.350,9.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 12.262 |  Acc: 3.720,7.816,12.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 11.848 |  Acc: 4.420,10.010,14.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 11.428 |  Acc: 5.632,11.940,17.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 11.472 |  Acc: 6.000,11.790,16.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 10.717 |  Acc: 8.060,15.844,21.988,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 10.619 |  Acc: 8.740,15.500,22.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 10.106 |  Acc: 10.700,19.112,25.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 10.319 |  Acc: 9.400,18.450,24.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 9.563 |  Acc: 13.192,22.254,29.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 9.621 |  Acc: 12.610,21.400,28.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 9.100 |  Acc: 15.822,25.224,32.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 9.828 |  Acc: 11.840,20.670,28.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 8.698 |  Acc: 17.996,27.444,34.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 9.287 |  Acc: 16.390,24.400,29.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 8.348 |  Acc: 20.204,29.826,37.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 8.741 |  Acc: 17.210,27.230,36.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 8.056 |  Acc: 21.632,31.826,39.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 8.240 |  Acc: 19.420,29.500,39.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 7.820 |  Acc: 22.500,33.284,41.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 8.687 |  Acc: 19.320,28.050,37.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 7.578 |  Acc: 24.242,35.042,43.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 8.016 |  Acc: 19.790,31.980,42.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 7.361 |  Acc: 25.174,36.790,45.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 8.155 |  Acc: 18.760,30.830,42.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 7.194 |  Acc: 26.002,37.930,46.626,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 8.841 |  Acc: 17.740,29.350,38.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 7.037 |  Acc: 26.798,39.332,48.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 7.628 |  Acc: 24.440,35.120,44.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 6.886 |  Acc: 27.618,40.576,49.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 8.123 |  Acc: 24.530,31.900,40.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 6.748 |  Acc: 28.346,42.026,50.376,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 7.934 |  Acc: 23.270,33.000,42.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 6.632 |  Acc: 28.890,42.842,51.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 7.537 |  Acc: 22.370,36.260,46.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 6.513 |  Acc: 29.204,43.918,52.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 8.021 |  Acc: 20.510,34.230,45.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 6.429 |  Acc: 29.592,44.882,53.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 7.468 |  Acc: 22.710,37.330,46.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 6.315 |  Acc: 30.166,46.118,54.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 7.487 |  Acc: 24.430,37.640,46.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 6.229 |  Acc: 30.588,46.828,55.128,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 7.815 |  Acc: 23.720,35.310,46.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 6.138 |  Acc: 31.242,47.364,55.988,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 7.284 |  Acc: 24.750,39.170,47.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 6.068 |  Acc: 31.238,48.114,56.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 6.751 |  Acc: 28.310,42.910,51.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 6.002 |  Acc: 32.038,48.792,57.172,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 7.336 |  Acc: 23.050,40.400,49.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 5.931 |  Acc: 32.154,49.352,57.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 8.252 |  Acc: 17.460,35.450,45.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 5.832 |  Acc: 32.420,50.538,58.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 6.902 |  Acc: 26.040,42.890,50.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 5.804 |  Acc: 33.058,50.706,59.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 6.572 |  Acc: 28.040,45.780,55.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 5.737 |  Acc: 33.250,50.976,59.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 7.381 |  Acc: 24.260,40.820,51.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 5.670 |  Acc: 33.716,51.774,60.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 6.682 |  Acc: 28.060,44.660,52.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 5.640 |  Acc: 34.066,51.786,60.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 7.256 |  Acc: 23.850,42.140,51.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 5.570 |  Acc: 34.376,52.624,61.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 7.783 |  Acc: 23.160,36.890,48.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 5.527 |  Acc: 34.694,53.010,61.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 6.463 |  Acc: 29.740,45.590,54.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 5.505 |  Acc: 34.700,53.158,61.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 7.515 |  Acc: 23.530,42.720,51.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 5.443 |  Acc: 35.048,53.598,62.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 7.059 |  Acc: 27.110,42.300,51.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.416 |  Acc: 35.008,54.026,62.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 7.615 |  Acc: 22.490,39.710,48.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.378 |  Acc: 35.520,54.714,63.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 7.153 |  Acc: 27.780,41.400,49.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.346 |  Acc: 35.382,54.620,62.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 6.543 |  Acc: 28.730,45.140,54.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.320 |  Acc: 35.594,54.752,63.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 6.945 |  Acc: 25.450,44.330,54.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.289 |  Acc: 35.810,55.394,63.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 8.193 |  Acc: 21.660,37.540,47.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.255 |  Acc: 36.018,55.360,63.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 6.545 |  Acc: 30.350,45.290,52.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.231 |  Acc: 36.252,55.738,64.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 6.837 |  Acc: 25.050,44.980,53.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.185 |  Acc: 36.440,55.734,64.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 8.217 |  Acc: 21.480,39.760,48.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.158 |  Acc: 36.500,56.512,64.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 7.316 |  Acc: 26.640,40.970,51.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.147 |  Acc: 36.532,56.382,65.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 7.129 |  Acc: 25.480,43.540,52.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 5.139 |  Acc: 36.802,56.344,65.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 7.226 |  Acc: 24.800,43.580,54.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 5.084 |  Acc: 37.098,56.820,65.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 6.342 |  Acc: 31.130,48.030,56.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 5.069 |  Acc: 36.954,57.324,66.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 6.187 |  Acc: 31.790,48.280,55.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 5.044 |  Acc: 37.356,57.408,66.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 6.312 |  Acc: 30.110,47.630,55.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 5.005 |  Acc: 37.522,57.728,66.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 6.605 |  Acc: 29.660,45.040,52.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 5.005 |  Acc: 37.498,57.464,66.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 7.460 |  Acc: 21.940,42.770,53.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 4.994 |  Acc: 37.642,57.628,66.554,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 7.342 |  Acc: 25.590,40.290,52.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 4.960 |  Acc: 37.548,58.136,67.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 6.581 |  Acc: 27.610,47.360,55.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 4.941 |  Acc: 37.606,58.164,67.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 7.272 |  Acc: 22.070,45.230,54.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 4.927 |  Acc: 37.936,58.436,67.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 6.756 |  Acc: 29.210,46.020,53.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 4.911 |  Acc: 38.118,58.490,67.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 6.301 |  Acc: 31.200,46.940,56.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 4.892 |  Acc: 38.104,58.648,67.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 6.872 |  Acc: 25.640,46.350,56.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 4.880 |  Acc: 37.930,58.714,67.944,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.353 |  Acc: 30.670,48.110,56.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 4.850 |  Acc: 38.238,58.898,68.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 6.657 |  Acc: 30.920,44.310,54.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 4.838 |  Acc: 38.368,59.066,68.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 6.477 |  Acc: 29.910,47.970,55.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 4.836 |  Acc: 38.114,59.480,68.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 6.377 |  Acc: 30.840,46.970,55.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.813 |  Acc: 38.342,59.438,68.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 6.962 |  Acc: 26.360,43.320,54.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.791 |  Acc: 38.690,59.572,68.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 7.637 |  Acc: 24.400,41.720,50.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.796 |  Acc: 38.632,59.352,68.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 6.582 |  Acc: 33.460,44.250,54.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.785 |  Acc: 38.696,59.642,68.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 6.788 |  Acc: 28.660,47.920,55.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.755 |  Acc: 39.042,59.998,68.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 6.999 |  Acc: 27.770,46.310,55.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.757 |  Acc: 38.898,60.028,69.038,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 6.241 |  Acc: 32.580,48.760,55.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.735 |  Acc: 38.906,60.182,69.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 6.202 |  Acc: 31.450,49.530,57.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.732 |  Acc: 39.028,60.036,69.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 6.566 |  Acc: 30.530,46.990,54.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.717 |  Acc: 39.050,60.066,69.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 6.165 |  Acc: 30.820,48.980,58.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.698 |  Acc: 39.274,60.444,69.654,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 6.924 |  Acc: 31.160,43.100,51.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.697 |  Acc: 39.176,60.412,69.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 6.312 |  Acc: 30.370,49.460,57.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.676 |  Acc: 39.164,60.560,69.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 6.821 |  Acc: 26.990,44.720,55.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.684 |  Acc: 39.166,60.518,70.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.145 |  Acc: 30.220,49.010,58.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.647 |  Acc: 39.338,60.954,70.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 6.871 |  Acc: 26.690,46.120,55.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.638 |  Acc: 39.714,61.134,70.270,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 6.031 |  Acc: 30.550,52.390,58.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.639 |  Acc: 39.308,60.954,70.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 6.467 |  Acc: 27.660,48.990,56.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.617 |  Acc: 39.394,61.274,70.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 6.031 |  Acc: 31.730,50.680,57.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.628 |  Acc: 39.430,61.186,70.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 6.115 |  Acc: 30.810,50.230,58.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.610 |  Acc: 39.668,61.058,70.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 6.839 |  Acc: 28.620,44.300,54.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.587 |  Acc: 39.604,61.586,70.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 7.085 |  Acc: 28.960,43.620,51.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.586 |  Acc: 39.748,61.348,70.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.704 |  Acc: 26.570,48.150,56.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.612 |  Acc: 39.576,61.282,70.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 7.148 |  Acc: 25.730,43.360,53.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.591 |  Acc: 40.064,61.314,70.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 5.996 |  Acc: 31.610,52.690,58.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.575 |  Acc: 39.916,61.484,70.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 6.954 |  Acc: 25.010,46.830,55.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.546 |  Acc: 40.164,61.474,71.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 6.750 |  Acc: 27.060,47.040,55.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.544 |  Acc: 39.972,61.580,71.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 6.755 |  Acc: 27.490,48.160,56.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.544 |  Acc: 40.162,61.664,71.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 6.357 |  Acc: 26.920,50.560,58.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.550 |  Acc: 39.828,61.686,71.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 7.398 |  Acc: 27.200,41.990,51.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.545 |  Acc: 39.764,61.916,71.146,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 6.110 |  Acc: 34.150,50.610,58.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.518 |  Acc: 40.166,61.990,71.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 7.722 |  Acc: 21.250,42.930,53.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.515 |  Acc: 40.038,62.156,71.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 5.889 |  Acc: 32.740,51.650,58.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.504 |  Acc: 40.236,62.114,71.886,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 7.069 |  Acc: 29.690,43.490,54.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.507 |  Acc: 40.238,61.988,71.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 7.605 |  Acc: 22.780,43.810,54.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.507 |  Acc: 40.278,62.162,71.304,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 6.460 |  Acc: 30.190,48.420,57.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.487 |  Acc: 40.394,62.410,71.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 6.151 |  Acc: 33.240,50.910,58.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.476 |  Acc: 40.410,62.306,72.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 6.541 |  Acc: 26.140,51.070,59.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.465 |  Acc: 40.644,62.656,72.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 6.696 |  Acc: 29.580,47.050,57.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.478 |  Acc: 40.212,62.436,71.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 7.000 |  Acc: 25.830,45.690,57.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.469 |  Acc: 40.350,62.568,71.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 6.757 |  Acc: 28.720,45.780,55.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.469 |  Acc: 40.472,62.232,71.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 6.668 |  Acc: 27.380,48.590,57.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.469 |  Acc: 40.370,62.482,71.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 6.976 |  Acc: 27.590,45.170,55.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.453 |  Acc: 40.678,62.684,72.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.178 |  Acc: 28.720,51.270,59.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.450 |  Acc: 40.636,62.396,72.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 5.749 |  Acc: 34.670,51.480,60.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.445 |  Acc: 40.582,62.584,72.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 5.705 |  Acc: 34.190,52.900,60.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.445 |  Acc: 40.440,62.478,72.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 6.685 |  Acc: 26.440,48.760,58.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.433 |  Acc: 40.460,62.746,72.346,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 6.184 |  Acc: 31.050,50.130,58.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.403 |  Acc: 40.760,62.990,72.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 6.296 |  Acc: 30.210,50.040,57.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.437 |  Acc: 40.384,63.114,72.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 7.283 |  Acc: 24.990,43.050,54.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.412 |  Acc: 40.858,62.896,72.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 6.628 |  Acc: 32.350,44.850,56.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.409 |  Acc: 40.944,62.864,72.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 7.632 |  Acc: 23.350,45.030,55.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.403 |  Acc: 40.536,63.176,72.940,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 6.691 |  Acc: 26.720,46.020,56.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.388 |  Acc: 40.826,63.264,72.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 7.544 |  Acc: 24.580,41.860,50.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.424 |  Acc: 40.622,62.998,72.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 6.770 |  Acc: 26.500,47.770,57.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.380 |  Acc: 40.590,63.018,73.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 5.899 |  Acc: 35.510,50.460,57.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.375 |  Acc: 40.966,63.236,73.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.383 |  Acc: 28.360,49.960,58.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.367 |  Acc: 41.102,63.276,72.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 6.409 |  Acc: 28.360,49.280,57.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.363 |  Acc: 41.152,63.450,73.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 6.177 |  Acc: 32.410,48.990,58.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.354 |  Acc: 41.180,63.378,73.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 6.609 |  Acc: 28.820,49.200,58.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.366 |  Acc: 41.020,63.452,73.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 8.144 |  Acc: 23.810,38.270,49.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.351 |  Acc: 41.478,63.530,73.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 8.065 |  Acc: 20.470,42.640,54.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.344 |  Acc: 41.336,63.366,73.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 7.105 |  Acc: 26.660,46.470,56.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.361 |  Acc: 40.936,63.284,73.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 6.787 |  Acc: 28.720,46.150,56.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.350 |  Acc: 41.298,63.474,73.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 7.639 |  Acc: 22.870,44.820,54.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.357 |  Acc: 41.156,63.436,73.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 7.475 |  Acc: 25.850,44.630,53.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.341 |  Acc: 40.992,63.590,73.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 7.700 |  Acc: 22.500,42.690,51.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.333 |  Acc: 41.326,63.662,73.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 7.726 |  Acc: 22.100,43.560,53.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.329 |  Acc: 41.086,63.588,73.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 7.250 |  Acc: 25.400,48.570,55.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.337 |  Acc: 41.234,63.460,73.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 6.151 |  Acc: 34.030,50.000,57.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.305 |  Acc: 41.280,63.552,73.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 7.094 |  Acc: 25.260,47.750,58.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.302 |  Acc: 41.380,64.046,73.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 6.384 |  Acc: 31.610,48.740,56.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.318 |  Acc: 41.162,63.836,73.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 7.024 |  Acc: 24.060,45.670,55.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.315 |  Acc: 41.260,63.782,73.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 6.313 |  Acc: 33.400,45.800,58.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.315 |  Acc: 41.422,63.844,73.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 6.986 |  Acc: 24.600,48.050,57.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.293 |  Acc: 41.184,64.118,73.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 6.392 |  Acc: 29.210,47.800,56.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.299 |  Acc: 41.382,63.912,73.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 6.016 |  Acc: 31.640,51.270,59.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.311 |  Acc: 41.252,63.754,73.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 7.287 |  Acc: 25.870,44.400,54.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.300 |  Acc: 41.598,63.846,73.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 6.862 |  Acc: 28.100,47.620,55.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.267 |  Acc: 41.522,64.126,74.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.206 |  Acc: 28.710,50.130,59.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.284 |  Acc: 41.446,64.006,73.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 6.240 |  Acc: 30.710,49.790,58.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.289 |  Acc: 41.598,64.098,73.654,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 6.483 |  Acc: 29.050,48.860,59.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.291 |  Acc: 41.378,63.892,73.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 7.542 |  Acc: 19.590,47.520,56.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.266 |  Acc: 41.536,64.170,74.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 5.680 |  Acc: 34.100,53.690,61.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.270 |  Acc: 41.400,64.182,74.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 6.305 |  Acc: 28.110,51.830,60.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.281 |  Acc: 41.536,64.228,73.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 5.731 |  Acc: 34.890,52.320,59.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.268 |  Acc: 41.688,64.152,74.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 7.594 |  Acc: 27.420,43.550,47.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.271 |  Acc: 41.514,64.536,74.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 6.224 |  Acc: 32.010,51.320,58.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.259 |  Acc: 41.694,64.588,74.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 6.264 |  Acc: 32.980,49.540,59.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.247 |  Acc: 41.510,64.056,74.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 6.124 |  Acc: 32.620,49.870,59.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.273 |  Acc: 41.282,64.334,73.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 6.281 |  Acc: 30.230,50.460,58.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.611 |  Acc: 45.676,71.164,81.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.415 |  Acc: 43.360,63.930,70.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.409 |  Acc: 46.980,73.050,84.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.392 |  Acc: 43.430,64.720,70.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.357 |  Acc: 46.806,73.690,85.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.412 |  Acc: 43.330,64.290,70.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.309 |  Acc: 47.460,73.808,85.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.417 |  Acc: 43.650,64.330,70.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.280 |  Acc: 47.540,74.426,86.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.423 |  Acc: 43.530,64.950,70.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.239 |  Acc: 47.592,74.606,86.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.485 |  Acc: 43.030,64.240,70.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.223 |  Acc: 47.626,74.516,87.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.423 |  Acc: 43.910,64.520,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.202 |  Acc: 47.684,74.668,87.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.420 |  Acc: 44.310,64.480,70.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.180 |  Acc: 47.608,75.322,87.914,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.443 |  Acc: 43.780,64.320,70.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.152 |  Acc: 47.886,75.240,88.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.498 |  Acc: 43.760,64.320,70.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.141 |  Acc: 47.840,75.402,88.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.446 |  Acc: 44.190,64.670,70.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.137 |  Acc: 47.946,75.384,88.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.514 |  Acc: 43.290,64.210,70.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.124 |  Acc: 47.996,75.530,88.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.493 |  Acc: 43.780,64.650,70.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.101 |  Acc: 47.934,75.644,88.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.550 |  Acc: 43.460,64.200,70.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.091 |  Acc: 48.074,75.802,89.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.540 |  Acc: 43.200,64.300,70.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.077 |  Acc: 48.058,75.810,89.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.484 |  Acc: 44.160,64.740,70.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.062 |  Acc: 48.242,76.106,89.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.544 |  Acc: 43.910,64.380,70.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 3.050 |  Acc: 48.122,76.246,89.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.557 |  Acc: 43.430,63.950,69.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 3.056 |  Acc: 48.144,75.978,89.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.528 |  Acc: 43.800,64.380,70.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 3.029 |  Acc: 48.464,76.346,89.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.584 |  Acc: 43.840,64.500,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 3.038 |  Acc: 48.298,76.060,89.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.514 |  Acc: 43.900,64.680,70.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 3.023 |  Acc: 48.382,76.410,90.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.548 |  Acc: 43.770,64.730,70.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 3.022 |  Acc: 48.258,76.264,90.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.575 |  Acc: 43.350,64.020,69.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 3.005 |  Acc: 48.186,76.516,90.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.570 |  Acc: 43.570,64.550,70.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 2.986 |  Acc: 48.486,76.574,90.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.677 |  Acc: 42.960,63.600,69.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 2.985 |  Acc: 48.634,76.632,90.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.580 |  Acc: 44.080,64.110,69.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.986 |  Acc: 48.630,76.572,90.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.600 |  Acc: 43.680,63.690,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.973 |  Acc: 48.466,76.638,90.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.679 |  Acc: 43.410,63.690,69.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.972 |  Acc: 48.490,76.786,90.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.610 |  Acc: 43.940,64.050,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.971 |  Acc: 48.556,76.702,90.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.599 |  Acc: 44.080,63.980,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.952 |  Acc: 48.494,77.002,90.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.643 |  Acc: 43.800,63.980,69.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.949 |  Acc: 48.434,77.194,91.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.636 |  Acc: 43.540,64.350,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.944 |  Acc: 48.760,77.010,91.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.635 |  Acc: 43.600,64.100,69.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.929 |  Acc: 48.624,77.408,91.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.633 |  Acc: 44.130,63.940,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.936 |  Acc: 48.510,77.176,91.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.755 |  Acc: 42.940,63.300,69.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.926 |  Acc: 48.678,77.280,91.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.740 |  Acc: 43.150,63.890,68.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.920 |  Acc: 48.656,77.284,91.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.629 |  Acc: 43.630,64.140,69.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.926 |  Acc: 48.590,77.412,91.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.626 |  Acc: 44.610,64.500,69.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.910 |  Acc: 48.736,77.278,91.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.715 |  Acc: 43.870,63.450,69.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.907 |  Acc: 48.880,77.432,91.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.781 |  Acc: 42.650,63.320,68.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.908 |  Acc: 48.726,77.184,91.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.709 |  Acc: 43.220,64.290,69.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.901 |  Acc: 48.646,77.578,91.434,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.814 |  Acc: 42.340,63.070,68.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.895 |  Acc: 48.922,77.628,91.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.741 |  Acc: 43.280,63.440,68.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.896 |  Acc: 48.880,77.520,91.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.707 |  Acc: 43.350,63.700,69.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.894 |  Acc: 48.750,77.596,91.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.748 |  Acc: 43.780,62.980,68.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.876 |  Acc: 48.992,77.874,91.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.820 |  Acc: 42.710,62.680,68.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.881 |  Acc: 48.892,77.668,91.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.806 |  Acc: 43.250,62.700,68.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.889 |  Acc: 48.828,77.560,91.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.735 |  Acc: 44.040,63.220,69.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.884 |  Acc: 48.562,77.682,91.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.958 |  Acc: 40.880,62.390,68.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.876 |  Acc: 48.858,77.710,92.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.867 |  Acc: 42.390,62.600,68.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.857 |  Acc: 49.034,77.858,91.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.803 |  Acc: 43.380,62.910,68.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.873 |  Acc: 48.976,77.902,91.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.795 |  Acc: 42.870,63.180,68.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.859 |  Acc: 49.032,78.022,92.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.897 |  Acc: 42.950,62.390,68.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.858 |  Acc: 48.922,78.022,92.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 5.032 |  Acc: 40.290,62.510,67.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.857 |  Acc: 49.048,77.894,92.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.827 |  Acc: 43.910,62.450,68.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.851 |  Acc: 49.034,77.776,92.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.836 |  Acc: 43.450,62.600,68.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.849 |  Acc: 49.088,78.036,92.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.802 |  Acc: 43.910,62.850,67.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.856 |  Acc: 48.904,78.080,92.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.860 |  Acc: 42.680,62.630,68.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.855 |  Acc: 49.144,77.972,92.140,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.811 |  Acc: 42.340,63.160,68.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.850 |  Acc: 48.938,77.720,92.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.813 |  Acc: 43.730,62.690,68.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.840 |  Acc: 49.184,78.006,92.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.790 |  Acc: 43.370,62.950,68.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.846 |  Acc: 49.172,78.084,92.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.790 |  Acc: 43.870,63.090,68.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.835 |  Acc: 49.318,77.944,92.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.892 |  Acc: 42.330,62.490,68.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.856 |  Acc: 48.962,77.768,92.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.937 |  Acc: 41.980,62.390,67.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.846 |  Acc: 49.076,78.080,92.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.947 |  Acc: 41.310,62.160,68.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.835 |  Acc: 49.154,78.184,92.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.858 |  Acc: 43.050,62.640,68.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.836 |  Acc: 49.208,78.326,92.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 5.018 |  Acc: 42.200,61.920,67.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.835 |  Acc: 49.054,78.332,92.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.839 |  Acc: 43.120,62.900,68.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.825 |  Acc: 49.108,78.116,92.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.801 |  Acc: 43.590,63.650,68.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.829 |  Acc: 49.132,78.570,92.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.868 |  Acc: 43.050,62.570,68.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.826 |  Acc: 49.172,78.262,92.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 5.027 |  Acc: 41.330,62.540,68.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.829 |  Acc: 49.222,78.504,92.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.955 |  Acc: 43.230,61.830,67.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.822 |  Acc: 49.342,78.252,92.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.860 |  Acc: 43.840,62.860,67.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.820 |  Acc: 49.104,78.586,92.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.835 |  Acc: 43.020,62.860,68.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.827 |  Acc: 49.064,78.248,92.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.864 |  Acc: 42.870,63.250,68.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.679 |  Acc: 50.302,80.208,94.104,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.594 |  Acc: 44.790,64.530,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.625 |  Acc: 50.428,81.058,95.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.622 |  Acc: 45.050,64.450,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.618 |  Acc: 50.506,81.194,95.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.606 |  Acc: 45.240,64.590,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.612 |  Acc: 50.352,81.180,95.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.609 |  Acc: 45.440,64.520,69.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.596 |  Acc: 50.668,81.364,95.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.600 |  Acc: 45.340,64.650,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.597 |  Acc: 50.400,81.392,95.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.603 |  Acc: 45.420,64.490,69.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.587 |  Acc: 50.654,81.384,95.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.625 |  Acc: 45.490,64.470,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.587 |  Acc: 50.650,81.396,95.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.627 |  Acc: 45.400,64.340,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.583 |  Acc: 50.716,81.238,95.500,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.626 |  Acc: 45.090,64.440,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.586 |  Acc: 50.776,81.484,95.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.664 |  Acc: 45.040,64.370,69.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.578 |  Acc: 50.506,81.718,95.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.620 |  Acc: 45.300,64.920,69.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.572 |  Acc: 50.866,81.640,95.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.632 |  Acc: 45.460,64.430,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.573 |  Acc: 50.840,81.644,95.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.627 |  Acc: 45.490,64.530,69.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.569 |  Acc: 50.546,81.704,95.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.637 |  Acc: 45.240,64.270,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.565 |  Acc: 50.676,81.764,95.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.648 |  Acc: 45.240,64.480,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.565 |  Acc: 50.828,81.642,95.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.635 |  Acc: 45.380,64.600,69.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.562 |  Acc: 50.688,81.780,95.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.634 |  Acc: 45.350,64.470,69.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.567 |  Acc: 50.660,81.700,95.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.652 |  Acc: 45.030,64.410,69.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.562 |  Acc: 50.976,81.772,95.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.671 |  Acc: 45.270,64.140,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.559 |  Acc: 50.616,81.744,95.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.660 |  Acc: 44.900,64.290,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.565 |  Acc: 50.654,81.788,95.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.672 |  Acc: 45.490,64.310,69.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.557 |  Acc: 50.818,81.840,95.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.665 |  Acc: 45.200,64.200,69.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.553 |  Acc: 50.578,81.768,95.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.639 |  Acc: 45.260,64.590,69.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.548 |  Acc: 50.800,81.908,95.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.668 |  Acc: 45.160,64.350,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.556 |  Acc: 50.990,81.898,95.942,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.663 |  Acc: 45.300,64.400,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.546 |  Acc: 50.770,82.016,95.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.669 |  Acc: 45.130,64.310,69.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.557 |  Acc: 50.696,81.702,95.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.655 |  Acc: 45.310,64.460,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.554 |  Acc: 50.780,81.686,95.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.675 |  Acc: 45.200,64.180,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.552 |  Acc: 50.670,81.988,96.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.682 |  Acc: 45.280,64.300,69.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.551 |  Acc: 50.800,81.634,96.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.670 |  Acc: 45.130,64.530,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.543 |  Acc: 50.750,81.988,96.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.665 |  Acc: 45.470,64.240,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.538 |  Acc: 50.676,82.084,96.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.657 |  Acc: 45.420,64.620,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.543 |  Acc: 50.944,81.754,96.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.670 |  Acc: 45.520,64.190,69.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.553 |  Acc: 50.900,81.778,95.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.687 |  Acc: 45.330,64.030,69.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.540 |  Acc: 50.638,81.928,96.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.670 |  Acc: 45.330,64.330,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.544 |  Acc: 50.810,81.882,96.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.681 |  Acc: 45.340,64.210,69.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.539 |  Acc: 50.824,82.166,95.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.671 |  Acc: 45.030,64.370,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.522 |  Acc: 51.178,82.208,96.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.682 |  Acc: 45.340,64.440,69.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.524 |  Acc: 50.764,82.454,96.346,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.685 |  Acc: 45.300,64.370,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.524 |  Acc: 51.020,82.042,96.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.667 |  Acc: 45.190,64.480,69.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.529 |  Acc: 51.074,82.162,96.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.676 |  Acc: 45.150,64.540,69.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.520 |  Acc: 51.142,82.232,96.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.653 |  Acc: 45.310,64.710,69.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.528 |  Acc: 51.008,82.294,96.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.664 |  Acc: 45.310,64.560,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.518 |  Acc: 51.008,82.360,96.274,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.672 |  Acc: 45.180,64.380,69.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.517 |  Acc: 51.138,82.242,96.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.671 |  Acc: 45.460,64.450,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.520 |  Acc: 51.048,82.344,96.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.668 |  Acc: 45.440,64.340,69.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.519 |  Acc: 51.044,82.184,96.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.673 |  Acc: 45.360,64.580,69.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.521 |  Acc: 50.892,82.130,96.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.679 |  Acc: 45.140,64.440,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.515 |  Acc: 50.894,82.386,96.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.661 |  Acc: 45.430,64.440,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.517 |  Acc: 50.728,82.484,96.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.663 |  Acc: 45.480,64.410,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.523 |  Acc: 50.846,82.264,96.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.692 |  Acc: 45.220,64.210,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.512 |  Acc: 51.016,82.536,96.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.661 |  Acc: 45.290,64.650,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.511 |  Acc: 51.128,82.400,96.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.672 |  Acc: 45.570,64.560,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.508 |  Acc: 50.980,82.430,96.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.666 |  Acc: 45.350,64.440,69.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.520 |  Acc: 50.946,82.318,96.318,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.675 |  Acc: 45.230,64.520,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.516 |  Acc: 50.734,82.416,96.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.659 |  Acc: 45.400,64.260,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.517 |  Acc: 51.168,82.226,96.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.675 |  Acc: 45.300,64.370,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.510 |  Acc: 51.136,82.378,96.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.688 |  Acc: 45.270,64.440,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.511 |  Acc: 51.150,82.344,96.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.683 |  Acc: 45.340,64.170,69.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.513 |  Acc: 50.770,82.362,96.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.675 |  Acc: 45.360,64.290,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.517 |  Acc: 51.016,82.308,96.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.679 |  Acc: 45.410,64.140,69.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.514 |  Acc: 50.632,82.274,96.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.689 |  Acc: 45.310,64.390,69.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.512 |  Acc: 50.760,82.352,96.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.691 |  Acc: 45.160,64.000,69.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.514 |  Acc: 51.052,82.216,96.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.672 |  Acc: 45.500,64.370,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.527 |  Acc: 50.942,82.134,96.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.680 |  Acc: 45.360,64.170,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.514 |  Acc: 50.872,82.344,96.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.685 |  Acc: 45.190,64.350,69.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.519 |  Acc: 51.178,82.180,96.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.699 |  Acc: 45.320,64.140,69.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.513 |  Acc: 51.164,82.360,96.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.674 |  Acc: 45.490,64.300,69.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.513 |  Acc: 51.112,82.472,96.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.678 |  Acc: 45.360,64.320,69.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.516 |  Acc: 50.972,82.214,96.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.675 |  Acc: 45.330,64.470,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.516 |  Acc: 50.926,82.362,96.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.671 |  Acc: 45.420,64.450,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.507 |  Acc: 51.120,82.440,96.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.677 |  Acc: 45.260,64.520,69.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.517 |  Acc: 51.020,82.242,96.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.677 |  Acc: 45.620,64.390,69.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.515 |  Acc: 51.226,82.246,96.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.688 |  Acc: 45.440,64.330,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, attention='yes', backend='resnet56_2con3_att2', batch_size=128, circles=0, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.504 |  Acc: 51.008,82.548,96.438,% | Adaptive Acc:87.316% | clf_exit: 0.343 0.464 0.192
Testing: Epoch=299 | Loss: 4.666 |  Acc: 45.410,64.450,69.350,% | Adaptive Acc:63.180% | clf_exit: 0.414 0.375 0.211

circles: 0
Testing: Epoch=299 | Loss: 4.666 |  Acc: 45.410,64.450,69.350,% | Adaptive Acc:63.180% | clf_exit: 0.414 0.375 0.211
