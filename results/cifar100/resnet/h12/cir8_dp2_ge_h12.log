==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=32, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=16, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=32, out_features=100, bias=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=64, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=64, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
    (2): ClassifierModule2(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=128, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=128, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.443 | Acc: 0.000,0.781,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.510 | Acc: 1.525,1.153,1.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.263 | Acc: 1.905,1.543,1.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.196 | Acc: 1.793,1.537,1.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.115 | Acc: 1.784,1.562,1.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.071 | Acc: 1.733,1.508,1.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 14.041 | Acc: 1.646,1.446,1.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 14.022 | Acc: 1.651,1.402,1.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.994 | Acc: 1.723,1.436,1.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.972 | Acc: 1.709,1.446,1.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.950 | Acc: 1.706,1.500,1.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.933 | Acc: 1.782,1.559,1.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.917 | Acc: 1.760,1.546,1.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.902 | Acc: 1.808,1.557,1.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.890 | Acc: 1.824,1.543,1.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.877 | Acc: 1.835,1.555,1.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.862 | Acc: 1.855,1.562,1.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.852 | Acc: 1.906,1.565,1.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.839 | Acc: 1.909,1.578,1.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.829 | Acc: 1.882,1.573,1.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.434 | Acc: 0.000,2.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.589 | Acc: 1.339,1.637,1.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.579 | Acc: 1.429,1.810,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.590 | Acc: 1.614,1.678,1.409,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 13.821 | Acc: 0.000,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.597 | Acc: 2.158,1.935,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.578 | Acc: 2.077,2.001,1.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.564 | Acc: 1.895,2.139,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.548 | Acc: 1.881,2.122,1.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.533 | Acc: 1.918,2.135,1.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.528 | Acc: 1.924,2.111,1.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.516 | Acc: 1.906,2.161,1.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.510 | Acc: 1.912,2.261,1.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.500 | Acc: 1.921,2.279,1.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.492 | Acc: 1.967,2.324,1.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.492 | Acc: 1.987,2.305,1.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.481 | Acc: 2.029,2.328,1.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.473 | Acc: 2.059,2.323,1.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.464 | Acc: 2.052,2.358,1.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.460 | Acc: 2.043,2.323,1.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.453 | Acc: 2.059,2.349,1.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.447 | Acc: 2.073,2.348,1.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.442 | Acc: 2.069,2.357,1.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.436 | Acc: 2.092,2.342,1.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.169 | Acc: 3.906,1.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.350 | Acc: 2.307,2.827,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.363 | Acc: 2.115,2.744,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.388 | Acc: 2.062,2.638,2.100,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 13.427 | Acc: 0.781,4.688,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.317 | Acc: 2.158,3.125,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.297 | Acc: 2.306,2.896,2.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.317 | Acc: 2.164,2.754,2.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.311 | Acc: 2.141,2.672,2.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.313 | Acc: 2.127,2.669,2.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.308 | Acc: 2.105,2.731,2.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.308 | Acc: 2.111,2.621,2.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.301 | Acc: 2.159,2.567,2.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.301 | Acc: 2.193,2.607,2.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.292 | Acc: 2.231,2.639,2.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.285 | Acc: 2.284,2.658,2.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.279 | Acc: 2.266,2.704,2.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.273 | Acc: 2.245,2.766,2.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.272 | Acc: 2.269,2.786,2.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.271 | Acc: 2.281,2.775,2.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.268 | Acc: 2.251,2.787,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.265 | Acc: 2.259,2.754,2.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.262 | Acc: 2.281,2.790,2.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.258 | Acc: 2.272,2.768,2.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.294 | Acc: 3.125,0.000,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.245 | Acc: 2.604,2.344,1.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.243 | Acc: 2.553,2.306,1.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.245 | Acc: 2.459,2.536,1.601,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 12.993 | Acc: 3.125,3.906,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.125 | Acc: 2.493,3.162,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.131 | Acc: 2.229,3.163,2.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.130 | Acc: 2.280,3.253,2.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.129 | Acc: 2.315,3.260,2.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.128 | Acc: 2.274,3.110,2.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.125 | Acc: 2.337,3.131,2.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.125 | Acc: 2.266,3.086,2.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.125 | Acc: 2.232,3.120,2.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.122 | Acc: 2.240,3.103,2.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.118 | Acc: 2.270,3.156,2.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.119 | Acc: 2.287,3.178,2.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.112 | Acc: 2.305,3.251,2.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.114 | Acc: 2.305,3.293,2.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.110 | Acc: 2.274,3.359,2.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.108 | Acc: 2.289,3.392,2.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.103 | Acc: 2.351,3.402,2.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.095 | Acc: 2.424,3.476,2.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.090 | Acc: 2.437,3.553,2.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.085 | Acc: 2.457,3.609,2.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.061 | Acc: 2.344,4.688,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.265 | Acc: 2.307,2.121,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.257 | Acc: 2.496,1.944,1.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.262 | Acc: 2.369,2.036,1.857,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 12.961 | Acc: 0.781,4.688,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.912 | Acc: 3.274,4.911,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.933 | Acc: 3.087,4.707,2.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.946 | Acc: 3.138,4.534,2.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.928 | Acc: 3.019,4.909,2.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.931 | Acc: 2.986,4.842,2.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.916 | Acc: 3.022,4.933,2.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.907 | Acc: 3.047,5.014,2.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.909 | Acc: 3.033,4.959,2.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.901 | Acc: 3.030,5.072,2.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.891 | Acc: 3.024,5.131,2.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.881 | Acc: 3.015,5.182,2.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.879 | Acc: 2.927,5.187,2.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.869 | Acc: 2.901,5.235,2.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.861 | Acc: 2.908,5.333,2.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.856 | Acc: 2.897,5.375,2.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.853 | Acc: 2.901,5.393,2.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.849 | Acc: 2.955,5.455,2.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.842 | Acc: 2.971,5.495,2.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.836 | Acc: 3.004,5.543,2.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.789 | Acc: 4.688,6.250,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.999 | Acc: 3.274,5.134,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.008 | Acc: 3.201,4.783,2.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.012 | Acc: 2.984,4.931,2.088,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 12.584 | Acc: 3.125,4.688,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.708 | Acc: 2.939,6.362,2.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.675 | Acc: 2.934,7.012,2.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.660 | Acc: 2.946,7.313,2.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.661 | Acc: 2.922,7.446,2.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.649 | Acc: 3.063,7.225,2.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.648 | Acc: 3.054,7.322,2.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.634 | Acc: 3.103,7.408,2.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.630 | Acc: 3.178,7.449,2.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.624 | Acc: 3.207,7.497,2.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.618 | Acc: 3.168,7.517,2.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.612 | Acc: 3.185,7.533,2.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.609 | Acc: 3.235,7.527,2.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.602 | Acc: 3.287,7.591,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.603 | Acc: 3.306,7.582,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.599 | Acc: 3.335,7.589,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.594 | Acc: 3.366,7.596,2.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.588 | Acc: 3.388,7.638,2.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.584 | Acc: 3.365,7.715,2.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.577 | Acc: 3.392,7.812,2.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.235 | Acc: 3.125,6.250,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.694 | Acc: 2.827,6.994,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.688 | Acc: 2.934,7.050,2.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.690 | Acc: 2.843,6.954,2.036,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 12.478 | Acc: 2.344,4.688,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.428 | Acc: 2.976,8.631,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.438 | Acc: 3.068,8.213,2.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.437 | Acc: 3.240,8.491,2.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.443 | Acc: 3.328,8.873,2.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.437 | Acc: 3.295,8.942,2.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.417 | Acc: 3.403,9.130,2.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.405 | Acc: 3.430,9.225,2.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.400 | Acc: 3.440,9.249,2.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.393 | Acc: 3.427,9.297,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.397 | Acc: 3.432,9.274,2.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.395 | Acc: 3.549,9.386,2.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.398 | Acc: 3.540,9.433,2.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.394 | Acc: 3.550,9.426,2.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.389 | Acc: 3.567,9.453,2.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.382 | Acc: 3.553,9.518,2.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.378 | Acc: 3.529,9.533,2.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.372 | Acc: 3.521,9.622,2.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.366 | Acc: 3.521,9.702,2.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.363 | Acc: 3.543,9.752,2.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.929 | Acc: 10.156,9.375,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.302 | Acc: 4.129,9.115,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.275 | Acc: 4.249,9.470,2.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.281 | Acc: 4.188,9.170,1.972,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 12.454 | Acc: 4.688,7.031,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.264 | Acc: 4.055,11.496,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.269 | Acc: 3.849,11.185,2.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.248 | Acc: 3.919,11.219,2.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.253 | Acc: 3.858,10.658,2.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.257 | Acc: 3.775,10.528,2.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.249 | Acc: 3.764,10.492,2.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.231 | Acc: 3.734,10.727,2.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.221 | Acc: 3.751,10.782,2.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.205 | Acc: 3.798,10.963,2.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.200 | Acc: 3.817,11.046,2.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.201 | Acc: 3.775,10.983,2.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.199 | Acc: 3.747,10.970,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.194 | Acc: 3.709,11.024,2.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.192 | Acc: 3.642,11.146,2.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.187 | Acc: 3.649,11.202,2.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.180 | Acc: 3.656,11.337,2.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.174 | Acc: 3.700,11.382,2.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.168 | Acc: 3.683,11.420,2.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.167 | Acc: 3.672,11.452,2.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.434 | Acc: 4.688,13.281,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.603 | Acc: 2.902,8.073,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.579 | Acc: 3.011,8.365,2.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.569 | Acc: 3.112,8.491,2.036,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 12.051 | Acc: 0.781,12.500,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.084 | Acc: 3.869,11.682,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.102 | Acc: 4.078,11.452,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.071 | Acc: 3.945,11.911,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.061 | Acc: 3.752,12.307,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.041 | Acc: 3.736,12.523,2.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.037 | Acc: 3.855,12.410,2.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.027 | Acc: 3.829,12.616,2.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.021 | Acc: 3.785,12.699,2.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.013 | Acc: 3.842,12.906,2.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.009 | Acc: 3.875,12.924,2.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.004 | Acc: 3.871,13.097,2.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.007 | Acc: 3.822,13.074,2.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.006 | Acc: 3.819,13.159,2.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.001 | Acc: 3.795,13.203,2.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.999 | Acc: 3.789,13.167,2.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.993 | Acc: 3.787,13.199,2.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.991 | Acc: 3.799,13.251,2.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.984 | Acc: 3.807,13.363,2.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.979 | Acc: 3.775,13.433,2.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.004 | Acc: 3.125,10.938,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.184 | Acc: 2.827,13.058,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.172 | Acc: 2.649,12.767,2.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.164 | Acc: 2.766,12.679,2.126,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 11.810 | Acc: 3.906,14.062,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.890 | Acc: 3.237,14.025,2.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.834 | Acc: 3.887,14.768,2.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.840 | Acc: 3.522,14.844,2.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.842 | Acc: 3.665,15.123,2.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.861 | Acc: 3.636,14.782,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.868 | Acc: 3.725,14.837,2.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.863 | Acc: 3.757,14.949,2.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.860 | Acc: 3.741,14.921,2.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.850 | Acc: 3.747,15.098,2.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.845 | Acc: 3.782,15.225,2.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.838 | Acc: 3.779,15.282,2.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.834 | Acc: 3.819,15.246,2.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.824 | Acc: 3.822,15.386,2.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.819 | Acc: 3.817,15.467,2.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.818 | Acc: 3.805,15.521,2.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.810 | Acc: 3.858,15.710,2.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.809 | Acc: 3.831,15.781,2.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.804 | Acc: 3.820,15.753,2.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.798 | Acc: 3.828,15.822,2.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.228 | Acc: 2.344,10.938,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.345 | Acc: 3.683,9.673,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.342 | Acc: 3.411,9.318,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.342 | Acc: 3.637,9.362,2.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 11.962 | Acc: 4.688,15.625,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.729 | Acc: 4.241,16.927,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.696 | Acc: 3.925,16.711,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.683 | Acc: 4.047,16.739,2.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.702 | Acc: 3.897,16.792,2.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.698 | Acc: 3.891,16.979,2.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.696 | Acc: 3.816,17.065,2.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.700 | Acc: 3.829,17.160,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.685 | Acc: 3.867,17.289,2.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.675 | Acc: 3.833,17.386,2.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.676 | Acc: 3.774,17.335,2.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.672 | Acc: 3.751,17.297,2.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.666 | Acc: 3.825,17.317,2.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.672 | Acc: 3.751,17.250,2.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.666 | Acc: 3.764,17.263,2.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.664 | Acc: 3.821,17.299,2.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.662 | Acc: 3.819,17.334,2.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.662 | Acc: 3.874,17.398,2.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.659 | Acc: 3.859,17.443,2.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.657 | Acc: 3.906,17.468,2.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.494 | Acc: 6.250,22.656,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.963 | Acc: 3.348,16.332,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.929 | Acc: 3.544,16.330,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.934 | Acc: 3.458,16.201,2.254,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 11.889 | Acc: 3.125,21.094,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.581 | Acc: 4.725,19.978,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.589 | Acc: 4.173,19.474,2.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.592 | Acc: 4.175,19.057,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.591 | Acc: 4.186,18.702,2.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.615 | Acc: 4.192,18.502,2.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.616 | Acc: 4.081,18.492,2.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.612 | Acc: 4.095,18.512,2.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.604 | Acc: 4.134,18.614,2.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.604 | Acc: 4.109,18.694,2.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.603 | Acc: 4.077,18.769,2.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.601 | Acc: 4.122,18.775,2.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.598 | Acc: 4.179,18.750,2.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.595 | Acc: 4.206,18.861,2.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.589 | Acc: 4.290,18.928,2.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.589 | Acc: 4.327,19.020,2.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.584 | Acc: 4.318,19.049,2.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.573 | Acc: 4.346,19.089,2.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.565 | Acc: 4.363,19.146,2.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.559 | Acc: 4.353,19.238,2.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.736 | Acc: 3.906,20.312,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.943 | Acc: 4.167,14.137,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.968 | Acc: 4.230,13.891,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.957 | Acc: 4.559,13.730,2.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 11.529 | Acc: 4.688,17.969,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.349 | Acc: 5.692,21.280,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.370 | Acc: 5.335,20.808,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.386 | Acc: 5.020,20.799,2.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.382 | Acc: 5.324,20.689,2.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.427 | Acc: 5.353,20.715,2.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.459 | Acc: 5.398,20.461,2.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.477 | Acc: 5.341,20.324,2.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.472 | Acc: 5.459,20.424,2.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.467 | Acc: 5.590,20.498,2.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.467 | Acc: 5.671,20.433,2.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.465 | Acc: 5.681,20.426,2.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.465 | Acc: 5.728,20.462,2.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.465 | Acc: 5.777,20.432,2.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.459 | Acc: 5.861,20.499,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.457 | Acc: 5.946,20.569,2.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.456 | Acc: 6.070,20.614,2.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.452 | Acc: 6.115,20.585,2.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.447 | Acc: 6.194,20.680,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.445 | Acc: 6.205,20.671,2.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.681 | Acc: 7.031,24.219,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.747 | Acc: 6.101,18.415,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.741 | Acc: 6.136,18.579,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.746 | Acc: 5.994,18.340,2.344,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 11.419 | Acc: 8.594,21.094,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.403 | Acc: 7.106,19.643,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.355 | Acc: 7.127,20.332,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.304 | Acc: 7.492,21.158,2.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.286 | Acc: 7.706,21.267,2.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.298 | Acc: 7.611,21.233,2.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.298 | Acc: 7.483,21.281,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.290 | Acc: 7.486,21.376,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.289 | Acc: 7.638,21.535,2.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.289 | Acc: 7.575,21.517,2.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.284 | Acc: 7.603,21.572,2.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.272 | Acc: 7.699,21.613,2.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.259 | Acc: 7.809,21.674,2.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.251 | Acc: 7.926,21.677,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.241 | Acc: 8.077,21.739,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.235 | Acc: 8.150,21.859,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.227 | Acc: 8.204,21.924,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.223 | Acc: 8.243,21.914,2.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.215 | Acc: 8.332,22.035,2.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.209 | Acc: 8.362,22.041,2.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.741 | Acc: 10.938,15.625,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.715 | Acc: 7.180,15.067,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.721 | Acc: 7.660,15.454,2.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.722 | Acc: 7.608,15.676,2.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 11.288 | Acc: 10.938,23.438,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.009 | Acc: 9.933,23.140,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.012 | Acc: 9.585,23.438,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.013 | Acc: 9.913,23.092,3.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.016 | Acc: 9.742,23.148,3.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.020 | Acc: 9.785,23.213,2.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.010 | Acc: 10.008,23.399,3.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.000 | Acc: 10.178,23.526,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.007 | Acc: 10.093,23.331,2.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.002 | Acc: 10.061,23.355,2.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.989 | Acc: 10.055,23.185,2.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.979 | Acc: 10.209,23.190,3.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.971 | Acc: 10.250,23.181,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.969 | Acc: 10.276,23.237,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.960 | Acc: 10.348,23.343,2.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.951 | Acc: 10.447,23.412,2.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.949 | Acc: 10.529,23.347,2.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.939 | Acc: 10.592,23.373,2.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.934 | Acc: 10.691,23.392,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.924 | Acc: 10.790,23.440,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.279 | Acc: 3.906,17.969,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.424 | Acc: 2.753,17.969,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.505 | Acc: 2.934,18.121,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.546 | Acc: 2.856,17.367,2.395,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 11.051 | Acc: 14.062,27.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.773 | Acc: 13.095,23.847,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.775 | Acc: 13.129,23.914,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.761 | Acc: 13.025,24.155,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.715 | Acc: 13.407,24.315,3.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.716 | Acc: 13.537,24.118,2.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.722 | Acc: 13.488,23.993,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.709 | Acc: 13.520,24.041,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.691 | Acc: 13.747,24.355,3.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.695 | Acc: 13.670,24.353,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.709 | Acc: 13.658,24.421,2.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.720 | Acc: 13.716,24.378,2.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.725 | Acc: 13.803,24.501,2.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.726 | Acc: 13.874,24.479,2.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.723 | Acc: 13.929,24.530,2.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.723 | Acc: 14.000,24.502,2.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.715 | Acc: 14.167,24.489,2.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.713 | Acc: 14.225,24.517,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.711 | Acc: 14.266,24.485,2.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.707 | Acc: 14.362,24.543,2.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.833 | Acc: 16.406,24.219,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.001 | Acc: 12.388,21.652,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.981 | Acc: 12.081,21.818,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.982 | Acc: 12.334,21.504,2.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 10.969 | Acc: 13.281,25.000,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.642 | Acc: 15.885,24.256,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.603 | Acc: 16.559,24.752,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.597 | Acc: 16.688,25.205,2.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.583 | Acc: 16.657,25.579,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.569 | Acc: 16.669,25.634,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.551 | Acc: 16.845,25.852,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.554 | Acc: 16.994,25.582,2.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.552 | Acc: 17.183,25.631,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.541 | Acc: 17.360,25.742,2.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.533 | Acc: 17.347,25.707,2.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.524 | Acc: 17.484,25.661,2.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.524 | Acc: 17.512,25.545,2.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.510 | Acc: 17.675,25.700,2.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.507 | Acc: 17.730,25.745,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.501 | Acc: 17.803,25.820,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.495 | Acc: 17.852,25.823,2.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.482 | Acc: 18.049,25.942,2.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.472 | Acc: 18.189,25.961,2.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.467 | Acc: 18.276,25.986,2.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.720 | Acc: 17.969,18.750,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.956 | Acc: 15.848,20.312,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.997 | Acc: 15.568,19.512,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.986 | Acc: 15.779,19.749,2.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 10.352 | Acc: 17.969,24.219,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.184 | Acc: 21.243,27.641,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.240 | Acc: 20.846,26.810,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.226 | Acc: 20.774,27.126,2.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.223 | Acc: 20.669,27.614,2.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.214 | Acc: 20.738,27.614,2.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.220 | Acc: 20.603,27.324,2.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.221 | Acc: 20.601,27.233,2.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.232 | Acc: 20.458,27.179,2.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.223 | Acc: 20.615,27.503,2.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.218 | Acc: 20.888,27.503,2.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.206 | Acc: 21.101,27.524,2.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.212 | Acc: 21.142,27.464,2.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.207 | Acc: 21.237,27.502,2.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.199 | Acc: 21.155,27.419,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.192 | Acc: 21.262,27.318,2.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.196 | Acc: 21.245,27.220,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.190 | Acc: 21.224,27.177,2.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.180 | Acc: 21.332,27.322,2.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.176 | Acc: 21.389,27.311,2.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.337 | Acc: 18.750,23.438,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.555 | Acc: 17.150,22.396,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.564 | Acc: 17.969,22.713,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.579 | Acc: 17.649,22.784,2.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 9.998 | Acc: 21.875,31.250,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.986 | Acc: 23.810,30.134,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.983 | Acc: 23.323,29.878,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.020 | Acc: 23.348,29.355,2.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.026 | Acc: 23.293,28.974,2.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.026 | Acc: 23.159,29.030,2.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.008 | Acc: 23.128,29.119,2.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.996 | Acc: 23.255,29.106,2.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.973 | Acc: 23.345,29.304,2.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.973 | Acc: 23.230,29.282,2.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.964 | Acc: 23.364,29.287,2.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.972 | Acc: 23.310,29.182,2.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.970 | Acc: 23.311,29.162,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.968 | Acc: 23.438,29.149,2.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.972 | Acc: 23.410,29.056,2.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.971 | Acc: 23.471,29.075,2.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.972 | Acc: 23.566,29.106,2.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.969 | Acc: 23.584,29.115,2.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.978 | Acc: 23.526,29.023,2.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.977 | Acc: 23.524,29.013,2.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.544 | Acc: 15.625,17.969,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.972 | Acc: 14.955,15.439,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.976 | Acc: 14.787,15.758,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.982 | Acc: 14.588,15.407,2.241,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 10.115 | Acc: 28.906,32.031,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.994 | Acc: 24.926,28.795,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.958 | Acc: 25.076,29.059,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.910 | Acc: 25.295,29.636,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.929 | Acc: 24.826,29.360,2.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.928 | Acc: 25.008,29.602,2.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.922 | Acc: 25.019,29.836,2.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.928 | Acc: 24.950,29.748,2.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.934 | Acc: 24.874,29.590,2.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.934 | Acc: 24.758,29.567,2.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.938 | Acc: 24.759,29.435,2.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.936 | Acc: 24.770,29.589,2.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.927 | Acc: 24.896,29.613,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.930 | Acc: 24.883,29.487,2.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.924 | Acc: 24.883,29.596,2.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.916 | Acc: 24.951,29.675,2.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.914 | Acc: 24.993,29.583,2.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.911 | Acc: 24.989,29.454,2.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.902 | Acc: 25.076,29.584,2.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.895 | Acc: 25.113,29.663,2.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.202 | Acc: 25.000,25.781,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.700 | Acc: 21.131,21.391,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.676 | Acc: 20.694,21.284,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.689 | Acc: 20.645,21.388,2.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 9.589 | Acc: 24.219,22.656,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.740 | Acc: 26.190,30.655,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.761 | Acc: 25.400,30.583,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.759 | Acc: 25.231,30.507,2.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.741 | Acc: 25.820,30.874,2.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.760 | Acc: 25.627,30.577,2.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.751 | Acc: 25.872,30.746,2.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.753 | Acc: 25.826,30.729,2.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.755 | Acc: 25.820,30.886,2.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.739 | Acc: 25.924,30.991,2.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.727 | Acc: 26.061,30.947,2.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.725 | Acc: 26.121,30.946,2.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.717 | Acc: 26.297,31.013,2.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.712 | Acc: 26.365,31.103,2.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.708 | Acc: 26.365,31.108,2.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.695 | Acc: 26.428,31.227,2.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.691 | Acc: 26.436,31.296,2.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.690 | Acc: 26.514,31.330,2.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.690 | Acc: 26.506,31.304,2.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.691 | Acc: 26.470,31.305,2.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.112 | Acc: 23.438,26.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.603 | Acc: 18.676,25.409,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.602 | Acc: 18.655,25.400,1.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.606 | Acc: 18.763,24.757,1.755,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 9.903 | Acc: 23.438,27.344,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.597 | Acc: 26.935,31.734,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.703 | Acc: 27.439,31.764,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.739 | Acc: 27.613,31.865,2.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.749 | Acc: 27.344,31.877,2.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.754 | Acc: 27.576,31.915,2.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.726 | Acc: 27.828,32.270,2.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.754 | Acc: 27.610,31.970,2.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.748 | Acc: 27.582,32.041,2.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.748 | Acc: 27.357,31.936,2.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.766 | Acc: 27.219,31.919,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.762 | Acc: 27.259,32.031,2.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.751 | Acc: 27.279,31.999,2.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.742 | Acc: 27.407,32.124,2.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.740 | Acc: 27.294,32.129,2.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.727 | Acc: 27.289,32.262,2.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.721 | Acc: 27.461,32.389,2.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.717 | Acc: 27.527,32.407,2.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.708 | Acc: 27.601,32.611,2.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.707 | Acc: 27.684,32.607,2.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.520 | Acc: 21.875,18.750,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.723 | Acc: 17.820,17.113,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.801 | Acc: 17.969,17.473,2.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.794 | Acc: 17.943,17.418,2.190,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 9.435 | Acc: 23.438,30.469,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.607 | Acc: 26.711,32.478,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.582 | Acc: 28.087,33.670,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.561 | Acc: 28.023,33.594,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.564 | Acc: 28.164,33.603,2.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.576 | Acc: 27.924,33.222,2.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.570 | Acc: 28.086,33.348,2.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.562 | Acc: 28.219,33.355,2.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.554 | Acc: 28.339,33.487,2.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.559 | Acc: 28.332,33.615,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.556 | Acc: 28.327,33.590,2.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.557 | Acc: 28.203,33.573,2.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.557 | Acc: 28.248,33.555,2.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.553 | Acc: 28.260,33.522,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.541 | Acc: 28.403,33.663,2.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.541 | Acc: 28.444,33.703,2.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.536 | Acc: 28.514,33.776,2.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.538 | Acc: 28.489,33.841,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.537 | Acc: 28.486,33.834,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.531 | Acc: 28.556,33.877,2.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.575 | Acc: 29.688,39.062,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.793 | Acc: 25.335,31.622,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.845 | Acc: 24.657,31.784,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.834 | Acc: 24.846,31.532,2.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 9.559 | Acc: 28.906,32.031,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.512 | Acc: 28.609,34.077,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.477 | Acc: 28.182,34.165,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.411 | Acc: 28.881,35.028,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.389 | Acc: 29.311,35.282,2.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.394 | Acc: 29.502,35.357,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.407 | Acc: 29.326,35.008,2.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.397 | Acc: 29.494,35.295,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.399 | Acc: 29.489,35.248,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.395 | Acc: 29.498,35.333,2.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.385 | Acc: 29.610,35.409,2.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.376 | Acc: 29.610,35.478,2.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.367 | Acc: 29.739,35.545,2.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.376 | Acc: 29.586,35.527,2.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.384 | Acc: 29.479,35.398,2.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.387 | Acc: 29.412,35.364,2.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.380 | Acc: 29.566,35.480,2.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.383 | Acc: 29.484,35.463,2.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.381 | Acc: 29.417,35.459,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.382 | Acc: 29.448,35.484,2.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.617 | Acc: 28.906,28.125,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.084 | Acc: 26.488,26.860,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.136 | Acc: 26.048,26.105,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.115 | Acc: 26.037,25.717,2.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 9.664 | Acc: 24.219,30.469,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.375 | Acc: 29.427,35.342,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.362 | Acc: 29.287,36.052,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.336 | Acc: 29.713,36.501,2.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.313 | Acc: 29.851,36.796,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.291 | Acc: 30.159,36.781,2.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.293 | Acc: 29.881,36.751,2.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.278 | Acc: 30.158,36.940,2.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.281 | Acc: 30.027,36.772,2.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.275 | Acc: 30.007,36.671,2.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.268 | Acc: 30.033,36.711,2.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.257 | Acc: 30.158,36.878,2.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.248 | Acc: 30.371,37.027,2.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.248 | Acc: 30.289,37.030,2.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.242 | Acc: 30.316,37.047,2.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.240 | Acc: 30.419,36.999,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.236 | Acc: 30.520,37.045,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.240 | Acc: 30.434,36.994,2.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.241 | Acc: 30.421,37.009,2.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.240 | Acc: 30.430,37.055,2.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.084 | Acc: 23.438,31.250,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.028 | Acc: 23.921,30.580,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.036 | Acc: 23.742,30.126,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.020 | Acc: 23.988,30.507,2.933,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 8.831 | Acc: 32.812,39.844,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.006 | Acc: 33.445,40.104,3.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.084 | Acc: 31.898,38.739,3.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.092 | Acc: 31.660,38.012,3.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.091 | Acc: 31.588,38.243,3.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.109 | Acc: 31.459,38.250,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.117 | Acc: 31.224,38.126,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.119 | Acc: 31.305,38.231,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.116 | Acc: 31.420,38.242,2.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.120 | Acc: 31.401,38.234,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.124 | Acc: 31.374,38.172,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.119 | Acc: 31.370,38.211,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.132 | Acc: 31.321,38.161,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.132 | Acc: 31.262,38.144,2.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.121 | Acc: 31.389,38.278,2.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.113 | Acc: 31.450,38.364,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.111 | Acc: 31.474,38.418,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.114 | Acc: 31.408,38.382,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.112 | Acc: 31.436,38.446,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.115 | Acc: 31.385,38.472,2.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.942 | Acc: 23.438,28.125,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.115 | Acc: 19.940,27.753,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.138 | Acc: 20.141,28.144,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.127 | Acc: 20.556,28.317,2.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 8.702 | Acc: 37.500,40.625,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.946 | Acc: 33.036,40.141,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.959 | Acc: 32.870,40.168,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.946 | Acc: 33.133,39.690,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.962 | Acc: 33.179,40.037,2.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.962 | Acc: 33.075,40.308,2.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.005 | Acc: 32.451,39.695,2.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.018 | Acc: 32.386,39.578,2.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.033 | Acc: 32.138,39.494,2.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.045 | Acc: 31.958,39.421,2.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.046 | Acc: 31.996,39.346,2.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.030 | Acc: 32.074,39.504,2.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.024 | Acc: 32.122,39.500,2.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.025 | Acc: 32.022,39.338,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.022 | Acc: 32.045,39.254,2.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.022 | Acc: 32.010,39.156,2.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.021 | Acc: 31.985,39.150,2.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.017 | Acc: 32.015,39.202,2.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.012 | Acc: 32.055,39.305,2.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.011 | Acc: 32.068,39.288,2.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.269 | Acc: 28.906,36.719,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.393 | Acc: 28.162,36.124,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.447 | Acc: 26.715,36.280,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.456 | Acc: 26.524,36.565,2.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 8.977 | Acc: 30.469,39.844,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.918 | Acc: 32.924,40.141,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.879 | Acc: 33.479,40.968,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.896 | Acc: 33.120,40.830,2.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.873 | Acc: 33.343,40.876,2.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.878 | Acc: 33.230,40.950,2.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.879 | Acc: 33.239,40.877,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.880 | Acc: 33.101,40.747,2.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.877 | Acc: 33.264,40.892,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.884 | Acc: 33.102,41.009,2.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.895 | Acc: 32.976,40.932,2.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.892 | Acc: 32.968,40.982,2.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.906 | Acc: 32.738,40.716,2.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.911 | Acc: 32.747,40.661,2.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.903 | Acc: 32.840,40.839,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.906 | Acc: 32.859,40.770,2.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.905 | Acc: 32.868,40.705,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.904 | Acc: 32.863,40.762,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.906 | Acc: 32.806,40.670,2.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.909 | Acc: 32.716,40.658,2.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.553 | Acc: 19.531,26.562,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.679 | Acc: 18.973,28.088,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.648 | Acc: 19.436,28.068,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.661 | Acc: 18.929,27.638,2.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 8.719 | Acc: 33.594,39.844,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.785 | Acc: 34.301,42.448,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.852 | Acc: 33.822,42.359,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.937 | Acc: 33.517,42.034,2.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.000 | Acc: 33.034,41.522,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.003 | Acc: 33.114,41.631,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.012 | Acc: 32.961,41.878,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.024 | Acc: 33.139,41.894,2.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.040 | Acc: 33.118,41.843,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.037 | Acc: 33.141,41.894,2.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.040 | Acc: 33.170,41.783,2.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.045 | Acc: 33.184,41.696,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.048 | Acc: 33.257,41.627,2.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.050 | Acc: 33.261,41.583,2.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.048 | Acc: 33.252,41.634,2.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.057 | Acc: 33.178,41.531,2.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.053 | Acc: 33.131,41.564,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.056 | Acc: 33.085,41.473,2.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.054 | Acc: 33.057,41.419,2.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.045 | Acc: 33.100,41.550,2.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.073 | Acc: 25.781,31.250,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.260 | Acc: 25.484,29.390,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.307 | Acc: 25.781,29.592,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.290 | Acc: 25.653,29.944,2.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 8.964 | Acc: 32.031,44.531,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.964 | Acc: 32.143,41.927,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.992 | Acc: 33.060,41.978,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.973 | Acc: 33.414,42.200,2.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.965 | Acc: 33.430,42.245,2.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.964 | Acc: 33.795,42.652,2.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.960 | Acc: 33.891,42.556,2.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.950 | Acc: 34.009,42.581,2.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.942 | Acc: 34.069,42.639,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.953 | Acc: 33.978,42.528,2.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.954 | Acc: 34.010,42.378,2.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.951 | Acc: 34.029,42.410,2.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.955 | Acc: 34.022,42.372,2.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.956 | Acc: 33.998,42.400,2.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.961 | Acc: 33.905,42.363,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.966 | Acc: 33.791,42.182,2.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.963 | Acc: 33.788,42.217,2.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.956 | Acc: 33.866,42.275,2.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.957 | Acc: 33.819,42.298,2.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.957 | Acc: 33.821,42.263,2.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.520 | Acc: 28.125,32.031,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.205 | Acc: 25.484,29.576,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.270 | Acc: 25.133,29.707,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.276 | Acc: 25.128,29.444,2.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 8.600 | Acc: 37.500,45.312,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.915 | Acc: 35.603,42.411,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.866 | Acc: 34.947,42.854,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.853 | Acc: 34.734,43.494,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.868 | Acc: 34.356,43.258,2.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.883 | Acc: 34.135,43.000,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.863 | Acc: 34.233,43.253,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.858 | Acc: 34.225,43.285,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.866 | Acc: 33.963,42.988,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.862 | Acc: 34.202,43.180,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.863 | Acc: 34.188,43.299,2.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.873 | Acc: 34.128,43.202,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.874 | Acc: 33.980,43.222,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.878 | Acc: 33.956,43.157,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.875 | Acc: 34.000,43.194,2.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.873 | Acc: 34.017,43.223,2.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.861 | Acc: 34.078,43.309,2.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.853 | Acc: 34.178,43.406,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.845 | Acc: 34.260,43.490,2.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.839 | Acc: 34.326,43.512,2.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.840 | Acc: 25.781,35.938,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.596 | Acc: 26.935,37.165,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.608 | Acc: 27.115,36.204,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.610 | Acc: 26.844,36.309,2.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 9.018 | Acc: 33.594,41.406,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.754 | Acc: 34.747,44.345,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.742 | Acc: 34.718,44.379,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.753 | Acc: 34.862,44.224,3.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.725 | Acc: 35.166,44.753,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.755 | Acc: 34.638,44.315,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.769 | Acc: 34.433,44.131,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.767 | Acc: 34.541,44.454,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.770 | Acc: 34.593,44.517,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.776 | Acc: 34.625,44.372,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.776 | Acc: 34.620,44.504,2.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.784 | Acc: 34.545,44.354,2.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.796 | Acc: 34.537,44.262,2.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.794 | Acc: 34.594,44.337,2.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.789 | Acc: 34.636,44.473,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.783 | Acc: 34.694,44.498,2.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.783 | Acc: 34.721,44.487,2.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.789 | Acc: 34.700,44.483,2.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.782 | Acc: 34.884,44.551,2.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.777 | Acc: 34.881,44.585,2.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.940 | Acc: 17.188,29.688,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.933 | Acc: 20.089,30.952,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.028 | Acc: 20.198,30.564,2.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.029 | Acc: 19.839,30.328,2.126,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 8.880 | Acc: 36.719,42.188,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.693 | Acc: 35.454,44.978,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.719 | Acc: 35.213,44.722,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.677 | Acc: 35.669,45.415,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.682 | Acc: 35.503,45.631,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.692 | Acc: 35.504,45.398,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.706 | Acc: 35.260,45.061,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.695 | Acc: 35.489,45.229,2.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.693 | Acc: 35.569,45.162,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.707 | Acc: 35.471,45.032,2.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.706 | Acc: 35.424,45.138,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.705 | Acc: 35.375,45.132,2.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.697 | Acc: 35.419,45.163,2.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.711 | Acc: 35.285,45.103,2.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.718 | Acc: 35.051,45.015,2.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.726 | Acc: 34.959,44.944,2.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.730 | Acc: 34.959,44.930,2.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.729 | Acc: 34.982,44.955,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.725 | Acc: 35.016,45.035,2.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.721 | Acc: 35.125,45.044,2.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.805 | Acc: 25.000,35.938,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.943 | Acc: 22.284,32.254,1.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.986 | Acc: 21.856,31.517,1.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.955 | Acc: 22.131,31.442,1.383,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 8.327 | Acc: 37.500,54.688,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.651 | Acc: 36.756,46.726,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.685 | Acc: 35.537,45.503,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.669 | Acc: 35.681,46.196,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.683 | Acc: 35.465,45.727,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.683 | Acc: 35.605,45.823,3.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.679 | Acc: 35.841,45.855,3.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.683 | Acc: 35.705,45.656,3.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.684 | Acc: 35.544,45.744,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.692 | Acc: 35.471,45.628,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.682 | Acc: 35.506,45.752,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.688 | Acc: 35.354,45.645,3.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.673 | Acc: 35.510,45.812,3.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.668 | Acc: 35.536,45.821,3.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.667 | Acc: 35.504,45.805,3.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.668 | Acc: 35.421,45.793,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.670 | Acc: 35.358,45.753,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.665 | Acc: 35.427,45.794,2.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.664 | Acc: 35.409,45.819,2.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.664 | Acc: 35.411,45.825,3.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.251 | Acc: 31.250,44.531,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.382 | Acc: 30.097,39.435,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.388 | Acc: 29.649,38.110,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.340 | Acc: 29.688,38.858,2.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 8.388 | Acc: 38.281,50.781,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.508 | Acc: 36.310,47.061,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.528 | Acc: 36.128,46.284,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.519 | Acc: 36.591,46.913,3.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.528 | Acc: 36.487,47.058,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.538 | Acc: 36.518,46.999,2.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.552 | Acc: 36.377,46.914,2.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.568 | Acc: 36.292,46.875,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.567 | Acc: 36.418,46.875,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.575 | Acc: 36.451,46.681,2.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.579 | Acc: 36.396,46.673,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.568 | Acc: 36.415,46.734,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.571 | Acc: 36.437,46.544,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.573 | Acc: 36.392,46.528,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.565 | Acc: 36.393,46.644,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.569 | Acc: 36.379,46.660,2.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.571 | Acc: 36.327,46.624,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.570 | Acc: 36.240,46.678,2.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.582 | Acc: 36.046,46.496,2.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.584 | Acc: 36.040,46.436,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.305 | Acc: 21.094,38.281,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.210 | Acc: 25.260,31.957,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.282 | Acc: 24.581,31.002,3.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.267 | Acc: 24.488,30.584,3.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 8.869 | Acc: 39.062,42.188,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.416 | Acc: 36.607,48.028,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.435 | Acc: 36.662,48.380,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.437 | Acc: 36.591,48.655,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.436 | Acc: 36.622,48.717,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.477 | Acc: 36.278,48.151,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.499 | Acc: 36.002,47.953,2.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.494 | Acc: 36.109,47.784,2.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.495 | Acc: 36.098,47.714,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.490 | Acc: 36.179,47.691,2.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.487 | Acc: 36.326,47.746,2.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.487 | Acc: 36.351,47.695,2.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.503 | Acc: 36.203,47.569,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.505 | Acc: 36.207,47.480,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.512 | Acc: 36.196,47.381,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.512 | Acc: 36.117,47.324,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.517 | Acc: 36.037,47.243,2.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.512 | Acc: 36.098,47.317,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.511 | Acc: 36.158,47.295,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.513 | Acc: 36.268,47.252,2.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.789 | Acc: 28.906,35.938,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.777 | Acc: 26.004,36.384,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.865 | Acc: 25.553,35.328,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.838 | Acc: 25.781,35.348,3.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 8.473 | Acc: 32.812,44.531,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.448 | Acc: 35.565,47.991,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.372 | Acc: 37.595,49.200,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.398 | Acc: 37.513,48.770,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.408 | Acc: 37.413,48.621,2.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.390 | Acc: 37.407,49.025,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.404 | Acc: 37.145,48.896,2.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.419 | Acc: 36.929,48.665,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.439 | Acc: 36.743,48.282,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.448 | Acc: 36.732,48.243,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.454 | Acc: 36.762,48.177,2.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.451 | Acc: 36.860,48.204,2.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.447 | Acc: 36.829,48.188,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.449 | Acc: 36.797,48.180,2.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.457 | Acc: 36.708,48.054,2.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.463 | Acc: 36.625,48.012,2.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.463 | Acc: 36.563,47.953,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.465 | Acc: 36.556,47.968,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.468 | Acc: 36.472,47.944,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.469 | Acc: 36.452,47.921,2.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.975 | Acc: 23.438,44.531,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.283 | Acc: 21.801,37.091,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.304 | Acc: 21.494,36.662,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.290 | Acc: 21.542,36.936,2.984,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 8.497 | Acc: 35.938,46.875,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.531 | Acc: 36.310,47.693,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.472 | Acc: 36.471,47.961,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.481 | Acc: 36.258,48.386,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.469 | Acc: 36.478,48.592,3.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.430 | Acc: 36.819,48.979,3.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.427 | Acc: 36.977,48.928,3.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.421 | Acc: 37.107,49.080,3.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.419 | Acc: 37.005,49.030,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.420 | Acc: 37.038,49.016,2.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.424 | Acc: 37.045,48.818,2.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.435 | Acc: 36.747,48.551,3.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.427 | Acc: 36.803,48.658,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.426 | Acc: 36.821,48.659,3.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.420 | Acc: 36.861,48.768,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.421 | Acc: 36.849,48.744,2.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.423 | Acc: 36.814,48.756,2.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.423 | Acc: 36.808,48.763,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.424 | Acc: 36.933,48.771,2.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.423 | Acc: 36.967,48.817,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.513 | Acc: 28.125,35.938,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.358 | Acc: 29.278,38.170,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.398 | Acc: 29.459,38.110,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.401 | Acc: 29.828,38.140,2.677,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 7.620 | Acc: 39.844,54.688,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.328 | Acc: 38.653,49.479,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.338 | Acc: 37.652,49.447,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.334 | Acc: 37.833,49.744,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.337 | Acc: 37.442,49.662,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.332 | Acc: 37.701,50.046,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.328 | Acc: 37.920,50.103,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.346 | Acc: 37.832,50.011,3.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.352 | Acc: 37.840,50.019,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.361 | Acc: 37.759,49.987,3.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.372 | Acc: 37.826,49.876,3.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.392 | Acc: 37.687,49.710,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.426 | Acc: 37.695,49.598,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.448 | Acc: 37.551,49.527,2.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.462 | Acc: 37.514,49.452,2.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.471 | Acc: 37.435,49.297,2.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.476 | Acc: 37.393,49.260,2.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.481 | Acc: 37.330,49.191,2.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.489 | Acc: 37.229,49.087,2.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.491 | Acc: 37.235,49.065,2.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.193 | Acc: 27.344,38.281,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.460 | Acc: 22.917,36.086,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.418 | Acc: 23.114,35.785,2.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.426 | Acc: 22.887,35.681,1.870,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 8.055 | Acc: 45.312,56.250,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.503 | Acc: 37.612,49.554,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.472 | Acc: 38.034,50.400,2.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.463 | Acc: 38.448,50.064,2.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.465 | Acc: 37.818,49.932,2.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.447 | Acc: 37.902,50.155,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.459 | Acc: 37.668,49.684,2.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.478 | Acc: 37.378,49.474,2.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.476 | Acc: 37.466,49.515,2.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.474 | Acc: 37.362,49.465,2.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.474 | Acc: 37.337,49.413,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.482 | Acc: 37.146,49.332,2.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.489 | Acc: 37.150,49.342,2.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.490 | Acc: 37.150,49.285,2.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.498 | Acc: 37.105,49.185,2.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.493 | Acc: 37.186,49.232,2.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.496 | Acc: 37.201,49.163,2.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.492 | Acc: 37.296,49.205,2.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.496 | Acc: 37.180,49.098,2.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.498 | Acc: 37.162,49.061,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.728 | Acc: 21.875,37.500,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.800 | Acc: 23.214,35.342,2.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.799 | Acc: 22.790,34.508,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.812 | Acc: 22.605,34.657,2.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 7.738 | Acc: 39.062,60.156,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.423 | Acc: 37.500,50.000,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.405 | Acc: 38.091,50.553,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.399 | Acc: 37.961,50.666,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.403 | Acc: 37.760,50.598,2.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.421 | Acc: 37.833,50.248,2.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.417 | Acc: 37.720,50.258,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.418 | Acc: 37.600,49.917,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.407 | Acc: 37.636,49.913,2.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.402 | Acc: 37.655,50.013,2.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.396 | Acc: 37.741,50.047,2.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.399 | Acc: 37.599,49.958,2.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.397 | Acc: 37.571,50.000,2.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.390 | Acc: 37.644,50.015,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.390 | Acc: 37.683,50.036,2.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.398 | Acc: 37.596,49.920,2.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.406 | Acc: 37.532,49.800,2.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.409 | Acc: 37.445,49.789,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.412 | Acc: 37.420,49.755,2.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.412 | Acc: 37.475,49.764,2.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.962 | Acc: 27.344,39.062,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.182 | Acc: 22.284,37.091,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.237 | Acc: 22.027,36.776,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.229 | Acc: 22.374,36.488,2.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 8.232 | Acc: 39.844,53.906,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.414 | Acc: 36.347,48.735,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.325 | Acc: 37.919,50.648,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.304 | Acc: 38.768,51.178,3.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.314 | Acc: 38.252,51.051,2.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.326 | Acc: 37.941,50.828,2.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.346 | Acc: 37.707,50.678,2.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.337 | Acc: 37.910,50.682,2.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.333 | Acc: 37.820,50.631,2.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.333 | Acc: 38.048,50.669,2.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.325 | Acc: 38.141,50.614,2.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.332 | Acc: 38.112,50.431,2.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.337 | Acc: 38.090,50.357,2.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.339 | Acc: 38.033,50.413,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.337 | Acc: 38.067,50.462,2.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.339 | Acc: 38.050,50.433,2.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.346 | Acc: 37.999,50.375,2.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.346 | Acc: 37.924,50.408,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.344 | Acc: 37.894,50.441,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.348 | Acc: 37.861,50.400,2.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.483 | Acc: 32.031,53.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.938 | Acc: 23.475,40.179,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.998 | Acc: 23.285,39.520,2.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.979 | Acc: 23.092,39.460,1.972,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 8.083 | Acc: 40.625,57.812,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.344 | Acc: 37.686,51.228,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.323 | Acc: 38.167,51.791,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.329 | Acc: 38.473,51.627,2.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.318 | Acc: 37.963,51.427,2.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.330 | Acc: 37.833,51.106,2.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.325 | Acc: 37.926,51.285,2.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.312 | Acc: 38.182,51.418,2.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.309 | Acc: 38.087,51.286,2.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.307 | Acc: 38.027,51.191,2.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.292 | Acc: 38.044,51.236,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.292 | Acc: 38.055,51.403,2.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.293 | Acc: 38.054,51.352,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.301 | Acc: 37.925,51.278,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.304 | Acc: 37.856,51.276,2.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.306 | Acc: 37.882,51.261,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.299 | Acc: 37.996,51.302,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.297 | Acc: 38.061,51.320,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.301 | Acc: 38.032,51.342,2.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.307 | Acc: 38.031,51.257,2.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.532 | Acc: 25.781,43.750,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.706 | Acc: 26.376,38.728,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.777 | Acc: 26.086,37.500,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.787 | Acc: 26.217,37.500,2.280,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 8.122 | Acc: 46.875,55.469,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.305 | Acc: 39.360,50.074,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.225 | Acc: 39.634,51.715,2.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.240 | Acc: 39.306,52.049,2.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.230 | Acc: 39.381,52.218,2.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.232 | Acc: 39.240,52.027,2.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.249 | Acc: 39.030,51.969,2.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.267 | Acc: 38.835,51.579,2.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.259 | Acc: 38.631,51.456,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.261 | Acc: 38.566,51.351,2.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.259 | Acc: 38.604,51.318,2.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.263 | Acc: 38.529,51.336,2.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.270 | Acc: 38.453,51.306,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.269 | Acc: 38.470,51.323,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.266 | Acc: 38.459,51.332,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.268 | Acc: 38.434,51.350,2.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.266 | Acc: 38.369,51.300,2.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.263 | Acc: 38.375,51.356,2.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.264 | Acc: 38.422,51.418,2.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.269 | Acc: 38.289,51.380,2.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.292 | Acc: 37.500,42.969,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.406 | Acc: 28.906,42.783,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.451 | Acc: 27.896,41.711,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.474 | Acc: 27.664,41.752,2.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 8.123 | Acc: 41.406,50.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.103 | Acc: 40.365,52.865,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.144 | Acc: 40.072,52.801,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.133 | Acc: 39.485,52.664,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.151 | Acc: 39.468,52.488,2.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.160 | Acc: 39.155,52.050,2.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.178 | Acc: 39.121,51.834,2.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.183 | Acc: 39.013,51.845,2.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.185 | Acc: 38.985,52.004,2.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.204 | Acc: 38.773,51.813,2.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.215 | Acc: 38.693,51.761,2.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.218 | Acc: 38.720,51.750,2.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.241 | Acc: 38.719,51.601,2.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.270 | Acc: 38.527,51.485,2.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.270 | Acc: 38.582,51.582,2.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.283 | Acc: 38.468,51.490,2.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.291 | Acc: 38.481,51.482,2.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.302 | Acc: 38.412,51.414,2.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.304 | Acc: 38.435,51.446,2.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.308 | Acc: 38.417,51.417,2.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.280 | Acc: 21.875,38.281,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.206 | Acc: 22.656,37.426,2.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.234 | Acc: 22.713,36.852,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.236 | Acc: 22.157,36.898,2.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 8.448 | Acc: 39.844,50.000,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.333 | Acc: 38.951,51.525,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.318 | Acc: 38.662,52.134,2.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.331 | Acc: 38.461,52.139,2.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.308 | Acc: 38.677,52.585,2.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.289 | Acc: 38.830,52.761,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.297 | Acc: 38.740,52.479,2.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.314 | Acc: 38.608,52.072,2.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.323 | Acc: 38.383,51.931,2.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.307 | Acc: 38.432,52.080,2.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.303 | Acc: 38.499,51.959,2.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.302 | Acc: 38.486,51.898,2.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.292 | Acc: 38.550,52.007,2.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.290 | Acc: 38.524,52.182,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.289 | Acc: 38.504,52.171,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.296 | Acc: 38.411,51.973,2.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.297 | Acc: 38.362,51.930,2.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.297 | Acc: 38.357,51.890,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.299 | Acc: 38.411,51.870,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.293 | Acc: 38.435,51.907,2.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.300 | Acc: 17.969,40.625,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.491 | Acc: 19.308,35.045,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.496 | Acc: 19.855,35.232,3.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.501 | Acc: 19.698,35.412,3.330,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 8.302 | Acc: 39.062,53.906,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.177 | Acc: 39.174,54.129,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.175 | Acc: 39.310,53.487,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.148 | Acc: 39.639,53.791,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.178 | Acc: 39.005,53.385,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.195 | Acc: 38.869,53.140,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.206 | Acc: 38.649,52.964,2.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.220 | Acc: 38.774,52.770,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.219 | Acc: 38.873,52.945,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.229 | Acc: 38.804,52.685,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.227 | Acc: 38.891,52.717,2.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.226 | Acc: 38.949,52.662,2.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.228 | Acc: 38.871,52.580,2.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.227 | Acc: 38.865,52.565,2.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.220 | Acc: 38.982,52.569,2.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.226 | Acc: 38.795,52.474,2.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.224 | Acc: 38.775,52.456,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.227 | Acc: 38.723,52.456,2.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.223 | Acc: 38.766,52.504,2.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.222 | Acc: 38.788,52.411,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.330 | Acc: 16.406,35.156,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.761 | Acc: 18.638,34.598,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.883 | Acc: 18.236,33.403,2.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.929 | Acc: 17.674,33.299,2.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 8.282 | Acc: 39.844,52.344,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.181 | Acc: 39.174,54.390,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.088 | Acc: 40.072,54.421,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.148 | Acc: 39.267,53.778,2.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.146 | Acc: 38.850,53.308,2.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.149 | Acc: 39.117,53.133,2.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.151 | Acc: 39.095,53.261,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.142 | Acc: 39.373,53.602,2.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.148 | Acc: 39.320,53.533,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.153 | Acc: 39.244,53.431,2.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.152 | Acc: 39.148,53.366,2.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.154 | Acc: 39.225,53.401,2.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.165 | Acc: 39.108,53.193,2.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.165 | Acc: 39.051,53.185,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.169 | Acc: 38.996,53.136,2.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.164 | Acc: 39.096,53.148,2.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.172 | Acc: 39.092,53.081,2.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.172 | Acc: 39.136,53.045,2.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.178 | Acc: 39.080,52.980,2.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.173 | Acc: 39.142,53.086,2.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.645 | Acc: 28.906,38.281,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.008 | Acc: 25.112,36.235,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.048 | Acc: 25.572,35.957,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.038 | Acc: 25.218,36.335,2.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 8.204 | Acc: 40.625,53.906,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.060 | Acc: 38.802,53.869,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.103 | Acc: 38.548,53.659,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.100 | Acc: 38.332,53.727,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.131 | Acc: 38.407,53.048,3.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.116 | Acc: 38.629,53.295,3.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.124 | Acc: 38.559,53.228,3.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.129 | Acc: 38.531,53.064,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.121 | Acc: 38.815,53.149,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.120 | Acc: 38.812,53.160,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.125 | Acc: 38.923,53.094,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.123 | Acc: 38.964,53.160,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.135 | Acc: 38.917,52.999,2.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.139 | Acc: 38.868,53.008,2.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.138 | Acc: 38.929,53.083,2.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.133 | Acc: 38.992,53.156,2.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.136 | Acc: 39.004,53.088,2.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.141 | Acc: 38.943,52.955,2.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.146 | Acc: 38.885,52.898,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.141 | Acc: 38.946,52.988,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.027 | Acc: 28.125,53.125,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.450 | Acc: 27.046,41.257,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.492 | Acc: 26.944,41.216,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.492 | Acc: 26.601,41.291,2.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 8.067 | Acc: 43.750,54.688,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.073 | Acc: 39.546,53.162,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.106 | Acc: 38.853,52.687,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.127 | Acc: 38.986,52.728,2.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.113 | Acc: 39.169,52.903,2.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.136 | Acc: 39.380,52.746,2.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.141 | Acc: 39.243,52.647,2.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.143 | Acc: 39.162,52.648,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.140 | Acc: 39.232,52.882,2.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.130 | Acc: 39.490,52.991,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.127 | Acc: 39.478,53.012,2.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.118 | Acc: 39.536,53.107,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.126 | Acc: 39.364,53.093,2.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.120 | Acc: 39.386,53.230,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.115 | Acc: 39.443,53.308,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.114 | Acc: 39.530,53.301,2.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.118 | Acc: 39.513,53.295,2.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.115 | Acc: 39.555,53.306,2.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.121 | Acc: 39.448,53.281,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.123 | Acc: 39.378,53.242,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.292 | Acc: 31.250,42.188,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.537 | Acc: 28.051,41.443,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.522 | Acc: 28.182,41.101,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.548 | Acc: 28.125,40.638,2.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 8.290 | Acc: 37.500,55.469,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.072 | Acc: 40.030,53.943,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.019 | Acc: 40.492,54.535,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.031 | Acc: 40.394,54.444,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.016 | Acc: 40.345,54.678,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.032 | Acc: 39.968,54.386,3.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.054 | Acc: 39.844,54.462,2.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.083 | Acc: 39.556,53.945,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.091 | Acc: 39.548,53.833,2.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.092 | Acc: 39.563,53.936,2.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.095 | Acc: 39.478,53.898,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.087 | Acc: 39.593,53.899,2.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.089 | Acc: 39.533,53.890,2.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.091 | Acc: 39.646,53.855,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.093 | Acc: 39.555,53.853,2.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.096 | Acc: 39.439,53.815,2.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.092 | Acc: 39.464,53.782,2.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.086 | Acc: 39.473,53.854,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.083 | Acc: 39.506,53.763,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.085 | Acc: 39.421,53.736,2.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.974 | Acc: 32.812,46.094,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.215 | Acc: 31.399,43.490,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.253 | Acc: 30.240,43.045,2.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.258 | Acc: 30.174,43.071,2.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 7.832 | Acc: 40.625,56.250,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.063 | Acc: 37.872,52.790,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.010 | Acc: 39.158,54.059,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.008 | Acc: 39.613,54.098,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.005 | Acc: 39.651,54.099,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.018 | Acc: 39.527,53.945,3.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.019 | Acc: 39.353,54.029,2.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.028 | Acc: 39.334,53.879,2.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.025 | Acc: 39.388,53.955,2.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.044 | Acc: 39.192,53.790,2.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.044 | Acc: 39.428,53.825,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.053 | Acc: 39.480,53.811,2.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.060 | Acc: 39.361,53.890,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.062 | Acc: 39.389,53.831,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.060 | Acc: 39.474,53.865,2.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.051 | Acc: 39.634,53.963,2.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.051 | Acc: 39.613,53.928,2.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.055 | Acc: 39.544,53.872,2.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.055 | Acc: 39.502,53.833,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.054 | Acc: 39.493,53.853,2.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.589 | Acc: 28.906,41.406,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.028 | Acc: 24.814,37.314,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.082 | Acc: 24.486,36.338,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.121 | Acc: 24.193,35.784,2.805,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 7.914 | Acc: 46.094,56.250,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.978 | Acc: 39.509,55.283,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.965 | Acc: 40.301,55.621,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.012 | Acc: 39.793,54.636,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.986 | Acc: 40.104,54.919,2.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.978 | Acc: 40.091,55.043,2.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.982 | Acc: 39.973,54.965,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.998 | Acc: 39.788,54.826,2.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.001 | Acc: 39.703,54.702,2.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.993 | Acc: 39.736,54.683,2.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.003 | Acc: 39.587,54.478,2.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.014 | Acc: 39.589,54.327,2.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.009 | Acc: 39.584,54.373,2.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.008 | Acc: 39.598,54.457,2.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.009 | Acc: 39.602,54.440,2.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.012 | Acc: 39.592,54.332,2.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.015 | Acc: 39.566,54.298,2.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.016 | Acc: 39.548,54.300,2.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.012 | Acc: 39.588,54.307,2.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.018 | Acc: 39.544,54.204,2.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.313 | Acc: 30.469,45.312,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.651 | Acc: 25.893,41.592,2.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.675 | Acc: 26.391,40.530,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.699 | Acc: 26.242,40.369,2.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 7.715 | Acc: 43.750,52.344,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.011 | Acc: 40.365,54.539,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.948 | Acc: 40.625,55.297,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.935 | Acc: 40.791,55.558,2.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.948 | Acc: 40.365,55.449,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.975 | Acc: 40.099,54.904,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.987 | Acc: 40.238,54.616,2.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.978 | Acc: 40.409,54.632,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.970 | Acc: 40.445,54.721,2.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.974 | Acc: 40.409,54.713,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.972 | Acc: 40.446,54.781,2.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.968 | Acc: 40.565,54.808,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.978 | Acc: 40.482,54.642,3.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.985 | Acc: 40.409,54.538,3.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.985 | Acc: 40.375,54.496,2.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.990 | Acc: 40.311,54.420,2.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.000 | Acc: 40.150,54.259,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.002 | Acc: 40.004,54.271,2.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.004 | Acc: 39.976,54.307,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.005 | Acc: 39.981,54.271,2.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.200 | Acc: 25.000,41.406,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.453 | Acc: 22.582,36.719,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.551 | Acc: 23.285,36.319,2.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.630 | Acc: 22.925,35.758,2.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 7.747 | Acc: 45.312,59.375,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.960 | Acc: 40.774,53.906,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.912 | Acc: 41.006,54.916,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.905 | Acc: 40.676,55.289,3.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.907 | Acc: 40.731,55.006,3.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.913 | Acc: 40.702,54.881,2.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.905 | Acc: 40.735,54.972,2.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.910 | Acc: 40.636,54.832,2.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.912 | Acc: 40.674,55.163,2.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.917 | Acc: 40.392,55.003,2.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.910 | Acc: 40.384,55.150,2.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.918 | Acc: 40.226,55.069,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.930 | Acc: 40.029,54.918,2.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.940 | Acc: 39.990,54.849,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.946 | Acc: 39.885,54.679,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.951 | Acc: 39.901,54.669,2.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.957 | Acc: 39.914,54.600,2.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.955 | Acc: 39.970,54.603,2.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.959 | Acc: 39.909,54.653,2.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.968 | Acc: 39.850,54.577,2.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.522 | Acc: 30.469,45.312,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.121 | Acc: 22.545,40.402,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.134 | Acc: 22.771,39.634,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.122 | Acc: 22.298,39.703,2.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 7.761 | Acc: 46.094,56.250,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.960 | Acc: 39.546,54.874,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.920 | Acc: 40.168,55.278,3.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.922 | Acc: 40.100,55.456,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.915 | Acc: 40.104,55.363,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.907 | Acc: 40.710,55.569,3.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.900 | Acc: 40.967,55.714,2.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.910 | Acc: 40.963,55.707,2.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.929 | Acc: 40.688,55.420,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.928 | Acc: 40.647,55.400,2.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.925 | Acc: 40.621,55.449,2.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.926 | Acc: 40.590,55.440,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.926 | Acc: 40.453,55.381,2.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.920 | Acc: 40.559,55.481,2.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.925 | Acc: 40.558,55.374,2.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.930 | Acc: 40.477,55.391,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.932 | Acc: 40.472,55.332,2.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.934 | Acc: 40.362,55.242,2.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.938 | Acc: 40.363,55.222,2.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.942 | Acc: 40.363,55.149,2.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.001 | Acc: 32.031,41.406,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.403 | Acc: 22.656,35.007,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.409 | Acc: 22.694,34.585,2.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.416 | Acc: 22.554,34.810,1.985,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 7.939 | Acc: 39.062,52.344,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.831 | Acc: 40.141,56.920,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.801 | Acc: 41.006,57.393,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.829 | Acc: 41.060,56.942,3.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.839 | Acc: 41.184,56.848,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.855 | Acc: 41.019,56.428,3.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.863 | Acc: 41.058,56.101,3.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.871 | Acc: 40.841,56.045,3.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.868 | Acc: 40.848,56.041,3.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.865 | Acc: 40.836,55.987,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.875 | Acc: 40.792,55.718,2.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.876 | Acc: 40.756,55.737,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.881 | Acc: 40.735,55.679,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.885 | Acc: 40.706,55.702,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.891 | Acc: 40.494,55.516,2.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.898 | Acc: 40.407,55.500,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.900 | Acc: 40.404,55.410,2.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.904 | Acc: 40.403,55.405,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.905 | Acc: 40.333,55.382,2.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.911 | Acc: 40.237,55.231,2.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.597 | Acc: 31.250,47.656,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.183 | Acc: 29.650,43.676,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.236 | Acc: 29.878,42.835,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.266 | Acc: 29.688,42.610,2.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 7.696 | Acc: 39.844,60.156,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.850 | Acc: 41.183,56.436,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.872 | Acc: 40.835,55.221,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.900 | Acc: 40.100,54.688,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.895 | Acc: 40.268,54.871,2.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.901 | Acc: 40.347,54.850,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.907 | Acc: 40.276,54.462,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.892 | Acc: 40.481,54.715,2.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.883 | Acc: 40.712,54.945,2.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.888 | Acc: 40.720,54.934,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.890 | Acc: 40.637,54.913,2.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.884 | Acc: 40.692,55.052,2.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.883 | Acc: 40.680,55.005,2.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.884 | Acc: 40.598,55.029,2.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.889 | Acc: 40.606,54.879,2.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.894 | Acc: 40.589,54.882,2.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.894 | Acc: 40.574,54.834,2.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.897 | Acc: 40.614,54.919,2.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.896 | Acc: 40.625,55.021,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.893 | Acc: 40.699,55.057,2.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.223 | Acc: 29.688,46.875,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.520 | Acc: 26.302,40.439,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.606 | Acc: 26.162,39.272,2.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.605 | Acc: 25.820,39.549,2.228,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 7.638 | Acc: 46.094,57.812,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.851 | Acc: 41.704,55.469,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.821 | Acc: 41.368,56.231,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.824 | Acc: 41.163,56.301,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.818 | Acc: 40.847,56.356,3.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.835 | Acc: 40.640,56.080,3.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.853 | Acc: 40.386,55.411,3.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.860 | Acc: 40.365,55.491,3.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.856 | Acc: 40.266,55.488,3.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.860 | Acc: 40.344,55.486,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.860 | Acc: 40.357,55.632,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.867 | Acc: 40.307,55.582,3.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.876 | Acc: 40.281,55.508,2.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.871 | Acc: 40.418,55.427,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.874 | Acc: 40.394,55.299,2.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.878 | Acc: 40.378,55.150,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.880 | Acc: 40.360,55.230,2.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.882 | Acc: 40.426,55.230,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.884 | Acc: 40.413,55.179,2.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.881 | Acc: 40.467,55.278,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.473 | Acc: 26.562,40.625,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.118 | Acc: 23.921,37.426,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.189 | Acc: 24.123,36.604,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.201 | Acc: 23.732,36.834,2.933,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 8.163 | Acc: 35.156,53.125,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.823 | Acc: 39.472,55.990,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.825 | Acc: 40.301,56.441,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.795 | Acc: 40.612,56.416,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.803 | Acc: 40.866,56.530,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.835 | Acc: 40.586,56.157,2.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.838 | Acc: 40.580,56.005,2.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.844 | Acc: 40.542,55.901,2.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.853 | Acc: 40.528,55.726,2.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.846 | Acc: 40.664,55.672,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.854 | Acc: 40.625,55.663,2.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.845 | Acc: 40.745,55.660,2.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.848 | Acc: 40.790,55.718,2.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.849 | Acc: 40.706,55.663,2.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.845 | Acc: 40.808,55.691,2.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.850 | Acc: 40.835,55.658,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.850 | Acc: 40.783,55.707,2.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.852 | Acc: 40.808,55.654,2.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.859 | Acc: 40.703,55.653,2.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.860 | Acc: 40.676,55.590,2.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.757 | Acc: 28.906,45.312,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.872 | Acc: 23.400,40.216,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.858 | Acc: 24.085,40.206,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.849 | Acc: 24.014,39.972,2.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 7.787 | Acc: 46.094,57.812,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.775 | Acc: 40.923,55.580,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.790 | Acc: 41.178,55.354,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.804 | Acc: 41.214,55.789,2.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.809 | Acc: 41.040,55.941,2.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.807 | Acc: 41.182,55.685,2.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.795 | Acc: 41.238,55.850,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.804 | Acc: 41.157,55.940,2.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.797 | Acc: 41.173,56.100,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.800 | Acc: 40.940,56.159,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.808 | Acc: 40.808,56.083,2.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.809 | Acc: 40.816,56.017,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.820 | Acc: 40.787,55.884,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.823 | Acc: 40.733,55.912,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.817 | Acc: 40.750,56.000,2.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.820 | Acc: 40.776,55.988,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.824 | Acc: 40.778,56.031,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.831 | Acc: 40.710,55.920,2.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.828 | Acc: 40.833,55.969,2.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.831 | Acc: 40.783,55.920,2.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.568 | Acc: 30.469,47.656,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.213 | Acc: 27.865,43.899,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.298 | Acc: 27.458,42.550,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.285 | Acc: 27.369,43.148,3.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 7.580 | Acc: 39.062,56.250,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.747 | Acc: 40.327,57.440,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.785 | Acc: 40.396,56.421,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.801 | Acc: 40.318,56.199,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.793 | Acc: 40.586,56.501,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.806 | Acc: 40.610,56.528,2.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.805 | Acc: 40.780,56.450,2.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.801 | Acc: 40.919,56.389,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.800 | Acc: 40.945,56.400,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.804 | Acc: 40.871,56.246,2.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.806 | Acc: 40.928,56.316,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.803 | Acc: 41.039,56.377,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.796 | Acc: 41.102,56.454,2.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.799 | Acc: 41.110,56.358,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.806 | Acc: 41.034,56.264,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.808 | Acc: 41.105,56.211,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.811 | Acc: 41.109,56.143,2.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.816 | Acc: 41.003,56.042,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.816 | Acc: 41.004,56.064,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.815 | Acc: 41.031,56.076,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.974 | Acc: 29.688,51.562,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.620 | Acc: 25.595,42.039,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.670 | Acc: 25.171,40.739,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.666 | Acc: 24.782,40.612,2.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 7.801 | Acc: 46.094,60.938,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.687 | Acc: 42.336,58.668,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.647 | Acc: 42.759,58.975,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.705 | Acc: 41.765,58.043,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.727 | Acc: 41.541,57.706,3.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.765 | Acc: 41.236,57.132,3.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.774 | Acc: 41.064,56.870,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.774 | Acc: 41.146,56.682,3.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.767 | Acc: 41.358,56.769,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.774 | Acc: 41.311,56.880,3.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.792 | Acc: 41.111,56.740,2.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.789 | Acc: 41.109,56.660,2.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.799 | Acc: 41.024,56.584,2.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.800 | Acc: 41.110,56.442,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.808 | Acc: 41.081,56.425,2.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.810 | Acc: 41.092,56.403,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.816 | Acc: 41.010,56.350,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.827 | Acc: 40.980,56.190,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.822 | Acc: 41.101,56.226,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.820 | Acc: 41.113,56.312,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.997 | Acc: 40.625,57.812,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.728 | Acc: 31.250,49.219,3.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.789 | Acc: 31.098,48.285,3.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.802 | Acc: 31.429,48.169,3.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 7.550 | Acc: 44.531,60.938,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.750 | Acc: 41.629,58.147,3.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.725 | Acc: 42.569,58.403,3.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.722 | Acc: 42.354,58.107,3.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.735 | Acc: 41.927,58.034,3.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.762 | Acc: 41.692,57.619,3.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.776 | Acc: 41.458,57.399,3.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.779 | Acc: 41.323,57.192,3.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.784 | Acc: 41.164,57.104,3.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.793 | Acc: 40.975,56.979,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.804 | Acc: 40.850,56.833,3.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.801 | Acc: 40.862,56.717,3.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.798 | Acc: 40.962,56.759,3.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.801 | Acc: 41.137,56.747,3.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.796 | Acc: 41.226,56.778,3.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.801 | Acc: 41.225,56.660,3.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.801 | Acc: 41.241,56.574,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.799 | Acc: 41.294,56.656,3.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.804 | Acc: 41.201,56.590,3.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.802 | Acc: 41.214,56.611,3.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.165 | Acc: 25.000,35.156,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.416 | Acc: 20.759,39.062,3.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.458 | Acc: 21.227,38.434,3.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.511 | Acc: 20.748,37.897,3.330,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 7.936 | Acc: 43.750,56.250,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.734 | Acc: 41.778,56.957,3.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.749 | Acc: 41.540,56.536,3.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.705 | Acc: 41.931,56.916,3.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.695 | Acc: 41.975,57.060,3.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.708 | Acc: 41.971,56.969,3.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.725 | Acc: 41.787,57.051,3.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.739 | Acc: 41.672,56.909,3.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.747 | Acc: 41.605,56.818,3.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.759 | Acc: 41.475,56.764,3.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.762 | Acc: 41.546,56.775,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.770 | Acc: 41.534,56.731,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.777 | Acc: 41.510,56.662,3.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.779 | Acc: 41.442,56.705,3.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.775 | Acc: 41.506,56.706,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.783 | Acc: 41.380,56.608,3.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.789 | Acc: 41.321,56.569,3.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.790 | Acc: 41.299,56.587,3.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.795 | Acc: 41.244,56.518,3.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.794 | Acc: 41.211,56.512,3.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.288 | Acc: 30.469,42.188,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.407 | Acc: 26.897,42.560,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.458 | Acc: 26.677,41.864,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.485 | Acc: 26.575,41.393,2.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 7.690 | Acc: 42.188,60.938,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.777 | Acc: 40.774,56.882,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.768 | Acc: 41.406,57.355,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.751 | Acc: 41.778,57.326,3.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.753 | Acc: 41.840,57.359,3.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.757 | Acc: 41.932,57.039,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.758 | Acc: 41.839,56.831,3.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.762 | Acc: 41.850,56.688,3.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.760 | Acc: 41.993,56.779,3.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.766 | Acc: 41.903,56.630,3.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.764 | Acc: 42.020,56.681,3.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.767 | Acc: 41.958,56.741,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.768 | Acc: 41.876,56.859,3.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.763 | Acc: 41.912,56.870,3.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.761 | Acc: 41.871,56.839,3.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.766 | Acc: 41.837,56.787,3.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.773 | Acc: 41.745,56.691,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.775 | Acc: 41.704,56.733,3.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.773 | Acc: 41.612,56.761,3.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.771 | Acc: 41.634,56.832,3.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.626 | Acc: 38.281,55.469,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.818 | Acc: 32.440,48.847,3.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.825 | Acc: 32.165,47.923,3.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.833 | Acc: 31.993,47.874,3.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 7.438 | Acc: 43.750,57.031,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.763 | Acc: 41.443,58.073,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.741 | Acc: 41.787,58.194,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.721 | Acc: 42.085,58.133,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.689 | Acc: 42.535,58.410,3.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.695 | Acc: 42.543,58.153,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.693 | Acc: 42.575,57.858,3.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.702 | Acc: 42.265,57.680,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.716 | Acc: 41.891,57.337,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.732 | Acc: 41.695,57.187,3.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.743 | Acc: 41.733,57.090,3.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.742 | Acc: 41.703,57.014,3.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.745 | Acc: 41.591,56.986,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.744 | Acc: 41.613,56.956,3.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.751 | Acc: 41.498,56.826,3.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.752 | Acc: 41.518,56.826,3.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.750 | Acc: 41.465,56.817,3.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.751 | Acc: 41.475,56.800,3.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.750 | Acc: 41.482,56.921,3.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.754 | Acc: 41.339,56.863,3.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.024 | Acc: 21.875,42.969,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.418 | Acc: 19.829,38.988,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.439 | Acc: 20.103,38.834,3.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.438 | Acc: 19.800,38.819,3.279,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 7.424 | Acc: 45.312,61.719,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.742 | Acc: 41.964,56.287,4.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.726 | Acc: 41.806,57.260,3.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.684 | Acc: 42.085,57.825,3.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.678 | Acc: 42.236,57.928,3.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.696 | Acc: 42.126,57.704,3.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.714 | Acc: 41.807,57.283,3.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.711 | Acc: 41.728,57.292,3.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.713 | Acc: 41.785,57.293,3.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.708 | Acc: 41.907,57.502,3.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.711 | Acc: 41.904,57.432,3.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.716 | Acc: 41.876,57.222,3.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.730 | Acc: 41.685,57.210,3.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.739 | Acc: 41.526,57.124,3.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.738 | Acc: 41.434,57.101,3.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.735 | Acc: 41.541,57.171,3.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.744 | Acc: 41.433,57.104,3.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.744 | Acc: 41.431,57.070,3.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.746 | Acc: 41.421,57.055,3.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.747 | Acc: 41.414,57.072,3.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.289 | Acc: 17.969,43.750,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.596 | Acc: 18.638,38.132,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.766 | Acc: 18.483,36.662,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.796 | Acc: 18.391,36.616,2.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 7.545 | Acc: 46.875,54.688,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.567 | Acc: 43.899,59.226,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.639 | Acc: 42.359,58.289,3.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.651 | Acc: 42.418,58.210,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.673 | Acc: 42.014,57.938,2.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.680 | Acc: 41.886,57.774,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.690 | Acc: 41.632,57.606,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.695 | Acc: 41.633,57.602,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.674 | Acc: 41.833,57.963,3.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.677 | Acc: 41.872,57.907,3.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.674 | Acc: 41.978,57.941,3.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.684 | Acc: 41.887,57.834,3.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.690 | Acc: 41.727,57.757,3.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.688 | Acc: 41.744,57.696,3.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.693 | Acc: 41.748,57.635,3.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.695 | Acc: 41.738,57.540,3.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.701 | Acc: 41.674,57.435,3.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.704 | Acc: 41.610,57.345,3.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.715 | Acc: 41.437,57.209,3.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.712 | Acc: 41.468,57.240,3.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.314 | Acc: 28.125,42.188,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.968 | Acc: 23.289,38.839,3.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.982 | Acc: 23.323,38.624,3.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.965 | Acc: 23.053,38.819,3.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 7.857 | Acc: 43.750,57.812,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.631 | Acc: 43.192,58.445,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.595 | Acc: 42.988,58.861,3.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.630 | Acc: 42.469,58.850,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.629 | Acc: 42.728,58.787,3.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.645 | Acc: 42.172,58.594,3.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.666 | Acc: 42.013,58.342,3.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.682 | Acc: 42.005,58.328,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.689 | Acc: 42.003,58.249,3.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.681 | Acc: 42.062,58.171,3.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.677 | Acc: 41.978,58.034,3.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.685 | Acc: 41.894,57.957,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.693 | Acc: 41.847,57.774,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.698 | Acc: 41.724,57.621,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.705 | Acc: 41.712,57.440,2.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.706 | Acc: 41.583,57.361,2.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.708 | Acc: 41.564,57.318,2.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.706 | Acc: 41.622,57.366,2.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.711 | Acc: 41.595,57.380,2.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.710 | Acc: 41.599,57.394,2.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.839 | Acc: 29.688,50.000,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.251 | Acc: 27.344,44.568,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.305 | Acc: 27.325,43.845,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.323 | Acc: 27.408,43.353,3.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 7.459 | Acc: 45.312,63.281,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.691 | Acc: 41.332,58.147,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.572 | Acc: 42.759,58.841,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.577 | Acc: 42.354,58.543,3.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.622 | Acc: 41.840,58.025,3.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.612 | Acc: 42.195,58.284,3.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.609 | Acc: 42.265,58.245,3.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.640 | Acc: 42.077,58.012,3.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.651 | Acc: 42.071,57.856,3.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.654 | Acc: 42.028,57.834,3.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.656 | Acc: 42.048,57.917,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.659 | Acc: 42.103,57.947,3.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.654 | Acc: 42.239,58.039,3.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.652 | Acc: 42.307,58.064,3.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.665 | Acc: 42.046,57.832,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.669 | Acc: 41.941,57.836,2.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.674 | Acc: 41.934,57.795,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.684 | Acc: 41.816,57.728,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.691 | Acc: 41.753,57.655,2.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.695 | Acc: 41.755,57.603,2.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.234 | Acc: 34.375,52.344,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.605 | Acc: 32.738,49.665,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.649 | Acc: 32.088,48.819,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.665 | Acc: 31.365,48.719,2.805,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 7.815 | Acc: 41.406,60.156,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.699 | Acc: 40.253,58.705,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.602 | Acc: 40.854,58.727,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.591 | Acc: 41.944,58.927,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.599 | Acc: 42.429,58.873,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.603 | Acc: 42.489,58.725,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.626 | Acc: 42.162,58.277,2.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.633 | Acc: 42.193,58.018,2.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.634 | Acc: 42.129,58.016,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.627 | Acc: 42.136,58.015,2.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.629 | Acc: 42.176,57.980,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.636 | Acc: 42.110,57.880,2.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.645 | Acc: 41.886,57.718,2.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.645 | Acc: 41.900,57.720,2.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.650 | Acc: 41.890,57.704,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.654 | Acc: 41.897,57.696,2.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.666 | Acc: 41.779,57.618,2.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.667 | Acc: 41.727,57.565,2.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.667 | Acc: 41.735,57.620,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.669 | Acc: 41.728,57.612,2.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.950 | Acc: 30.469,40.625,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.374 | Acc: 25.930,42.299,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.468 | Acc: 25.171,41.235,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.477 | Acc: 25.013,41.048,2.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 8.119 | Acc: 33.594,51.562,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.606 | Acc: 42.485,58.147,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.563 | Acc: 44.055,59.527,3.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.572 | Acc: 43.840,59.375,3.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.547 | Acc: 43.866,59.693,3.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.567 | Acc: 43.425,59.236,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.581 | Acc: 43.059,59.110,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.594 | Acc: 43.008,58.943,3.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.603 | Acc: 43.022,58.885,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.617 | Acc: 43.016,58.663,2.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.623 | Acc: 42.942,58.637,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.623 | Acc: 42.997,58.615,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.630 | Acc: 42.884,58.467,2.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.626 | Acc: 42.897,58.393,2.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.637 | Acc: 42.643,58.227,2.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.643 | Acc: 42.533,58.165,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.646 | Acc: 42.441,58.117,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.655 | Acc: 42.357,57.975,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.658 | Acc: 42.287,57.899,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.658 | Acc: 42.284,57.825,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.266 | Acc: 39.062,50.781,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.654 | Acc: 33.036,48.363,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.679 | Acc: 33.003,47.542,3.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.690 | Acc: 32.377,47.336,3.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 7.383 | Acc: 42.969,60.156,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.565 | Acc: 42.411,58.408,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.541 | Acc: 42.835,58.670,2.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.565 | Acc: 42.431,58.350,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.585 | Acc: 42.593,58.266,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.607 | Acc: 42.551,58.099,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.611 | Acc: 42.762,58.187,3.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.615 | Acc: 42.520,58.211,2.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.608 | Acc: 42.576,58.366,2.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.622 | Acc: 42.598,58.343,2.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.622 | Acc: 42.425,58.217,2.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.621 | Acc: 42.364,58.297,2.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.623 | Acc: 42.278,58.334,2.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.626 | Acc: 42.232,58.276,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.631 | Acc: 42.087,58.171,2.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.642 | Acc: 41.967,58.031,2.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.645 | Acc: 41.925,57.915,2.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.650 | Acc: 41.935,57.854,2.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.649 | Acc: 41.919,57.849,2.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.651 | Acc: 41.952,57.911,2.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.055 | Acc: 39.062,59.375,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.433 | Acc: 33.408,50.484,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.524 | Acc: 32.927,48.876,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.507 | Acc: 33.197,49.052,2.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 7.797 | Acc: 40.625,60.156,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.651 | Acc: 41.071,57.589,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.636 | Acc: 41.711,57.851,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.644 | Acc: 41.342,57.710,2.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.622 | Acc: 41.782,58.131,2.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.647 | Acc: 41.468,57.696,2.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.641 | Acc: 41.729,57.916,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.632 | Acc: 41.899,57.934,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.631 | Acc: 41.819,58.123,2.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.624 | Acc: 41.864,58.184,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.619 | Acc: 42.086,58.193,2.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.618 | Acc: 42.060,58.166,2.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.619 | Acc: 42.103,58.198,2.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.621 | Acc: 42.098,58.130,2.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.626 | Acc: 42.035,58.149,2.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.628 | Acc: 41.998,58.098,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.631 | Acc: 42.007,58.070,2.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.636 | Acc: 41.954,58.028,2.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.633 | Acc: 41.943,58.033,2.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.635 | Acc: 42.001,58.024,2.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.308 | Acc: 28.125,42.969,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.360 | Acc: 28.906,42.039,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.371 | Acc: 29.192,41.292,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.438 | Acc: 28.906,41.201,2.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 7.379 | Acc: 44.531,59.375,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.484 | Acc: 42.969,60.528,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.552 | Acc: 42.607,59.832,3.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.596 | Acc: 42.290,59.042,3.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.587 | Acc: 42.429,59.076,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.576 | Acc: 42.744,59.282,3.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.574 | Acc: 42.736,59.304,3.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.584 | Acc: 42.503,59.159,2.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.602 | Acc: 42.416,58.827,2.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.619 | Acc: 42.339,58.585,2.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.617 | Acc: 42.238,58.446,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.616 | Acc: 42.233,58.314,2.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.615 | Acc: 42.259,58.354,2.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.616 | Acc: 42.382,58.324,2.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.626 | Acc: 42.235,58.191,2.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.622 | Acc: 42.315,58.306,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.623 | Acc: 42.341,58.236,2.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.627 | Acc: 42.270,58.207,2.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.627 | Acc: 42.302,58.245,2.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.629 | Acc: 42.313,58.247,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.124 | Acc: 27.344,46.875,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.281 | Acc: 25.112,45.573,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.432 | Acc: 24.085,43.407,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.465 | Acc: 24.168,43.494,2.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 7.677 | Acc: 42.969,57.812,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.535 | Acc: 41.555,60.565,3.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.566 | Acc: 41.178,59.661,3.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.554 | Acc: 41.701,60.054,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.560 | Acc: 42.014,59.568,3.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.562 | Acc: 42.002,59.522,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.564 | Acc: 41.936,59.633,3.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.568 | Acc: 41.977,59.519,3.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.582 | Acc: 41.940,59.331,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.584 | Acc: 41.898,59.453,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.587 | Acc: 41.888,59.359,2.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.596 | Acc: 41.848,59.219,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.588 | Acc: 41.954,59.281,2.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.584 | Acc: 42.080,59.216,2.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.583 | Acc: 42.093,59.116,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.581 | Acc: 42.110,59.089,2.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.588 | Acc: 42.112,59.090,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.595 | Acc: 41.993,58.979,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.599 | Acc: 41.980,58.931,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.609 | Acc: 41.896,58.766,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.889 | Acc: 31.250,50.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.503 | Acc: 27.195,43.490,3.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.598 | Acc: 26.543,42.740,3.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.617 | Acc: 26.319,41.931,3.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 7.799 | Acc: 31.250,57.031,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.611 | Acc: 43.043,59.747,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.561 | Acc: 42.626,60.366,2.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.604 | Acc: 42.303,59.862,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.635 | Acc: 41.782,59.307,2.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.629 | Acc: 42.056,59.669,3.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.646 | Acc: 41.897,59.285,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.636 | Acc: 41.766,59.209,2.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.635 | Acc: 41.731,59.016,3.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.646 | Acc: 41.553,58.814,3.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.641 | Acc: 41.748,58.897,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.640 | Acc: 41.721,58.778,3.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.643 | Acc: 41.798,58.714,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.639 | Acc: 41.936,58.624,3.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.633 | Acc: 41.996,58.736,3.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.632 | Acc: 41.998,58.731,3.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.636 | Acc: 41.983,58.601,3.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.626 | Acc: 42.082,58.701,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.629 | Acc: 41.999,58.589,3.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.638 | Acc: 41.900,58.497,3.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.599 | Acc: 34.375,55.469,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.354 | Acc: 27.083,44.680,3.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.329 | Acc: 27.325,44.950,3.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.355 | Acc: 27.203,44.672,3.509,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 7.270 | Acc: 39.062,60.938,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.571 | Acc: 42.150,59.040,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.570 | Acc: 42.188,58.460,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.553 | Acc: 42.687,58.888,2.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.559 | Acc: 42.496,58.854,2.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.568 | Acc: 42.628,58.926,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.569 | Acc: 42.704,58.891,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.570 | Acc: 42.742,58.782,2.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.580 | Acc: 42.653,58.705,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.588 | Acc: 42.615,58.568,2.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.581 | Acc: 42.732,58.761,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.580 | Acc: 42.831,58.905,2.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.587 | Acc: 42.703,58.866,2.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.586 | Acc: 42.690,58.869,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.597 | Acc: 42.577,58.736,2.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.601 | Acc: 42.525,58.718,2.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.613 | Acc: 42.372,58.548,2.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.616 | Acc: 42.302,58.486,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.620 | Acc: 42.270,58.434,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.622 | Acc: 42.288,58.383,2.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.349 | Acc: 29.688,45.312,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.568 | Acc: 25.409,43.155,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.694 | Acc: 24.143,41.673,2.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.687 | Acc: 24.065,41.483,2.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 7.902 | Acc: 41.406,55.469,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.652 | Acc: 43.006,59.561,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.585 | Acc: 42.683,59.585,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.574 | Acc: 42.853,59.183,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.566 | Acc: 42.708,59.163,2.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.569 | Acc: 42.543,58.988,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.563 | Acc: 42.556,59.214,2.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.566 | Acc: 42.636,59.220,2.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.574 | Acc: 42.610,59.200,2.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.575 | Acc: 42.546,59.168,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.571 | Acc: 42.444,59.247,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.575 | Acc: 42.477,59.227,3.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.579 | Acc: 42.473,59.122,3.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.585 | Acc: 42.484,59.130,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.592 | Acc: 42.449,59.022,3.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.593 | Acc: 42.429,58.955,3.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.595 | Acc: 42.397,58.969,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.598 | Acc: 42.382,58.983,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.599 | Acc: 42.356,58.998,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.605 | Acc: 42.302,58.897,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.667 | Acc: 29.688,46.875,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.292 | Acc: 22.842,40.737,4.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.395 | Acc: 22.313,39.653,3.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.388 | Acc: 22.336,39.831,3.394,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 7.719 | Acc: 42.969,57.812,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.555 | Acc: 42.411,57.812,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.588 | Acc: 42.816,58.689,2.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.585 | Acc: 42.828,58.427,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.586 | Acc: 42.400,58.748,2.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.583 | Acc: 42.435,59.058,2.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.581 | Acc: 42.556,59.375,2.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.574 | Acc: 42.847,59.430,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.565 | Acc: 42.813,59.453,2.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.559 | Acc: 42.861,59.496,2.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.557 | Acc: 42.685,59.488,2.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.556 | Acc: 42.679,59.474,3.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.557 | Acc: 42.810,59.414,3.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.563 | Acc: 42.720,59.378,3.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.571 | Acc: 42.607,59.189,3.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.573 | Acc: 42.457,59.128,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.575 | Acc: 42.428,58.969,3.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.578 | Acc: 42.414,58.963,3.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.575 | Acc: 42.506,59.018,3.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.576 | Acc: 42.448,58.963,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.376 | Acc: 35.156,43.750,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.867 | Acc: 32.106,44.829,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.901 | Acc: 32.107,44.569,3.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.932 | Acc: 31.596,44.672,3.125,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 7.530 | Acc: 41.406,57.812,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.528 | Acc: 43.824,59.933,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.512 | Acc: 43.769,60.061,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.517 | Acc: 43.148,59.465,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.532 | Acc: 43.133,59.414,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.550 | Acc: 43.093,59.112,3.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.540 | Acc: 43.266,59.304,3.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.535 | Acc: 43.351,59.297,3.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.548 | Acc: 43.100,59.225,2.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.560 | Acc: 43.077,59.090,3.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.560 | Acc: 43.085,59.161,3.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.579 | Acc: 43.018,58.951,2.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.593 | Acc: 42.917,58.798,2.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.604 | Acc: 42.762,58.746,2.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.616 | Acc: 42.588,58.608,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.611 | Acc: 42.569,58.677,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.616 | Acc: 42.577,58.657,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.617 | Acc: 42.529,58.653,2.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.620 | Acc: 42.560,58.676,2.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.618 | Acc: 42.565,58.688,2.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.303 | Acc: 28.125,39.844,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.680 | Acc: 26.042,41.220,3.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.778 | Acc: 25.800,39.939,3.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.769 | Acc: 25.922,39.780,3.458,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 7.692 | Acc: 42.188,60.156,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.500 | Acc: 43.266,61.049,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.512 | Acc: 42.683,60.880,3.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.550 | Acc: 42.687,59.951,3.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.566 | Acc: 42.458,59.713,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.566 | Acc: 42.489,59.607,3.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.577 | Acc: 42.213,59.265,3.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.580 | Acc: 42.304,59.275,3.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.580 | Acc: 42.386,59.433,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.598 | Acc: 42.261,59.211,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.602 | Acc: 42.195,59.122,3.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.610 | Acc: 42.050,58.997,3.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.608 | Acc: 42.116,59.103,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.609 | Acc: 42.217,59.094,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.613 | Acc: 42.254,59.058,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.617 | Acc: 42.263,58.955,2.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.619 | Acc: 42.275,58.874,2.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.619 | Acc: 42.314,58.947,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.620 | Acc: 42.391,58.901,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.618 | Acc: 42.382,58.889,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.324 | Acc: 25.781,39.062,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.687 | Acc: 24.405,41.667,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.751 | Acc: 24.276,41.025,3.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.751 | Acc: 24.257,41.137,3.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 7.650 | Acc: 46.094,60.938,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.632 | Acc: 42.671,59.189,3.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.615 | Acc: 42.626,59.146,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.558 | Acc: 43.302,59.452,3.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.561 | Acc: 43.133,59.414,3.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.559 | Acc: 43.015,59.383,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.571 | Acc: 42.962,59.524,3.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.577 | Acc: 42.936,59.497,3.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.579 | Acc: 42.935,59.603,3.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.589 | Acc: 43.016,59.405,3.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.597 | Acc: 42.891,59.286,3.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.596 | Acc: 42.796,59.340,3.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.597 | Acc: 42.729,59.193,3.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.598 | Acc: 42.777,59.148,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.607 | Acc: 42.682,59.011,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.606 | Acc: 42.761,58.926,3.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.606 | Acc: 42.769,58.832,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.605 | Acc: 42.769,58.864,3.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.614 | Acc: 42.625,58.698,2.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.614 | Acc: 42.565,58.723,3.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.807 | Acc: 23.438,41.406,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.899 | Acc: 21.949,41.518,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.923 | Acc: 22.561,40.377,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.938 | Acc: 22.720,40.356,3.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 7.750 | Acc: 40.625,57.812,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.656 | Acc: 41.555,57.701,3.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.624 | Acc: 42.054,58.060,3.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.580 | Acc: 42.418,59.004,3.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.557 | Acc: 42.766,59.201,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.565 | Acc: 42.481,59.019,3.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.562 | Acc: 42.562,59.104,3.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.585 | Acc: 42.332,58.965,3.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.594 | Acc: 42.343,58.904,3.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.596 | Acc: 42.287,58.987,3.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.599 | Acc: 42.250,58.815,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.589 | Acc: 42.368,58.968,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.590 | Acc: 42.265,58.937,3.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.589 | Acc: 42.316,58.998,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.584 | Acc: 42.357,59.078,3.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.580 | Acc: 42.411,59.134,3.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.583 | Acc: 42.504,59.151,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.589 | Acc: 42.396,59.070,3.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.588 | Acc: 42.363,59.089,3.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.590 | Acc: 42.399,58.996,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.325 | Acc: 32.031,45.312,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.702 | Acc: 23.326,42.299,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.788 | Acc: 22.828,40.301,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.816 | Acc: 23.002,40.318,2.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 7.914 | Acc: 41.406,61.719,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.626 | Acc: 41.109,58.259,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.574 | Acc: 42.168,58.594,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.599 | Acc: 41.701,58.248,3.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.563 | Acc: 42.515,59.115,3.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.547 | Acc: 42.752,59.321,3.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.554 | Acc: 42.401,59.155,3.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.566 | Acc: 42.354,58.926,3.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.567 | Acc: 42.454,58.836,3.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.562 | Acc: 42.606,58.961,3.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.564 | Acc: 42.588,58.959,3.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.571 | Acc: 42.449,59.043,3.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.580 | Acc: 42.324,58.908,3.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.590 | Acc: 42.313,58.854,3.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.582 | Acc: 42.418,58.911,3.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.579 | Acc: 42.483,58.929,3.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.580 | Acc: 42.494,58.917,3.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.580 | Acc: 42.543,58.898,3.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.578 | Acc: 42.545,58.929,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.577 | Acc: 42.581,58.963,3.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.997 | Acc: 32.031,51.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.606 | Acc: 27.269,45.982,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.598 | Acc: 27.725,45.427,2.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.610 | Acc: 27.382,45.236,2.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 7.370 | Acc: 45.312,60.156,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.528 | Acc: 43.564,60.268,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.569 | Acc: 42.683,59.223,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.566 | Acc: 43.097,59.004,2.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.561 | Acc: 43.142,59.250,2.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.546 | Acc: 43.317,59.537,2.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.547 | Acc: 43.292,59.711,2.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.552 | Acc: 43.107,59.646,2.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.554 | Acc: 43.037,59.569,2.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.558 | Acc: 42.809,59.461,2.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.543 | Acc: 42.844,59.597,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.543 | Acc: 42.820,59.569,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.545 | Acc: 42.833,59.479,2.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.543 | Acc: 42.882,59.498,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.546 | Acc: 42.958,59.333,2.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.550 | Acc: 42.906,59.227,2.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.550 | Acc: 42.871,59.227,2.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.546 | Acc: 42.914,59.256,2.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.550 | Acc: 42.899,59.213,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.553 | Acc: 42.774,59.248,2.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.898 | Acc: 21.875,48.438,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.005 | Acc: 28.385,45.982,2.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.115 | Acc: 28.125,44.874,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.146 | Acc: 27.459,44.582,2.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 7.077 | Acc: 53.125,64.844,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.478 | Acc: 43.601,60.268,3.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.432 | Acc: 43.998,60.957,3.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.431 | Acc: 44.096,61.335,3.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.450 | Acc: 43.943,60.899,3.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.449 | Acc: 44.013,60.945,3.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.461 | Acc: 43.679,60.460,3.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.470 | Acc: 43.639,60.212,3.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.487 | Acc: 43.323,59.957,3.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.500 | Acc: 43.033,59.863,3.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.501 | Acc: 43.000,59.853,3.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.502 | Acc: 43.089,59.803,3.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.504 | Acc: 43.021,59.579,3.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.514 | Acc: 42.843,59.531,3.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.522 | Acc: 42.724,59.503,3.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.530 | Acc: 42.595,59.448,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.534 | Acc: 42.606,59.275,3.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.536 | Acc: 42.572,59.267,3.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.535 | Acc: 42.627,59.282,3.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.537 | Acc: 42.632,59.221,3.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.886 | Acc: 37.500,53.906,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.255 | Acc: 28.497,45.461,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.386 | Acc: 27.992,44.188,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.376 | Acc: 27.690,43.929,2.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 6.975 | Acc: 50.000,66.406,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.537 | Acc: 41.704,59.821,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.520 | Acc: 42.092,60.061,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.526 | Acc: 42.444,59.990,2.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.510 | Acc: 42.429,59.944,2.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.505 | Acc: 42.474,60.009,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.496 | Acc: 42.620,60.227,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.508 | Acc: 42.531,60.101,3.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.511 | Acc: 42.634,60.045,3.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.506 | Acc: 42.839,60.100,3.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.507 | Acc: 42.868,60.106,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.505 | Acc: 42.912,60.022,3.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.515 | Acc: 42.784,59.848,3.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.509 | Acc: 42.858,59.824,3.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.516 | Acc: 42.844,59.647,3.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.520 | Acc: 42.831,59.487,3.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.527 | Acc: 42.757,59.394,3.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.530 | Acc: 42.760,59.380,3.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.530 | Acc: 42.813,59.379,3.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.529 | Acc: 42.893,59.428,3.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.408 | Acc: 24.219,46.875,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.029 | Acc: 21.317,38.802,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.139 | Acc: 21.075,37.348,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.111 | Acc: 20.838,37.398,2.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 7.387 | Acc: 43.750,64.844,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.515 | Acc: 42.150,59.784,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.497 | Acc: 42.397,59.928,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.493 | Acc: 42.789,59.849,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.469 | Acc: 43.027,60.388,3.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.458 | Acc: 43.046,60.620,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.476 | Acc: 42.891,60.350,2.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.462 | Acc: 43.068,60.278,3.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.478 | Acc: 42.755,60.079,3.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.482 | Acc: 42.775,60.066,3.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.493 | Acc: 42.650,60.036,3.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.503 | Acc: 42.598,59.979,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.507 | Acc: 42.635,59.916,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.509 | Acc: 42.684,59.845,3.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.520 | Acc: 42.529,59.645,3.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.514 | Acc: 42.639,59.744,3.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.517 | Acc: 42.762,59.721,3.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.521 | Acc: 42.701,59.732,3.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.528 | Acc: 42.646,59.639,3.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.529 | Acc: 42.702,59.654,3.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.802 | Acc: 32.812,48.438,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.358 | Acc: 28.981,42.039,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.407 | Acc: 28.906,41.997,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.435 | Acc: 28.573,41.739,2.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 7.441 | Acc: 39.844,60.156,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.536 | Acc: 42.411,59.970,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.549 | Acc: 43.026,60.290,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.514 | Acc: 43.468,60.592,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.512 | Acc: 43.383,60.475,2.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.498 | Acc: 43.278,60.504,2.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.504 | Acc: 43.253,60.415,2.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.500 | Acc: 43.318,60.616,2.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.509 | Acc: 43.381,60.375,2.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.510 | Acc: 43.482,60.342,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.526 | Acc: 43.179,60.005,2.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.535 | Acc: 43.100,59.951,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.539 | Acc: 43.179,59.832,2.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.545 | Acc: 43.124,59.839,2.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.542 | Acc: 43.161,59.903,2.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.550 | Acc: 43.132,59.803,2.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.554 | Acc: 43.271,59.830,2.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.565 | Acc: 43.138,59.705,2.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.577 | Acc: 43.032,59.546,2.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.587 | Acc: 43.028,59.457,2.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.388 | Acc: 30.469,42.969,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.445 | Acc: 28.088,44.531,2.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.472 | Acc: 27.477,42.854,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.454 | Acc: 27.728,43.225,2.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 7.597 | Acc: 37.500,63.281,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.661 | Acc: 42.039,59.635,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.641 | Acc: 42.454,59.909,2.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.626 | Acc: 43.071,59.810,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.634 | Acc: 42.805,59.616,2.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.624 | Acc: 42.806,59.623,2.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.603 | Acc: 43.027,59.898,2.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.611 | Acc: 42.974,59.863,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.602 | Acc: 43.061,59.914,2.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.600 | Acc: 43.064,59.902,2.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.599 | Acc: 43.023,59.818,2.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.597 | Acc: 43.025,59.881,2.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.603 | Acc: 42.878,59.693,2.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.608 | Acc: 42.771,59.620,2.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.617 | Acc: 42.694,59.514,2.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.612 | Acc: 42.790,59.627,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.617 | Acc: 42.694,59.558,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.620 | Acc: 42.692,59.540,2.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.630 | Acc: 42.648,59.405,2.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.625 | Acc: 42.678,59.422,2.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.471 | Acc: 34.375,51.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.285 | Acc: 26.749,44.606,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.290 | Acc: 26.048,43.636,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.301 | Acc: 26.153,43.596,2.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 7.596 | Acc: 42.188,58.594,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.496 | Acc: 44.420,60.119,3.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.488 | Acc: 44.245,60.652,3.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.476 | Acc: 44.390,60.566,3.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.498 | Acc: 44.280,60.224,3.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.507 | Acc: 44.152,60.118,3.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.518 | Acc: 44.273,60.066,3.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.547 | Acc: 43.955,59.929,3.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.565 | Acc: 43.653,59.729,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.576 | Acc: 43.582,59.781,3.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.587 | Acc: 43.548,59.799,3.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.592 | Acc: 43.520,59.739,3.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.598 | Acc: 43.452,59.686,3.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.603 | Acc: 43.298,59.722,3.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.603 | Acc: 43.352,59.667,2.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.609 | Acc: 43.278,59.541,2.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.606 | Acc: 43.312,59.526,2.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.605 | Acc: 43.283,59.542,2.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.610 | Acc: 43.231,59.533,2.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.606 | Acc: 43.297,59.549,2.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.570 | Acc: 33.594,48.438,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.988 | Acc: 24.479,44.680,3.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.012 | Acc: 24.219,43.921,3.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.035 | Acc: 24.193,43.660,3.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 7.480 | Acc: 42.969,58.594,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.632 | Acc: 42.932,60.677,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.667 | Acc: 42.626,59.566,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.627 | Acc: 43.046,60.284,2.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.591 | Acc: 43.162,60.378,2.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.585 | Acc: 43.294,60.319,2.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.589 | Acc: 43.272,60.079,2.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.599 | Acc: 43.201,59.885,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.585 | Acc: 43.153,59.865,3.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.584 | Acc: 43.310,59.906,2.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.577 | Acc: 43.369,60.016,2.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.575 | Acc: 43.358,59.891,2.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.574 | Acc: 43.380,59.994,2.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.566 | Acc: 43.397,60.150,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.572 | Acc: 43.344,60.195,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.577 | Acc: 43.288,60.123,2.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.579 | Acc: 43.275,60.078,2.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.588 | Acc: 43.125,59.916,2.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.592 | Acc: 43.094,59.875,2.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.592 | Acc: 43.059,59.877,2.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.758 | Acc: 31.250,43.750,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.996 | Acc: 27.530,44.122,1.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.063 | Acc: 26.677,43.236,1.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.030 | Acc: 26.447,43.327,1.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 7.573 | Acc: 42.969,61.719,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.596 | Acc: 42.113,61.235,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.567 | Acc: 42.759,60.995,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.563 | Acc: 42.764,60.412,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.574 | Acc: 42.641,60.031,3.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.572 | Acc: 42.489,59.947,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.563 | Acc: 42.627,60.105,3.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.566 | Acc: 42.581,59.912,3.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.561 | Acc: 42.755,59.957,3.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.572 | Acc: 42.736,59.725,3.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.574 | Acc: 42.778,59.806,3.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.582 | Acc: 42.594,59.725,3.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.582 | Acc: 42.687,59.829,2.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.587 | Acc: 42.765,59.653,2.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.589 | Acc: 42.780,59.698,3.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.591 | Acc: 42.813,59.720,3.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.588 | Acc: 42.905,59.772,3.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.598 | Acc: 42.866,59.689,3.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.600 | Acc: 42.858,59.680,2.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.606 | Acc: 42.864,59.607,2.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.337 | Acc: 25.000,46.094,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.270 | Acc: 21.912,40.774,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.299 | Acc: 20.998,39.386,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.286 | Acc: 20.799,38.794,2.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 7.359 | Acc: 46.094,64.062,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.572 | Acc: 42.708,61.012,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.550 | Acc: 43.407,61.261,3.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.615 | Acc: 43.058,60.489,3.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.588 | Acc: 43.490,60.831,3.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.597 | Acc: 43.348,60.419,3.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.587 | Acc: 43.343,60.602,3.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.586 | Acc: 43.218,60.522,3.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.584 | Acc: 43.265,60.515,3.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.591 | Acc: 43.159,60.359,3.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.583 | Acc: 43.311,60.374,3.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.581 | Acc: 43.329,60.404,3.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.584 | Acc: 43.416,60.364,3.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.590 | Acc: 43.436,60.297,2.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.593 | Acc: 43.352,60.265,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.592 | Acc: 43.368,60.229,3.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.594 | Acc: 43.351,60.212,2.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.596 | Acc: 43.315,60.170,2.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.594 | Acc: 43.306,60.178,2.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.595 | Acc: 43.319,60.091,2.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.609 | Acc: 21.094,42.188,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.657 | Acc: 21.577,38.244,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.698 | Acc: 21.646,37.862,2.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.705 | Acc: 21.235,37.807,2.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 7.710 | Acc: 43.750,62.500,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.496 | Acc: 44.382,61.012,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.515 | Acc: 43.579,60.747,3.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.542 | Acc: 43.609,60.169,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.531 | Acc: 43.490,60.455,3.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.529 | Acc: 43.611,60.605,3.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.530 | Acc: 43.763,60.647,3.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.544 | Acc: 43.534,60.273,3.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.549 | Acc: 43.425,60.214,3.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.559 | Acc: 43.469,60.122,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.563 | Acc: 43.319,60.009,3.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.563 | Acc: 43.276,59.976,3.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.561 | Acc: 43.393,59.981,3.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.568 | Acc: 43.328,59.818,3.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.573 | Acc: 43.461,59.742,3.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.588 | Acc: 43.361,59.715,3.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.591 | Acc: 43.421,59.774,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.608 | Acc: 43.388,59.742,3.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.619 | Acc: 43.417,59.659,3.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.632 | Acc: 43.356,59.588,3.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.456 | Acc: 25.000,46.094,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.662 | Acc: 22.582,44.940,1.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.677 | Acc: 22.618,44.779,1.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.732 | Acc: 22.682,43.968,0.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 8.035 | Acc: 35.156,60.938,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.694 | Acc: 43.341,62.054,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.690 | Acc: 43.750,61.185,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.653 | Acc: 44.198,61.002,2.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.686 | Acc: 43.798,60.397,2.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.657 | Acc: 43.843,60.736,2.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.663 | Acc: 43.840,60.608,2.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.664 | Acc: 43.761,60.511,2.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.671 | Acc: 43.706,60.413,2.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.677 | Acc: 43.504,60.165,2.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.672 | Acc: 43.412,60.067,2.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.683 | Acc: 43.354,59.919,3.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.686 | Acc: 43.218,59.897,2.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.686 | Acc: 43.304,59.887,2.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.693 | Acc: 43.230,59.784,2.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.695 | Acc: 43.104,59.736,3.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.690 | Acc: 43.110,59.781,2.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.695 | Acc: 43.113,59.769,3.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.698 | Acc: 43.023,59.695,3.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.697 | Acc: 43.028,59.734,3.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.963 | Acc: 28.906,39.844,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.318 | Acc: 20.647,36.086,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.450 | Acc: 19.950,34.813,2.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.433 | Acc: 19.749,34.708,2.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 7.733 | Acc: 44.531,57.812,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.766 | Acc: 42.448,60.045,3.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.713 | Acc: 43.274,60.061,3.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.676 | Acc: 43.686,60.361,3.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.666 | Acc: 43.750,60.291,3.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.663 | Acc: 43.649,60.079,3.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.649 | Acc: 43.472,60.163,3.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.629 | Acc: 43.927,60.378,3.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.637 | Acc: 43.721,60.185,3.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.636 | Acc: 43.694,60.152,3.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.631 | Acc: 43.703,60.253,3.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.623 | Acc: 43.626,60.284,3.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.631 | Acc: 43.481,60.276,3.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.641 | Acc: 43.427,60.249,3.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.645 | Acc: 43.372,60.184,3.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.644 | Acc: 43.394,60.180,3.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.639 | Acc: 43.365,60.227,3.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.641 | Acc: 43.328,60.234,3.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.648 | Acc: 43.315,60.156,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.656 | Acc: 43.291,60.140,3.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.796 | Acc: 25.000,48.438,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.512 | Acc: 22.470,42.076,1.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.559 | Acc: 22.618,40.796,1.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.630 | Acc: 22.106,40.612,1.614,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 7.944 | Acc: 41.406,56.250,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.688 | Acc: 43.192,60.379,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.599 | Acc: 43.674,60.309,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.589 | Acc: 44.070,60.694,3.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.587 | Acc: 44.117,60.687,2.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.620 | Acc: 43.866,60.419,3.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.611 | Acc: 43.660,60.486,3.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.604 | Acc: 43.451,60.367,3.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.608 | Acc: 43.405,60.370,3.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.618 | Acc: 43.189,60.251,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.616 | Acc: 43.233,60.176,3.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.616 | Acc: 43.248,60.199,3.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.622 | Acc: 43.257,60.137,3.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.624 | Acc: 43.169,59.953,3.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.628 | Acc: 43.060,59.917,3.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.630 | Acc: 43.153,59.912,3.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.626 | Acc: 43.224,59.927,3.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.620 | Acc: 43.269,59.994,3.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.620 | Acc: 43.257,59.940,3.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.623 | Acc: 43.342,59.892,3.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.727 | Acc: 20.312,38.281,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.290 | Acc: 15.848,31.176,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.363 | Acc: 16.139,30.831,2.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.456 | Acc: 15.510,30.571,2.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 8.038 | Acc: 37.500,60.938,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.538 | Acc: 45.089,61.756,2.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.506 | Acc: 45.827,61.681,3.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.582 | Acc: 44.672,60.476,3.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.611 | Acc: 44.309,60.291,3.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.625 | Acc: 43.858,59.901,3.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.614 | Acc: 43.866,60.130,3.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.616 | Acc: 43.722,60.300,3.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.622 | Acc: 43.614,60.045,3.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.622 | Acc: 43.646,60.148,3.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.627 | Acc: 43.505,60.059,3.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.632 | Acc: 43.478,59.912,3.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.632 | Acc: 43.517,59.907,3.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.648 | Acc: 43.463,59.782,3.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.655 | Acc: 43.355,59.728,3.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.662 | Acc: 43.343,59.795,3.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.666 | Acc: 43.244,59.784,3.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.664 | Acc: 43.296,59.677,3.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.652 | Acc: 43.402,59.726,3.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.646 | Acc: 43.293,59.613,3.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.014 | Acc: 37.500,45.312,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.593 | Acc: 29.985,40.625,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.606 | Acc: 30.240,39.806,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.628 | Acc: 30.059,39.575,2.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 7.473 | Acc: 41.406,58.594,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.363 | Acc: 43.527,60.305,6.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.331 | Acc: 43.540,60.309,7.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.325 | Acc: 43.622,60.438,7.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.313 | Acc: 43.721,60.503,8.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.302 | Acc: 43.851,60.659,8.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.294 | Acc: 43.711,60.879,8.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.300 | Acc: 43.739,60.755,8.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.320 | Acc: 43.522,60.588,8.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.328 | Acc: 43.560,60.597,8.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.323 | Acc: 43.699,60.654,8.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.327 | Acc: 43.658,60.496,8.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.335 | Acc: 43.601,60.386,8.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.328 | Acc: 43.651,60.462,8.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.339 | Acc: 43.453,60.368,8.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.346 | Acc: 43.397,60.151,8.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.347 | Acc: 43.344,60.098,8.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.338 | Acc: 43.372,60.106,8.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.341 | Acc: 43.356,60.098,8.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.337 | Acc: 43.352,60.136,8.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.404 | Acc: 25.781,45.312,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.221 | Acc: 22.396,40.513,6.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.277 | Acc: 21.875,38.796,7.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.285 | Acc: 21.849,38.973,6.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 7.091 | Acc: 53.906,65.625,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.176 | Acc: 43.973,60.193,9.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.168 | Acc: 43.598,60.938,9.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.164 | Acc: 43.455,60.912,9.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.186 | Acc: 43.248,60.311,9.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.213 | Acc: 43.185,60.125,9.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.215 | Acc: 43.279,60.363,9.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.207 | Acc: 43.379,60.439,9.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.218 | Acc: 43.342,60.384,9.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.225 | Acc: 43.223,60.281,9.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.224 | Acc: 43.307,60.226,9.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.223 | Acc: 43.230,60.078,9.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.219 | Acc: 43.264,60.046,9.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.219 | Acc: 43.151,60.010,9.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.210 | Acc: 43.305,59.995,9.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.206 | Acc: 43.228,60.019,9.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.202 | Acc: 43.224,60.086,9.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.196 | Acc: 43.253,60.138,9.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.190 | Acc: 43.315,60.126,9.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.188 | Acc: 43.340,60.066,9.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.724 | Acc: 15.625,32.031,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.713 | Acc: 15.327,32.812,8.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.912 | Acc: 14.253,31.726,7.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.887 | Acc: 13.998,30.930,7.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 7.285 | Acc: 39.062,55.469,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.136 | Acc: 42.560,59.673,10.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.097 | Acc: 43.502,60.385,10.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.051 | Acc: 43.699,60.758,10.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.033 | Acc: 43.586,60.503,11.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.039 | Acc: 43.611,60.272,11.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.060 | Acc: 43.395,60.221,11.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.058 | Acc: 43.362,60.278,11.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.056 | Acc: 43.245,60.151,11.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.059 | Acc: 43.331,60.148,11.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.061 | Acc: 43.400,60.125,11.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.061 | Acc: 43.453,60.082,11.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.066 | Acc: 43.371,60.049,11.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.065 | Acc: 43.397,60.129,11.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.064 | Acc: 43.436,60.131,11.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.068 | Acc: 43.441,59.969,11.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.070 | Acc: 43.370,59.923,11.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.070 | Acc: 43.294,59.911,11.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.075 | Acc: 43.200,59.834,11.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.076 | Acc: 43.311,59.758,11.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.155 | Acc: 31.250,52.344,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.102 | Acc: 21.205,45.164,8.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.240 | Acc: 21.608,44.322,8.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.275 | Acc: 21.337,43.852,8.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 6.936 | Acc: 43.750,60.156,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.974 | Acc: 43.973,61.198,12.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.967 | Acc: 43.941,60.766,12.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.949 | Acc: 44.390,61.142,12.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.951 | Acc: 44.203,60.986,12.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.955 | Acc: 43.897,60.829,12.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.965 | Acc: 43.711,60.557,12.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.977 | Acc: 43.285,60.472,13.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.981 | Acc: 43.148,60.282,13.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.989 | Acc: 43.141,60.238,13.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.001 | Acc: 42.910,59.974,13.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.008 | Acc: 42.880,59.937,13.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.015 | Acc: 42.855,59.920,13.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.004 | Acc: 42.993,60.001,13.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.004 | Acc: 42.972,60.001,13.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.010 | Acc: 42.870,59.866,13.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.007 | Acc: 42.876,59.803,13.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.001 | Acc: 42.905,59.785,13.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.006 | Acc: 42.921,59.641,13.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.011 | Acc: 42.944,59.623,13.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.512 | Acc: 28.906,42.969,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.138 | Acc: 21.057,39.769,10.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.233 | Acc: 20.332,38.758,10.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.198 | Acc: 20.120,38.973,10.336,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 6.710 | Acc: 44.531,60.156,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.796 | Acc: 43.824,60.603,15.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.882 | Acc: 44.131,60.156,14.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.904 | Acc: 44.057,59.785,13.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.908 | Acc: 43.846,59.848,13.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.907 | Acc: 43.928,60.048,13.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.909 | Acc: 43.724,59.892,13.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.927 | Acc: 43.684,59.680,13.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.936 | Acc: 43.469,59.642,13.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.936 | Acc: 43.400,59.500,13.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.936 | Acc: 43.365,59.507,13.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.954 | Acc: 43.237,59.410,13.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.967 | Acc: 43.147,59.223,13.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.972 | Acc: 43.109,59.195,13.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.978 | Acc: 43.002,59.105,13.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.986 | Acc: 42.935,59.058,13.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.991 | Acc: 42.857,58.959,13.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.997 | Acc: 42.840,58.908,13.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.997 | Acc: 42.874,58.879,13.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.999 | Acc: 42.854,58.823,13.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.300 | Acc: 24.219,44.531,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.595 | Acc: 21.652,41.183,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.706 | Acc: 21.570,40.396,8.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.714 | Acc: 20.889,39.754,8.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 6.574 | Acc: 44.531,64.062,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.890 | Acc: 42.262,59.524,14.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.921 | Acc: 42.969,59.165,15.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.923 | Acc: 42.841,58.773,15.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.895 | Acc: 42.785,59.153,15.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.899 | Acc: 42.961,59.383,15.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.878 | Acc: 43.434,59.569,15.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.895 | Acc: 43.235,59.292,15.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.913 | Acc: 43.119,59.128,15.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.915 | Acc: 42.939,58.883,15.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.918 | Acc: 42.949,58.909,15.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.917 | Acc: 42.944,58.845,15.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.915 | Acc: 43.008,58.863,15.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.937 | Acc: 42.882,58.597,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.942 | Acc: 42.958,58.630,14.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.946 | Acc: 42.797,58.552,14.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.945 | Acc: 42.867,58.557,14.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.947 | Acc: 42.829,58.424,14.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.943 | Acc: 42.854,58.466,14.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.948 | Acc: 42.821,58.454,14.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.493 | Acc: 30.469,41.406,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.731 | Acc: 24.628,38.616,5.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.874 | Acc: 24.333,37.252,5.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.869 | Acc: 24.385,37.090,4.764,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 7.244 | Acc: 35.156,50.781,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.830 | Acc: 42.336,59.970,15.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.701 | Acc: 43.598,61.242,15.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.761 | Acc: 43.046,60.758,15.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.809 | Acc: 43.412,60.417,15.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.846 | Acc: 43.332,60.056,15.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.878 | Acc: 43.001,59.536,15.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.878 | Acc: 43.063,59.225,15.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.891 | Acc: 42.954,59.040,15.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.909 | Acc: 42.783,58.650,15.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.924 | Acc: 42.693,58.500,15.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.931 | Acc: 42.658,58.353,15.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.935 | Acc: 42.596,58.227,15.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.941 | Acc: 42.523,58.166,15.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.944 | Acc: 42.610,58.057,15.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.943 | Acc: 42.574,58.051,15.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.940 | Acc: 42.555,58.056,15.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.940 | Acc: 42.566,58.122,15.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.939 | Acc: 42.555,58.105,15.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.939 | Acc: 42.530,58.009,15.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.692 | Acc: 21.094,35.938,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.966 | Acc: 20.908,37.426,9.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.030 | Acc: 21.284,36.814,9.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.033 | Acc: 20.876,36.565,9.477,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 7.245 | Acc: 34.375,55.469,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.960 | Acc: 41.853,58.929,13.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.935 | Acc: 42.645,58.994,14.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.978 | Acc: 42.469,58.197,14.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.961 | Acc: 42.554,58.266,14.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.962 | Acc: 42.551,58.114,15.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.962 | Acc: 42.575,58.058,15.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.954 | Acc: 42.625,58.355,15.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.934 | Acc: 42.702,58.327,15.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.934 | Acc: 42.645,58.240,15.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.937 | Acc: 42.716,58.038,15.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.945 | Acc: 42.583,57.851,15.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.947 | Acc: 42.528,57.780,15.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.946 | Acc: 42.478,57.786,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.951 | Acc: 42.393,57.787,15.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.947 | Acc: 42.390,57.781,15.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.948 | Acc: 42.370,57.791,15.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.942 | Acc: 42.368,57.783,15.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.949 | Acc: 42.324,57.683,15.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.953 | Acc: 42.257,57.646,15.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.177 | Acc: 25.000,37.500,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.399 | Acc: 21.280,36.421,7.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.510 | Acc: 20.808,35.728,7.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.542 | Acc: 20.671,35.643,7.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 7.114 | Acc: 42.188,56.250,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.103 | Acc: 41.555,56.734,13.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.055 | Acc: 42.588,56.841,13.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.973 | Acc: 43.251,57.736,14.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.947 | Acc: 43.113,57.948,15.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.940 | Acc: 43.015,58.021,15.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.920 | Acc: 42.904,58.155,15.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.902 | Acc: 42.880,58.145,15.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.885 | Acc: 42.911,58.235,15.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.901 | Acc: 42.822,58.071,15.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.900 | Acc: 42.736,57.886,15.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.899 | Acc: 42.537,57.876,15.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.895 | Acc: 42.564,58.039,16.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.898 | Acc: 42.508,57.911,16.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.891 | Acc: 42.415,57.943,16.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.897 | Acc: 42.390,57.846,16.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.906 | Acc: 42.226,57.618,16.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.916 | Acc: 42.204,57.547,16.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.919 | Acc: 42.138,57.479,16.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.927 | Acc: 42.114,57.421,16.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.472 | Acc: 32.031,47.656,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.873 | Acc: 29.353,44.048,12.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.917 | Acc: 29.002,43.083,12.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.946 | Acc: 28.356,42.841,13.217,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 6.892 | Acc: 37.500,56.250,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.885 | Acc: 41.927,57.626,16.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.937 | Acc: 41.349,57.222,16.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.902 | Acc: 42.495,57.761,16.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.895 | Acc: 42.795,57.812,16.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.903 | Acc: 42.628,57.758,16.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.877 | Acc: 43.014,58.071,16.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.873 | Acc: 42.880,57.973,16.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.878 | Acc: 42.644,57.866,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.884 | Acc: 42.563,57.778,16.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.885 | Acc: 42.440,57.743,16.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.884 | Acc: 42.403,57.735,16.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.874 | Acc: 42.418,57.929,16.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.874 | Acc: 42.430,57.884,16.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.893 | Acc: 42.343,57.754,16.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.898 | Acc: 42.330,57.758,16.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.912 | Acc: 42.265,57.528,16.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.914 | Acc: 42.169,57.496,15.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.917 | Acc: 42.110,57.403,15.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.917 | Acc: 42.060,57.396,16.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.585 | Acc: 27.344,42.969,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.721 | Acc: 24.442,38.356,11.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.787 | Acc: 23.609,37.805,11.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.764 | Acc: 23.668,37.718,11.706,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 7.146 | Acc: 42.188,52.344,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.815 | Acc: 41.927,57.589,16.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.919 | Acc: 41.597,56.993,16.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.895 | Acc: 42.213,57.031,16.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.929 | Acc: 42.101,56.954,16.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.908 | Acc: 42.095,57.047,16.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.928 | Acc: 42.233,56.999,16.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.951 | Acc: 42.115,56.760,15.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.975 | Acc: 41.833,56.434,15.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.984 | Acc: 41.924,56.410,15.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.983 | Acc: 41.947,56.584,15.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.979 | Acc: 42.043,56.678,15.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.974 | Acc: 42.087,56.769,15.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.959 | Acc: 42.149,56.941,15.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.954 | Acc: 42.174,57.051,15.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.945 | Acc: 42.322,57.156,15.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.935 | Acc: 42.394,57.197,15.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.932 | Acc: 42.460,57.176,15.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.938 | Acc: 42.410,57.126,15.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.937 | Acc: 42.372,57.117,15.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.144 | Acc: 31.250,44.531,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.422 | Acc: 26.116,41.667,10.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.530 | Acc: 25.362,40.149,10.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.548 | Acc: 25.231,39.549,10.207,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 6.834 | Acc: 44.531,55.469,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.884 | Acc: 42.708,58.185,16.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.830 | Acc: 42.721,58.060,16.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.820 | Acc: 42.777,58.133,16.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.818 | Acc: 42.892,58.169,16.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.815 | Acc: 42.644,58.168,16.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.823 | Acc: 42.807,57.871,16.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.829 | Acc: 42.503,57.724,16.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.857 | Acc: 42.435,57.526,16.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.859 | Acc: 42.300,57.601,16.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.862 | Acc: 42.226,57.498,16.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.874 | Acc: 42.074,57.356,16.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.880 | Acc: 42.003,57.307,16.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.885 | Acc: 42.047,57.307,16.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.880 | Acc: 42.126,57.351,16.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.888 | Acc: 42.094,57.314,16.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.886 | Acc: 42.102,57.204,16.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.886 | Acc: 42.181,57.242,16.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.884 | Acc: 42.220,57.207,16.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.885 | Acc: 42.173,57.253,16.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.233 | Acc: 32.812,46.094,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.736 | Acc: 24.665,39.844,9.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.783 | Acc: 24.543,39.501,9.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.864 | Acc: 24.488,38.960,9.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 6.669 | Acc: 42.969,63.281,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.863 | Acc: 43.899,59.933,15.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.781 | Acc: 43.960,60.061,16.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.818 | Acc: 43.302,59.349,16.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.814 | Acc: 42.901,58.854,16.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.829 | Acc: 42.659,58.308,16.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.831 | Acc: 42.452,58.045,16.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.806 | Acc: 42.653,58.095,16.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.796 | Acc: 42.648,58.176,17.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.798 | Acc: 42.615,58.162,17.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.796 | Acc: 42.739,58.174,16.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.822 | Acc: 42.368,57.880,16.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.838 | Acc: 42.350,57.689,16.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.847 | Acc: 42.289,57.567,16.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.845 | Acc: 42.315,57.573,16.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.853 | Acc: 42.278,57.457,16.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.854 | Acc: 42.282,57.391,16.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.868 | Acc: 42.199,57.164,16.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.872 | Acc: 42.209,57.124,16.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.874 | Acc: 42.196,57.085,16.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.321 | Acc: 25.781,46.875,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.331 | Acc: 21.391,42.150,11.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.389 | Acc: 21.018,41.330,12.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.413 | Acc: 21.478,41.317,12.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 6.544 | Acc: 43.750,59.375,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.753 | Acc: 42.969,57.850,16.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.784 | Acc: 42.873,57.660,16.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.815 | Acc: 42.418,56.903,17.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.815 | Acc: 42.303,56.993,17.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.841 | Acc: 42.443,57.024,16.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.855 | Acc: 42.388,56.954,16.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.862 | Acc: 42.243,56.843,16.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.869 | Acc: 42.144,56.667,16.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.875 | Acc: 42.002,56.647,16.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.882 | Acc: 42.020,56.689,16.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.870 | Acc: 42.032,56.798,16.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.879 | Acc: 41.909,56.727,16.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.884 | Acc: 41.822,56.564,16.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.885 | Acc: 41.807,56.623,16.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.884 | Acc: 41.811,56.598,16.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.893 | Acc: 41.796,56.542,16.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.894 | Acc: 41.777,56.500,16.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.896 | Acc: 41.794,56.568,16.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.900 | Acc: 41.726,56.519,16.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.832 | Acc: 21.094,39.844,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.750 | Acc: 19.382,36.719,15.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.760 | Acc: 19.550,36.738,15.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.730 | Acc: 19.173,36.796,14.767,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 6.826 | Acc: 42.969,60.938,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.706 | Acc: 43.080,58.780,16.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.777 | Acc: 42.931,57.774,16.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.865 | Acc: 41.816,56.673,16.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.832 | Acc: 41.927,57.051,16.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.849 | Acc: 41.832,56.799,16.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.858 | Acc: 42.045,56.792,16.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.878 | Acc: 41.883,56.782,16.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.897 | Acc: 41.518,56.517,16.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.905 | Acc: 41.527,56.401,16.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.917 | Acc: 41.453,56.293,16.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.911 | Acc: 41.438,56.303,16.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.902 | Acc: 41.578,56.457,16.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.898 | Acc: 41.565,56.627,16.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.914 | Acc: 41.498,56.361,16.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.909 | Acc: 41.536,56.320,16.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.894 | Acc: 41.667,56.486,16.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.892 | Acc: 41.654,56.445,16.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.891 | Acc: 41.759,56.555,16.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.897 | Acc: 41.675,56.443,16.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.793 | Acc: 35.938,44.531,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.861 | Acc: 27.493,43.118,13.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.996 | Acc: 27.439,41.616,13.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.003 | Acc: 27.228,41.483,12.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 7.285 | Acc: 42.969,53.906,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.031 | Acc: 40.513,55.320,15.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.979 | Acc: 41.178,55.697,16.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.915 | Acc: 41.957,56.173,16.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.865 | Acc: 42.467,56.318,16.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.891 | Acc: 42.002,56.157,17.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.887 | Acc: 42.091,56.353,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.885 | Acc: 42.049,56.566,17.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.888 | Acc: 41.925,56.478,17.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.891 | Acc: 41.795,56.414,17.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.884 | Acc: 41.795,56.413,17.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.887 | Acc: 41.724,56.497,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.887 | Acc: 41.643,56.464,17.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.893 | Acc: 41.604,56.427,17.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.903 | Acc: 41.406,56.278,17.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.893 | Acc: 41.520,56.364,16.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.886 | Acc: 41.533,56.484,17.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.888 | Acc: 41.535,56.509,16.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.885 | Acc: 41.575,56.568,16.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.881 | Acc: 41.661,56.691,17.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.792 | Acc: 24.219,46.094,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.205 | Acc: 21.540,38.058,9.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.192 | Acc: 21.399,37.767,9.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.170 | Acc: 21.286,37.359,9.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 6.947 | Acc: 39.062,55.469,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.816 | Acc: 41.592,56.548,18.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.778 | Acc: 41.273,57.088,18.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.801 | Acc: 41.381,56.711,17.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.832 | Acc: 41.358,56.318,17.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.853 | Acc: 41.476,56.265,16.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.855 | Acc: 41.581,56.127,16.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.845 | Acc: 41.800,56.189,16.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.845 | Acc: 41.770,56.444,16.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.848 | Acc: 41.838,56.496,16.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.845 | Acc: 41.869,56.444,16.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.861 | Acc: 41.866,56.384,16.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.875 | Acc: 41.743,56.334,16.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.894 | Acc: 41.517,56.130,16.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.904 | Acc: 41.476,56.092,16.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.925 | Acc: 41.367,55.913,16.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.941 | Acc: 41.263,55.654,16.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.937 | Acc: 41.312,55.673,16.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.937 | Acc: 41.315,55.681,16.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.942 | Acc: 41.279,55.635,16.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.134 | Acc: 25.781,40.625,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.739 | Acc: 20.350,38.802,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.893 | Acc: 19.398,37.329,12.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.912 | Acc: 19.493,37.065,12.282,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 6.857 | Acc: 41.406,57.031,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.939 | Acc: 40.327,55.618,17.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.957 | Acc: 40.549,54.821,17.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.888 | Acc: 41.189,55.648,17.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.920 | Acc: 40.837,55.449,17.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.989 | Acc: 40.323,54.935,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.049 | Acc: 40.115,54.384,17.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.070 | Acc: 40.016,54.272,16.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.054 | Acc: 40.314,54.430,16.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.045 | Acc: 40.504,54.498,16.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.025 | Acc: 40.699,54.653,16.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.017 | Acc: 40.890,54.726,16.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.010 | Acc: 41.008,54.898,16.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.011 | Acc: 40.942,54.879,16.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.007 | Acc: 40.984,54.924,16.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.009 | Acc: 40.970,54.913,16.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.002 | Acc: 41.051,54.963,16.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.004 | Acc: 41.008,54.903,16.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.004 | Acc: 41.043,54.900,16.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.005 | Acc: 40.984,54.825,16.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.075 | Acc: 25.781,45.312,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.206 | Acc: 21.019,42.671,16.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.246 | Acc: 20.713,41.749,15.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.255 | Acc: 20.940,41.317,15.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 6.397 | Acc: 34.375,56.250,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.838 | Acc: 40.290,56.920,18.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.888 | Acc: 39.958,55.755,17.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.882 | Acc: 40.612,56.276,17.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.841 | Acc: 41.609,56.617,17.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.815 | Acc: 41.778,56.567,17.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.853 | Acc: 41.613,56.179,17.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.856 | Acc: 41.539,55.979,17.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.873 | Acc: 41.484,55.939,17.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.893 | Acc: 41.367,55.654,17.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.931 | Acc: 41.224,55.379,17.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.950 | Acc: 41.283,55.246,16.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.954 | Acc: 41.335,55.206,16.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.958 | Acc: 41.281,55.128,17.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.952 | Acc: 41.317,55.185,17.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.951 | Acc: 41.341,55.092,17.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.963 | Acc: 41.302,54.977,17.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.963 | Acc: 41.386,54.875,17.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.960 | Acc: 41.402,54.900,17.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.965 | Acc: 41.351,54.913,17.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.805 | Acc: 13.281,28.906,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.384 | Acc: 11.756,27.083,15.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.570 | Acc: 11.795,26.220,14.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.610 | Acc: 11.757,26.473,14.805,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 6.742 | Acc: 42.188,54.688,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.713 | Acc: 43.676,57.552,17.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.811 | Acc: 42.588,57.355,17.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.811 | Acc: 42.380,57.326,17.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.925 | Acc: 41.715,56.250,16.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.914 | Acc: 41.607,55.856,16.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.883 | Acc: 41.684,56.218,16.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.906 | Acc: 41.689,56.084,16.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.946 | Acc: 41.518,55.512,16.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.955 | Acc: 41.549,55.292,16.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.953 | Acc: 41.465,55.286,16.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.980 | Acc: 41.184,54.914,16.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.019 | Acc: 40.933,54.551,16.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.043 | Acc: 40.823,54.259,16.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.059 | Acc: 40.725,54.031,16.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.054 | Acc: 40.827,54.065,16.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.064 | Acc: 40.715,54.033,16.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.058 | Acc: 40.680,54.007,16.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.065 | Acc: 40.612,54.006,16.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.077 | Acc: 40.570,53.919,16.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.092 | Acc: 26.562,46.875,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.321 | Acc: 24.702,41.369,13.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.411 | Acc: 23.971,40.187,13.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.405 | Acc: 23.630,39.844,13.371,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 6.700 | Acc: 42.188,60.938,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.939 | Acc: 42.969,55.804,15.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.090 | Acc: 41.349,54.230,15.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.351 | Acc: 39.959,51.767,14.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.308 | Acc: 40.017,51.649,14.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.232 | Acc: 40.339,52.398,14.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.197 | Acc: 40.470,52.751,15.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.162 | Acc: 40.531,53.059,15.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.139 | Acc: 40.431,53.174,15.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.104 | Acc: 40.685,53.557,15.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.085 | Acc: 40.629,53.770,15.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.074 | Acc: 40.703,53.963,16.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.055 | Acc: 40.800,54.104,16.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.046 | Acc: 40.885,54.250,16.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.055 | Acc: 40.820,54.181,16.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.067 | Acc: 40.799,53.963,16.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.064 | Acc: 40.810,53.994,16.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.064 | Acc: 40.829,53.986,16.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.065 | Acc: 40.850,53.986,16.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.069 | Acc: 40.818,53.980,16.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.968 | Acc: 27.344,38.281,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.907 | Acc: 19.494,31.585,10.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.965 | Acc: 19.531,30.926,9.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.900 | Acc: 19.877,31.186,9.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 7.205 | Acc: 40.625,55.469,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.169 | Acc: 40.365,53.981,15.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.115 | Acc: 39.863,54.116,16.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.073 | Acc: 39.741,54.162,16.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.982 | Acc: 40.673,55.112,17.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.965 | Acc: 40.919,55.206,17.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.960 | Acc: 41.006,55.165,17.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.976 | Acc: 41.113,55.092,17.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.977 | Acc: 41.003,54.828,17.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.971 | Acc: 41.018,54.968,17.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.958 | Acc: 41.107,55.045,17.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.966 | Acc: 41.099,55.009,17.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.976 | Acc: 41.011,54.820,17.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.980 | Acc: 40.936,54.756,17.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.972 | Acc: 41.000,54.829,17.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.971 | Acc: 40.986,54.854,17.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.976 | Acc: 40.907,54.807,17.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.978 | Acc: 40.898,54.868,17.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.988 | Acc: 40.794,54.716,17.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.986 | Acc: 40.773,54.716,17.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.032 | Acc: 27.344,46.875,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.740 | Acc: 22.991,39.621,8.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.729 | Acc: 23.609,39.386,8.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.752 | Acc: 23.271,38.845,7.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 6.967 | Acc: 36.719,49.219,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.043 | Acc: 40.253,54.241,16.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.949 | Acc: 40.454,55.373,16.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.913 | Acc: 41.022,55.622,16.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.862 | Acc: 41.252,55.777,17.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.863 | Acc: 41.545,55.593,17.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.857 | Acc: 41.613,55.546,17.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.869 | Acc: 41.611,55.430,17.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.898 | Acc: 41.363,55.309,17.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.942 | Acc: 40.949,54.895,17.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.942 | Acc: 40.994,54.824,17.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.952 | Acc: 40.982,54.850,17.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.950 | Acc: 40.998,54.963,17.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.954 | Acc: 41.029,54.984,17.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.951 | Acc: 41.053,55.107,17.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.954 | Acc: 40.999,55.033,17.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.946 | Acc: 41.070,55.038,17.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.951 | Acc: 41.145,55.049,17.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.954 | Acc: 41.116,54.982,17.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.955 | Acc: 41.129,55.003,17.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.238 | Acc: 12.500,28.906,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.288 | Acc: 12.314,26.265,9.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.364 | Acc: 12.043,25.419,9.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.379 | Acc: 12.129,24.859,9.375,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 7.241 | Acc: 39.844,56.250,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.617 | Acc: 37.946,49.516,14.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.507 | Acc: 38.148,50.000,14.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.350 | Acc: 39.460,51.255,15.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.275 | Acc: 40.027,51.852,15.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.272 | Acc: 39.635,51.841,15.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.239 | Acc: 39.870,52.215,15.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.213 | Acc: 40.082,52.449,16.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.164 | Acc: 40.460,52.926,16.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.159 | Acc: 40.461,53.129,16.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.167 | Acc: 40.450,53.024,15.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.162 | Acc: 40.342,52.825,16.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.145 | Acc: 40.450,53.015,16.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.120 | Acc: 40.574,53.233,16.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.112 | Acc: 40.583,53.306,16.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.112 | Acc: 40.586,53.356,16.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.104 | Acc: 40.581,53.351,16.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.107 | Acc: 40.540,53.366,16.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.110 | Acc: 40.450,53.409,16.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.118 | Acc: 40.334,53.299,16.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.034 | Acc: 18.750,38.281,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.844 | Acc: 19.717,37.277,10.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.952 | Acc: 19.322,35.842,9.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.988 | Acc: 19.198,35.617,9.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 7.295 | Acc: 39.844,52.344,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.006 | Acc: 41.815,54.576,15.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.985 | Acc: 41.463,54.592,16.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.943 | Acc: 41.573,55.482,16.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.961 | Acc: 41.358,55.170,16.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.949 | Acc: 41.267,55.067,16.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.970 | Acc: 41.200,55.133,16.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.007 | Acc: 41.146,54.715,16.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.019 | Acc: 41.018,54.498,16.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.014 | Acc: 40.940,54.454,16.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.010 | Acc: 40.971,54.481,17.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.020 | Acc: 41.024,54.507,16.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.022 | Acc: 40.949,54.389,16.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.013 | Acc: 41.083,54.520,16.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.046 | Acc: 40.758,54.148,16.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.050 | Acc: 40.794,54.111,16.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.050 | Acc: 40.766,54.026,16.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.058 | Acc: 40.721,54.032,16.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.052 | Acc: 40.789,54.086,16.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.049 | Acc: 40.885,54.068,16.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.086 | Acc: 14.062,26.562,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.023 | Acc: 13.393,26.786,9.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.142 | Acc: 13.319,26.524,9.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.136 | Acc: 13.051,26.434,9.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 7.677 | Acc: 32.031,48.438,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.189 | Acc: 39.732,52.567,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.045 | Acc: 39.996,53.335,17.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.987 | Acc: 40.535,53.970,17.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.006 | Acc: 40.866,54.234,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.021 | Acc: 40.733,54.022,17.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.032 | Acc: 40.690,53.790,17.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.030 | Acc: 40.752,54.023,17.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.040 | Acc: 40.727,53.906,17.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.058 | Acc: 40.724,53.690,17.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.068 | Acc: 40.672,53.494,17.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.099 | Acc: 40.515,53.334,17.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.128 | Acc: 40.298,52.921,16.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.155 | Acc: 40.128,52.655,16.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.156 | Acc: 40.105,52.602,16.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.156 | Acc: 40.072,52.538,16.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.152 | Acc: 40.177,52.646,16.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.146 | Acc: 40.263,52.745,16.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.135 | Acc: 40.309,52.859,16.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.121 | Acc: 40.465,52.945,16.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.394 | Acc: 29.688,43.750,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.848 | Acc: 25.000,39.769,7.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.919 | Acc: 24.714,39.710,7.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.969 | Acc: 24.270,39.562,7.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 6.950 | Acc: 39.062,54.688,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.976 | Acc: 41.927,55.208,15.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.936 | Acc: 42.321,55.393,16.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.900 | Acc: 42.482,55.712,16.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.921 | Acc: 41.850,55.006,17.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.961 | Acc: 41.662,54.510,16.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.956 | Acc: 41.555,54.662,17.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.968 | Acc: 41.478,54.610,17.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.017 | Acc: 41.071,54.173,17.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.030 | Acc: 40.914,54.057,17.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.047 | Acc: 40.924,53.980,17.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.101 | Acc: 40.544,53.394,16.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.115 | Acc: 40.453,53.196,16.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.114 | Acc: 40.508,53.230,16.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.139 | Acc: 40.366,52.997,16.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.151 | Acc: 40.303,52.839,16.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.152 | Acc: 40.287,52.770,16.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.146 | Acc: 40.309,52.829,16.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.157 | Acc: 40.255,52.703,16.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.160 | Acc: 40.201,52.629,16.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.406 | Acc: 18.750,35.156,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.596 | Acc: 20.312,37.835,15.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.675 | Acc: 19.646,37.100,14.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.679 | Acc: 19.314,36.911,14.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 7.266 | Acc: 39.062,44.531,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.849 | Acc: 42.560,54.129,17.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.847 | Acc: 42.149,55.088,17.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.958 | Acc: 41.253,53.957,17.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.011 | Acc: 40.615,53.713,17.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.012 | Acc: 40.702,53.999,17.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.015 | Acc: 40.631,53.880,17.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.034 | Acc: 40.708,53.762,17.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.034 | Acc: 40.892,54.028,17.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.999 | Acc: 41.052,54.385,17.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.003 | Acc: 41.107,54.342,17.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.021 | Acc: 41.032,54.147,17.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.028 | Acc: 41.033,54.020,17.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.018 | Acc: 41.071,54.080,17.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.008 | Acc: 41.167,54.151,17.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.036 | Acc: 40.942,53.813,17.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.042 | Acc: 40.946,53.814,17.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.046 | Acc: 40.866,53.679,17.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.050 | Acc: 40.794,53.677,17.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.056 | Acc: 40.674,53.588,17.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.120 | Acc: 18.750,36.719,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.693 | Acc: 17.411,32.924,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.808 | Acc: 16.273,31.841,12.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.818 | Acc: 16.201,31.814,12.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 6.711 | Acc: 51.562,60.938,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.994 | Acc: 41.927,53.609,16.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.938 | Acc: 42.226,54.688,17.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.962 | Acc: 42.085,54.713,16.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.978 | Acc: 41.860,54.716,16.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.994 | Acc: 41.870,54.595,16.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.005 | Acc: 41.593,54.403,16.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.010 | Acc: 41.517,54.211,16.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.058 | Acc: 41.091,53.804,16.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.117 | Acc: 40.655,53.401,16.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.209 | Acc: 40.011,52.476,15.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.268 | Acc: 39.709,51.835,15.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.285 | Acc: 39.633,51.546,15.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.282 | Acc: 39.592,51.622,15.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.273 | Acc: 39.674,51.793,15.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.266 | Acc: 39.779,51.918,15.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.258 | Acc: 39.839,52.074,15.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.258 | Acc: 39.830,52.167,15.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.264 | Acc: 39.729,52.149,15.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.268 | Acc: 39.696,52.130,15.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.832 | Acc: 9.375,25.781,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.082 | Acc: 11.161,23.810,8.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.197 | Acc: 10.404,22.961,8.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.224 | Acc: 10.259,22.733,7.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 7.491 | Acc: 38.281,49.219,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.203 | Acc: 39.323,52.269,15.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.103 | Acc: 39.596,52.973,16.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.046 | Acc: 40.715,53.573,17.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.064 | Acc: 40.355,53.588,17.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.032 | Acc: 40.656,53.868,17.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.997 | Acc: 40.922,54.358,17.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.985 | Acc: 40.924,54.449,17.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.984 | Acc: 41.008,54.556,17.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.994 | Acc: 41.013,54.441,17.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.033 | Acc: 40.963,54.050,16.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.048 | Acc: 41.000,53.913,16.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.042 | Acc: 41.050,53.987,16.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.049 | Acc: 41.035,53.987,16.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.057 | Acc: 41.000,53.920,16.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.070 | Acc: 40.895,53.901,16.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.069 | Acc: 40.895,53.909,16.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.073 | Acc: 40.918,53.888,16.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.085 | Acc: 40.831,53.748,16.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.083 | Acc: 40.816,53.707,16.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.460 | Acc: 21.094,40.625,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.638 | Acc: 21.019,36.235,15.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.751 | Acc: 20.922,35.252,14.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.781 | Acc: 20.684,35.182,14.524,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 6.403 | Acc: 47.656,60.156,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.055 | Acc: 40.402,54.762,16.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.021 | Acc: 40.530,53.944,16.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.059 | Acc: 40.804,53.548,16.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.058 | Acc: 41.107,53.578,16.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.054 | Acc: 41.027,53.713,16.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.040 | Acc: 41.103,53.893,16.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.060 | Acc: 40.802,53.613,16.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.074 | Acc: 40.712,53.377,16.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.077 | Acc: 40.694,53.539,16.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.072 | Acc: 40.827,53.681,16.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.061 | Acc: 40.950,53.747,16.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.056 | Acc: 40.939,53.858,16.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.043 | Acc: 40.978,53.936,16.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.034 | Acc: 41.045,54.059,16.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.029 | Acc: 41.074,54.002,16.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.014 | Acc: 41.314,54.210,16.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.007 | Acc: 41.326,54.300,17.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.008 | Acc: 41.302,54.263,17.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.991 | Acc: 41.363,54.415,17.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.130 | Acc: 32.812,50.781,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.151 | Acc: 28.943,47.173,16.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.205 | Acc: 28.335,45.560,16.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.215 | Acc: 28.099,45.479,16.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 6.440 | Acc: 46.094,57.812,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.577 | Acc: 44.606,57.403,21.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.546 | Acc: 44.284,57.698,21.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.599 | Acc: 43.852,57.198,20.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.588 | Acc: 44.117,57.224,20.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.593 | Acc: 44.121,57.201,20.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.603 | Acc: 43.931,57.315,20.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.577 | Acc: 44.055,57.552,21.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.589 | Acc: 43.745,57.318,20.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.576 | Acc: 43.715,57.489,21.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.587 | Acc: 43.458,57.292,21.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.596 | Acc: 43.432,57.279,21.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.605 | Acc: 43.348,57.307,21.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.603 | Acc: 43.292,57.244,21.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.599 | Acc: 43.163,57.334,21.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.596 | Acc: 43.104,57.325,21.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.592 | Acc: 43.122,57.443,21.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.584 | Acc: 43.079,57.473,21.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.579 | Acc: 43.081,57.577,21.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.577 | Acc: 43.151,57.640,21.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.969 | Acc: 22.656,43.750,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.567 | Acc: 21.652,39.695,13.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.499 | Acc: 22.332,40.168,12.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.527 | Acc: 22.170,40.151,12.935,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 6.379 | Acc: 46.094,60.938,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.469 | Acc: 43.378,59.487,22.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.431 | Acc: 42.778,59.775,22.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.402 | Acc: 43.340,59.785,22.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.391 | Acc: 43.432,59.578,22.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.438 | Acc: 43.123,58.834,22.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.440 | Acc: 43.040,58.742,22.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.470 | Acc: 42.847,58.394,22.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.458 | Acc: 42.891,58.502,22.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.472 | Acc: 42.822,58.339,22.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.466 | Acc: 42.918,58.314,22.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.462 | Acc: 42.841,58.261,22.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.480 | Acc: 42.849,58.020,22.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.528 | Acc: 42.511,57.567,22.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.546 | Acc: 42.418,57.398,22.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.557 | Acc: 42.309,57.244,22.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.557 | Acc: 42.326,57.236,22.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.557 | Acc: 42.380,57.302,22.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.547 | Acc: 42.480,57.380,22.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.555 | Acc: 42.411,57.302,22.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.137 | Acc: 25.000,44.531,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.059 | Acc: 24.033,44.680,12.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.194 | Acc: 23.056,43.502,12.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.199 | Acc: 22.900,43.481,12.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 6.498 | Acc: 52.344,58.594,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.347 | Acc: 44.494,59.412,23.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.301 | Acc: 45.351,59.394,24.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.305 | Acc: 44.723,59.221,24.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.350 | Acc: 44.097,58.835,24.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.361 | Acc: 43.982,58.609,24.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.367 | Acc: 43.963,58.574,24.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.381 | Acc: 43.767,58.538,24.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.396 | Acc: 43.638,58.492,24.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.395 | Acc: 43.625,58.391,24.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.399 | Acc: 43.521,58.298,24.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.401 | Acc: 43.492,58.261,24.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.406 | Acc: 43.487,58.263,24.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.410 | Acc: 43.382,58.279,24.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.419 | Acc: 43.311,58.088,24.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.415 | Acc: 43.304,58.140,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.402 | Acc: 43.368,58.316,24.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.399 | Acc: 43.347,58.307,24.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.405 | Acc: 43.265,58.217,24.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.411 | Acc: 43.168,58.061,24.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.890 | Acc: 26.562,49.219,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.964 | Acc: 27.530,48.140,19.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.013 | Acc: 28.030,47.199,19.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.056 | Acc: 27.959,46.977,19.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 6.130 | Acc: 44.531,58.594,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.282 | Acc: 44.122,59.487,25.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.298 | Acc: 43.464,59.165,26.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.294 | Acc: 43.391,58.965,26.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.324 | Acc: 43.258,58.825,26.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.295 | Acc: 43.386,59.352,26.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.298 | Acc: 43.782,59.304,26.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.321 | Acc: 43.672,58.865,25.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.329 | Acc: 43.619,58.599,26.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.350 | Acc: 43.344,58.175,25.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.364 | Acc: 43.458,58.116,25.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.369 | Acc: 43.549,58.106,25.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.377 | Acc: 43.380,57.952,25.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.386 | Acc: 43.310,57.941,25.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.393 | Acc: 43.147,57.832,25.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.397 | Acc: 43.086,57.667,25.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.394 | Acc: 43.178,57.669,26.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.398 | Acc: 43.129,57.680,25.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.404 | Acc: 42.971,57.663,25.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.405 | Acc: 42.934,57.636,25.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.252 | Acc: 25.000,37.500,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.807 | Acc: 23.624,41.629,19.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.926 | Acc: 23.152,40.816,18.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.899 | Acc: 23.591,40.868,18.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 6.437 | Acc: 36.719,55.469,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.452 | Acc: 41.704,56.213,25.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.338 | Acc: 42.645,57.412,26.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.317 | Acc: 42.738,57.608,26.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.318 | Acc: 42.824,57.976,26.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.312 | Acc: 42.799,58.052,26.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.320 | Acc: 42.794,58.252,26.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.301 | Acc: 43.041,58.522,26.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.293 | Acc: 43.056,58.579,26.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.293 | Acc: 43.072,58.628,26.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.292 | Acc: 43.050,58.442,27.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.302 | Acc: 43.029,58.329,26.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.301 | Acc: 42.972,58.325,26.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.295 | Acc: 42.987,58.303,27.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.296 | Acc: 42.952,58.274,27.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.295 | Acc: 42.982,58.275,27.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.304 | Acc: 42.988,58.258,27.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.295 | Acc: 43.099,58.321,27.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.300 | Acc: 43.051,58.254,27.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.309 | Acc: 43.043,58.143,27.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.747 | Acc: 21.094,36.719,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.918 | Acc: 19.829,36.458,20.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.011 | Acc: 19.322,35.785,21.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.069 | Acc: 18.852,35.963,20.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 6.949 | Acc: 42.969,56.250,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.245 | Acc: 43.006,57.143,26.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.232 | Acc: 43.788,58.155,27.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.266 | Acc: 43.814,58.017,27.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.326 | Acc: 43.229,57.610,27.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.527 | Acc: 41.870,56.149,26.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.577 | Acc: 41.613,55.449,25.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.589 | Acc: 41.395,55.192,25.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.593 | Acc: 41.280,54.993,25.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.563 | Acc: 41.454,55.193,26.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.544 | Acc: 41.542,55.298,26.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.536 | Acc: 41.647,55.419,26.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.528 | Acc: 41.669,55.478,26.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.511 | Acc: 41.691,55.574,26.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.508 | Acc: 41.729,55.569,26.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.505 | Acc: 41.733,55.645,26.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.495 | Acc: 41.891,55.744,26.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.494 | Acc: 41.922,55.817,26.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.499 | Acc: 41.874,55.780,26.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.490 | Acc: 41.857,55.875,26.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.558 | Acc: 25.000,43.750,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.356 | Acc: 27.083,42.932,21.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.338 | Acc: 27.287,42.435,20.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.348 | Acc: 27.177,42.059,20.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 6.340 | Acc: 42.188,59.375,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.213 | Acc: 42.783,58.519,29.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.272 | Acc: 42.588,57.793,28.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.267 | Acc: 42.725,57.787,29.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.295 | Acc: 42.535,57.822,29.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.288 | Acc: 42.683,57.658,28.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.273 | Acc: 42.833,57.967,28.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.278 | Acc: 42.736,57.890,28.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.274 | Acc: 42.901,57.919,28.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.266 | Acc: 42.921,58.076,28.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.270 | Acc: 42.833,58.104,28.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.290 | Acc: 42.721,57.940,28.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.312 | Acc: 42.735,57.851,28.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.335 | Acc: 42.642,57.714,28.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.360 | Acc: 42.449,57.379,28.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.369 | Acc: 42.328,57.283,27.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.379 | Acc: 42.248,57.175,27.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.383 | Acc: 42.252,57.169,27.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.382 | Acc: 42.229,57.139,27.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.373 | Acc: 42.298,57.245,28.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.988 | Acc: 28.125,42.188,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.993 | Acc: 29.315,43.043,24.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.096 | Acc: 28.754,42.283,23.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.082 | Acc: 28.420,42.341,24.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 6.181 | Acc: 46.094,59.375,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.305 | Acc: 42.560,58.817,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.265 | Acc: 42.740,58.784,28.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.273 | Acc: 42.777,58.274,28.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.301 | Acc: 42.332,58.468,28.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.295 | Acc: 42.443,58.253,28.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.282 | Acc: 42.388,58.245,28.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.274 | Acc: 42.581,58.261,28.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.284 | Acc: 42.517,58.162,28.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.302 | Acc: 42.498,58.054,28.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.300 | Acc: 42.518,58.019,28.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.301 | Acc: 42.477,57.919,28.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.312 | Acc: 42.531,57.706,28.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.328 | Acc: 42.550,57.660,28.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.335 | Acc: 42.413,57.568,28.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.337 | Acc: 42.450,57.496,28.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.337 | Acc: 42.445,57.452,28.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.327 | Acc: 42.501,57.480,28.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.333 | Acc: 42.443,57.332,28.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.330 | Acc: 42.468,57.269,28.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.360 | Acc: 25.781,42.188,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.093 | Acc: 24.442,40.774,22.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.283 | Acc: 23.514,38.948,22.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.312 | Acc: 23.220,38.730,22.669,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 6.398 | Acc: 44.531,58.594,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.342 | Acc: 42.150,57.515,28.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.303 | Acc: 42.130,57.241,28.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.285 | Acc: 42.367,57.646,28.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.333 | Acc: 42.188,57.176,28.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.349 | Acc: 42.396,57.178,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.299 | Acc: 42.820,57.541,28.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.275 | Acc: 42.869,57.668,28.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.283 | Acc: 42.809,57.633,28.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.278 | Acc: 42.934,57.640,28.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.273 | Acc: 42.848,57.641,29.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.275 | Acc: 42.824,57.572,28.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.285 | Acc: 42.771,57.359,28.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.296 | Acc: 42.631,57.259,28.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.290 | Acc: 42.613,57.251,29.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.295 | Acc: 42.556,57.187,29.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.303 | Acc: 42.445,57.060,29.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.306 | Acc: 42.417,57.089,29.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.301 | Acc: 42.484,57.038,29.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.302 | Acc: 42.475,56.964,29.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.886 | Acc: 21.875,44.531,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.122 | Acc: 21.801,41.406,21.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.267 | Acc: 21.265,40.320,20.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.296 | Acc: 21.030,40.126,20.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 6.889 | Acc: 40.625,50.781,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.358 | Acc: 40.365,55.580,28.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.330 | Acc: 41.540,56.764,27.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.249 | Acc: 42.149,57.851,28.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.290 | Acc: 42.255,57.514,28.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.290 | Acc: 42.512,57.511,28.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.281 | Acc: 42.691,57.716,28.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.289 | Acc: 42.581,57.502,29.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.283 | Acc: 42.498,57.541,29.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.285 | Acc: 42.541,57.441,29.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.273 | Acc: 42.483,57.474,29.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.264 | Acc: 42.562,57.537,29.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.268 | Acc: 42.521,57.511,29.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.271 | Acc: 42.538,57.522,29.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.283 | Acc: 42.365,57.368,29.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.304 | Acc: 42.322,57.182,29.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.310 | Acc: 42.348,57.131,29.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.311 | Acc: 42.478,57.116,29.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.308 | Acc: 42.512,57.144,29.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.319 | Acc: 42.393,57.052,29.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.194 | Acc: 25.781,43.750,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.330 | Acc: 23.140,45.089,26.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.476 | Acc: 22.428,44.112,25.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.536 | Acc: 22.003,43.814,25.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 5.913 | Acc: 43.750,60.156,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.183 | Acc: 42.671,58.817,30.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.075 | Acc: 43.769,59.127,31.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.159 | Acc: 43.199,58.671,30.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.195 | Acc: 42.930,58.150,30.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.212 | Acc: 42.938,58.060,30.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.222 | Acc: 42.762,57.916,30.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.236 | Acc: 42.653,57.713,30.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.248 | Acc: 42.513,57.516,30.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.254 | Acc: 42.434,57.446,29.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.265 | Acc: 42.359,57.280,29.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.264 | Acc: 42.523,57.356,29.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.272 | Acc: 42.492,57.368,29.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.264 | Acc: 42.553,57.471,29.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.256 | Acc: 42.646,57.504,29.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.241 | Acc: 42.782,57.563,29.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.243 | Acc: 42.867,57.557,29.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.249 | Acc: 42.808,57.499,29.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.256 | Acc: 42.811,57.399,29.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.281 | Acc: 42.727,57.251,29.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.381 | Acc: 7.031,24.219,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.166 | Acc: 9.003,21.466,22.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.126 | Acc: 9.661,21.704,21.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.187 | Acc: 9.349,21.299,21.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 6.564 | Acc: 42.969,53.125,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.458 | Acc: 42.783,56.734,27.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.505 | Acc: 41.273,54.973,28.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.514 | Acc: 40.984,55.123,28.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.497 | Acc: 41.435,55.131,28.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.452 | Acc: 42.025,55.716,28.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.430 | Acc: 42.039,55.908,28.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.410 | Acc: 42.038,55.940,29.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.401 | Acc: 41.950,55.915,29.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.368 | Acc: 42.200,56.181,29.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.368 | Acc: 42.164,56.095,29.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.365 | Acc: 42.071,56.126,29.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.364 | Acc: 42.152,56.130,29.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.372 | Acc: 42.062,56.121,29.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.373 | Acc: 42.099,56.200,29.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.372 | Acc: 42.099,56.253,29.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.372 | Acc: 42.029,56.189,29.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.358 | Acc: 42.119,56.303,29.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.341 | Acc: 42.205,56.440,29.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.333 | Acc: 42.255,56.396,29.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.023 | Acc: 21.875,39.062,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.753 | Acc: 19.940,36.570,14.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.969 | Acc: 18.807,34.642,13.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.964 | Acc: 18.494,34.209,14.267,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 6.074 | Acc: 38.281,54.688,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.371 | Acc: 40.997,56.585,26.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.292 | Acc: 41.692,56.669,28.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.279 | Acc: 41.752,56.737,28.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.240 | Acc: 41.975,57.369,29.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.252 | Acc: 42.017,57.310,29.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.269 | Acc: 42.323,57.251,29.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.271 | Acc: 42.243,57.142,29.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.279 | Acc: 42.430,57.036,30.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.293 | Acc: 42.330,56.859,29.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.283 | Acc: 42.421,56.876,29.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.285 | Acc: 42.368,56.819,29.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.293 | Acc: 42.376,56.733,29.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.290 | Acc: 42.352,56.738,29.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.299 | Acc: 42.349,56.684,29.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.309 | Acc: 42.325,56.665,29.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.310 | Acc: 42.278,56.659,29.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.300 | Acc: 42.352,56.733,29.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.295 | Acc: 42.354,56.702,29.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.288 | Acc: 42.380,56.781,30.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.729 | Acc: 23.438,40.625,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.889 | Acc: 21.317,42.001,26.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.019 | Acc: 20.998,40.606,25.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.017 | Acc: 20.889,40.126,25.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 6.080 | Acc: 42.969,59.375,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.217 | Acc: 41.853,56.994,29.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.160 | Acc: 42.988,57.927,30.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.160 | Acc: 43.122,58.043,30.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.191 | Acc: 42.872,57.899,30.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.215 | Acc: 42.659,57.743,30.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.215 | Acc: 42.788,57.754,30.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.195 | Acc: 42.825,57.873,30.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.211 | Acc: 42.653,57.672,30.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.238 | Acc: 42.390,57.515,30.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.251 | Acc: 42.222,57.264,30.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.243 | Acc: 42.343,57.293,30.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.238 | Acc: 42.431,57.414,30.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.257 | Acc: 42.277,57.295,30.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.264 | Acc: 42.213,57.190,30.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.280 | Acc: 42.086,57.023,30.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.296 | Acc: 41.881,56.863,30.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.300 | Acc: 41.883,56.733,30.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.306 | Acc: 41.926,56.676,30.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.306 | Acc: 41.960,56.711,30.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.743 | Acc: 21.875,36.719,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.611 | Acc: 21.168,35.268,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.767 | Acc: 20.979,33.880,17.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.782 | Acc: 20.671,34.080,18.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 6.087 | Acc: 42.969,57.812,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.217 | Acc: 43.080,58.371,30.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.274 | Acc: 42.454,57.069,30.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.240 | Acc: 42.559,57.070,30.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.224 | Acc: 42.843,57.147,30.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.204 | Acc: 42.860,57.526,31.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.199 | Acc: 42.801,57.554,31.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.214 | Acc: 42.620,57.358,31.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.217 | Acc: 42.697,57.483,31.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.219 | Acc: 42.766,57.493,31.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.210 | Acc: 42.872,57.540,31.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.227 | Acc: 42.732,57.395,31.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.248 | Acc: 42.654,57.187,30.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.263 | Acc: 42.604,57.067,30.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.267 | Acc: 42.546,56.987,30.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.263 | Acc: 42.525,56.990,30.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.252 | Acc: 42.545,57.107,30.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.251 | Acc: 42.467,57.077,30.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.255 | Acc: 42.454,57.036,30.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.252 | Acc: 42.438,57.083,30.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.312 | Acc: 28.906,48.438,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.988 | Acc: 25.521,47.173,30.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.102 | Acc: 25.400,46.456,30.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.120 | Acc: 24.923,45.966,29.547,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 6.060 | Acc: 39.062,57.812,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.074 | Acc: 42.485,59.933,32.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.186 | Acc: 43.026,58.518,31.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.329 | Acc: 42.047,57.082,30.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.338 | Acc: 42.207,56.887,30.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.330 | Acc: 42.249,56.830,30.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.313 | Acc: 42.168,56.896,30.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.312 | Acc: 41.960,56.904,30.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.294 | Acc: 41.901,56.954,30.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.296 | Acc: 41.989,56.932,30.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.287 | Acc: 42.075,56.930,30.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.278 | Acc: 42.096,57.070,30.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.283 | Acc: 42.061,57.064,30.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.275 | Acc: 42.104,57.163,30.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.271 | Acc: 42.060,57.134,30.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.267 | Acc: 42.097,57.122,31.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.278 | Acc: 41.961,56.956,30.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.283 | Acc: 41.945,56.940,30.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.293 | Acc: 42.017,56.821,30.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.290 | Acc: 42.083,56.861,30.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.272 | Acc: 28.906,44.531,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.944 | Acc: 21.652,42.448,22.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.066 | Acc: 21.608,41.292,23.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.078 | Acc: 21.555,41.253,22.682,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 5.780 | Acc: 52.344,64.062,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.103 | Acc: 43.750,58.891,32.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.108 | Acc: 42.835,58.384,32.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.083 | Acc: 43.609,58.632,32.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.122 | Acc: 43.316,58.189,32.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.115 | Acc: 43.015,58.222,32.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.176 | Acc: 42.568,57.877,31.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.190 | Acc: 42.620,57.707,31.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.181 | Acc: 42.716,57.657,31.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.178 | Acc: 42.585,57.558,31.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.189 | Acc: 42.428,57.404,31.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.186 | Acc: 42.467,57.455,31.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.193 | Acc: 42.463,57.378,31.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.209 | Acc: 42.451,57.274,31.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.214 | Acc: 42.368,57.181,31.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.213 | Acc: 42.309,57.213,31.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.218 | Acc: 42.282,57.097,31.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.219 | Acc: 42.259,57.079,31.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.227 | Acc: 42.268,57.111,31.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.230 | Acc: 42.278,57.070,30.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.405 | Acc: 30.469,43.750,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.718 | Acc: 26.376,40.625,27.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.750 | Acc: 26.677,40.149,27.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.803 | Acc: 26.140,39.703,26.985,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 6.355 | Acc: 41.406,55.469,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.145 | Acc: 43.080,58.557,32.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.139 | Acc: 42.931,58.498,32.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.190 | Acc: 43.084,57.774,31.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.156 | Acc: 43.364,58.054,31.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.152 | Acc: 43.286,58.060,31.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.171 | Acc: 43.072,57.890,31.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.212 | Acc: 42.886,57.635,31.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.213 | Acc: 42.663,57.546,31.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.191 | Acc: 42.736,57.541,31.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.187 | Acc: 42.623,57.529,31.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.190 | Acc: 42.605,57.547,31.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.195 | Acc: 42.525,57.527,31.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.207 | Acc: 42.451,57.381,31.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.216 | Acc: 42.374,57.251,31.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.215 | Acc: 42.413,57.314,31.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.230 | Acc: 42.334,57.194,31.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.233 | Acc: 42.304,57.166,31.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.237 | Acc: 42.250,57.163,31.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.250 | Acc: 42.120,57.037,31.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.927 | Acc: 29.688,46.875,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.879 | Acc: 25.967,40.253,25.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.890 | Acc: 26.334,40.225,24.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.912 | Acc: 25.999,40.164,24.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 5.949 | Acc: 45.312,64.844,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.040 | Acc: 43.750,59.673,34.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.934 | Acc: 43.407,59.680,35.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.847 | Acc: 44.480,60.822,35.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.825 | Acc: 44.300,61.188,36.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.775 | Acc: 44.500,61.595,36.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.745 | Acc: 44.944,61.990,36.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.701 | Acc: 45.407,62.400,36.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.687 | Acc: 45.531,62.451,36.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.675 | Acc: 45.606,62.543,36.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.675 | Acc: 45.581,62.535,36.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.655 | Acc: 45.829,62.811,37.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.647 | Acc: 45.902,62.821,37.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.640 | Acc: 45.959,62.886,37.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.624 | Acc: 46.010,63.173,37.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.615 | Acc: 46.060,63.325,37.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.601 | Acc: 46.176,63.481,37.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.597 | Acc: 46.158,63.446,37.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.579 | Acc: 46.289,63.586,37.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.569 | Acc: 46.385,63.716,37.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.980 | Acc: 43.750,62.500,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.920 | Acc: 43.490,61.198,36.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.021 | Acc: 42.969,59.527,35.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.038 | Acc: 43.212,59.567,35.169,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 5.501 | Acc: 46.094,64.062,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.454 | Acc: 47.135,64.100,38.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.420 | Acc: 46.589,64.768,38.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.381 | Acc: 47.272,65.292,39.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.384 | Acc: 47.338,65.509,38.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.378 | Acc: 47.486,65.749,39.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.399 | Acc: 46.991,65.367,39.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.385 | Acc: 47.047,65.304,39.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.392 | Acc: 47.069,65.334,39.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.383 | Acc: 47.181,65.414,39.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.392 | Acc: 47.073,65.341,39.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.390 | Acc: 47.059,65.307,39.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.389 | Acc: 47.014,65.298,39.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.388 | Acc: 47.165,65.356,39.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.380 | Acc: 47.228,65.397,39.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.373 | Acc: 47.275,65.472,39.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.370 | Acc: 47.371,65.430,39.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.365 | Acc: 47.423,65.439,39.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.358 | Acc: 47.559,65.506,39.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.354 | Acc: 47.574,65.506,39.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.881 | Acc: 43.750,60.156,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.840 | Acc: 44.568,62.314,37.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.910 | Acc: 43.864,60.480,37.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.942 | Acc: 43.763,60.131,37.295,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 5.460 | Acc: 45.312,64.844,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.321 | Acc: 49.033,65.774,40.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.270 | Acc: 49.657,65.796,41.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.264 | Acc: 48.668,66.265,41.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.253 | Acc: 48.650,66.348,41.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.270 | Acc: 48.708,66.375,41.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.273 | Acc: 48.509,66.413,41.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.275 | Acc: 48.576,66.528,41.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.287 | Acc: 48.438,66.363,41.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.272 | Acc: 48.507,66.467,41.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.276 | Acc: 48.441,66.379,41.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.277 | Acc: 48.370,66.406,41.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.277 | Acc: 48.386,66.322,41.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.273 | Acc: 48.297,66.388,41.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.273 | Acc: 48.198,66.398,41.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.280 | Acc: 48.004,66.263,41.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.280 | Acc: 48.009,66.231,41.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.278 | Acc: 47.984,66.191,41.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.272 | Acc: 48.018,66.240,41.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.277 | Acc: 47.980,66.148,40.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.841 | Acc: 46.875,63.281,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.767 | Acc: 44.606,62.463,39.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.847 | Acc: 44.036,60.995,38.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.858 | Acc: 43.955,60.771,38.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 5.135 | Acc: 49.219,71.875,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.194 | Acc: 48.661,67.634,41.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.212 | Acc: 48.761,67.797,41.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.183 | Acc: 48.809,67.674,41.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.190 | Acc: 48.611,67.371,41.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.174 | Acc: 48.731,67.489,42.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.185 | Acc: 48.812,67.233,42.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.190 | Acc: 48.676,67.066,42.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.205 | Acc: 48.588,66.848,42.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.210 | Acc: 48.532,66.859,41.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.201 | Acc: 48.519,66.869,41.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.213 | Acc: 48.406,66.760,41.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.218 | Acc: 48.363,66.727,41.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.219 | Acc: 48.396,66.709,41.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.232 | Acc: 48.290,66.595,41.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.245 | Acc: 48.087,66.391,41.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.248 | Acc: 48.007,66.387,41.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.247 | Acc: 48.069,66.358,41.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.250 | Acc: 48.033,66.335,41.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.251 | Acc: 48.019,66.275,41.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.803 | Acc: 48.438,64.062,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.787 | Acc: 44.085,62.091,39.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.859 | Acc: 44.131,60.880,38.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.883 | Acc: 44.173,60.643,37.666,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 4.416 | Acc: 51.562,75.781,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.107 | Acc: 49.665,67.746,43.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.092 | Acc: 50.038,67.988,42.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.145 | Acc: 48.988,67.559,42.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.162 | Acc: 48.717,67.303,42.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.168 | Acc: 48.786,67.551,42.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.154 | Acc: 48.922,67.723,42.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.158 | Acc: 48.953,67.803,42.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.159 | Acc: 48.884,67.648,42.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.156 | Acc: 48.977,67.667,42.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.163 | Acc: 48.908,67.487,42.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.171 | Acc: 48.802,67.304,42.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.178 | Acc: 48.593,67.197,42.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.185 | Acc: 48.500,67.152,42.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.196 | Acc: 48.315,66.846,42.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.193 | Acc: 48.378,66.814,42.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.195 | Acc: 48.347,66.813,42.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.188 | Acc: 48.371,66.876,42.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.186 | Acc: 48.429,66.865,42.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.183 | Acc: 48.419,66.847,42.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.670 | Acc: 50.000,63.281,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.727 | Acc: 45.052,62.128,40.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.797 | Acc: 44.264,61.319,39.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.822 | Acc: 44.237,60.886,39.191,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 5.264 | Acc: 50.781,62.500,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.107 | Acc: 50.632,68.676,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.152 | Acc: 49.028,67.550,41.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.169 | Acc: 48.783,67.111,41.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.156 | Acc: 48.447,67.458,41.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.158 | Acc: 48.352,67.435,42.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.150 | Acc: 48.528,67.304,42.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.150 | Acc: 48.543,67.232,42.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.140 | Acc: 48.481,67.333,42.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.137 | Acc: 48.567,67.321,42.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.136 | Acc: 48.511,67.222,42.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.145 | Acc: 48.445,67.103,42.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.138 | Acc: 48.587,67.132,42.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.152 | Acc: 48.467,66.993,42.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.151 | Acc: 48.379,66.934,42.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.160 | Acc: 48.360,66.871,42.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.159 | Acc: 48.438,66.876,42.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.161 | Acc: 48.454,66.839,42.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.160 | Acc: 48.440,66.848,42.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.163 | Acc: 48.440,66.810,42.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.763 | Acc: 45.312,68.750,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.723 | Acc: 45.201,63.207,40.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.819 | Acc: 44.741,61.719,39.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.842 | Acc: 44.621,61.027,38.691,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 5.433 | Acc: 42.969,66.406,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.159 | Acc: 48.103,67.076,41.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.162 | Acc: 48.742,66.978,41.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.141 | Acc: 48.694,67.085,41.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.115 | Acc: 48.900,67.323,42.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.132 | Acc: 48.762,67.157,42.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.140 | Acc: 48.799,67.175,42.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.149 | Acc: 48.886,66.933,41.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.138 | Acc: 49.015,67.018,42.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.141 | Acc: 48.865,66.920,42.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.145 | Acc: 48.776,66.915,42.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.146 | Acc: 48.660,67.011,42.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.155 | Acc: 48.528,66.980,42.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.156 | Acc: 48.446,66.990,42.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.159 | Acc: 48.415,66.987,42.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.163 | Acc: 48.365,66.962,42.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.159 | Acc: 48.391,66.993,42.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.159 | Acc: 48.419,67.029,42.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.165 | Acc: 48.353,66.952,42.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.172 | Acc: 48.300,66.859,42.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.825 | Acc: 42.188,64.062,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.838 | Acc: 43.787,61.049,39.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.925 | Acc: 43.426,60.061,39.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.945 | Acc: 43.289,59.887,38.832,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 4.955 | Acc: 48.438,70.312,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.169 | Acc: 49.219,67.039,42.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.131 | Acc: 49.066,67.721,43.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.096 | Acc: 49.103,67.738,43.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.102 | Acc: 49.209,67.718,43.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.136 | Acc: 48.809,67.350,43.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.135 | Acc: 48.928,67.543,43.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.141 | Acc: 49.008,67.370,43.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.138 | Acc: 48.947,67.139,43.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.150 | Acc: 48.886,67.058,43.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.161 | Acc: 48.861,67.044,42.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.147 | Acc: 49.049,67.127,43.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.145 | Acc: 48.979,67.081,43.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.154 | Acc: 48.892,66.861,42.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.155 | Acc: 48.857,66.837,42.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.148 | Acc: 48.915,66.858,42.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.147 | Acc: 48.912,66.927,43.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.148 | Acc: 48.903,66.942,43.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.155 | Acc: 48.788,66.908,42.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.153 | Acc: 48.846,66.915,43.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.659 | Acc: 46.875,63.281,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.812 | Acc: 44.568,61.719,39.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.896 | Acc: 44.150,60.880,39.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.905 | Acc: 44.096,60.592,39.152,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 5.727 | Acc: 45.312,62.500,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.207 | Acc: 48.438,66.927,41.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.175 | Acc: 48.285,67.054,41.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.151 | Acc: 48.284,67.367,41.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.149 | Acc: 48.341,67.525,42.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.128 | Acc: 48.499,67.319,42.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.120 | Acc: 48.754,67.633,42.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.104 | Acc: 48.853,67.564,42.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.112 | Acc: 48.913,67.576,42.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.107 | Acc: 48.943,67.593,42.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.100 | Acc: 49.028,67.607,43.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.109 | Acc: 48.862,67.562,43.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.111 | Acc: 48.885,67.525,43.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.119 | Acc: 48.731,67.481,43.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.115 | Acc: 48.766,67.527,43.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.114 | Acc: 48.713,67.569,43.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.118 | Acc: 48.686,67.470,43.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.113 | Acc: 48.678,67.520,43.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.108 | Acc: 48.686,67.532,43.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.100 | Acc: 48.821,67.507,43.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.624 | Acc: 46.875,64.844,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.740 | Acc: 44.829,62.500,39.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.832 | Acc: 44.188,61.090,39.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.872 | Acc: 43.891,60.489,38.563,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 5.216 | Acc: 46.875,67.188,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.088 | Acc: 49.442,68.341,43.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.099 | Acc: 49.200,67.797,44.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.099 | Acc: 49.180,67.456,44.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.094 | Acc: 49.296,67.805,44.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.096 | Acc: 49.157,67.559,44.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.088 | Acc: 49.115,67.446,44.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.098 | Acc: 49.064,67.465,44.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.081 | Acc: 49.165,67.615,44.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.091 | Acc: 49.016,67.593,44.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.088 | Acc: 49.075,67.642,44.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.093 | Acc: 49.074,67.629,44.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.101 | Acc: 48.901,67.570,44.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.099 | Acc: 48.973,67.583,44.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.100 | Acc: 49.035,67.635,44.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.101 | Acc: 49.021,67.582,44.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.100 | Acc: 48.973,67.655,44.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.104 | Acc: 48.958,67.646,43.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.092 | Acc: 49.030,67.679,44.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.095 | Acc: 48.930,67.639,44.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.677 | Acc: 49.219,63.281,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.712 | Acc: 44.606,62.202,41.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.791 | Acc: 44.512,61.300,40.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.824 | Acc: 44.057,60.835,40.330,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 5.418 | Acc: 39.844,61.719,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.988 | Acc: 49.591,68.973,45.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.972 | Acc: 50.095,68.617,45.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.998 | Acc: 50.102,68.122,44.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.002 | Acc: 49.797,67.969,44.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.020 | Acc: 49.412,67.976,44.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.038 | Acc: 49.264,67.827,44.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.024 | Acc: 49.368,67.836,44.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.034 | Acc: 49.267,67.721,44.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.035 | Acc: 49.145,67.718,44.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.028 | Acc: 49.215,67.782,44.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.026 | Acc: 49.145,67.767,44.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.037 | Acc: 49.154,67.567,44.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.048 | Acc: 49.051,67.487,44.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.058 | Acc: 48.957,67.491,44.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.054 | Acc: 49.053,67.618,44.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.059 | Acc: 49.031,67.514,44.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.063 | Acc: 48.992,67.458,44.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.066 | Acc: 48.974,67.423,44.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.066 | Acc: 48.936,67.395,44.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.759 | Acc: 46.875,64.062,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.783 | Acc: 45.871,62.016,40.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.885 | Acc: 44.646,60.556,40.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.897 | Acc: 44.185,60.540,39.178,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 4.825 | Acc: 55.469,69.531,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.969 | Acc: 49.963,67.485,44.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.009 | Acc: 48.723,67.740,45.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.011 | Acc: 48.937,67.956,45.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.032 | Acc: 48.534,67.776,44.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.034 | Acc: 48.971,67.567,44.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.030 | Acc: 49.096,67.659,45.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.037 | Acc: 49.030,67.736,44.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.040 | Acc: 49.136,67.760,44.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.043 | Acc: 49.089,67.779,44.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.043 | Acc: 49.013,67.786,44.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.040 | Acc: 48.918,67.732,44.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.037 | Acc: 48.985,67.752,44.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.049 | Acc: 48.851,67.598,44.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.055 | Acc: 48.827,67.657,44.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.061 | Acc: 48.840,67.603,44.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.053 | Acc: 48.893,67.701,44.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.063 | Acc: 48.774,67.623,44.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.075 | Acc: 48.691,67.555,44.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.079 | Acc: 48.665,67.436,44.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.570 | Acc: 49.219,67.969,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.718 | Acc: 45.536,61.830,41.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.818 | Acc: 44.741,61.185,40.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.832 | Acc: 44.647,60.861,39.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 4.780 | Acc: 49.219,70.312,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.037 | Acc: 48.103,68.304,44.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.020 | Acc: 48.609,68.788,44.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.043 | Acc: 48.450,67.994,43.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.047 | Acc: 48.515,67.843,43.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.049 | Acc: 48.863,67.946,44.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.044 | Acc: 48.851,67.917,44.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.032 | Acc: 48.859,68.002,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.019 | Acc: 48.913,68.299,44.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.024 | Acc: 48.856,68.232,44.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.010 | Acc: 48.834,68.334,44.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.015 | Acc: 48.894,68.290,44.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.021 | Acc: 48.804,68.261,44.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.024 | Acc: 48.791,68.100,44.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.028 | Acc: 48.741,68.069,44.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.036 | Acc: 48.741,68.008,44.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.039 | Acc: 48.615,67.940,44.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.030 | Acc: 48.657,68.017,44.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.036 | Acc: 48.673,67.949,44.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.039 | Acc: 48.714,67.926,44.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.576 | Acc: 47.656,64.844,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.660 | Acc: 46.131,62.798,41.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.729 | Acc: 45.332,62.024,40.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.751 | Acc: 44.903,61.719,40.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 4.622 | Acc: 59.375,70.312,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.036 | Acc: 48.772,66.890,44.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.074 | Acc: 47.999,67.245,44.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.029 | Acc: 48.553,68.289,44.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.015 | Acc: 48.814,68.538,44.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.031 | Acc: 48.708,68.239,44.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.016 | Acc: 48.605,68.130,45.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.021 | Acc: 48.637,67.996,44.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.045 | Acc: 48.360,67.702,44.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.044 | Acc: 48.394,67.723,44.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.055 | Acc: 48.317,67.654,44.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.050 | Acc: 48.423,67.668,44.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.054 | Acc: 48.428,67.602,44.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.048 | Acc: 48.473,67.660,44.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.043 | Acc: 48.496,67.666,44.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.040 | Acc: 48.554,67.691,44.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.034 | Acc: 48.744,67.740,44.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.031 | Acc: 48.811,67.740,44.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.040 | Acc: 48.808,67.716,44.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.045 | Acc: 48.860,67.731,44.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.747 | Acc: 47.656,66.406,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.765 | Acc: 44.903,62.946,41.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.825 | Acc: 44.093,61.643,40.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.846 | Acc: 43.929,61.168,40.228,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 5.447 | Acc: 46.875,59.375,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.065 | Acc: 49.888,66.443,43.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.021 | Acc: 49.352,67.264,43.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.030 | Acc: 49.308,67.738,44.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.002 | Acc: 49.489,67.949,44.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.994 | Acc: 49.737,67.721,45.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.002 | Acc: 49.671,67.736,45.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.025 | Acc: 49.379,67.631,44.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.033 | Acc: 49.466,67.639,44.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.030 | Acc: 49.473,67.805,44.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.024 | Acc: 49.518,67.821,44.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.040 | Acc: 49.297,67.682,44.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.041 | Acc: 49.284,67.700,44.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.035 | Acc: 49.267,67.807,44.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.036 | Acc: 49.272,67.724,44.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.040 | Acc: 49.172,67.629,44.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.037 | Acc: 49.075,67.652,44.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.024 | Acc: 49.141,67.685,44.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.020 | Acc: 49.221,67.746,44.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.025 | Acc: 49.129,67.719,44.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.691 | Acc: 47.656,64.062,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.715 | Acc: 44.308,62.984,42.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.811 | Acc: 44.436,62.024,41.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.824 | Acc: 44.224,61.591,40.663,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 5.243 | Acc: 51.562,65.625,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.877 | Acc: 50.000,69.643,46.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.934 | Acc: 49.676,68.712,46.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.957 | Acc: 49.898,68.033,46.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.995 | Acc: 49.344,68.007,45.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.002 | Acc: 49.373,67.915,45.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.016 | Acc: 49.303,67.794,45.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.030 | Acc: 49.235,67.575,44.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.023 | Acc: 49.117,67.585,45.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.023 | Acc: 48.912,67.623,45.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.027 | Acc: 48.900,67.704,45.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.023 | Acc: 48.901,67.743,45.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.028 | Acc: 48.865,67.823,45.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.029 | Acc: 48.845,67.810,45.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.030 | Acc: 48.860,67.852,45.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.023 | Acc: 48.975,67.971,45.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.026 | Acc: 49.053,67.930,45.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.027 | Acc: 48.960,67.895,45.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.035 | Acc: 48.803,67.817,45.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.033 | Acc: 48.737,67.838,45.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.664 | Acc: 46.875,64.062,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.708 | Acc: 45.350,62.649,42.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.815 | Acc: 44.493,61.166,41.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.820 | Acc: 44.326,61.283,40.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 4.704 | Acc: 51.562,68.750,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.916 | Acc: 48.958,69.382,46.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.974 | Acc: 48.476,68.579,45.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.964 | Acc: 48.745,68.584,46.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.990 | Acc: 48.775,68.316,46.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.979 | Acc: 48.933,68.108,45.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.986 | Acc: 49.006,68.098,45.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.984 | Acc: 49.224,68.118,45.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.983 | Acc: 49.355,68.066,46.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.978 | Acc: 49.409,68.189,46.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.998 | Acc: 49.160,67.965,45.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.009 | Acc: 49.046,67.792,45.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.020 | Acc: 49.008,67.742,45.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.039 | Acc: 48.967,67.705,45.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.063 | Acc: 48.827,67.496,45.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.062 | Acc: 48.897,67.546,45.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.058 | Acc: 48.807,67.565,45.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.056 | Acc: 48.781,67.586,45.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.052 | Acc: 48.803,67.661,45.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.054 | Acc: 48.825,67.651,45.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.797 | Acc: 48.438,67.969,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.848 | Acc: 43.973,61.533,40.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.895 | Acc: 43.388,60.347,39.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.906 | Acc: 43.417,60.515,39.857,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 5.488 | Acc: 44.531,62.500,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.006 | Acc: 48.586,68.192,44.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.995 | Acc: 49.028,68.197,45.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.034 | Acc: 49.027,67.892,44.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.081 | Acc: 48.611,67.467,44.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.039 | Acc: 48.948,67.768,44.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.008 | Acc: 49.212,68.091,45.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.020 | Acc: 48.975,67.924,45.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.026 | Acc: 48.986,67.780,45.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.035 | Acc: 48.899,67.675,44.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.041 | Acc: 48.787,67.658,44.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.043 | Acc: 48.706,67.668,45.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.037 | Acc: 48.732,67.609,45.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.033 | Acc: 48.767,67.616,45.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.033 | Acc: 48.818,67.707,45.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.034 | Acc: 48.931,67.670,45.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.038 | Acc: 48.897,67.662,45.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.043 | Acc: 48.852,67.625,44.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.046 | Acc: 48.790,67.536,45.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.039 | Acc: 48.813,67.493,45.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.875 | Acc: 44.531,64.062,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.791 | Acc: 43.973,62.240,41.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.890 | Acc: 43.693,60.556,40.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.900 | Acc: 43.327,60.412,40.177,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 5.053 | Acc: 40.625,70.312,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.943 | Acc: 48.475,68.415,45.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.993 | Acc: 47.637,68.331,45.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.997 | Acc: 47.989,68.058,45.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.002 | Acc: 48.302,68.075,45.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.981 | Acc: 48.755,68.410,45.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.993 | Acc: 48.580,68.298,45.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.005 | Acc: 48.709,68.163,45.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.017 | Acc: 48.622,68.066,45.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.009 | Acc: 48.778,68.116,45.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.021 | Acc: 48.752,67.957,45.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.018 | Acc: 48.848,68.057,45.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.012 | Acc: 48.778,68.060,45.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.000 | Acc: 48.875,68.145,45.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.001 | Acc: 48.907,68.066,45.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.012 | Acc: 48.772,67.995,45.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.011 | Acc: 48.768,67.996,45.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.007 | Acc: 48.866,68.051,45.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.014 | Acc: 48.797,67.986,45.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.031 | Acc: 48.694,67.860,45.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.111 | Acc: 44.531,63.281,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.192 | Acc: 42.225,58.594,38.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.273 | Acc: 41.768,57.832,37.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.271 | Acc: 41.381,57.864,36.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 5.296 | Acc: 40.625,64.844,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.073 | Acc: 49.702,67.225,45.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.032 | Acc: 49.829,67.207,45.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.972 | Acc: 49.859,67.585,46.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.015 | Acc: 49.826,67.612,45.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.024 | Acc: 49.629,67.636,45.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.031 | Acc: 49.496,67.601,45.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.037 | Acc: 49.490,67.664,45.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.039 | Acc: 49.335,67.755,45.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.025 | Acc: 49.504,67.917,45.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.032 | Acc: 49.366,67.774,45.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.037 | Acc: 49.300,67.647,45.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.037 | Acc: 49.290,67.683,45.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.039 | Acc: 49.192,67.696,45.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.033 | Acc: 49.166,67.694,45.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.028 | Acc: 49.066,67.717,45.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.031 | Acc: 49.007,67.643,45.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.026 | Acc: 48.974,67.634,45.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.031 | Acc: 48.914,67.584,45.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.037 | Acc: 48.821,67.507,45.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.206 | Acc: 45.312,57.812,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.057 | Acc: 43.080,59.970,40.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.117 | Acc: 42.950,59.051,39.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.131 | Acc: 42.367,59.080,38.717,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 4.840 | Acc: 53.906,74.219,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.043 | Acc: 49.293,68.304,45.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.021 | Acc: 49.409,67.245,45.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.025 | Acc: 49.052,67.623,45.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.021 | Acc: 48.949,67.631,45.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.018 | Acc: 48.809,67.690,45.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.019 | Acc: 48.825,67.820,45.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.014 | Acc: 48.864,68.041,45.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.002 | Acc: 49.102,68.017,45.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.001 | Acc: 49.012,67.990,45.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.000 | Acc: 48.927,67.961,45.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.994 | Acc: 48.964,68.100,45.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.999 | Acc: 48.943,68.056,45.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.002 | Acc: 48.916,68.035,45.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.009 | Acc: 48.905,67.972,45.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.005 | Acc: 48.977,68.013,46.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.005 | Acc: 48.985,68.017,45.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.011 | Acc: 48.875,67.930,45.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.014 | Acc: 48.840,67.858,45.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.019 | Acc: 48.819,67.745,45.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.315 | Acc: 50.781,66.406,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.712 | Acc: 45.312,62.016,43.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.809 | Acc: 44.512,60.938,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.847 | Acc: 44.249,60.284,41.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 4.589 | Acc: 53.906,78.125,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.868 | Acc: 50.149,68.601,46.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.991 | Acc: 49.104,67.435,45.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.991 | Acc: 49.334,67.713,45.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.037 | Acc: 49.026,67.380,45.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.062 | Acc: 48.824,67.141,45.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.027 | Acc: 49.077,67.459,45.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.007 | Acc: 49.246,67.675,46.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.001 | Acc: 49.136,67.721,46.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.008 | Acc: 49.219,67.753,46.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.012 | Acc: 49.071,67.759,46.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.004 | Acc: 49.063,67.909,46.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.004 | Acc: 49.044,67.865,46.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.995 | Acc: 49.147,67.891,46.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.991 | Acc: 49.169,67.919,46.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.982 | Acc: 49.133,67.930,46.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.982 | Acc: 49.170,67.954,46.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.979 | Acc: 49.191,67.969,46.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.980 | Acc: 49.193,67.925,46.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.981 | Acc: 49.165,67.920,46.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.758 | Acc: 42.969,63.281,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.746 | Acc: 43.824,61.942,41.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.816 | Acc: 43.483,61.433,41.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.858 | Acc: 43.225,61.168,41.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 4.585 | Acc: 51.562,70.312,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.889 | Acc: 49.702,69.420,44.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.917 | Acc: 49.009,69.284,45.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.959 | Acc: 48.886,69.083,45.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.013 | Acc: 48.968,68.509,45.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.006 | Acc: 48.847,68.495,45.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.024 | Acc: 48.696,68.279,45.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.031 | Acc: 48.526,68.030,45.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.023 | Acc: 48.476,68.051,45.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.015 | Acc: 48.528,68.098,45.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.005 | Acc: 48.678,68.179,45.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.003 | Acc: 48.681,68.160,45.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.999 | Acc: 48.745,68.144,45.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.995 | Acc: 48.695,68.106,45.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.993 | Acc: 48.749,68.147,45.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.988 | Acc: 48.915,68.205,46.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.986 | Acc: 48.958,68.254,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.982 | Acc: 48.987,68.235,46.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.981 | Acc: 48.989,68.235,46.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.981 | Acc: 49.055,68.196,46.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.952 | Acc: 43.750,64.844,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.811 | Acc: 45.499,62.426,40.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.894 | Acc: 44.531,61.395,39.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.915 | Acc: 44.339,60.938,39.165,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 5.932 | Acc: 36.719,61.719,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.982 | Acc: 48.847,67.708,46.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.970 | Acc: 48.914,67.988,46.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.952 | Acc: 49.296,68.289,46.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.926 | Acc: 49.691,68.605,47.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.933 | Acc: 49.242,68.487,47.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.946 | Acc: 48.747,68.434,47.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.953 | Acc: 48.692,68.390,47.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.953 | Acc: 48.748,68.386,47.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.964 | Acc: 48.701,68.176,46.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.971 | Acc: 48.741,68.035,46.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.974 | Acc: 48.766,67.990,46.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.979 | Acc: 48.869,67.972,46.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.979 | Acc: 48.913,67.948,46.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.981 | Acc: 48.938,67.874,46.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.982 | Acc: 48.923,67.974,46.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.981 | Acc: 48.997,68.025,46.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.979 | Acc: 48.971,67.987,46.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.972 | Acc: 49.022,68.088,46.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.979 | Acc: 48.946,68.053,46.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.661 | Acc: 44.531,62.500,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.723 | Acc: 44.643,62.760,42.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.824 | Acc: 43.636,61.242,41.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.831 | Acc: 43.596,61.245,41.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 4.992 | Acc: 50.781,66.406,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.935 | Acc: 50.074,67.969,47.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.951 | Acc: 49.676,67.912,46.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.953 | Acc: 49.590,67.853,46.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.962 | Acc: 49.508,67.660,46.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.979 | Acc: 49.451,67.389,46.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.967 | Acc: 49.561,67.465,46.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.967 | Acc: 49.379,67.465,46.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.973 | Acc: 49.165,67.513,46.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.965 | Acc: 49.227,67.598,46.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.965 | Acc: 49.087,67.603,46.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.965 | Acc: 49.053,67.658,46.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.979 | Acc: 49.002,67.628,46.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.984 | Acc: 48.952,67.628,46.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.991 | Acc: 48.982,67.563,46.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.994 | Acc: 49.037,67.626,46.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.993 | Acc: 49.082,67.592,46.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.988 | Acc: 49.129,67.675,46.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.993 | Acc: 49.121,67.646,46.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.002 | Acc: 49.042,67.622,46.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.972 | Acc: 42.969,64.062,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.876 | Acc: 43.378,61.310,42.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.976 | Acc: 42.683,60.328,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.992 | Acc: 42.405,60.310,41.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 5.124 | Acc: 50.781,63.281,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.026 | Acc: 48.177,67.448,46.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.944 | Acc: 48.819,67.816,46.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.903 | Acc: 49.001,68.353,47.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.898 | Acc: 49.479,68.875,47.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.897 | Acc: 49.257,68.758,47.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.911 | Acc: 49.290,68.550,47.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.914 | Acc: 49.363,68.794,47.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.921 | Acc: 49.170,68.575,47.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.921 | Acc: 49.016,68.577,47.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.933 | Acc: 48.830,68.455,47.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.946 | Acc: 48.780,68.294,47.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.948 | Acc: 48.797,68.199,47.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.958 | Acc: 48.797,68.139,46.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.956 | Acc: 48.810,68.166,46.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.960 | Acc: 48.767,68.078,46.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.971 | Acc: 48.776,67.947,46.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.973 | Acc: 48.763,67.916,46.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.975 | Acc: 48.786,67.932,46.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.972 | Acc: 48.833,67.987,46.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.631 | Acc: 48.438,64.844,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.840 | Acc: 44.196,61.682,43.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.924 | Acc: 43.845,60.747,42.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.932 | Acc: 43.315,60.540,41.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 4.725 | Acc: 56.250,66.406,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.850 | Acc: 49.554,68.415,48.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.941 | Acc: 49.314,68.255,46.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.929 | Acc: 48.963,68.468,47.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.928 | Acc: 49.035,68.451,46.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.910 | Acc: 49.242,68.541,47.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.928 | Acc: 49.322,68.376,46.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.932 | Acc: 49.302,68.329,47.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.939 | Acc: 49.350,68.386,47.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.940 | Acc: 49.275,68.418,47.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.940 | Acc: 49.160,68.311,47.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.926 | Acc: 49.130,68.294,47.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.933 | Acc: 48.998,68.196,47.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.936 | Acc: 49.021,68.112,47.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.931 | Acc: 49.197,68.177,47.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.938 | Acc: 49.068,68.187,47.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.936 | Acc: 49.107,68.195,47.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.936 | Acc: 49.125,68.200,47.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.945 | Acc: 49.050,68.023,47.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.947 | Acc: 49.038,68.016,47.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.791 | Acc: 43.750,61.719,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.826 | Acc: 44.122,60.231,43.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.900 | Acc: 43.998,59.813,42.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.907 | Acc: 43.699,59.900,41.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 5.008 | Acc: 47.656,66.406,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.008 | Acc: 48.661,66.927,45.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.031 | Acc: 48.933,67.321,45.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.997 | Acc: 48.745,67.789,46.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.982 | Acc: 48.765,67.593,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.970 | Acc: 48.948,67.799,47.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.005 | Acc: 48.767,67.323,46.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.031 | Acc: 48.537,67.055,46.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.028 | Acc: 48.578,67.110,46.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.017 | Acc: 48.541,67.179,46.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.016 | Acc: 48.581,67.211,46.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.007 | Acc: 48.547,67.350,46.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.007 | Acc: 48.460,67.353,46.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.987 | Acc: 48.584,67.385,46.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.976 | Acc: 48.841,67.521,46.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.969 | Acc: 48.941,67.678,46.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.969 | Acc: 48.919,67.755,46.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.963 | Acc: 48.990,67.751,46.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.967 | Acc: 48.948,67.761,46.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.964 | Acc: 49.016,67.770,46.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.655 | Acc: 43.750,65.625,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.810 | Acc: 43.750,61.496,43.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.901 | Acc: 43.369,60.747,41.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.918 | Acc: 42.982,60.579,41.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 5.248 | Acc: 47.656,65.625,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.716 | Acc: 49.814,70.052,48.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.752 | Acc: 50.324,69.455,48.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.759 | Acc: 50.282,69.467,48.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.792 | Acc: 50.444,69.396,48.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.818 | Acc: 50.511,69.377,48.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.822 | Acc: 50.394,69.428,48.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.832 | Acc: 50.111,69.204,48.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.864 | Acc: 49.772,68.837,47.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.870 | Acc: 49.547,68.888,48.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.874 | Acc: 49.425,68.863,48.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.885 | Acc: 49.551,68.750,47.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.876 | Acc: 49.627,68.906,48.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.881 | Acc: 49.596,68.825,48.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.888 | Acc: 49.544,68.719,47.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.889 | Acc: 49.567,68.737,48.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.903 | Acc: 49.450,68.592,47.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.925 | Acc: 49.329,68.326,47.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.932 | Acc: 49.204,68.226,47.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.948 | Acc: 49.001,68.073,47.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.818 | Acc: 43.750,61.719,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.794 | Acc: 44.122,61.384,43.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.896 | Acc: 43.845,60.232,42.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.910 | Acc: 43.635,60.067,41.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 4.754 | Acc: 49.219,66.406,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.987 | Acc: 48.996,68.266,47.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.964 | Acc: 49.657,68.388,46.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.948 | Acc: 49.321,68.404,46.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.961 | Acc: 49.103,68.123,46.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.944 | Acc: 49.157,68.255,47.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.925 | Acc: 49.193,68.434,47.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.920 | Acc: 49.191,68.467,47.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.937 | Acc: 48.957,68.347,47.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.930 | Acc: 48.895,68.400,47.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.937 | Acc: 48.958,68.284,47.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.931 | Acc: 48.968,68.273,47.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.929 | Acc: 49.005,68.277,47.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.931 | Acc: 49.006,68.259,47.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.926 | Acc: 49.027,68.344,47.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.928 | Acc: 48.938,68.278,47.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.920 | Acc: 48.990,68.429,47.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.923 | Acc: 48.983,68.351,47.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.925 | Acc: 48.989,68.347,47.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.927 | Acc: 49.008,68.332,47.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.550 | Acc: 42.188,67.969,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.822 | Acc: 44.717,62.202,42.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.929 | Acc: 43.712,61.166,40.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.972 | Acc: 43.148,60.605,40.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 4.819 | Acc: 52.344,67.188,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.804 | Acc: 49.591,69.866,48.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.812 | Acc: 49.638,70.027,48.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.881 | Acc: 48.911,69.185,47.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.906 | Acc: 48.929,68.818,47.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.912 | Acc: 49.041,68.704,47.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.934 | Acc: 48.605,68.466,47.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.952 | Acc: 48.498,68.074,47.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.954 | Acc: 48.700,68.163,47.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.957 | Acc: 48.796,68.068,47.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.976 | Acc: 48.803,67.980,46.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.975 | Acc: 48.886,68.008,46.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.979 | Acc: 48.872,67.991,46.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.981 | Acc: 48.830,67.945,46.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.978 | Acc: 48.810,67.960,46.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.981 | Acc: 48.790,67.927,46.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.986 | Acc: 48.739,67.864,46.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.993 | Acc: 48.722,67.811,46.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.994 | Acc: 48.645,67.770,46.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.991 | Acc: 48.649,67.762,47.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.746 | Acc: 46.875,65.625,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.789 | Acc: 44.345,61.942,43.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.877 | Acc: 43.674,61.261,42.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.906 | Acc: 43.276,60.899,42.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 4.457 | Acc: 60.156,69.531,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.944 | Acc: 49.591,68.155,46.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.960 | Acc: 49.600,68.331,47.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.915 | Acc: 49.257,68.353,48.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.882 | Acc: 49.257,68.779,48.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.859 | Acc: 49.080,68.851,48.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.881 | Acc: 49.044,68.576,48.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.866 | Acc: 49.313,68.684,48.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.873 | Acc: 49.204,68.527,48.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.880 | Acc: 49.085,68.413,48.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.885 | Acc: 49.040,68.381,48.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.887 | Acc: 49.060,68.446,48.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.888 | Acc: 49.073,68.432,48.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.885 | Acc: 49.072,68.439,48.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.886 | Acc: 49.158,68.461,48.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.887 | Acc: 49.143,68.439,48.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.900 | Acc: 49.024,68.356,48.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.905 | Acc: 49.063,68.374,48.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.913 | Acc: 48.927,68.298,47.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.922 | Acc: 48.895,68.244,47.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.748 | Acc: 47.656,63.281,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.932 | Acc: 43.452,60.454,43.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.054 | Acc: 42.226,59.299,41.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.074 | Acc: 42.098,59.068,41.265,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 5.170 | Acc: 49.219,66.406,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.838 | Acc: 48.847,70.052,49.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.922 | Acc: 48.495,69.093,48.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.925 | Acc: 48.668,68.968,47.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.981 | Acc: 48.110,68.451,47.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.085 | Acc: 47.494,67.373,46.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.142 | Acc: 47.275,67.033,46.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.161 | Acc: 47.141,66.717,45.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.157 | Acc: 47.317,66.722,45.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.135 | Acc: 47.574,66.998,46.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.120 | Acc: 47.773,67.106,46.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.105 | Acc: 47.943,67.081,46.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.092 | Acc: 48.039,67.061,46.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.080 | Acc: 48.057,67.223,46.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.074 | Acc: 48.104,67.285,46.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.068 | Acc: 48.165,67.286,46.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.060 | Acc: 48.172,67.363,46.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.057 | Acc: 48.188,67.382,46.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.057 | Acc: 48.210,67.384,46.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.060 | Acc: 48.222,67.364,46.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.616 | Acc: 47.656,64.844,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.794 | Acc: 43.973,61.682,44.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.871 | Acc: 43.255,60.614,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.878 | Acc: 43.263,60.617,42.533,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 4.860 | Acc: 52.344,70.312,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.964 | Acc: 48.698,68.527,47.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.956 | Acc: 48.171,68.255,47.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.945 | Acc: 48.566,68.648,47.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.947 | Acc: 48.245,68.056,47.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.963 | Acc: 48.499,68.015,46.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.940 | Acc: 48.670,68.137,47.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.935 | Acc: 48.681,68.246,47.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.936 | Acc: 48.510,68.148,47.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.958 | Acc: 48.394,67.891,47.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.964 | Acc: 48.480,67.860,47.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.946 | Acc: 48.667,67.997,47.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.955 | Acc: 48.716,68.004,47.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.953 | Acc: 48.710,68.068,47.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.983 | Acc: 48.529,67.891,47.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.989 | Acc: 48.601,67.901,47.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.996 | Acc: 48.525,67.796,47.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.997 | Acc: 48.568,67.721,47.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.991 | Acc: 48.660,67.742,47.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.993 | Acc: 48.599,67.762,47.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.680 | Acc: 53.125,65.625,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.909 | Acc: 44.159,61.161,41.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.976 | Acc: 43.750,60.271,40.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.000 | Acc: 43.494,60.272,40.190,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 4.371 | Acc: 60.156,80.469,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.999 | Acc: 48.735,68.378,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.986 | Acc: 48.914,68.159,46.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.999 | Acc: 48.796,67.508,47.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.036 | Acc: 48.553,67.130,46.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.040 | Acc: 48.167,67.079,46.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.071 | Acc: 48.044,66.884,46.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.064 | Acc: 48.194,66.816,46.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.089 | Acc: 48.069,66.717,46.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.110 | Acc: 47.885,66.626,46.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.116 | Acc: 47.889,66.535,46.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.109 | Acc: 48.066,66.604,45.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.121 | Acc: 48.036,66.539,45.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.121 | Acc: 48.024,66.580,46.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.119 | Acc: 48.121,66.701,46.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.116 | Acc: 48.095,66.738,46.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.118 | Acc: 48.089,66.752,46.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.127 | Acc: 48.027,66.716,45.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.147 | Acc: 47.858,66.519,45.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.147 | Acc: 47.882,66.599,45.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.856 | Acc: 50.781,64.062,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.906 | Acc: 45.796,60.528,41.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.985 | Acc: 44.684,59.851,40.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.014 | Acc: 44.634,59.606,41.022,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 5.550 | Acc: 39.062,64.844,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.115 | Acc: 48.140,65.960,47.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.088 | Acc: 47.961,66.997,46.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.081 | Acc: 48.271,67.226,46.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.054 | Acc: 48.428,67.602,46.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.049 | Acc: 48.252,67.427,46.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.050 | Acc: 48.270,67.304,46.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.046 | Acc: 48.399,67.337,46.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.060 | Acc: 48.141,67.197,46.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.056 | Acc: 48.226,67.343,46.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.049 | Acc: 48.434,67.456,46.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.067 | Acc: 48.293,67.354,46.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.065 | Acc: 48.318,67.314,46.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.052 | Acc: 48.393,67.463,46.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.032 | Acc: 48.535,67.627,46.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.038 | Acc: 48.484,67.546,46.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.027 | Acc: 48.603,67.696,46.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.031 | Acc: 48.584,67.650,46.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.034 | Acc: 48.559,67.664,46.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.033 | Acc: 48.571,67.665,46.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.697 | Acc: 42.969,63.281,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.863 | Acc: 44.829,60.826,43.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.942 | Acc: 44.284,59.851,42.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.960 | Acc: 43.596,59.913,42.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 5.547 | Acc: 40.625,60.156,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.996 | Acc: 49.665,67.225,47.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.941 | Acc: 49.809,67.721,47.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.959 | Acc: 49.513,67.892,47.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.933 | Acc: 49.585,68.364,48.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.947 | Acc: 49.428,68.178,47.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.946 | Acc: 49.561,68.201,47.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.949 | Acc: 49.302,67.963,47.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.953 | Acc: 49.146,67.906,47.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.955 | Acc: 49.206,67.947,47.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.960 | Acc: 49.133,67.922,47.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.957 | Acc: 49.261,67.905,47.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.958 | Acc: 49.147,67.742,47.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.956 | Acc: 49.021,67.843,47.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.958 | Acc: 49.027,67.824,47.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.950 | Acc: 49.086,67.878,47.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.947 | Acc: 49.138,67.915,47.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.945 | Acc: 49.164,67.966,47.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.948 | Acc: 49.184,67.945,47.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.944 | Acc: 49.167,67.975,47.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.769 | Acc: 42.969,60.938,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.037 | Acc: 41.518,60.193,41.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.061 | Acc: 41.578,59.699,41.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.048 | Acc: 41.765,59.708,41.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 4.421 | Acc: 57.031,77.344,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.721 | Acc: 50.670,70.461,49.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.918 | Acc: 49.257,68.236,48.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.934 | Acc: 49.270,67.905,48.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.958 | Acc: 48.717,67.843,47.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.974 | Acc: 48.430,67.675,47.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.988 | Acc: 48.199,67.659,47.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.987 | Acc: 48.438,67.614,47.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.983 | Acc: 48.598,67.551,47.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.981 | Acc: 48.666,67.559,47.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.968 | Acc: 48.748,67.806,47.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.956 | Acc: 48.770,67.909,47.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.947 | Acc: 48.927,67.995,47.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.948 | Acc: 48.886,67.945,47.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.958 | Acc: 48.868,67.852,47.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.951 | Acc: 48.853,67.927,47.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.948 | Acc: 48.834,67.923,47.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.961 | Acc: 48.715,67.811,47.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.965 | Acc: 48.671,67.681,47.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.964 | Acc: 48.663,67.688,47.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.826 | Acc: 46.094,64.844,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.766 | Acc: 44.606,62.463,44.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.905 | Acc: 43.236,60.575,43.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.914 | Acc: 43.097,60.643,43.135,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 5.048 | Acc: 43.750,65.625,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.788 | Acc: 50.930,68.304,48.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.875 | Acc: 49.619,68.007,48.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.982 | Acc: 48.796,67.290,47.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.002 | Acc: 48.775,67.361,46.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.984 | Acc: 48.739,67.381,47.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.977 | Acc: 48.980,67.472,47.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.995 | Acc: 48.676,67.276,47.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.015 | Acc: 48.578,67.144,47.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.001 | Acc: 48.748,67.252,47.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.007 | Acc: 48.737,67.168,47.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.010 | Acc: 48.777,67.180,47.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.003 | Acc: 48.856,67.226,47.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.996 | Acc: 48.922,67.301,47.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.994 | Acc: 48.860,67.343,47.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.001 | Acc: 48.788,67.289,47.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.010 | Acc: 48.781,67.207,47.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.013 | Acc: 48.777,67.190,47.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.009 | Acc: 48.782,67.207,47.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.007 | Acc: 48.751,67.235,47.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.052 | Acc: 42.969,64.844,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.031 | Acc: 40.848,60.640,44.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.125 | Acc: 40.415,59.356,42.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.147 | Acc: 39.997,59.388,42.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 4.627 | Acc: 52.344,65.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.716 | Acc: 51.860,69.754,50.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.829 | Acc: 49.390,68.598,49.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.840 | Acc: 49.577,68.763,49.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.843 | Acc: 49.508,68.740,49.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.861 | Acc: 49.513,68.487,49.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.901 | Acc: 49.329,68.330,48.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.924 | Acc: 49.064,68.323,48.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.919 | Acc: 49.088,68.328,48.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.935 | Acc: 48.904,68.094,48.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.941 | Acc: 48.846,68.027,48.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.955 | Acc: 48.657,67.774,47.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.968 | Acc: 48.668,67.696,47.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.981 | Acc: 48.611,67.568,47.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.981 | Acc: 48.546,67.588,47.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.981 | Acc: 48.523,67.564,47.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.984 | Acc: 48.532,67.555,47.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.990 | Acc: 48.486,67.474,47.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.003 | Acc: 48.422,67.358,47.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.005 | Acc: 48.435,67.308,47.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.619 | Acc: 47.656,62.500,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.775 | Acc: 45.499,61.570,43.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.857 | Acc: 44.417,60.633,42.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.877 | Acc: 44.083,60.566,41.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 4.269 | Acc: 50.781,74.219,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.993 | Acc: 48.586,68.341,46.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.929 | Acc: 48.742,68.369,47.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.963 | Acc: 48.604,68.238,46.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.989 | Acc: 48.158,67.911,46.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.023 | Acc: 48.120,67.706,46.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.016 | Acc: 48.354,67.685,46.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.002 | Acc: 48.482,67.996,46.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.000 | Acc: 48.491,67.915,46.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.997 | Acc: 48.403,67.757,47.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.002 | Acc: 48.344,67.821,47.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.980 | Acc: 48.579,67.919,47.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.988 | Acc: 48.593,67.774,47.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.982 | Acc: 48.563,67.828,47.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.975 | Acc: 48.682,67.869,47.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.976 | Acc: 48.731,67.904,47.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.983 | Acc: 48.647,67.896,47.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.987 | Acc: 48.701,67.802,47.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.984 | Acc: 48.773,67.826,47.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.980 | Acc: 48.753,67.766,47.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.755 | Acc: 48.438,64.062,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.903 | Acc: 44.829,61.198,41.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.012 | Acc: 43.998,60.137,40.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.056 | Acc: 43.801,59.567,40.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 4.700 | Acc: 50.000,63.281,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.877 | Acc: 49.777,68.862,46.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.949 | Acc: 48.952,67.873,46.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.940 | Acc: 49.155,68.058,47.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.926 | Acc: 49.248,67.978,47.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.911 | Acc: 49.381,68.046,47.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.915 | Acc: 49.180,68.195,47.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.913 | Acc: 48.825,67.991,47.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.901 | Acc: 49.068,68.071,47.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.907 | Acc: 49.271,68.111,47.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.909 | Acc: 49.188,68.179,48.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.907 | Acc: 49.194,68.068,48.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.919 | Acc: 48.972,67.936,48.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.934 | Acc: 48.907,67.915,48.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.935 | Acc: 48.969,67.938,48.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.934 | Acc: 48.894,67.969,48.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.943 | Acc: 48.778,67.803,47.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.945 | Acc: 48.738,67.790,47.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.939 | Acc: 48.740,67.822,47.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.940 | Acc: 48.743,67.825,48.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.007 | Acc: 46.875,62.500,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.139 | Acc: 41.369,59.821,42.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.217 | Acc: 40.835,58.727,41.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.223 | Acc: 40.868,58.760,40.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 4.771 | Acc: 53.125,65.625,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.039 | Acc: 48.438,67.448,45.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.004 | Acc: 48.018,67.054,46.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.931 | Acc: 48.642,67.751,48.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.926 | Acc: 48.370,67.747,48.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.932 | Acc: 48.414,67.799,48.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.898 | Acc: 48.864,68.169,48.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.889 | Acc: 48.908,68.185,48.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.904 | Acc: 48.748,67.906,48.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.914 | Acc: 48.813,67.982,48.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.914 | Acc: 48.850,68.004,48.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.906 | Acc: 48.759,68.043,48.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.912 | Acc: 48.668,67.985,48.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.909 | Acc: 48.704,68.059,48.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.899 | Acc: 48.735,68.152,48.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.904 | Acc: 48.591,68.065,48.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.903 | Acc: 48.625,68.042,48.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.897 | Acc: 48.685,68.058,48.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.884 | Acc: 48.842,68.259,48.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.885 | Acc: 48.932,68.262,48.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.905 | Acc: 43.750,62.500,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.097 | Acc: 41.629,59.561,42.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.251 | Acc: 40.339,58.060,40.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.246 | Acc: 40.215,57.851,40.484,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 4.871 | Acc: 54.688,69.531,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.859 | Acc: 51.153,69.717,49.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.863 | Acc: 50.838,68.712,48.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.888 | Acc: 49.910,68.584,48.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.873 | Acc: 49.749,68.760,49.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.899 | Acc: 49.134,68.340,49.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.883 | Acc: 49.077,68.150,49.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.879 | Acc: 49.075,68.296,49.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.884 | Acc: 48.889,68.197,48.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.879 | Acc: 48.973,68.387,48.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.863 | Acc: 49.141,68.525,49.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.861 | Acc: 49.180,68.474,49.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.858 | Acc: 49.190,68.413,49.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.860 | Acc: 49.084,68.433,49.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.862 | Acc: 49.049,68.450,49.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.866 | Acc: 49.040,68.464,49.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.869 | Acc: 49.058,68.382,49.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.879 | Acc: 49.072,68.248,49.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.884 | Acc: 49.082,68.241,49.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.886 | Acc: 49.036,68.274,49.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.434 | Acc: 52.344,64.844,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.704 | Acc: 45.536,61.793,44.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.801 | Acc: 44.684,60.785,43.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.819 | Acc: 44.608,60.617,42.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 5.173 | Acc: 44.531,64.062,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.779 | Acc: 48.140,70.164,49.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.804 | Acc: 48.876,69.150,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.856 | Acc: 48.950,69.057,49.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.848 | Acc: 48.920,69.039,49.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.868 | Acc: 48.832,68.619,49.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.838 | Acc: 49.251,69.002,49.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.875 | Acc: 49.152,68.578,49.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.916 | Acc: 48.962,68.289,48.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.937 | Acc: 48.925,68.094,48.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.964 | Acc: 48.713,67.806,48.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.982 | Acc: 48.590,67.675,48.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.984 | Acc: 48.567,67.609,48.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.993 | Acc: 48.479,67.502,47.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.999 | Acc: 48.463,67.471,47.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.005 | Acc: 48.391,67.385,47.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.003 | Acc: 48.430,67.501,47.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.001 | Acc: 48.435,67.481,47.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.010 | Acc: 48.331,67.417,47.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.015 | Acc: 48.314,67.425,47.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.152 | Acc: 42.969,57.812,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.879 | Acc: 43.118,60.305,43.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.994 | Acc: 42.283,59.280,43.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.013 | Acc: 41.880,59.260,43.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 5.040 | Acc: 46.094,65.625,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.893 | Acc: 49.219,68.118,49.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.918 | Acc: 49.009,68.236,49.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.917 | Acc: 49.039,68.007,49.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.909 | Acc: 48.949,67.843,48.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.908 | Acc: 48.933,68.062,49.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.918 | Acc: 48.896,67.982,48.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.957 | Acc: 48.803,67.930,48.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.960 | Acc: 48.792,67.944,48.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.965 | Acc: 48.696,67.792,48.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.955 | Acc: 48.760,67.806,48.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.965 | Acc: 48.727,67.764,48.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.970 | Acc: 48.720,67.716,48.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.971 | Acc: 48.671,67.702,47.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.967 | Acc: 48.660,67.760,47.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.961 | Acc: 48.694,67.771,48.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.955 | Acc: 48.742,67.901,48.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.951 | Acc: 48.724,67.950,48.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.941 | Acc: 48.855,68.034,48.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.937 | Acc: 48.926,68.065,48.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.730 | Acc: 43.750,64.844,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.876 | Acc: 43.229,59.896,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.959 | Acc: 42.226,59.470,43.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.965 | Acc: 42.085,59.426,43.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 4.821 | Acc: 53.906,65.625,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.918 | Acc: 49.107,66.629,47.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.892 | Acc: 49.047,67.931,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.896 | Acc: 49.014,68.046,48.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.924 | Acc: 48.630,67.940,48.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.911 | Acc: 48.778,68.232,48.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.896 | Acc: 49.019,68.479,48.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.901 | Acc: 48.864,68.451,48.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.919 | Acc: 48.612,68.211,48.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.923 | Acc: 48.571,68.029,48.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.924 | Acc: 48.511,68.058,48.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.921 | Acc: 48.568,68.082,48.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.911 | Acc: 48.674,68.089,48.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.909 | Acc: 48.626,68.121,48.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.907 | Acc: 48.716,68.200,48.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.900 | Acc: 48.814,68.169,48.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.895 | Acc: 48.834,68.202,48.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.903 | Acc: 48.772,68.193,48.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.908 | Acc: 48.738,68.086,48.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.907 | Acc: 48.802,68.073,48.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.705 | Acc: 42.969,62.500,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.061 | Acc: 41.778,58.854,43.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.217 | Acc: 41.197,57.908,41.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.241 | Acc: 40.369,58.120,41.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 4.699 | Acc: 51.562,67.188,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.973 | Acc: 47.842,68.452,49.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.957 | Acc: 47.961,68.521,49.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.966 | Acc: 48.066,68.302,48.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.976 | Acc: 48.052,68.162,48.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.963 | Acc: 48.205,68.348,48.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.964 | Acc: 48.341,68.233,48.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.958 | Acc: 48.316,68.262,48.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.952 | Acc: 48.374,68.173,48.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.949 | Acc: 48.498,68.055,48.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.957 | Acc: 48.472,67.953,48.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.959 | Acc: 48.462,67.856,48.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.952 | Acc: 48.629,67.888,48.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.957 | Acc: 48.635,67.822,48.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.955 | Acc: 48.593,67.791,48.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.958 | Acc: 48.518,67.722,48.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.954 | Acc: 48.557,67.694,48.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.958 | Acc: 48.513,67.673,48.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.961 | Acc: 48.461,67.700,48.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.961 | Acc: 48.476,67.753,48.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.569 | Acc: 49.219,64.062,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.699 | Acc: 44.978,61.384,46.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.795 | Acc: 43.769,60.175,45.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.819 | Acc: 43.609,59.964,44.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 4.769 | Acc: 53.125,67.969,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.770 | Acc: 50.781,69.457,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.778 | Acc: 50.629,69.627,49.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.789 | Acc: 50.269,69.659,49.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.792 | Acc: 50.309,69.194,49.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.797 | Acc: 49.861,69.261,49.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.798 | Acc: 49.839,69.202,49.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.828 | Acc: 49.717,68.811,49.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.847 | Acc: 49.626,68.522,49.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.860 | Acc: 49.366,68.543,49.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.864 | Acc: 49.363,68.466,49.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.877 | Acc: 49.222,68.418,49.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.884 | Acc: 49.196,68.296,49.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.889 | Acc: 49.195,68.247,48.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.884 | Acc: 49.124,68.272,48.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.882 | Acc: 49.128,68.267,49.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.880 | Acc: 49.141,68.368,49.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.873 | Acc: 49.173,68.448,49.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.868 | Acc: 49.191,68.490,49.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.870 | Acc: 49.182,68.508,49.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.656 | Acc: 46.094,64.062,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.843 | Acc: 44.903,60.975,45.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.946 | Acc: 44.322,59.985,43.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.960 | Acc: 43.584,59.375,43.635,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 5.235 | Acc: 45.312,60.938,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.795 | Acc: 48.772,69.382,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.870 | Acc: 48.018,68.293,48.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.853 | Acc: 49.091,68.494,49.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.854 | Acc: 49.074,68.248,49.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.864 | Acc: 48.979,68.123,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.860 | Acc: 48.980,68.298,49.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.865 | Acc: 48.997,68.213,49.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.860 | Acc: 49.068,68.405,49.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.859 | Acc: 49.094,68.469,49.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.859 | Acc: 49.067,68.404,49.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.849 | Acc: 49.261,68.435,49.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.850 | Acc: 49.186,68.442,49.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.847 | Acc: 49.165,68.594,49.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.853 | Acc: 49.094,68.541,49.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.874 | Acc: 49.097,68.410,49.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.880 | Acc: 49.131,68.421,49.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.894 | Acc: 49.056,68.347,49.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.895 | Acc: 49.033,68.337,49.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.891 | Acc: 49.049,68.391,49.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.829 | Acc: 48.438,62.500,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.807 | Acc: 43.490,61.161,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.881 | Acc: 43.274,60.442,44.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.887 | Acc: 42.789,60.451,43.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 4.914 | Acc: 44.531,66.406,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.714 | Acc: 49.107,69.754,51.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.780 | Acc: 48.742,68.807,50.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.857 | Acc: 48.617,68.135,49.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.868 | Acc: 48.736,68.297,49.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.896 | Acc: 48.492,68.046,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.879 | Acc: 48.883,68.188,49.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.860 | Acc: 49.053,68.318,49.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.853 | Acc: 49.175,68.372,49.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.868 | Acc: 49.236,68.228,49.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.874 | Acc: 49.137,68.214,49.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.872 | Acc: 49.152,68.347,49.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.864 | Acc: 49.238,68.442,49.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.873 | Acc: 49.111,68.298,49.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.871 | Acc: 49.121,68.269,49.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.866 | Acc: 49.110,68.252,49.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.875 | Acc: 49.056,68.151,49.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.882 | Acc: 48.980,68.097,49.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.880 | Acc: 48.989,68.096,49.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.877 | Acc: 49.008,68.127,49.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.700 | Acc: 46.875,63.281,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.702 | Acc: 44.829,61.347,45.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.780 | Acc: 44.284,61.166,44.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.815 | Acc: 44.249,61.206,44.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 4.367 | Acc: 51.562,74.219,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.670 | Acc: 50.186,70.052,50.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.803 | Acc: 49.181,68.178,50.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.818 | Acc: 49.321,68.148,50.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.821 | Acc: 49.248,68.615,50.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.816 | Acc: 49.381,68.905,50.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.798 | Acc: 49.535,69.053,50.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.808 | Acc: 49.463,68.994,50.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.809 | Acc: 49.258,68.949,50.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.814 | Acc: 49.262,68.832,50.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.835 | Acc: 49.149,68.618,50.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.828 | Acc: 49.219,68.708,50.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.848 | Acc: 49.105,68.549,50.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.855 | Acc: 49.036,68.520,50.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.863 | Acc: 49.024,68.478,49.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.864 | Acc: 49.016,68.493,50.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.873 | Acc: 48.927,68.370,49.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.871 | Acc: 48.964,68.422,49.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.877 | Acc: 48.903,68.302,49.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.878 | Acc: 48.946,68.328,49.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.901 | Acc: 45.312,67.188,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.835 | Acc: 42.783,62.128,45.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.941 | Acc: 42.435,60.785,44.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.958 | Acc: 41.765,60.400,43.545,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 5.416 | Acc: 41.406,59.375,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.933 | Acc: 48.140,67.262,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.886 | Acc: 48.609,68.083,50.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.869 | Acc: 48.591,68.097,49.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.836 | Acc: 48.843,68.277,49.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.835 | Acc: 48.917,68.232,49.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.857 | Acc: 48.793,68.001,49.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.880 | Acc: 48.681,67.863,49.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.875 | Acc: 48.651,67.867,49.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.881 | Acc: 48.696,67.999,49.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.889 | Acc: 48.741,67.996,49.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.880 | Acc: 48.837,68.128,49.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.874 | Acc: 48.917,68.069,49.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.884 | Acc: 48.943,68.029,49.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.883 | Acc: 48.999,68.033,49.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.892 | Acc: 48.985,67.930,49.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.889 | Acc: 48.995,68.015,49.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.890 | Acc: 48.962,68.003,49.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.885 | Acc: 48.994,68.057,49.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.879 | Acc: 49.055,68.104,49.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.940 | Acc: 43.750,59.375,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.897 | Acc: 43.155,60.156,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.973 | Acc: 42.226,59.870,43.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.000 | Acc: 41.995,59.798,43.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 4.697 | Acc: 55.469,62.500,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.899 | Acc: 49.107,68.601,49.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.906 | Acc: 48.952,68.007,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.889 | Acc: 49.321,68.315,49.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.829 | Acc: 49.730,68.972,49.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.864 | Acc: 49.118,68.796,49.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.853 | Acc: 49.219,68.776,50.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.828 | Acc: 49.463,68.999,50.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.819 | Acc: 49.423,69.065,50.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.820 | Acc: 49.486,69.005,50.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.837 | Acc: 49.363,68.867,50.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.846 | Acc: 49.275,68.693,49.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.852 | Acc: 49.196,68.653,49.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.853 | Acc: 49.180,68.678,49.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.859 | Acc: 49.146,68.700,49.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.873 | Acc: 49.073,68.545,49.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.908 | Acc: 48.834,68.292,49.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.925 | Acc: 48.735,68.170,49.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.937 | Acc: 48.665,68.079,49.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.941 | Acc: 48.583,68.018,49.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.610 | Acc: 46.094,64.062,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.792 | Acc: 43.341,61.161,45.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.872 | Acc: 42.473,59.832,44.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.889 | Acc: 42.072,59.926,44.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 4.793 | Acc: 54.688,64.062,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.807 | Acc: 48.735,70.424,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.830 | Acc: 48.761,69.970,50.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.874 | Acc: 48.681,69.647,49.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.860 | Acc: 49.055,69.608,50.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.867 | Acc: 49.157,69.392,49.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.892 | Acc: 49.122,69.008,49.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.877 | Acc: 49.396,69.077,49.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.888 | Acc: 49.296,68.842,49.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.892 | Acc: 49.115,68.677,49.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.895 | Acc: 49.090,68.583,49.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.891 | Acc: 49.046,68.531,49.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.874 | Acc: 49.251,68.549,49.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.876 | Acc: 49.276,68.523,49.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.879 | Acc: 49.119,68.416,49.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.884 | Acc: 49.131,68.366,49.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.886 | Acc: 49.131,68.363,49.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.897 | Acc: 49.072,68.269,49.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.897 | Acc: 49.007,68.235,49.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.898 | Acc: 48.973,68.180,49.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.101 | Acc: 46.875,60.938,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.134 | Acc: 41.964,59.226,44.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.201 | Acc: 41.444,58.537,42.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.215 | Acc: 41.150,58.837,42.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 4.784 | Acc: 47.656,69.531,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.920 | Acc: 48.326,68.490,47.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.943 | Acc: 48.514,67.988,47.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.901 | Acc: 48.566,68.276,48.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.846 | Acc: 49.074,68.866,49.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.833 | Acc: 49.103,68.750,49.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.805 | Acc: 49.425,68.905,49.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.922 | Acc: 48.875,68.135,48.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.975 | Acc: 48.622,67.615,48.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.988 | Acc: 48.511,67.425,48.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.982 | Acc: 48.546,67.522,48.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.978 | Acc: 48.462,67.502,48.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.978 | Acc: 48.447,67.473,48.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.971 | Acc: 48.557,67.532,48.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.976 | Acc: 48.543,67.468,48.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.973 | Acc: 48.606,67.540,48.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.979 | Acc: 48.513,67.557,48.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.978 | Acc: 48.440,67.517,48.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.983 | Acc: 48.386,67.423,48.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.980 | Acc: 48.433,67.421,48.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.687 | Acc: 45.312,65.625,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.810 | Acc: 43.638,61.012,43.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.898 | Acc: 42.931,60.175,42.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.921 | Acc: 42.341,60.143,42.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 5.262 | Acc: 46.875,67.969,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.777 | Acc: 49.107,67.969,50.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.827 | Acc: 49.238,68.064,50.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.824 | Acc: 49.449,68.263,50.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.817 | Acc: 49.373,68.345,50.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.836 | Acc: 49.451,68.363,50.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.840 | Acc: 49.464,68.382,50.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.850 | Acc: 49.252,68.395,50.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.854 | Acc: 49.233,68.338,50.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.869 | Acc: 49.046,68.284,49.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.871 | Acc: 49.009,68.210,49.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.887 | Acc: 48.872,68.043,49.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.895 | Acc: 48.908,68.069,49.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.899 | Acc: 48.931,67.999,49.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.907 | Acc: 48.849,67.921,49.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.913 | Acc: 48.749,67.868,49.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.913 | Acc: 48.708,67.837,49.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.911 | Acc: 48.717,67.808,49.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.916 | Acc: 48.641,67.835,49.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.917 | Acc: 48.661,67.844,49.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.314 | Acc: 42.969,59.375,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.320 | Acc: 42.113,59.003,41.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.480 | Acc: 41.216,57.641,40.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.470 | Acc: 40.856,57.275,40.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 4.866 | Acc: 44.531,69.531,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.980 | Acc: 48.624,68.155,49.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.961 | Acc: 48.742,68.121,49.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.936 | Acc: 48.822,68.263,49.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.880 | Acc: 48.872,68.634,49.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.888 | Acc: 48.933,68.325,49.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.900 | Acc: 48.644,68.001,49.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.880 | Acc: 48.814,68.008,49.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.883 | Acc: 48.918,68.216,49.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.891 | Acc: 48.973,68.223,49.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.887 | Acc: 48.923,68.221,49.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.888 | Acc: 48.925,68.089,49.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.906 | Acc: 48.797,67.917,49.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.901 | Acc: 48.919,67.921,49.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.902 | Acc: 48.957,67.947,49.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.909 | Acc: 48.962,67.878,49.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.928 | Acc: 48.878,67.849,49.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.942 | Acc: 48.861,67.733,49.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.944 | Acc: 48.779,67.694,49.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.952 | Acc: 48.706,67.637,49.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.467 | Acc: 46.094,57.812,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.539 | Acc: 41.220,56.473,38.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.670 | Acc: 40.206,54.421,37.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.679 | Acc: 39.831,54.355,37.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 4.704 | Acc: 50.781,65.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.380 | Acc: 46.689,64.323,45.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.269 | Acc: 46.570,64.920,45.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.157 | Acc: 47.041,65.830,46.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.133 | Acc: 47.521,65.818,46.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.137 | Acc: 47.486,65.880,46.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.105 | Acc: 47.760,66.096,46.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.090 | Acc: 47.922,66.307,47.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.080 | Acc: 47.928,66.508,47.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.069 | Acc: 48.032,66.687,47.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.061 | Acc: 48.134,66.717,47.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.049 | Acc: 48.197,66.809,47.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.041 | Acc: 48.301,66.999,47.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.041 | Acc: 48.327,67.047,47.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.043 | Acc: 48.415,67.054,47.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.041 | Acc: 48.510,67.058,47.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.041 | Acc: 48.474,67.027,47.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.047 | Acc: 48.460,66.901,47.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.049 | Acc: 48.405,66.910,47.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.050 | Acc: 48.386,66.839,47.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.094 | Acc: 47.656,58.594,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.008 | Acc: 43.750,58.482,43.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.122 | Acc: 42.397,57.584,42.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.143 | Acc: 42.341,57.966,41.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 4.862 | Acc: 50.781,70.312,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.789 | Acc: 50.223,69.457,49.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.796 | Acc: 49.714,69.436,50.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.866 | Acc: 49.129,68.340,49.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.877 | Acc: 48.872,68.268,49.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.898 | Acc: 48.646,68.201,49.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.884 | Acc: 48.780,68.356,49.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.879 | Acc: 48.787,68.340,49.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.871 | Acc: 48.835,68.338,49.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.868 | Acc: 48.899,68.374,49.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.856 | Acc: 48.884,68.431,50.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.845 | Acc: 48.922,68.503,50.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.841 | Acc: 48.911,68.504,50.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.849 | Acc: 48.785,68.448,50.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.856 | Acc: 48.704,68.314,50.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.868 | Acc: 48.669,68.114,50.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.865 | Acc: 48.717,68.166,50.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.868 | Acc: 48.735,68.209,50.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.875 | Acc: 48.658,68.133,49.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.879 | Acc: 48.630,68.108,49.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.995 | Acc: 43.750,62.500,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.028 | Acc: 42.857,61.049,43.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.114 | Acc: 41.825,60.004,41.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.144 | Acc: 41.637,59.401,41.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 5.406 | Acc: 46.094,65.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.865 | Acc: 49.740,68.304,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.945 | Acc: 48.666,68.216,48.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.936 | Acc: 48.719,67.828,48.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.931 | Acc: 49.161,68.007,48.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.958 | Acc: 48.592,67.613,48.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.954 | Acc: 48.651,67.665,48.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.946 | Acc: 48.681,67.886,48.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.930 | Acc: 48.767,68.105,49.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.941 | Acc: 48.636,68.072,49.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.927 | Acc: 48.640,68.171,49.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.922 | Acc: 48.724,68.061,49.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.904 | Acc: 48.985,68.251,49.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.896 | Acc: 49.027,68.373,49.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.892 | Acc: 48.996,68.380,49.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.883 | Acc: 49.079,68.498,49.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.880 | Acc: 49.109,68.494,49.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.886 | Acc: 49.113,68.413,49.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.892 | Acc: 49.046,68.373,49.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.895 | Acc: 49.042,68.282,49.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.760 | Acc: 41.406,62.500,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.895 | Acc: 43.341,60.454,45.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.993 | Acc: 43.083,59.775,43.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.017 | Acc: 42.495,59.311,43.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 4.545 | Acc: 53.125,70.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.973 | Acc: 47.284,67.485,48.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.889 | Acc: 48.361,68.617,49.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.870 | Acc: 48.924,68.507,49.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.852 | Acc: 48.823,68.567,49.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.849 | Acc: 48.847,68.549,50.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.842 | Acc: 48.741,68.698,50.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.833 | Acc: 48.814,68.672,50.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.832 | Acc: 48.831,68.677,50.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.846 | Acc: 48.813,68.612,50.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.845 | Acc: 48.884,68.552,50.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.834 | Acc: 49.095,68.704,50.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.836 | Acc: 49.105,68.646,50.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.842 | Acc: 49.162,68.543,50.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.841 | Acc: 49.188,68.489,50.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.844 | Acc: 49.198,68.449,50.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.845 | Acc: 49.102,68.446,50.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.841 | Acc: 49.168,68.484,50.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.848 | Acc: 49.147,68.397,50.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.845 | Acc: 49.206,68.444,50.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.604 | Acc: 50.781,63.281,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.629 | Acc: 46.391,62.946,46.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.733 | Acc: 44.989,61.604,44.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.761 | Acc: 44.647,61.194,44.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 4.135 | Acc: 52.344,72.656,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.748 | Acc: 48.363,69.494,51.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.794 | Acc: 48.800,69.436,51.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.888 | Acc: 48.258,68.686,49.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.894 | Acc: 48.245,68.528,49.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.893 | Acc: 48.360,68.502,49.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.898 | Acc: 48.399,68.343,50.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.915 | Acc: 48.487,68.118,49.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.907 | Acc: 48.496,67.906,49.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.903 | Acc: 48.610,67.964,49.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.898 | Acc: 48.574,67.926,50.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.892 | Acc: 48.625,67.937,50.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.887 | Acc: 48.713,68.024,50.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.877 | Acc: 48.779,68.071,50.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.882 | Acc: 48.621,68.019,50.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.885 | Acc: 48.611,68.010,50.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.880 | Acc: 48.618,68.032,50.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.868 | Acc: 48.667,68.170,50.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.868 | Acc: 48.753,68.209,50.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.875 | Acc: 48.702,68.153,50.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.184 | Acc: 45.312,61.719,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.064 | Acc: 42.188,61.161,40.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.165 | Acc: 42.016,60.480,39.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.214 | Acc: 41.675,59.862,39.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 4.865 | Acc: 49.219,71.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.965 | Acc: 49.963,68.936,49.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.896 | Acc: 49.752,68.807,49.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.860 | Acc: 49.654,68.801,49.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.845 | Acc: 49.441,68.808,50.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.833 | Acc: 49.296,68.758,50.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.905 | Acc: 49.199,68.285,49.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.955 | Acc: 48.820,67.791,49.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.980 | Acc: 48.811,67.517,48.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.991 | Acc: 48.688,67.395,48.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.982 | Acc: 48.706,67.561,48.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.987 | Acc: 48.618,67.438,48.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.982 | Acc: 48.574,67.447,48.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.987 | Acc: 48.602,67.352,48.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.979 | Acc: 48.607,67.324,49.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.978 | Acc: 48.692,67.317,49.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.990 | Acc: 48.598,67.209,48.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.993 | Acc: 48.602,67.158,48.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.998 | Acc: 48.533,67.064,48.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.996 | Acc: 48.528,67.128,48.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.805 | Acc: 46.875,64.062,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.840 | Acc: 43.750,60.677,43.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.956 | Acc: 43.045,59.985,42.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.993 | Acc: 42.341,59.708,42.789,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 4.530 | Acc: 57.031,75.781,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.883 | Acc: 48.475,69.048,49.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.867 | Acc: 48.876,68.445,49.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.896 | Acc: 48.924,68.340,49.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.947 | Acc: 48.650,68.056,49.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.941 | Acc: 48.267,68.062,49.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.912 | Acc: 48.360,68.124,49.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.901 | Acc: 48.482,68.085,49.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.881 | Acc: 48.486,68.211,49.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.876 | Acc: 48.696,68.344,49.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.874 | Acc: 48.756,68.264,49.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.883 | Acc: 48.756,68.100,49.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.922 | Acc: 48.473,67.862,49.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.931 | Acc: 48.399,67.795,49.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.941 | Acc: 48.418,67.680,49.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.940 | Acc: 48.450,67.701,49.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.947 | Acc: 48.369,67.626,49.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.942 | Acc: 48.334,67.600,49.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.940 | Acc: 48.329,67.648,49.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.937 | Acc: 48.444,67.653,49.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.110 | Acc: 43.750,58.594,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.285 | Acc: 41.071,56.920,42.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.377 | Acc: 40.720,56.460,41.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.359 | Acc: 40.254,56.557,41.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 4.574 | Acc: 51.562,67.188,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.899 | Acc: 48.698,67.634,50.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.916 | Acc: 48.152,67.702,50.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.924 | Acc: 48.438,67.700,50.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.918 | Acc: 48.640,68.171,50.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.919 | Acc: 48.824,68.139,49.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.888 | Acc: 48.941,68.292,50.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.893 | Acc: 48.925,68.251,50.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.914 | Acc: 48.865,68.076,49.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.934 | Acc: 48.576,67.930,49.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.943 | Acc: 48.496,67.786,49.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.946 | Acc: 48.625,67.781,49.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.939 | Acc: 48.836,67.904,49.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.933 | Acc: 48.854,67.933,49.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.940 | Acc: 48.782,67.838,49.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.945 | Acc: 48.707,67.813,49.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.948 | Acc: 48.708,67.728,49.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.958 | Acc: 48.564,67.666,49.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.962 | Acc: 48.531,67.635,49.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.974 | Acc: 48.493,67.522,49.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.507 | Acc: 44.531,60.156,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.252 | Acc: 41.741,59.412,41.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.376 | Acc: 40.758,57.812,40.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.388 | Acc: 40.484,57.300,39.703,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 4.748 | Acc: 42.969,69.531,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.874 | Acc: 49.740,68.676,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.842 | Acc: 49.752,69.093,50.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.868 | Acc: 49.065,68.916,50.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.839 | Acc: 49.296,68.750,51.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.879 | Acc: 48.994,68.356,50.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.913 | Acc: 48.612,68.014,50.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.920 | Acc: 48.676,67.658,50.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.918 | Acc: 48.598,67.726,49.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.916 | Acc: 48.589,67.636,49.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.923 | Acc: 48.581,67.491,49.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.947 | Acc: 48.438,67.393,49.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.952 | Acc: 48.441,67.388,49.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.943 | Acc: 48.587,67.493,49.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.944 | Acc: 48.513,67.493,49.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.948 | Acc: 48.508,67.502,49.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.944 | Acc: 48.557,67.536,49.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.947 | Acc: 48.559,67.465,49.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.950 | Acc: 48.533,67.352,49.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.945 | Acc: 48.575,67.403,49.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.712 | Acc: 38.281,62.500,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.471 | Acc: 40.997,57.478,40.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.543 | Acc: 40.816,57.031,40.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.561 | Acc: 40.100,56.865,40.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 4.903 | Acc: 48.438,65.625,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.788 | Acc: 48.921,69.048,50.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.804 | Acc: 49.066,68.693,50.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.825 | Acc: 48.783,68.379,50.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.825 | Acc: 48.688,68.355,50.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.826 | Acc: 48.391,68.209,49.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.820 | Acc: 48.450,68.266,50.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.836 | Acc: 48.432,68.229,50.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.832 | Acc: 48.588,68.260,50.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.838 | Acc: 48.597,68.297,50.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.836 | Acc: 48.888,68.322,50.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.848 | Acc: 48.971,68.276,50.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.883 | Acc: 48.801,67.985,49.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.879 | Acc: 48.869,68.029,49.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.888 | Acc: 48.843,67.944,49.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.905 | Acc: 48.778,67.787,49.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.914 | Acc: 48.700,67.733,49.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.915 | Acc: 48.724,67.744,49.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.915 | Acc: 48.782,67.770,49.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.930 | Acc: 48.766,67.649,49.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.484 | Acc: 40.625,58.594,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.348 | Acc: 41.629,56.808,40.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.493 | Acc: 40.720,56.155,40.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.495 | Acc: 39.933,56.365,39.844,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 5.306 | Acc: 53.125,64.062,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.087 | Acc: 49.702,66.369,46.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.112 | Acc: 48.666,66.159,46.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.099 | Acc: 48.502,66.176,46.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.063 | Acc: 48.495,66.493,47.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.025 | Acc: 48.407,66.785,48.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.999 | Acc: 48.489,67.052,48.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.966 | Acc: 48.604,67.282,48.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.939 | Acc: 48.549,67.619,49.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.933 | Acc: 48.524,67.615,49.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.926 | Acc: 48.453,67.627,49.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.927 | Acc: 48.413,67.651,49.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.919 | Acc: 48.428,67.716,49.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.917 | Acc: 48.381,67.702,49.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.913 | Acc: 48.407,67.696,49.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.937 | Acc: 48.282,67.507,49.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.937 | Acc: 48.289,67.489,49.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.935 | Acc: 48.289,67.462,49.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.940 | Acc: 48.277,67.477,49.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.941 | Acc: 48.288,67.466,49.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.727 | Acc: 42.969,63.281,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.843 | Acc: 43.824,60.119,44.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.923 | Acc: 43.864,59.889,43.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.939 | Acc: 43.494,59.541,43.558,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 5.157 | Acc: 50.781,71.875,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.937 | Acc: 49.182,67.746,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.930 | Acc: 48.361,67.683,48.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.936 | Acc: 48.220,67.636,49.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.945 | Acc: 48.341,67.940,48.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.968 | Acc: 48.205,67.783,48.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.964 | Acc: 48.360,67.736,48.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.965 | Acc: 48.293,67.647,48.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.946 | Acc: 48.515,67.721,49.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.942 | Acc: 48.312,67.770,49.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.921 | Acc: 48.449,68.058,49.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.916 | Acc: 48.554,68.050,49.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.920 | Acc: 48.450,67.927,49.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.931 | Acc: 48.408,67.846,49.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.935 | Acc: 48.404,67.721,49.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.936 | Acc: 48.500,67.717,49.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.927 | Acc: 48.586,67.813,49.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.935 | Acc: 48.534,67.790,49.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.933 | Acc: 48.463,67.739,49.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.940 | Acc: 48.384,67.610,49.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.091 | Acc: 40.625,56.250,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.037 | Acc: 40.513,59.152,44.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.123 | Acc: 40.415,58.613,43.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.159 | Acc: 40.202,58.197,43.186,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 4.807 | Acc: 48.438,71.875,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.808 | Acc: 49.256,69.010,50.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.867 | Acc: 48.457,67.340,49.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.889 | Acc: 48.399,67.354,49.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.904 | Acc: 48.235,67.544,49.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.900 | Acc: 47.942,67.729,49.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.932 | Acc: 47.940,67.472,49.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.979 | Acc: 47.651,67.043,49.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.991 | Acc: 47.676,67.056,49.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.000 | Acc: 47.600,67.028,48.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.994 | Acc: 47.532,67.055,49.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.986 | Acc: 47.738,67.096,49.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.971 | Acc: 47.893,67.090,49.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.976 | Acc: 47.809,67.113,49.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.982 | Acc: 47.848,67.060,49.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.998 | Acc: 47.804,66.938,49.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.003 | Acc: 47.849,66.968,49.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.003 | Acc: 47.906,66.952,49.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.013 | Acc: 47.825,66.839,49.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.005 | Acc: 47.925,66.898,49.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.040 | Acc: 42.969,64.062,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.910 | Acc: 44.122,59.635,44.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.075 | Acc: 42.931,58.613,43.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.078 | Acc: 42.328,58.671,43.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 5.082 | Acc: 44.531,68.750,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.893 | Acc: 48.549,67.634,51.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.939 | Acc: 48.114,67.054,50.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.916 | Acc: 48.591,67.354,50.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.924 | Acc: 48.669,67.535,50.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.933 | Acc: 48.476,67.567,50.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.943 | Acc: 48.366,67.362,49.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.064 | Acc: 47.712,66.329,48.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.124 | Acc: 47.355,65.834,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.155 | Acc: 47.186,65.539,48.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.158 | Acc: 47.209,65.543,48.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.157 | Acc: 47.154,65.664,48.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.137 | Acc: 47.339,65.926,48.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.128 | Acc: 47.384,65.984,48.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.113 | Acc: 47.437,66.084,48.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.100 | Acc: 47.498,66.266,48.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.095 | Acc: 47.364,66.272,48.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.084 | Acc: 47.324,66.376,48.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.087 | Acc: 47.303,66.333,48.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.081 | Acc: 47.402,66.355,48.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.819 | Acc: 40.625,60.156,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.313 | Acc: 40.141,56.845,42.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.361 | Acc: 39.882,56.193,41.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.361 | Acc: 39.664,55.968,41.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 4.953 | Acc: 50.781,64.062,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.931 | Acc: 49.070,67.708,50.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.969 | Acc: 48.495,67.302,49.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.921 | Acc: 48.527,68.071,49.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.901 | Acc: 48.486,68.162,49.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.895 | Acc: 48.646,67.984,49.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.876 | Acc: 48.457,68.079,50.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.857 | Acc: 48.609,68.102,50.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.871 | Acc: 48.486,68.017,50.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.862 | Acc: 48.425,68.133,50.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.862 | Acc: 48.523,68.151,50.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.869 | Acc: 48.586,68.142,50.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.879 | Acc: 48.515,68.024,50.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.895 | Acc: 48.423,67.846,50.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.900 | Acc: 48.426,67.763,49.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.916 | Acc: 48.282,67.608,49.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.923 | Acc: 48.233,67.635,49.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.928 | Acc: 48.179,67.595,49.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.929 | Acc: 48.241,67.610,49.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.919 | Acc: 48.314,67.659,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.130 | Acc: 45.312,64.062,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.037 | Acc: 42.708,60.045,41.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.118 | Acc: 42.226,59.204,40.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.150 | Acc: 41.816,58.799,40.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 4.720 | Acc: 50.000,75.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.841 | Acc: 49.033,69.085,51.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.849 | Acc: 49.447,68.369,51.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.847 | Acc: 49.270,68.430,51.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.901 | Acc: 48.843,67.969,51.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.923 | Acc: 48.430,67.567,51.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.889 | Acc: 48.386,67.891,51.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.905 | Acc: 48.371,67.808,51.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.905 | Acc: 48.394,67.721,51.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.903 | Acc: 48.459,67.744,51.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.928 | Acc: 48.270,67.452,50.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.922 | Acc: 48.416,67.449,50.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.922 | Acc: 48.395,67.547,50.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.920 | Acc: 48.432,67.568,50.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.936 | Acc: 48.354,67.485,50.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.948 | Acc: 48.305,67.429,50.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.950 | Acc: 48.274,67.319,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.949 | Acc: 48.298,67.430,49.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.951 | Acc: 48.329,67.408,49.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.960 | Acc: 48.282,67.327,49.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.880 | Acc: 44.531,65.625,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.909 | Acc: 43.676,60.751,44.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.993 | Acc: 43.159,59.909,44.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.993 | Acc: 42.828,59.606,44.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 4.452 | Acc: 46.094,64.844,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.832 | Acc: 49.888,67.894,51.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.894 | Acc: 49.123,67.702,50.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.818 | Acc: 49.244,68.712,51.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.855 | Acc: 48.852,68.383,50.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.851 | Acc: 48.615,68.479,50.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.857 | Acc: 48.528,68.376,50.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.847 | Acc: 48.498,68.229,50.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.864 | Acc: 48.491,68.177,50.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.857 | Acc: 48.619,68.262,50.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.845 | Acc: 48.632,68.354,50.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.843 | Acc: 48.688,68.358,50.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.831 | Acc: 48.794,68.497,50.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.846 | Acc: 48.617,68.325,50.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.841 | Acc: 48.649,68.294,50.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.837 | Acc: 48.674,68.322,50.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.836 | Acc: 48.805,68.317,50.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.847 | Acc: 48.779,68.223,50.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.843 | Acc: 48.844,68.220,50.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.847 | Acc: 48.800,68.223,50.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.181 | Acc: 45.312,62.500,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.216 | Acc: 40.885,58.594,42.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.286 | Acc: 40.244,58.498,42.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.313 | Acc: 39.626,58.030,41.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 4.665 | Acc: 49.219,70.312,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.838 | Acc: 49.591,67.932,50.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.841 | Acc: 49.123,68.407,50.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.832 | Acc: 49.513,68.340,50.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.847 | Acc: 49.344,68.490,51.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.828 | Acc: 49.489,68.603,51.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.802 | Acc: 49.477,68.802,51.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.773 | Acc: 49.557,68.900,52.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.749 | Acc: 49.704,69.099,52.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.721 | Acc: 49.853,69.540,52.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.719 | Acc: 49.775,69.539,52.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.709 | Acc: 49.675,69.552,53.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.706 | Acc: 49.605,69.590,53.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.691 | Acc: 49.650,69.732,53.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.683 | Acc: 49.711,69.751,53.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.673 | Acc: 49.748,69.853,53.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.672 | Acc: 49.637,69.789,53.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.664 | Acc: 49.672,69.873,53.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.662 | Acc: 49.691,69.860,53.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.658 | Acc: 49.729,69.923,53.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.315 | Acc: 47.656,64.062,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.397 | Acc: 46.615,62.760,48.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.489 | Acc: 46.361,62.252,48.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.506 | Acc: 45.978,62.013,47.669,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 4.843 | Acc: 45.312,68.750,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.618 | Acc: 51.042,70.461,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 50.343,70.636,55.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.564 | Acc: 50.179,70.530,55.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.591 | Acc: 49.682,70.177,54.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.595 | Acc: 49.830,69.879,54.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.575 | Acc: 50.071,70.022,54.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.555 | Acc: 49.878,70.213,55.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.556 | Acc: 49.893,70.240,54.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.556 | Acc: 49.840,70.312,55.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.543 | Acc: 49.969,70.472,55.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.535 | Acc: 50.120,70.563,55.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.533 | Acc: 50.207,70.620,55.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.526 | Acc: 50.254,70.651,55.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.535 | Acc: 50.242,70.607,55.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.527 | Acc: 50.335,70.684,55.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.524 | Acc: 50.370,70.712,55.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.523 | Acc: 50.289,70.709,55.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.525 | Acc: 50.290,70.689,55.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.525 | Acc: 50.269,70.677,55.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.383 | Acc: 49.219,62.500,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.320 | Acc: 47.582,63.393,49.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.431 | Acc: 46.551,62.767,48.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.461 | Acc: 46.119,62.410,48.271,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 4.501 | Acc: 44.531,69.531,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.434 | Acc: 51.004,70.573,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.432 | Acc: 50.953,70.751,56.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.432 | Acc: 50.909,70.786,56.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.440 | Acc: 50.984,71.074,56.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.459 | Acc: 50.704,71.101,56.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.470 | Acc: 50.400,71.081,56.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.464 | Acc: 50.488,71.011,56.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.457 | Acc: 50.539,71.234,56.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.452 | Acc: 50.574,71.262,56.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.451 | Acc: 50.692,71.300,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.459 | Acc: 50.619,71.154,56.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.462 | Acc: 50.493,71.149,56.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.463 | Acc: 50.542,71.001,56.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.461 | Acc: 50.467,70.980,56.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.465 | Acc: 50.405,70.938,56.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.470 | Acc: 50.399,70.933,56.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.474 | Acc: 50.323,70.913,56.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.477 | Acc: 50.396,70.916,56.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.474 | Acc: 50.459,70.926,56.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.386 | Acc: 46.094,63.281,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.313 | Acc: 46.466,64.062,50.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.415 | Acc: 46.494,63.605,49.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.438 | Acc: 46.055,62.910,49.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 4.128 | Acc: 55.469,72.656,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.446 | Acc: 50.260,70.312,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.473 | Acc: 50.286,70.312,56.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.495 | Acc: 49.718,70.274,56.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.487 | Acc: 50.058,70.467,56.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.475 | Acc: 50.186,70.893,56.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.473 | Acc: 50.213,70.958,56.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.458 | Acc: 50.249,71.049,56.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.460 | Acc: 50.471,71.060,56.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.454 | Acc: 50.514,71.141,56.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.454 | Acc: 50.622,71.308,56.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.453 | Acc: 50.597,71.299,56.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.447 | Acc: 50.778,71.240,56.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.450 | Acc: 50.814,71.151,56.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.441 | Acc: 50.943,71.194,56.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.438 | Acc: 50.958,71.257,56.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.431 | Acc: 51.032,71.298,56.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.427 | Acc: 51.058,71.360,56.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.424 | Acc: 51.119,71.373,56.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.427 | Acc: 51.074,71.332,56.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.219 | Acc: 51.562,65.625,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.310 | Acc: 46.466,63.542,50.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.407 | Acc: 46.189,63.491,49.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.428 | Acc: 45.953,63.140,49.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 4.527 | Acc: 44.531,71.875,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.440 | Acc: 49.591,71.838,57.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.460 | Acc: 50.019,71.380,56.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.434 | Acc: 50.717,71.311,56.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.424 | Acc: 50.849,71.354,56.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.443 | Acc: 50.928,71.063,56.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.427 | Acc: 50.820,71.449,56.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.432 | Acc: 51.014,71.271,56.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.422 | Acc: 51.029,71.380,57.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.408 | Acc: 51.230,71.482,57.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.410 | Acc: 51.220,71.467,57.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.409 | Acc: 51.216,71.539,57.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.404 | Acc: 51.245,71.635,57.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.395 | Acc: 51.302,71.668,57.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.396 | Acc: 51.309,71.742,57.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.402 | Acc: 51.155,71.680,57.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.405 | Acc: 51.032,71.641,57.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.408 | Acc: 50.992,71.614,57.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.417 | Acc: 50.933,71.531,56.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.417 | Acc: 50.929,71.555,56.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.229 | Acc: 51.562,64.062,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.282 | Acc: 46.875,64.137,51.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.373 | Acc: 46.627,63.415,50.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.394 | Acc: 46.324,63.089,49.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 4.224 | Acc: 55.469,71.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.446 | Acc: 51.562,71.243,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.383 | Acc: 51.562,71.704,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.429 | Acc: 50.922,71.401,56.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.413 | Acc: 50.810,71.557,57.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.417 | Acc: 51.075,71.635,57.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.406 | Acc: 50.968,71.668,57.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.413 | Acc: 50.798,71.637,57.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.416 | Acc: 50.854,71.560,57.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.420 | Acc: 50.799,71.430,57.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.415 | Acc: 50.719,71.440,57.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.411 | Acc: 50.714,71.454,57.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.418 | Acc: 50.571,71.389,57.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.406 | Acc: 50.706,71.549,57.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.403 | Acc: 50.748,71.655,57.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.400 | Acc: 50.735,71.735,57.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.401 | Acc: 50.720,71.748,57.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.410 | Acc: 50.598,71.628,57.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.409 | Acc: 50.593,71.613,57.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.405 | Acc: 50.685,71.629,57.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.231 | Acc: 50.000,64.844,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.298 | Acc: 47.098,64.100,50.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.382 | Acc: 46.475,63.224,49.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.408 | Acc: 46.171,62.961,49.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 4.537 | Acc: 46.875,72.656,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.406 | Acc: 49.888,71.987,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.438 | Acc: 49.867,70.827,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.425 | Acc: 50.448,71.043,56.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.430 | Acc: 50.762,71.026,56.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.418 | Acc: 50.688,71.248,57.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.409 | Acc: 50.826,71.410,57.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.406 | Acc: 50.892,71.387,57.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.407 | Acc: 50.781,71.288,57.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.392 | Acc: 50.898,71.409,57.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.391 | Acc: 50.812,71.502,57.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.383 | Acc: 50.866,71.698,57.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.386 | Acc: 50.762,71.658,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.388 | Acc: 50.796,71.671,57.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.386 | Acc: 50.848,71.744,57.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.381 | Acc: 50.979,71.719,57.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.383 | Acc: 50.998,71.671,57.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.385 | Acc: 51.001,71.708,57.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.384 | Acc: 51.052,71.754,57.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.386 | Acc: 51.029,71.752,57.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.321 | Acc: 50.000,67.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.274 | Acc: 47.656,65.030,51.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.383 | Acc: 46.932,63.891,49.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.416 | Acc: 46.452,63.384,49.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 4.770 | Acc: 43.750,75.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.401 | Acc: 50.707,71.391,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.408 | Acc: 50.991,71.704,57.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.419 | Acc: 50.961,71.427,57.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.399 | Acc: 50.637,71.769,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.416 | Acc: 50.511,71.736,57.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.401 | Acc: 50.652,71.823,57.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.399 | Acc: 50.770,71.587,57.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.408 | Acc: 50.607,71.555,57.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.398 | Acc: 50.660,71.581,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.399 | Acc: 50.781,71.723,57.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.394 | Acc: 50.859,71.801,57.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.390 | Acc: 50.888,71.813,57.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.399 | Acc: 50.787,71.728,57.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.389 | Acc: 50.904,71.861,57.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.386 | Acc: 50.906,71.870,57.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.393 | Acc: 50.852,71.894,57.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.389 | Acc: 50.928,71.960,57.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.387 | Acc: 50.939,71.949,57.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.383 | Acc: 50.980,72.027,57.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.301 | Acc: 49.219,63.281,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.264 | Acc: 47.619,64.360,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.377 | Acc: 46.684,63.605,50.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.401 | Acc: 46.324,63.179,49.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 4.314 | Acc: 50.000,75.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.293 | Acc: 51.562,71.354,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.352 | Acc: 51.029,71.513,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 52.024,72.234,58.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.330 | Acc: 51.997,72.097,57.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.340 | Acc: 52.034,72.045,57.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.362 | Acc: 51.711,71.791,57.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.361 | Acc: 51.651,71.781,57.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.354 | Acc: 51.664,71.797,57.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.358 | Acc: 51.429,71.780,57.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.354 | Acc: 51.310,71.945,57.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.348 | Acc: 51.350,71.963,57.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.355 | Acc: 51.186,71.875,57.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.359 | Acc: 51.131,71.878,58.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.366 | Acc: 51.059,71.800,57.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.364 | Acc: 51.106,71.836,57.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.362 | Acc: 51.158,71.817,57.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.364 | Acc: 51.173,71.799,57.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.363 | Acc: 51.218,71.832,57.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.360 | Acc: 51.218,71.840,58.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.328 | Acc: 50.000,65.625,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.279 | Acc: 47.061,64.509,51.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.364 | Acc: 46.684,63.929,50.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.385 | Acc: 46.311,63.537,49.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 4.361 | Acc: 53.906,71.094,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.314 | Acc: 52.381,72.359,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 51.715,72.504,58.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.334 | Acc: 51.191,72.310,58.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.340 | Acc: 51.427,72.434,58.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.320 | Acc: 51.679,72.455,58.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.336 | Acc: 51.634,72.237,58.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.339 | Acc: 51.502,72.202,58.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.341 | Acc: 51.330,72.253,58.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.346 | Acc: 51.329,72.177,58.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.358 | Acc: 51.209,72.065,58.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.351 | Acc: 51.244,72.147,58.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.348 | Acc: 51.284,72.180,58.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.348 | Acc: 51.269,72.282,58.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.344 | Acc: 51.318,72.273,58.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.348 | Acc: 51.204,72.249,58.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.353 | Acc: 51.100,72.230,58.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.350 | Acc: 51.100,72.264,58.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.353 | Acc: 51.028,72.202,58.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.355 | Acc: 51.050,72.172,58.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.356 | Acc: 49.219,67.188,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.244 | Acc: 47.210,64.546,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.374 | Acc: 46.875,63.681,50.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.406 | Acc: 46.350,63.192,49.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 4.358 | Acc: 50.000,71.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.312 | Acc: 52.158,72.173,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.285 | Acc: 52.001,72.504,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.278 | Acc: 52.177,72.426,58.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.301 | Acc: 51.948,72.106,58.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.311 | Acc: 51.756,72.215,58.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.326 | Acc: 51.627,71.933,58.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.338 | Acc: 51.308,71.919,58.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.351 | Acc: 51.194,71.739,58.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.358 | Acc: 51.127,71.676,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.359 | Acc: 51.252,71.782,58.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.365 | Acc: 51.135,71.868,58.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.364 | Acc: 51.073,71.992,58.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.371 | Acc: 51.000,71.923,58.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.368 | Acc: 50.979,71.914,58.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.369 | Acc: 50.914,71.870,58.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.377 | Acc: 50.908,71.731,57.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.378 | Acc: 50.953,71.758,57.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.372 | Acc: 50.989,71.819,57.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.373 | Acc: 50.984,71.822,57.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.229 | Acc: 51.562,66.406,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.308 | Acc: 46.726,64.211,51.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.398 | Acc: 46.227,63.472,50.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.425 | Acc: 45.850,63.051,49.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 4.646 | Acc: 48.438,71.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.258 | Acc: 51.228,72.991,58.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.308 | Acc: 51.620,73.037,58.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.318 | Acc: 51.127,72.567,58.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.318 | Acc: 51.341,72.714,58.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.324 | Acc: 51.044,72.734,58.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.334 | Acc: 51.091,72.527,58.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.321 | Acc: 51.230,72.728,58.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.317 | Acc: 51.242,72.656,58.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.316 | Acc: 51.191,72.721,58.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.337 | Acc: 51.011,72.536,58.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.340 | Acc: 50.969,72.458,58.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.351 | Acc: 50.891,72.371,58.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.351 | Acc: 50.904,72.384,58.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.351 | Acc: 50.948,72.331,58.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.341 | Acc: 51.111,72.373,58.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.340 | Acc: 51.095,72.398,58.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.347 | Acc: 51.113,72.324,58.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.350 | Acc: 51.082,72.286,58.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.349 | Acc: 51.165,72.314,58.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.242 | Acc: 50.000,67.188,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.248 | Acc: 47.842,65.365,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.363 | Acc: 47.046,64.062,50.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.381 | Acc: 46.542,63.627,49.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 4.221 | Acc: 54.688,75.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.224 | Acc: 51.414,72.879,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.265 | Acc: 51.277,72.771,59.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.315 | Acc: 51.268,72.259,58.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.349 | Acc: 51.148,72.174,58.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.343 | Acc: 51.315,72.300,58.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.361 | Acc: 51.291,72.140,58.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.345 | Acc: 51.263,72.263,58.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.340 | Acc: 51.262,72.224,58.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.345 | Acc: 51.247,72.164,58.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.359 | Acc: 51.108,72.085,58.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.355 | Acc: 51.114,71.995,58.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.348 | Acc: 51.186,72.047,58.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.352 | Acc: 51.161,72.004,58.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.346 | Acc: 51.198,72.095,58.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.341 | Acc: 51.199,72.150,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.342 | Acc: 51.241,72.221,58.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.343 | Acc: 51.226,72.187,58.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.348 | Acc: 51.173,72.083,58.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.348 | Acc: 51.132,72.111,58.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.240 | Acc: 48.438,69.531,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.275 | Acc: 46.875,65.216,51.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.368 | Acc: 46.437,64.482,49.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.390 | Acc: 46.017,63.832,49.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 4.473 | Acc: 47.656,69.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.457 | Acc: 48.698,72.805,56.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.414 | Acc: 49.371,71.875,57.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 50.256,72.067,58.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.392 | Acc: 50.212,71.894,57.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.398 | Acc: 50.008,71.798,57.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.383 | Acc: 50.368,71.849,58.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.365 | Acc: 50.670,72.169,58.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.343 | Acc: 51.004,72.074,58.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.355 | Acc: 50.928,72.039,58.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.362 | Acc: 50.843,71.976,58.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.363 | Acc: 50.852,72.006,58.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.357 | Acc: 50.856,71.979,58.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.361 | Acc: 50.820,71.971,58.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.353 | Acc: 50.854,72.072,58.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.348 | Acc: 50.885,72.150,58.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.347 | Acc: 50.871,72.162,58.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.347 | Acc: 50.946,72.138,58.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.340 | Acc: 51.008,72.182,58.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.347 | Acc: 51.027,72.140,58.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.312 | Acc: 50.781,68.750,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.272 | Acc: 47.061,65.216,51.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.374 | Acc: 46.322,64.101,49.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.396 | Acc: 45.978,63.653,49.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 4.508 | Acc: 52.344,68.750,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.418 | Acc: 51.079,71.354,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.316 | Acc: 51.391,71.799,58.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.288 | Acc: 51.831,72.592,59.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.284 | Acc: 51.890,72.743,59.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.290 | Acc: 51.748,72.432,59.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.303 | Acc: 51.705,72.417,58.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.317 | Acc: 51.446,72.146,58.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.306 | Acc: 51.509,72.317,58.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.307 | Acc: 51.398,72.367,58.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.325 | Acc: 51.150,72.167,58.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.323 | Acc: 51.400,72.239,58.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.330 | Acc: 51.229,72.228,58.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.328 | Acc: 51.272,72.192,58.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.323 | Acc: 51.362,72.253,58.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.318 | Acc: 51.407,72.288,58.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.326 | Acc: 51.326,72.199,58.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.324 | Acc: 51.320,72.230,58.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.324 | Acc: 51.264,72.280,58.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.326 | Acc: 51.154,72.338,58.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.222 | Acc: 50.000,67.969,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.279 | Acc: 47.470,65.253,51.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.384 | Acc: 46.894,63.948,50.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.402 | Acc: 46.388,63.486,49.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 4.695 | Acc: 46.094,67.188,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.310 | Acc: 50.223,73.065,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.374 | Acc: 49.505,72.504,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.371 | Acc: 49.680,72.054,59.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 50.174,72.290,58.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.369 | Acc: 50.077,71.991,58.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.354 | Acc: 50.368,72.127,58.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.336 | Acc: 50.571,72.429,58.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.349 | Acc: 50.573,72.297,58.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.351 | Acc: 50.561,72.147,58.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.352 | Acc: 50.684,72.023,58.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.343 | Acc: 50.785,72.087,58.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.340 | Acc: 50.914,72.170,58.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.337 | Acc: 50.931,72.138,58.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.337 | Acc: 50.976,72.186,58.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.343 | Acc: 50.945,72.244,58.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.340 | Acc: 50.971,72.196,58.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.342 | Acc: 50.962,72.164,58.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.335 | Acc: 50.980,72.234,58.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.333 | Acc: 51.023,72.244,58.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.345 | Acc: 50.781,67.188,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.270 | Acc: 48.363,65.104,52.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.383 | Acc: 47.237,63.891,50.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.400 | Acc: 46.785,63.345,49.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 4.706 | Acc: 48.438,68.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.419 | Acc: 50.372,72.061,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.396 | Acc: 50.686,71.684,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.404 | Acc: 50.384,71.440,57.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.390 | Acc: 50.338,71.653,57.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.383 | Acc: 50.333,71.713,57.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.351 | Acc: 50.633,72.049,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.351 | Acc: 50.626,71.947,57.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.359 | Acc: 50.485,71.856,57.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.360 | Acc: 50.479,71.815,57.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.359 | Acc: 50.564,71.859,57.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.357 | Acc: 50.643,71.847,58.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.349 | Acc: 50.814,72.001,58.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.351 | Acc: 50.901,72.010,58.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.342 | Acc: 51.006,72.039,58.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.343 | Acc: 51.010,72.031,58.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.347 | Acc: 50.944,72.006,58.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.341 | Acc: 50.967,72.049,58.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.335 | Acc: 50.976,72.094,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.329 | Acc: 51.033,72.080,58.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.326 | Acc: 49.219,67.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.262 | Acc: 47.582,64.695,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.361 | Acc: 46.989,63.872,50.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.385 | Acc: 46.414,63.461,50.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 4.101 | Acc: 50.781,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 51.265,73.214,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.238 | Acc: 51.867,73.209,59.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.249 | Acc: 51.665,72.682,59.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.269 | Acc: 51.524,72.579,59.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.284 | Acc: 51.439,72.440,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.264 | Acc: 51.582,72.689,58.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.260 | Acc: 51.662,72.701,58.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.267 | Acc: 51.519,72.608,58.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.280 | Acc: 51.433,72.402,58.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.285 | Acc: 51.454,72.392,58.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.297 | Acc: 51.280,72.271,58.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.307 | Acc: 51.170,72.180,58.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.306 | Acc: 51.221,72.168,58.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.307 | Acc: 51.298,72.170,58.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.309 | Acc: 51.363,72.202,58.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.315 | Acc: 51.329,72.165,58.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.320 | Acc: 51.308,72.090,58.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.319 | Acc: 51.318,72.065,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.322 | Acc: 51.292,72.057,58.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.177 | Acc: 50.000,64.844,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.267 | Acc: 47.731,64.955,51.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.367 | Acc: 47.161,64.005,50.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.391 | Acc: 46.862,63.550,49.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 4.812 | Acc: 49.219,72.656,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.353 | Acc: 51.376,72.359,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.401 | Acc: 49.924,72.104,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.425 | Acc: 49.629,71.785,57.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.380 | Acc: 50.376,71.952,58.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.359 | Acc: 50.456,72.192,58.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.372 | Acc: 50.413,72.056,58.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.374 | Acc: 50.199,71.997,58.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.377 | Acc: 50.204,72.089,58.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.361 | Acc: 50.337,72.225,58.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.358 | Acc: 50.505,72.256,58.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.351 | Acc: 50.520,72.274,58.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.343 | Acc: 50.648,72.348,58.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.340 | Acc: 50.760,72.426,58.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.339 | Acc: 50.728,72.387,58.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.338 | Acc: 50.781,72.407,58.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.326 | Acc: 50.893,72.498,58.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.320 | Acc: 50.969,72.546,58.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.316 | Acc: 51.019,72.576,58.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.319 | Acc: 50.945,72.490,58.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.256 | Acc: 51.562,67.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.278 | Acc: 47.842,64.323,51.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.381 | Acc: 46.875,63.681,50.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.402 | Acc: 46.363,63.294,49.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 5.007 | Acc: 43.750,63.281,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.231 | Acc: 50.558,72.545,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.213 | Acc: 51.867,72.961,59.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.239 | Acc: 51.883,73.156,59.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.272 | Acc: 51.871,72.868,59.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.280 | Acc: 51.694,72.811,59.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.299 | Acc: 51.453,72.501,59.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.297 | Acc: 51.324,72.540,59.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.309 | Acc: 51.257,72.341,58.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.312 | Acc: 51.243,72.225,58.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.305 | Acc: 51.154,72.271,59.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.299 | Acc: 51.220,72.274,59.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.304 | Acc: 51.261,72.251,58.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.305 | Acc: 51.281,72.297,58.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.305 | Acc: 51.254,72.253,58.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.298 | Acc: 51.329,72.264,58.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.309 | Acc: 51.283,72.279,58.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.307 | Acc: 51.281,72.253,58.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.304 | Acc: 51.353,72.254,58.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.301 | Acc: 51.476,72.332,58.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.320 | Acc: 48.438,66.406,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.264 | Acc: 47.173,64.881,51.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.376 | Acc: 46.665,63.491,50.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.402 | Acc: 46.260,63.089,49.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 4.425 | Acc: 53.125,71.094,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.324 | Acc: 51.749,71.205,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 51.486,71.875,58.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 51.575,72.080,58.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.299 | Acc: 51.640,72.319,58.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.296 | Acc: 51.446,72.223,58.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.337 | Acc: 51.156,72.062,58.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.357 | Acc: 51.053,72.030,58.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.342 | Acc: 51.233,72.147,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.337 | Acc: 51.157,72.160,58.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.336 | Acc: 51.049,72.124,58.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.321 | Acc: 51.174,72.250,59.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.323 | Acc: 51.180,72.241,58.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.323 | Acc: 51.060,72.165,58.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.329 | Acc: 50.990,72.122,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.331 | Acc: 51.010,72.070,58.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.332 | Acc: 50.978,72.023,58.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.328 | Acc: 50.985,72.074,58.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.324 | Acc: 50.957,72.076,58.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.320 | Acc: 51.003,72.111,58.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.233 | Acc: 50.000,68.750,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.257 | Acc: 47.507,65.104,51.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.369 | Acc: 46.742,63.891,50.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.396 | Acc: 46.260,63.397,49.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 4.726 | Acc: 47.656,71.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.371 | Acc: 50.521,72.321,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.299 | Acc: 51.029,72.351,58.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.289 | Acc: 51.396,72.938,59.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.264 | Acc: 51.456,73.139,59.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.259 | Acc: 51.508,72.919,59.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.275 | Acc: 51.349,72.727,59.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.285 | Acc: 51.036,72.734,59.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.280 | Acc: 51.199,72.928,59.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.287 | Acc: 51.096,72.790,59.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.284 | Acc: 51.174,72.769,59.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.288 | Acc: 51.103,72.723,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.282 | Acc: 51.173,72.643,59.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.279 | Acc: 51.203,72.665,59.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.292 | Acc: 51.093,72.606,59.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.281 | Acc: 51.197,72.661,59.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.283 | Acc: 51.307,72.698,59.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.283 | Acc: 51.343,72.700,59.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.289 | Acc: 51.292,72.654,59.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.289 | Acc: 51.273,72.628,59.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.255 | Acc: 47.656,67.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.265 | Acc: 47.619,64.732,50.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.370 | Acc: 46.589,63.624,50.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.386 | Acc: 46.491,63.230,49.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 4.229 | Acc: 48.438,73.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.225 | Acc: 51.823,73.103,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.239 | Acc: 51.562,72.999,59.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.272 | Acc: 50.973,72.631,58.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.240 | Acc: 51.505,72.849,59.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.253 | Acc: 51.346,72.625,59.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.246 | Acc: 51.162,72.663,59.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.233 | Acc: 51.280,72.834,59.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.239 | Acc: 51.402,72.821,59.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.239 | Acc: 51.571,72.894,59.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.238 | Acc: 51.520,72.952,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.240 | Acc: 51.492,72.844,59.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.237 | Acc: 51.501,72.954,59.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.248 | Acc: 51.410,72.821,59.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.249 | Acc: 51.376,72.726,59.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.254 | Acc: 51.360,72.641,59.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.260 | Acc: 51.324,72.639,59.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.258 | Acc: 51.331,72.601,59.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.263 | Acc: 51.314,72.561,59.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.264 | Acc: 51.234,72.568,59.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.266 | Acc: 50.000,64.062,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.224 | Acc: 47.879,64.955,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.338 | Acc: 46.837,63.948,50.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.357 | Acc: 46.311,63.563,50.589,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 4.074 | Acc: 56.250,75.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.212 | Acc: 52.046,72.359,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.213 | Acc: 51.791,73.095,60.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.233 | Acc: 51.844,73.079,59.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.228 | Acc: 51.717,73.370,59.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.217 | Acc: 51.593,73.523,59.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.255 | Acc: 51.098,72.992,59.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.259 | Acc: 51.152,72.856,59.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.262 | Acc: 51.228,72.831,59.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.254 | Acc: 51.316,72.989,59.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.264 | Acc: 51.255,72.812,59.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.272 | Acc: 51.181,72.646,59.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.274 | Acc: 51.186,72.582,59.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.275 | Acc: 51.257,72.602,59.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.288 | Acc: 51.273,72.489,59.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.287 | Acc: 51.259,72.449,59.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.295 | Acc: 51.222,72.410,59.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.294 | Acc: 51.310,72.436,59.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.288 | Acc: 51.366,72.440,59.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.281 | Acc: 51.466,72.505,59.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.296 | Acc: 48.438,67.188,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.273 | Acc: 47.247,64.732,51.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.375 | Acc: 46.418,63.758,50.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.393 | Acc: 46.017,63.601,50.474,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 4.159 | Acc: 46.094,69.531,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.215 | Acc: 52.641,73.065,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.245 | Acc: 51.886,72.885,59.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.260 | Acc: 51.614,73.002,59.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.283 | Acc: 51.389,72.897,59.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.283 | Acc: 51.207,72.772,59.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.286 | Acc: 51.337,72.766,59.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.297 | Acc: 51.164,72.656,59.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.303 | Acc: 51.199,72.617,59.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.307 | Acc: 51.200,72.540,59.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.310 | Acc: 51.205,72.435,59.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.316 | Acc: 51.248,72.289,58.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.308 | Acc: 51.306,72.407,59.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.307 | Acc: 51.248,72.399,59.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.297 | Acc: 51.471,72.539,59.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.296 | Acc: 51.500,72.633,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.286 | Acc: 51.504,72.693,59.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.287 | Acc: 51.459,72.668,59.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.288 | Acc: 51.413,72.689,59.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.289 | Acc: 51.394,72.677,59.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.253 | Acc: 50.781,68.750,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.274 | Acc: 47.359,65.699,51.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.383 | Acc: 46.818,64.329,50.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.409 | Acc: 46.311,63.947,49.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 4.773 | Acc: 46.875,71.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 50.781,73.028,60.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.279 | Acc: 51.639,72.885,59.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.283 | Acc: 51.358,72.746,59.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.276 | Acc: 51.582,72.714,59.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.264 | Acc: 51.833,72.649,59.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.278 | Acc: 51.601,72.534,59.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.271 | Acc: 51.574,72.529,59.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.270 | Acc: 51.621,72.506,59.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.256 | Acc: 51.722,72.661,59.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.253 | Acc: 51.699,72.648,59.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.263 | Acc: 51.676,72.589,59.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.263 | Acc: 51.631,72.501,59.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.269 | Acc: 51.574,72.465,59.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.266 | Acc: 51.524,72.478,59.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.268 | Acc: 51.443,72.462,59.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.263 | Acc: 51.465,72.496,59.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.262 | Acc: 51.443,72.468,59.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.267 | Acc: 51.415,72.355,59.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.271 | Acc: 51.370,72.357,59.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.365 | Acc: 50.000,64.844,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.265 | Acc: 47.917,65.141,51.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.380 | Acc: 46.894,64.043,50.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.400 | Acc: 46.401,63.473,50.295,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 3.909 | Acc: 48.438,72.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.184 | Acc: 52.455,74.070,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.143 | Acc: 52.115,74.581,59.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.197 | Acc: 51.230,73.847,59.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.223 | Acc: 51.254,73.466,60.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.205 | Acc: 51.493,73.453,59.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.225 | Acc: 51.408,73.515,60.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.237 | Acc: 51.369,73.327,59.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.234 | Acc: 51.339,73.321,59.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.234 | Acc: 51.394,73.226,59.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.243 | Acc: 51.271,73.018,59.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.251 | Acc: 51.283,72.921,59.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.255 | Acc: 51.345,72.899,59.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.261 | Acc: 51.296,72.830,59.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.264 | Acc: 51.279,72.801,59.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.272 | Acc: 51.145,72.721,59.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.276 | Acc: 51.078,72.715,59.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.277 | Acc: 51.081,72.656,59.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.272 | Acc: 51.121,72.704,59.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.272 | Acc: 51.134,72.701,59.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.287 | Acc: 50.781,64.062,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.257 | Acc: 47.470,64.918,51.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.368 | Acc: 46.646,64.082,50.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.386 | Acc: 46.158,63.730,50.333,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 4.655 | Acc: 50.781,74.219,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.333 | Acc: 51.079,72.656,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.311 | Acc: 51.582,72.771,59.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.316 | Acc: 50.858,72.477,59.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.295 | Acc: 51.100,72.541,59.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.276 | Acc: 51.300,72.471,59.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.273 | Acc: 51.433,72.366,59.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.261 | Acc: 51.651,72.606,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.272 | Acc: 51.703,72.535,59.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.266 | Acc: 51.614,72.639,59.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.260 | Acc: 51.691,72.676,59.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.266 | Acc: 51.524,72.642,59.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.266 | Acc: 51.634,72.556,59.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.270 | Acc: 51.616,72.590,59.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.275 | Acc: 51.576,72.576,59.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.270 | Acc: 51.550,72.565,59.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.281 | Acc: 51.416,72.469,59.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.281 | Acc: 51.400,72.468,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.276 | Acc: 51.467,72.500,59.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.280 | Acc: 51.386,72.484,59.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.150 | Acc: 48.438,68.750,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.256 | Acc: 47.619,64.546,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.359 | Acc: 46.589,63.472,51.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.378 | Acc: 46.119,63.473,50.845,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 4.417 | Acc: 44.531,75.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.253 | Acc: 49.405,72.619,60.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.280 | Acc: 49.600,72.485,59.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.277 | Acc: 50.487,72.579,59.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.295 | Acc: 50.058,72.328,59.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.307 | Acc: 50.271,72.339,59.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.276 | Acc: 50.613,72.553,59.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.274 | Acc: 50.643,72.568,59.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.284 | Acc: 50.539,72.516,59.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.282 | Acc: 50.591,72.471,59.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.275 | Acc: 50.657,72.610,59.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.261 | Acc: 50.901,72.702,59.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.261 | Acc: 50.869,72.783,59.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.260 | Acc: 50.853,72.896,59.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.263 | Acc: 50.817,72.784,59.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.274 | Acc: 50.724,72.690,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.272 | Acc: 50.767,72.683,59.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.265 | Acc: 50.820,72.750,59.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.269 | Acc: 50.842,72.695,59.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.263 | Acc: 50.890,72.800,59.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.176 | Acc: 49.219,65.625,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.262 | Acc: 47.284,64.658,52.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.377 | Acc: 46.723,63.815,50.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.395 | Acc: 46.363,63.614,50.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 4.792 | Acc: 48.438,67.969,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.339 | Acc: 50.409,70.871,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.279 | Acc: 51.601,71.875,59.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.255 | Acc: 52.664,72.477,59.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.240 | Acc: 52.324,72.618,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.272 | Acc: 51.996,72.239,59.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.251 | Acc: 51.885,72.534,60.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.251 | Acc: 51.884,72.490,59.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.263 | Acc: 51.844,72.448,59.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.263 | Acc: 51.692,72.566,59.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.272 | Acc: 51.675,72.555,59.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.273 | Acc: 51.729,72.600,59.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.262 | Acc: 51.582,72.754,59.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.259 | Acc: 51.551,72.737,59.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.261 | Acc: 51.588,72.726,59.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.259 | Acc: 51.562,72.752,59.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.259 | Acc: 51.623,72.744,59.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.260 | Acc: 51.615,72.723,59.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.264 | Acc: 51.521,72.687,59.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.266 | Acc: 51.464,72.703,59.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.284 | Acc: 47.656,66.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.237 | Acc: 47.842,65.253,52.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.328 | Acc: 47.123,64.043,50.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.356 | Acc: 46.632,63.819,50.461,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 4.617 | Acc: 45.312,64.062,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 51.004,70.908,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.220 | Acc: 51.582,72.161,59.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.272 | Acc: 50.845,71.952,59.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.291 | Acc: 50.714,71.952,58.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.299 | Acc: 50.789,72.169,58.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.281 | Acc: 51.085,72.282,58.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.281 | Acc: 51.108,72.213,58.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.274 | Acc: 51.058,72.423,59.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.272 | Acc: 51.019,72.557,59.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.267 | Acc: 51.084,72.687,59.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.268 | Acc: 51.036,72.730,59.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.266 | Acc: 50.950,72.783,59.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.261 | Acc: 50.967,72.848,59.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.265 | Acc: 50.987,72.773,59.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.262 | Acc: 51.168,72.750,59.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.252 | Acc: 51.217,72.817,59.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.256 | Acc: 51.150,72.817,59.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.258 | Acc: 51.153,72.838,59.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.263 | Acc: 51.107,72.740,59.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.216 | Acc: 48.438,64.844,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.233 | Acc: 47.321,65.290,52.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.350 | Acc: 46.494,64.062,50.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.367 | Acc: 46.235,63.678,50.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 3.811 | Acc: 45.312,81.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.186 | Acc: 50.484,73.103,61.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.198 | Acc: 51.239,72.828,60.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.203 | Acc: 51.242,73.117,60.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.231 | Acc: 51.157,72.772,59.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.222 | Acc: 51.423,73.004,59.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.225 | Acc: 51.356,72.927,59.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.235 | Acc: 51.225,72.950,59.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.241 | Acc: 51.208,72.918,59.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.232 | Acc: 51.347,72.950,60.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.238 | Acc: 51.442,72.858,60.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.246 | Acc: 51.453,72.854,59.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.250 | Acc: 51.433,72.822,59.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.260 | Acc: 51.407,72.719,59.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.261 | Acc: 51.460,72.712,59.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.259 | Acc: 51.389,72.739,59.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.267 | Acc: 51.334,72.647,59.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.265 | Acc: 51.217,72.629,59.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.269 | Acc: 51.216,72.628,59.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.270 | Acc: 51.167,72.646,59.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.155 | Acc: 48.438,67.188,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.259 | Acc: 47.768,65.327,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.369 | Acc: 46.589,64.043,50.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.387 | Acc: 46.209,63.576,50.435,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 4.183 | Acc: 56.250,75.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.229 | Acc: 50.670,73.028,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.237 | Acc: 51.791,73.152,59.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.237 | Acc: 51.985,72.912,59.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.258 | Acc: 51.919,73.052,59.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.261 | Acc: 51.856,72.981,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.268 | Acc: 52.002,72.986,59.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.275 | Acc: 51.884,72.939,59.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.261 | Acc: 51.951,73.006,59.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.280 | Acc: 51.584,72.768,59.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.275 | Acc: 51.621,72.765,59.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.278 | Acc: 51.654,72.734,59.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.282 | Acc: 51.527,72.698,59.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.285 | Acc: 51.485,72.707,59.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.282 | Acc: 51.474,72.717,59.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.284 | Acc: 51.365,72.719,59.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.281 | Acc: 51.353,72.664,59.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.285 | Acc: 51.244,72.626,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.284 | Acc: 51.279,72.615,59.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.278 | Acc: 51.351,72.667,59.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.200 | Acc: 52.344,67.969,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.285 | Acc: 47.619,64.360,50.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.389 | Acc: 46.665,63.624,49.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.402 | Acc: 46.311,63.294,49.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 4.347 | Acc: 52.344,72.656,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.122 | Acc: 51.897,73.400,61.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.185 | Acc: 51.696,73.209,61.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.211 | Acc: 51.460,73.181,60.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.237 | Acc: 51.264,73.100,60.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.241 | Acc: 50.998,72.950,60.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.251 | Acc: 51.007,72.695,60.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.257 | Acc: 51.075,72.662,59.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.270 | Acc: 50.912,72.506,60.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.267 | Acc: 50.941,72.557,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.280 | Acc: 50.886,72.532,60.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.265 | Acc: 51.064,72.706,60.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.261 | Acc: 51.128,72.802,60.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.261 | Acc: 51.119,72.815,60.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.257 | Acc: 51.126,72.787,60.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.257 | Acc: 51.220,72.763,60.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.255 | Acc: 51.273,72.790,60.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.257 | Acc: 51.251,72.856,60.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.255 | Acc: 51.268,72.808,60.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.253 | Acc: 51.316,72.800,60.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.237 | Acc: 48.438,66.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.264 | Acc: 47.954,65.290,52.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.370 | Acc: 47.008,64.120,51.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.392 | Acc: 46.580,63.691,50.884,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 4.552 | Acc: 57.031,67.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.198 | Acc: 52.939,72.210,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.218 | Acc: 52.306,72.142,60.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.285 | Acc: 51.409,71.709,60.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.247 | Acc: 51.466,72.242,60.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.243 | Acc: 51.454,72.254,60.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.254 | Acc: 51.214,72.249,60.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.263 | Acc: 51.313,72.158,60.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.261 | Acc: 51.300,72.360,60.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.271 | Acc: 51.165,72.354,59.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.267 | Acc: 51.182,72.365,59.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.264 | Acc: 51.227,72.384,59.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.268 | Acc: 51.186,72.309,59.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.264 | Acc: 51.152,72.372,59.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.250 | Acc: 51.348,72.590,59.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.252 | Acc: 51.308,72.511,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.254 | Acc: 51.249,72.591,59.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.255 | Acc: 51.148,72.629,59.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.258 | Acc: 51.138,72.687,59.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.261 | Acc: 51.136,72.699,59.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.281 | Acc: 46.875,66.406,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.240 | Acc: 47.098,65.104,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.351 | Acc: 46.341,64.139,50.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.376 | Acc: 46.132,63.550,50.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 4.604 | Acc: 48.438,68.750,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.182 | Acc: 51.042,73.326,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.158 | Acc: 51.353,73.590,60.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.142 | Acc: 51.434,73.361,61.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.174 | Acc: 51.350,72.743,60.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.178 | Acc: 51.416,72.981,60.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.197 | Acc: 51.504,72.772,60.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.219 | Acc: 51.274,72.640,60.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.220 | Acc: 51.310,72.705,60.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.213 | Acc: 51.407,72.747,60.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.218 | Acc: 51.407,72.738,60.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.215 | Acc: 51.396,72.709,60.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.224 | Acc: 51.371,72.585,60.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.233 | Acc: 51.392,72.551,60.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.234 | Acc: 51.376,72.648,60.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.236 | Acc: 51.363,72.716,60.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.245 | Acc: 51.351,72.676,60.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.246 | Acc: 51.407,72.659,60.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.250 | Acc: 51.383,72.645,60.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.247 | Acc: 51.388,72.699,60.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.256 | Acc: 48.438,65.625,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.233 | Acc: 47.768,65.104,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.357 | Acc: 46.646,63.929,51.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.388 | Acc: 46.119,63.653,50.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 4.602 | Acc: 48.438,65.625,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.286 | Acc: 52.158,71.912,59.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.280 | Acc: 52.572,71.780,59.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.219 | Acc: 52.395,72.567,60.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.224 | Acc: 52.180,72.830,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.222 | Acc: 52.266,72.795,59.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.219 | Acc: 52.234,72.837,60.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.213 | Acc: 52.150,72.906,60.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.231 | Acc: 52.096,72.695,59.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.236 | Acc: 52.007,72.751,59.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.228 | Acc: 52.044,72.746,59.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.224 | Acc: 51.923,72.681,59.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.239 | Acc: 51.682,72.585,59.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.237 | Acc: 51.769,72.671,60.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.244 | Acc: 51.626,72.612,59.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.244 | Acc: 51.570,72.651,59.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.237 | Acc: 51.550,72.724,59.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.231 | Acc: 51.576,72.823,59.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.236 | Acc: 51.604,72.764,59.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.240 | Acc: 51.501,72.714,59.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.131 | Acc: 50.000,66.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.265 | Acc: 47.917,65.104,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.368 | Acc: 46.894,63.815,50.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.402 | Acc: 46.235,63.371,50.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 4.074 | Acc: 54.688,74.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.260 | Acc: 51.414,72.954,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.282 | Acc: 50.743,72.980,59.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.278 | Acc: 51.165,72.964,59.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.254 | Acc: 51.447,73.071,59.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.261 | Acc: 51.702,72.803,59.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.280 | Acc: 51.575,72.553,59.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.282 | Acc: 51.424,72.706,59.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.275 | Acc: 51.417,72.758,59.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.260 | Acc: 51.619,72.842,59.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.262 | Acc: 51.531,72.707,59.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.275 | Acc: 51.428,72.586,59.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.274 | Acc: 51.362,72.608,59.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.271 | Acc: 51.251,72.695,59.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.263 | Acc: 51.315,72.765,59.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.257 | Acc: 51.368,72.851,59.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.252 | Acc: 51.346,72.844,59.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.250 | Acc: 51.345,72.817,59.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.252 | Acc: 51.346,72.747,59.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.251 | Acc: 51.290,72.757,59.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.178 | Acc: 48.438,65.625,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.226 | Acc: 47.731,64.844,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.346 | Acc: 46.932,63.948,51.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.374 | Acc: 46.350,63.537,50.333,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 4.149 | Acc: 54.688,75.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.253 | Acc: 52.158,72.061,60.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.218 | Acc: 51.601,72.980,59.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.253 | Acc: 50.935,72.772,59.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.240 | Acc: 51.080,72.656,59.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.231 | Acc: 51.261,72.896,60.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.219 | Acc: 51.511,72.934,60.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.229 | Acc: 51.579,72.900,60.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.210 | Acc: 51.689,73.166,60.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.214 | Acc: 51.657,73.161,60.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.214 | Acc: 51.769,73.111,60.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.219 | Acc: 51.612,73.035,60.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.219 | Acc: 51.666,72.977,60.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.216 | Acc: 51.655,72.902,60.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.219 | Acc: 51.540,72.834,60.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.211 | Acc: 51.596,72.924,60.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.220 | Acc: 51.572,72.831,60.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.216 | Acc: 51.659,72.901,60.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.215 | Acc: 51.625,72.940,60.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.213 | Acc: 51.649,72.960,60.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.177 | Acc: 47.656,64.844,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.230 | Acc: 47.656,65.030,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.346 | Acc: 46.780,64.310,51.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.369 | Acc: 46.286,63.870,50.589,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 4.073 | Acc: 54.688,75.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.236 | Acc: 50.856,74.293,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.233 | Acc: 51.124,73.742,59.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.252 | Acc: 51.358,73.258,59.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.216 | Acc: 51.572,73.601,59.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.211 | Acc: 51.547,73.337,60.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.206 | Acc: 51.659,73.405,60.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.208 | Acc: 51.474,73.316,60.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.204 | Acc: 51.635,73.224,60.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.203 | Acc: 51.580,73.248,60.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.206 | Acc: 51.656,73.255,60.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.215 | Acc: 51.467,73.204,60.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.218 | Acc: 51.355,73.052,60.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.220 | Acc: 51.221,73.033,60.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.211 | Acc: 51.351,73.123,60.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.217 | Acc: 51.381,73.110,60.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.217 | Acc: 51.412,73.082,60.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.218 | Acc: 51.333,73.055,60.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.215 | Acc: 51.260,73.052,60.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.214 | Acc: 51.181,73.099,60.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.208 | Acc: 48.438,65.625,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.210 | Acc: 47.805,64.844,51.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.330 | Acc: 46.875,63.967,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.353 | Acc: 46.440,63.473,50.320,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 4.037 | Acc: 53.125,75.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 50.484,72.842,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.281 | Acc: 50.819,72.713,59.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.275 | Acc: 51.255,72.528,60.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.282 | Acc: 51.100,72.492,59.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.260 | Acc: 51.330,72.679,60.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.237 | Acc: 51.569,73.031,60.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.228 | Acc: 51.618,73.000,60.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.211 | Acc: 51.888,73.108,60.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.207 | Acc: 51.878,73.027,60.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.202 | Acc: 51.877,73.127,60.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.200 | Acc: 51.905,73.162,60.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.203 | Acc: 51.799,73.149,60.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.206 | Acc: 51.673,73.171,60.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.201 | Acc: 51.857,73.207,60.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.202 | Acc: 51.786,73.248,60.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.199 | Acc: 51.750,73.260,60.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.200 | Acc: 51.801,73.259,60.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.206 | Acc: 51.686,73.232,60.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.208 | Acc: 51.712,73.165,60.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.130 | Acc: 50.781,67.188,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.212 | Acc: 48.140,65.216,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.332 | Acc: 47.313,64.062,51.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.353 | Acc: 46.760,63.614,51.114,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 3.834 | Acc: 57.031,82.031,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.196 | Acc: 52.344,73.140,59.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.152 | Acc: 52.210,73.933,60.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.185 | Acc: 51.819,73.361,60.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.184 | Acc: 51.939,73.264,60.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.188 | Acc: 51.764,73.113,60.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.199 | Acc: 51.717,73.134,60.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.178 | Acc: 51.934,73.454,60.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.185 | Acc: 51.985,73.355,60.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.190 | Acc: 52.007,73.273,60.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.195 | Acc: 52.056,73.243,60.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.200 | Acc: 51.891,73.257,60.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.209 | Acc: 51.796,73.204,60.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.199 | Acc: 51.706,73.315,60.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.204 | Acc: 51.629,73.240,60.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.204 | Acc: 51.565,73.136,60.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.195 | Acc: 51.621,73.253,60.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.198 | Acc: 51.599,73.250,60.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.200 | Acc: 51.526,73.247,60.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.204 | Acc: 51.380,73.093,60.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.167 | Acc: 46.875,64.844,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.222 | Acc: 47.991,64.732,52.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.348 | Acc: 47.027,63.700,51.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.367 | Acc: 46.465,63.461,50.768,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 3.762 | Acc: 55.469,79.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.125 | Acc: 51.786,74.368,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.136 | Acc: 51.315,73.742,61.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.147 | Acc: 51.358,73.553,61.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.158 | Acc: 51.871,73.515,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.164 | Acc: 51.787,73.631,61.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.174 | Acc: 51.685,73.373,61.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.176 | Acc: 51.840,73.465,61.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.187 | Acc: 51.776,73.258,60.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.181 | Acc: 51.752,73.217,60.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.177 | Acc: 51.714,73.251,60.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.174 | Acc: 51.587,73.222,60.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.172 | Acc: 51.559,73.143,60.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.182 | Acc: 51.506,73.117,60.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.190 | Acc: 51.468,73.065,60.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.190 | Acc: 51.524,73.001,60.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.190 | Acc: 51.543,73.048,60.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.191 | Acc: 51.512,73.112,60.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.194 | Acc: 51.454,73.117,60.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.192 | Acc: 51.517,73.140,60.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.179 | Acc: 50.000,66.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.210 | Acc: 47.805,65.216,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.331 | Acc: 47.046,64.120,51.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.352 | Acc: 46.440,63.781,50.730,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 4.271 | Acc: 49.219,70.312,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.235 | Acc: 51.414,72.247,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.229 | Acc: 51.372,72.904,59.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.230 | Acc: 51.114,72.836,59.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.203 | Acc: 51.360,73.071,59.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.191 | Acc: 51.748,73.082,60.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.193 | Acc: 51.763,72.992,60.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.191 | Acc: 51.740,73.116,60.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.200 | Acc: 51.723,72.928,60.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.200 | Acc: 51.610,72.898,60.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.201 | Acc: 51.524,72.816,60.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.205 | Acc: 51.517,72.851,60.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.213 | Acc: 51.426,72.860,60.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.210 | Acc: 51.527,72.887,60.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.212 | Acc: 51.487,72.909,60.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.214 | Acc: 51.479,72.939,60.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.216 | Acc: 51.409,72.866,60.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.203 | Acc: 51.546,73.011,60.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.211 | Acc: 51.491,72.985,60.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.212 | Acc: 51.511,73.034,60.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.188 | Acc: 48.438,66.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.204 | Acc: 47.545,65.290,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.315 | Acc: 46.761,64.253,51.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.339 | Acc: 46.350,63.960,50.871,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 4.102 | Acc: 50.000,78.125,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.205 | Acc: 51.339,73.028,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.119 | Acc: 51.639,74.028,61.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.110 | Acc: 51.960,74.219,61.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.134 | Acc: 51.659,73.929,61.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.163 | Acc: 51.601,73.476,61.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.175 | Acc: 51.543,73.386,60.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.173 | Acc: 51.590,73.515,60.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.175 | Acc: 51.509,73.462,60.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.191 | Acc: 51.269,73.338,60.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.186 | Acc: 51.228,73.399,60.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.182 | Acc: 51.244,73.438,60.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.176 | Acc: 51.274,73.486,60.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.173 | Acc: 51.377,73.596,60.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.181 | Acc: 51.415,73.535,61.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.184 | Acc: 51.482,73.479,60.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.191 | Acc: 51.356,73.403,60.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.198 | Acc: 51.274,73.330,60.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.192 | Acc: 51.309,73.427,60.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.194 | Acc: 51.306,73.415,60.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.206 | Acc: 49.219,66.406,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.214 | Acc: 47.954,65.216,52.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.323 | Acc: 47.008,64.101,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.347 | Acc: 46.478,63.794,50.730,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 3.996 | Acc: 53.125,74.219,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.115 | Acc: 52.046,74.516,61.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.180 | Acc: 51.658,74.009,60.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.117 | Acc: 52.523,74.424,61.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.142 | Acc: 52.334,73.814,60.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.162 | Acc: 51.965,73.584,60.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.155 | Acc: 51.963,73.386,60.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.165 | Acc: 51.867,73.299,60.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.164 | Acc: 51.815,73.311,60.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.169 | Acc: 51.683,73.386,60.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.165 | Acc: 51.765,73.484,61.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.167 | Acc: 51.753,73.434,61.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.171 | Acc: 51.770,73.343,60.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.163 | Acc: 51.709,73.375,60.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.165 | Acc: 51.560,73.285,60.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.169 | Acc: 51.609,73.225,60.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.175 | Acc: 51.597,73.187,60.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.177 | Acc: 51.574,73.190,60.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.178 | Acc: 51.556,73.202,60.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.180 | Acc: 51.452,73.140,60.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.209 | Acc: 49.219,66.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.211 | Acc: 48.363,65.253,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.322 | Acc: 47.142,64.158,50.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.342 | Acc: 46.478,63.794,50.640,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 4.281 | Acc: 45.312,74.219,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.100 | Acc: 52.083,74.144,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.109 | Acc: 51.867,74.066,61.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.140 | Acc: 51.870,74.193,61.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.111 | Acc: 52.238,74.267,61.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.144 | Acc: 52.282,74.002,60.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.141 | Acc: 52.079,73.870,61.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.170 | Acc: 51.784,73.582,60.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.162 | Acc: 51.829,73.641,60.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.184 | Acc: 51.675,73.433,60.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.188 | Acc: 51.632,73.255,60.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.180 | Acc: 51.732,73.275,60.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.178 | Acc: 51.806,73.279,60.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.185 | Acc: 51.796,73.210,60.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.174 | Acc: 51.868,73.362,60.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.173 | Acc: 51.954,73.256,60.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.180 | Acc: 51.918,73.160,60.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.176 | Acc: 51.844,73.252,60.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.186 | Acc: 51.686,73.158,60.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.191 | Acc: 51.704,73.097,60.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.170 | Acc: 49.219,66.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.223 | Acc: 48.177,65.253,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.327 | Acc: 47.142,64.348,50.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.351 | Acc: 46.478,63.870,50.551,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 4.908 | Acc: 51.562,71.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.238 | Acc: 51.414,72.433,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.208 | Acc: 51.582,72.485,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.193 | Acc: 51.422,72.567,61.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.195 | Acc: 51.254,72.724,60.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.177 | Acc: 51.624,72.803,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.195 | Acc: 51.504,72.837,60.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.191 | Acc: 51.479,72.989,60.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.180 | Acc: 51.553,73.151,60.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.189 | Acc: 51.459,73.230,60.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.188 | Acc: 51.419,73.231,60.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.183 | Acc: 51.418,73.204,60.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.181 | Acc: 51.326,73.149,60.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.186 | Acc: 51.371,73.168,60.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.186 | Acc: 51.290,73.173,60.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.185 | Acc: 51.391,73.225,60.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.180 | Acc: 51.536,73.333,60.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.177 | Acc: 51.528,73.277,60.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.176 | Acc: 51.567,73.308,60.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.177 | Acc: 51.556,73.355,60.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.179 | Acc: 48.438,66.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.217 | Acc: 48.251,65.030,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.322 | Acc: 47.199,64.120,51.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.346 | Acc: 46.632,63.755,50.897,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 4.904 | Acc: 45.312,70.312,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.201 | Acc: 52.381,74.107,60.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.158 | Acc: 51.772,74.486,61.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.157 | Acc: 51.819,74.308,61.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.178 | Acc: 51.669,73.843,60.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.173 | Acc: 51.717,73.623,60.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.169 | Acc: 51.956,73.670,60.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.181 | Acc: 51.889,73.659,60.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.168 | Acc: 52.038,73.729,60.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.170 | Acc: 51.886,73.619,60.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.170 | Acc: 51.831,73.612,60.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.170 | Acc: 51.736,73.604,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.172 | Acc: 51.741,73.567,60.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.178 | Acc: 51.733,73.512,60.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.189 | Acc: 51.679,73.438,60.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.183 | Acc: 51.659,73.479,60.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.187 | Acc: 51.657,73.484,60.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.186 | Acc: 51.739,73.506,60.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.195 | Acc: 51.640,73.403,60.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.191 | Acc: 51.694,73.409,60.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.172 | Acc: 48.438,65.625,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.207 | Acc: 48.065,65.290,52.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.318 | Acc: 47.237,64.253,51.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.342 | Acc: 46.683,63.947,50.858,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 4.179 | Acc: 53.125,72.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.139 | Acc: 52.046,73.177,60.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.157 | Acc: 52.134,72.790,60.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.145 | Acc: 52.357,73.258,61.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.149 | Acc: 51.890,73.380,61.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.159 | Acc: 51.663,73.283,61.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.171 | Acc: 51.556,73.270,61.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.179 | Acc: 51.513,73.183,61.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.170 | Acc: 51.592,73.248,61.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.179 | Acc: 51.459,73.170,61.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.172 | Acc: 51.702,73.290,61.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.168 | Acc: 51.743,73.349,61.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.168 | Acc: 51.825,73.288,61.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.172 | Acc: 51.745,73.249,61.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.173 | Acc: 51.818,73.282,61.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.177 | Acc: 51.817,73.321,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.176 | Acc: 51.879,73.369,61.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.177 | Acc: 51.883,73.334,61.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.179 | Acc: 51.788,73.340,61.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.178 | Acc: 51.825,73.314,60.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.198 | Acc: 48.438,67.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.204 | Acc: 48.065,64.918,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.319 | Acc: 47.180,63.891,51.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.340 | Acc: 46.657,63.730,50.717,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 4.537 | Acc: 45.312,66.406,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.157 | Acc: 51.414,74.479,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.167 | Acc: 51.601,73.800,61.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.170 | Acc: 51.511,73.745,61.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.180 | Acc: 51.485,73.717,61.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.168 | Acc: 51.663,73.871,61.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.168 | Acc: 51.827,73.612,61.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.171 | Acc: 51.668,73.504,61.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.155 | Acc: 51.562,73.661,61.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.165 | Acc: 51.506,73.545,61.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.158 | Acc: 51.531,73.562,61.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.165 | Acc: 51.464,73.505,61.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.161 | Acc: 51.494,73.483,61.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.156 | Acc: 51.500,73.497,61.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.158 | Acc: 51.476,73.460,61.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.151 | Acc: 51.591,73.513,61.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.167 | Acc: 51.487,73.457,61.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.169 | Acc: 51.533,73.360,61.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.169 | Acc: 51.515,73.349,61.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.172 | Acc: 51.468,73.345,61.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.183 | Acc: 49.219,67.188,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.208 | Acc: 48.103,65.476,52.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.325 | Acc: 47.142,64.139,51.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.343 | Acc: 46.773,63.742,50.832,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 4.001 | Acc: 55.469,77.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.106 | Acc: 51.116,74.033,62.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.148 | Acc: 51.905,73.495,61.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.155 | Acc: 52.485,73.655,61.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.141 | Acc: 52.575,73.833,61.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.154 | Acc: 52.297,73.716,61.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.173 | Acc: 52.176,73.657,61.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.173 | Acc: 52.089,73.742,61.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.169 | Acc: 52.193,73.695,61.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.168 | Acc: 52.158,73.614,60.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.172 | Acc: 51.994,73.542,61.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.185 | Acc: 51.863,73.420,61.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.191 | Acc: 51.789,73.408,61.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.188 | Acc: 51.787,73.420,60.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.182 | Acc: 51.799,73.390,61.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.176 | Acc: 51.827,73.450,61.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.171 | Acc: 51.825,73.484,61.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.171 | Acc: 51.821,73.522,61.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.169 | Acc: 51.846,73.548,61.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.168 | Acc: 51.870,73.515,61.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.236 | Acc: 46.875,65.625,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.192 | Acc: 47.954,65.067,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.314 | Acc: 46.856,63.872,51.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.338 | Acc: 46.299,63.627,50.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 3.886 | Acc: 57.812,77.344,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.202 | Acc: 51.414,72.321,60.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.213 | Acc: 51.143,72.542,60.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.193 | Acc: 51.306,72.759,60.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.176 | Acc: 51.505,73.110,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.148 | Acc: 51.818,73.144,61.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.142 | Acc: 52.157,73.341,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.151 | Acc: 52.117,73.210,61.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.156 | Acc: 52.121,73.258,61.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.157 | Acc: 52.098,73.321,61.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.154 | Acc: 51.990,73.239,61.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.151 | Acc: 51.948,73.353,61.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.148 | Acc: 51.877,73.292,61.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.149 | Acc: 51.904,73.243,61.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.159 | Acc: 51.813,73.137,61.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.159 | Acc: 51.843,73.157,61.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.155 | Acc: 51.893,73.279,61.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.163 | Acc: 51.743,73.199,60.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.167 | Acc: 51.699,73.189,60.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.169 | Acc: 51.624,73.183,60.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.197 | Acc: 50.000,66.406,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.196 | Acc: 47.768,65.476,52.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.308 | Acc: 46.799,64.253,51.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.326 | Acc: 46.504,63.934,50.897,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 3.993 | Acc: 52.344,74.219,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.196 | Acc: 51.228,73.214,61.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.181 | Acc: 51.505,72.999,60.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.201 | Acc: 51.178,72.810,60.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.163 | Acc: 51.688,73.476,60.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.152 | Acc: 52.003,73.476,60.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.162 | Acc: 51.827,73.534,60.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.142 | Acc: 51.945,73.803,60.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.154 | Acc: 51.737,73.505,60.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.171 | Acc: 51.498,73.299,60.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.177 | Acc: 51.450,73.309,60.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.177 | Acc: 51.304,73.310,60.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.178 | Acc: 51.423,73.340,60.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.181 | Acc: 51.341,73.282,60.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.184 | Acc: 51.223,73.265,60.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.181 | Acc: 51.376,73.295,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.181 | Acc: 51.351,73.313,60.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.182 | Acc: 51.343,73.307,60.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.179 | Acc: 51.418,73.353,60.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.177 | Acc: 51.339,73.323,60.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.229 | Acc: 46.875,65.625,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.215 | Acc: 47.917,65.179,52.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.332 | Acc: 46.837,64.120,51.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.352 | Acc: 46.580,63.870,51.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 3.982 | Acc: 50.781,71.875,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.201 | Acc: 50.670,72.768,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.191 | Acc: 51.582,72.923,61.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.172 | Acc: 51.524,73.130,61.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.157 | Acc: 51.418,73.669,61.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.162 | Acc: 51.129,73.577,61.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.160 | Acc: 51.072,73.638,61.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.157 | Acc: 51.346,73.770,61.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.158 | Acc: 51.281,73.700,61.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.171 | Acc: 51.165,73.554,61.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.167 | Acc: 51.158,73.566,61.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.183 | Acc: 51.029,73.328,61.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.179 | Acc: 51.196,73.441,61.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.175 | Acc: 51.269,73.470,61.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.178 | Acc: 51.298,73.382,61.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.172 | Acc: 51.425,73.461,61.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.173 | Acc: 51.507,73.459,61.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.174 | Acc: 51.508,73.470,61.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.166 | Acc: 51.604,73.498,61.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.160 | Acc: 51.677,73.554,61.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.228 | Acc: 48.438,66.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.209 | Acc: 47.768,65.216,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.323 | Acc: 46.761,63.891,51.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.342 | Acc: 46.363,63.742,50.845,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 4.446 | Acc: 53.125,70.312,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.143 | Acc: 52.641,73.400,61.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.193 | Acc: 51.562,73.190,61.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.205 | Acc: 51.178,72.656,60.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.163 | Acc: 51.707,73.216,61.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.168 | Acc: 52.027,73.128,60.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.164 | Acc: 52.260,73.153,60.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.163 | Acc: 52.233,73.244,60.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.159 | Acc: 52.014,73.205,61.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.159 | Acc: 51.968,73.200,61.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.158 | Acc: 52.142,73.247,61.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.153 | Acc: 52.033,73.328,61.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.164 | Acc: 51.851,73.217,61.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.165 | Acc: 51.904,73.246,61.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.169 | Acc: 51.888,73.218,61.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.174 | Acc: 51.892,73.142,61.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.171 | Acc: 51.898,73.153,61.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.171 | Acc: 51.897,73.169,61.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.169 | Acc: 51.863,73.184,61.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.169 | Acc: 51.854,73.200,60.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.250 | Acc: 48.438,67.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.217 | Acc: 47.619,65.067,52.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.332 | Acc: 46.665,63.758,51.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.342 | Acc: 46.440,63.563,51.114,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 4.502 | Acc: 50.781,73.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.129 | Acc: 51.972,73.996,60.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.160 | Acc: 51.372,73.457,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.184 | Acc: 51.217,73.271,61.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.146 | Acc: 52.054,73.534,61.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.171 | Acc: 51.748,73.267,60.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.180 | Acc: 51.679,73.341,60.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.187 | Acc: 51.490,73.127,60.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.178 | Acc: 51.626,73.185,60.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.164 | Acc: 51.683,73.394,61.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.179 | Acc: 51.555,73.231,61.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.184 | Acc: 51.435,73.130,60.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.183 | Acc: 51.468,73.211,60.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.183 | Acc: 51.362,73.201,60.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.179 | Acc: 51.432,73.262,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.182 | Acc: 51.347,73.191,60.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.186 | Acc: 51.258,73.116,60.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.180 | Acc: 51.386,73.224,60.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.176 | Acc: 51.454,73.256,60.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.176 | Acc: 51.458,73.232,61.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.229 | Acc: 49.219,67.188,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.213 | Acc: 47.656,64.807,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.325 | Acc: 46.684,63.834,51.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.343 | Acc: 46.286,63.627,50.717,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 3.804 | Acc: 50.781,75.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.181 | Acc: 50.893,73.624,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.205 | Acc: 51.010,73.533,60.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.202 | Acc: 50.961,73.476,60.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.195 | Acc: 51.302,73.447,60.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.200 | Acc: 51.199,73.422,60.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.214 | Acc: 50.807,73.044,60.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.192 | Acc: 51.103,73.188,60.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.189 | Acc: 51.223,73.219,60.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.183 | Acc: 51.325,73.256,60.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.167 | Acc: 51.325,73.352,60.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.161 | Acc: 51.442,73.310,60.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.158 | Acc: 51.439,73.347,60.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.160 | Acc: 51.494,73.318,60.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.162 | Acc: 51.485,73.351,60.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.161 | Acc: 51.521,73.360,60.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.157 | Acc: 51.604,73.391,60.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.170 | Acc: 51.494,73.277,60.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.163 | Acc: 51.586,73.301,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.162 | Acc: 51.642,73.292,60.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.180 | Acc: 47.656,66.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.195 | Acc: 47.619,65.699,52.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.300 | Acc: 46.837,64.425,51.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.323 | Acc: 46.388,64.050,51.165,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 4.563 | Acc: 53.125,75.000,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.132 | Acc: 53.088,74.293,60.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.149 | Acc: 52.782,73.990,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.136 | Acc: 52.177,74.001,61.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.137 | Acc: 52.074,74.151,61.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.151 | Acc: 52.065,74.049,61.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.140 | Acc: 52.169,73.889,61.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.127 | Acc: 52.222,73.947,61.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.118 | Acc: 52.319,73.971,61.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.125 | Acc: 52.314,73.934,61.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.126 | Acc: 52.165,73.927,61.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.125 | Acc: 52.156,73.918,61.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.130 | Acc: 52.046,73.839,61.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.138 | Acc: 52.020,73.773,61.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.146 | Acc: 51.935,73.649,61.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.156 | Acc: 51.822,73.528,61.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.155 | Acc: 51.913,73.498,61.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.158 | Acc: 51.860,73.467,61.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.157 | Acc: 51.872,73.489,61.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.158 | Acc: 51.862,73.479,61.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.238 | Acc: 48.438,66.406,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.202 | Acc: 47.173,65.141,52.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.314 | Acc: 46.418,63.948,51.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.331 | Acc: 46.235,63.691,51.242,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 4.671 | Acc: 46.094,62.500,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.157 | Acc: 51.153,72.991,61.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.104 | Acc: 51.582,73.399,62.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.106 | Acc: 51.153,73.578,61.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.114 | Acc: 51.119,73.814,61.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.104 | Acc: 51.338,74.041,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.109 | Acc: 51.349,73.967,61.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.127 | Acc: 51.402,73.936,61.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.125 | Acc: 51.509,73.918,61.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.128 | Acc: 51.433,73.873,61.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.152 | Acc: 51.294,73.737,60.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.176 | Acc: 51.124,73.533,60.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.184 | Acc: 51.303,73.415,60.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.187 | Acc: 51.326,73.351,60.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.188 | Acc: 51.415,73.332,60.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.182 | Acc: 51.347,73.305,60.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.183 | Acc: 51.302,73.299,60.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.178 | Acc: 51.384,73.286,60.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.172 | Acc: 51.437,73.338,60.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.171 | Acc: 51.437,73.384,60.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.167 | Acc: 48.438,66.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.189 | Acc: 47.731,65.327,52.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.298 | Acc: 46.951,64.139,51.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.319 | Acc: 46.555,63.960,50.935,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 4.502 | Acc: 53.906,69.531,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.120 | Acc: 51.042,72.731,61.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.134 | Acc: 51.315,73.495,61.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.109 | Acc: 51.498,73.975,62.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.136 | Acc: 51.283,73.814,61.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.157 | Acc: 51.408,73.755,61.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.162 | Acc: 51.440,73.605,61.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.159 | Acc: 51.474,73.809,61.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.150 | Acc: 51.572,73.758,61.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.164 | Acc: 51.429,73.627,61.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.158 | Acc: 51.539,73.667,61.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.156 | Acc: 51.570,73.621,61.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.164 | Acc: 51.611,73.493,61.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.172 | Acc: 51.467,73.452,61.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.178 | Acc: 51.446,73.279,61.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.176 | Acc: 51.482,73.334,61.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.173 | Acc: 51.443,73.418,61.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.171 | Acc: 51.533,73.401,61.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.170 | Acc: 51.541,73.446,61.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.168 | Acc: 51.519,73.513,61.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.242 | Acc: 49.219,67.969,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.194 | Acc: 47.433,65.513,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.305 | Acc: 46.608,64.367,51.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.329 | Acc: 46.260,63.934,50.794,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 4.142 | Acc: 56.250,69.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.140 | Acc: 51.935,74.516,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.179 | Acc: 51.601,73.685,60.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.176 | Acc: 51.691,73.450,60.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.160 | Acc: 51.755,73.794,61.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.155 | Acc: 51.686,73.608,61.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.165 | Acc: 51.776,73.567,61.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.156 | Acc: 51.529,73.687,61.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.164 | Acc: 51.548,73.753,61.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.168 | Acc: 51.424,73.731,60.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.175 | Acc: 51.551,73.612,60.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.167 | Acc: 51.559,73.628,60.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.170 | Acc: 51.572,73.609,60.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.170 | Acc: 51.485,73.482,60.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.165 | Acc: 51.632,73.515,60.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.171 | Acc: 51.601,73.508,60.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.162 | Acc: 51.743,73.593,60.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.167 | Acc: 51.705,73.506,60.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.166 | Acc: 51.664,73.524,60.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.171 | Acc: 51.665,73.481,60.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.255 | Acc: 46.875,64.844,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.185 | Acc: 47.470,65.551,52.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.305 | Acc: 46.723,64.329,51.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.327 | Acc: 46.145,63.960,51.255,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 3.960 | Acc: 50.781,73.438,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.258 | Acc: 52.530,72.135,60.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.178 | Acc: 51.620,72.942,61.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.151 | Acc: 52.011,73.348,61.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.145 | Acc: 52.006,73.621,61.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.142 | Acc: 51.911,73.569,61.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.149 | Acc: 51.743,73.515,61.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.149 | Acc: 51.612,73.543,61.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.157 | Acc: 51.553,73.428,61.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.154 | Acc: 51.584,73.485,61.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.157 | Acc: 51.535,73.507,61.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.160 | Acc: 51.566,73.491,61.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.155 | Acc: 51.540,73.515,61.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.162 | Acc: 51.446,73.372,61.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.172 | Acc: 51.490,73.271,61.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.170 | Acc: 51.453,73.230,61.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.164 | Acc: 51.536,73.304,61.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.164 | Acc: 51.622,73.295,61.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.161 | Acc: 51.682,73.368,61.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.159 | Acc: 51.669,73.409,61.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.263 | Acc: 48.438,65.625,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.203 | Acc: 47.768,65.253,52.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.318 | Acc: 46.894,64.082,51.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.337 | Acc: 46.478,63.832,51.025,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 3.966 | Acc: 57.031,75.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.135 | Acc: 52.195,74.182,61.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.128 | Acc: 52.077,73.780,61.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.132 | Acc: 51.806,73.591,61.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.152 | Acc: 51.746,73.206,60.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.171 | Acc: 51.493,73.051,60.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.151 | Acc: 51.892,73.386,61.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.145 | Acc: 51.934,73.415,61.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.153 | Acc: 51.999,73.389,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.141 | Acc: 52.098,73.498,61.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.153 | Acc: 51.811,73.387,61.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.153 | Acc: 51.888,73.349,61.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.155 | Acc: 51.841,73.275,61.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.154 | Acc: 51.838,73.363,61.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.158 | Acc: 51.799,73.393,61.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.161 | Acc: 51.806,73.373,61.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.165 | Acc: 51.743,73.391,61.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.163 | Acc: 51.762,73.428,61.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.168 | Acc: 51.729,73.396,61.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.169 | Acc: 51.731,73.343,61.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.242 | Acc: 48.438,65.625,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.191 | Acc: 47.768,65.588,52.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.316 | Acc: 46.989,64.310,51.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.336 | Acc: 46.683,63.896,50.820,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 4.165 | Acc: 46.094,71.875,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.077 | Acc: 52.641,74.107,62.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.125 | Acc: 52.001,73.590,61.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.180 | Acc: 51.242,73.297,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.128 | Acc: 51.746,73.601,61.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.141 | Acc: 51.733,73.476,61.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.159 | Acc: 51.575,73.360,61.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.159 | Acc: 51.468,73.399,61.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.153 | Acc: 51.621,73.481,61.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.144 | Acc: 51.662,73.515,61.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.141 | Acc: 51.679,73.601,61.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.136 | Acc: 51.676,73.671,61.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.142 | Acc: 51.598,73.606,61.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.144 | Acc: 51.637,73.590,61.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.140 | Acc: 51.643,73.649,61.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.137 | Acc: 51.713,73.627,61.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.146 | Acc: 51.682,73.605,61.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.151 | Acc: 51.620,73.509,61.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.146 | Acc: 51.707,73.548,61.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.147 | Acc: 51.702,73.556,61.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.206 | Acc: 50.000,64.844,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.194 | Acc: 47.768,65.141,52.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.300 | Acc: 46.742,64.234,51.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.317 | Acc: 46.350,63.986,51.165,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 3.804 | Acc: 54.688,81.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.203 | Acc: 50.893,72.768,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.197 | Acc: 52.611,73.457,61.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.160 | Acc: 52.651,73.745,61.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.183 | Acc: 52.160,73.708,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.164 | Acc: 52.351,73.561,61.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.175 | Acc: 52.073,73.334,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.176 | Acc: 52.083,73.343,61.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.169 | Acc: 51.980,73.370,61.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.181 | Acc: 51.765,73.200,61.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.152 | Acc: 51.975,73.465,61.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.150 | Acc: 51.920,73.473,61.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.149 | Acc: 51.919,73.389,61.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.148 | Acc: 52.003,73.384,61.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.148 | Acc: 51.957,73.401,61.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.147 | Acc: 51.879,73.417,61.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.148 | Acc: 51.918,73.408,61.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.151 | Acc: 51.828,73.387,61.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.153 | Acc: 51.820,73.368,61.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.158 | Acc: 51.743,73.337,61.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.252 | Acc: 48.438,66.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.211 | Acc: 47.582,65.551,52.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.325 | Acc: 46.704,64.253,51.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.343 | Acc: 46.260,63.960,51.089,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 4.166 | Acc: 50.000,72.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.134 | Acc: 52.493,75.335,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.139 | Acc: 52.572,74.657,61.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.149 | Acc: 51.908,74.449,61.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.136 | Acc: 51.948,74.286,61.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.125 | Acc: 51.918,74.420,61.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.140 | Acc: 51.943,74.354,61.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.134 | Acc: 51.928,74.324,61.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.127 | Acc: 51.820,74.146,61.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.130 | Acc: 51.744,73.999,61.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.139 | Acc: 51.660,73.888,61.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.148 | Acc: 51.538,73.706,61.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.160 | Acc: 51.517,73.506,61.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.162 | Acc: 51.577,73.426,61.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.167 | Acc: 51.599,73.346,61.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.162 | Acc: 51.578,73.331,61.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.164 | Acc: 51.572,73.316,60.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.161 | Acc: 51.613,73.403,60.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.162 | Acc: 51.638,73.418,60.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.155 | Acc: 51.753,73.476,61.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.237 | Acc: 48.438,64.844,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.202 | Acc: 48.065,65.365,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.319 | Acc: 46.970,64.024,51.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.343 | Acc: 46.529,63.922,51.153,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 4.328 | Acc: 45.312,74.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.150 | Acc: 51.823,73.661,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.197 | Acc: 50.762,72.752,61.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.200 | Acc: 51.076,72.720,61.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.180 | Acc: 51.235,73.235,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.172 | Acc: 51.578,73.306,61.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.147 | Acc: 52.021,73.547,61.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.152 | Acc: 51.967,73.443,61.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.149 | Acc: 51.946,73.559,61.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.141 | Acc: 51.955,73.507,61.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.151 | Acc: 51.881,73.414,61.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.147 | Acc: 51.909,73.452,61.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.137 | Acc: 52.023,73.515,61.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.139 | Acc: 52.038,73.470,61.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.145 | Acc: 51.941,73.410,61.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.146 | Acc: 51.944,73.349,61.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.149 | Acc: 51.893,73.274,61.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.155 | Acc: 51.812,73.236,61.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.154 | Acc: 51.865,73.232,61.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.156 | Acc: 51.843,73.282,61.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.249 | Acc: 50.000,66.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.223 | Acc: 47.768,65.327,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.333 | Acc: 46.761,64.024,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.348 | Acc: 46.350,63.614,50.717,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 3.672 | Acc: 55.469,74.219,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.186 | Acc: 50.856,73.512,62.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.203 | Acc: 51.391,73.247,61.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.248 | Acc: 50.576,72.695,60.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.188 | Acc: 51.215,73.003,61.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.170 | Acc: 51.392,73.329,61.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.186 | Acc: 51.298,73.063,61.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.172 | Acc: 51.768,73.260,61.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.166 | Acc: 51.985,73.219,61.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.164 | Acc: 51.834,73.105,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.158 | Acc: 51.932,73.185,61.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.154 | Acc: 52.026,73.289,61.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.160 | Acc: 51.916,73.262,61.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.152 | Acc: 51.904,73.384,61.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.147 | Acc: 51.904,73.426,61.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.139 | Acc: 52.012,73.422,61.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.140 | Acc: 52.013,73.433,61.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.148 | Acc: 52.018,73.369,61.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.150 | Acc: 51.904,73.409,61.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.150 | Acc: 51.942,73.386,61.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.249 | Acc: 48.438,66.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.212 | Acc: 48.103,65.662,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.316 | Acc: 46.970,64.367,51.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.339 | Acc: 46.504,64.037,50.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 3.744 | Acc: 53.125,77.344,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.154 | Acc: 52.827,73.251,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.174 | Acc: 52.992,73.323,61.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.177 | Acc: 52.395,73.438,62.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.159 | Acc: 52.392,73.447,61.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.161 | Acc: 52.305,73.499,61.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.160 | Acc: 52.066,73.483,62.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.150 | Acc: 52.272,73.604,62.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.157 | Acc: 52.116,73.510,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.154 | Acc: 52.119,73.537,61.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.156 | Acc: 52.068,73.562,61.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.149 | Acc: 52.163,73.688,61.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.148 | Acc: 52.182,73.642,61.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.146 | Acc: 52.131,73.638,61.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.149 | Acc: 52.082,73.493,61.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.149 | Acc: 52.061,73.469,61.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.157 | Acc: 51.884,73.450,61.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.152 | Acc: 51.904,73.472,61.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.153 | Acc: 51.801,73.440,61.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.153 | Acc: 51.792,73.448,61.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.316 | Acc: 47.656,66.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.210 | Acc: 47.991,65.402,52.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.330 | Acc: 46.913,64.234,51.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.349 | Acc: 46.516,63.717,51.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 4.053 | Acc: 52.344,77.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.197 | Acc: 52.195,73.028,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.140 | Acc: 52.077,73.990,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.121 | Acc: 52.139,73.886,61.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.095 | Acc: 52.305,73.920,61.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.089 | Acc: 52.058,73.933,62.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.111 | Acc: 51.446,73.554,61.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.111 | Acc: 51.535,73.482,61.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.113 | Acc: 51.436,73.505,61.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.115 | Acc: 51.316,73.580,61.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.119 | Acc: 51.314,73.507,61.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.124 | Acc: 51.336,73.554,62.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.126 | Acc: 51.527,73.574,62.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.123 | Acc: 51.628,73.617,61.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.127 | Acc: 51.604,73.457,61.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.123 | Acc: 51.747,73.518,61.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.131 | Acc: 51.738,73.442,61.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.141 | Acc: 51.620,73.376,61.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.138 | Acc: 51.634,73.375,61.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.141 | Acc: 51.575,73.376,61.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.162 | Acc: 48.438,67.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.201 | Acc: 47.693,65.774,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.314 | Acc: 46.837,64.329,51.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.333 | Acc: 46.286,63.845,51.383,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 4.183 | Acc: 49.219,71.094,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.043 | Acc: 52.679,73.921,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.162 | Acc: 51.086,72.523,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.124 | Acc: 52.075,73.079,61.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.109 | Acc: 52.093,73.582,61.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.099 | Acc: 52.166,73.693,61.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.123 | Acc: 51.969,73.683,61.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.135 | Acc: 51.773,73.559,61.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.136 | Acc: 51.844,73.680,61.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.134 | Acc: 51.809,73.658,61.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.147 | Acc: 51.780,73.581,61.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.143 | Acc: 51.828,73.575,61.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.149 | Acc: 51.702,73.567,61.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.154 | Acc: 51.670,73.536,61.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.158 | Acc: 51.599,73.518,61.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.162 | Acc: 51.607,73.510,60.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.159 | Acc: 51.597,73.564,61.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.163 | Acc: 51.508,73.547,61.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.159 | Acc: 51.545,73.539,61.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.163 | Acc: 51.528,73.481,60.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.214 | Acc: 49.219,66.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.210 | Acc: 47.917,65.216,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.322 | Acc: 47.046,64.386,51.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.336 | Acc: 46.619,64.011,51.153,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 4.050 | Acc: 59.375,67.188,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.052 | Acc: 53.943,74.330,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 52.515,74.619,61.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.050 | Acc: 51.972,74.488,62.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.061 | Acc: 52.170,74.344,61.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.052 | Acc: 52.413,74.327,61.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.073 | Acc: 52.040,74.083,61.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.090 | Acc: 52.083,74.030,61.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.090 | Acc: 52.043,74.063,61.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.094 | Acc: 52.037,74.033,61.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.107 | Acc: 52.111,73.908,61.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.114 | Acc: 52.043,73.943,61.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.127 | Acc: 51.922,73.807,61.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.129 | Acc: 51.976,73.767,61.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.132 | Acc: 51.985,73.727,61.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.139 | Acc: 51.879,73.723,61.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.145 | Acc: 51.791,73.608,61.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.146 | Acc: 51.730,73.584,61.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.149 | Acc: 51.636,73.557,61.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.154 | Acc: 51.577,73.491,61.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.242 | Acc: 49.219,67.969,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.201 | Acc: 47.693,65.476,52.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.316 | Acc: 46.761,64.425,51.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.339 | Acc: 46.324,63.922,51.101,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 4.610 | Acc: 46.875,67.188,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.155 | Acc: 50.670,74.516,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.188 | Acc: 51.410,73.647,60.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.206 | Acc: 51.178,73.527,60.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.208 | Acc: 50.897,73.264,60.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.219 | Acc: 50.828,73.136,60.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.220 | Acc: 50.923,72.940,60.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.216 | Acc: 50.798,72.939,60.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.205 | Acc: 51.247,73.098,60.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.191 | Acc: 51.398,73.235,61.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.183 | Acc: 51.384,73.266,61.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.184 | Acc: 51.329,73.204,61.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.178 | Acc: 51.381,73.285,61.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.176 | Acc: 51.404,73.186,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.176 | Acc: 51.468,73.260,61.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.176 | Acc: 51.428,73.251,61.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.177 | Acc: 51.455,73.309,61.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.173 | Acc: 51.521,73.334,61.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.175 | Acc: 51.418,73.310,61.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.164 | Acc: 51.542,73.394,61.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.218 | Acc: 48.438,67.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.201 | Acc: 47.545,65.253,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.318 | Acc: 46.856,64.139,51.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.338 | Acc: 46.401,63.627,50.717,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 4.901 | Acc: 50.781,67.969,57.031,% | Adaptive Acc: 63.281% | clf_exit: 0.367 0.297 0.336
Batch: 20 | Loss: 4.237 | Acc: 51.265,73.772,60.975,% | Adaptive Acc: 67.262% | clf_exit: 0.344 0.357 0.299
Batch: 40 | Loss: 4.215 | Acc: 51.086,73.133,61.357,% | Adaptive Acc: 67.016% | clf_exit: 0.347 0.357 0.296
Batch: 60 | Loss: 4.246 | Acc: 50.653,72.592,60.669,% | Adaptive Acc: 66.445% | clf_exit: 0.341 0.360 0.299
Batch: 80 | Loss: 4.220 | Acc: 50.916,73.187,60.928,% | Adaptive Acc: 66.879% | clf_exit: 0.342 0.361 0.297
Batch: 100 | Loss: 4.198 | Acc: 51.052,73.476,60.907,% | Adaptive Acc: 66.816% | clf_exit: 0.342 0.363 0.296
Batch: 120 | Loss: 4.189 | Acc: 51.272,73.612,60.899,% | Adaptive Acc: 66.974% | clf_exit: 0.342 0.365 0.294
Batch: 140 | Loss: 4.185 | Acc: 51.335,73.454,60.865,% | Adaptive Acc: 66.949% | clf_exit: 0.342 0.364 0.294
Batch: 160 | Loss: 4.176 | Acc: 51.344,73.520,60.899,% | Adaptive Acc: 66.974% | clf_exit: 0.343 0.363 0.294
Batch: 180 | Loss: 4.175 | Acc: 51.295,73.485,60.916,% | Adaptive Acc: 67.015% | clf_exit: 0.343 0.364 0.293
Batch: 200 | Loss: 4.166 | Acc: 51.485,73.445,61.093,% | Adaptive Acc: 67.102% | clf_exit: 0.344 0.363 0.293
Batch: 220 | Loss: 4.163 | Acc: 51.492,73.526,61.082,% | Adaptive Acc: 67.035% | clf_exit: 0.345 0.363 0.292
Batch: 240 | Loss: 4.168 | Acc: 51.537,73.532,61.119,% | Adaptive Acc: 66.941% | clf_exit: 0.344 0.364 0.292
Batch: 260 | Loss: 4.168 | Acc: 51.512,73.590,61.120,% | Adaptive Acc: 66.936% | clf_exit: 0.345 0.363 0.292
Batch: 280 | Loss: 4.163 | Acc: 51.462,73.621,61.157,% | Adaptive Acc: 67.012% | clf_exit: 0.345 0.364 0.291
Batch: 300 | Loss: 4.160 | Acc: 51.524,73.648,61.169,% | Adaptive Acc: 67.050% | clf_exit: 0.346 0.364 0.290
Batch: 320 | Loss: 4.157 | Acc: 51.665,73.642,61.181,% | Adaptive Acc: 67.114% | clf_exit: 0.346 0.364 0.290
Batch: 340 | Loss: 4.160 | Acc: 51.652,73.575,61.164,% | Adaptive Acc: 67.080% | clf_exit: 0.345 0.364 0.291
Batch: 360 | Loss: 4.162 | Acc: 51.653,73.589,61.141,% | Adaptive Acc: 67.049% | clf_exit: 0.345 0.364 0.291
Batch: 380 | Loss: 4.164 | Acc: 51.581,73.550,61.145,% | Adaptive Acc: 66.995% | clf_exit: 0.345 0.364 0.291
Batch: 0 | Loss: 5.261 | Acc: 47.656,66.406,56.250,% | Adaptive Acc: 59.375% | clf_exit: 0.477 0.273 0.250
Batch: 20 | Loss: 5.221 | Acc: 47.991,65.141,52.455,% | Adaptive Acc: 59.263% | clf_exit: 0.413 0.314 0.272
Batch: 40 | Loss: 5.337 | Acc: 46.951,63.796,51.353,% | Adaptive Acc: 58.632% | clf_exit: 0.402 0.311 0.287
Batch: 60 | Loss: 5.354 | Acc: 46.388,63.563,50.858,% | Adaptive Acc: 58.197% | clf_exit: 0.400 0.314 0.287
model is save as models/resnet56_h12_cifar100_adaptive0_circles8_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 143.260 | Acc: 1.562,1.562,0.000,% | Adaptive Acc: 1.562% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 141.723 | Acc: 1.042,1.079,0.781,% | Adaptive Acc: 1.042% | clf_exit: 1.000 0.000 0.000
Batch: 40 | Loss: 143.122 | Acc: 1.067,1.086,0.877,% | Adaptive Acc: 1.067% | clf_exit: 1.000 0.000 0.000
Batch: 60 | Loss: 142.949 | Acc: 1.012,1.025,0.999,% | Adaptive Acc: 1.012% | clf_exit: 1.000 0.000 0.000
Batch: 0 | Loss: 117.897 | Acc: 1.562,1.562,0.000,% | Adaptive Acc: 1.562% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 116.763 | Acc: 1.042,1.339,0.781,% | Adaptive Acc: 1.042% | clf_exit: 1.000 0.000 0.000
Batch: 40 | Loss: 117.901 | Acc: 1.067,1.353,0.877,% | Adaptive Acc: 1.067% | clf_exit: 1.000 0.000 0.000
Batch: 60 | Loss: 117.714 | Acc: 1.012,1.281,0.999,% | Adaptive Acc: 1.012% | clf_exit: 1.000 0.000 0.000
Batch: 0 | Loss: 100.312 | Acc: 1.562,1.562,0.000,% | Adaptive Acc: 1.562% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 99.198 | Acc: 1.042,2.604,0.781,% | Adaptive Acc: 1.042% | clf_exit: 1.000 0.000 0.000
Batch: 40 | Loss: 100.174 | Acc: 1.105,2.572,0.877,% | Adaptive Acc: 1.105% | clf_exit: 1.000 0.000 0.000
Batch: 60 | Loss: 99.996 | Acc: 1.050,2.382,0.999,% | Adaptive Acc: 1.050% | clf_exit: 1.000 0.000 0.000
Batch: 0 | Loss: 83.175 | Acc: 1.562,0.781,0.000,% | Adaptive Acc: 1.562% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 82.111 | Acc: 1.302,2.009,0.781,% | Adaptive Acc: 1.302% | clf_exit: 1.000 0.000 0.000
Batch: 40 | Loss: 82.933 | Acc: 1.391,1.905,0.877,% | Adaptive Acc: 1.391% | clf_exit: 0.999 0.001 0.000
Batch: 60 | Loss: 82.761 | Acc: 1.332,1.870,0.999,% | Adaptive Acc: 1.332% | clf_exit: 0.999 0.001 0.000
Batch: 0 | Loss: 67.580 | Acc: 2.344,1.562,0.000,% | Adaptive Acc: 2.344% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 66.627 | Acc: 1.786,1.749,0.781,% | Adaptive Acc: 1.786% | clf_exit: 0.997 0.003 0.000
Batch: 40 | Loss: 67.313 | Acc: 1.734,1.829,0.877,% | Adaptive Acc: 1.734% | clf_exit: 0.997 0.002 0.000
Batch: 60 | Loss: 67.158 | Acc: 1.652,1.755,0.999,% | Adaptive Acc: 1.652% | clf_exit: 0.998 0.002 0.000
Batch: 0 | Loss: 53.663 | Acc: 2.344,1.562,0.000,% | Adaptive Acc: 2.344% | clf_exit: 0.992 0.008 0.000
Batch: 20 | Loss: 52.816 | Acc: 1.935,2.865,0.781,% | Adaptive Acc: 1.935% | clf_exit: 0.991 0.006 0.003
Batch: 40 | Loss: 53.375 | Acc: 1.925,2.896,0.877,% | Adaptive Acc: 1.944% | clf_exit: 0.988 0.007 0.004
Batch: 60 | Loss: 53.241 | Acc: 1.844,2.882,0.999,% | Adaptive Acc: 1.844% | clf_exit: 0.987 0.008 0.005
Batch: 0 | Loss: 40.130 | Acc: 2.344,10.156,0.000,% | Adaptive Acc: 3.125% | clf_exit: 0.914 0.016 0.070
Batch: 20 | Loss: 39.418 | Acc: 2.790,9.077,0.781,% | Adaptive Acc: 2.902% | clf_exit: 0.920 0.012 0.068
Batch: 40 | Loss: 39.844 | Acc: 2.706,8.422,0.877,% | Adaptive Acc: 2.954% | clf_exit: 0.918 0.014 0.067
Batch: 60 | Loss: 39.735 | Acc: 2.818,8.683,0.999,% | Adaptive Acc: 3.048% | clf_exit: 0.919 0.014 0.068
Batch: 0 | Loss: 24.596 | Acc: 7.812,35.156,0.000,% | Adaptive Acc: 12.500% | clf_exit: 0.586 0.141 0.273
Batch: 20 | Loss: 24.030 | Acc: 11.310,38.095,0.781,% | Adaptive Acc: 16.183% | clf_exit: 0.640 0.130 0.230
Batch: 40 | Loss: 24.332 | Acc: 10.766,36.947,0.877,% | Adaptive Acc: 15.625% | clf_exit: 0.633 0.129 0.238
Batch: 60 | Loss: 24.239 | Acc: 10.630,36.911,0.999,% | Adaptive Acc: 15.920% | clf_exit: 0.631 0.130 0.239
Batch: 0 | Loss: 5.261 | Acc: 47.656,66.406,56.250,% | Adaptive Acc: 59.375% | clf_exit: 0.477 0.273 0.250
Batch: 20 | Loss: 5.221 | Acc: 47.991,65.141,52.455,% | Adaptive Acc: 59.263% | clf_exit: 0.413 0.314 0.272
Batch: 40 | Loss: 5.337 | Acc: 46.951,63.796,51.353,% | Adaptive Acc: 58.632% | clf_exit: 0.402 0.311 0.287
Batch: 60 | Loss: 5.354 | Acc: 46.388,63.563,50.858,% | Adaptive Acc: 58.197% | clf_exit: 0.400 0.314 0.287







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.822 |  Acc: 1.882,1.570,1.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 13.585 |  Acc: 1.580,1.820,1.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 13.434 |  Acc: 2.106,2.358,1.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 13.380 |  Acc: 2.050,2.860,2.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 13.258 |  Acc: 2.286,2.772,2.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 13.240 |  Acc: 2.300,2.620,1.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 13.084 |  Acc: 2.460,3.646,2.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 13.250 |  Acc: 2.400,2.150,1.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 12.834 |  Acc: 3.036,5.572,2.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 13.005 |  Acc: 2.930,4.940,2.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 12.574 |  Acc: 3.394,7.858,2.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 12.688 |  Acc: 2.810,6.870,2.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 12.362 |  Acc: 3.558,9.752,2.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 12.266 |  Acc: 4.130,9.070,2.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 12.164 |  Acc: 3.664,11.488,2.274,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 12.541 |  Acc: 2.970,8.550,2.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 11.975 |  Acc: 3.784,13.468,2.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 12.144 |  Acc: 2.750,12.570,2.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 11.799 |  Acc: 3.830,15.810,2.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 12.320 |  Acc: 3.740,9.710,2.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 11.655 |  Acc: 3.930,17.478,2.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 11.928 |  Acc: 3.360,16.140,2.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 11.558 |  Acc: 4.342,19.230,2.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 11.940 |  Acc: 4.560,13.690,2.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 11.442 |  Acc: 6.202,20.694,2.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 11.714 |  Acc: 5.870,18.340,2.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 11.206 |  Acc: 8.346,22.072,2.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 11.689 |  Acc: 7.720,16.070,2.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 10.926 |  Acc: 10.814,23.420,2.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 13.524 |  Acc: 2.820,17.410,2.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 10.706 |  Acc: 14.374,24.558,2.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 10.958 |  Acc: 12.550,21.860,2.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 10.465 |  Acc: 18.262,25.964,2.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 10.984 |  Acc: 15.710,19.980,2.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 10.169 |  Acc: 21.410,27.374,2.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 10.574 |  Acc: 17.840,22.790,2.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 9.981 |  Acc: 23.500,28.984,2.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 11.970 |  Acc: 14.800,15.620,2.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 9.890 |  Acc: 25.164,29.700,2.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 10.666 |  Acc: 20.690,21.720,2.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 9.692 |  Acc: 26.494,31.304,2.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 10.602 |  Acc: 19.150,25.000,1.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 9.706 |  Acc: 27.676,32.596,2.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 11.775 |  Acc: 17.970,17.400,2.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 9.529 |  Acc: 28.568,33.900,2.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 9.819 |  Acc: 25.230,31.430,2.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 9.378 |  Acc: 29.468,35.520,2.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 10.101 |  Acc: 26.220,25.860,2.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 9.244 |  Acc: 30.406,36.988,2.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 9.997 |  Acc: 23.960,30.620,2.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 9.114 |  Acc: 31.390,38.492,2.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 10.107 |  Acc: 20.930,28.620,2.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 9.009 |  Acc: 32.038,39.310,2.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 9.462 |  Acc: 26.360,36.200,2.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 8.909 |  Acc: 32.722,40.684,2.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 10.643 |  Acc: 19.090,27.860,2.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 9.040 |  Acc: 33.140,41.560,2.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 10.284 |  Acc: 25.570,30.180,2.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 8.954 |  Acc: 33.880,42.338,2.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 10.265 |  Acc: 25.090,29.710,2.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 8.841 |  Acc: 34.294,43.464,2.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 9.608 |  Acc: 26.750,36.160,2.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 8.782 |  Acc: 34.840,44.516,2.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 11.021 |  Acc: 20.100,30.470,2.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 8.717 |  Acc: 35.140,45.092,2.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 10.938 |  Acc: 22.130,31.450,1.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 8.663 |  Acc: 35.438,45.846,2.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 9.317 |  Acc: 29.580,39.090,2.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 8.584 |  Acc: 36.026,46.474,2.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 10.249 |  Acc: 24.720,30.450,3.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 8.513 |  Acc: 36.308,47.272,2.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 9.835 |  Acc: 25.480,35.230,3.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 8.468 |  Acc: 36.464,47.954,3.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 10.250 |  Acc: 21.640,37.220,2.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 8.427 |  Acc: 36.926,48.782,2.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 9.378 |  Acc: 29.690,38.660,2.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 8.491 |  Acc: 37.264,49.062,2.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 10.402 |  Acc: 22.980,35.760,2.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 8.502 |  Acc: 37.106,49.046,2.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 10.820 |  Acc: 22.730,34.670,2.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 8.413 |  Acc: 37.476,49.772,2.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 10.196 |  Acc: 22.640,36.730,2.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 8.351 |  Acc: 37.794,50.336,2.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 10.005 |  Acc: 22.950,39.450,2.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 8.311 |  Acc: 37.976,51.172,2.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 9.773 |  Acc: 26.120,37.780,2.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 8.265 |  Acc: 38.292,51.412,2.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 9.454 |  Acc: 27.790,41.710,2.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 8.308 |  Acc: 38.444,51.434,2.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 10.196 |  Acc: 22.480,37.140,2.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 8.293 |  Acc: 38.400,51.890,2.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 10.468 |  Acc: 20.200,35.590,3.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 8.223 |  Acc: 38.846,52.406,2.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 10.932 |  Acc: 17.600,32.920,2.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 8.173 |  Acc: 39.152,53.072,2.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 10.015 |  Acc: 25.520,36.390,2.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 8.142 |  Acc: 38.950,53.002,2.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 9.459 |  Acc: 26.760,41.510,2.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 8.120 |  Acc: 39.404,53.246,2.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 9.535 |  Acc: 28.210,40.550,2.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 8.085 |  Acc: 39.412,53.730,2.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 9.265 |  Acc: 29.940,43.220,2.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 8.053 |  Acc: 39.492,53.876,2.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 10.139 |  Acc: 24.590,35.790,2.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 8.018 |  Acc: 39.512,54.224,2.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 9.688 |  Acc: 26.510,40.600,2.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 8.004 |  Acc: 40.014,54.274,2.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 10.660 |  Acc: 22.830,35.500,2.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 7.969 |  Acc: 39.814,54.552,2.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 10.113 |  Acc: 22.350,39.690,2.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 7.944 |  Acc: 40.324,55.100,2.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 10.410 |  Acc: 22.640,35.170,1.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 7.915 |  Acc: 40.236,55.160,2.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 9.257 |  Acc: 29.800,42.530,2.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 7.897 |  Acc: 40.674,55.010,2.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 9.580 |  Acc: 25.800,39.580,2.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 7.883 |  Acc: 40.506,55.234,3.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 10.201 |  Acc: 23.570,37.040,2.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 7.862 |  Acc: 40.662,55.544,2.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 9.834 |  Acc: 24.150,40.110,2.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 7.831 |  Acc: 40.782,55.958,2.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 9.282 |  Acc: 27.320,43.350,3.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 7.819 |  Acc: 41.016,56.026,2.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 9.647 |  Acc: 24.860,40.820,2.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 7.820 |  Acc: 41.114,56.322,3.080,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 8.791 |  Acc: 31.710,48.160,3.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 7.802 |  Acc: 41.230,56.606,3.150,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 10.535 |  Acc: 20.810,37.760,3.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 7.798 |  Acc: 41.150,56.472,3.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 9.469 |  Acc: 26.410,41.480,3.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 7.774 |  Acc: 41.600,56.768,3.128,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 8.801 |  Acc: 32.100,48.050,3.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 7.756 |  Acc: 41.362,56.850,3.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 10.401 |  Acc: 20.210,39.260,3.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 7.747 |  Acc: 41.440,57.046,3.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 10.800 |  Acc: 18.470,36.600,3.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 7.716 |  Acc: 41.402,57.218,3.080,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 9.949 |  Acc: 23.120,38.690,3.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 7.710 |  Acc: 41.594,57.382,2.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 9.299 |  Acc: 27.990,43.520,3.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 7.697 |  Acc: 41.750,57.594,2.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 8.641 |  Acc: 31.410,48.850,2.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 7.668 |  Acc: 41.788,57.644,2.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 9.445 |  Acc: 25.180,41.530,2.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 7.660 |  Acc: 42.214,57.838,2.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 8.684 |  Acc: 32.270,47.350,3.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 7.651 |  Acc: 41.962,57.916,2.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 8.513 |  Acc: 33.050,49.460,2.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 7.638 |  Acc: 42.030,57.988,2.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 9.438 |  Acc: 28.850,41.260,2.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 7.633 |  Acc: 42.252,58.190,2.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 9.463 |  Acc: 24.090,43.440,2.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 7.612 |  Acc: 41.902,58.702,2.942,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 9.630 |  Acc: 26.250,42.140,3.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 7.639 |  Acc: 41.870,58.514,3.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 9.363 |  Acc: 26.840,44.830,3.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 7.621 |  Acc: 42.310,58.366,2.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 9.672 |  Acc: 24.100,41.930,2.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 7.604 |  Acc: 42.312,58.878,3.038,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 10.370 |  Acc: 22.510,40.010,3.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 7.576 |  Acc: 42.444,58.942,3.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 8.925 |  Acc: 31.380,44.590,3.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 7.619 |  Acc: 42.518,58.652,2.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 9.747 |  Acc: 26.030,40.340,3.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 7.619 |  Acc: 42.360,58.866,2.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 9.712 |  Acc: 24.750,41.480,3.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 7.616 |  Acc: 42.574,58.702,2.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 9.915 |  Acc: 22.790,40.400,3.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 7.590 |  Acc: 42.404,59.008,3.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 9.800 |  Acc: 23.060,40.440,2.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 7.578 |  Acc: 42.620,58.960,3.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 9.584 |  Acc: 27.620,45.560,2.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 7.553 |  Acc: 42.756,59.284,2.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 9.142 |  Acc: 27.470,44.830,2.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 7.540 |  Acc: 42.568,59.164,3.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 9.358 |  Acc: 27.670,44.180,3.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 7.531 |  Acc: 42.894,59.436,3.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 10.080 |  Acc: 20.970,37.430,3.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 7.531 |  Acc: 42.700,59.602,3.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 9.410 |  Acc: 28.520,42.100,2.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 7.587 |  Acc: 43.096,59.480,2.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 9.424 |  Acc: 27.950,43.620,2.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 7.625 |  Acc: 42.722,59.418,2.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 10.287 |  Acc: 26.040,43.770,2.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 7.610 |  Acc: 43.266,59.504,2.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 10.026 |  Acc: 24.260,43.840,3.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 7.592 |  Acc: 43.052,59.864,2.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 10.015 |  Acc: 26.440,43.260,1.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 7.606 |  Acc: 42.882,59.596,2.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 10.279 |  Acc: 21.310,39.110,2.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 7.593 |  Acc: 43.306,60.088,2.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 10.674 |  Acc: 21.180,38.080,2.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 7.635 |  Acc: 43.376,59.586,3.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 11.732 |  Acc: 22.660,44.000,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 7.698 |  Acc: 43.058,59.726,3.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 11.422 |  Acc: 20.080,35.030,2.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 7.658 |  Acc: 43.254,60.074,3.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 11.612 |  Acc: 22.010,40.670,1.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 7.624 |  Acc: 43.328,59.880,3.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 12.457 |  Acc: 15.430,30.810,2.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 7.643 |  Acc: 43.268,59.602,3.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 10.630 |  Acc: 30.080,39.680,2.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 7.332 |  Acc: 43.386,60.150,8.500,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 10.248 |  Acc: 21.910,38.870,6.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 7.186 |  Acc: 43.304,60.042,10.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 11.831 |  Acc: 14.000,31.140,7.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 7.076 |  Acc: 43.326,59.776,11.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 10.277 |  Acc: 21.550,43.920,8.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 7.010 |  Acc: 42.928,59.608,13.104,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 10.209 |  Acc: 20.440,38.880,10.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 6.997 |  Acc: 42.848,58.760,13.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 9.707 |  Acc: 21.100,39.970,8.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 6.944 |  Acc: 42.856,58.460,14.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 10.854 |  Acc: 24.300,37.220,4.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 6.938 |  Acc: 42.526,58.004,15.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 9.992 |  Acc: 21.200,36.870,9.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 6.953 |  Acc: 42.298,57.650,15.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 10.533 |  Acc: 20.820,36.050,7.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 6.929 |  Acc: 42.106,57.326,16.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 8.952 |  Acc: 28.470,42.820,13.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 6.919 |  Acc: 42.082,57.328,16.128,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 9.760 |  Acc: 23.790,38.010,11.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 6.936 |  Acc: 42.346,57.088,15.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 9.536 |  Acc: 25.050,39.960,10.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 6.888 |  Acc: 42.198,57.180,16.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 9.857 |  Acc: 24.360,39.020,9.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 6.877 |  Acc: 42.138,57.050,16.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 9.349 |  Acc: 21.500,41.660,12.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 6.894 |  Acc: 41.750,56.578,16.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 9.713 |  Acc: 19.150,37.080,14.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 6.896 |  Acc: 41.654,56.472,16.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 8.983 |  Acc: 27.190,41.500,12.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 6.886 |  Acc: 41.616,56.630,16.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 10.181 |  Acc: 21.060,37.620,9.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 6.941 |  Acc: 41.240,55.664,16.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 9.862 |  Acc: 19.680,37.470,12.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 7.001 |  Acc: 41.040,54.830,16.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 9.229 |  Acc: 21.090,41.400,15.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 6.965 |  Acc: 41.382,54.948,17.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 12.597 |  Acc: 11.780,26.600,14.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 7.074 |  Acc: 40.548,53.932,16.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 9.371 |  Acc: 23.810,39.890,13.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 7.078 |  Acc: 40.740,53.872,16.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 10.874 |  Acc: 19.950,31.500,9.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 6.987 |  Acc: 40.778,54.710,17.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 9.765 |  Acc: 23.340,38.790,7.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 6.965 |  Acc: 41.096,54.948,17.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 12.355 |  Acc: 12.220,25.110,9.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 7.115 |  Acc: 40.360,53.346,16.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 9.937 |  Acc: 19.290,35.860,9.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 7.048 |  Acc: 40.904,54.092,16.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 13.050 |  Acc: 13.050,26.700,9.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 7.118 |  Acc: 40.486,53.026,16.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 9.994 |  Acc: 24.160,39.350,7.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 7.162 |  Acc: 40.244,52.612,16.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 9.640 |  Acc: 19.540,37.020,14.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 7.060 |  Acc: 40.690,53.570,17.138,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 10.793 |  Acc: 16.130,31.960,12.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 7.271 |  Acc: 39.686,52.096,15.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 13.213 |  Acc: 10.250,22.900,7.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 7.083 |  Acc: 40.798,53.666,16.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 9.798 |  Acc: 20.480,35.210,14.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 6.984 |  Acc: 41.400,54.486,17.230,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 8.179 |  Acc: 28.070,45.700,16.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 6.576 |  Acc: 43.112,57.612,21.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 9.533 |  Acc: 22.050,39.910,12.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 6.554 |  Acc: 42.380,57.280,22.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 9.205 |  Acc: 22.360,43.230,12.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 6.412 |  Acc: 43.140,58.012,24.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 8.046 |  Acc: 27.980,46.990,19.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 6.408 |  Acc: 42.886,57.610,25.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 8.885 |  Acc: 23.950,40.860,19.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 6.314 |  Acc: 43.038,58.054,26.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 10.041 |  Acc: 18.550,35.910,21.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 6.485 |  Acc: 41.910,55.942,26.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 8.333 |  Acc: 27.310,42.280,20.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 6.373 |  Acc: 42.330,57.220,28.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 8.059 |  Acc: 28.690,42.290,24.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 6.331 |  Acc: 42.446,57.260,28.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 9.284 |  Acc: 23.410,38.830,22.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 6.306 |  Acc: 42.480,56.910,29.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 9.330 |  Acc: 20.870,40.050,20.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 6.321 |  Acc: 42.368,57.044,29.104,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 8.546 |  Acc: 21.960,44.030,25.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 6.284 |  Acc: 42.716,57.196,29.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 14.179 |  Acc: 9.770,21.190,21.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 6.335 |  Acc: 42.290,56.454,29.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 9.961 |  Acc: 18.390,34.240,14.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 6.287 |  Acc: 42.396,56.770,30.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 8.966 |  Acc: 21.120,40.400,25.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 6.305 |  Acc: 42.016,56.722,30.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 9.780 |  Acc: 20.630,33.830,18.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 6.256 |  Acc: 42.406,57.058,30.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 8.109 |  Acc: 24.970,46.310,29.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 6.287 |  Acc: 42.092,56.864,30.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 9.085 |  Acc: 21.310,41.390,22.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 6.228 |  Acc: 42.308,57.144,31.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 8.761 |  Acc: 26.300,39.690,27.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 6.248 |  Acc: 42.106,56.992,31.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 8.939 |  Acc: 26.110,40.020,24.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 5.565 |  Acc: 46.404,63.748,37.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 6.025 |  Acc: 43.410,59.860,35.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 5.355 |  Acc: 47.548,65.488,39.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 5.927 |  Acc: 43.840,60.420,37.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 5.277 |  Acc: 47.968,66.132,40.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 5.849 |  Acc: 44.230,60.950,38.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 5.248 |  Acc: 48.056,66.314,41.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 5.866 |  Acc: 44.150,60.980,38.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 5.179 |  Acc: 48.400,66.848,42.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 5.814 |  Acc: 44.250,61.160,39.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 5.169 |  Acc: 48.392,66.772,42.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 5.835 |  Acc: 44.580,61.220,38.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 5.172 |  Acc: 48.270,66.804,42.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 5.929 |  Acc: 43.340,60.220,39.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 5.150 |  Acc: 48.858,66.964,43.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 5.891 |  Acc: 43.780,60.810,39.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 5.105 |  Acc: 48.792,67.454,43.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 5.871 |  Acc: 43.770,61.000,38.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 5.096 |  Acc: 48.918,67.610,44.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 5.810 |  Acc: 44.080,61.190,40.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 5.064 |  Acc: 48.964,67.402,44.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 5.869 |  Acc: 44.090,60.640,39.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 5.075 |  Acc: 48.666,67.506,44.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 5.818 |  Acc: 44.620,61.400,39.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 5.041 |  Acc: 48.674,67.938,44.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 5.747 |  Acc: 44.800,61.950,40.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 5.044 |  Acc: 48.846,67.732,44.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 5.838 |  Acc: 43.920,61.510,40.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 5.022 |  Acc: 49.122,67.746,44.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 5.823 |  Acc: 44.110,61.450,40.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 5.032 |  Acc: 48.770,67.828,45.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 5.797 |  Acc: 44.360,61.540,40.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 5.048 |  Acc: 48.890,67.702,45.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 5.905 |  Acc: 43.400,60.480,39.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 5.038 |  Acc: 48.814,67.472,45.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 5.895 |  Acc: 43.310,60.670,40.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 5.038 |  Acc: 48.646,67.786,45.190,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 6.264 |  Acc: 41.440,57.950,37.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 5.040 |  Acc: 48.808,67.484,45.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 6.108 |  Acc: 42.330,59.410,38.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 5.022 |  Acc: 48.768,67.752,45.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 5.840 |  Acc: 44.010,60.410,41.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 4.984 |  Acc: 49.116,67.926,46.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 5.856 |  Acc: 43.200,61.160,41.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 4.984 |  Acc: 49.050,68.162,46.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 5.896 |  Acc: 44.580,61.210,39.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 4.985 |  Acc: 48.908,67.976,46.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 5.830 |  Acc: 43.680,61.460,41.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 5.000 |  Acc: 49.012,67.648,46.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 5.976 |  Acc: 42.320,60.430,41.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 4.972 |  Acc: 48.804,67.952,46.746,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 5.922 |  Acc: 43.360,60.480,41.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 4.949 |  Acc: 48.978,68.002,47.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 5.888 |  Acc: 43.660,60.130,41.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 4.961 |  Acc: 49.018,67.784,46.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 5.903 |  Acc: 42.990,60.660,41.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 4.948 |  Acc: 49.028,68.042,47.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 5.883 |  Acc: 43.820,60.380,42.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 4.931 |  Acc: 48.978,68.312,47.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 5.971 |  Acc: 43.080,60.670,40.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 4.989 |  Acc: 48.652,67.802,47.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 5.891 |  Acc: 43.290,60.790,42.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 4.924 |  Acc: 48.910,68.206,47.886,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 6.057 |  Acc: 42.290,59.120,41.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 5.057 |  Acc: 48.248,67.388,46.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 5.859 |  Acc: 43.490,60.810,42.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 4.994 |  Acc: 48.602,67.766,47.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 5.979 |  Acc: 43.360,60.420,40.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 5.142 |  Acc: 47.920,66.652,45.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 6.003 |  Acc: 44.410,59.610,40.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 5.032 |  Acc: 48.582,67.654,46.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 5.946 |  Acc: 43.530,60.050,42.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 4.946 |  Acc: 49.132,67.956,47.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 6.029 |  Acc: 41.840,59.840,41.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 4.966 |  Acc: 48.706,67.712,47.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 5.890 |  Acc: 43.030,60.850,43.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 5.005 |  Acc: 48.774,67.240,47.554,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 6.129 |  Acc: 40.220,59.570,42.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 5.002 |  Acc: 48.414,67.356,47.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 5.855 |  Acc: 44.030,60.720,42.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 4.979 |  Acc: 48.712,67.852,47.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 6.044 |  Acc: 43.810,59.580,40.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 4.942 |  Acc: 48.750,67.768,48.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 6.219 |  Acc: 40.950,58.830,40.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 4.885 |  Acc: 48.910,68.322,48.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 6.246 |  Acc: 40.240,57.930,40.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 4.888 |  Acc: 49.040,68.272,49.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 5.813 |  Acc: 44.500,60.860,43.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 5.015 |  Acc: 48.302,67.414,47.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 5.997 |  Acc: 41.940,59.500,43.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 4.935 |  Acc: 48.934,68.090,48.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 5.947 |  Acc: 42.020,59.720,43.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 4.910 |  Acc: 48.786,68.064,48.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 6.221 |  Acc: 40.430,58.170,41.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 4.955 |  Acc: 48.552,67.802,48.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 5.793 |  Acc: 43.360,60.210,45.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 4.866 |  Acc: 49.230,68.488,49.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 5.948 |  Acc: 43.300,59.710,43.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 4.886 |  Acc: 49.112,68.444,49.156,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 5.859 |  Acc: 42.690,60.820,44.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 4.878 |  Acc: 49.000,68.148,49.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 5.794 |  Acc: 43.860,61.370,44.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 4.877 |  Acc: 48.926,68.328,49.892,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 5.939 |  Acc: 41.580,60.480,43.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 4.884 |  Acc: 49.076,68.108,49.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 5.995 |  Acc: 41.950,59.950,43.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 4.939 |  Acc: 48.656,67.972,49.308,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 5.861 |  Acc: 42.350,60.330,44.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 4.898 |  Acc: 48.994,68.158,49.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 6.222 |  Acc: 41.070,58.860,42.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 4.972 |  Acc: 48.462,67.478,48.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 5.904 |  Acc: 42.450,60.200,42.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 4.925 |  Acc: 48.604,67.762,49.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 6.447 |  Acc: 40.990,57.290,40.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 4.953 |  Acc: 48.674,67.594,49.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 6.667 |  Acc: 40.060,54.470,37.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 5.051 |  Acc: 48.366,66.842,47.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 6.094 |  Acc: 42.510,58.420,41.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 4.877 |  Acc: 48.694,68.132,49.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 6.119 |  Acc: 41.620,59.470,41.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 4.894 |  Acc: 49.006,68.266,49.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 5.987 |  Acc: 42.540,59.430,43.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 4.846 |  Acc: 49.142,68.458,50.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 5.745 |  Acc: 44.610,61.420,44.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 4.880 |  Acc: 48.748,68.124,50.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 6.196 |  Acc: 41.810,59.970,39.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 4.993 |  Acc: 48.508,67.148,48.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 5.974 |  Acc: 42.220,59.580,43.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 4.944 |  Acc: 48.400,67.600,49.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 6.331 |  Acc: 40.310,56.740,41.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 4.973 |  Acc: 48.444,67.532,49.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 6.350 |  Acc: 40.690,57.380,40.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 4.944 |  Acc: 48.582,67.358,49.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 6.569 |  Acc: 40.120,56.910,40.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 4.943 |  Acc: 48.718,67.578,49.304,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 6.469 |  Acc: 39.810,56.440,40.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 4.944 |  Acc: 48.284,67.396,49.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 5.923 |  Acc: 43.620,59.530,43.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 4.939 |  Acc: 48.408,67.576,49.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 6.128 |  Acc: 40.180,58.420,43.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 5.003 |  Acc: 47.924,66.884,49.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 6.053 |  Acc: 42.020,58.920,43.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 5.078 |  Acc: 47.396,66.390,48.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 6.322 |  Acc: 39.840,56.200,41.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 4.922 |  Acc: 48.330,67.658,50.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 6.131 |  Acc: 41.750,58.810,40.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 4.960 |  Acc: 48.300,67.310,49.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 5.970 |  Acc: 42.750,59.740,44.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 4.851 |  Acc: 48.748,68.198,50.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 6.278 |  Acc: 39.410,57.940,42.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 4.655 |  Acc: 49.748,69.978,53.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 5.488 |  Acc: 45.820,62.270,47.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 4.522 |  Acc: 50.260,70.706,55.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 5.445 |  Acc: 45.790,62.460,48.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 4.470 |  Acc: 50.498,70.960,56.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 5.416 |  Acc: 45.860,62.990,49.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 4.426 |  Acc: 51.046,71.350,56.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 5.406 |  Acc: 45.680,63.380,49.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 4.418 |  Acc: 50.958,71.556,56.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 5.368 |  Acc: 45.980,63.290,49.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 4.403 |  Acc: 50.702,71.638,57.146,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 5.382 |  Acc: 45.880,63.100,49.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 4.387 |  Acc: 51.010,71.728,57.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 5.389 |  Acc: 46.130,63.460,49.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 4.389 |  Acc: 50.938,71.962,57.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 5.375 |  Acc: 46.070,63.340,49.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 4.360 |  Acc: 51.188,71.826,58.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 5.358 |  Acc: 46.070,63.580,50.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 4.355 |  Acc: 51.060,72.186,58.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 5.382 |  Acc: 46.100,63.260,49.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 4.375 |  Acc: 51.024,71.800,57.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 5.402 |  Acc: 45.640,63.200,49.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 4.353 |  Acc: 51.138,72.282,58.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 5.356 |  Acc: 46.230,63.700,49.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 4.350 |  Acc: 51.084,72.074,58.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 5.367 |  Acc: 46.010,63.960,49.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 4.348 |  Acc: 50.966,72.094,58.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 5.369 |  Acc: 45.750,63.790,49.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 4.331 |  Acc: 51.076,72.258,58.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 5.383 |  Acc: 46.080,63.660,50.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 4.332 |  Acc: 51.046,72.222,58.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 5.381 |  Acc: 46.410,63.500,50.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 4.330 |  Acc: 51.070,72.072,58.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 5.362 |  Acc: 46.170,63.460,50.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 4.318 |  Acc: 51.348,72.094,58.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 5.366 |  Acc: 46.450,63.500,50.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 4.321 |  Acc: 50.906,72.452,58.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 5.376 |  Acc: 46.020,63.360,50.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 4.303 |  Acc: 51.392,72.306,58.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 5.372 |  Acc: 46.020,63.210,50.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 4.318 |  Acc: 50.994,72.118,58.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 5.366 |  Acc: 46.020,63.570,50.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 4.287 |  Acc: 51.352,72.640,59.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 5.352 |  Acc: 46.260,63.410,50.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 4.271 |  Acc: 51.166,72.488,59.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 5.330 |  Acc: 46.170,63.600,50.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 4.283 |  Acc: 51.422,72.480,59.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 5.367 |  Acc: 45.920,63.690,50.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 4.290 |  Acc: 51.376,72.662,59.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 5.384 |  Acc: 45.930,63.990,50.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 4.272 |  Acc: 51.394,72.380,59.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 5.371 |  Acc: 46.220,63.590,50.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 4.274 |  Acc: 51.152,72.712,59.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 5.353 |  Acc: 45.990,63.950,50.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 4.278 |  Acc: 51.392,72.464,59.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 5.353 |  Acc: 45.950,63.730,51.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 4.263 |  Acc: 50.912,72.804,59.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 5.367 |  Acc: 46.070,63.750,50.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 4.264 |  Acc: 51.488,72.720,59.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 5.331 |  Acc: 46.400,63.960,50.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 4.262 |  Acc: 51.082,72.736,59.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 5.341 |  Acc: 45.960,63.880,50.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 4.272 |  Acc: 51.110,72.604,59.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 5.359 |  Acc: 46.100,63.720,50.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 4.282 |  Acc: 51.330,72.642,59.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 5.382 |  Acc: 46.080,63.370,50.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 4.257 |  Acc: 51.240,72.776,60.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 5.367 |  Acc: 46.210,63.780,51.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 4.261 |  Acc: 51.142,72.664,59.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 5.350 |  Acc: 45.990,63.690,50.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 4.249 |  Acc: 51.392,72.660,60.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 5.364 |  Acc: 46.090,63.820,50.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 4.245 |  Acc: 51.472,72.678,59.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 5.386 |  Acc: 45.950,63.600,50.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 4.250 |  Acc: 51.254,72.778,59.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 5.349 |  Acc: 46.220,63.750,50.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 4.221 |  Acc: 51.534,72.882,60.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 5.344 |  Acc: 46.120,64.040,50.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 4.214 |  Acc: 51.182,73.088,60.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 5.325 |  Acc: 46.280,63.680,50.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 4.208 |  Acc: 51.686,73.202,60.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 5.328 |  Acc: 46.470,63.860,51.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 4.202 |  Acc: 51.366,73.090,60.346,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 5.339 |  Acc: 46.170,63.670,51.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 4.191 |  Acc: 51.490,73.130,60.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 5.327 |  Acc: 46.150,63.910,51.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 4.210 |  Acc: 51.526,73.064,60.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 5.308 |  Acc: 46.120,64.010,51.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 4.192 |  Acc: 51.320,73.424,60.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 5.322 |  Acc: 46.370,63.960,50.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 4.183 |  Acc: 51.456,73.114,60.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 5.317 |  Acc: 46.300,63.940,51.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 4.187 |  Acc: 51.722,73.166,60.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 5.325 |  Acc: 46.360,64.020,50.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 4.182 |  Acc: 51.532,73.316,60.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 5.320 |  Acc: 46.450,63.910,51.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 4.188 |  Acc: 51.690,73.426,60.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 5.317 |  Acc: 46.520,64.030,51.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 4.179 |  Acc: 51.804,73.330,60.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 5.316 |  Acc: 46.370,63.880,50.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 4.169 |  Acc: 51.526,73.322,61.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 5.319 |  Acc: 46.490,63.940,51.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 4.173 |  Acc: 51.830,73.490,61.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 5.315 |  Acc: 46.170,63.740,51.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 4.168 |  Acc: 51.656,73.158,60.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 5.301 |  Acc: 46.300,64.050,51.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 4.178 |  Acc: 51.318,73.292,60.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 5.326 |  Acc: 46.380,63.860,51.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 4.162 |  Acc: 51.694,73.566,61.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 5.320 |  Acc: 46.230,63.780,51.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 4.171 |  Acc: 51.828,73.192,60.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 5.317 |  Acc: 46.180,63.780,51.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 4.175 |  Acc: 51.466,73.262,61.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 5.317 |  Acc: 46.070,63.770,51.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 4.164 |  Acc: 51.666,73.312,60.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 5.300 |  Acc: 46.210,64.080,51.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 4.160 |  Acc: 51.828,73.440,61.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 5.306 |  Acc: 46.070,63.730,51.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 4.173 |  Acc: 51.424,73.364,60.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 5.294 |  Acc: 46.390,64.040,51.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 4.166 |  Acc: 51.562,73.498,61.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 5.307 |  Acc: 46.110,64.120,51.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 4.173 |  Acc: 51.650,73.452,60.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 5.307 |  Acc: 46.010,64.030,51.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 4.158 |  Acc: 51.726,73.476,61.256,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 5.312 |  Acc: 46.270,63.990,51.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 4.165 |  Acc: 51.750,73.394,61.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 5.311 |  Acc: 46.420,63.860,51.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 4.143 |  Acc: 51.742,73.600,61.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 5.293 |  Acc: 46.170,64.000,51.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 4.159 |  Acc: 51.754,73.340,61.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 5.321 |  Acc: 46.070,64.030,51.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 4.158 |  Acc: 51.702,73.426,61.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 5.320 |  Acc: 46.270,63.930,51.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 4.156 |  Acc: 51.890,73.328,61.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 5.326 |  Acc: 46.110,63.690,51.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 4.155 |  Acc: 51.894,73.336,61.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 5.317 |  Acc: 46.300,64.030,51.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 4.153 |  Acc: 51.758,73.456,61.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 5.324 |  Acc: 46.290,63.750,51.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 4.141 |  Acc: 51.542,73.418,61.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 5.310 |  Acc: 46.150,63.940,51.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 4.165 |  Acc: 51.560,73.490,60.912,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 5.309 |  Acc: 46.480,64.040,51.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 4.156 |  Acc: 51.570,73.458,61.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 5.319 |  Acc: 46.060,63.970,51.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 4.167 |  Acc: 51.516,73.372,61.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 5.315 |  Acc: 46.150,63.660,51.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 4.157 |  Acc: 51.664,73.580,61.206,% | Adaptive Acc:67.056% | clf_exit: 0.346 0.363 0.291
Testing: Epoch=299 | Loss: 5.330 |  Acc: 46.230,63.660,51.040,% | Adaptive Acc:58.220% | clf_exit: 0.399 0.313 0.288

circles: 0
Testing: Epoch=299 | Loss: 143.235 |  Acc: 1.000,1.030,1.000,% | Adaptive Acc:1.000% | clf_exit: 1.000 0.000 0.000
circles: 1
Testing: Epoch=299 | Loss: 117.968 |  Acc: 1.000,1.290,1.000,% | Adaptive Acc:1.000% | clf_exit: 1.000 0.000 0.000
circles: 2
Testing: Epoch=299 | Loss: 100.246 |  Acc: 1.040,2.440,1.000,% | Adaptive Acc:1.040% | clf_exit: 1.000 0.000 0.000
circles: 3
Testing: Epoch=299 | Loss: 82.997 |  Acc: 1.390,1.900,1.000,% | Adaptive Acc:1.390% | clf_exit: 1.000 0.001 0.000
circles: 4
Testing: Epoch=299 | Loss: 67.352 |  Acc: 1.730,1.780,1.000,% | Adaptive Acc:1.730% | clf_exit: 0.998 0.002 0.000
circles: 5
Testing: Epoch=299 | Loss: 53.384 |  Acc: 1.910,3.130,1.000,% | Adaptive Acc:1.910% | clf_exit: 0.987 0.008 0.005
circles: 6
Testing: Epoch=299 | Loss: 39.827 |  Acc: 2.840,9.040,1.000,% | Adaptive Acc:3.070% | clf_exit: 0.917 0.015 0.068
circles: 7
Testing: Epoch=299 | Loss: 24.266 |  Acc: 10.670,36.940,1.000,% | Adaptive Acc:15.930% | clf_exit: 0.638 0.128 0.234
circles: 8
Testing: Epoch=299 | Loss: 5.330 |  Acc: 46.230,63.660,51.040,% | Adaptive Acc:58.220% | clf_exit: 0.399 0.313 0.288
