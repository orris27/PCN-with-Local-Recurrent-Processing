==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=32, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=16, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=32, out_features=100, bias=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=64, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=64, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
    (2): ClassifierModule2(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=128, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=128, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.158 | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.711 | Acc: 0.744,1.376,1.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.458 | Acc: 1.067,1.448,1.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.262 | Acc: 1.140,1.511,2.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.127 | Acc: 1.370,1.813,2.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.028 | Acc: 1.416,2.081,2.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.936 | Acc: 1.537,2.195,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.857 | Acc: 1.640,2.294,3.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.779 | Acc: 1.727,2.455,3.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.703 | Acc: 1.847,2.594,3.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.636 | Acc: 1.873,2.756,3.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.570 | Acc: 1.990,2.941,4.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.515 | Acc: 2.052,3.109,4.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.461 | Acc: 2.116,3.185,4.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.406 | Acc: 2.199,3.322,4.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.357 | Acc: 2.274,3.439,5.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.306 | Acc: 2.310,3.597,5.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.261 | Acc: 2.339,3.709,5.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.214 | Acc: 2.391,3.859,5.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.172 | Acc: 2.452,3.994,6.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.108 | Acc: 2.344,9.375,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.406 | Acc: 3.423,6.324,9.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.394 | Acc: 3.335,6.136,9.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.409 | Acc: 3.317,6.084,9.324,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 12.443 | Acc: 2.344,6.250,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.379 | Acc: 2.716,6.473,10.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.271 | Acc: 3.201,7.165,11.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.257 | Acc: 3.317,7.428,11.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.244 | Acc: 3.530,7.494,11.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.227 | Acc: 3.496,7.681,11.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.223 | Acc: 3.590,7.696,11.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.195 | Acc: 3.707,7.824,11.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.168 | Acc: 3.833,7.944,11.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.153 | Acc: 3.932,7.916,11.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.135 | Acc: 3.961,8.030,11.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.117 | Acc: 4.016,8.099,11.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.102 | Acc: 4.059,8.192,11.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.081 | Acc: 4.182,8.318,11.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.059 | Acc: 4.218,8.399,11.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.031 | Acc: 4.309,8.565,12.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.008 | Acc: 4.357,8.662,12.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.984 | Acc: 4.481,8.779,12.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.956 | Acc: 4.592,8.912,12.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.932 | Acc: 4.690,9.090,12.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.833 | Acc: 3.125,7.031,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.865 | Acc: 4.576,9.077,13.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.830 | Acc: 4.688,9.013,13.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.818 | Acc: 4.867,9.439,12.871,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 11.429 | Acc: 8.594,11.719,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.505 | Acc: 6.138,11.793,14.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.481 | Acc: 6.250,11.585,15.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.438 | Acc: 6.276,11.642,15.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.422 | Acc: 6.375,11.873,15.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.398 | Acc: 6.405,12.136,15.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.387 | Acc: 6.515,12.255,16.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.390 | Acc: 6.494,12.079,15.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.372 | Acc: 6.628,12.092,15.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.345 | Acc: 6.828,12.254,16.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.332 | Acc: 6.891,12.278,16.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.321 | Acc: 6.862,12.387,16.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.303 | Acc: 6.892,12.539,16.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.289 | Acc: 6.941,12.599,16.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.275 | Acc: 6.965,12.625,16.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.261 | Acc: 7.057,12.658,16.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.244 | Acc: 7.155,12.782,16.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.226 | Acc: 7.221,12.834,16.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.214 | Acc: 7.289,12.874,16.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.195 | Acc: 7.314,13.004,17.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.224 | Acc: 8.594,13.281,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.203 | Acc: 7.664,12.016,16.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.150 | Acc: 8.175,11.947,16.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.137 | Acc: 8.235,11.898,16.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 11.023 | Acc: 9.375,12.500,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.835 | Acc: 8.408,14.397,18.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.861 | Acc: 8.251,14.482,19.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.790 | Acc: 8.274,14.946,19.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.777 | Acc: 8.372,15.162,19.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.771 | Acc: 8.416,15.184,19.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.752 | Acc: 8.645,15.373,19.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.737 | Acc: 8.677,15.525,19.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.727 | Acc: 8.676,15.475,19.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.703 | Acc: 8.831,15.573,20.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.681 | Acc: 8.877,15.718,20.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.656 | Acc: 8.968,15.816,20.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.642 | Acc: 9.015,15.926,20.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.624 | Acc: 9.159,16.008,20.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.609 | Acc: 9.311,16.078,20.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.593 | Acc: 9.435,16.217,20.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.573 | Acc: 9.502,16.319,20.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.558 | Acc: 9.581,16.367,20.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.544 | Acc: 9.633,16.452,21.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.531 | Acc: 9.652,16.505,21.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.462 | Acc: 10.156,15.625,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.753 | Acc: 8.259,14.472,20.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.671 | Acc: 8.784,15.034,21.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.668 | Acc: 8.927,15.446,20.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 10.195 | Acc: 13.281,17.188,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.200 | Acc: 11.012,18.304,23.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.152 | Acc: 11.700,18.750,23.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.160 | Acc: 11.373,18.942,23.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.125 | Acc: 11.699,19.001,24.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.126 | Acc: 11.641,18.959,24.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.118 | Acc: 11.906,18.989,23.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.111 | Acc: 11.852,18.972,23.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.102 | Acc: 11.874,18.983,23.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.087 | Acc: 11.917,19.048,23.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.078 | Acc: 11.890,19.100,23.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.078 | Acc: 11.846,19.065,23.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.065 | Acc: 11.936,19.100,23.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.061 | Acc: 11.889,19.031,23.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.037 | Acc: 11.958,19.287,23.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.031 | Acc: 12.017,19.264,23.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.018 | Acc: 12.135,19.305,23.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.997 | Acc: 12.275,19.440,24.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.992 | Acc: 12.277,19.436,24.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.984 | Acc: 12.346,19.478,24.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.954 | Acc: 12.500,20.312,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.182 | Acc: 10.565,17.076,23.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.132 | Acc: 10.938,17.607,23.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.132 | Acc: 10.758,17.802,23.450,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 9.546 | Acc: 11.719,18.750,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.733 | Acc: 13.914,20.647,25.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.724 | Acc: 13.338,20.713,26.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.711 | Acc: 13.294,20.914,25.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.697 | Acc: 13.146,21.123,26.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.682 | Acc: 13.359,21.032,26.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.661 | Acc: 13.410,21.100,26.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.645 | Acc: 13.619,21.221,26.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.628 | Acc: 13.771,21.283,26.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.601 | Acc: 13.937,21.405,26.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.592 | Acc: 14.055,21.444,26.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.582 | Acc: 14.151,21.557,26.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.575 | Acc: 14.260,21.687,26.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.561 | Acc: 14.281,21.761,26.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.553 | Acc: 14.293,21.747,26.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.551 | Acc: 14.288,21.763,26.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.548 | Acc: 14.323,21.846,26.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.543 | Acc: 14.296,21.866,27.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.531 | Acc: 14.355,21.914,27.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.518 | Acc: 14.425,22.019,27.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.487 | Acc: 15.625,24.219,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.457 | Acc: 13.876,21.763,27.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.440 | Acc: 13.834,21.437,28.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.456 | Acc: 13.563,21.709,28.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 9.262 | Acc: 10.156,23.438,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.243 | Acc: 15.253,23.847,30.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.192 | Acc: 16.235,24.238,29.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.209 | Acc: 15.715,23.847,29.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.227 | Acc: 15.664,23.505,29.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.244 | Acc: 15.702,23.832,29.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.249 | Acc: 15.619,23.683,29.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.225 | Acc: 15.797,23.825,29.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.212 | Acc: 15.853,23.952,29.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.206 | Acc: 15.901,24.068,29.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.214 | Acc: 15.831,23.966,29.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.199 | Acc: 15.971,23.993,29.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.199 | Acc: 16.063,24.018,29.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.178 | Acc: 16.278,24.240,29.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.166 | Acc: 16.270,24.288,29.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.165 | Acc: 16.253,24.211,29.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.156 | Acc: 16.324,24.199,29.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.146 | Acc: 16.374,24.258,29.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.136 | Acc: 16.443,24.353,30.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.121 | Acc: 16.505,24.424,30.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.921 | Acc: 17.188,24.219,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.588 | Acc: 12.835,21.391,29.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.616 | Acc: 12.576,21.399,29.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.603 | Acc: 12.462,21.235,29.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 9.224 | Acc: 14.844,25.000,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.885 | Acc: 17.894,25.521,31.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.883 | Acc: 17.492,25.419,31.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.900 | Acc: 17.469,24.987,31.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.897 | Acc: 17.236,25.386,31.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.874 | Acc: 17.234,25.596,31.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.857 | Acc: 17.355,25.717,32.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.835 | Acc: 17.625,26.042,32.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.830 | Acc: 17.731,26.068,32.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.818 | Acc: 17.913,26.217,32.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.804 | Acc: 18.027,26.345,32.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.799 | Acc: 18.015,26.312,32.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.794 | Acc: 18.034,26.306,32.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.800 | Acc: 17.927,26.134,32.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.795 | Acc: 18.013,26.176,32.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.786 | Acc: 18.086,26.259,32.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.784 | Acc: 18.095,26.212,32.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.780 | Acc: 18.182,26.276,32.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.777 | Acc: 18.192,26.283,32.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.776 | Acc: 18.223,26.294,32.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.943 | Acc: 16.406,34.375,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.961 | Acc: 17.001,24.665,31.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.980 | Acc: 16.978,24.200,31.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.998 | Acc: 17.188,24.308,31.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 8.873 | Acc: 21.875,22.656,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.556 | Acc: 20.424,27.939,35.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.624 | Acc: 18.960,26.829,33.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.622 | Acc: 18.648,27.075,34.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.570 | Acc: 19.039,27.913,34.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.574 | Acc: 19.121,27.715,34.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.572 | Acc: 19.350,27.744,34.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.551 | Acc: 19.409,27.804,34.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.536 | Acc: 19.594,27.776,34.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.532 | Acc: 19.479,27.702,34.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.542 | Acc: 19.422,27.725,34.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.544 | Acc: 19.503,27.902,34.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.518 | Acc: 19.654,28.086,34.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.511 | Acc: 19.615,28.164,34.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.501 | Acc: 19.704,28.233,35.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.492 | Acc: 19.780,28.286,35.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.490 | Acc: 19.765,28.278,35.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.476 | Acc: 19.827,28.407,35.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.470 | Acc: 19.836,28.447,35.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.460 | Acc: 19.958,28.523,35.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.782 | Acc: 17.969,25.000,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.839 | Acc: 12.649,21.317,27.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.846 | Acc: 12.633,21.341,26.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.835 | Acc: 12.577,21.171,26.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 8.705 | Acc: 19.531,21.875,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.333 | Acc: 20.647,28.125,36.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.299 | Acc: 21.056,29.078,36.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.285 | Acc: 20.812,28.945,36.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.279 | Acc: 20.920,28.897,36.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.270 | Acc: 21.024,29.131,36.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.257 | Acc: 20.978,29.300,37.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.259 | Acc: 20.972,29.172,37.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.234 | Acc: 21.036,29.493,37.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.226 | Acc: 20.977,29.502,37.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.229 | Acc: 20.934,29.412,37.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.216 | Acc: 20.995,29.525,37.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.218 | Acc: 21.052,29.483,37.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.217 | Acc: 21.004,29.604,37.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.207 | Acc: 21.005,29.740,37.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.200 | Acc: 21.076,29.799,37.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.194 | Acc: 21.155,29.907,37.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.195 | Acc: 21.174,29.926,37.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.196 | Acc: 21.213,30.003,37.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.191 | Acc: 21.194,30.059,37.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.564 | Acc: 19.531,35.156,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.010 | Acc: 17.001,26.004,36.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.909 | Acc: 17.359,26.029,35.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.908 | Acc: 16.995,25.397,35.041,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 8.460 | Acc: 25.000,25.781,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.046 | Acc: 22.842,32.329,39.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.049 | Acc: 22.923,31.688,38.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.028 | Acc: 22.874,31.660,38.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.018 | Acc: 22.434,31.684,38.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.029 | Acc: 22.177,31.521,38.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.011 | Acc: 22.308,31.734,39.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.999 | Acc: 22.224,31.749,39.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.998 | Acc: 22.137,31.764,39.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.992 | Acc: 22.151,31.708,38.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.985 | Acc: 22.132,31.608,38.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.975 | Acc: 22.218,31.692,38.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.974 | Acc: 22.238,31.675,39.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.966 | Acc: 22.177,31.693,39.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.955 | Acc: 22.270,31.734,39.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.960 | Acc: 22.282,31.702,39.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.963 | Acc: 22.325,31.691,39.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.957 | Acc: 22.262,31.694,39.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.955 | Acc: 22.329,31.715,39.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.953 | Acc: 22.318,31.750,39.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.223 | Acc: 15.625,25.000,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.867 | Acc: 11.235,21.280,32.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.827 | Acc: 11.261,21.627,32.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.790 | Acc: 11.104,21.350,32.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 7.866 | Acc: 17.188,28.906,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.888 | Acc: 21.801,32.031,41.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.838 | Acc: 22.752,33.060,40.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.808 | Acc: 22.976,33.248,40.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.804 | Acc: 23.264,33.391,40.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.790 | Acc: 23.430,33.284,40.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.769 | Acc: 23.399,33.355,41.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.749 | Acc: 23.521,33.544,41.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.730 | Acc: 23.559,33.613,41.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.726 | Acc: 23.524,33.792,41.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.722 | Acc: 23.360,33.730,41.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.718 | Acc: 23.402,33.721,41.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.722 | Acc: 23.386,33.694,41.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.737 | Acc: 23.285,33.531,41.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.737 | Acc: 23.279,33.508,41.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.729 | Acc: 23.419,33.674,41.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.725 | Acc: 23.347,33.613,41.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.723 | Acc: 23.447,33.610,41.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.722 | Acc: 23.450,33.602,41.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.721 | Acc: 23.454,33.590,41.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.604 | Acc: 22.656,21.094,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.029 | Acc: 16.815,25.037,34.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.980 | Acc: 16.616,25.362,35.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.019 | Acc: 16.368,24.629,34.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 7.273 | Acc: 26.562,36.719,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.510 | Acc: 25.707,34.673,43.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.523 | Acc: 24.924,34.604,42.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.535 | Acc: 24.462,34.644,42.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.561 | Acc: 24.084,34.568,42.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.541 | Acc: 23.987,35.002,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.536 | Acc: 24.025,35.021,43.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.526 | Acc: 24.141,35.201,43.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.543 | Acc: 24.010,34.986,42.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.543 | Acc: 24.042,34.945,42.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.535 | Acc: 23.974,34.931,42.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.521 | Acc: 24.070,35.096,42.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.531 | Acc: 24.209,35.078,42.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.527 | Acc: 24.231,35.177,42.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.529 | Acc: 24.160,35.198,43.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.531 | Acc: 24.149,35.195,42.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.540 | Acc: 24.109,35.103,42.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.540 | Acc: 24.013,35.076,42.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.530 | Acc: 24.152,35.221,42.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.524 | Acc: 24.131,35.238,42.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.014 | Acc: 17.969,29.688,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.175 | Acc: 15.402,26.376,33.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.107 | Acc: 15.187,26.848,32.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.122 | Acc: 15.010,26.370,32.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 7.056 | Acc: 25.781,41.406,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.417 | Acc: 24.144,35.900,43.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.344 | Acc: 24.924,36.223,44.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.386 | Acc: 25.000,35.899,44.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.400 | Acc: 25.048,35.976,44.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.415 | Acc: 25.046,35.837,44.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.410 | Acc: 25.045,35.699,44.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.409 | Acc: 25.055,35.949,44.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.404 | Acc: 25.126,36.059,44.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.405 | Acc: 25.091,36.002,44.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.395 | Acc: 25.140,36.066,44.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.388 | Acc: 25.028,36.072,44.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.383 | Acc: 25.039,36.245,44.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.384 | Acc: 24.952,36.135,44.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.370 | Acc: 25.145,36.224,44.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.367 | Acc: 25.145,36.226,44.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.364 | Acc: 25.161,36.266,44.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.360 | Acc: 25.174,36.235,44.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.359 | Acc: 25.195,36.251,44.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.356 | Acc: 25.160,36.255,44.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.808 | Acc: 21.094,25.000,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.533 | Acc: 14.955,25.000,35.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.693 | Acc: 15.263,24.543,34.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.701 | Acc: 15.049,24.168,34.273,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 7.329 | Acc: 23.438,39.844,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.345 | Acc: 25.223,37.351,45.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.299 | Acc: 25.572,37.100,45.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.278 | Acc: 25.730,37.462,45.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.266 | Acc: 25.714,37.240,45.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.256 | Acc: 25.565,37.144,45.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.239 | Acc: 25.807,37.390,45.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.219 | Acc: 26.180,37.483,45.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.222 | Acc: 26.121,37.456,45.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.209 | Acc: 26.187,37.565,45.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.212 | Acc: 26.197,37.636,45.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.207 | Acc: 26.163,37.701,45.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.197 | Acc: 26.131,37.801,45.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.204 | Acc: 26.140,37.736,45.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.205 | Acc: 26.107,37.778,45.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.195 | Acc: 26.126,37.923,45.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.193 | Acc: 26.027,37.921,45.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.187 | Acc: 26.063,37.924,45.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.185 | Acc: 26.056,37.937,45.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.187 | Acc: 26.025,37.914,45.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.591 | Acc: 16.406,30.469,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.404 | Acc: 17.225,31.399,40.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.433 | Acc: 17.149,30.831,39.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.438 | Acc: 16.931,30.751,39.716,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 7.490 | Acc: 24.219,36.719,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.959 | Acc: 27.976,39.695,47.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.970 | Acc: 27.287,39.425,47.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.028 | Acc: 26.960,39.191,47.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.986 | Acc: 27.016,39.352,47.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.975 | Acc: 27.042,39.411,47.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.968 | Acc: 27.111,39.424,47.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.986 | Acc: 26.900,39.240,47.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.992 | Acc: 26.994,39.436,47.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.990 | Acc: 27.024,39.434,47.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.001 | Acc: 27.095,39.358,47.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.014 | Acc: 26.990,39.186,47.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.012 | Acc: 26.974,39.169,47.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.010 | Acc: 26.985,39.167,47.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.007 | Acc: 26.982,39.171,47.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.999 | Acc: 26.978,39.322,47.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.006 | Acc: 26.974,39.272,47.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.006 | Acc: 26.952,39.342,47.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.001 | Acc: 27.056,39.311,47.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.007 | Acc: 27.020,39.272,47.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.583 | Acc: 16.406,25.781,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.904 | Acc: 17.783,27.753,39.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.779 | Acc: 17.645,28.601,39.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.773 | Acc: 17.354,28.522,39.178,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 6.997 | Acc: 28.125,41.406,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.831 | Acc: 25.260,39.732,49.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.856 | Acc: 26.010,39.310,48.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.886 | Acc: 27.241,39.895,48.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.912 | Acc: 27.141,39.699,48.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.904 | Acc: 27.081,39.859,48.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.886 | Acc: 27.066,39.966,48.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.866 | Acc: 27.183,40.204,48.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.866 | Acc: 27.290,40.130,48.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.861 | Acc: 27.469,40.064,48.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.865 | Acc: 27.456,40.162,48.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.859 | Acc: 27.574,40.176,48.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.854 | Acc: 27.571,40.077,48.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.859 | Acc: 27.535,40.095,48.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.861 | Acc: 27.563,40.061,48.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.860 | Acc: 27.660,40.197,48.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.876 | Acc: 27.648,40.124,48.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.882 | Acc: 27.587,40.114,48.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.878 | Acc: 27.625,40.116,48.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.885 | Acc: 27.606,40.164,48.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.942 | Acc: 23.438,34.375,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.297 | Acc: 19.308,33.036,42.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.237 | Acc: 18.979,33.136,42.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.230 | Acc: 18.763,33.005,42.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 6.369 | Acc: 26.562,39.844,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.671 | Acc: 28.795,41.443,50.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.690 | Acc: 29.230,41.883,50.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.690 | Acc: 28.727,41.573,50.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.706 | Acc: 28.839,41.532,50.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.699 | Acc: 28.891,41.816,50.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.727 | Acc: 28.738,41.348,49.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.752 | Acc: 28.585,41.201,49.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.747 | Acc: 28.712,41.314,49.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.748 | Acc: 28.790,41.467,49.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.755 | Acc: 28.867,41.453,49.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.759 | Acc: 28.874,41.445,49.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.775 | Acc: 28.725,41.283,49.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.779 | Acc: 28.745,41.331,49.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.785 | Acc: 28.581,41.276,49.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.788 | Acc: 28.558,41.251,48.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.789 | Acc: 28.439,41.202,48.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.801 | Acc: 28.382,41.184,48.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.790 | Acc: 28.430,41.318,48.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.784 | Acc: 28.435,41.380,48.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.133 | Acc: 26.562,40.625,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.402 | Acc: 22.656,37.760,46.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.368 | Acc: 23.247,37.824,46.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.364 | Acc: 23.399,37.154,46.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 6.743 | Acc: 28.906,40.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.578 | Acc: 30.283,43.824,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.554 | Acc: 29.497,43.979,51.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.569 | Acc: 29.598,43.878,51.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.611 | Acc: 29.070,43.605,51.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.620 | Acc: 29.192,43.386,51.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.627 | Acc: 29.197,43.221,50.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.636 | Acc: 29.156,42.908,50.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.640 | Acc: 29.178,42.770,50.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.637 | Acc: 29.338,42.731,50.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.635 | Acc: 29.384,42.743,50.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.651 | Acc: 29.341,42.580,49.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.651 | Acc: 29.370,42.541,50.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.646 | Acc: 29.355,42.604,50.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.636 | Acc: 29.440,42.630,50.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.640 | Acc: 29.402,42.629,50.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.641 | Acc: 29.303,42.613,50.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.634 | Acc: 29.293,42.664,50.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.636 | Acc: 29.162,42.558,50.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.634 | Acc: 29.165,42.534,50.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.281 | Acc: 27.344,40.625,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.725 | Acc: 21.429,35.975,45.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.704 | Acc: 21.303,35.442,45.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.725 | Acc: 21.068,35.041,45.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 6.843 | Acc: 25.781,41.406,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.379 | Acc: 30.060,45.573,52.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.404 | Acc: 30.240,44.512,52.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.507 | Acc: 29.892,44.173,51.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.529 | Acc: 29.475,43.875,51.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.515 | Acc: 29.533,43.936,51.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.491 | Acc: 29.578,44.002,51.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.496 | Acc: 29.660,43.977,51.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.503 | Acc: 29.459,43.866,51.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.517 | Acc: 29.416,43.836,51.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.536 | Acc: 29.318,43.610,51.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.544 | Acc: 29.334,43.552,51.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.535 | Acc: 29.451,43.711,51.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.522 | Acc: 29.538,43.819,51.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.525 | Acc: 29.471,43.675,51.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.524 | Acc: 29.475,43.493,51.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.528 | Acc: 29.420,43.458,51.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.529 | Acc: 29.431,43.470,51.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.531 | Acc: 29.406,43.443,51.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.529 | Acc: 29.452,43.477,51.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.558 | Acc: 24.219,36.719,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.723 | Acc: 23.884,37.314,44.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.702 | Acc: 23.590,36.947,43.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.691 | Acc: 23.156,36.450,44.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 6.194 | Acc: 29.688,44.531,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.366 | Acc: 30.506,44.643,52.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.443 | Acc: 29.954,43.979,51.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.377 | Acc: 30.264,44.787,52.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.388 | Acc: 30.112,44.753,52.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.400 | Acc: 30.221,44.678,52.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.403 | Acc: 30.372,44.641,52.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.401 | Acc: 30.424,44.542,52.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.413 | Acc: 30.216,44.347,52.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.411 | Acc: 30.335,44.445,52.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.414 | Acc: 30.267,44.407,52.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.411 | Acc: 30.334,44.393,52.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.419 | Acc: 30.323,44.291,52.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.418 | Acc: 30.283,44.277,52.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.413 | Acc: 30.302,44.367,52.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.407 | Acc: 30.274,44.425,52.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.409 | Acc: 30.218,44.424,52.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.409 | Acc: 30.210,44.490,52.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.411 | Acc: 30.244,44.518,52.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.415 | Acc: 30.253,44.492,52.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.969 | Acc: 28.125,43.750,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.199 | Acc: 25.335,38.095,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.206 | Acc: 25.819,37.481,48.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.159 | Acc: 26.127,37.961,48.770,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 7.054 | Acc: 27.344,35.938,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.365 | Acc: 30.171,45.275,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.355 | Acc: 29.364,45.541,54.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.392 | Acc: 29.457,45.428,54.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.367 | Acc: 29.832,45.457,53.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.371 | Acc: 29.680,45.135,53.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.356 | Acc: 30.178,45.480,53.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.354 | Acc: 30.264,45.506,53.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.345 | Acc: 30.343,45.410,53.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.331 | Acc: 30.348,45.537,53.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.336 | Acc: 30.399,45.480,53.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.328 | Acc: 30.462,45.482,53.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.321 | Acc: 30.475,45.507,53.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.329 | Acc: 30.517,45.462,53.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.334 | Acc: 30.524,45.360,53.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.333 | Acc: 30.612,45.393,53.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.328 | Acc: 30.700,45.446,53.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.325 | Acc: 30.705,45.448,53.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.318 | Acc: 30.813,45.466,53.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.325 | Acc: 30.782,45.399,53.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.304 | Acc: 29.688,46.094,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.658 | Acc: 23.103,38.802,45.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.667 | Acc: 22.809,36.757,45.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.634 | Acc: 22.951,35.899,45.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 6.529 | Acc: 29.688,46.094,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.166 | Acc: 33.371,47.879,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.269 | Acc: 31.555,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.232 | Acc: 32.057,45.940,54.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.226 | Acc: 31.887,45.910,54.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.221 | Acc: 31.877,46.163,54.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.248 | Acc: 31.650,45.939,54.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.227 | Acc: 31.810,46.271,54.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.230 | Acc: 31.609,46.176,54.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.218 | Acc: 31.621,46.228,54.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.219 | Acc: 31.600,46.179,54.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.226 | Acc: 31.494,46.065,54.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.217 | Acc: 31.545,46.032,54.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.214 | Acc: 31.666,46.073,54.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.218 | Acc: 31.714,46.069,54.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.213 | Acc: 31.691,46.127,54.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.212 | Acc: 31.637,46.106,54.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.213 | Acc: 31.639,46.160,54.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.218 | Acc: 31.616,46.148,54.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.218 | Acc: 31.594,46.086,54.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.043 | Acc: 19.531,33.594,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.330 | Acc: 20.945,32.515,42.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.396 | Acc: 20.903,31.936,41.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.383 | Acc: 21.017,31.916,41.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 6.668 | Acc: 31.250,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.236 | Acc: 31.213,45.610,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.166 | Acc: 32.260,46.399,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.129 | Acc: 32.159,46.773,55.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.121 | Acc: 31.964,46.875,55.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.102 | Acc: 32.031,47.107,55.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.108 | Acc: 32.135,47.017,55.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.086 | Acc: 32.098,47.257,55.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.067 | Acc: 32.274,47.569,55.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.077 | Acc: 32.286,47.535,55.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.089 | Acc: 32.187,47.306,55.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.102 | Acc: 32.176,47.172,55.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.105 | Acc: 32.167,47.222,55.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.109 | Acc: 32.055,47.219,55.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.113 | Acc: 31.976,47.150,55.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.116 | Acc: 32.031,47.129,55.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.111 | Acc: 32.082,47.213,55.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.120 | Acc: 32.072,47.209,55.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.126 | Acc: 32.005,47.191,55.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.128 | Acc: 31.998,47.142,55.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.524 | Acc: 22.656,43.750,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.794 | Acc: 22.135,36.421,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.823 | Acc: 22.085,36.071,44.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.837 | Acc: 21.683,35.669,44.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 6.070 | Acc: 33.594,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.065 | Acc: 31.882,47.433,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.041 | Acc: 32.565,47.485,56.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.076 | Acc: 31.890,47.157,55.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.086 | Acc: 31.655,47.492,55.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.105 | Acc: 31.474,47.370,55.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.098 | Acc: 31.650,47.592,55.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.078 | Acc: 31.815,47.773,55.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.080 | Acc: 31.861,47.923,55.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.066 | Acc: 31.725,47.898,55.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.058 | Acc: 31.767,48.010,55.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.069 | Acc: 31.720,47.886,55.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.064 | Acc: 31.869,48.058,55.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.062 | Acc: 32.052,48.024,55.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.064 | Acc: 31.967,48.057,55.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.050 | Acc: 32.083,48.188,55.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.059 | Acc: 32.036,48.070,55.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.065 | Acc: 32.036,47.991,55.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.067 | Acc: 32.044,47.959,55.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.069 | Acc: 32.033,47.915,55.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.224 | Acc: 26.562,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.556 | Acc: 24.330,36.942,46.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.560 | Acc: 24.714,36.681,46.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.549 | Acc: 24.590,36.668,46.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 5.738 | Acc: 31.250,50.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.683 | Acc: 35.417,51.265,60.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.832 | Acc: 34.718,49.829,57.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.892 | Acc: 33.722,49.424,57.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.900 | Acc: 33.738,49.383,57.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.927 | Acc: 33.563,49.165,57.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.949 | Acc: 33.387,48.941,57.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.957 | Acc: 33.234,48.820,56.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.962 | Acc: 33.075,48.898,56.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.967 | Acc: 32.977,48.744,56.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.984 | Acc: 32.902,48.597,56.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.981 | Acc: 32.936,48.551,56.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.979 | Acc: 33.017,48.470,56.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.976 | Acc: 32.968,48.494,56.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.981 | Acc: 32.960,48.449,56.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.988 | Acc: 32.864,48.409,56.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.985 | Acc: 32.900,48.474,56.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.980 | Acc: 32.849,48.467,56.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.985 | Acc: 32.830,48.444,56.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.996 | Acc: 32.761,48.345,55.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.945 | Acc: 24.219,40.625,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.098 | Acc: 24.665,42.113,49.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.115 | Acc: 23.895,41.273,48.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.101 | Acc: 23.489,40.958,48.527,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 6.381 | Acc: 39.062,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.878 | Acc: 33.222,48.921,58.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.859 | Acc: 32.965,49.581,58.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.863 | Acc: 33.184,49.526,58.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.842 | Acc: 33.758,50.000,57.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.845 | Acc: 33.710,49.830,57.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.849 | Acc: 33.458,49.832,57.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.864 | Acc: 33.516,49.701,57.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.896 | Acc: 33.506,49.437,57.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.896 | Acc: 33.425,49.322,57.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.900 | Acc: 33.329,49.324,56.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.897 | Acc: 33.318,49.406,57.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.904 | Acc: 33.351,49.293,56.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.911 | Acc: 33.264,49.213,56.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.910 | Acc: 33.196,49.213,56.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.921 | Acc: 33.119,49.099,56.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.929 | Acc: 33.092,49.085,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.927 | Acc: 33.042,49.084,56.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.929 | Acc: 33.057,49.074,56.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.927 | Acc: 33.085,49.094,56.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.527 | Acc: 20.312,42.188,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.673 | Acc: 19.829,40.141,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.730 | Acc: 19.970,39.653,47.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.727 | Acc: 20.197,38.998,48.207,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 5.248 | Acc: 32.812,57.031,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.816 | Acc: 33.296,49.665,57.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.750 | Acc: 33.727,49.962,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.793 | Acc: 33.338,49.155,57.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.777 | Acc: 33.488,49.489,57.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.777 | Acc: 33.694,49.776,57.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.787 | Acc: 33.729,49.897,57.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.786 | Acc: 33.511,50.006,58.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.796 | Acc: 33.472,50.204,58.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.802 | Acc: 33.404,50.129,58.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.801 | Acc: 33.465,50.128,58.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.820 | Acc: 33.382,49.972,57.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.824 | Acc: 33.409,49.867,57.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.819 | Acc: 33.417,49.979,57.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.824 | Acc: 33.427,49.953,57.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.824 | Acc: 33.615,49.990,57.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.837 | Acc: 33.555,49.835,57.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.838 | Acc: 33.619,49.867,57.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.841 | Acc: 33.602,49.825,57.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.842 | Acc: 33.618,49.783,57.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.912 | Acc: 23.438,41.406,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.355 | Acc: 20.052,35.714,45.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.323 | Acc: 20.084,35.518,44.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.331 | Acc: 19.992,35.246,44.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 5.632 | Acc: 31.250,51.562,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.784 | Acc: 34.003,49.702,56.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.749 | Acc: 34.032,50.705,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.780 | Acc: 33.850,50.448,57.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.810 | Acc: 33.951,50.203,57.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.781 | Acc: 34.035,50.418,58.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.763 | Acc: 34.078,50.562,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.757 | Acc: 34.153,50.765,57.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.772 | Acc: 33.963,50.684,57.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.774 | Acc: 33.995,50.652,57.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.768 | Acc: 33.928,50.509,57.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.777 | Acc: 33.919,50.414,57.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.777 | Acc: 33.989,50.438,57.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.796 | Acc: 33.764,50.239,57.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.797 | Acc: 33.663,50.270,57.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.803 | Acc: 33.576,50.231,57.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.798 | Acc: 33.618,50.187,57.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.797 | Acc: 33.646,50.183,57.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.799 | Acc: 33.561,50.154,57.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.800 | Acc: 33.575,50.144,57.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.030 | Acc: 28.125,43.750,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.062 | Acc: 26.860,41.071,48.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.056 | Acc: 26.505,40.720,48.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.047 | Acc: 26.562,40.881,48.399,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 6.105 | Acc: 28.906,47.656,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.569 | Acc: 33.743,53.348,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.590 | Acc: 33.670,52.439,60.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.638 | Acc: 33.824,51.575,59.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.660 | Acc: 33.594,51.437,59.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.683 | Acc: 33.408,51.207,59.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.664 | Acc: 33.581,51.472,59.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.694 | Acc: 33.544,51.213,58.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.691 | Acc: 33.642,51.349,58.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.682 | Acc: 33.762,51.390,58.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.717 | Acc: 33.539,51.158,58.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.714 | Acc: 33.608,51.266,58.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.719 | Acc: 33.652,51.125,58.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.723 | Acc: 33.713,51.096,58.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.717 | Acc: 33.833,51.018,58.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.719 | Acc: 33.929,50.963,58.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.734 | Acc: 33.857,50.908,58.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.740 | Acc: 33.855,50.875,58.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.751 | Acc: 33.840,50.775,58.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.753 | Acc: 33.838,50.769,58.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.510 | Acc: 18.750,45.312,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.422 | Acc: 20.164,40.588,48.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.533 | Acc: 19.607,39.196,47.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.558 | Acc: 19.685,39.114,47.106,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 5.777 | Acc: 32.812,57.031,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.705 | Acc: 33.333,50.744,58.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.670 | Acc: 33.479,51.639,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.658 | Acc: 33.927,51.409,58.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.666 | Acc: 34.008,51.476,58.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.669 | Acc: 34.027,51.230,58.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.668 | Acc: 34.181,51.162,58.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.671 | Acc: 34.098,51.175,58.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.682 | Acc: 34.098,51.247,58.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.692 | Acc: 34.051,51.260,58.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.695 | Acc: 34.076,51.267,58.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.691 | Acc: 34.110,51.290,58.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.698 | Acc: 34.093,51.216,58.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.696 | Acc: 34.159,51.206,58.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.703 | Acc: 34.242,51.182,58.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.700 | Acc: 34.079,51.235,58.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.702 | Acc: 34.073,51.214,58.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.697 | Acc: 34.178,51.313,58.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.702 | Acc: 34.176,51.238,58.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.707 | Acc: 34.154,51.247,58.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.831 | Acc: 28.906,50.000,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.056 | Acc: 25.260,44.085,49.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.048 | Acc: 25.686,43.750,48.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.044 | Acc: 25.307,43.417,49.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 5.061 | Acc: 35.156,56.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.537 | Acc: 34.635,52.976,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.534 | Acc: 35.023,52.801,60.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.507 | Acc: 34.772,53.035,60.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.494 | Acc: 35.156,53.250,60.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.527 | Acc: 34.971,52.738,60.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.560 | Acc: 34.724,52.544,60.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.562 | Acc: 34.929,52.427,60.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.570 | Acc: 34.880,52.451,60.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.574 | Acc: 34.897,52.534,60.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.569 | Acc: 34.997,52.573,60.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.594 | Acc: 34.672,52.372,59.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.601 | Acc: 34.573,52.246,59.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.612 | Acc: 34.495,52.143,59.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.628 | Acc: 34.467,52.049,59.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.635 | Acc: 34.315,51.918,59.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.645 | Acc: 34.351,51.789,59.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.643 | Acc: 34.380,51.810,59.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.649 | Acc: 34.388,51.764,59.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.642 | Acc: 34.461,51.772,59.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.789 | Acc: 28.125,47.656,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.837 | Acc: 27.009,45.015,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.813 | Acc: 27.325,44.531,51.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.838 | Acc: 27.113,43.686,51.204,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 5.494 | Acc: 26.562,49.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.508 | Acc: 35.491,53.757,61.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.535 | Acc: 34.813,53.201,61.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.512 | Acc: 35.310,53.381,61.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.555 | Acc: 35.089,52.845,60.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.569 | Acc: 34.901,52.831,60.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.581 | Acc: 34.724,52.576,60.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.600 | Acc: 34.630,52.416,59.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.601 | Acc: 34.540,52.446,60.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.597 | Acc: 34.530,52.365,59.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.602 | Acc: 34.429,52.247,59.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.605 | Acc: 34.326,52.128,59.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.605 | Acc: 34.394,52.159,59.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.601 | Acc: 34.495,52.293,59.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.603 | Acc: 34.489,52.246,59.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.606 | Acc: 34.557,52.188,59.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.598 | Acc: 34.618,52.244,59.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.592 | Acc: 34.583,52.280,59.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.591 | Acc: 34.611,52.346,59.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.590 | Acc: 34.607,52.348,59.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.858 | Acc: 29.688,46.875,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.682 | Acc: 29.055,45.238,51.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.716 | Acc: 29.649,44.569,50.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.736 | Acc: 29.688,44.544,50.384,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 5.271 | Acc: 36.719,56.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.322 | Acc: 35.565,55.357,63.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.450 | Acc: 34.451,53.220,61.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.460 | Acc: 34.708,53.343,61.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.502 | Acc: 34.780,53.164,60.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.488 | Acc: 34.963,53.396,60.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.474 | Acc: 35.189,53.467,61.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.490 | Acc: 35.034,53.153,60.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.502 | Acc: 34.860,53.086,60.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.512 | Acc: 34.906,53.026,60.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.517 | Acc: 34.865,52.950,60.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.540 | Acc: 34.845,52.673,60.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.546 | Acc: 34.842,52.720,60.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.558 | Acc: 34.773,52.619,59.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.555 | Acc: 34.853,52.644,59.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.549 | Acc: 34.910,52.676,59.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.556 | Acc: 34.871,52.633,59.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.556 | Acc: 34.874,52.610,59.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.549 | Acc: 34.940,52.640,60.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.549 | Acc: 34.910,52.604,59.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.007 | Acc: 28.906,42.969,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.002 | Acc: 25.818,42.820,51.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.054 | Acc: 25.896,42.073,49.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.111 | Acc: 25.743,41.086,49.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.031 | Acc: 39.062,54.688,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.438 | Acc: 35.156,53.013,63.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.412 | Acc: 35.309,53.258,63.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.440 | Acc: 35.156,53.074,62.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.451 | Acc: 34.992,53.154,62.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.477 | Acc: 34.746,53.148,61.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.481 | Acc: 34.963,53.190,61.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.483 | Acc: 35.062,53.175,61.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.481 | Acc: 35.190,53.251,61.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.488 | Acc: 35.320,53.207,61.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.491 | Acc: 35.253,53.148,61.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.497 | Acc: 35.326,53.178,60.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.495 | Acc: 35.296,53.238,60.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.505 | Acc: 35.201,53.089,60.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.508 | Acc: 35.142,53.005,60.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.509 | Acc: 35.135,52.943,60.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.517 | Acc: 35.083,52.894,60.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.519 | Acc: 35.071,52.891,60.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.514 | Acc: 35.102,53.038,60.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.511 | Acc: 35.144,53.066,60.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.976 | Acc: 32.031,52.344,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.589 | Acc: 27.939,45.387,53.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.588 | Acc: 28.277,45.560,52.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.586 | Acc: 28.471,45.223,52.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 5.506 | Acc: 33.594,51.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.431 | Acc: 36.049,53.869,62.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.461 | Acc: 35.766,53.659,62.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.468 | Acc: 35.617,53.714,61.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.485 | Acc: 35.619,53.511,61.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.473 | Acc: 35.659,53.697,61.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.439 | Acc: 35.666,53.887,61.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.455 | Acc: 35.649,53.496,61.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.442 | Acc: 35.709,53.664,61.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.432 | Acc: 35.873,53.798,61.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.438 | Acc: 35.743,53.677,61.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.456 | Acc: 35.573,53.500,61.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.459 | Acc: 35.571,53.501,61.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.474 | Acc: 35.462,53.406,60.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.482 | Acc: 35.437,53.356,60.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.483 | Acc: 35.359,53.309,60.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.488 | Acc: 35.322,53.237,60.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.481 | Acc: 35.397,53.292,60.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.485 | Acc: 35.429,53.238,60.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.486 | Acc: 35.429,53.187,60.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.155 | Acc: 33.594,48.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.359 | Acc: 30.394,47.321,53.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.398 | Acc: 30.030,47.027,52.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.407 | Acc: 30.020,46.901,52.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 5.584 | Acc: 29.688,51.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.407 | Acc: 35.826,54.278,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.373 | Acc: 36.719,53.944,62.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.367 | Acc: 36.155,54.098,62.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.377 | Acc: 36.150,53.887,62.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.368 | Acc: 36.046,53.960,62.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.366 | Acc: 36.092,54.081,62.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.383 | Acc: 35.954,54.145,62.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.404 | Acc: 35.753,53.945,62.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.404 | Acc: 35.696,53.919,62.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.411 | Acc: 35.778,53.906,62.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.434 | Acc: 35.687,53.758,61.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.443 | Acc: 35.532,53.744,61.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.450 | Acc: 35.483,53.589,61.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.454 | Acc: 35.437,53.589,61.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.460 | Acc: 35.525,53.561,61.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.459 | Acc: 35.533,53.570,61.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.453 | Acc: 35.610,53.640,61.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.454 | Acc: 35.511,53.662,61.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.460 | Acc: 35.503,53.560,61.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.819 | Acc: 25.000,39.062,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.577 | Acc: 17.113,32.664,45.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.566 | Acc: 17.016,32.622,45.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.540 | Acc: 17.380,32.723,45.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 5.011 | Acc: 41.406,57.812,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.446 | Acc: 34.896,52.641,61.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.437 | Acc: 34.585,52.915,60.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.384 | Acc: 35.694,53.804,61.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.352 | Acc: 35.966,54.090,61.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.363 | Acc: 35.698,53.929,61.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.381 | Acc: 35.686,53.816,61.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.394 | Acc: 35.406,53.541,61.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.396 | Acc: 35.433,53.533,61.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.404 | Acc: 35.277,53.496,61.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.395 | Acc: 35.351,53.615,61.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.400 | Acc: 35.425,53.616,61.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.405 | Acc: 35.477,53.595,61.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.408 | Acc: 35.480,53.574,61.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.419 | Acc: 35.434,53.459,61.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.419 | Acc: 35.369,53.517,61.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.410 | Acc: 35.460,53.695,61.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.403 | Acc: 35.592,53.746,61.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.411 | Acc: 35.537,53.673,61.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.409 | Acc: 35.595,53.691,61.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.619 | Acc: 24.219,42.188,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.924 | Acc: 19.234,37.277,47.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.954 | Acc: 19.303,37.119,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.898 | Acc: 19.339,37.513,46.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 4.826 | Acc: 35.156,54.688,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.170 | Acc: 36.272,54.911,63.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.246 | Acc: 36.223,54.459,63.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.260 | Acc: 36.834,54.726,62.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.228 | Acc: 36.535,55.015,63.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.281 | Acc: 36.347,54.765,62.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.290 | Acc: 36.293,54.468,62.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.308 | Acc: 36.336,54.255,62.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.322 | Acc: 36.238,54.159,62.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.337 | Acc: 36.253,54.122,62.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.344 | Acc: 36.159,54.031,61.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.348 | Acc: 36.100,54.030,62.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.349 | Acc: 36.148,54.065,62.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.347 | Acc: 36.150,54.092,62.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.348 | Acc: 36.129,54.154,62.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.353 | Acc: 36.091,54.205,62.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.362 | Acc: 36.008,54.174,62.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.366 | Acc: 36.009,54.151,61.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.368 | Acc: 36.022,54.146,61.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.374 | Acc: 35.985,54.097,61.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.557 | Acc: 19.531,46.875,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.613 | Acc: 21.503,40.960,49.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.602 | Acc: 21.361,40.987,49.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.623 | Acc: 21.235,40.587,49.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 5.139 | Acc: 42.969,53.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.267 | Acc: 36.830,53.646,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.425 | Acc: 35.556,53.449,61.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.392 | Acc: 35.451,53.829,62.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.364 | Acc: 35.764,54.032,62.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.345 | Acc: 35.682,54.254,62.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.350 | Acc: 35.763,54.184,62.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.368 | Acc: 35.572,53.973,62.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.360 | Acc: 35.806,53.994,62.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.359 | Acc: 35.851,53.980,62.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.351 | Acc: 35.996,54.085,62.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.351 | Acc: 36.005,54.115,62.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.343 | Acc: 36.077,54.253,62.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.340 | Acc: 36.153,54.322,62.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.343 | Acc: 36.085,54.321,62.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.343 | Acc: 36.034,54.298,62.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.339 | Acc: 36.144,54.352,62.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.342 | Acc: 36.171,54.316,62.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.345 | Acc: 36.065,54.296,62.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.354 | Acc: 36.011,54.329,62.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.701 | Acc: 15.625,28.125,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.791 | Acc: 13.579,32.106,46.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.651 | Acc: 14.348,32.698,46.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.640 | Acc: 13.973,32.018,46.055,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 5.380 | Acc: 31.250,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.276 | Acc: 37.612,55.766,65.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.271 | Acc: 36.871,55.964,64.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.246 | Acc: 36.936,55.661,64.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.207 | Acc: 37.500,55.768,64.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.196 | Acc: 37.469,55.910,64.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.221 | Acc: 37.126,55.746,63.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.236 | Acc: 36.957,55.602,63.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.248 | Acc: 36.811,55.459,63.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.270 | Acc: 36.598,55.218,63.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.269 | Acc: 36.680,55.239,63.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.284 | Acc: 36.563,55.101,63.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.283 | Acc: 36.579,55.057,63.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.294 | Acc: 36.494,54.918,62.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.298 | Acc: 36.449,54.807,62.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.308 | Acc: 36.374,54.708,62.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.313 | Acc: 36.337,54.709,62.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.315 | Acc: 36.329,54.699,62.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.313 | Acc: 36.331,54.646,62.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.309 | Acc: 36.395,54.681,62.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.280 | Acc: 28.906,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.295 | Acc: 28.571,50.074,56.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.274 | Acc: 29.745,48.971,55.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.315 | Acc: 28.701,47.887,55.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 5.554 | Acc: 32.812,55.469,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.196 | Acc: 37.314,55.878,64.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.186 | Acc: 36.909,55.564,64.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.168 | Acc: 37.116,56.173,64.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.179 | Acc: 37.269,56.221,64.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.196 | Acc: 37.075,56.064,64.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.219 | Acc: 36.893,55.979,63.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.221 | Acc: 36.896,55.818,63.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.240 | Acc: 36.801,55.614,63.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.253 | Acc: 36.831,55.603,63.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.248 | Acc: 36.979,55.597,63.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.252 | Acc: 36.977,55.607,63.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.258 | Acc: 36.881,55.488,63.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.257 | Acc: 36.889,55.451,63.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.259 | Acc: 36.755,55.355,63.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.259 | Acc: 36.688,55.344,63.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.264 | Acc: 36.580,55.332,62.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.270 | Acc: 36.600,55.279,62.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.273 | Acc: 36.649,55.267,62.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.278 | Acc: 36.571,55.163,62.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.465 | Acc: 24.219,41.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.626 | Acc: 23.586,40.551,49.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.527 | Acc: 24.409,40.606,50.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.547 | Acc: 24.603,40.920,49.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 5.344 | Acc: 31.250,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.177 | Acc: 35.379,55.618,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.134 | Acc: 36.357,56.136,64.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.175 | Acc: 36.258,55.776,64.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.175 | Acc: 36.420,55.729,64.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.186 | Acc: 36.433,55.608,64.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.207 | Acc: 36.428,55.553,63.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.204 | Acc: 36.486,55.663,63.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.221 | Acc: 36.340,55.677,63.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.229 | Acc: 36.352,55.611,63.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.218 | Acc: 36.532,55.784,63.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.221 | Acc: 36.553,55.744,63.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.221 | Acc: 36.583,55.793,63.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.229 | Acc: 36.437,55.711,63.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.240 | Acc: 36.310,55.613,63.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.243 | Acc: 36.246,55.565,63.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.243 | Acc: 36.346,55.610,63.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.243 | Acc: 36.359,55.590,63.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.249 | Acc: 36.301,55.499,63.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.256 | Acc: 36.274,55.381,63.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.709 | Acc: 23.438,42.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.639 | Acc: 20.685,41.109,52.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.634 | Acc: 19.950,40.168,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.621 | Acc: 19.775,40.177,52.011,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 5.281 | Acc: 35.938,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.177 | Acc: 36.868,54.799,63.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.152 | Acc: 36.719,55.564,63.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.155 | Acc: 36.796,55.879,64.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.168 | Acc: 36.796,55.295,64.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.143 | Acc: 36.788,55.685,64.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.166 | Acc: 36.570,55.566,63.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.175 | Acc: 36.608,55.430,63.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.182 | Acc: 36.559,55.449,63.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.169 | Acc: 36.706,55.715,63.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.177 | Acc: 36.719,55.838,63.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.194 | Acc: 36.715,55.642,63.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.213 | Acc: 36.579,55.475,63.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.212 | Acc: 36.680,55.535,63.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.223 | Acc: 36.610,55.541,63.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.232 | Acc: 36.599,55.482,63.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.228 | Acc: 36.609,55.517,63.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.233 | Acc: 36.593,55.517,63.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.230 | Acc: 36.589,55.614,63.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.234 | Acc: 36.573,55.536,63.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.279 | Acc: 38.281,47.656,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.715 | Acc: 29.241,44.606,52.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.701 | Acc: 29.383,43.445,52.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.694 | Acc: 28.612,43.366,51.601,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 4.580 | Acc: 40.625,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.123 | Acc: 35.975,57.738,65.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.064 | Acc: 37.367,58.022,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.068 | Acc: 37.474,57.620,65.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.074 | Acc: 37.519,57.234,64.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.087 | Acc: 37.392,57.170,65.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.105 | Acc: 37.222,56.650,64.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.122 | Acc: 37.251,56.544,64.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.140 | Acc: 37.267,56.366,64.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.138 | Acc: 37.310,56.241,64.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.149 | Acc: 37.158,56.262,63.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.158 | Acc: 37.104,56.172,63.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.163 | Acc: 36.991,56.033,63.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.165 | Acc: 37.069,56.034,63.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.166 | Acc: 37.052,56.172,63.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.175 | Acc: 37.093,56.133,63.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.183 | Acc: 37.001,56.053,63.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.183 | Acc: 37.106,56.055,63.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.185 | Acc: 37.093,56.081,63.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.184 | Acc: 37.166,56.004,63.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.799 | Acc: 32.812,39.844,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.107 | Acc: 28.088,39.993,50.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.098 | Acc: 27.877,39.367,50.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.117 | Acc: 27.600,39.408,49.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 5.056 | Acc: 35.938,53.125,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.091 | Acc: 37.202,56.510,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.089 | Acc: 37.633,56.707,64.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.126 | Acc: 37.423,56.352,63.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.159 | Acc: 37.076,56.019,63.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.145 | Acc: 37.229,56.095,64.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.147 | Acc: 37.377,56.114,64.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.141 | Acc: 37.223,56.433,64.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.132 | Acc: 37.485,56.415,64.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.139 | Acc: 37.453,56.310,64.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.131 | Acc: 37.566,56.386,64.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.131 | Acc: 37.571,56.420,64.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.140 | Acc: 37.562,56.347,64.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.157 | Acc: 37.476,56.064,63.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.168 | Acc: 37.314,56.000,63.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.177 | Acc: 37.277,55.970,63.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.178 | Acc: 37.257,56.002,63.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.181 | Acc: 37.296,55.998,63.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.181 | Acc: 37.253,55.990,63.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.180 | Acc: 37.287,55.910,63.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.699 | Acc: 22.656,40.625,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.408 | Acc: 22.768,41.592,50.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.481 | Acc: 21.723,41.006,49.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.494 | Acc: 21.376,40.830,49.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 4.944 | Acc: 36.719,58.594,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.069 | Acc: 36.942,57.031,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.063 | Acc: 37.500,57.031,64.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.106 | Acc: 36.757,56.634,64.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.091 | Acc: 37.278,56.877,64.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.122 | Acc: 37.291,56.436,64.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.103 | Acc: 37.487,56.838,64.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.107 | Acc: 37.428,56.826,64.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.104 | Acc: 37.607,56.861,64.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.111 | Acc: 37.681,56.820,64.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.130 | Acc: 37.551,56.611,64.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.141 | Acc: 37.578,56.455,64.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.154 | Acc: 37.474,56.373,63.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.156 | Acc: 37.470,56.334,63.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.155 | Acc: 37.511,56.322,63.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.157 | Acc: 37.497,56.268,63.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.158 | Acc: 37.478,56.204,63.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.159 | Acc: 37.411,56.168,63.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.155 | Acc: 37.435,56.254,63.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.157 | Acc: 37.500,56.266,63.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.698 | Acc: 35.938,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.750 | Acc: 25.670,46.801,54.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.785 | Acc: 25.152,46.303,53.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.771 | Acc: 24.821,46.337,53.471,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 5.053 | Acc: 36.719,62.500,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.970 | Acc: 38.467,58.333,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.972 | Acc: 37.976,57.679,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.007 | Acc: 38.012,57.467,65.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.993 | Acc: 38.137,57.687,65.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.030 | Acc: 37.763,57.170,65.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.017 | Acc: 37.855,57.160,65.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.020 | Acc: 37.993,57.253,65.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.033 | Acc: 37.811,57.128,65.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.066 | Acc: 37.569,56.738,64.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.078 | Acc: 37.484,56.693,64.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.076 | Acc: 37.585,56.745,64.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.093 | Acc: 37.416,56.694,64.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.096 | Acc: 37.473,56.753,64.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.091 | Acc: 37.428,56.789,64.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.097 | Acc: 37.331,56.676,64.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.100 | Acc: 37.381,56.627,64.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.109 | Acc: 37.305,56.555,64.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.116 | Acc: 37.303,56.486,64.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.125 | Acc: 37.270,56.385,64.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.530 | Acc: 28.125,46.094,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.598 | Acc: 26.265,46.243,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.670 | Acc: 25.877,45.484,54.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.686 | Acc: 25.961,45.197,53.740,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 5.286 | Acc: 39.844,54.688,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.048 | Acc: 38.356,57.440,65.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.109 | Acc: 36.986,56.707,64.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.087 | Acc: 36.796,56.890,64.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.119 | Acc: 36.420,56.684,64.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.128 | Acc: 36.665,56.474,64.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.131 | Acc: 36.557,56.489,64.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.116 | Acc: 36.625,56.582,64.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.092 | Acc: 36.957,56.823,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.093 | Acc: 37.224,56.962,64.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.099 | Acc: 37.286,56.860,64.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.100 | Acc: 37.302,56.883,64.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.104 | Acc: 37.208,56.788,64.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.108 | Acc: 37.249,56.792,64.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.111 | Acc: 37.189,56.714,64.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.113 | Acc: 37.217,56.593,64.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.102 | Acc: 37.342,56.776,64.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.098 | Acc: 37.413,56.859,64.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.100 | Acc: 37.413,56.884,64.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.108 | Acc: 37.342,56.773,64.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.369 | Acc: 35.938,45.312,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.712 | Acc: 28.683,43.750,53.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.753 | Acc: 28.925,43.941,53.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.789 | Acc: 28.471,43.776,52.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 4.699 | Acc: 40.625,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.858 | Acc: 39.323,58.408,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.884 | Acc: 38.853,58.670,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.961 | Acc: 38.217,57.966,66.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.987 | Acc: 38.397,57.649,65.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.019 | Acc: 37.879,57.317,65.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.029 | Acc: 37.900,57.154,65.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.041 | Acc: 37.688,57.048,65.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.037 | Acc: 37.767,57.157,65.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.037 | Acc: 37.707,57.225,65.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.058 | Acc: 37.690,57.105,64.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.051 | Acc: 37.740,57.208,64.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.066 | Acc: 37.578,57.051,64.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.057 | Acc: 37.730,57.085,64.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.062 | Acc: 37.711,57.115,64.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.072 | Acc: 37.739,56.974,64.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.077 | Acc: 37.790,56.961,64.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.083 | Acc: 37.729,56.956,64.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.086 | Acc: 37.632,56.871,64.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.085 | Acc: 37.644,56.929,64.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.366 | Acc: 23.438,42.969,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.409 | Acc: 22.545,41.146,51.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.364 | Acc: 23.399,41.768,51.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.380 | Acc: 23.015,41.509,51.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 4.762 | Acc: 32.812,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.886 | Acc: 38.058,58.110,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.951 | Acc: 37.805,57.717,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.966 | Acc: 37.282,57.979,66.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.956 | Acc: 37.953,57.803,66.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.980 | Acc: 37.833,57.828,66.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.986 | Acc: 37.784,57.574,66.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.996 | Acc: 37.722,57.558,66.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.996 | Acc: 37.743,57.599,66.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.008 | Acc: 37.711,57.588,65.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.022 | Acc: 37.675,57.408,65.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.028 | Acc: 37.571,57.349,65.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.027 | Acc: 37.610,57.342,65.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.026 | Acc: 37.722,57.435,65.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.027 | Acc: 37.720,57.379,65.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.038 | Acc: 37.741,57.356,65.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.047 | Acc: 37.809,57.277,65.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.056 | Acc: 37.722,57.166,64.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.059 | Acc: 37.719,57.131,65.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.056 | Acc: 37.767,57.144,64.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.139 | Acc: 38.281,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.296 | Acc: 32.031,48.363,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.310 | Acc: 32.165,47.790,53.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.263 | Acc: 31.775,48.245,54.201,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.923 | Acc: 34.375,64.062,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.721 | Acc: 39.025,61.161,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.881 | Acc: 38.053,59.108,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.916 | Acc: 37.859,58.811,67.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.963 | Acc: 37.944,58.275,66.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.980 | Acc: 37.786,58.137,66.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.003 | Acc: 37.332,57.812,65.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.006 | Acc: 37.472,57.757,65.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.002 | Acc: 37.558,57.759,65.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.993 | Acc: 37.819,57.843,65.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.999 | Acc: 37.768,57.820,65.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.005 | Acc: 37.705,57.728,65.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.010 | Acc: 37.720,57.715,65.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.033 | Acc: 37.653,57.453,65.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.037 | Acc: 37.645,57.398,65.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.032 | Acc: 37.726,57.402,65.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.033 | Acc: 37.809,57.404,65.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.028 | Acc: 37.821,57.505,65.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.034 | Acc: 37.762,57.458,65.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.034 | Acc: 37.787,57.423,65.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.237 | Acc: 36.719,50.000,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.395 | Acc: 29.799,46.726,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.355 | Acc: 30.145,46.037,55.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.374 | Acc: 29.367,45.300,55.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 4.141 | Acc: 45.312,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.740 | Acc: 40.551,60.826,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.810 | Acc: 39.977,59.585,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.843 | Acc: 39.549,59.144,67.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.897 | Acc: 38.773,58.574,67.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.926 | Acc: 38.304,58.315,66.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.943 | Acc: 38.294,58.174,66.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.952 | Acc: 38.259,58.134,66.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.941 | Acc: 38.339,58.152,66.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.945 | Acc: 38.355,58.097,66.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.937 | Acc: 38.604,58.046,66.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.956 | Acc: 38.500,57.996,66.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.964 | Acc: 38.385,57.842,65.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.976 | Acc: 38.296,57.830,65.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.981 | Acc: 38.267,57.771,65.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.992 | Acc: 38.138,57.693,65.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.998 | Acc: 38.128,57.640,65.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.998 | Acc: 38.093,57.611,65.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.003 | Acc: 38.104,57.572,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.009 | Acc: 38.068,57.519,65.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.139 | Acc: 21.094,39.062,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.525 | Acc: 23.028,41.443,51.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.621 | Acc: 23.209,40.892,50.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.654 | Acc: 22.861,41.291,50.384,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 5.577 | Acc: 30.469,55.469,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.910 | Acc: 37.835,57.999,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.899 | Acc: 38.453,58.270,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.931 | Acc: 38.320,58.145,67.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.953 | Acc: 38.358,57.870,66.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.955 | Acc: 38.127,57.990,66.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.952 | Acc: 38.262,58.051,66.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.955 | Acc: 38.032,58.095,66.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.956 | Acc: 37.951,58.031,66.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.979 | Acc: 37.871,57.890,66.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.989 | Acc: 37.792,57.750,66.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.983 | Acc: 37.924,57.781,66.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.988 | Acc: 37.892,57.819,65.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.988 | Acc: 37.895,57.815,65.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.995 | Acc: 37.911,57.707,65.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.994 | Acc: 37.882,57.742,65.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.003 | Acc: 37.797,57.591,65.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.004 | Acc: 37.871,57.597,65.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.003 | Acc: 37.907,57.598,65.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.006 | Acc: 37.902,57.550,65.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.120 | Acc: 22.656,38.281,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.004 | Acc: 24.442,43.378,54.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.076 | Acc: 24.562,43.121,53.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.113 | Acc: 24.334,42.546,53.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 5.153 | Acc: 36.719,59.375,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.973 | Acc: 36.570,57.217,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.879 | Acc: 39.120,58.308,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.906 | Acc: 38.653,58.171,66.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.921 | Acc: 38.436,58.189,66.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.906 | Acc: 38.297,58.176,66.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.920 | Acc: 38.481,57.922,66.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.948 | Acc: 38.337,57.740,65.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.962 | Acc: 38.369,57.638,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.976 | Acc: 38.281,57.489,65.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.982 | Acc: 38.126,57.502,65.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.981 | Acc: 38.203,57.678,65.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.976 | Acc: 38.340,57.718,65.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.976 | Acc: 38.362,57.815,65.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.972 | Acc: 38.509,57.960,65.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.969 | Acc: 38.556,58.103,65.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.975 | Acc: 38.503,58.080,65.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.981 | Acc: 38.400,58.039,65.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.975 | Acc: 38.519,57.988,65.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.974 | Acc: 38.484,57.983,65.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.835 | Acc: 32.812,45.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.896 | Acc: 26.079,44.754,53.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.868 | Acc: 26.562,44.512,53.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.877 | Acc: 26.230,44.429,53.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 5.388 | Acc: 32.031,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.895 | Acc: 37.388,59.747,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.868 | Acc: 38.110,59.832,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.862 | Acc: 37.795,59.554,66.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.873 | Acc: 37.789,59.423,66.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.891 | Acc: 37.918,58.981,66.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.894 | Acc: 37.894,59.013,66.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.904 | Acc: 38.098,58.865,66.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.916 | Acc: 37.980,58.652,66.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.917 | Acc: 38.122,58.611,66.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.926 | Acc: 38.157,58.524,66.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.931 | Acc: 38.214,58.580,66.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.934 | Acc: 38.032,58.597,66.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.934 | Acc: 38.114,58.645,66.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.935 | Acc: 38.215,58.655,66.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.937 | Acc: 38.242,58.521,66.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.937 | Acc: 38.274,58.550,66.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.936 | Acc: 38.403,58.591,66.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.944 | Acc: 38.402,58.414,66.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.942 | Acc: 38.417,58.362,66.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.359 | Acc: 33.594,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.729 | Acc: 29.167,46.912,55.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.752 | Acc: 29.059,46.151,54.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.751 | Acc: 29.393,46.235,53.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 5.088 | Acc: 33.594,57.031,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.965 | Acc: 38.021,58.296,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.913 | Acc: 38.472,58.899,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.916 | Acc: 38.678,58.811,66.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.928 | Acc: 38.792,58.391,66.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.925 | Acc: 38.567,58.331,66.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.946 | Acc: 38.165,58.110,66.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.929 | Acc: 38.193,58.101,66.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.936 | Acc: 38.111,58.079,66.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.927 | Acc: 38.169,58.179,66.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.935 | Acc: 38.083,58.240,65.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.931 | Acc: 38.147,58.251,65.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.938 | Acc: 38.272,58.189,65.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.937 | Acc: 38.335,58.288,65.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.943 | Acc: 38.287,58.230,65.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.941 | Acc: 38.341,58.225,65.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.942 | Acc: 38.364,58.277,65.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.949 | Acc: 38.302,58.223,65.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.958 | Acc: 38.335,58.165,65.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.962 | Acc: 38.255,58.106,65.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.070 | Acc: 32.031,46.094,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.732 | Acc: 28.609,46.317,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.749 | Acc: 29.364,46.132,52.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.711 | Acc: 28.945,45.876,52.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 5.191 | Acc: 29.688,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.675 | Acc: 39.323,59.896,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.737 | Acc: 39.310,58.575,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.744 | Acc: 39.485,59.516,67.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.744 | Acc: 39.612,59.520,68.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.741 | Acc: 39.674,59.584,68.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.776 | Acc: 39.411,59.226,67.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.799 | Acc: 39.362,59.192,67.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.821 | Acc: 39.271,59.040,67.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.839 | Acc: 39.239,58.991,67.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.852 | Acc: 39.136,58.963,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.856 | Acc: 39.031,59.075,67.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.871 | Acc: 38.936,58.795,66.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.880 | Acc: 38.763,58.648,66.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.885 | Acc: 38.746,58.763,66.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.888 | Acc: 38.697,58.749,66.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.884 | Acc: 38.773,58.779,66.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.886 | Acc: 38.815,58.802,66.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.896 | Acc: 38.760,58.717,66.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.912 | Acc: 38.613,58.551,66.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.189 | Acc: 35.156,49.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.499 | Acc: 29.353,47.545,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.500 | Acc: 29.973,47.542,54.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.538 | Acc: 29.342,47.272,53.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 4.608 | Acc: 37.500,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.833 | Acc: 38.281,59.338,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.828 | Acc: 38.796,59.889,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.853 | Acc: 38.614,59.657,67.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.851 | Acc: 38.484,59.385,67.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.863 | Acc: 38.428,59.089,67.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.887 | Acc: 38.126,58.755,67.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.890 | Acc: 38.176,58.544,67.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.880 | Acc: 38.286,58.739,67.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.882 | Acc: 38.506,58.771,67.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.890 | Acc: 38.631,58.710,67.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.904 | Acc: 38.617,58.608,66.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.919 | Acc: 38.544,58.471,66.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.922 | Acc: 38.482,58.483,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.919 | Acc: 38.498,58.599,66.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.920 | Acc: 38.450,58.581,66.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.920 | Acc: 38.512,58.548,66.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.922 | Acc: 38.607,58.452,66.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.922 | Acc: 38.595,58.427,66.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.928 | Acc: 38.525,58.450,66.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.335 | Acc: 27.344,45.312,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.365 | Acc: 22.247,43.080,52.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.393 | Acc: 21.894,43.064,52.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.395 | Acc: 22.118,42.610,52.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 4.647 | Acc: 39.844,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.839 | Acc: 38.504,58.780,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.830 | Acc: 38.796,58.918,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.805 | Acc: 39.062,59.324,68.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.799 | Acc: 39.207,59.471,68.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.793 | Acc: 39.279,59.514,67.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.807 | Acc: 39.146,59.207,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.799 | Acc: 38.957,59.209,67.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.809 | Acc: 38.985,59.263,67.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.806 | Acc: 39.015,59.297,67.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.807 | Acc: 39.070,59.286,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.828 | Acc: 38.903,59.195,67.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.825 | Acc: 39.007,59.200,67.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.832 | Acc: 38.994,59.016,67.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.847 | Acc: 38.962,58.838,66.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.855 | Acc: 38.925,58.739,66.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.867 | Acc: 38.863,58.642,66.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.865 | Acc: 38.914,58.690,66.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.875 | Acc: 38.857,58.682,66.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.885 | Acc: 38.775,58.635,66.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.958 | Acc: 27.344,49.219,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.676 | Acc: 25.558,48.363,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.663 | Acc: 25.896,47.485,54.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.691 | Acc: 25.576,47.195,54.393,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 4.621 | Acc: 42.188,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.776 | Acc: 38.579,58.780,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.743 | Acc: 38.586,59.470,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.790 | Acc: 38.243,59.349,68.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.768 | Acc: 38.281,59.597,68.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.789 | Acc: 38.529,59.421,68.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.803 | Acc: 38.527,59.401,68.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.819 | Acc: 38.503,59.303,68.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.821 | Acc: 38.427,59.365,68.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.858 | Acc: 38.311,58.987,67.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.865 | Acc: 38.308,58.881,67.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.875 | Acc: 38.260,58.820,67.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.869 | Acc: 38.372,58.798,67.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.875 | Acc: 38.296,58.684,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.885 | Acc: 38.253,58.610,67.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.880 | Acc: 38.432,58.672,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.882 | Acc: 38.449,58.708,67.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.882 | Acc: 38.446,58.681,66.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.885 | Acc: 38.446,58.739,66.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.882 | Acc: 38.527,58.709,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.031 | Acc: 26.562,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.949 | Acc: 25.223,44.978,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.050 | Acc: 24.638,43.540,52.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.046 | Acc: 24.488,43.289,52.331,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 4.855 | Acc: 39.844,59.375,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.769 | Acc: 37.574,60.119,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.786 | Acc: 39.101,59.966,67.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.801 | Acc: 38.461,59.849,67.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.813 | Acc: 38.349,59.520,67.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.815 | Acc: 38.482,59.530,67.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.811 | Acc: 38.623,59.524,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.810 | Acc: 38.664,59.547,67.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.815 | Acc: 38.728,59.749,67.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.820 | Acc: 38.894,59.634,67.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.818 | Acc: 38.961,59.523,67.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.824 | Acc: 38.829,59.446,67.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.836 | Acc: 38.738,59.339,67.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.846 | Acc: 38.775,59.198,67.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.850 | Acc: 38.737,59.194,67.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.846 | Acc: 38.741,59.250,67.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.844 | Acc: 38.775,59.302,67.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.838 | Acc: 38.868,59.345,67.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.846 | Acc: 38.801,59.182,67.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.846 | Acc: 38.862,59.211,67.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.383 | Acc: 34.375,49.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.858 | Acc: 25.707,47.805,55.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.817 | Acc: 25.877,47.942,55.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.821 | Acc: 25.551,47.746,54.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 5.502 | Acc: 33.594,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.772 | Acc: 39.211,59.747,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.816 | Acc: 38.605,59.413,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.824 | Acc: 38.486,58.901,67.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.813 | Acc: 38.619,58.951,67.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.795 | Acc: 38.776,59.305,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.815 | Acc: 38.585,59.162,67.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.820 | Acc: 38.425,59.297,67.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.815 | Acc: 38.378,59.312,67.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.824 | Acc: 38.281,59.146,67.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.822 | Acc: 38.328,59.223,67.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.816 | Acc: 38.465,59.400,67.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.813 | Acc: 38.524,59.446,67.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.818 | Acc: 38.509,59.285,67.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.818 | Acc: 38.534,59.214,67.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.822 | Acc: 38.658,59.214,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.831 | Acc: 38.673,59.154,67.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.837 | Acc: 38.726,59.144,66.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.842 | Acc: 38.729,59.111,66.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.845 | Acc: 38.745,59.082,66.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.088 | Acc: 27.344,38.281,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.251 | Acc: 25.446,43.452,52.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.254 | Acc: 25.819,42.797,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.291 | Acc: 25.333,42.495,51.742,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.709 | Acc: 41.406,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.681 | Acc: 40.141,60.045,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.664 | Acc: 39.710,60.252,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.653 | Acc: 39.613,60.425,68.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.707 | Acc: 39.439,59.886,68.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.746 | Acc: 38.954,59.924,68.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.773 | Acc: 38.623,59.853,68.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.790 | Acc: 38.752,59.586,67.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.796 | Acc: 38.796,59.608,67.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.801 | Acc: 38.760,59.526,67.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.798 | Acc: 38.919,59.519,67.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.798 | Acc: 39.052,59.534,67.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.796 | Acc: 39.137,59.527,67.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.801 | Acc: 39.197,59.498,67.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.806 | Acc: 39.151,59.397,67.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.804 | Acc: 39.117,59.396,67.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.816 | Acc: 39.055,59.283,67.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.825 | Acc: 38.991,59.150,67.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.825 | Acc: 38.989,59.154,67.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.831 | Acc: 38.923,59.135,67.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.411 | Acc: 38.281,46.094,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.006 | Acc: 28.832,44.122,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.905 | Acc: 28.773,44.341,52.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.906 | Acc: 28.266,43.878,52.088,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 5.133 | Acc: 38.281,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.644 | Acc: 39.546,60.491,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.763 | Acc: 38.548,59.756,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.744 | Acc: 39.037,59.977,68.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.745 | Acc: 39.323,59.915,68.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.773 | Acc: 39.024,59.623,67.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.802 | Acc: 38.895,59.304,67.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.817 | Acc: 38.874,59.104,67.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.797 | Acc: 39.053,59.297,67.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.804 | Acc: 38.955,59.151,67.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.808 | Acc: 38.880,59.130,67.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.799 | Acc: 38.840,59.308,67.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.804 | Acc: 38.874,59.197,67.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.818 | Acc: 38.796,59.112,67.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.820 | Acc: 38.779,59.130,67.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.823 | Acc: 38.819,59.118,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.827 | Acc: 38.778,59.056,67.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.829 | Acc: 38.836,59.095,67.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.834 | Acc: 38.894,59.102,67.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.829 | Acc: 38.976,59.121,67.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.026 | Acc: 39.844,49.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.982 | Acc: 34.040,50.037,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.969 | Acc: 34.108,49.886,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.004 | Acc: 33.927,49.411,55.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 4.372 | Acc: 47.656,60.156,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.781 | Acc: 39.211,60.491,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.725 | Acc: 39.596,60.461,68.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.733 | Acc: 39.062,60.233,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.730 | Acc: 39.149,60.291,68.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.732 | Acc: 39.310,60.350,68.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.754 | Acc: 39.198,60.337,68.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.771 | Acc: 39.018,60.090,68.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.769 | Acc: 38.990,60.190,68.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.782 | Acc: 39.032,60.040,67.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.796 | Acc: 39.024,60.016,67.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.812 | Acc: 39.017,59.835,67.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.808 | Acc: 39.140,59.916,67.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.816 | Acc: 39.197,59.866,67.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.817 | Acc: 39.165,59.764,67.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.819 | Acc: 39.203,59.777,67.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.826 | Acc: 39.223,59.711,67.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.826 | Acc: 39.214,59.643,67.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.822 | Acc: 39.324,59.687,67.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.815 | Acc: 39.397,59.754,67.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.869 | Acc: 40.625,53.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.348 | Acc: 32.440,47.805,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.295 | Acc: 32.717,47.580,55.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.330 | Acc: 32.031,47.131,54.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 4.631 | Acc: 39.062,65.625,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.674 | Acc: 39.918,61.384,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.669 | Acc: 40.530,61.185,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.717 | Acc: 40.113,60.425,67.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.732 | Acc: 39.747,60.176,67.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.728 | Acc: 39.867,60.063,68.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.743 | Acc: 39.954,60.008,67.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.745 | Acc: 39.805,60.051,67.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.743 | Acc: 39.553,60.054,68.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.756 | Acc: 39.300,59.845,68.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.753 | Acc: 39.338,59.853,68.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.758 | Acc: 39.225,59.831,68.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.761 | Acc: 39.202,59.848,67.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.762 | Acc: 39.224,59.860,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.764 | Acc: 39.160,59.828,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.775 | Acc: 39.073,59.624,67.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.784 | Acc: 39.014,59.489,67.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.782 | Acc: 39.085,59.538,67.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.782 | Acc: 39.114,59.550,67.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.780 | Acc: 39.233,59.560,67.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.658 | Acc: 29.688,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.482 | Acc: 29.427,48.698,55.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.494 | Acc: 29.649,47.980,54.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.505 | Acc: 29.905,47.490,54.521,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 4.470 | Acc: 39.844,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.607 | Acc: 40.290,61.012,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.702 | Acc: 38.834,60.042,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.673 | Acc: 39.524,60.233,69.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.701 | Acc: 39.622,60.214,69.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.719 | Acc: 39.426,59.924,68.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.724 | Acc: 39.443,59.724,68.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.738 | Acc: 39.561,59.724,68.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.735 | Acc: 39.621,59.807,68.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.720 | Acc: 39.615,59.992,68.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.735 | Acc: 39.373,59.814,68.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.734 | Acc: 39.469,59.926,68.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.726 | Acc: 39.539,60.049,68.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.733 | Acc: 39.485,59.989,68.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.741 | Acc: 39.424,59.962,68.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.748 | Acc: 39.475,59.897,68.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.759 | Acc: 39.445,59.842,68.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.762 | Acc: 39.408,59.801,68.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.760 | Acc: 39.409,59.816,68.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.770 | Acc: 39.350,59.783,67.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.366 | Acc: 32.812,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.587 | Acc: 29.985,46.577,55.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.596 | Acc: 29.726,47.218,55.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.651 | Acc: 29.444,46.721,54.764,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 4.227 | Acc: 35.156,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.585 | Acc: 39.658,61.644,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.638 | Acc: 39.939,60.671,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.720 | Acc: 39.869,59.862,68.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.697 | Acc: 39.718,59.925,68.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.697 | Acc: 39.457,60.102,68.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.713 | Acc: 39.540,60.001,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.717 | Acc: 39.195,60.134,68.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.723 | Acc: 39.305,60.006,68.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.738 | Acc: 39.343,59.893,68.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.741 | Acc: 39.432,59.775,68.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.747 | Acc: 39.271,59.693,68.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.750 | Acc: 39.296,59.777,68.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.751 | Acc: 39.380,59.812,68.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.754 | Acc: 39.363,59.870,68.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.747 | Acc: 39.483,59.917,68.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.754 | Acc: 39.479,59.820,68.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.753 | Acc: 39.518,59.826,68.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.761 | Acc: 39.532,59.778,68.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.761 | Acc: 39.460,59.812,68.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.690 | Acc: 23.438,44.531,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.731 | Acc: 25.670,47.210,55.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.704 | Acc: 25.857,46.913,55.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.726 | Acc: 25.090,46.376,55.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 4.954 | Acc: 35.938,61.719,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.513 | Acc: 40.253,62.798,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 40.111,62.043,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.630 | Acc: 39.818,61.270,69.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.666 | Acc: 39.612,60.745,68.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.668 | Acc: 39.836,60.675,68.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.689 | Acc: 39.579,60.576,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.680 | Acc: 39.644,60.699,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.691 | Acc: 39.528,60.506,68.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.694 | Acc: 39.546,60.398,68.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.711 | Acc: 39.525,60.273,68.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.721 | Acc: 39.462,60.139,68.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.720 | Acc: 39.377,60.156,68.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.722 | Acc: 39.434,60.096,68.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.741 | Acc: 39.307,59.937,68.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.750 | Acc: 39.340,59.871,67.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.749 | Acc: 39.393,59.942,67.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.751 | Acc: 39.431,59.934,67.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.752 | Acc: 39.409,59.927,67.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.757 | Acc: 39.393,59.865,67.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.543 | Acc: 34.375,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.488 | Acc: 28.646,47.284,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.461 | Acc: 28.639,47.294,56.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.449 | Acc: 28.471,47.400,56.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 4.689 | Acc: 39.062,54.688,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.606 | Acc: 39.881,60.565,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.651 | Acc: 40.130,60.633,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.662 | Acc: 39.767,60.771,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.679 | Acc: 39.497,60.561,69.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.692 | Acc: 39.395,60.458,69.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.688 | Acc: 39.398,60.479,69.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.682 | Acc: 39.589,60.561,69.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.682 | Acc: 39.499,60.593,69.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.697 | Acc: 39.326,60.571,69.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.707 | Acc: 39.187,60.471,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.708 | Acc: 39.147,60.450,68.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.711 | Acc: 39.251,60.299,68.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.706 | Acc: 39.287,60.333,68.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.715 | Acc: 39.290,60.265,68.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.728 | Acc: 39.242,60.138,68.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.732 | Acc: 39.301,60.030,68.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.739 | Acc: 39.340,59.994,68.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.748 | Acc: 39.337,59.996,68.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.745 | Acc: 39.333,59.968,68.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.168 | Acc: 22.656,46.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.009 | Acc: 19.978,39.546,51.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.924 | Acc: 20.617,39.901,51.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.923 | Acc: 20.287,40.023,50.999,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.877 | Acc: 33.594,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 40.662,61.644,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.541 | Acc: 40.816,61.814,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 40.523,61.629,70.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.592 | Acc: 40.471,61.333,69.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.603 | Acc: 40.277,61.278,69.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.626 | Acc: 40.134,61.247,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.656 | Acc: 39.899,61.015,69.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.664 | Acc: 39.878,60.889,69.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.676 | Acc: 39.723,60.722,68.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.683 | Acc: 39.583,60.681,68.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.685 | Acc: 39.727,60.732,68.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.691 | Acc: 39.776,60.730,68.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.702 | Acc: 39.637,60.644,68.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.707 | Acc: 39.521,60.579,68.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.716 | Acc: 39.473,60.501,68.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.718 | Acc: 39.381,60.499,68.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.720 | Acc: 39.418,60.388,68.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.733 | Acc: 39.487,60.308,68.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.738 | Acc: 39.497,60.347,68.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.401 | Acc: 37.500,52.344,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.192 | Acc: 31.250,50.707,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.233 | Acc: 30.488,50.457,56.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.301 | Acc: 30.123,49.654,55.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.359 | Acc: 43.750,60.156,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.616 | Acc: 41.295,61.086,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 41.082,60.995,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 40.727,60.886,70.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.600 | Acc: 40.490,60.860,70.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.642 | Acc: 40.339,60.396,69.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.631 | Acc: 40.638,60.686,69.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.633 | Acc: 40.564,60.600,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.643 | Acc: 40.489,60.481,69.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.655 | Acc: 40.310,60.497,69.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.680 | Acc: 40.019,60.257,69.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.685 | Acc: 40.021,60.195,69.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.690 | Acc: 39.931,60.127,69.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.693 | Acc: 40.086,60.162,69.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.697 | Acc: 40.063,60.020,68.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.699 | Acc: 39.971,59.995,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.705 | Acc: 40.017,60.013,68.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.716 | Acc: 39.935,59.888,68.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.724 | Acc: 39.930,59.910,68.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.724 | Acc: 40.020,59.933,68.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.601 | Acc: 27.344,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.050 | Acc: 26.004,46.354,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.038 | Acc: 26.696,46.380,55.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.056 | Acc: 26.434,45.927,55.020,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 5.569 | Acc: 34.375,59.375,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 39.955,62.388,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 40.149,61.109,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.609 | Acc: 40.190,60.938,70.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.606 | Acc: 39.979,61.092,70.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.633 | Acc: 39.960,60.821,69.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.644 | Acc: 39.728,60.718,69.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.654 | Acc: 39.666,60.561,69.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.644 | Acc: 39.863,60.671,69.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.645 | Acc: 39.934,60.679,69.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.665 | Acc: 39.836,60.588,68.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.682 | Acc: 39.720,60.481,68.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.681 | Acc: 39.873,60.539,68.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.686 | Acc: 39.850,60.524,68.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.699 | Acc: 39.830,60.401,68.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.713 | Acc: 39.732,60.291,68.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.717 | Acc: 39.688,60.190,68.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.725 | Acc: 39.557,60.131,68.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.732 | Acc: 39.495,60.007,68.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.732 | Acc: 39.503,60.101,68.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.667 | Acc: 30.469,50.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.501 | Acc: 29.092,47.396,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.565 | Acc: 28.411,46.399,54.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.573 | Acc: 28.035,46.158,55.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 4.629 | Acc: 36.719,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.595 | Acc: 38.988,61.384,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.560 | Acc: 40.835,62.443,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 40.151,61.860,70.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.595 | Acc: 40.538,61.526,70.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.601 | Acc: 40.648,61.402,70.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.616 | Acc: 40.393,61.351,69.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.611 | Acc: 40.342,61.392,69.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.608 | Acc: 40.416,61.326,69.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.608 | Acc: 40.336,61.330,69.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.623 | Acc: 40.252,61.287,69.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.626 | Acc: 40.204,61.227,69.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.637 | Acc: 40.200,61.080,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.638 | Acc: 40.224,61.090,69.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.650 | Acc: 40.138,61.071,69.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.662 | Acc: 40.085,60.914,68.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.670 | Acc: 40.075,60.850,68.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.677 | Acc: 40.018,60.736,68.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.689 | Acc: 39.943,60.567,68.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.701 | Acc: 39.852,60.482,68.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.053 | Acc: 33.594,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.187 | Acc: 30.692,50.484,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.196 | Acc: 30.583,49.619,56.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.192 | Acc: 30.443,49.436,56.186,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.540 | Acc: 44.531,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.524 | Acc: 41.592,62.277,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 41.139,61.814,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.619 | Acc: 40.215,61.002,69.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.599 | Acc: 40.239,61.208,69.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.636 | Acc: 40.145,60.752,69.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.653 | Acc: 39.753,60.434,68.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.648 | Acc: 40.010,60.660,68.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.648 | Acc: 40.115,60.792,68.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.660 | Acc: 39.995,60.713,68.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.668 | Acc: 39.976,60.681,68.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.664 | Acc: 40.063,60.757,68.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.668 | Acc: 40.067,60.675,68.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.670 | Acc: 40.011,60.722,68.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.679 | Acc: 39.980,60.707,68.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.673 | Acc: 40.116,60.790,68.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.673 | Acc: 40.136,60.699,68.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.679 | Acc: 40.061,60.541,68.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.681 | Acc: 40.136,60.468,68.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.682 | Acc: 40.114,60.476,68.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.625 | Acc: 33.594,49.219,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.361 | Acc: 25.149,44.457,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.386 | Acc: 25.819,43.998,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.452 | Acc: 24.910,43.353,49.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.604 | Acc: 42.969,70.312,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 40.327,61.942,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 40.111,61.890,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.549 | Acc: 40.343,62.193,69.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.544 | Acc: 40.519,62.085,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.588 | Acc: 40.347,61.556,69.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.594 | Acc: 40.276,61.428,69.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.608 | Acc: 40.204,61.292,69.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.638 | Acc: 39.965,60.923,68.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.637 | Acc: 40.038,60.881,68.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.629 | Acc: 40.225,61.023,69.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.619 | Acc: 40.307,61.150,69.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.634 | Acc: 40.184,61.041,69.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.649 | Acc: 40.125,60.836,68.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.656 | Acc: 40.108,60.779,68.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.657 | Acc: 40.140,60.740,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.652 | Acc: 40.199,60.718,68.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.655 | Acc: 40.130,60.766,68.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.660 | Acc: 40.084,60.715,68.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.664 | Acc: 39.998,60.646,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.290 | Acc: 32.031,56.250,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.210 | Acc: 28.497,50.818,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.269 | Acc: 28.258,49.962,57.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.302 | Acc: 28.330,49.808,57.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 4.461 | Acc: 39.844,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.617 | Acc: 39.137,61.905,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 39.901,61.757,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 40.241,61.539,69.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.550 | Acc: 40.345,61.950,70.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.549 | Acc: 40.215,61.982,70.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.559 | Acc: 40.147,61.648,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.573 | Acc: 40.148,61.602,70.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.593 | Acc: 40.198,61.442,69.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.602 | Acc: 40.146,61.391,69.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.614 | Acc: 39.968,61.318,69.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.615 | Acc: 40.017,61.224,69.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.616 | Acc: 40.054,61.236,69.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.613 | Acc: 40.068,61.219,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.619 | Acc: 39.986,61.135,69.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.623 | Acc: 39.961,61.018,69.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.639 | Acc: 39.851,60.879,69.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.643 | Acc: 39.853,60.832,69.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.647 | Acc: 39.913,60.764,69.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.649 | Acc: 39.926,60.745,69.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.969 | Acc: 35.156,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.395 | Acc: 30.841,47.396,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.466 | Acc: 30.183,45.751,54.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.473 | Acc: 30.085,45.581,54.316,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 4.268 | Acc: 42.969,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 40.662,61.049,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.455 | Acc: 41.387,61.700,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.521 | Acc: 40.791,61.335,70.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.513 | Acc: 41.184,61.651,70.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.540 | Acc: 41.035,61.610,70.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.552 | Acc: 40.961,61.622,70.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.591 | Acc: 40.486,61.059,69.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.598 | Acc: 40.538,60.947,69.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.603 | Acc: 40.452,60.989,69.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.616 | Acc: 40.306,60.860,69.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.617 | Acc: 40.378,60.909,69.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.631 | Acc: 40.226,60.626,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.636 | Acc: 40.200,60.653,69.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.638 | Acc: 40.147,60.698,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.640 | Acc: 40.194,60.709,69.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.649 | Acc: 40.143,60.602,68.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.658 | Acc: 40.075,60.527,68.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.659 | Acc: 40.056,60.552,68.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.660 | Acc: 40.045,60.611,68.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.423 | Acc: 27.344,44.531,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.771 | Acc: 27.567,46.280,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.823 | Acc: 27.820,45.084,52.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.825 | Acc: 27.510,44.980,52.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 4.316 | Acc: 46.094,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.488 | Acc: 40.699,62.723,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.510 | Acc: 41.082,62.824,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.520 | Acc: 41.176,62.282,70.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.565 | Acc: 40.451,61.825,70.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.592 | Acc: 40.494,61.363,69.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.614 | Acc: 40.322,61.054,69.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.620 | Acc: 40.137,61.087,69.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.631 | Acc: 40.125,61.049,69.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.632 | Acc: 40.137,61.041,69.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.627 | Acc: 40.221,61.085,69.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.631 | Acc: 40.201,61.026,69.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.621 | Acc: 40.362,61.203,69.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.624 | Acc: 40.317,61.159,69.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.618 | Acc: 40.369,61.271,69.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.619 | Acc: 40.389,61.252,69.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.629 | Acc: 40.338,61.152,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.639 | Acc: 40.311,61.052,68.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.647 | Acc: 40.240,61.015,68.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.640 | Acc: 40.287,61.052,68.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.691 | Acc: 28.906,51.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.841 | Acc: 25.521,48.586,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.879 | Acc: 25.191,47.675,53.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.895 | Acc: 25.346,46.798,53.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 5.154 | Acc: 32.812,57.031,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.525 | Acc: 41.295,62.351,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 40.720,61.357,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 40.369,61.411,70.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.553 | Acc: 40.316,61.613,70.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.542 | Acc: 40.439,61.858,70.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.540 | Acc: 40.360,61.783,70.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.562 | Acc: 40.453,61.569,70.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.569 | Acc: 40.402,61.559,69.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.592 | Acc: 40.133,61.244,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.585 | Acc: 40.291,61.342,69.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.571 | Acc: 40.448,61.496,69.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.576 | Acc: 40.567,61.414,69.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.595 | Acc: 40.472,61.222,69.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.602 | Acc: 40.366,61.188,69.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.610 | Acc: 40.290,61.174,69.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.619 | Acc: 40.240,61.052,69.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.625 | Acc: 40.300,60.995,69.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.623 | Acc: 40.309,61.095,69.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.628 | Acc: 40.297,61.001,69.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.806 | Acc: 28.906,42.188,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.921 | Acc: 25.744,45.647,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.901 | Acc: 26.467,45.446,54.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.911 | Acc: 26.601,45.492,54.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.312 | Acc: 39.062,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.622 | Acc: 40.253,61.086,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 40.034,60.766,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 39.600,60.809,69.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.624 | Acc: 39.670,60.764,69.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.607 | Acc: 39.681,61.046,69.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.622 | Acc: 39.618,60.944,69.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.625 | Acc: 39.522,61.004,69.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.631 | Acc: 39.596,60.908,69.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.620 | Acc: 39.783,61.158,69.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.630 | Acc: 39.743,61.023,69.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.629 | Acc: 39.837,61.008,69.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.614 | Acc: 39.980,61.109,69.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.619 | Acc: 39.966,61.042,69.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.633 | Acc: 39.908,60.910,69.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.640 | Acc: 40.015,60.888,69.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.643 | Acc: 40.012,60.809,69.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.652 | Acc: 39.890,60.759,69.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.656 | Acc: 39.809,60.723,69.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.656 | Acc: 39.875,60.755,69.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.425 | Acc: 28.906,47.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.799 | Acc: 25.558,45.424,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.767 | Acc: 25.476,46.094,54.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.755 | Acc: 25.256,46.017,54.022,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 3.943 | Acc: 46.875,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.428 | Acc: 42.448,62.202,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.447 | Acc: 42.435,61.928,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.497 | Acc: 41.919,61.770,71.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.502 | Acc: 41.541,61.902,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.526 | Acc: 41.043,61.951,70.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.534 | Acc: 40.922,61.983,70.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.545 | Acc: 40.758,61.863,70.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.546 | Acc: 40.780,61.952,70.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.543 | Acc: 40.832,61.904,70.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.558 | Acc: 40.648,61.734,70.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.574 | Acc: 40.781,61.563,70.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.582 | Acc: 40.586,61.566,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.581 | Acc: 40.643,61.539,69.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.583 | Acc: 40.770,61.588,69.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.581 | Acc: 40.794,61.579,69.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.593 | Acc: 40.737,61.436,69.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.596 | Acc: 40.655,61.517,69.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.607 | Acc: 40.538,61.370,69.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.610 | Acc: 40.475,61.329,69.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.416 | Acc: 25.000,38.281,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.383 | Acc: 24.665,41.443,51.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.401 | Acc: 24.009,41.197,51.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.435 | Acc: 23.630,40.715,51.562,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 5.022 | Acc: 31.250,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 39.323,61.533,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.528 | Acc: 39.672,61.395,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.497 | Acc: 40.574,61.655,71.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.498 | Acc: 40.808,61.825,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.493 | Acc: 40.927,61.912,71.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.516 | Acc: 40.612,61.751,71.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.511 | Acc: 40.625,61.830,71.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.517 | Acc: 40.596,61.864,70.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.516 | Acc: 40.573,61.904,70.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.529 | Acc: 40.524,61.765,70.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.545 | Acc: 40.501,61.775,70.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.562 | Acc: 40.388,61.673,70.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.571 | Acc: 40.323,61.590,70.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.577 | Acc: 40.361,61.516,70.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.576 | Acc: 40.378,61.511,70.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.575 | Acc: 40.423,61.602,70.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.590 | Acc: 40.339,61.432,69.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.591 | Acc: 40.341,61.429,69.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.596 | Acc: 40.328,61.397,69.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.364 | Acc: 26.562,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.907 | Acc: 27.046,45.759,54.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.897 | Acc: 26.810,45.732,53.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.913 | Acc: 26.550,45.786,53.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 4.360 | Acc: 42.969,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.476 | Acc: 41.257,62.612,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 40.263,61.738,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.512 | Acc: 40.330,62.282,70.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.530 | Acc: 40.143,61.873,70.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.552 | Acc: 39.774,61.657,70.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.530 | Acc: 40.231,61.732,70.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.551 | Acc: 40.248,61.553,69.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.576 | Acc: 39.955,61.321,69.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.578 | Acc: 39.943,61.287,69.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.575 | Acc: 39.949,61.377,69.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.574 | Acc: 39.876,61.394,69.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.586 | Acc: 39.860,61.281,69.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.594 | Acc: 39.784,61.114,69.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.601 | Acc: 39.835,61.199,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.611 | Acc: 39.810,61.117,69.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.604 | Acc: 39.946,61.249,69.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.594 | Acc: 40.068,61.318,69.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.598 | Acc: 40.058,61.264,69.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.600 | Acc: 40.032,61.249,69.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.912 | Acc: 32.031,44.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.784 | Acc: 29.501,42.708,52.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.818 | Acc: 29.992,42.873,51.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.818 | Acc: 29.406,43.033,51.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 3.964 | Acc: 47.656,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 40.774,61.458,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 40.568,60.976,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.546 | Acc: 40.535,61.463,70.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.574 | Acc: 40.201,61.073,70.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.569 | Acc: 40.385,61.170,70.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.570 | Acc: 40.515,61.176,70.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.552 | Acc: 40.675,61.497,70.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.550 | Acc: 40.741,61.476,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.557 | Acc: 40.698,61.443,70.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.560 | Acc: 40.637,61.532,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.571 | Acc: 40.561,61.482,70.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.568 | Acc: 40.583,61.573,70.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.569 | Acc: 40.613,61.527,69.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.571 | Acc: 40.453,61.496,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.570 | Acc: 40.545,61.542,69.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.572 | Acc: 40.547,61.480,69.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.585 | Acc: 40.439,61.329,69.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.587 | Acc: 40.454,61.269,69.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.596 | Acc: 40.424,61.239,69.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.584 | Acc: 33.594,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.858 | Acc: 31.027,44.494,52.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.866 | Acc: 31.631,43.960,51.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.863 | Acc: 31.673,43.904,51.447,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 4.460 | Acc: 37.500,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.522 | Acc: 40.104,61.868,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 40.492,62.138,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.467 | Acc: 40.932,61.988,71.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.472 | Acc: 40.808,62.269,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.502 | Acc: 40.772,61.912,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.536 | Acc: 40.560,61.686,70.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.544 | Acc: 40.542,61.713,70.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.541 | Acc: 40.766,61.728,70.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.539 | Acc: 40.793,61.745,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.554 | Acc: 40.668,61.602,70.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.549 | Acc: 40.837,61.641,70.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.553 | Acc: 40.939,61.576,70.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.559 | Acc: 40.912,61.512,69.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.567 | Acc: 40.839,61.566,69.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.571 | Acc: 40.809,61.602,69.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.576 | Acc: 40.849,61.595,69.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.577 | Acc: 40.861,61.684,69.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.576 | Acc: 40.872,61.671,69.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.577 | Acc: 40.834,61.655,69.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.546 | Acc: 25.781,54.688,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.189 | Acc: 22.693,46.354,54.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.227 | Acc: 22.637,46.094,53.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.248 | Acc: 22.439,45.722,53.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 4.208 | Acc: 50.781,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.386 | Acc: 42.225,62.500,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.433 | Acc: 41.787,62.976,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.455 | Acc: 41.931,62.679,71.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.497 | Acc: 41.387,62.105,70.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.509 | Acc: 41.267,62.206,70.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.497 | Acc: 41.238,62.416,70.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.490 | Acc: 41.063,62.439,70.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.500 | Acc: 41.159,62.398,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.508 | Acc: 41.212,62.358,70.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.508 | Acc: 41.329,62.267,70.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.514 | Acc: 41.198,62.171,70.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.511 | Acc: 41.215,62.150,70.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.520 | Acc: 41.134,62.042,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.524 | Acc: 41.087,62.027,70.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.540 | Acc: 41.051,61.869,70.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.541 | Acc: 41.158,61.838,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.552 | Acc: 41.021,61.732,69.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.562 | Acc: 40.820,61.697,69.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.564 | Acc: 40.836,61.690,69.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.504 | Acc: 33.594,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.369 | Acc: 31.734,48.735,53.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.362 | Acc: 31.726,48.037,54.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.392 | Acc: 31.173,48.002,54.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 5.016 | Acc: 38.281,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 40.811,61.830,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.510 | Acc: 40.644,62.081,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.466 | Acc: 40.587,62.359,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.487 | Acc: 40.451,62.259,71.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.472 | Acc: 40.509,62.376,70.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.485 | Acc: 40.367,62.371,70.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.484 | Acc: 40.475,62.395,70.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.485 | Acc: 40.601,62.311,70.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.494 | Acc: 40.431,62.319,70.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.507 | Acc: 40.598,62.224,70.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.501 | Acc: 40.696,62.313,70.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.516 | Acc: 40.628,62.260,70.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.528 | Acc: 40.553,62.054,70.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.536 | Acc: 40.594,61.994,70.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.534 | Acc: 40.596,61.991,70.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.540 | Acc: 40.632,61.969,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.545 | Acc: 40.657,61.936,70.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.550 | Acc: 40.644,61.922,70.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.558 | Acc: 40.703,61.819,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.958 | Acc: 30.469,47.656,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.687 | Acc: 27.976,46.429,54.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.773 | Acc: 27.401,45.617,53.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.783 | Acc: 26.960,45.569,53.817,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 5.406 | Acc: 31.250,50.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.518 | Acc: 40.179,62.463,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.469 | Acc: 40.454,63.224,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.485 | Acc: 40.817,62.897,71.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.489 | Acc: 41.155,62.606,70.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.459 | Acc: 41.298,62.980,71.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.467 | Acc: 41.129,62.674,71.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.474 | Acc: 41.102,62.666,71.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.499 | Acc: 40.848,62.476,70.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.509 | Acc: 40.806,62.396,70.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.518 | Acc: 40.804,62.356,70.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.526 | Acc: 40.784,62.334,70.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.531 | Acc: 40.790,62.289,70.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.531 | Acc: 40.781,62.305,70.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.543 | Acc: 40.689,62.222,70.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.548 | Acc: 40.773,62.261,70.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.550 | Acc: 40.844,62.244,70.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.553 | Acc: 40.801,62.161,69.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.559 | Acc: 40.770,62.069,69.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.565 | Acc: 40.697,62.020,69.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.777 | Acc: 28.906,48.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.879 | Acc: 27.232,48.140,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.935 | Acc: 27.306,47.675,54.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.977 | Acc: 27.139,46.952,54.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 3.962 | Acc: 42.188,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.449 | Acc: 40.551,63.579,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.386 | Acc: 41.311,64.005,72.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.394 | Acc: 41.496,63.576,72.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.429 | Acc: 41.088,63.223,71.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.444 | Acc: 41.136,63.011,71.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.490 | Acc: 40.922,62.655,70.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.502 | Acc: 40.985,62.456,70.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.507 | Acc: 40.926,62.345,70.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.511 | Acc: 40.927,62.189,70.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.528 | Acc: 40.827,61.944,70.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.535 | Acc: 40.819,61.966,70.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.559 | Acc: 40.619,61.725,69.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.563 | Acc: 40.634,61.731,69.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.571 | Acc: 40.633,61.705,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.574 | Acc: 40.565,61.649,69.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.570 | Acc: 40.596,61.736,69.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.566 | Acc: 40.655,61.817,69.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.567 | Acc: 40.651,61.784,69.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.566 | Acc: 40.631,61.850,69.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.767 | Acc: 30.469,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.163 | Acc: 28.757,42.039,50.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.187 | Acc: 29.059,41.616,50.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.214 | Acc: 29.457,41.189,49.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 4.131 | Acc: 39.844,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 42.560,63.653,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.338 | Acc: 42.378,63.434,72.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.392 | Acc: 41.957,62.577,71.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.403 | Acc: 42.139,62.548,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.416 | Acc: 41.808,62.748,71.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.421 | Acc: 41.755,62.700,71.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.426 | Acc: 41.728,62.639,71.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.444 | Acc: 41.382,62.607,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.462 | Acc: 41.251,62.379,70.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.466 | Acc: 41.367,62.426,70.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.476 | Acc: 41.275,62.376,70.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.488 | Acc: 41.247,62.302,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.488 | Acc: 41.245,62.249,70.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.506 | Acc: 41.109,61.991,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.514 | Acc: 40.960,61.989,70.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.523 | Acc: 40.912,61.913,70.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.531 | Acc: 40.854,61.790,70.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.536 | Acc: 40.798,61.762,70.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.540 | Acc: 40.777,61.690,70.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.358 | Acc: 34.375,43.750,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.685 | Acc: 29.576,45.052,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.632 | Acc: 30.088,45.636,55.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.653 | Acc: 29.559,45.466,54.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 4.267 | Acc: 44.531,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 41.555,62.612,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.439 | Acc: 40.854,62.900,72.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.416 | Acc: 41.163,63.179,72.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.443 | Acc: 40.856,62.876,71.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.457 | Acc: 40.749,62.771,71.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.461 | Acc: 40.819,62.732,71.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.486 | Acc: 40.719,62.467,71.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.481 | Acc: 40.727,62.621,71.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.467 | Acc: 40.901,62.668,71.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.479 | Acc: 40.979,62.453,70.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.489 | Acc: 41.003,62.362,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.504 | Acc: 40.855,62.166,70.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.503 | Acc: 40.990,62.207,70.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.512 | Acc: 40.945,62.086,70.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.530 | Acc: 40.778,61.955,70.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.536 | Acc: 40.761,61.855,70.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.541 | Acc: 40.751,61.804,70.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.533 | Acc: 40.850,61.846,70.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.537 | Acc: 40.787,61.793,70.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.539 | Acc: 31.250,47.656,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.670 | Acc: 27.567,46.503,53.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.678 | Acc: 27.591,46.494,52.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.705 | Acc: 27.792,46.158,52.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 4.232 | Acc: 44.531,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 41.406,61.682,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.469 | Acc: 41.597,62.329,71.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.437 | Acc: 42.008,62.577,71.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.449 | Acc: 41.792,62.432,70.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.446 | Acc: 41.507,62.693,70.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.446 | Acc: 41.632,62.687,70.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.438 | Acc: 41.545,62.794,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.445 | Acc: 41.474,62.665,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.446 | Acc: 41.566,62.690,70.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.443 | Acc: 41.577,62.683,70.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.457 | Acc: 41.463,62.574,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.457 | Acc: 41.478,62.617,70.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.479 | Acc: 41.379,62.473,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.486 | Acc: 41.362,62.414,70.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.494 | Acc: 41.409,62.430,70.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.498 | Acc: 41.406,62.373,70.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.506 | Acc: 41.372,62.328,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.513 | Acc: 41.266,62.212,70.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.515 | Acc: 41.131,62.158,70.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.510 | Acc: 32.031,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.162 | Acc: 26.637,43.713,52.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.157 | Acc: 27.096,44.017,52.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.192 | Acc: 27.036,43.814,52.075,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 3.942 | Acc: 46.094,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.404 | Acc: 41.555,63.132,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.412 | Acc: 41.730,63.396,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.432 | Acc: 41.291,62.795,71.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.415 | Acc: 41.464,62.780,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.429 | Acc: 41.460,62.585,71.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.441 | Acc: 41.368,62.519,71.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.451 | Acc: 41.246,62.395,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.463 | Acc: 41.159,62.267,70.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.477 | Acc: 40.957,62.051,70.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.481 | Acc: 40.979,62.135,70.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.473 | Acc: 41.003,62.320,70.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.479 | Acc: 40.985,62.273,70.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.491 | Acc: 40.942,62.165,70.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.499 | Acc: 40.928,62.086,70.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.503 | Acc: 40.882,62.043,70.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.504 | Acc: 40.851,62.055,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.511 | Acc: 40.902,62.085,70.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.509 | Acc: 41.045,62.121,70.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.517 | Acc: 40.937,61.985,70.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.330 | Acc: 24.219,44.531,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.293 | Acc: 25.112,42.932,53.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.348 | Acc: 24.104,42.550,52.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.312 | Acc: 23.732,42.930,53.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 3.922 | Acc: 46.094,65.625,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.381 | Acc: 42.336,63.802,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.423 | Acc: 41.139,62.767,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.452 | Acc: 40.459,62.500,71.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.471 | Acc: 40.461,62.452,71.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.455 | Acc: 40.625,62.601,71.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.466 | Acc: 40.838,62.461,71.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.470 | Acc: 40.952,62.533,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.481 | Acc: 40.868,62.447,71.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.473 | Acc: 40.957,62.418,71.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.485 | Acc: 40.862,62.356,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.481 | Acc: 40.979,62.465,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.492 | Acc: 40.914,62.364,70.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.499 | Acc: 40.876,62.225,70.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.511 | Acc: 40.834,62.108,70.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.514 | Acc: 40.895,62.118,70.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.507 | Acc: 40.917,62.196,70.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.509 | Acc: 40.843,62.225,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.512 | Acc: 40.809,62.199,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.522 | Acc: 40.842,62.147,70.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.395 | Acc: 31.250,42.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.794 | Acc: 22.842,40.104,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.847 | Acc: 22.370,39.139,48.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.909 | Acc: 22.836,39.703,48.591,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 4.453 | Acc: 39.062,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 39.286,62.872,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.481 | Acc: 40.854,62.691,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.433 | Acc: 41.509,62.897,71.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.396 | Acc: 41.782,63.436,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.413 | Acc: 41.646,63.181,71.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.421 | Acc: 41.542,63.088,71.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.446 | Acc: 41.456,62.943,70.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.449 | Acc: 41.241,62.932,70.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.465 | Acc: 41.195,62.668,70.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.479 | Acc: 41.161,62.605,70.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.487 | Acc: 41.208,62.521,70.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.482 | Acc: 41.247,62.542,70.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.495 | Acc: 41.128,62.431,70.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.496 | Acc: 41.003,62.389,70.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.502 | Acc: 40.903,62.368,70.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.507 | Acc: 40.878,62.242,70.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.507 | Acc: 40.820,62.225,70.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.510 | Acc: 40.872,62.180,70.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.507 | Acc: 40.920,62.250,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.453 | Acc: 28.906,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.772 | Acc: 27.046,48.214,53.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.722 | Acc: 27.401,48.171,53.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.771 | Acc: 27.459,47.797,53.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 4.397 | Acc: 40.625,59.375,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.327 | Acc: 42.076,63.318,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.346 | Acc: 42.435,63.891,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.371 | Acc: 41.790,63.486,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.382 | Acc: 41.512,63.416,71.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.425 | Acc: 41.282,62.693,71.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.466 | Acc: 41.006,62.364,71.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.482 | Acc: 40.996,62.068,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.485 | Acc: 40.926,62.044,70.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.493 | Acc: 40.966,61.909,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.494 | Acc: 40.777,61.874,70.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.498 | Acc: 40.689,61.892,70.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.512 | Acc: 40.612,61.822,70.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.513 | Acc: 40.568,61.776,70.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.519 | Acc: 40.522,61.755,70.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.522 | Acc: 40.508,61.755,70.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.524 | Acc: 40.535,61.746,70.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.528 | Acc: 40.469,61.710,70.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.528 | Acc: 40.502,61.760,70.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.531 | Acc: 40.596,61.719,70.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.138 | Acc: 29.688,53.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.473 | Acc: 28.534,48.847,57.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.483 | Acc: 28.239,47.656,57.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.522 | Acc: 27.856,46.683,56.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 4.668 | Acc: 36.719,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.561 | Acc: 39.397,62.016,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.408 | Acc: 40.758,63.396,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.392 | Acc: 41.240,63.525,72.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.443 | Acc: 40.683,63.040,71.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.463 | Acc: 40.849,62.871,71.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.494 | Acc: 40.702,62.481,70.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.501 | Acc: 40.797,62.467,70.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.510 | Acc: 41.018,62.524,70.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.496 | Acc: 41.182,62.556,70.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.499 | Acc: 41.243,62.477,70.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.496 | Acc: 41.070,62.472,70.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.505 | Acc: 40.972,62.370,70.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.503 | Acc: 41.008,62.353,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.499 | Acc: 41.081,62.400,70.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.497 | Acc: 41.069,62.477,70.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.502 | Acc: 40.951,62.390,70.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.498 | Acc: 41.053,62.438,70.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.496 | Acc: 41.131,62.411,70.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.511 | Acc: 40.961,62.264,70.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.986 | Acc: 28.125,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.670 | Acc: 27.530,47.470,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.807 | Acc: 26.315,46.208,53.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.824 | Acc: 26.204,46.311,53.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 4.276 | Acc: 41.406,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.356 | Acc: 41.629,63.802,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.362 | Acc: 41.749,63.300,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.372 | Acc: 41.150,63.448,72.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.397 | Acc: 41.078,62.867,72.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.419 | Acc: 41.298,62.546,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.429 | Acc: 41.129,62.674,71.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.413 | Acc: 41.362,62.927,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.422 | Acc: 41.329,62.845,71.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.425 | Acc: 41.290,62.750,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.433 | Acc: 41.251,62.617,71.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.448 | Acc: 41.176,62.567,71.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.448 | Acc: 41.234,62.695,71.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.464 | Acc: 41.173,62.557,71.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.466 | Acc: 41.173,62.547,71.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.470 | Acc: 41.152,62.414,71.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.476 | Acc: 41.107,62.381,70.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.482 | Acc: 41.051,62.319,70.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.487 | Acc: 41.103,62.305,70.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.493 | Acc: 41.115,62.293,70.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.795 | Acc: 32.812,56.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.938 | Acc: 32.366,50.930,57.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.983 | Acc: 32.355,50.781,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.989 | Acc: 32.018,50.064,56.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.432 | Acc: 39.844,63.281,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.300 | Acc: 42.076,63.504,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.369 | Acc: 41.368,63.091,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 40.612,63.268,72.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.428 | Acc: 40.635,63.098,71.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.465 | Acc: 40.648,62.655,71.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.456 | Acc: 40.567,62.694,71.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.462 | Acc: 40.642,62.666,71.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.450 | Acc: 40.659,62.689,71.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.447 | Acc: 40.867,62.794,71.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.445 | Acc: 40.948,62.718,71.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.441 | Acc: 40.950,62.783,71.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.444 | Acc: 40.920,62.724,71.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.447 | Acc: 40.960,62.647,71.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.450 | Acc: 40.881,62.570,71.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.458 | Acc: 40.846,62.547,71.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.468 | Acc: 40.793,62.517,71.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.470 | Acc: 40.925,62.479,70.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.477 | Acc: 40.893,62.470,70.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.484 | Acc: 40.853,62.424,70.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.814 | Acc: 39.062,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.118 | Acc: 32.329,50.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.124 | Acc: 32.965,50.953,57.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.135 | Acc: 32.518,50.525,57.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 4.250 | Acc: 41.406,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.241 | Acc: 41.853,64.323,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.239 | Acc: 42.245,65.187,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.259 | Acc: 41.995,65.190,73.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.317 | Acc: 41.580,64.149,73.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.351 | Acc: 41.576,63.815,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.350 | Acc: 41.529,63.830,72.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.338 | Acc: 41.639,63.946,72.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.344 | Acc: 41.668,63.844,72.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.360 | Acc: 41.609,63.743,72.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.371 | Acc: 41.624,63.549,72.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.379 | Acc: 41.657,63.423,72.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.388 | Acc: 41.542,63.330,71.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.389 | Acc: 41.610,63.308,71.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.397 | Acc: 41.612,63.192,71.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.407 | Acc: 41.611,63.063,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.422 | Acc: 41.479,62.885,71.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.440 | Acc: 41.376,62.745,71.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.444 | Acc: 41.320,62.708,71.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.452 | Acc: 41.220,62.588,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.934 | Acc: 35.156,54.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.037 | Acc: 29.353,52.753,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.935 | Acc: 30.469,52.611,59.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.952 | Acc: 30.418,52.139,59.746,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 3.996 | Acc: 42.969,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.338 | Acc: 42.076,64.249,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.386 | Acc: 41.120,63.110,72.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.439 | Acc: 40.907,62.756,71.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.438 | Acc: 41.040,62.616,71.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.415 | Acc: 41.375,62.763,71.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.412 | Acc: 41.335,62.997,71.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.410 | Acc: 41.406,63.010,71.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.424 | Acc: 41.241,62.951,71.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.437 | Acc: 41.083,62.832,71.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.448 | Acc: 41.037,62.620,71.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.448 | Acc: 41.014,62.659,71.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.453 | Acc: 41.085,62.691,71.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.456 | Acc: 41.014,62.710,70.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.456 | Acc: 41.014,62.784,70.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.464 | Acc: 41.027,62.718,70.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.471 | Acc: 40.973,62.653,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.466 | Acc: 41.010,62.720,70.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.468 | Acc: 40.993,62.721,70.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.470 | Acc: 41.006,62.711,70.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.528 | Acc: 29.688,52.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.504 | Acc: 28.274,50.707,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.528 | Acc: 28.525,50.438,55.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.504 | Acc: 28.112,50.026,56.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 4.795 | Acc: 40.625,60.938,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.342 | Acc: 43.192,63.542,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.374 | Acc: 42.035,63.472,72.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.383 | Acc: 41.778,63.384,72.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.370 | Acc: 41.715,63.542,72.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.366 | Acc: 41.816,63.653,72.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.383 | Acc: 41.852,63.378,71.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.397 | Acc: 41.744,63.320,71.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.403 | Acc: 41.751,63.204,71.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.406 | Acc: 41.687,63.212,71.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.415 | Acc: 41.674,63.172,71.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.414 | Acc: 41.696,63.235,71.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.411 | Acc: 41.727,63.268,71.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.409 | Acc: 41.679,63.245,71.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.414 | Acc: 41.637,63.170,71.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.418 | Acc: 41.598,63.107,71.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.427 | Acc: 41.508,62.972,71.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.444 | Acc: 41.370,62.784,70.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.449 | Acc: 41.413,62.781,70.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.457 | Acc: 41.384,62.693,70.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.836 | Acc: 26.562,50.000,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.095 | Acc: 23.586,45.945,55.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.145 | Acc: 23.647,45.694,55.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.124 | Acc: 23.617,45.581,55.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 3.974 | Acc: 50.781,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.466 | Acc: 41.034,61.644,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.374 | Acc: 41.959,63.110,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 41.598,63.204,71.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.398 | Acc: 41.262,63.146,71.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.384 | Acc: 41.476,63.165,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.378 | Acc: 41.593,63.107,71.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.350 | Acc: 41.766,63.414,71.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.361 | Acc: 41.591,63.417,71.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.379 | Acc: 41.475,63.277,71.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.393 | Acc: 41.418,63.153,71.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.404 | Acc: 41.512,63.023,71.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.412 | Acc: 41.435,63.090,70.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.427 | Acc: 41.325,62.937,70.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.432 | Acc: 41.264,62.948,70.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.446 | Acc: 41.167,62.809,70.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.448 | Acc: 41.173,62.743,70.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.460 | Acc: 41.118,62.690,70.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.463 | Acc: 41.118,62.669,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.471 | Acc: 41.101,62.588,70.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.876 | Acc: 38.281,46.875,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.532 | Acc: 31.957,47.321,53.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.519 | Acc: 32.679,46.951,53.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.549 | Acc: 32.006,46.580,53.266,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 4.609 | Acc: 46.094,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.472 | Acc: 41.369,63.244,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.423 | Acc: 40.758,63.548,72.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.360 | Acc: 41.381,64.050,72.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.355 | Acc: 41.242,64.043,72.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.366 | Acc: 41.143,64.032,72.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.390 | Acc: 41.090,63.772,71.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.379 | Acc: 41.268,63.791,72.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.384 | Acc: 41.168,63.757,71.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.398 | Acc: 41.091,63.627,71.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.407 | Acc: 41.021,63.464,71.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.410 | Acc: 41.222,63.419,71.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.415 | Acc: 41.212,63.340,71.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.413 | Acc: 41.239,63.377,71.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.411 | Acc: 41.273,63.301,71.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.417 | Acc: 41.323,63.248,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.433 | Acc: 41.253,63.091,71.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.438 | Acc: 41.312,63.057,71.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.443 | Acc: 41.263,62.993,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.441 | Acc: 41.380,63.021,70.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.541 | Acc: 35.938,57.031,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.019 | Acc: 30.618,50.409,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.031 | Acc: 31.079,50.171,58.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.071 | Acc: 30.686,49.846,58.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 4.330 | Acc: 39.844,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.414 | Acc: 41.332,62.946,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.393 | Acc: 41.063,63.357,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.376 | Acc: 41.419,63.499,71.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.403 | Acc: 41.532,62.934,71.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.423 | Acc: 41.685,62.670,71.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.422 | Acc: 41.632,62.784,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.414 | Acc: 41.772,62.993,71.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.408 | Acc: 41.629,63.068,71.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.405 | Acc: 41.644,63.117,71.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.412 | Acc: 41.601,62.920,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.418 | Acc: 41.579,62.938,71.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.422 | Acc: 41.546,62.989,71.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.431 | Acc: 41.397,62.949,71.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.432 | Acc: 41.390,62.950,71.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.431 | Acc: 41.453,62.985,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.431 | Acc: 41.438,63.062,71.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.440 | Acc: 41.363,62.986,70.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.440 | Acc: 41.452,62.978,70.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.438 | Acc: 41.478,63.006,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.473 | Acc: 32.031,44.531,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.354 | Acc: 30.208,50.298,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.393 | Acc: 29.707,49.638,56.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.409 | Acc: 29.547,49.923,56.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 4.243 | Acc: 46.094,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.429 | Acc: 41.034,63.393,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.388 | Acc: 41.444,63.548,72.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 42.085,63.691,72.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.369 | Acc: 42.024,63.657,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.366 | Acc: 42.025,63.738,72.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.386 | Acc: 41.736,63.462,72.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.382 | Acc: 41.694,63.237,72.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.393 | Acc: 41.780,63.087,71.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.394 | Acc: 41.799,63.195,71.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.401 | Acc: 41.791,63.075,71.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.408 | Acc: 41.774,62.960,71.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.413 | Acc: 41.682,62.905,71.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.416 | Acc: 41.685,62.898,71.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.416 | Acc: 41.637,62.900,71.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.426 | Acc: 41.593,62.843,71.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.430 | Acc: 41.577,62.836,71.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.427 | Acc: 41.670,62.878,71.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.430 | Acc: 41.636,62.838,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.434 | Acc: 41.613,62.834,71.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.734 | Acc: 38.281,58.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.853 | Acc: 33.147,54.092,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.834 | Acc: 33.918,53.601,59.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.858 | Acc: 33.555,52.920,59.349,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 4.060 | Acc: 46.094,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.340 | Acc: 41.332,63.170,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.406 | Acc: 42.073,62.976,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.411 | Acc: 41.842,62.846,71.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.414 | Acc: 41.985,63.098,71.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.390 | Acc: 41.986,63.212,71.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.401 | Acc: 41.852,63.165,71.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.402 | Acc: 41.717,63.204,71.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.405 | Acc: 41.901,63.213,71.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.417 | Acc: 41.803,63.096,71.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.427 | Acc: 41.713,62.994,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.421 | Acc: 41.756,63.037,71.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.419 | Acc: 41.899,63.025,71.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.427 | Acc: 41.879,62.988,71.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.432 | Acc: 41.876,62.853,71.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.439 | Acc: 41.884,62.700,71.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.441 | Acc: 41.842,62.639,71.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.443 | Acc: 41.807,62.523,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.452 | Acc: 41.698,62.461,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.457 | Acc: 41.617,62.430,70.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.067 | Acc: 35.156,55.469,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.027 | Acc: 30.506,51.860,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.020 | Acc: 31.174,51.334,57.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.039 | Acc: 31.519,51.025,57.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 4.423 | Acc: 33.594,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.193 | Acc: 43.527,64.658,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.256 | Acc: 41.997,64.748,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.289 | Acc: 42.200,64.050,72.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.301 | Acc: 42.265,63.966,73.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.297 | Acc: 42.319,64.093,72.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.327 | Acc: 42.097,63.701,72.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.334 | Acc: 42.016,63.780,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.358 | Acc: 41.799,63.500,72.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.377 | Acc: 41.773,63.242,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.379 | Acc: 41.857,63.172,71.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.395 | Acc: 41.707,63.048,71.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.394 | Acc: 41.880,63.171,71.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.392 | Acc: 41.933,63.111,71.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.410 | Acc: 41.768,63.070,71.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.413 | Acc: 41.650,63.029,71.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.421 | Acc: 41.630,62.887,71.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.422 | Acc: 41.583,62.878,71.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.424 | Acc: 41.530,62.903,71.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.430 | Acc: 41.486,62.826,71.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.627 | Acc: 28.125,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.271 | Acc: 26.451,44.792,54.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.187 | Acc: 26.143,44.989,54.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.178 | Acc: 25.897,44.544,54.303,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 4.613 | Acc: 42.188,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.365 | Acc: 41.518,63.356,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.295 | Acc: 42.264,63.891,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 41.842,64.037,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.347 | Acc: 41.561,63.542,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.335 | Acc: 41.762,63.769,72.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.346 | Acc: 41.813,63.707,72.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.373 | Acc: 41.628,63.625,72.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.383 | Acc: 41.746,63.626,71.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.386 | Acc: 41.657,63.424,71.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.395 | Acc: 41.476,63.297,71.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.415 | Acc: 41.435,63.083,71.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.429 | Acc: 41.432,62.944,71.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.423 | Acc: 41.466,63.039,71.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.430 | Acc: 41.442,62.923,71.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.431 | Acc: 41.391,62.863,71.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.432 | Acc: 41.426,62.841,71.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.435 | Acc: 41.328,62.809,71.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.442 | Acc: 41.326,62.712,70.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.444 | Acc: 41.283,62.754,70.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.754 | Acc: 28.125,48.438,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.931 | Acc: 25.037,46.280,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.928 | Acc: 26.029,46.303,54.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.996 | Acc: 25.961,45.953,54.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 4.396 | Acc: 35.938,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.275 | Acc: 41.890,65.774,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.266 | Acc: 42.264,64.653,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 42.008,64.472,72.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.315 | Acc: 42.062,64.217,72.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.314 | Acc: 42.010,64.171,72.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.308 | Acc: 42.252,64.495,72.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.324 | Acc: 41.955,64.328,72.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.335 | Acc: 41.989,64.232,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.342 | Acc: 41.933,64.235,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.345 | Acc: 42.090,64.191,71.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.351 | Acc: 42.014,64.077,71.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.360 | Acc: 41.977,63.972,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.371 | Acc: 41.966,63.775,71.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.389 | Acc: 41.776,63.556,71.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.394 | Acc: 41.783,63.427,71.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.394 | Acc: 41.818,63.318,71.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.396 | Acc: 41.720,63.229,71.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.405 | Acc: 41.644,63.128,71.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.413 | Acc: 41.591,63.058,71.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.320 | Acc: 35.156,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.231 | Acc: 31.250,49.740,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.270 | Acc: 31.364,49.352,57.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.320 | Acc: 31.084,48.911,56.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 4.445 | Acc: 42.969,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.311 | Acc: 41.034,64.323,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.272 | Acc: 41.940,64.653,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.270 | Acc: 41.931,64.524,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.277 | Acc: 41.956,64.400,73.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.282 | Acc: 41.925,64.325,73.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.277 | Acc: 41.942,64.437,73.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.301 | Acc: 41.628,64.389,72.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.319 | Acc: 41.557,64.121,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.340 | Acc: 41.484,63.851,72.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.357 | Acc: 41.453,63.705,72.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.373 | Acc: 41.512,63.592,71.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.381 | Acc: 41.559,63.466,71.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.391 | Acc: 41.418,63.329,71.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.405 | Acc: 41.348,63.187,71.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.409 | Acc: 41.370,63.209,71.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.403 | Acc: 41.457,63.303,71.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.409 | Acc: 41.541,63.256,71.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.408 | Acc: 41.538,63.279,71.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.416 | Acc: 41.474,63.171,71.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.812 | Acc: 30.469,45.312,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.466 | Acc: 30.878,48.884,56.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.474 | Acc: 30.526,48.380,55.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.503 | Acc: 30.123,48.079,55.853,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 4.158 | Acc: 39.062,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 41.146,62.463,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.347 | Acc: 41.616,63.720,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.331 | Acc: 41.611,63.922,72.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.336 | Acc: 41.638,63.465,72.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.317 | Acc: 41.808,63.637,72.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.331 | Acc: 41.606,63.527,72.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.347 | Acc: 41.595,63.353,72.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.361 | Acc: 41.460,63.242,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.361 | Acc: 41.609,63.264,71.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.379 | Acc: 41.581,63.211,71.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.385 | Acc: 41.548,63.179,71.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.394 | Acc: 41.572,63.113,71.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.400 | Acc: 41.487,62.979,71.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.403 | Acc: 41.465,63.070,71.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.407 | Acc: 41.482,63.022,71.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.411 | Acc: 41.443,62.936,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.408 | Acc: 41.491,63.043,71.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.405 | Acc: 41.560,63.073,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.405 | Acc: 41.628,63.125,71.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.168 | Acc: 35.156,50.781,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.404 | Acc: 29.464,49.144,56.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.388 | Acc: 30.030,48.800,56.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.436 | Acc: 29.662,48.297,56.481,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 4.478 | Acc: 36.719,59.375,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.281 | Acc: 41.853,63.765,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.248 | Acc: 41.883,65.034,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.205 | Acc: 42.482,65.292,73.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.253 | Acc: 41.927,64.660,72.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.265 | Acc: 42.141,64.534,72.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.285 | Acc: 41.987,64.192,72.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.286 | Acc: 41.861,64.290,72.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.297 | Acc: 41.843,64.247,72.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.306 | Acc: 41.777,64.175,72.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.321 | Acc: 41.702,64.094,72.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.339 | Acc: 41.618,63.992,72.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.350 | Acc: 41.604,63.913,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.354 | Acc: 41.616,63.877,72.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.359 | Acc: 41.604,63.826,72.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.363 | Acc: 41.619,63.722,71.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.369 | Acc: 41.650,63.651,71.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.380 | Acc: 41.567,63.581,71.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.375 | Acc: 41.623,63.623,71.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.384 | Acc: 41.611,63.533,71.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.176 | Acc: 36.719,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.218 | Acc: 31.882,51.860,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.220 | Acc: 31.136,51.162,57.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.213 | Acc: 31.429,51.370,56.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 4.284 | Acc: 40.625,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.279 | Acc: 41.741,64.881,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 41.806,63.834,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.330 | Acc: 41.534,63.947,72.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.362 | Acc: 41.435,63.628,72.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.356 | Acc: 41.646,63.699,72.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.358 | Acc: 41.497,63.727,72.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.364 | Acc: 41.439,63.769,72.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.358 | Acc: 41.503,63.859,72.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.362 | Acc: 41.488,63.842,72.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.362 | Acc: 41.608,63.942,72.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.370 | Acc: 41.569,63.956,72.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.359 | Acc: 41.546,64.095,72.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.364 | Acc: 41.553,64.080,72.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.367 | Acc: 41.545,64.010,72.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.368 | Acc: 41.671,64.021,71.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.377 | Acc: 41.620,63.882,71.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.381 | Acc: 41.619,63.843,71.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.394 | Acc: 41.532,63.692,71.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.398 | Acc: 41.519,63.599,71.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.743 | Acc: 35.938,52.344,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.196 | Acc: 31.808,48.326,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.127 | Acc: 31.803,48.476,57.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.146 | Acc: 31.596,48.002,57.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 4.564 | Acc: 32.031,61.719,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.310 | Acc: 40.923,63.951,73.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.250 | Acc: 41.368,64.291,73.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.210 | Acc: 41.829,65.036,73.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.240 | Acc: 41.811,64.728,73.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.240 | Acc: 42.056,64.674,73.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.246 | Acc: 42.078,64.799,72.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.275 | Acc: 41.822,64.561,72.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.303 | Acc: 41.731,64.257,72.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.312 | Acc: 41.726,64.157,72.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.327 | Acc: 41.593,64.004,72.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.346 | Acc: 41.473,63.730,72.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.345 | Acc: 41.568,63.673,71.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.350 | Acc: 41.616,63.676,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.351 | Acc: 41.626,63.737,71.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.354 | Acc: 41.642,63.704,71.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.361 | Acc: 41.613,63.585,71.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.361 | Acc: 41.718,63.625,71.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.368 | Acc: 41.651,63.604,71.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.373 | Acc: 41.622,63.554,71.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.402 | Acc: 23.438,42.188,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.435 | Acc: 22.842,43.676,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.570 | Acc: 22.485,42.626,52.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.642 | Acc: 21.811,42.188,52.395,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 4.126 | Acc: 46.094,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.319 | Acc: 41.295,63.839,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.292 | Acc: 41.330,64.405,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.308 | Acc: 41.176,64.306,72.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.270 | Acc: 41.696,64.545,73.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.270 | Acc: 41.901,64.565,73.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.280 | Acc: 42.013,64.392,72.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.288 | Acc: 42.088,64.184,72.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.301 | Acc: 41.882,64.038,72.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.308 | Acc: 41.911,63.989,72.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.313 | Acc: 41.884,63.934,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.324 | Acc: 41.792,63.840,72.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.341 | Acc: 41.653,63.657,72.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.349 | Acc: 41.511,63.643,72.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.361 | Acc: 41.470,63.523,71.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.384 | Acc: 41.326,63.338,71.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.381 | Acc: 41.379,63.403,71.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.379 | Acc: 41.365,63.432,71.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.387 | Acc: 41.350,63.387,71.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.392 | Acc: 41.423,63.363,71.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.926 | Acc: 35.938,50.000,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.045 | Acc: 32.999,49.256,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.104 | Acc: 32.546,48.342,57.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.129 | Acc: 32.313,48.425,56.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 4.133 | Acc: 46.875,67.188,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.231 | Acc: 43.229,64.323,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.265 | Acc: 42.988,64.615,72.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.318 | Acc: 42.495,64.524,72.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.297 | Acc: 42.573,64.468,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.301 | Acc: 42.474,64.148,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.315 | Acc: 42.200,64.069,72.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.309 | Acc: 42.293,64.085,72.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.311 | Acc: 42.124,64.218,72.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.309 | Acc: 42.282,64.278,72.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 42.335,64.327,72.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.330 | Acc: 42.237,64.211,72.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.349 | Acc: 42.213,63.988,72.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.361 | Acc: 42.020,63.829,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.359 | Acc: 42.018,63.843,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.362 | Acc: 42.029,63.793,71.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.365 | Acc: 41.988,63.785,71.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.361 | Acc: 42.016,63.861,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.362 | Acc: 42.001,63.840,71.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.368 | Acc: 41.978,63.722,71.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.934 | Acc: 25.781,53.125,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.675 | Acc: 25.112,50.074,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.725 | Acc: 25.171,49.295,57.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.764 | Acc: 24.846,48.924,56.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 3.652 | Acc: 47.656,66.406,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.344 | Acc: 42.783,63.951,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.302 | Acc: 42.721,64.558,72.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.256 | Acc: 43.058,64.831,72.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.289 | Acc: 42.757,64.477,72.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.338 | Acc: 42.304,63.939,72.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.355 | Acc: 42.252,63.830,71.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.340 | Acc: 42.271,63.990,72.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.341 | Acc: 42.236,63.956,72.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.339 | Acc: 42.080,63.989,72.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.345 | Acc: 42.024,63.845,71.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.361 | Acc: 41.883,63.610,71.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.364 | Acc: 41.847,63.505,71.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.363 | Acc: 41.894,63.584,71.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.368 | Acc: 41.954,63.481,71.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.372 | Acc: 41.933,63.375,71.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.376 | Acc: 41.910,63.327,71.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.388 | Acc: 41.727,63.254,71.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.389 | Acc: 41.694,63.214,71.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.394 | Acc: 41.740,63.191,71.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.612 | Acc: 38.281,53.906,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.137 | Acc: 32.031,48.958,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.120 | Acc: 32.793,49.162,59.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.172 | Acc: 32.454,48.950,58.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 4.215 | Acc: 42.969,67.188,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.297 | Acc: 40.848,64.137,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 41.006,63.872,72.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.296 | Acc: 41.650,64.293,72.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.258 | Acc: 42.226,64.593,72.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.252 | Acc: 42.311,64.666,72.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.288 | Acc: 41.994,64.431,72.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.292 | Acc: 42.237,64.389,72.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.298 | Acc: 42.061,64.295,72.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.312 | Acc: 42.179,64.153,72.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 42.191,64.094,72.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.334 | Acc: 41.975,63.812,72.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.347 | Acc: 41.824,63.771,71.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.355 | Acc: 41.813,63.709,71.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.354 | Acc: 41.821,63.715,71.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.361 | Acc: 41.806,63.590,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.370 | Acc: 41.808,63.500,71.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.370 | Acc: 41.773,63.540,71.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.368 | Acc: 41.770,63.563,71.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.374 | Acc: 41.708,63.468,71.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.101 | Acc: 31.250,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.174 | Acc: 30.246,52.307,57.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.156 | Acc: 30.107,51.810,56.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.187 | Acc: 29.867,51.332,56.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 4.217 | Acc: 41.406,64.062,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 41.667,64.546,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 41.921,64.062,72.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.333 | Acc: 41.701,63.934,72.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.325 | Acc: 41.889,63.735,72.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.317 | Acc: 42.133,63.761,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.326 | Acc: 42.200,63.740,72.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.332 | Acc: 42.138,63.797,72.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.336 | Acc: 42.333,63.791,72.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.337 | Acc: 42.347,63.782,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.338 | Acc: 42.343,63.790,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.339 | Acc: 42.286,63.882,72.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.352 | Acc: 42.090,63.677,72.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.359 | Acc: 42.026,63.646,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.359 | Acc: 42.090,63.562,72.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.361 | Acc: 42.045,63.494,71.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.371 | Acc: 41.905,63.401,71.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.370 | Acc: 41.908,63.426,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.374 | Acc: 41.878,63.327,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.380 | Acc: 41.839,63.302,71.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.104 | Acc: 38.281,57.812,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.069 | Acc: 32.180,52.530,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.081 | Acc: 32.698,51.429,58.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.116 | Acc: 32.646,51.447,58.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 4.051 | Acc: 47.656,71.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.222 | Acc: 42.783,65.439,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.279 | Acc: 42.454,64.748,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.259 | Acc: 42.610,64.921,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.264 | Acc: 42.371,64.757,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.268 | Acc: 42.489,64.836,73.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.283 | Acc: 42.188,64.637,73.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.277 | Acc: 42.476,64.556,73.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.299 | Acc: 42.241,64.315,73.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.302 | Acc: 42.231,64.274,72.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 42.133,64.300,72.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.326 | Acc: 42.064,64.087,72.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.335 | Acc: 42.090,64.037,72.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.349 | Acc: 41.978,63.904,72.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.353 | Acc: 41.993,63.879,72.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.358 | Acc: 42.016,63.803,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.362 | Acc: 41.961,63.761,72.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.360 | Acc: 41.952,63.719,72.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.359 | Acc: 41.978,63.662,72.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.368 | Acc: 41.911,63.523,71.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.184 | Acc: 37.500,53.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.943 | Acc: 32.217,51.488,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.993 | Acc: 32.508,51.677,58.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.012 | Acc: 32.313,51.742,57.979,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 4.356 | Acc: 42.188,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.249 | Acc: 42.522,64.583,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.259 | Acc: 42.988,63.662,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.244 | Acc: 43.327,64.434,73.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.276 | Acc: 42.708,64.400,72.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.282 | Acc: 42.698,64.449,72.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.309 | Acc: 42.246,64.192,72.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.323 | Acc: 42.143,64.035,72.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.333 | Acc: 42.047,63.902,72.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.338 | Acc: 42.062,63.950,72.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.342 | Acc: 42.048,63.856,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.333 | Acc: 42.050,63.773,71.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.335 | Acc: 42.025,63.865,71.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.339 | Acc: 42.029,63.889,71.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.336 | Acc: 42.018,63.935,72.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.338 | Acc: 41.949,63.889,72.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.344 | Acc: 41.939,63.785,71.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.348 | Acc: 41.890,63.815,71.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.362 | Acc: 41.843,63.656,71.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.364 | Acc: 41.890,63.650,71.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.914 | Acc: 28.906,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.779 | Acc: 28.646,46.801,55.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.717 | Acc: 28.773,46.837,55.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.687 | Acc: 28.586,47.439,55.136,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 4.329 | Acc: 40.625,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.133 | Acc: 43.601,66.257,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.210 | Acc: 42.492,64.806,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.241 | Acc: 42.879,64.267,73.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.257 | Acc: 42.670,64.111,72.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.258 | Acc: 42.752,64.202,72.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.241 | Acc: 42.678,64.618,73.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.264 | Acc: 42.642,64.334,72.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.270 | Acc: 42.547,64.339,72.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.262 | Acc: 42.580,64.529,73.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.281 | Acc: 42.456,64.292,72.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.283 | Acc: 42.403,64.211,72.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.295 | Acc: 42.366,64.095,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.309 | Acc: 42.211,63.943,72.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.315 | Acc: 42.235,63.865,72.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.319 | Acc: 42.213,63.829,72.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.325 | Acc: 42.202,63.761,72.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.342 | Acc: 42.103,63.591,72.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.350 | Acc: 42.068,63.504,71.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.359 | Acc: 41.939,63.490,71.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.193 | Acc: 31.250,54.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.188 | Acc: 30.952,51.488,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.225 | Acc: 30.831,50.705,56.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.219 | Acc: 30.776,50.730,56.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 3.964 | Acc: 42.969,63.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.102 | Acc: 42.857,64.955,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.199 | Acc: 41.730,64.196,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.230 | Acc: 41.880,64.050,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.269 | Acc: 41.773,63.966,73.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.269 | Acc: 42.048,63.916,73.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.286 | Acc: 42.097,63.765,72.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.293 | Acc: 42.210,63.885,72.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.301 | Acc: 41.945,63.703,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.308 | Acc: 41.726,63.726,72.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 41.690,63.775,72.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.303 | Acc: 41.912,63.960,72.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.305 | Acc: 41.909,64.001,72.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.315 | Acc: 41.960,63.919,72.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.319 | Acc: 41.873,63.907,72.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.320 | Acc: 41.889,63.912,72.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.328 | Acc: 41.939,63.851,72.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.336 | Acc: 41.972,63.836,72.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.339 | Acc: 41.997,63.798,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.346 | Acc: 41.900,63.689,72.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.109 | Acc: 31.250,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.134 | Acc: 28.385,53.720,60.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.112 | Acc: 28.887,52.611,58.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.145 | Acc: 28.957,52.075,58.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 4.362 | Acc: 39.062,56.250,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.253 | Acc: 42.894,64.509,73.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.249 | Acc: 41.730,64.291,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.239 | Acc: 42.149,64.472,73.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.247 | Acc: 42.110,64.284,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.274 | Acc: 41.979,63.993,72.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.292 | Acc: 41.994,63.875,72.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.316 | Acc: 41.805,63.675,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.305 | Acc: 41.950,63.733,72.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.311 | Acc: 41.972,63.838,72.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.310 | Acc: 41.993,63.895,72.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.329 | Acc: 41.823,63.734,72.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.323 | Acc: 41.938,63.813,72.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.324 | Acc: 42.071,63.835,72.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.335 | Acc: 41.996,63.771,72.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.339 | Acc: 41.993,63.720,72.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.344 | Acc: 41.883,63.649,72.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.345 | Acc: 41.821,63.639,72.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.351 | Acc: 41.807,63.571,72.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.353 | Acc: 41.814,63.538,71.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.705 | Acc: 29.688,41.406,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.492 | Acc: 22.470,42.783,54.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.656 | Acc: 22.370,41.502,52.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.744 | Acc: 21.773,40.791,52.139,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 3.547 | Acc: 47.656,75.781,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.204 | Acc: 42.932,65.253,73.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.229 | Acc: 42.931,65.434,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.225 | Acc: 43.110,65.330,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.209 | Acc: 43.104,65.307,73.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.219 | Acc: 43.031,65.316,73.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.245 | Acc: 42.652,64.876,73.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.261 | Acc: 42.514,64.777,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.280 | Acc: 42.333,64.572,73.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.304 | Acc: 42.123,64.287,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.315 | Acc: 42.090,64.164,72.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.324 | Acc: 41.990,64.126,72.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.317 | Acc: 42.074,64.205,72.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.322 | Acc: 41.957,64.107,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.327 | Acc: 41.957,64.024,72.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.330 | Acc: 41.938,63.922,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.335 | Acc: 42.015,63.895,72.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.345 | Acc: 41.926,63.808,72.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.353 | Acc: 41.861,63.770,72.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.353 | Acc: 41.845,63.755,72.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.203 | Acc: 36.719,50.000,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.326 | Acc: 33.185,47.842,55.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.347 | Acc: 32.889,47.637,55.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.376 | Acc: 32.684,47.746,55.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 4.511 | Acc: 41.406,54.688,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.273 | Acc: 43.973,63.579,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.240 | Acc: 43.445,64.367,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.216 | Acc: 43.545,64.562,73.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.240 | Acc: 42.843,64.381,73.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.219 | Acc: 42.806,64.449,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.223 | Acc: 42.820,64.443,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.257 | Acc: 42.426,64.340,73.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.280 | Acc: 42.537,64.276,73.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.299 | Acc: 42.395,64.067,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.316 | Acc: 42.316,63.930,72.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.320 | Acc: 42.195,63.847,72.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.326 | Acc: 42.119,63.797,72.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.326 | Acc: 42.101,63.826,72.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.333 | Acc: 42.062,63.684,72.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.330 | Acc: 42.071,63.655,72.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.337 | Acc: 42.156,63.651,72.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.341 | Acc: 42.142,63.646,72.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.339 | Acc: 42.142,63.690,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.344 | Acc: 42.097,63.638,72.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.159 | Acc: 38.281,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.179 | Acc: 29.799,50.372,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.191 | Acc: 29.764,49.695,59.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.254 | Acc: 29.790,49.372,58.235,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 4.761 | Acc: 37.500,53.906,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.313 | Acc: 40.811,63.616,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.226 | Acc: 42.492,65.015,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.258 | Acc: 42.175,64.600,73.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.260 | Acc: 42.245,64.554,73.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.272 | Acc: 42.180,64.604,73.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.273 | Acc: 42.317,64.611,73.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.276 | Acc: 42.448,64.473,73.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.287 | Acc: 42.411,64.363,72.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.297 | Acc: 42.421,64.205,72.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 42.359,64.160,72.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.323 | Acc: 42.177,63.942,72.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.333 | Acc: 42.123,63.904,72.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.324 | Acc: 42.226,63.994,72.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.340 | Acc: 42.124,63.840,72.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.337 | Acc: 42.198,63.824,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.339 | Acc: 42.190,63.795,72.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.342 | Acc: 42.160,63.758,72.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.343 | Acc: 42.194,63.688,72.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.350 | Acc: 42.116,63.626,72.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.786 | Acc: 33.594,53.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.111 | Acc: 32.552,50.781,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.044 | Acc: 32.984,50.953,58.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.037 | Acc: 32.979,51.178,57.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 4.159 | Acc: 39.062,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.236 | Acc: 42.522,65.030,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.234 | Acc: 42.321,64.863,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.198 | Acc: 42.175,64.972,74.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.202 | Acc: 42.024,65.017,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.214 | Acc: 42.010,64.735,73.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.221 | Acc: 42.246,64.695,73.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.223 | Acc: 42.304,64.766,73.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.230 | Acc: 42.372,64.858,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.250 | Acc: 42.352,64.770,73.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.269 | Acc: 42.320,64.552,73.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.286 | Acc: 42.329,64.374,72.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.294 | Acc: 42.217,64.144,72.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.302 | Acc: 42.119,64.083,72.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.307 | Acc: 42.035,63.993,72.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.318 | Acc: 41.944,63.938,72.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.322 | Acc: 41.976,63.902,72.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.327 | Acc: 41.986,63.872,72.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.326 | Acc: 41.956,63.876,72.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.332 | Acc: 41.927,63.837,72.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.808 | Acc: 32.812,53.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.732 | Acc: 34.933,53.832,59.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.776 | Acc: 35.156,53.373,58.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.811 | Acc: 35.400,52.728,58.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 4.250 | Acc: 39.844,62.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 41.853,62.946,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 41.197,63.148,72.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.249 | Acc: 42.021,64.037,73.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.260 | Acc: 41.889,64.034,73.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.274 | Acc: 41.561,63.970,73.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.272 | Acc: 41.813,64.095,73.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.280 | Acc: 41.988,64.240,73.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.278 | Acc: 41.964,64.354,73.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.285 | Acc: 41.907,64.313,72.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.285 | Acc: 41.993,64.261,73.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.299 | Acc: 41.990,64.211,72.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.310 | Acc: 41.951,64.079,72.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.322 | Acc: 41.894,63.940,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.327 | Acc: 41.871,63.907,72.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.322 | Acc: 41.918,63.886,72.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.325 | Acc: 41.981,63.843,72.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.321 | Acc: 42.013,63.904,72.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.329 | Acc: 41.960,63.833,72.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.334 | Acc: 41.987,63.718,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.908 | Acc: 40.625,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.056 | Acc: 34.003,50.446,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.000 | Acc: 34.928,49.638,57.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.051 | Acc: 34.567,49.654,56.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 4.221 | Acc: 39.844,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.253 | Acc: 42.708,65.179,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.279 | Acc: 42.111,64.405,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.249 | Acc: 42.149,64.716,73.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.243 | Acc: 42.448,64.660,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.215 | Acc: 42.814,64.836,73.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.235 | Acc: 42.723,64.508,72.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.257 | Acc: 42.459,64.478,72.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.277 | Acc: 42.260,64.257,72.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.273 | Acc: 42.295,64.214,72.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.279 | Acc: 42.211,64.202,72.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.289 | Acc: 42.099,64.161,72.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.302 | Acc: 42.090,64.144,72.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.309 | Acc: 42.044,64.122,72.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.312 | Acc: 42.090,64.049,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.326 | Acc: 41.993,63.966,72.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.324 | Acc: 42.027,63.948,72.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.324 | Acc: 42.071,63.943,72.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.328 | Acc: 42.112,63.868,72.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.331 | Acc: 42.089,63.851,72.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.877 | Acc: 36.719,45.312,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.682 | Acc: 31.213,46.875,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.661 | Acc: 31.441,46.818,53.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.673 | Acc: 31.352,47.285,54.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 4.957 | Acc: 35.156,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 41.815,65.476,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.220 | Acc: 42.626,65.415,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.253 | Acc: 42.687,64.921,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.236 | Acc: 42.641,64.824,73.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.248 | Acc: 42.644,64.581,73.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.241 | Acc: 42.497,64.792,73.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.257 | Acc: 42.143,64.705,73.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.272 | Acc: 42.226,64.722,72.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.269 | Acc: 42.295,64.753,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.272 | Acc: 42.362,64.708,73.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.276 | Acc: 42.347,64.663,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.286 | Acc: 42.246,64.533,72.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.300 | Acc: 42.131,64.428,72.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.308 | Acc: 42.012,64.288,72.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.307 | Acc: 42.003,64.257,72.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.312 | Acc: 42.020,64.279,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.314 | Acc: 41.972,64.234,72.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.319 | Acc: 41.997,64.225,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.322 | Acc: 41.919,64.190,72.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.030 | Acc: 21.094,50.781,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.269 | Acc: 23.958,45.796,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.293 | Acc: 23.971,45.293,54.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.287 | Acc: 23.822,44.723,54.201,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 3.680 | Acc: 46.094,68.750,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.260 | Acc: 41.927,65.104,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.228 | Acc: 42.664,64.748,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.230 | Acc: 42.533,64.895,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.247 | Acc: 42.641,64.728,73.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.250 | Acc: 42.605,64.790,73.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.231 | Acc: 42.788,65.063,73.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.244 | Acc: 42.525,64.766,73.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.273 | Acc: 42.406,64.630,73.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.287 | Acc: 42.352,64.468,73.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.286 | Acc: 42.359,64.509,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.294 | Acc: 42.212,64.423,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.301 | Acc: 42.233,64.370,72.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.312 | Acc: 42.217,64.167,72.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.312 | Acc: 42.335,64.163,72.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.320 | Acc: 42.260,64.099,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.321 | Acc: 42.319,64.109,72.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.321 | Acc: 42.357,64.067,72.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.325 | Acc: 42.363,64.050,72.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.324 | Acc: 42.319,64.054,72.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.663 | Acc: 29.688,41.406,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.567 | Acc: 28.497,38.356,49.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.528 | Acc: 28.716,38.319,49.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.505 | Acc: 28.560,38.345,49.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 4.296 | Acc: 45.312,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.158 | Acc: 43.266,65.588,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.177 | Acc: 42.721,65.777,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.240 | Acc: 42.047,65.036,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.260 | Acc: 41.686,64.525,73.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.261 | Acc: 42.110,64.619,73.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.263 | Acc: 42.323,64.482,73.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.276 | Acc: 42.182,64.400,72.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.288 | Acc: 42.304,64.465,72.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.289 | Acc: 42.200,64.378,72.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.292 | Acc: 42.086,64.366,72.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.289 | Acc: 42.297,64.398,72.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.294 | Acc: 42.259,64.416,72.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.296 | Acc: 42.214,64.416,72.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.306 | Acc: 42.174,64.271,72.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.311 | Acc: 42.141,64.195,72.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.315 | Acc: 42.141,64.157,72.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.319 | Acc: 42.123,64.127,72.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.316 | Acc: 42.185,64.093,72.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.314 | Acc: 42.194,64.099,72.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.619 | Acc: 29.688,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.955 | Acc: 27.604,46.540,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.981 | Acc: 27.401,45.274,53.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.981 | Acc: 26.729,45.236,53.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 3.734 | Acc: 49.219,71.875,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 42.522,65.216,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.215 | Acc: 43.369,65.282,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.255 | Acc: 42.725,64.562,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.234 | Acc: 42.757,64.873,73.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.230 | Acc: 42.853,64.728,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.231 | Acc: 42.891,64.566,73.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.249 | Acc: 42.742,64.456,73.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.256 | Acc: 42.571,64.363,73.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.262 | Acc: 42.451,64.261,73.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.255 | Acc: 42.514,64.303,73.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.270 | Acc: 42.456,64.130,72.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.282 | Acc: 42.350,64.046,72.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.299 | Acc: 42.292,63.883,72.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.302 | Acc: 42.154,63.923,72.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.308 | Acc: 42.175,63.826,72.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.314 | Acc: 42.170,63.809,72.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.323 | Acc: 42.121,63.749,72.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.327 | Acc: 42.079,63.803,72.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.329 | Acc: 42.120,63.812,72.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.465 | Acc: 37.500,57.031,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.807 | Acc: 32.999,51.786,60.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.753 | Acc: 33.956,52.401,59.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.798 | Acc: 33.876,52.075,59.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 3.671 | Acc: 53.906,65.625,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.097 | Acc: 44.717,65.067,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.153 | Acc: 43.236,64.882,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.192 | Acc: 42.636,65.023,74.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.208 | Acc: 42.737,64.554,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.199 | Acc: 42.884,64.697,73.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.222 | Acc: 42.633,64.566,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.241 | Acc: 42.498,64.423,73.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.246 | Acc: 42.513,64.359,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.251 | Acc: 42.278,64.252,73.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.259 | Acc: 42.226,64.136,73.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.265 | Acc: 42.318,64.179,73.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.271 | Acc: 42.385,64.053,73.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.276 | Acc: 42.286,64.083,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.280 | Acc: 42.299,64.113,72.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.287 | Acc: 42.284,64.088,72.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.289 | Acc: 42.336,64.116,72.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.290 | Acc: 42.323,64.090,72.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.298 | Acc: 42.261,64.021,72.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.300 | Acc: 42.280,64.015,72.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.856 | Acc: 20.312,43.750,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.010 | Acc: 19.531,42.448,51.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.981 | Acc: 19.588,42.359,51.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.948 | Acc: 19.032,42.392,51.486,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 5.198 | Acc: 35.156,55.469,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.113 | Acc: 41.890,65.774,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.159 | Acc: 42.149,65.473,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.147 | Acc: 42.533,65.753,74.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.165 | Acc: 42.631,65.577,74.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.170 | Acc: 42.551,65.501,74.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.173 | Acc: 42.788,65.225,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.194 | Acc: 42.642,65.254,74.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.203 | Acc: 42.537,65.174,73.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.218 | Acc: 42.554,64.939,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.225 | Acc: 42.580,64.817,73.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.244 | Acc: 42.492,64.540,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.253 | Acc: 42.470,64.494,73.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.261 | Acc: 42.442,64.440,72.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.270 | Acc: 42.432,64.452,72.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.278 | Acc: 42.346,64.361,72.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.283 | Acc: 42.295,64.291,72.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.294 | Acc: 42.240,64.214,72.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.295 | Acc: 42.237,64.190,72.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.299 | Acc: 42.247,64.132,72.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.093 | Acc: 32.812,50.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.727 | Acc: 29.018,48.475,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.701 | Acc: 28.754,47.847,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.726 | Acc: 28.522,47.374,56.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 4.861 | Acc: 39.062,55.469,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.295 | Acc: 43.192,63.504,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.245 | Acc: 42.683,63.967,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.238 | Acc: 42.764,63.934,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.252 | Acc: 42.554,63.908,73.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.251 | Acc: 42.605,64.101,73.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.267 | Acc: 42.426,63.966,73.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.283 | Acc: 42.182,63.913,72.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.289 | Acc: 42.333,63.946,72.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.278 | Acc: 42.537,64.024,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.278 | Acc: 42.580,64.078,72.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.299 | Acc: 42.470,63.804,72.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.297 | Acc: 42.346,63.904,72.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.300 | Acc: 42.388,63.880,72.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.303 | Acc: 42.438,63.965,72.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.309 | Acc: 42.343,63.928,72.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.301 | Acc: 42.448,64.092,72.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.302 | Acc: 42.368,64.014,72.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.304 | Acc: 42.337,64.034,72.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.306 | Acc: 42.333,64.060,72.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.523 | Acc: 27.344,50.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.179 | Acc: 25.112,45.201,55.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.204 | Acc: 25.019,45.675,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.267 | Acc: 24.513,45.453,54.892,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 4.132 | Acc: 40.625,67.188,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.191 | Acc: 42.001,65.662,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.211 | Acc: 41.845,65.568,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.216 | Acc: 41.714,65.663,73.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.218 | Acc: 41.908,65.413,74.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.237 | Acc: 41.747,64.797,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.262 | Acc: 41.729,64.631,73.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.273 | Acc: 41.772,64.417,73.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.261 | Acc: 41.925,64.640,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.259 | Acc: 42.123,64.559,73.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.265 | Acc: 42.195,64.548,73.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.267 | Acc: 42.248,64.529,73.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.274 | Acc: 42.317,64.497,73.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.277 | Acc: 42.283,64.485,73.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.283 | Acc: 42.318,64.388,72.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.297 | Acc: 42.156,64.265,72.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.300 | Acc: 42.151,64.206,72.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.316 | Acc: 42.146,64.104,72.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.314 | Acc: 42.125,64.104,72.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.316 | Acc: 42.112,64.118,72.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.243 | Acc: 28.125,53.906,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.297 | Acc: 30.022,51.562,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.290 | Acc: 29.630,51.753,58.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.342 | Acc: 29.239,51.627,58.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 3.554 | Acc: 41.406,75.781,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.139 | Acc: 42.820,65.774,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.205 | Acc: 41.978,65.168,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.272 | Acc: 41.137,64.408,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.261 | Acc: 41.628,64.361,73.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.287 | Acc: 41.692,64.310,73.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.290 | Acc: 41.884,64.411,73.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.274 | Acc: 42.032,64.556,73.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.267 | Acc: 42.081,64.625,73.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.271 | Acc: 42.114,64.529,73.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.282 | Acc: 42.121,64.436,73.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.285 | Acc: 42.145,64.462,73.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.287 | Acc: 42.145,64.484,72.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.285 | Acc: 42.349,64.455,72.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.287 | Acc: 42.318,64.396,72.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.290 | Acc: 42.237,64.312,72.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.285 | Acc: 42.295,64.340,72.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.294 | Acc: 42.259,64.200,72.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.293 | Acc: 42.235,64.175,72.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.298 | Acc: 42.173,64.110,72.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.910 | Acc: 36.719,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.233 | Acc: 32.329,51.376,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.166 | Acc: 32.660,51.277,58.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.221 | Acc: 32.082,50.538,57.787,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 4.505 | Acc: 41.406,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.156 | Acc: 43.043,65.476,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.129 | Acc: 42.854,66.311,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.139 | Acc: 42.777,65.894,74.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.145 | Acc: 43.017,65.779,74.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.160 | Acc: 43.031,65.780,73.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.189 | Acc: 42.665,65.470,73.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.193 | Acc: 42.658,65.448,73.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.207 | Acc: 42.382,65.280,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.222 | Acc: 42.412,65.284,73.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.227 | Acc: 42.394,65.190,73.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.243 | Acc: 42.325,65.070,73.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.249 | Acc: 42.401,65.006,72.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.260 | Acc: 42.313,64.913,72.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.273 | Acc: 42.321,64.744,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.276 | Acc: 42.258,64.701,72.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.276 | Acc: 42.248,64.720,72.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.275 | Acc: 42.270,64.757,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.273 | Acc: 42.341,64.768,72.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.274 | Acc: 42.337,64.727,72.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.558 | Acc: 29.688,52.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.965 | Acc: 26.228,48.177,54.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.008 | Acc: 26.239,47.104,54.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.062 | Acc: 25.564,47.029,53.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 4.049 | Acc: 39.844,72.656,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.099 | Acc: 43.601,66.927,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.093 | Acc: 43.559,66.330,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.132 | Acc: 43.084,65.920,74.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.184 | Acc: 43.084,65.249,74.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.193 | Acc: 42.744,65.153,74.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.195 | Acc: 42.807,65.373,74.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.199 | Acc: 42.636,65.326,74.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.196 | Acc: 42.697,65.363,74.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.209 | Acc: 42.619,65.206,73.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.224 | Acc: 42.475,65.120,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.242 | Acc: 42.435,64.939,73.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.249 | Acc: 42.453,64.899,73.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.264 | Acc: 42.406,64.772,72.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.271 | Acc: 42.427,64.632,72.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.271 | Acc: 42.525,64.618,72.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.278 | Acc: 42.484,64.535,72.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.280 | Acc: 42.490,64.560,72.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.284 | Acc: 42.486,64.504,72.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.292 | Acc: 42.393,64.417,72.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.720 | Acc: 27.344,46.875,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.067 | Acc: 26.525,42.894,51.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.086 | Acc: 27.382,43.007,50.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.087 | Acc: 27.254,42.751,50.768,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.091 | Acc: 42.969,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.167 | Acc: 42.485,66.071,73.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.238 | Acc: 42.168,64.977,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.283 | Acc: 42.482,64.434,73.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.270 | Acc: 42.689,64.439,73.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.257 | Acc: 42.481,64.527,73.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.267 | Acc: 42.297,64.392,73.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.261 | Acc: 42.420,64.511,73.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.245 | Acc: 42.503,64.679,73.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.246 | Acc: 42.615,64.568,73.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.246 | Acc: 42.526,64.568,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.244 | Acc: 42.580,64.589,73.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.250 | Acc: 42.525,64.494,73.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.252 | Acc: 42.493,64.497,72.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.262 | Acc: 42.449,64.457,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.268 | Acc: 42.385,64.384,72.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.271 | Acc: 42.348,64.398,72.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.284 | Acc: 42.323,64.317,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.294 | Acc: 42.237,64.264,72.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.297 | Acc: 42.220,64.218,72.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.972 | Acc: 36.719,56.250,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.397 | Acc: 29.985,50.781,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.369 | Acc: 29.935,50.857,58.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.390 | Acc: 29.572,50.282,58.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 3.731 | Acc: 49.219,69.531,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.142 | Acc: 42.894,66.667,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.216 | Acc: 42.416,65.568,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.218 | Acc: 42.661,65.651,73.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.220 | Acc: 42.747,65.712,73.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.230 | Acc: 42.752,65.401,73.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.240 | Acc: 42.646,65.179,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.235 | Acc: 42.575,65.165,73.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.240 | Acc: 42.571,65.101,73.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.242 | Acc: 42.645,65.060,73.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.248 | Acc: 42.701,65.026,73.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.255 | Acc: 42.488,64.964,72.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.264 | Acc: 42.440,64.815,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.271 | Acc: 42.424,64.757,72.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.277 | Acc: 42.368,64.705,72.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.278 | Acc: 42.442,64.628,72.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.269 | Acc: 42.577,64.729,72.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.275 | Acc: 42.508,64.628,72.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.278 | Acc: 42.514,64.536,72.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.284 | Acc: 42.522,64.405,72.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.040 | Acc: 20.312,38.281,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.332 | Acc: 15.811,37.054,47.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.245 | Acc: 16.120,37.138,47.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.267 | Acc: 16.137,36.975,47.182,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 4.151 | Acc: 45.312,64.844,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.094 | Acc: 43.304,65.811,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.082 | Acc: 43.083,66.406,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.087 | Acc: 43.097,66.137,75.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.105 | Acc: 43.046,66.098,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.124 | Acc: 42.992,66.205,74.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.151 | Acc: 42.730,65.883,74.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.176 | Acc: 42.764,65.498,74.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.184 | Acc: 42.775,65.572,74.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.188 | Acc: 42.861,65.487,73.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.191 | Acc: 42.887,65.384,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.194 | Acc: 42.884,65.349,73.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.198 | Acc: 42.894,65.307,73.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.200 | Acc: 42.864,65.305,73.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.203 | Acc: 42.891,65.305,73.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.213 | Acc: 42.842,65.163,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.226 | Acc: 42.747,65.012,73.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.230 | Acc: 42.678,65.022,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.238 | Acc: 42.566,64.963,73.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.242 | Acc: 42.600,64.973,73.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.027 | Acc: 32.031,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.413 | Acc: 27.902,51.265,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.416 | Acc: 27.782,50.648,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.461 | Acc: 27.651,50.115,57.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 3.809 | Acc: 39.844,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.270 | Acc: 41.964,65.216,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.243 | Acc: 42.226,65.015,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.233 | Acc: 42.738,64.767,72.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.231 | Acc: 43.191,64.902,72.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.244 | Acc: 43.069,64.867,72.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.254 | Acc: 42.814,64.889,72.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.262 | Acc: 42.780,64.977,72.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.251 | Acc: 42.716,65.043,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.259 | Acc: 42.869,64.960,72.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.258 | Acc: 42.891,64.984,72.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.244 | Acc: 42.923,65.084,72.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.245 | Acc: 42.962,64.990,72.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.251 | Acc: 42.933,64.960,72.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.253 | Acc: 42.944,64.916,72.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.261 | Acc: 42.878,64.730,72.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.268 | Acc: 42.803,64.654,72.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.278 | Acc: 42.749,64.500,72.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.276 | Acc: 42.731,64.487,72.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.283 | Acc: 42.714,64.450,72.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.196 | Acc: 29.688,57.031,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.337 | Acc: 28.348,51.042,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.381 | Acc: 28.373,49.981,57.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.407 | Acc: 27.894,49.885,57.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 3.737 | Acc: 43.750,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.070 | Acc: 43.713,65.662,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 44.017,65.854,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.127 | Acc: 43.635,65.715,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.145 | Acc: 43.605,65.644,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.146 | Acc: 43.680,65.602,74.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.164 | Acc: 43.395,65.567,74.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.187 | Acc: 43.035,65.403,74.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.200 | Acc: 42.954,65.203,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.198 | Acc: 42.960,65.202,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.206 | Acc: 42.930,65.194,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.211 | Acc: 42.983,65.130,73.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.225 | Acc: 42.884,64.973,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.234 | Acc: 42.786,64.934,73.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.237 | Acc: 42.960,64.955,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.236 | Acc: 42.940,64.953,73.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.246 | Acc: 42.796,64.829,73.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.247 | Acc: 42.824,64.809,73.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.255 | Acc: 42.763,64.731,72.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.258 | Acc: 42.737,64.674,72.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.142 | Acc: 33.594,54.688,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.279 | Acc: 32.031,49.293,55.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.226 | Acc: 32.851,50.152,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.223 | Acc: 32.351,50.346,55.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 4.189 | Acc: 42.188,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.167 | Acc: 42.188,64.993,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.183 | Acc: 42.397,65.111,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.158 | Acc: 42.853,65.369,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.180 | Acc: 43.046,65.316,73.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.175 | Acc: 43.185,65.424,73.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.192 | Acc: 43.001,65.470,73.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.204 | Acc: 43.096,65.281,73.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.200 | Acc: 43.294,65.261,73.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.229 | Acc: 43.025,65.120,73.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.223 | Acc: 43.120,65.139,73.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.234 | Acc: 43.001,65.074,73.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.232 | Acc: 42.972,65.074,73.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.242 | Acc: 42.768,64.957,73.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.240 | Acc: 42.794,64.885,73.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.242 | Acc: 42.759,64.828,73.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.249 | Acc: 42.725,64.834,73.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.257 | Acc: 42.740,64.720,72.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.264 | Acc: 42.731,64.658,72.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.265 | Acc: 42.753,64.553,72.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.284 | Acc: 29.688,52.344,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.111 | Acc: 26.042,47.135,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.086 | Acc: 26.486,46.894,55.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.076 | Acc: 26.588,47.259,56.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 4.287 | Acc: 42.188,64.844,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.987 | Acc: 43.415,67.634,76.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.918 | Acc: 44.436,68.921,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.895 | Acc: 44.762,69.326,77.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.840 | Acc: 45.245,69.579,78.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.826 | Acc: 45.189,69.531,78.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.789 | Acc: 45.158,69.783,78.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.770 | Acc: 45.396,70.074,78.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.759 | Acc: 45.434,70.133,79.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.742 | Acc: 45.498,70.334,79.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.712 | Acc: 45.631,70.585,79.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.695 | Acc: 45.825,70.769,79.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.675 | Acc: 46.068,70.851,79.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.669 | Acc: 46.076,70.914,80.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.655 | Acc: 46.227,71.021,80.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.648 | Acc: 46.239,71.081,80.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.637 | Acc: 46.325,71.198,80.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.633 | Acc: 46.341,71.144,80.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.625 | Acc: 46.353,71.252,80.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.617 | Acc: 46.395,71.325,80.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.210 | Acc: 52.344,70.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.380 | Acc: 43.229,64.881,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.401 | Acc: 43.731,64.139,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.426 | Acc: 43.494,63.870,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.473 | Acc: 46.094,78.906,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.356 | Acc: 48.289,74.144,83.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.414 | Acc: 47.447,73.285,83.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.432 | Acc: 47.464,73.194,83.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.444 | Acc: 47.126,73.129,82.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.466 | Acc: 47.037,72.726,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.471 | Acc: 47.075,72.805,82.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.473 | Acc: 47.113,72.839,82.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.472 | Acc: 47.074,72.802,82.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.463 | Acc: 47.121,72.855,82.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.469 | Acc: 47.124,72.734,82.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.465 | Acc: 47.190,72.755,82.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.463 | Acc: 47.335,72.776,82.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.449 | Acc: 47.498,72.929,82.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.443 | Acc: 47.598,72.995,83.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.438 | Acc: 47.633,73.030,83.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.440 | Acc: 47.569,73.007,82.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.437 | Acc: 47.622,73.101,83.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.436 | Acc: 47.650,73.091,83.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.431 | Acc: 47.646,73.187,83.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.329 | Acc: 50.781,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.343 | Acc: 43.862,64.732,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.358 | Acc: 44.379,64.348,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 43.968,64.280,70.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.508 | Acc: 46.875,71.094,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.288 | Acc: 48.065,75.372,84.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.305 | Acc: 48.533,74.486,84.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.286 | Acc: 48.783,74.539,84.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.295 | Acc: 48.785,74.421,84.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.317 | Acc: 48.267,74.134,84.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.320 | Acc: 48.360,73.973,84.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.324 | Acc: 48.221,74.136,84.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.329 | Acc: 48.302,74.180,84.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.338 | Acc: 48.200,74.107,84.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.342 | Acc: 48.224,74.009,84.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.343 | Acc: 48.208,74.106,84.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.352 | Acc: 48.117,74.044,84.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.353 | Acc: 48.135,73.940,84.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.354 | Acc: 48.285,73.946,84.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.353 | Acc: 48.188,73.957,84.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.353 | Acc: 48.177,73.985,84.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.360 | Acc: 47.975,73.887,84.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.355 | Acc: 47.987,73.950,84.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.355 | Acc: 47.921,73.897,84.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.240 | Acc: 52.344,71.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.324 | Acc: 43.973,65.588,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 44.284,64.710,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.370 | Acc: 44.185,64.703,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 3.106 | Acc: 56.250,84.375,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.322 | Acc: 47.991,75.670,85.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.357 | Acc: 47.618,74.123,84.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.345 | Acc: 47.631,74.372,84.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.325 | Acc: 47.463,74.450,84.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.286 | Acc: 47.741,75.139,85.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.295 | Acc: 47.650,74.981,85.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.284 | Acc: 47.839,75.116,85.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.302 | Acc: 47.768,75.010,85.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.291 | Acc: 47.794,75.138,85.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.294 | Acc: 47.823,75.019,85.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.298 | Acc: 47.819,74.954,85.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.298 | Acc: 47.893,74.912,85.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.303 | Acc: 47.830,74.749,84.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.301 | Acc: 47.931,74.789,84.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.303 | Acc: 47.975,74.725,84.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.298 | Acc: 48.060,74.774,84.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.298 | Acc: 48.030,74.750,84.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.305 | Acc: 47.931,74.671,84.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.307 | Acc: 47.929,74.670,84.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.421 | Acc: 52.344,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.352 | Acc: 44.457,64.918,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.384 | Acc: 44.817,64.558,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.405 | Acc: 44.557,64.511,69.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.781 | Acc: 53.125,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.256 | Acc: 48.326,75.558,86.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.276 | Acc: 47.504,75.038,85.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.265 | Acc: 47.605,75.205,85.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.255 | Acc: 47.656,75.309,85.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.274 | Acc: 47.610,75.116,85.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.273 | Acc: 47.682,75.032,85.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.279 | Acc: 47.800,74.806,85.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.277 | Acc: 47.753,74.786,85.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.284 | Acc: 47.794,74.758,85.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.272 | Acc: 47.823,74.876,85.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.274 | Acc: 47.890,74.830,85.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.277 | Acc: 48.010,74.786,85.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.292 | Acc: 47.872,74.566,85.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.295 | Acc: 47.831,74.455,85.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.288 | Acc: 47.841,74.548,85.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.283 | Acc: 47.960,74.584,85.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.286 | Acc: 47.924,74.576,85.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.285 | Acc: 47.907,74.572,85.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.282 | Acc: 48.013,74.631,85.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.275 | Acc: 51.562,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.306 | Acc: 43.936,65.960,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.334 | Acc: 44.627,65.034,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.365 | Acc: 44.237,64.895,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.178 | Acc: 40.625,79.688,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.115 | Acc: 49.256,76.674,86.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.192 | Acc: 49.162,75.514,86.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.223 | Acc: 48.924,74.962,85.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.237 | Acc: 48.698,74.711,85.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.229 | Acc: 48.584,74.845,85.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.220 | Acc: 48.612,74.903,85.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.219 | Acc: 48.631,75.083,85.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.227 | Acc: 48.544,74.927,85.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.238 | Acc: 48.515,74.819,85.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.234 | Acc: 48.550,74.903,85.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.238 | Acc: 48.438,74.901,85.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.240 | Acc: 48.360,74.990,85.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.251 | Acc: 48.249,74.919,85.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.246 | Acc: 48.329,75.014,85.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.245 | Acc: 48.282,75.143,85.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.242 | Acc: 48.362,75.148,85.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.240 | Acc: 48.399,75.121,85.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.246 | Acc: 48.219,75.030,85.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.249 | Acc: 48.202,74.969,85.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.257 | Acc: 50.781,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.333 | Acc: 43.750,65.476,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.357 | Acc: 44.131,65.034,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.384 | Acc: 43.981,64.946,69.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 3.009 | Acc: 50.000,79.688,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.189 | Acc: 47.879,76.488,86.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.212 | Acc: 48.209,76.181,86.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.227 | Acc: 48.309,75.512,85.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.218 | Acc: 48.360,75.395,85.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.219 | Acc: 48.035,75.410,85.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.222 | Acc: 48.082,75.349,85.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.217 | Acc: 48.244,75.327,86.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.228 | Acc: 48.171,75.228,85.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.222 | Acc: 48.187,75.246,86.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.223 | Acc: 48.336,75.315,85.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.223 | Acc: 48.360,75.385,86.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.227 | Acc: 48.237,75.318,86.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.225 | Acc: 48.285,75.422,86.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.224 | Acc: 48.260,75.384,86.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.222 | Acc: 48.282,75.371,86.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.224 | Acc: 48.282,75.316,86.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.231 | Acc: 48.273,75.149,86.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.234 | Acc: 48.221,75.123,86.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.231 | Acc: 48.273,75.172,86.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.309 | Acc: 53.906,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.329 | Acc: 44.717,64.918,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.354 | Acc: 44.779,64.386,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.384 | Acc: 44.454,64.485,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 2.803 | Acc: 53.906,76.562,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.144 | Acc: 48.921,75.186,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.199 | Acc: 48.438,75.076,87.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.171 | Acc: 49.129,75.704,87.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.193 | Acc: 48.920,75.203,86.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.188 | Acc: 49.180,75.170,86.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.201 | Acc: 48.993,75.065,86.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.196 | Acc: 48.798,75.233,86.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.193 | Acc: 48.593,75.374,86.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.207 | Acc: 48.416,75.211,86.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.207 | Acc: 48.356,75.210,86.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.199 | Acc: 48.406,75.318,86.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.199 | Acc: 48.489,75.324,86.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.201 | Acc: 48.512,75.335,86.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.205 | Acc: 48.546,75.325,86.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.203 | Acc: 48.570,75.296,86.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.205 | Acc: 48.515,75.280,86.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.204 | Acc: 48.467,75.254,86.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.204 | Acc: 48.461,75.229,86.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.203 | Acc: 48.396,75.209,86.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.412 | Acc: 50.000,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.343 | Acc: 43.936,65.699,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.372 | Acc: 44.398,64.920,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.402 | Acc: 44.403,64.754,70.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 2.909 | Acc: 57.031,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.175 | Acc: 49.479,75.707,85.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.156 | Acc: 49.104,75.553,86.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.183 | Acc: 49.039,75.256,86.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.187 | Acc: 48.862,75.058,86.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.187 | Acc: 48.608,75.178,86.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.193 | Acc: 48.502,75.077,86.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.181 | Acc: 48.620,75.305,86.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.179 | Acc: 48.729,75.446,86.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.174 | Acc: 48.774,75.406,86.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.174 | Acc: 48.601,75.288,86.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.178 | Acc: 48.544,75.382,86.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.187 | Acc: 48.457,75.266,86.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.185 | Acc: 48.521,75.401,86.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.187 | Acc: 48.457,75.328,86.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.190 | Acc: 48.448,75.265,86.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.192 | Acc: 48.416,75.324,86.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.188 | Acc: 48.499,75.403,86.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.187 | Acc: 48.472,75.381,86.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.188 | Acc: 48.433,75.357,86.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.322 | Acc: 53.125,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.278 | Acc: 44.978,65.216,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.318 | Acc: 45.255,65.015,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.343 | Acc: 45.018,65.215,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 3.052 | Acc: 49.219,80.469,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.144 | Acc: 48.661,76.897,86.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.118 | Acc: 48.685,76.620,87.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.152 | Acc: 48.181,76.076,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.154 | Acc: 48.544,76.100,87.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.156 | Acc: 48.832,76.037,87.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.151 | Acc: 48.844,75.949,87.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.151 | Acc: 48.770,75.781,87.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.147 | Acc: 48.908,75.733,87.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.152 | Acc: 48.813,75.708,87.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.164 | Acc: 48.671,75.657,87.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.175 | Acc: 48.441,75.509,87.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.175 | Acc: 48.551,75.525,87.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.174 | Acc: 48.596,75.497,87.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.173 | Acc: 48.610,75.528,87.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.172 | Acc: 48.604,75.527,87.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.167 | Acc: 48.588,75.548,87.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.168 | Acc: 48.589,75.522,87.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.167 | Acc: 48.606,75.517,87.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.168 | Acc: 48.522,75.531,87.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.401 | Acc: 50.781,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.347 | Acc: 44.531,65.067,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.372 | Acc: 44.779,64.844,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.401 | Acc: 44.416,64.818,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 3.092 | Acc: 50.781,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.027 | Acc: 50.037,76.860,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.059 | Acc: 49.829,76.791,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.069 | Acc: 49.782,76.601,88.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.088 | Acc: 49.537,76.476,87.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.093 | Acc: 49.474,76.400,87.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.114 | Acc: 49.329,76.104,87.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.109 | Acc: 49.285,76.263,87.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.119 | Acc: 49.010,76.174,87.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.128 | Acc: 48.899,76.049,87.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.138 | Acc: 48.846,75.983,87.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.149 | Acc: 48.713,75.845,87.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.146 | Acc: 48.778,75.950,87.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.146 | Acc: 48.791,75.808,87.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.156 | Acc: 48.702,75.648,87.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.157 | Acc: 48.700,75.646,87.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.157 | Acc: 48.644,75.579,87.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.162 | Acc: 48.580,75.525,87.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.162 | Acc: 48.574,75.428,87.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.159 | Acc: 48.509,75.506,87.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.355 | Acc: 51.562,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.328 | Acc: 44.903,65.699,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.365 | Acc: 44.779,64.996,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.396 | Acc: 44.454,64.933,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 3.153 | Acc: 46.875,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.147 | Acc: 48.884,76.376,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.158 | Acc: 48.380,75.686,88.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.130 | Acc: 48.604,75.871,88.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.110 | Acc: 48.553,76.148,88.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.120 | Acc: 48.283,75.774,88.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.120 | Acc: 48.438,75.949,88.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.126 | Acc: 48.360,75.986,88.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.127 | Acc: 48.336,76.068,88.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.120 | Acc: 48.571,76.196,88.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.113 | Acc: 48.694,76.189,88.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.118 | Acc: 48.554,76.142,88.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.129 | Acc: 48.506,75.947,87.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.133 | Acc: 48.521,75.922,87.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.131 | Acc: 48.474,75.956,87.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.131 | Acc: 48.479,75.994,87.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.134 | Acc: 48.542,75.983,87.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.132 | Acc: 48.580,75.992,87.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.137 | Acc: 48.498,75.874,87.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.136 | Acc: 48.561,75.880,87.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.264 | Acc: 50.781,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.347 | Acc: 44.754,65.327,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.392 | Acc: 44.970,64.939,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.412 | Acc: 44.685,64.869,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 2.747 | Acc: 49.219,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.139 | Acc: 47.842,75.707,86.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.141 | Acc: 48.209,75.191,86.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.106 | Acc: 48.514,75.576,87.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.106 | Acc: 48.601,75.704,87.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.114 | Acc: 48.670,75.727,87.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.118 | Acc: 48.521,75.736,87.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.116 | Acc: 48.543,75.848,87.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.106 | Acc: 48.743,75.946,87.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.111 | Acc: 48.731,75.829,87.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.116 | Acc: 48.585,75.750,87.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.119 | Acc: 48.611,75.735,87.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.129 | Acc: 48.554,75.687,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.128 | Acc: 48.590,75.703,87.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.132 | Acc: 48.521,75.634,87.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.136 | Acc: 48.562,75.600,87.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.139 | Acc: 48.605,75.589,87.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.141 | Acc: 48.547,75.607,87.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.137 | Acc: 48.613,75.706,87.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.136 | Acc: 48.620,75.660,87.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.404 | Acc: 50.000,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.332 | Acc: 44.494,64.435,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.348 | Acc: 44.950,64.520,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.374 | Acc: 44.416,64.626,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 3.102 | Acc: 48.438,70.312,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.072 | Acc: 49.330,75.670,88.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.044 | Acc: 49.295,76.239,88.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.033 | Acc: 49.372,76.396,88.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.043 | Acc: 49.267,76.302,88.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.050 | Acc: 49.226,76.253,88.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.075 | Acc: 48.954,76.111,88.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.074 | Acc: 48.825,76.058,88.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.081 | Acc: 48.719,76.000,88.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.081 | Acc: 48.757,76.023,88.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.085 | Acc: 48.764,75.979,88.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.089 | Acc: 48.802,75.979,88.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.095 | Acc: 48.788,75.930,88.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.098 | Acc: 48.644,75.937,88.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.098 | Acc: 48.649,75.901,88.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.099 | Acc: 48.658,75.828,88.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.098 | Acc: 48.569,75.852,88.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.100 | Acc: 48.589,75.820,88.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.103 | Acc: 48.580,75.807,88.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.107 | Acc: 48.569,75.820,88.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.284 | Acc: 52.344,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.317 | Acc: 45.052,65.402,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 45.274,64.863,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.370 | Acc: 44.928,64.780,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 2.914 | Acc: 50.781,81.250,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.025 | Acc: 50.186,77.046,88.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.048 | Acc: 49.714,76.848,88.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.035 | Acc: 49.667,76.985,88.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.065 | Acc: 49.354,76.698,88.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.088 | Acc: 49.149,76.354,88.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.080 | Acc: 49.245,76.440,88.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.086 | Acc: 48.947,76.474,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.097 | Acc: 48.806,76.388,88.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.094 | Acc: 48.770,76.278,88.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.091 | Acc: 48.729,76.267,88.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.095 | Acc: 48.734,76.266,88.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.099 | Acc: 48.703,76.170,88.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.107 | Acc: 48.674,76.084,88.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.111 | Acc: 48.604,76.026,87.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.112 | Acc: 48.534,76.036,87.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.107 | Acc: 48.591,76.088,87.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.103 | Acc: 48.600,76.143,87.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.103 | Acc: 48.637,76.160,87.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.103 | Acc: 48.542,76.179,87.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.456 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.348 | Acc: 45.499,65.625,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.387 | Acc: 45.408,64.920,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.407 | Acc: 45.236,64.857,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 2.723 | Acc: 50.000,79.688,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.935 | Acc: 50.744,78.423,89.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 49.295,76.791,88.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.048 | Acc: 48.835,76.370,88.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.042 | Acc: 48.804,76.717,88.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.048 | Acc: 48.561,76.787,88.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.045 | Acc: 48.670,76.769,88.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.044 | Acc: 48.748,76.651,88.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.049 | Acc: 48.777,76.480,88.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.044 | Acc: 48.787,76.593,88.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.060 | Acc: 48.760,76.384,88.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.057 | Acc: 48.738,76.354,88.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.060 | Acc: 48.784,76.355,88.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.065 | Acc: 48.791,76.248,88.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.066 | Acc: 48.802,76.223,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.069 | Acc: 48.739,76.222,88.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.069 | Acc: 48.727,76.232,88.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.075 | Acc: 48.710,76.189,88.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.075 | Acc: 48.723,76.240,88.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.076 | Acc: 48.737,76.214,88.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.302 | Acc: 52.344,71.875,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.378 | Acc: 44.680,65.513,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.382 | Acc: 44.931,65.072,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.415 | Acc: 44.582,64.882,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 3.107 | Acc: 43.750,72.656,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.936 | Acc: 48.661,77.753,89.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.986 | Acc: 48.838,76.829,88.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.997 | Acc: 49.180,76.819,88.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.992 | Acc: 49.228,77.064,89.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.005 | Acc: 49.466,76.856,88.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.010 | Acc: 49.335,77.098,88.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.030 | Acc: 49.191,76.795,88.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.039 | Acc: 49.020,76.611,88.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.046 | Acc: 49.081,76.506,88.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.066 | Acc: 48.850,76.399,88.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.067 | Acc: 48.968,76.400,88.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.072 | Acc: 48.904,76.404,88.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.072 | Acc: 48.889,76.395,88.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.070 | Acc: 48.944,76.404,88.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.069 | Acc: 48.957,76.347,88.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.071 | Acc: 49.009,76.307,88.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.073 | Acc: 48.942,76.255,88.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.078 | Acc: 48.894,76.162,88.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.081 | Acc: 48.868,76.146,88.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 51.562,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.377 | Acc: 44.531,64.844,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.397 | Acc: 44.588,64.615,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.416 | Acc: 44.262,64.741,70.415,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 3.019 | Acc: 50.781,76.562,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.064 | Acc: 49.368,75.856,88.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.026 | Acc: 49.524,76.696,89.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.004 | Acc: 49.757,76.793,89.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.016 | Acc: 49.556,76.669,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.011 | Acc: 49.404,76.926,89.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.018 | Acc: 49.374,76.763,89.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.017 | Acc: 49.357,76.729,89.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.026 | Acc: 49.316,76.669,88.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.037 | Acc: 49.171,76.558,88.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.043 | Acc: 49.114,76.372,88.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.044 | Acc: 49.212,76.403,88.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.048 | Acc: 49.206,76.371,88.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.053 | Acc: 49.105,76.251,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.053 | Acc: 49.158,76.287,88.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.052 | Acc: 49.182,76.344,88.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.056 | Acc: 49.104,76.322,88.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.065 | Acc: 49.068,76.260,88.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.066 | Acc: 49.005,76.210,88.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.068 | Acc: 48.891,76.187,88.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.402 | Acc: 52.344,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.378 | Acc: 45.238,65.030,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.409 | Acc: 45.255,64.615,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.432 | Acc: 44.992,64.677,69.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.904 | Acc: 48.438,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 49.888,77.753,89.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.007 | Acc: 49.790,76.582,89.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.009 | Acc: 49.680,76.780,89.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.041 | Acc: 49.103,76.466,89.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.009 | Acc: 49.513,76.756,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.999 | Acc: 49.761,76.743,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.010 | Acc: 49.706,76.679,89.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.017 | Acc: 49.466,76.655,89.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.038 | Acc: 49.102,76.442,89.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.041 | Acc: 49.087,76.419,88.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.043 | Acc: 49.109,76.389,88.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.040 | Acc: 49.190,76.420,88.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.043 | Acc: 49.144,76.455,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.048 | Acc: 49.102,76.437,88.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.051 | Acc: 49.058,76.456,88.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.054 | Acc: 49.031,76.451,88.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.059 | Acc: 48.990,76.370,88.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.059 | Acc: 49.005,76.413,88.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.061 | Acc: 48.989,76.417,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.303 | Acc: 50.000,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.402 | Acc: 44.978,64.583,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.440 | Acc: 45.255,64.158,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.471 | Acc: 44.941,64.062,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 2.521 | Acc: 60.156,82.031,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.029 | Acc: 47.879,75.818,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.065 | Acc: 47.809,75.705,88.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.051 | Acc: 48.399,76.050,89.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.035 | Acc: 48.659,76.524,89.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.017 | Acc: 48.909,76.733,89.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.021 | Acc: 48.767,76.634,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.021 | Acc: 48.737,76.651,89.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.034 | Acc: 48.729,76.446,89.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.032 | Acc: 48.666,76.519,89.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.027 | Acc: 48.675,76.551,89.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.029 | Acc: 48.660,76.520,89.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.028 | Acc: 48.697,76.537,89.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.030 | Acc: 48.830,76.571,89.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.030 | Acc: 48.821,76.496,89.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.032 | Acc: 48.783,76.412,89.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.035 | Acc: 48.754,76.409,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.037 | Acc: 48.797,76.427,89.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.036 | Acc: 48.784,76.413,89.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.035 | Acc: 48.794,76.435,89.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.584 | Acc: 50.781,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.426 | Acc: 44.903,64.993,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.461 | Acc: 44.646,64.120,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.476 | Acc: 44.390,63.998,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 3.118 | Acc: 46.875,68.750,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.021 | Acc: 49.442,76.897,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.012 | Acc: 49.848,77.039,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.979 | Acc: 49.846,77.395,89.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.016 | Acc: 49.306,76.861,89.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.028 | Acc: 49.350,76.686,89.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.020 | Acc: 49.341,76.646,89.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.013 | Acc: 49.435,76.784,89.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.017 | Acc: 49.563,76.791,89.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.013 | Acc: 49.525,76.817,89.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.020 | Acc: 49.394,76.831,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.026 | Acc: 49.293,76.750,89.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.033 | Acc: 49.144,76.695,89.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.036 | Acc: 49.045,76.622,89.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.032 | Acc: 49.144,76.574,89.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.037 | Acc: 49.141,76.562,89.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.036 | Acc: 49.104,76.562,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.032 | Acc: 49.088,76.620,89.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.036 | Acc: 49.017,76.552,89.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.037 | Acc: 48.950,76.515,89.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.560 | Acc: 51.562,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.429 | Acc: 44.234,64.732,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.443 | Acc: 44.588,64.253,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.465 | Acc: 44.211,64.280,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 3.076 | Acc: 51.562,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.019 | Acc: 48.438,76.414,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.984 | Acc: 49.181,76.848,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.976 | Acc: 48.975,76.921,89.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.975 | Acc: 48.978,76.919,90.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.982 | Acc: 49.103,76.872,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.979 | Acc: 49.032,77.085,89.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.978 | Acc: 49.053,77.150,89.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.982 | Acc: 49.161,77.067,89.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.993 | Acc: 49.111,76.891,89.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.993 | Acc: 49.067,76.831,89.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.988 | Acc: 49.134,76.916,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.990 | Acc: 49.131,76.864,89.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.986 | Acc: 49.246,76.994,89.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.994 | Acc: 49.224,76.827,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.999 | Acc: 49.268,76.788,89.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.010 | Acc: 49.104,76.789,89.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.013 | Acc: 49.056,76.741,89.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.016 | Acc: 48.989,76.692,89.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.018 | Acc: 48.993,76.661,89.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 50.000,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.415 | Acc: 44.159,65.253,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.458 | Acc: 44.569,64.386,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.484 | Acc: 44.249,64.229,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 3.217 | Acc: 49.219,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.037 | Acc: 49.405,75.632,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.015 | Acc: 49.257,76.562,89.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 49.129,76.780,89.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.996 | Acc: 48.862,76.794,89.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.010 | Acc: 48.708,76.795,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.004 | Acc: 48.935,76.692,89.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.016 | Acc: 48.742,76.601,89.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.011 | Acc: 48.894,76.587,89.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.007 | Acc: 49.050,76.714,89.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.016 | Acc: 48.997,76.582,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.012 | Acc: 48.985,76.640,89.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.010 | Acc: 49.021,76.666,89.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.014 | Acc: 48.934,76.619,89.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.009 | Acc: 48.988,76.657,89.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.017 | Acc: 48.897,76.578,89.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.015 | Acc: 48.953,76.589,89.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.014 | Acc: 49.013,76.604,89.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.016 | Acc: 49.015,76.545,89.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.012 | Acc: 49.083,76.622,89.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.531 | Acc: 50.781,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.465 | Acc: 44.792,64.955,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.470 | Acc: 44.722,64.768,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.501 | Acc: 44.557,64.549,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.734 | Acc: 49.219,75.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 50.037,76.339,89.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.933 | Acc: 49.543,77.534,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.956 | Acc: 49.424,77.433,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.952 | Acc: 49.662,77.614,89.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.975 | Acc: 49.157,77.351,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.982 | Acc: 49.083,77.408,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.980 | Acc: 49.152,77.360,89.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.987 | Acc: 49.039,77.193,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.001 | Acc: 48.994,76.994,89.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.004 | Acc: 49.024,76.866,89.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.007 | Acc: 49.046,76.859,89.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.008 | Acc: 49.011,76.767,89.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.008 | Acc: 49.036,76.757,89.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.004 | Acc: 49.088,76.785,89.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.001 | Acc: 49.118,76.742,89.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.008 | Acc: 49.056,76.584,89.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.004 | Acc: 49.081,76.620,89.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.006 | Acc: 49.056,76.604,89.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.009 | Acc: 49.014,76.585,89.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.569 | Acc: 53.125,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.454 | Acc: 44.457,64.509,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.504 | Acc: 44.607,63.872,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.526 | Acc: 44.121,63.832,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 3.006 | Acc: 44.531,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.978 | Acc: 49.256,78.051,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.984 | Acc: 48.780,77.515,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.988 | Acc: 48.745,77.241,90.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.979 | Acc: 48.929,77.238,90.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.986 | Acc: 48.654,77.212,89.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.983 | Acc: 48.812,77.137,89.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.987 | Acc: 48.814,77.072,89.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.972 | Acc: 49.088,77.121,89.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.980 | Acc: 49.214,77.033,89.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.981 | Acc: 49.246,76.963,89.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.981 | Acc: 49.187,77.011,89.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.991 | Acc: 49.121,76.854,89.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.996 | Acc: 49.168,76.751,89.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.998 | Acc: 49.088,76.729,89.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.002 | Acc: 49.034,76.682,89.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.003 | Acc: 49.051,76.687,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.996 | Acc: 49.084,76.748,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.002 | Acc: 49.015,76.697,89.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.008 | Acc: 48.915,76.579,89.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.540 | Acc: 46.875,70.312,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.425 | Acc: 44.643,64.435,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.432 | Acc: 45.160,64.444,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.450 | Acc: 45.056,64.562,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 3.223 | Acc: 43.750,72.656,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.085 | Acc: 48.512,76.153,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.055 | Acc: 48.438,76.620,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.052 | Acc: 48.373,76.652,89.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.035 | Acc: 48.264,76.534,89.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.006 | Acc: 48.886,76.833,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.998 | Acc: 48.973,76.860,90.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.998 | Acc: 48.980,76.928,89.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.998 | Acc: 49.228,76.713,89.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.989 | Acc: 49.296,76.783,89.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.996 | Acc: 49.293,76.706,89.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.994 | Acc: 49.311,76.785,89.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.994 | Acc: 49.241,76.715,89.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.000 | Acc: 49.057,76.616,89.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.003 | Acc: 49.074,76.593,89.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.002 | Acc: 49.190,76.635,89.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.001 | Acc: 49.180,76.677,89.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.000 | Acc: 49.216,76.695,89.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.002 | Acc: 49.234,76.690,89.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.003 | Acc: 49.165,76.704,89.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.490 | Acc: 48.438,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.416 | Acc: 44.234,65.253,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.480 | Acc: 44.627,64.082,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.493 | Acc: 44.288,64.498,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 3.211 | Acc: 46.875,67.188,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 48.549,76.786,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.969 | Acc: 49.009,77.134,90.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.929 | Acc: 49.488,77.600,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.953 | Acc: 49.296,77.363,90.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.970 | Acc: 49.072,77.065,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.988 | Acc: 48.818,76.840,89.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.990 | Acc: 48.759,76.773,89.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.995 | Acc: 48.700,76.873,89.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.995 | Acc: 48.688,76.912,89.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.997 | Acc: 48.651,76.873,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.983 | Acc: 48.876,77.100,90.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.978 | Acc: 48.969,77.101,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.980 | Acc: 48.958,77.047,90.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.981 | Acc: 49.044,77.021,89.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.986 | Acc: 48.933,76.973,89.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.989 | Acc: 48.919,76.993,89.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.984 | Acc: 49.104,76.989,89.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.984 | Acc: 49.154,77.013,89.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.984 | Acc: 49.198,77.003,89.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.459 | Acc: 47.656,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.388 | Acc: 45.164,64.807,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.411 | Acc: 45.446,64.253,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.458 | Acc: 45.428,64.293,69.493,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.883 | Acc: 49.219,70.312,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 49.814,76.525,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.965 | Acc: 49.657,76.505,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.963 | Acc: 50.026,76.793,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.975 | Acc: 49.653,76.466,90.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.980 | Acc: 49.590,76.508,90.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.981 | Acc: 49.651,76.692,90.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.981 | Acc: 49.551,76.795,90.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.982 | Acc: 49.423,76.965,90.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.973 | Acc: 49.517,77.119,90.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.973 | Acc: 49.363,77.107,90.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.967 | Acc: 49.360,77.114,90.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.977 | Acc: 49.232,77.055,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.973 | Acc: 49.341,77.140,90.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.977 | Acc: 49.244,77.069,90.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.980 | Acc: 49.216,76.978,89.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.986 | Acc: 49.168,76.940,89.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.981 | Acc: 49.235,76.979,89.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.983 | Acc: 49.117,76.980,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.984 | Acc: 49.129,77.034,89.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.448 | Acc: 49.219,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.449 | Acc: 44.531,64.509,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 44.893,64.196,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.490 | Acc: 44.800,64.447,69.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 3.344 | Acc: 45.312,72.656,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.951 | Acc: 49.442,77.232,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.913 | Acc: 49.505,77.820,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.962 | Acc: 48.745,77.536,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.969 | Acc: 48.746,77.450,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.965 | Acc: 49.165,77.421,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.960 | Acc: 49.341,77.415,90.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.965 | Acc: 49.379,77.161,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.959 | Acc: 49.262,77.227,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.952 | Acc: 49.374,77.413,90.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.951 | Acc: 49.456,77.414,90.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.945 | Acc: 49.625,77.471,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.945 | Acc: 49.553,77.506,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.949 | Acc: 49.605,77.356,90.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.956 | Acc: 49.614,77.352,90.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.960 | Acc: 49.507,77.281,90.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.962 | Acc: 49.540,77.254,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.968 | Acc: 49.473,77.140,90.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.975 | Acc: 49.301,77.067,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.981 | Acc: 49.145,76.995,89.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.576 | Acc: 52.344,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.445 | Acc: 44.271,64.583,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.473 | Acc: 44.264,64.729,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.515 | Acc: 44.365,64.319,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 2.937 | Acc: 44.531,82.031,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.888 | Acc: 50.744,77.790,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.921 | Acc: 50.000,77.630,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.906 | Acc: 49.513,77.869,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.911 | Acc: 49.701,77.855,90.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.945 | Acc: 49.327,77.460,90.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.950 | Acc: 49.451,77.389,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.955 | Acc: 49.413,77.299,90.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.958 | Acc: 49.442,77.237,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.958 | Acc: 49.348,77.210,90.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.963 | Acc: 49.405,77.114,90.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.963 | Acc: 49.265,77.110,90.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.964 | Acc: 49.335,77.127,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.963 | Acc: 49.422,77.071,90.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.964 | Acc: 49.488,77.041,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.967 | Acc: 49.377,77.040,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.972 | Acc: 49.316,76.906,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.975 | Acc: 49.239,76.911,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.970 | Acc: 49.247,76.993,90.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.970 | Acc: 49.245,77.010,90.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 46.875,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.438 | Acc: 44.457,65.290,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.491 | Acc: 44.455,64.348,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.507 | Acc: 44.659,64.434,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 2.793 | Acc: 50.000,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.956 | Acc: 48.624,76.562,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 49.562,77.801,91.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.919 | Acc: 49.577,77.228,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.936 | Acc: 49.450,77.016,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.923 | Acc: 49.660,77.290,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.929 | Acc: 49.425,77.215,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.936 | Acc: 49.440,77.261,90.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.932 | Acc: 49.568,77.455,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.946 | Acc: 49.422,77.344,90.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.938 | Acc: 49.666,77.398,90.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.943 | Acc: 49.657,77.315,90.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.946 | Acc: 49.527,77.253,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.947 | Acc: 49.458,77.266,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.949 | Acc: 49.369,77.191,90.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.954 | Acc: 49.323,77.152,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.952 | Acc: 49.301,77.207,90.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.953 | Acc: 49.310,77.183,90.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.954 | Acc: 49.336,77.173,90.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.962 | Acc: 49.235,77.116,90.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.581 | Acc: 50.000,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.478 | Acc: 43.713,64.732,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.511 | Acc: 44.455,64.024,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 44.121,64.062,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 3.130 | Acc: 47.656,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 48.958,76.600,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.927 | Acc: 50.133,77.325,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.895 | Acc: 50.525,77.702,90.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.903 | Acc: 50.434,77.623,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.911 | Acc: 50.240,77.692,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.929 | Acc: 49.690,77.621,90.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.939 | Acc: 49.518,77.416,90.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.952 | Acc: 49.316,77.232,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.950 | Acc: 49.378,77.275,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.950 | Acc: 49.316,77.270,90.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.944 | Acc: 49.342,77.358,90.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.948 | Acc: 49.387,77.243,90.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.942 | Acc: 49.479,77.287,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.952 | Acc: 49.455,77.202,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.950 | Acc: 49.468,77.191,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.958 | Acc: 49.202,77.176,90.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.964 | Acc: 49.148,77.105,90.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.965 | Acc: 49.124,77.097,90.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.963 | Acc: 49.114,77.096,90.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.374 | Acc: 52.344,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.422 | Acc: 45.238,64.769,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.457 | Acc: 45.198,64.082,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.477 | Acc: 44.954,64.383,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.965 | Acc: 46.875,80.469,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.924 | Acc: 49.107,77.418,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.916 | Acc: 48.933,77.820,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.922 | Acc: 48.642,77.779,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.934 | Acc: 48.553,77.749,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.929 | Acc: 48.569,77.653,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.931 | Acc: 48.954,77.621,90.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.944 | Acc: 49.003,77.588,90.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.944 | Acc: 48.884,77.387,90.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.947 | Acc: 48.908,77.426,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.959 | Acc: 48.842,77.254,90.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.957 | Acc: 48.844,77.298,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.958 | Acc: 48.882,77.298,90.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.962 | Acc: 48.851,77.224,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.968 | Acc: 48.796,77.166,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.967 | Acc: 48.790,77.172,90.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.966 | Acc: 48.798,77.222,90.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.961 | Acc: 48.962,77.227,90.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.960 | Acc: 49.048,77.188,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.961 | Acc: 49.042,77.104,90.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.498 | Acc: 51.562,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.513 | Acc: 44.196,64.025,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.540 | Acc: 44.550,63.834,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 44.288,63.730,68.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 2.752 | Acc: 50.000,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.938 | Acc: 48.475,76.786,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.936 | Acc: 48.342,77.020,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.941 | Acc: 48.245,77.267,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.940 | Acc: 48.302,77.479,90.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.931 | Acc: 48.793,77.468,90.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.924 | Acc: 49.096,77.415,90.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.928 | Acc: 49.086,77.371,90.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.942 | Acc: 49.034,77.198,90.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.943 | Acc: 49.214,77.240,90.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.949 | Acc: 49.250,77.223,90.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.948 | Acc: 49.311,77.224,90.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.950 | Acc: 49.280,77.188,90.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.956 | Acc: 49.186,77.131,90.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.952 | Acc: 49.124,77.235,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.957 | Acc: 48.988,77.167,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.955 | Acc: 49.124,77.181,90.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.952 | Acc: 49.143,77.190,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.951 | Acc: 49.102,77.142,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.950 | Acc: 49.098,77.190,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.471 | Acc: 50.781,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.482 | Acc: 44.792,64.695,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.513 | Acc: 44.989,64.158,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.540 | Acc: 44.762,64.037,68.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 2.696 | Acc: 53.125,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.842 | Acc: 49.888,79.092,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.864 | Acc: 49.314,78.639,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.860 | Acc: 49.987,78.394,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.864 | Acc: 50.164,78.376,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.871 | Acc: 49.853,78.326,91.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.870 | Acc: 49.742,78.422,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.879 | Acc: 49.889,78.164,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.891 | Acc: 49.835,78.115,91.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.894 | Acc: 49.646,78.073,90.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.897 | Acc: 49.720,78.024,90.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.904 | Acc: 49.654,78.005,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.904 | Acc: 49.650,77.976,90.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.911 | Acc: 49.590,77.909,90.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.920 | Acc: 49.411,77.816,90.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.928 | Acc: 49.349,77.689,90.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.926 | Acc: 49.297,77.663,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.923 | Acc: 49.210,77.683,90.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.929 | Acc: 49.212,77.521,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.928 | Acc: 49.170,77.541,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.443 | Acc: 48.438,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.468 | Acc: 44.978,64.509,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.491 | Acc: 44.665,64.005,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.508 | Acc: 44.915,64.255,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 2.798 | Acc: 49.219,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.842 | Acc: 49.442,78.534,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.880 | Acc: 49.066,77.858,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.889 | Acc: 49.039,77.959,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.891 | Acc: 49.354,77.855,91.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.901 | Acc: 49.165,77.731,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.896 | Acc: 49.064,77.809,90.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.903 | Acc: 48.864,77.820,90.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.914 | Acc: 48.894,77.747,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.920 | Acc: 48.994,77.555,90.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.919 | Acc: 49.153,77.565,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.915 | Acc: 49.229,77.559,90.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.916 | Acc: 49.154,77.535,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.918 | Acc: 49.141,77.484,90.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.918 | Acc: 49.113,77.430,90.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.916 | Acc: 49.162,77.523,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.918 | Acc: 49.175,77.526,90.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.921 | Acc: 49.184,77.550,90.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.925 | Acc: 49.165,77.508,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.931 | Acc: 49.131,77.489,90.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.582 | Acc: 46.094,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.536 | Acc: 44.122,63.765,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 43.998,63.834,68.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 43.840,63.909,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.724 | Acc: 54.688,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.001 | Acc: 47.917,76.637,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.962 | Acc: 49.162,77.229,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.952 | Acc: 48.796,77.305,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.961 | Acc: 48.611,77.189,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.926 | Acc: 49.110,77.522,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.928 | Acc: 49.115,77.499,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.932 | Acc: 48.975,77.316,90.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.925 | Acc: 49.175,77.446,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.925 | Acc: 49.176,77.430,90.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.926 | Acc: 49.254,77.383,90.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.937 | Acc: 49.145,77.153,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.946 | Acc: 48.998,77.058,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.943 | Acc: 49.150,77.113,90.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.937 | Acc: 49.338,77.113,90.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.935 | Acc: 49.471,77.159,90.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.936 | Acc: 49.382,77.142,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.927 | Acc: 49.503,77.243,90.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.929 | Acc: 49.457,77.257,90.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.934 | Acc: 49.442,77.245,90.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.448 | Acc: 47.656,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.467 | Acc: 44.420,64.844,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.489 | Acc: 44.779,64.367,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.515 | Acc: 44.787,64.216,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 2.623 | Acc: 52.344,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 49.330,77.269,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.919 | Acc: 49.104,78.087,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.918 | Acc: 49.270,77.997,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.925 | Acc: 49.412,77.990,91.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.926 | Acc: 49.397,77.908,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.946 | Acc: 49.180,77.447,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.944 | Acc: 49.252,77.272,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.943 | Acc: 49.209,77.286,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.938 | Acc: 49.253,77.374,90.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.937 | Acc: 49.160,77.394,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.934 | Acc: 49.251,77.379,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.933 | Acc: 49.248,77.412,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.933 | Acc: 49.231,77.404,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.931 | Acc: 49.274,77.435,90.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.932 | Acc: 49.221,77.437,90.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.931 | Acc: 49.207,77.439,90.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.926 | Acc: 49.230,77.534,90.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.922 | Acc: 49.240,77.575,90.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.925 | Acc: 49.170,77.534,90.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.512 | Acc: 49.219,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.476 | Acc: 45.312,64.360,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.505 | Acc: 45.293,63.872,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.530 | Acc: 45.031,64.191,68.404,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 3.173 | Acc: 44.531,75.000,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.925 | Acc: 49.107,77.493,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.960 | Acc: 49.085,77.325,90.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.919 | Acc: 49.757,77.741,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.889 | Acc: 50.183,77.865,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.881 | Acc: 50.101,77.916,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.879 | Acc: 49.897,77.873,91.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.894 | Acc: 49.651,77.648,91.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.891 | Acc: 49.558,77.664,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.887 | Acc: 49.629,77.732,91.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.889 | Acc: 49.786,77.740,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 49.625,77.740,91.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.902 | Acc: 49.446,77.772,91.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.905 | Acc: 49.467,77.619,91.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.908 | Acc: 49.430,77.613,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.908 | Acc: 49.473,77.647,90.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.911 | Acc: 49.477,77.524,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.912 | Acc: 49.519,77.557,90.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.914 | Acc: 49.429,77.541,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.919 | Acc: 49.465,77.487,90.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.488 | Acc: 49.219,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.477 | Acc: 44.866,65.402,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.520 | Acc: 45.198,64.958,68.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 44.941,64.780,68.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 2.853 | Acc: 51.562,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.802 | Acc: 50.484,78.869,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.801 | Acc: 50.667,78.792,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.842 | Acc: 50.154,78.330,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.868 | Acc: 50.048,77.980,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.883 | Acc: 49.752,77.963,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.878 | Acc: 49.729,77.918,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.879 | Acc: 49.884,78.053,91.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.880 | Acc: 49.903,77.878,91.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.876 | Acc: 49.935,77.896,91.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.875 | Acc: 49.942,77.954,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.875 | Acc: 49.894,77.945,91.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.886 | Acc: 49.757,77.807,91.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.894 | Acc: 49.689,77.733,91.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.903 | Acc: 49.636,77.563,91.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.905 | Acc: 49.631,77.637,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.907 | Acc: 49.637,77.633,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 49.741,77.699,90.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.903 | Acc: 49.734,77.606,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.908 | Acc: 49.567,77.536,90.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.513 | Acc: 48.438,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 45.164,64.881,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 45.084,64.272,68.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.563 | Acc: 45.018,64.280,68.596,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 2.823 | Acc: 51.562,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.838 | Acc: 50.000,78.423,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.858 | Acc: 50.438,78.239,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.852 | Acc: 50.692,78.138,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.870 | Acc: 50.482,78.019,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.867 | Acc: 50.394,78.071,91.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.861 | Acc: 50.510,78.151,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.866 | Acc: 50.305,78.164,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.871 | Acc: 50.233,78.232,91.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.874 | Acc: 50.155,78.160,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.879 | Acc: 49.949,78.086,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.894 | Acc: 49.646,77.821,91.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.905 | Acc: 49.527,77.658,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.906 | Acc: 49.584,77.607,91.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.904 | Acc: 49.522,77.583,91.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.904 | Acc: 49.564,77.616,91.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.902 | Acc: 49.618,77.650,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 49.636,77.630,91.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.903 | Acc: 49.636,77.593,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.906 | Acc: 49.635,77.580,91.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.641 | Acc: 46.875,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 42.969,63.616,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 43.350,63.167,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 43.122,63.384,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 3.004 | Acc: 50.000,78.906,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.852 | Acc: 50.856,76.860,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 49.295,76.982,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.918 | Acc: 49.308,77.049,91.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.909 | Acc: 49.711,77.247,91.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.902 | Acc: 49.791,77.011,91.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.887 | Acc: 50.077,77.370,91.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.889 | Acc: 49.956,77.294,91.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.896 | Acc: 49.922,77.455,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.892 | Acc: 49.892,77.452,91.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.885 | Acc: 49.891,77.589,91.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.880 | Acc: 49.933,77.779,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.881 | Acc: 49.802,77.749,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.882 | Acc: 49.832,77.769,91.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.890 | Acc: 49.708,77.702,91.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.886 | Acc: 49.681,77.772,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.885 | Acc: 49.671,77.818,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.895 | Acc: 49.620,77.745,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.898 | Acc: 49.543,77.690,91.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.906 | Acc: 49.346,77.635,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.534 | Acc: 43.750,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.659 | Acc: 42.634,63.207,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.671 | Acc: 43.655,63.148,68.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.685 | Acc: 43.020,63.256,68.468,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 3.161 | Acc: 47.656,76.562,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.846 | Acc: 49.702,78.274,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.865 | Acc: 49.752,78.068,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.859 | Acc: 50.051,78.061,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.849 | Acc: 50.116,78.154,91.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.851 | Acc: 50.186,78.264,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.862 | Acc: 50.019,78.125,91.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.861 | Acc: 50.044,78.158,91.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.873 | Acc: 49.913,77.921,91.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.880 | Acc: 49.970,77.935,91.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.878 | Acc: 49.926,77.950,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.891 | Acc: 49.608,77.828,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.899 | Acc: 49.436,77.700,91.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.907 | Acc: 49.434,77.619,91.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.902 | Acc: 49.519,77.705,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.902 | Acc: 49.458,77.806,90.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.905 | Acc: 49.375,77.765,90.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.903 | Acc: 49.381,77.832,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.903 | Acc: 49.398,77.824,90.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.905 | Acc: 49.381,77.799,90.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.512 | Acc: 47.656,72.656,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 44.085,64.658,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 44.131,64.291,68.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.584 | Acc: 44.147,64.178,69.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 3.186 | Acc: 41.406,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.877 | Acc: 49.070,78.274,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.863 | Acc: 49.028,78.277,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.871 | Acc: 49.347,77.920,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.851 | Acc: 49.392,78.260,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.861 | Acc: 49.389,78.233,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 49.245,78.403,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.867 | Acc: 49.291,78.507,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.854 | Acc: 49.500,78.659,91.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.864 | Acc: 49.417,78.513,91.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.872 | Acc: 49.207,78.444,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.874 | Acc: 49.268,78.425,91.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.872 | Acc: 49.391,78.368,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.874 | Acc: 49.413,78.290,91.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.878 | Acc: 49.433,78.125,91.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.886 | Acc: 49.395,78.019,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.888 | Acc: 49.409,77.996,91.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.895 | Acc: 49.345,77.914,91.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.898 | Acc: 49.294,77.852,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.901 | Acc: 49.252,77.819,91.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.747 | Acc: 48.438,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.655 | Acc: 43.452,63.839,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.657 | Acc: 43.941,63.681,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.662 | Acc: 43.648,63.781,68.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.919 | Acc: 42.969,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.933 | Acc: 49.144,77.679,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 50.133,77.439,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.906 | Acc: 49.834,77.651,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.912 | Acc: 49.334,77.633,91.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.902 | Acc: 49.110,77.591,91.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.895 | Acc: 49.070,77.660,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.897 | Acc: 48.925,77.754,91.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.903 | Acc: 48.966,77.480,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.897 | Acc: 49.059,77.616,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.890 | Acc: 49.137,77.624,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 49.314,77.552,91.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.889 | Acc: 49.339,77.499,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.884 | Acc: 49.425,77.610,91.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.885 | Acc: 49.383,77.577,91.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.882 | Acc: 49.489,77.658,91.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.890 | Acc: 49.448,77.558,91.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.890 | Acc: 49.510,77.626,91.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.892 | Acc: 49.535,77.616,91.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.896 | Acc: 49.522,77.565,91.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.755 | Acc: 48.438,64.844,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.615 | Acc: 43.787,64.472,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 44.207,64.005,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.641 | Acc: 43.737,63.934,68.417,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 2.735 | Acc: 52.344,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.919 | Acc: 49.554,77.604,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.903 | Acc: 49.390,77.649,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.916 | Acc: 48.655,77.651,91.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.900 | Acc: 49.084,77.903,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.884 | Acc: 49.358,77.831,91.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.877 | Acc: 49.496,77.822,91.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.884 | Acc: 49.385,77.610,91.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.900 | Acc: 49.233,77.446,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.900 | Acc: 49.206,77.460,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.899 | Acc: 49.436,77.565,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 49.502,77.538,91.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.895 | Acc: 49.517,77.636,91.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.896 | Acc: 49.533,77.562,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 49.572,77.666,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.886 | Acc: 49.618,77.671,91.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.886 | Acc: 49.606,77.585,91.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.887 | Acc: 49.670,77.582,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.888 | Acc: 49.643,77.632,91.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.886 | Acc: 49.608,77.705,91.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.558 | Acc: 49.219,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 44.420,64.546,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.577 | Acc: 44.874,64.196,68.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.595 | Acc: 44.467,64.280,68.622,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.932 | Acc: 43.750,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.850 | Acc: 48.996,78.051,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.887 | Acc: 49.314,77.191,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.884 | Acc: 49.488,77.433,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.883 | Acc: 49.547,77.459,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.863 | Acc: 49.644,77.893,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 49.516,77.989,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.866 | Acc: 49.568,77.914,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.870 | Acc: 49.393,77.814,91.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.870 | Acc: 49.478,77.883,91.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.872 | Acc: 49.378,77.837,91.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.867 | Acc: 49.360,77.966,91.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.863 | Acc: 49.368,78.015,91.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.868 | Acc: 49.344,77.892,91.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.867 | Acc: 49.436,77.878,91.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.867 | Acc: 49.374,77.855,91.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.871 | Acc: 49.399,77.760,91.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.874 | Acc: 49.329,77.765,91.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.875 | Acc: 49.364,77.768,91.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.880 | Acc: 49.319,77.717,91.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.680 | Acc: 46.875,63.281,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.587 | Acc: 44.271,64.249,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 44.207,64.215,68.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.634 | Acc: 44.211,64.088,68.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.510 | Acc: 55.469,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.882 | Acc: 49.070,77.865,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.866 | Acc: 48.990,77.858,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.877 | Acc: 49.385,77.869,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.879 | Acc: 49.662,77.971,91.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.881 | Acc: 49.729,78.024,91.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.882 | Acc: 49.458,77.925,91.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.869 | Acc: 49.518,78.197,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.859 | Acc: 49.495,78.256,91.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.867 | Acc: 49.504,78.151,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.863 | Acc: 49.576,78.176,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.869 | Acc: 49.509,78.005,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 49.530,77.947,91.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.871 | Acc: 49.608,77.859,91.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.870 | Acc: 49.566,77.858,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.870 | Acc: 49.556,77.873,91.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.869 | Acc: 49.628,77.860,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.866 | Acc: 49.684,77.884,91.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.868 | Acc: 49.665,77.848,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.874 | Acc: 49.682,77.797,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.704 | Acc: 50.000,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.609 | Acc: 44.494,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.651 | Acc: 44.379,63.720,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.678 | Acc: 44.390,63.640,67.853,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 2.547 | Acc: 54.688,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.820 | Acc: 50.632,78.869,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.811 | Acc: 50.514,78.982,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.811 | Acc: 50.371,78.881,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.817 | Acc: 50.135,78.839,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.840 | Acc: 49.729,78.612,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.849 | Acc: 49.722,78.603,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.862 | Acc: 49.573,78.546,91.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.866 | Acc: 49.534,78.251,91.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.865 | Acc: 49.689,78.250,91.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.864 | Acc: 49.724,78.199,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.860 | Acc: 49.756,78.252,91.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.862 | Acc: 49.737,78.213,91.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 49.695,78.134,91.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.866 | Acc: 49.728,78.195,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.861 | Acc: 49.811,78.309,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.866 | Acc: 49.788,78.225,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.866 | Acc: 49.762,78.185,91.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.869 | Acc: 49.680,78.177,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.874 | Acc: 49.576,78.098,91.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.486 | Acc: 50.781,67.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.607 | Acc: 43.713,64.807,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 44.341,64.043,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.654 | Acc: 43.993,64.037,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.499 | Acc: 54.688,76.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.815 | Acc: 49.851,77.939,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.850 | Acc: 49.333,77.820,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.848 | Acc: 49.232,78.356,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.850 | Acc: 49.769,78.424,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.865 | Acc: 49.783,78.202,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.882 | Acc: 49.690,77.976,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.880 | Acc: 49.773,78.081,91.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.873 | Acc: 49.956,78.198,91.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.871 | Acc: 49.871,78.203,91.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.867 | Acc: 49.899,78.230,91.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.865 | Acc: 49.806,78.302,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.869 | Acc: 49.789,78.264,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.868 | Acc: 49.886,78.266,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.871 | Acc: 49.917,78.203,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.870 | Acc: 49.922,78.099,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.874 | Acc: 49.844,78.086,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.874 | Acc: 49.750,78.095,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.875 | Acc: 49.682,78.090,91.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.877 | Acc: 49.666,78.037,91.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.620 | Acc: 46.094,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.588 | Acc: 44.122,64.360,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.616 | Acc: 44.303,63.834,68.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.630 | Acc: 44.211,63.973,68.635,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 3.081 | Acc: 44.531,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.735 | Acc: 48.735,79.799,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.759 | Acc: 49.390,79.268,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.835 | Acc: 48.911,78.778,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.845 | Acc: 48.515,78.482,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.842 | Acc: 49.080,78.458,91.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.847 | Acc: 49.077,78.609,91.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.839 | Acc: 49.113,78.646,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.833 | Acc: 49.345,78.620,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.837 | Acc: 49.422,78.656,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.844 | Acc: 49.238,78.490,91.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.846 | Acc: 49.095,78.411,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.846 | Acc: 49.235,78.362,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.843 | Acc: 49.321,78.376,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.845 | Acc: 49.366,78.381,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 49.333,78.265,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.849 | Acc: 49.413,78.305,91.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.857 | Acc: 49.425,78.191,91.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.858 | Acc: 49.377,78.188,91.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 49.381,78.141,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.859 | Acc: 46.875,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.626 | Acc: 44.159,64.621,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.668 | Acc: 44.207,63.853,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 44.109,63.858,67.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 2.509 | Acc: 55.469,83.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.836 | Acc: 49.144,78.609,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.823 | Acc: 49.466,78.678,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.824 | Acc: 49.705,78.586,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.860 | Acc: 49.257,78.347,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.858 | Acc: 49.381,78.318,91.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.853 | Acc: 49.684,78.248,91.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.848 | Acc: 49.789,78.081,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.845 | Acc: 49.704,78.101,91.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.844 | Acc: 49.706,78.198,91.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.841 | Acc: 49.778,78.218,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.832 | Acc: 49.834,78.312,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.832 | Acc: 49.880,78.342,91.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.831 | Acc: 49.916,78.347,91.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.839 | Acc: 49.853,78.253,91.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.846 | Acc: 49.683,78.226,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.852 | Acc: 49.603,78.152,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 49.647,78.123,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.860 | Acc: 49.582,78.071,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.865 | Acc: 49.576,78.057,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.706 | Acc: 50.000,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.587 | Acc: 44.568,64.360,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.608 | Acc: 44.684,63.834,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.643 | Acc: 44.723,63.934,67.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.559 | Acc: 54.688,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.852 | Acc: 49.888,77.827,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 49.409,78.411,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.820 | Acc: 49.526,78.753,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.818 | Acc: 49.759,78.906,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.818 | Acc: 50.015,78.891,91.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.828 | Acc: 49.871,78.725,91.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.825 | Acc: 49.972,78.834,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.823 | Acc: 50.053,78.892,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.829 | Acc: 49.940,78.798,91.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.838 | Acc: 49.848,78.553,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.834 | Acc: 49.901,78.606,91.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.834 | Acc: 49.838,78.524,91.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.833 | Acc: 49.871,78.481,91.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.836 | Acc: 49.897,78.372,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.848 | Acc: 49.868,78.281,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.847 | Acc: 49.827,78.271,91.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.847 | Acc: 49.945,78.317,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.856 | Acc: 49.840,78.188,91.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 49.826,78.201,91.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.876 | Acc: 42.969,64.844,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.638 | Acc: 43.638,63.988,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.665 | Acc: 44.188,63.739,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 43.942,63.665,68.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.725 | Acc: 51.562,83.594,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.775 | Acc: 49.554,79.315,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.789 | Acc: 49.276,79.192,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 49.616,79.214,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.802 | Acc: 49.971,78.897,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.808 | Acc: 49.799,79.061,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.823 | Acc: 49.703,78.874,92.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.828 | Acc: 49.629,78.729,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.831 | Acc: 49.777,78.610,91.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 50.052,78.574,91.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.828 | Acc: 50.000,78.506,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 49.876,78.404,91.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.831 | Acc: 49.955,78.378,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.835 | Acc: 49.913,78.290,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.839 | Acc: 49.883,78.328,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.848 | Acc: 49.860,78.218,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.853 | Acc: 49.798,78.130,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.855 | Acc: 49.741,78.116,91.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.854 | Acc: 49.781,78.136,91.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.860 | Acc: 49.690,78.098,91.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.376 | Acc: 48.438,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 44.531,64.137,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 44.989,63.643,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.623 | Acc: 44.647,63.755,68.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.765 | Acc: 48.438,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.788 | Acc: 50.074,79.427,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.804 | Acc: 50.076,79.059,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.799 | Acc: 50.205,78.855,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.814 | Acc: 49.797,78.646,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.820 | Acc: 49.760,78.659,92.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.835 | Acc: 49.806,78.512,92.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.831 | Acc: 49.778,78.524,92.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.836 | Acc: 49.709,78.460,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.838 | Acc: 49.698,78.298,92.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.843 | Acc: 49.798,78.230,91.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.849 | Acc: 49.618,78.220,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.854 | Acc: 49.569,78.193,91.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.856 | Acc: 49.623,78.143,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.856 | Acc: 49.569,78.125,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.851 | Acc: 49.577,78.128,91.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.851 | Acc: 49.618,78.137,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.852 | Acc: 49.597,78.116,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.856 | Acc: 49.561,78.097,91.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 49.582,78.018,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.813 | Acc: 46.094,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.614 | Acc: 44.048,63.653,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.649 | Acc: 44.245,63.262,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.666 | Acc: 44.006,63.332,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 2.519 | Acc: 55.469,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.706 | Acc: 52.307,79.688,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.760 | Acc: 49.886,79.268,92.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.794 | Acc: 49.091,78.957,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 49.508,78.954,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.776 | Acc: 49.698,79.192,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.780 | Acc: 49.645,79.106,92.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.793 | Acc: 49.607,78.890,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.802 | Acc: 49.733,78.770,92.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.809 | Acc: 49.685,78.561,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 49.693,78.661,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 49.710,78.691,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.814 | Acc: 49.660,78.715,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.816 | Acc: 49.569,78.703,92.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.820 | Acc: 49.555,78.673,92.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 49.650,78.621,92.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.823 | Acc: 49.650,78.512,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.827 | Acc: 49.636,78.446,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.829 | Acc: 49.684,78.432,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.834 | Acc: 49.643,78.310,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.739 | Acc: 46.875,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 44.940,63.914,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.627 | Acc: 44.722,63.357,67.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.656 | Acc: 44.736,63.576,67.943,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 2.977 | Acc: 52.344,71.094,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.795 | Acc: 50.335,78.795,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.825 | Acc: 50.152,78.011,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.817 | Acc: 49.846,77.907,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.840 | Acc: 49.749,77.894,92.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.838 | Acc: 49.838,77.816,92.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.842 | Acc: 49.877,77.802,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.854 | Acc: 49.668,77.671,91.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.861 | Acc: 49.403,77.703,91.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.854 | Acc: 49.460,77.771,91.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.855 | Acc: 49.398,77.775,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.844 | Acc: 49.590,77.878,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.840 | Acc: 49.728,77.927,91.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.842 | Acc: 49.677,77.951,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.850 | Acc: 49.494,77.891,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 49.593,77.889,91.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.857 | Acc: 49.535,77.852,91.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.858 | Acc: 49.455,77.809,91.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.859 | Acc: 49.457,77.837,91.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.859 | Acc: 49.457,77.846,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.773 | Acc: 42.188,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.741 | Acc: 43.080,63.207,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.773 | Acc: 43.712,62.652,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.784 | Acc: 42.866,62.987,67.943,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 3.109 | Acc: 46.875,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.732 | Acc: 51.116,79.464,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.828 | Acc: 50.076,78.620,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.815 | Acc: 50.295,78.624,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.816 | Acc: 50.068,78.434,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.825 | Acc: 49.930,78.342,92.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.829 | Acc: 50.090,78.422,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.839 | Acc: 50.150,78.208,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.829 | Acc: 50.053,78.314,92.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.820 | Acc: 50.259,78.492,92.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.817 | Acc: 50.128,78.560,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.824 | Acc: 49.993,78.524,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.823 | Acc: 49.958,78.475,92.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.826 | Acc: 49.979,78.418,92.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.831 | Acc: 49.911,78.339,91.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.829 | Acc: 49.914,78.364,91.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.828 | Acc: 49.949,78.381,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 49.853,78.313,91.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 49.706,78.305,91.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.840 | Acc: 49.686,78.232,91.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.874 | Acc: 45.312,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.700 | Acc: 42.969,64.323,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.701 | Acc: 43.236,63.948,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.722 | Acc: 43.148,63.832,67.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 2.849 | Acc: 51.562,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.801 | Acc: 48.586,78.571,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.765 | Acc: 49.486,79.478,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 49.206,78.906,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.796 | Acc: 49.701,79.157,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.812 | Acc: 49.544,78.968,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.823 | Acc: 49.477,78.667,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.830 | Acc: 49.512,78.574,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.827 | Acc: 49.534,78.533,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.829 | Acc: 49.473,78.552,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.827 | Acc: 49.499,78.533,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.822 | Acc: 49.721,78.599,91.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.820 | Acc: 49.773,78.569,91.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.824 | Acc: 49.740,78.550,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.832 | Acc: 49.739,78.498,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.830 | Acc: 49.743,78.499,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.838 | Acc: 49.684,78.402,91.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.837 | Acc: 49.686,78.437,91.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.838 | Acc: 49.788,78.417,91.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.842 | Acc: 49.690,78.328,91.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.672 | Acc: 47.656,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.635 | Acc: 43.155,63.616,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.648 | Acc: 43.483,63.357,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.698 | Acc: 43.084,63.332,68.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 3.079 | Acc: 46.094,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.798 | Acc: 49.888,78.162,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.795 | Acc: 49.829,79.040,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 50.000,78.970,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.793 | Acc: 49.961,78.964,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.789 | Acc: 50.085,79.015,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.804 | Acc: 49.955,78.622,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.803 | Acc: 50.033,78.552,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.808 | Acc: 50.015,78.610,91.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 49.871,78.639,91.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.814 | Acc: 49.650,78.615,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.824 | Acc: 49.516,78.433,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.830 | Acc: 49.442,78.410,91.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.829 | Acc: 49.392,78.454,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.831 | Acc: 49.419,78.395,91.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.831 | Acc: 49.481,78.322,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.832 | Acc: 49.523,78.315,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 49.475,78.317,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.837 | Acc: 49.457,78.264,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 49.530,78.242,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.801 | Acc: 53.125,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.664 | Acc: 43.862,63.765,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.713 | Acc: 43.750,63.758,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.737 | Acc: 43.609,63.832,67.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 3.125 | Acc: 49.219,71.875,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.834 | Acc: 48.921,77.790,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.810 | Acc: 50.457,77.839,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.791 | Acc: 50.961,78.432,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 50.810,78.463,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.776 | Acc: 50.851,78.736,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.801 | Acc: 50.323,78.319,92.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.804 | Acc: 50.194,78.330,92.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.804 | Acc: 50.165,78.542,92.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.811 | Acc: 49.840,78.449,92.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.811 | Acc: 49.806,78.448,92.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.812 | Acc: 49.894,78.425,92.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 49.900,78.358,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.806 | Acc: 49.943,78.332,92.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.805 | Acc: 49.911,78.406,92.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.808 | Acc: 49.894,78.468,92.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.814 | Acc: 49.864,78.388,92.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.821 | Acc: 49.901,78.267,92.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.821 | Acc: 49.883,78.281,92.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 49.797,78.236,91.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.710 | Acc: 49.219,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.649 | Acc: 45.536,64.583,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.654 | Acc: 45.008,63.758,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.683 | Acc: 44.903,63.909,68.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 2.705 | Acc: 52.344,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.790 | Acc: 50.074,78.571,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.795 | Acc: 49.905,78.125,92.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 49.475,78.624,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.815 | Acc: 49.151,78.376,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.801 | Acc: 49.304,78.535,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.820 | Acc: 49.257,78.357,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.818 | Acc: 49.307,78.291,92.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.814 | Acc: 49.408,78.484,92.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 49.551,78.470,92.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.818 | Acc: 49.425,78.315,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 49.342,78.288,92.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.826 | Acc: 49.306,78.258,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.830 | Acc: 49.365,78.239,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.836 | Acc: 49.369,78.164,91.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 49.369,78.231,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.838 | Acc: 49.387,78.157,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.838 | Acc: 49.384,78.185,91.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.841 | Acc: 49.366,78.244,91.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 49.434,78.324,91.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.641 | Acc: 47.656,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.857 | Acc: 40.848,62.016,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.898 | Acc: 41.425,61.947,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.926 | Acc: 40.958,61.988,67.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 3.311 | Acc: 42.969,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.772 | Acc: 49.442,79.539,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.811 | Acc: 49.524,78.963,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.801 | Acc: 50.000,79.150,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 50.135,79.504,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.792 | Acc: 50.077,79.425,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.804 | Acc: 49.890,79.197,91.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.818 | Acc: 49.751,78.973,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.817 | Acc: 49.709,79.037,92.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.830 | Acc: 49.581,78.859,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.826 | Acc: 49.821,78.786,91.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.830 | Acc: 49.767,78.715,91.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.834 | Acc: 49.760,78.650,91.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.838 | Acc: 49.749,78.556,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.840 | Acc: 49.677,78.486,91.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.839 | Acc: 49.696,78.522,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.842 | Acc: 49.742,78.402,91.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.842 | Acc: 49.727,78.333,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.843 | Acc: 49.727,78.307,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.844 | Acc: 49.828,78.285,91.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.612 | Acc: 43.750,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.733 | Acc: 43.601,63.021,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.727 | Acc: 43.483,63.396,67.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.748 | Acc: 43.097,63.371,67.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 2.766 | Acc: 50.781,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.753 | Acc: 49.405,79.501,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.766 | Acc: 49.905,79.325,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.779 | Acc: 49.872,79.226,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.804 | Acc: 49.875,78.762,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.829 | Acc: 49.621,78.558,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.812 | Acc: 49.780,78.771,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.803 | Acc: 49.734,78.829,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.805 | Acc: 49.617,78.921,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.799 | Acc: 49.858,78.975,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.811 | Acc: 49.833,78.759,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 49.852,78.744,92.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.816 | Acc: 49.689,78.699,92.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.831 | Acc: 49.476,78.655,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.834 | Acc: 49.491,78.556,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 49.559,78.387,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.838 | Acc: 49.611,78.278,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.837 | Acc: 49.643,78.299,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.833 | Acc: 49.749,78.294,91.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.835 | Acc: 49.705,78.246,91.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.645 | Acc: 49.219,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.661 | Acc: 44.308,63.951,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.699 | Acc: 44.322,63.091,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.728 | Acc: 43.801,63.294,66.534,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 2.491 | Acc: 52.344,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.820 | Acc: 51.153,79.650,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.775 | Acc: 50.553,79.668,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.812 | Acc: 50.064,79.495,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.790 | Acc: 50.357,79.379,91.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.792 | Acc: 50.340,79.169,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.811 | Acc: 50.045,78.868,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.820 | Acc: 49.828,78.912,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.826 | Acc: 49.699,78.683,91.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 49.715,78.600,91.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.821 | Acc: 49.829,78.549,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 49.915,78.532,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.825 | Acc: 49.890,78.559,91.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.824 | Acc: 49.892,78.544,91.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.826 | Acc: 49.833,78.536,91.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.825 | Acc: 49.818,78.494,91.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.824 | Acc: 49.813,78.485,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.827 | Acc: 49.810,78.512,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.823 | Acc: 49.890,78.551,91.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.831 | Acc: 49.742,78.500,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.808 | Acc: 46.094,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.672 | Acc: 44.234,64.509,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.685 | Acc: 43.693,63.796,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.701 | Acc: 43.673,63.870,67.802,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.368 | Acc: 53.906,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.784 | Acc: 49.851,79.129,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.781 | Acc: 49.714,79.040,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.771 | Acc: 49.821,78.791,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.792 | Acc: 49.489,78.694,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.783 | Acc: 49.660,78.929,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.784 | Acc: 49.626,78.951,92.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 49.479,78.807,92.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.806 | Acc: 49.578,78.780,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.802 | Acc: 49.689,78.824,92.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.805 | Acc: 49.790,78.805,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 49.855,78.797,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.815 | Acc: 49.763,78.709,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.814 | Acc: 49.820,78.631,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.821 | Acc: 49.753,78.528,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.819 | Acc: 49.855,78.491,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 49.832,78.463,91.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 49.817,78.372,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.826 | Acc: 49.799,78.339,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.831 | Acc: 49.813,78.314,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.802 | Acc: 43.750,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.710 | Acc: 43.452,64.137,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.743 | Acc: 43.788,63.224,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.755 | Acc: 43.532,63.512,67.482,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.722 | Acc: 48.438,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.747 | Acc: 49.926,79.427,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.762 | Acc: 49.543,79.726,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.777 | Acc: 49.782,79.547,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.780 | Acc: 49.672,79.456,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.792 | Acc: 49.729,79.053,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.788 | Acc: 49.722,78.932,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.802 | Acc: 49.551,78.790,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.802 | Acc: 49.476,78.814,92.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 49.504,78.716,92.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 49.483,78.724,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.812 | Acc: 49.427,78.638,91.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.819 | Acc: 49.465,78.569,91.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 49.503,78.508,91.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.822 | Acc: 49.572,78.500,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 49.533,78.468,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.828 | Acc: 49.523,78.441,91.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.826 | Acc: 49.553,78.402,91.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.826 | Acc: 49.565,78.467,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.829 | Acc: 49.565,78.455,91.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.544 | Acc: 47.656,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.677 | Acc: 44.345,63.951,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.683 | Acc: 44.188,63.643,67.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.696 | Acc: 44.198,63.883,67.444,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 2.903 | Acc: 49.219,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.707 | Acc: 51.153,79.055,93.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.705 | Acc: 50.514,79.421,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.735 | Acc: 50.371,79.086,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.727 | Acc: 50.627,79.147,92.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.740 | Acc: 50.317,79.100,92.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.757 | Acc: 50.052,79.035,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.767 | Acc: 49.928,79.017,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.782 | Acc: 49.777,78.935,92.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.799 | Acc: 49.637,78.725,92.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.801 | Acc: 49.639,78.712,92.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.806 | Acc: 49.579,78.662,92.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 49.731,78.589,92.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 49.629,78.613,92.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.813 | Acc: 49.589,78.559,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.817 | Acc: 49.598,78.496,92.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.815 | Acc: 49.611,78.500,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.818 | Acc: 49.578,78.480,92.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.817 | Acc: 49.630,78.530,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.817 | Acc: 49.682,78.549,92.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.008 | Acc: 46.875,67.969,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.663 | Acc: 44.159,64.174,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.688 | Acc: 43.960,63.777,68.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.711 | Acc: 44.249,63.781,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 2.830 | Acc: 53.906,75.781,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 50.856,78.795,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 50.915,78.811,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.778 | Acc: 50.499,78.612,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.743 | Acc: 50.694,79.147,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 50.565,79.038,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.757 | Acc: 50.801,79.145,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.771 | Acc: 50.443,79.028,92.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.775 | Acc: 50.301,78.984,92.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.776 | Acc: 50.345,78.911,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.785 | Acc: 50.377,78.840,92.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.788 | Acc: 50.272,78.832,92.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 50.318,78.744,92.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.800 | Acc: 50.219,78.601,92.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.805 | Acc: 50.133,78.567,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.811 | Acc: 50.067,78.478,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.815 | Acc: 50.044,78.356,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.819 | Acc: 50.016,78.411,91.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.822 | Acc: 50.000,78.398,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.825 | Acc: 50.016,78.447,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.735 | Acc: 48.438,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.622 | Acc: 44.940,64.249,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 45.217,63.872,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.631 | Acc: 44.813,64.075,68.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 2.576 | Acc: 55.469,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.750 | Acc: 50.967,79.948,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 50.629,79.973,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.788 | Acc: 50.461,79.444,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.776 | Acc: 50.482,79.215,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.778 | Acc: 50.487,79.177,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.792 | Acc: 50.303,78.887,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 50.089,78.751,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.797 | Acc: 50.102,78.785,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.780 | Acc: 50.388,78.980,92.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 50.241,78.794,92.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 50.255,78.729,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.796 | Acc: 50.136,78.647,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.803 | Acc: 50.096,78.586,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.805 | Acc: 50.103,78.684,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 50.096,78.776,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.803 | Acc: 50.085,78.750,92.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.805 | Acc: 50.110,78.716,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.810 | Acc: 49.942,78.623,91.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.816 | Acc: 49.844,78.502,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.862 | Acc: 46.094,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.854 | Acc: 41.629,62.835,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.885 | Acc: 42.550,61.871,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.907 | Acc: 42.546,62.154,67.021,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.409 | Acc: 57.031,85.156,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.770 | Acc: 50.186,79.985,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.792 | Acc: 50.362,79.383,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.752 | Acc: 51.767,79.367,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.766 | Acc: 51.562,79.196,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.777 | Acc: 50.866,78.844,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.785 | Acc: 50.749,78.855,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 50.504,78.762,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.784 | Acc: 50.510,78.746,92.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.798 | Acc: 50.224,78.665,92.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.813 | Acc: 49.992,78.603,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 49.989,78.669,91.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.810 | Acc: 50.036,78.696,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 49.973,78.670,91.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.814 | Acc: 50.014,78.595,91.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 49.964,78.473,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.822 | Acc: 49.973,78.424,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.819 | Acc: 49.950,78.464,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.821 | Acc: 49.907,78.497,91.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.825 | Acc: 49.795,78.441,91.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.785 | Acc: 49.219,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.789 | Acc: 43.676,63.356,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.779 | Acc: 43.769,62.538,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.787 | Acc: 43.584,62.513,67.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.988 | Acc: 49.219,76.562,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.811 | Acc: 49.070,78.125,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.799 | Acc: 49.352,78.754,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.790 | Acc: 49.821,79.009,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.819 | Acc: 49.421,78.655,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.822 | Acc: 49.397,78.697,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.813 | Acc: 49.580,78.880,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.816 | Acc: 49.623,78.651,91.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.819 | Acc: 49.709,78.756,91.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.809 | Acc: 49.909,78.911,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.817 | Acc: 49.782,78.836,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.827 | Acc: 49.664,78.581,91.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.816 | Acc: 49.724,78.663,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 49.617,78.742,91.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 49.605,78.642,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.814 | Acc: 49.603,78.634,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.810 | Acc: 49.744,78.663,91.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.809 | Acc: 49.842,78.677,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.814 | Acc: 49.771,78.571,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.815 | Acc: 49.754,78.638,91.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.666 | Acc: 50.781,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.638 | Acc: 45.089,63.430,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.657 | Acc: 45.065,63.224,67.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 44.647,63.486,67.585,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.835 | Acc: 49.219,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.743 | Acc: 47.954,79.464,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.757 | Acc: 49.123,79.440,92.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.740 | Acc: 49.769,79.854,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 49.730,79.485,92.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.760 | Acc: 49.776,79.347,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.756 | Acc: 50.084,79.210,92.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.754 | Acc: 49.994,79.316,92.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.753 | Acc: 50.000,79.328,92.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.765 | Acc: 49.953,79.178,92.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.772 | Acc: 49.957,79.069,92.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.783 | Acc: 49.767,78.980,92.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.788 | Acc: 49.786,78.909,92.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.792 | Acc: 49.731,78.873,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.797 | Acc: 49.680,78.803,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.798 | Acc: 49.714,78.847,92.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.797 | Acc: 49.822,78.833,92.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.799 | Acc: 49.812,78.769,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.804 | Acc: 49.762,78.668,92.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.810 | Acc: 49.795,78.609,92.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.762 | Acc: 45.312,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.882 | Acc: 41.518,62.388,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.886 | Acc: 42.607,62.157,66.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.921 | Acc: 42.520,62.282,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 2.703 | Acc: 50.000,85.156,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.685 | Acc: 51.860,81.064,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.765 | Acc: 50.305,79.649,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.794 | Acc: 49.885,79.086,92.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.792 | Acc: 50.183,78.897,92.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.788 | Acc: 50.054,78.821,92.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.792 | Acc: 49.910,78.771,92.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 50.211,78.801,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.796 | Acc: 50.345,78.698,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 50.142,78.729,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.796 | Acc: 50.019,78.751,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.791 | Acc: 50.124,78.818,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.799 | Acc: 50.084,78.767,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.798 | Acc: 50.072,78.876,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.797 | Acc: 50.114,78.781,92.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.795 | Acc: 50.034,78.818,92.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.799 | Acc: 49.949,78.721,92.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.803 | Acc: 49.938,78.705,92.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.805 | Acc: 49.887,78.696,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.807 | Acc: 49.861,78.730,92.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.574 | Acc: 50.781,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.657 | Acc: 44.420,64.137,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.693 | Acc: 44.627,63.643,67.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.726 | Acc: 44.249,63.768,67.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.487 | Acc: 55.469,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.744 | Acc: 50.335,79.725,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.762 | Acc: 49.924,79.249,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.752 | Acc: 50.102,79.431,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.748 | Acc: 50.579,79.466,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.746 | Acc: 50.603,79.339,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.747 | Acc: 50.671,79.300,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.755 | Acc: 50.482,79.311,91.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.757 | Acc: 50.539,79.256,92.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.771 | Acc: 50.324,79.075,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.774 | Acc: 50.272,79.073,91.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.788 | Acc: 50.110,78.988,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.783 | Acc: 50.188,79.114,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.789 | Acc: 50.168,79.023,91.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.794 | Acc: 50.217,78.945,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.799 | Acc: 50.117,78.906,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.804 | Acc: 50.075,78.838,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.808 | Acc: 50.009,78.792,91.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.811 | Acc: 49.989,78.748,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.814 | Acc: 49.951,78.660,91.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.909 | Acc: 49.219,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.729 | Acc: 44.234,63.504,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.738 | Acc: 43.750,63.034,67.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.779 | Acc: 43.443,63.179,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.616 | Acc: 50.000,72.656,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.679 | Acc: 50.521,79.464,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 49.619,79.402,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.735 | Acc: 49.308,79.713,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.704 | Acc: 49.865,80.035,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.704 | Acc: 49.915,79.827,93.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.714 | Acc: 49.839,79.849,93.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.711 | Acc: 50.066,79.682,93.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.703 | Acc: 50.228,79.974,93.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.705 | Acc: 50.190,80.003,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.698 | Acc: 50.354,80.006,93.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.690 | Acc: 50.488,80.009,93.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.690 | Acc: 50.496,80.083,93.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.682 | Acc: 50.569,80.101,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.683 | Acc: 50.459,80.160,93.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.675 | Acc: 50.602,80.225,93.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.675 | Acc: 50.660,80.216,93.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.676 | Acc: 50.559,80.253,93.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.677 | Acc: 50.604,80.272,93.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.678 | Acc: 50.656,80.227,93.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.487 | Acc: 49.219,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.435 | Acc: 45.871,64.993,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.455 | Acc: 45.979,64.634,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.475 | Acc: 45.812,64.946,69.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.544 | Acc: 43.750,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.595 | Acc: 51.749,81.250,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.587 | Acc: 51.886,81.860,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.596 | Acc: 52.036,81.481,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.596 | Acc: 51.669,81.578,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.613 | Acc: 51.694,81.281,94.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.614 | Acc: 51.330,81.231,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.628 | Acc: 50.997,81.111,94.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.631 | Acc: 50.961,81.036,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.638 | Acc: 51.019,80.857,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.641 | Acc: 50.882,80.842,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.635 | Acc: 50.771,80.964,94.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.636 | Acc: 50.742,80.900,94.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.637 | Acc: 50.808,80.873,94.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.630 | Acc: 50.909,80.969,94.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.634 | Acc: 50.854,80.853,94.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.631 | Acc: 50.983,80.853,94.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.628 | Acc: 51.015,80.916,94.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.631 | Acc: 50.937,80.837,94.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.629 | Acc: 50.956,80.819,94.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.536 | Acc: 50.000,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.432 | Acc: 46.205,65.216,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.453 | Acc: 46.075,64.672,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.477 | Acc: 45.940,64.972,69.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.448 | Acc: 53.125,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.606 | Acc: 50.967,80.841,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.596 | Acc: 51.562,81.098,94.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.592 | Acc: 51.409,81.045,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.587 | Acc: 51.157,81.279,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.580 | Acc: 51.191,81.498,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.590 | Acc: 51.162,81.386,94.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.591 | Acc: 50.931,81.455,94.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.591 | Acc: 51.169,81.425,94.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.600 | Acc: 51.114,81.401,94.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.604 | Acc: 51.069,81.336,94.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.609 | Acc: 51.018,81.388,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.612 | Acc: 51.028,81.282,94.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.614 | Acc: 50.964,81.232,94.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.618 | Acc: 50.879,81.189,94.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.618 | Acc: 50.911,81.183,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.616 | Acc: 50.879,81.172,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.614 | Acc: 50.864,81.209,94.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.613 | Acc: 50.872,81.233,94.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.615 | Acc: 50.849,81.219,94.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.517 | Acc: 49.219,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.451 | Acc: 46.205,64.881,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.472 | Acc: 46.037,64.482,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.494 | Acc: 45.966,64.844,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.050 | Acc: 60.156,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.462 | Acc: 54.204,83.296,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.495 | Acc: 53.430,82.470,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.535 | Acc: 52.754,82.134,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.554 | Acc: 52.296,81.780,95.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.555 | Acc: 52.135,81.768,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.565 | Acc: 51.969,81.708,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.570 | Acc: 51.662,81.632,95.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.578 | Acc: 51.524,81.522,95.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.580 | Acc: 51.308,81.440,95.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.577 | Acc: 51.380,81.522,95.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.581 | Acc: 51.170,81.547,95.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.583 | Acc: 51.115,81.509,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.593 | Acc: 51.072,81.421,95.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.595 | Acc: 51.084,81.406,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.598 | Acc: 51.106,81.315,95.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.607 | Acc: 50.942,81.228,95.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.613 | Acc: 50.882,81.119,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.614 | Acc: 50.855,81.105,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.611 | Acc: 50.904,81.129,95.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.576 | Acc: 50.000,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.443 | Acc: 46.280,65.327,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.460 | Acc: 46.113,64.787,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.482 | Acc: 46.068,65.061,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 2.843 | Acc: 53.906,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.543 | Acc: 52.121,82.552,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.565 | Acc: 51.791,82.412,95.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.598 | Acc: 51.498,81.545,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.575 | Acc: 51.736,81.838,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.583 | Acc: 51.361,81.660,95.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.588 | Acc: 51.362,81.573,95.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.590 | Acc: 51.308,81.516,95.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.592 | Acc: 51.169,81.434,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.591 | Acc: 51.161,81.285,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.586 | Acc: 51.384,81.153,95.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.586 | Acc: 51.453,81.172,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.591 | Acc: 51.417,81.205,95.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.603 | Acc: 51.215,81.109,95.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.604 | Acc: 51.168,81.086,95.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.601 | Acc: 51.197,81.118,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.599 | Acc: 51.246,81.170,95.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.600 | Acc: 51.210,81.165,95.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.598 | Acc: 51.216,81.196,95.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.597 | Acc: 51.265,81.195,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.468 | Acc: 50.781,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.453 | Acc: 45.722,65.141,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 45.865,64.596,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.489 | Acc: 45.889,64.831,69.493,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.555 | Acc: 47.656,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.536 | Acc: 52.753,81.510,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.585 | Acc: 51.429,81.460,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.591 | Acc: 51.153,81.365,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.594 | Acc: 50.772,81.327,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.594 | Acc: 50.696,81.412,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.586 | Acc: 50.962,81.431,95.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.599 | Acc: 50.920,81.272,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.597 | Acc: 50.772,81.299,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.598 | Acc: 50.643,81.250,95.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.595 | Acc: 50.770,81.320,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.593 | Acc: 50.855,81.303,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.594 | Acc: 50.846,81.302,95.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.602 | Acc: 50.736,81.238,95.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.599 | Acc: 50.759,81.311,95.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.599 | Acc: 50.818,81.271,95.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.599 | Acc: 50.915,81.269,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.600 | Acc: 50.882,81.236,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.599 | Acc: 50.885,81.302,95.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.600 | Acc: 50.869,81.307,95.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.522 | Acc: 50.000,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.473 | Acc: 46.131,64.918,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.486 | Acc: 46.132,64.501,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.503 | Acc: 46.081,64.933,69.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.439 | Acc: 55.469,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.620 | Acc: 50.521,80.729,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.601 | Acc: 50.762,81.002,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.597 | Acc: 50.909,81.096,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.587 | Acc: 51.138,81.308,95.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.589 | Acc: 51.145,81.374,95.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.584 | Acc: 51.272,81.424,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.587 | Acc: 51.324,81.394,95.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.580 | Acc: 51.349,81.517,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.576 | Acc: 51.424,81.604,95.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.571 | Acc: 51.508,81.619,95.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.573 | Acc: 51.439,81.589,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.580 | Acc: 51.394,81.477,95.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.584 | Acc: 51.368,81.546,95.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.590 | Acc: 51.254,81.375,95.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.589 | Acc: 51.238,81.445,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.587 | Acc: 51.219,81.445,95.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.589 | Acc: 51.306,81.413,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.591 | Acc: 51.229,81.417,95.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.591 | Acc: 51.241,81.408,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.499 | Acc: 50.781,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.450 | Acc: 46.466,64.955,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 46.284,64.672,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.495 | Acc: 46.260,64.754,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.694 | Acc: 50.000,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.645 | Acc: 50.223,80.469,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.625 | Acc: 50.686,80.907,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.618 | Acc: 50.615,81.250,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.615 | Acc: 50.926,81.327,94.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.608 | Acc: 51.106,81.250,94.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.604 | Acc: 51.162,81.360,94.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.609 | Acc: 51.092,81.278,94.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.605 | Acc: 51.237,81.163,94.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.602 | Acc: 51.265,81.133,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.596 | Acc: 51.349,81.227,95.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.597 | Acc: 51.393,81.109,94.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.599 | Acc: 51.196,81.033,95.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.600 | Acc: 51.131,81.037,95.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.602 | Acc: 51.132,81.003,95.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.595 | Acc: 51.228,81.089,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.595 | Acc: 51.151,81.136,95.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.590 | Acc: 51.237,81.188,95.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.587 | Acc: 51.255,81.285,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.585 | Acc: 51.296,81.309,95.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.514 | Acc: 51.562,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.448 | Acc: 46.615,64.769,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.471 | Acc: 46.513,64.329,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.498 | Acc: 46.440,64.664,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.354 | Acc: 50.000,88.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.516 | Acc: 50.781,82.552,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.545 | Acc: 51.105,82.050,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.543 | Acc: 51.447,82.249,95.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.553 | Acc: 51.350,81.896,95.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.558 | Acc: 51.168,81.915,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.564 | Acc: 51.227,81.792,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.576 | Acc: 51.169,81.610,95.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.575 | Acc: 51.218,81.614,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.582 | Acc: 51.027,81.479,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.574 | Acc: 51.135,81.580,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.577 | Acc: 51.163,81.671,95.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.584 | Acc: 51.138,81.571,95.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.585 | Acc: 51.149,81.585,95.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.581 | Acc: 51.182,81.698,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.580 | Acc: 51.186,81.717,95.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.582 | Acc: 51.173,81.693,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.582 | Acc: 51.100,81.669,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.587 | Acc: 51.043,81.616,95.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.586 | Acc: 51.113,81.588,95.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.513 | Acc: 50.781,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.460 | Acc: 46.354,64.844,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.478 | Acc: 46.265,64.348,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.501 | Acc: 46.132,64.562,69.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.589 | Acc: 57.812,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.659 | Acc: 50.670,80.320,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.607 | Acc: 50.991,81.193,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.572 | Acc: 51.268,81.724,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.586 | Acc: 51.051,81.385,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.571 | Acc: 51.261,81.366,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.570 | Acc: 51.201,81.437,95.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.582 | Acc: 51.114,81.361,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.587 | Acc: 51.189,81.376,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.580 | Acc: 51.342,81.358,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.585 | Acc: 51.275,81.324,95.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.584 | Acc: 51.280,81.360,95.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.588 | Acc: 51.251,81.286,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.588 | Acc: 51.338,81.262,95.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.585 | Acc: 51.343,81.294,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.585 | Acc: 51.360,81.276,95.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.586 | Acc: 51.360,81.269,95.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.587 | Acc: 51.338,81.273,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.587 | Acc: 51.346,81.239,95.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.586 | Acc: 51.359,81.283,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.560 | Acc: 51.562,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.479 | Acc: 45.945,64.769,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.499 | Acc: 45.998,64.253,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.523 | Acc: 45.914,64.549,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.374 | Acc: 51.562,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.446 | Acc: 51.972,83.482,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.519 | Acc: 51.010,82.412,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.561 | Acc: 50.410,81.737,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.551 | Acc: 50.897,81.780,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.562 | Acc: 51.021,81.714,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.579 | Acc: 50.826,81.431,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.573 | Acc: 51.047,81.477,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.577 | Acc: 51.038,81.502,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.581 | Acc: 50.993,81.608,95.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.580 | Acc: 51.108,81.666,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.578 | Acc: 51.106,81.660,95.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.579 | Acc: 51.067,81.629,95.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.579 | Acc: 51.078,81.561,95.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.579 | Acc: 51.079,81.472,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.578 | Acc: 51.051,81.437,95.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.579 | Acc: 51.088,81.450,95.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.577 | Acc: 51.134,81.420,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.578 | Acc: 51.119,81.406,95.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.577 | Acc: 51.138,81.385,95.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.529 | Acc: 50.781,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.461 | Acc: 46.205,65.104,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.475 | Acc: 46.227,64.710,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.495 | Acc: 46.081,64.767,69.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.955 | Acc: 50.781,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.589 | Acc: 50.893,80.804,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.549 | Acc: 51.715,81.383,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.572 | Acc: 51.268,81.852,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.577 | Acc: 51.514,81.983,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.588 | Acc: 51.114,81.583,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.597 | Acc: 51.027,81.308,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.591 | Acc: 51.103,81.283,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.586 | Acc: 51.135,81.342,95.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.588 | Acc: 51.045,81.410,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.590 | Acc: 50.898,81.363,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.588 | Acc: 50.845,81.420,95.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.586 | Acc: 50.862,81.435,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.587 | Acc: 50.925,81.436,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.583 | Acc: 50.937,81.442,95.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.585 | Acc: 50.963,81.414,95.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.583 | Acc: 50.988,81.415,95.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.579 | Acc: 51.056,81.424,95.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.581 | Acc: 51.056,81.369,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.581 | Acc: 51.064,81.443,95.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.490 | Acc: 52.344,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.457 | Acc: 46.503,64.955,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.473 | Acc: 46.303,64.310,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.493 | Acc: 46.107,64.664,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.770 | Acc: 48.438,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.590 | Acc: 51.711,80.915,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.576 | Acc: 51.010,81.136,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.590 | Acc: 50.653,81.045,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.581 | Acc: 51.119,81.125,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.555 | Acc: 51.145,81.637,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.553 | Acc: 51.020,81.650,95.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.565 | Acc: 50.986,81.483,95.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.570 | Acc: 51.179,81.488,95.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.573 | Acc: 51.213,81.332,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.575 | Acc: 51.325,81.215,95.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.574 | Acc: 51.319,81.261,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.574 | Acc: 51.287,81.338,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.575 | Acc: 51.395,81.331,95.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.574 | Acc: 51.398,81.325,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.573 | Acc: 51.376,81.408,95.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.574 | Acc: 51.353,81.355,95.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.574 | Acc: 51.370,81.353,95.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.574 | Acc: 51.409,81.410,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.576 | Acc: 51.357,81.385,95.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.502 | Acc: 50.000,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.438 | Acc: 45.647,65.774,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 45.865,65.072,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.498 | Acc: 45.812,65.202,69.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.705 | Acc: 50.000,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.540 | Acc: 51.079,82.366,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.552 | Acc: 50.857,81.631,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.569 | Acc: 50.256,81.775,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.555 | Acc: 50.810,81.916,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.574 | Acc: 50.611,81.706,95.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.558 | Acc: 50.923,81.889,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.563 | Acc: 50.986,81.848,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.557 | Acc: 51.102,82.002,95.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.554 | Acc: 51.165,81.962,95.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.565 | Acc: 51.030,81.872,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.559 | Acc: 51.160,81.893,95.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.556 | Acc: 51.297,81.911,95.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.556 | Acc: 51.326,81.947,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.558 | Acc: 51.279,81.912,95.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.558 | Acc: 51.287,81.901,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.568 | Acc: 51.185,81.720,95.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.569 | Acc: 51.162,81.720,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.570 | Acc: 51.175,81.713,95.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.569 | Acc: 51.257,81.677,95.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.569 | Acc: 49.219,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.471 | Acc: 45.573,64.658,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.494 | Acc: 45.922,64.539,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.518 | Acc: 45.825,64.780,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.565 | Acc: 47.656,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.609 | Acc: 50.260,81.250,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.574 | Acc: 51.086,81.479,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.556 | Acc: 51.063,81.545,95.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.563 | Acc: 50.887,81.491,95.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.563 | Acc: 50.859,81.629,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.543 | Acc: 51.330,81.792,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.560 | Acc: 51.125,81.782,95.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.562 | Acc: 50.966,81.779,95.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.566 | Acc: 50.911,81.656,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.562 | Acc: 51.034,81.627,95.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.564 | Acc: 51.022,81.579,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.565 | Acc: 50.976,81.545,95.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.572 | Acc: 50.865,81.534,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.565 | Acc: 51.051,81.584,95.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.561 | Acc: 51.160,81.600,95.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.564 | Acc: 51.115,81.608,95.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.563 | Acc: 51.123,81.662,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.567 | Acc: 51.089,81.575,95.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.567 | Acc: 51.087,81.531,95.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.507 | Acc: 51.562,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.462 | Acc: 45.945,65.290,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.486 | Acc: 46.094,64.825,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.507 | Acc: 46.094,65.049,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.866 | Acc: 46.094,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.599 | Acc: 51.153,81.101,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.586 | Acc: 50.934,81.040,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.557 | Acc: 51.409,81.404,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.550 | Acc: 51.582,81.674,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.554 | Acc: 51.648,81.822,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.568 | Acc: 51.369,81.399,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.577 | Acc: 51.180,81.217,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.583 | Acc: 51.087,81.274,95.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.577 | Acc: 51.334,81.379,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.576 | Acc: 51.244,81.510,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.569 | Acc: 51.333,81.600,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.571 | Acc: 51.336,81.639,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.571 | Acc: 51.293,81.624,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.570 | Acc: 51.376,81.650,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.567 | Acc: 51.329,81.655,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.567 | Acc: 51.385,81.620,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.570 | Acc: 51.379,81.596,95.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.570 | Acc: 51.303,81.635,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.567 | Acc: 51.337,81.654,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.562 | Acc: 50.000,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.471 | Acc: 45.871,64.769,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.496 | Acc: 45.998,64.310,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.523 | Acc: 45.940,64.703,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.803 | Acc: 50.781,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.602 | Acc: 49.814,81.548,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.573 | Acc: 50.457,81.764,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.588 | Acc: 50.218,81.647,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.573 | Acc: 50.309,81.732,95.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.572 | Acc: 50.217,81.892,95.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.573 | Acc: 50.600,81.773,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.569 | Acc: 50.737,81.859,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.563 | Acc: 50.844,81.857,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.562 | Acc: 50.980,81.902,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.553 | Acc: 51.197,81.911,95.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.547 | Acc: 51.347,81.893,95.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.547 | Acc: 51.358,81.885,95.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.556 | Acc: 51.272,81.789,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.557 | Acc: 51.209,81.784,95.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.557 | Acc: 51.147,81.873,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.563 | Acc: 51.098,81.795,95.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.565 | Acc: 51.127,81.749,95.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.565 | Acc: 51.076,81.717,95.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.566 | Acc: 51.046,81.720,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.570 | Acc: 49.219,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.491 | Acc: 46.168,64.993,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.511 | Acc: 46.132,64.367,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.530 | Acc: 46.081,64.460,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 2.404 | Acc: 53.125,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.596 | Acc: 49.851,81.659,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.596 | Acc: 50.514,81.402,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.579 | Acc: 50.909,81.647,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.569 | Acc: 51.157,81.607,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.564 | Acc: 51.423,81.536,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.570 | Acc: 51.511,81.579,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.561 | Acc: 51.668,81.538,95.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.574 | Acc: 51.485,81.493,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.576 | Acc: 51.446,81.401,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.576 | Acc: 51.345,81.332,95.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.576 | Acc: 51.372,81.314,95.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.580 | Acc: 51.206,81.263,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.577 | Acc: 51.248,81.265,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.577 | Acc: 51.237,81.314,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.574 | Acc: 51.171,81.395,95.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.575 | Acc: 51.158,81.355,95.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.573 | Acc: 51.152,81.397,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.572 | Acc: 51.153,81.382,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.572 | Acc: 51.163,81.375,95.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.546 | Acc: 50.000,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.466 | Acc: 46.094,64.993,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.496 | Acc: 46.037,64.615,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.517 | Acc: 46.017,64.716,69.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.771 | Acc: 49.219,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.563 | Acc: 52.567,81.920,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.564 | Acc: 51.696,81.383,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.547 | Acc: 52.036,81.749,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.542 | Acc: 51.948,81.848,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.555 | Acc: 51.408,81.745,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.559 | Acc: 51.395,81.702,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.560 | Acc: 51.341,81.710,95.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.556 | Acc: 51.266,81.755,95.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.550 | Acc: 51.273,81.811,95.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.555 | Acc: 51.259,81.798,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.555 | Acc: 51.403,81.752,95.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.565 | Acc: 51.407,81.645,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.567 | Acc: 51.362,81.591,95.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.564 | Acc: 51.362,81.634,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.564 | Acc: 51.347,81.637,95.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.567 | Acc: 51.280,81.639,95.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.568 | Acc: 51.251,81.584,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.563 | Acc: 51.309,81.670,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.567 | Acc: 51.230,81.611,95.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.552 | Acc: 50.000,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.462 | Acc: 46.429,64.732,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.485 | Acc: 46.361,64.444,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.513 | Acc: 46.183,64.728,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.092 | Acc: 60.938,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.452 | Acc: 52.939,82.552,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.517 | Acc: 51.029,81.593,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.534 | Acc: 51.409,81.698,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 51.804,81.819,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.562 | Acc: 51.446,81.451,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.566 | Acc: 51.349,81.379,95.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.579 | Acc: 51.141,81.184,95.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.570 | Acc: 51.169,81.366,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.580 | Acc: 51.053,81.302,95.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.578 | Acc: 51.259,81.367,95.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.577 | Acc: 51.234,81.257,95.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.583 | Acc: 51.271,81.208,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.580 | Acc: 51.332,81.301,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.580 | Acc: 51.290,81.317,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.578 | Acc: 51.321,81.375,95.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.578 | Acc: 51.227,81.398,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.574 | Acc: 51.272,81.440,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.575 | Acc: 51.227,81.371,95.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.572 | Acc: 51.273,81.439,95.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.523 | Acc: 50.781,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.472 | Acc: 46.205,65.179,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.496 | Acc: 46.246,64.539,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.522 | Acc: 45.927,64.728,69.429,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.270 | Acc: 60.938,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.589 | Acc: 51.786,81.659,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.588 | Acc: 51.524,81.612,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.573 | Acc: 51.447,81.698,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.562 | Acc: 51.553,81.645,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.552 | Acc: 51.702,81.807,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.550 | Acc: 51.685,81.876,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.549 | Acc: 51.751,81.837,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.557 | Acc: 51.606,81.755,95.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.560 | Acc: 51.537,81.729,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.567 | Acc: 51.224,81.685,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.561 | Acc: 51.322,81.773,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.556 | Acc: 51.290,81.830,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.554 | Acc: 51.326,81.774,95.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.557 | Acc: 51.298,81.734,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.555 | Acc: 51.324,81.767,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.554 | Acc: 51.302,81.771,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.553 | Acc: 51.290,81.740,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.556 | Acc: 51.158,81.687,95.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.559 | Acc: 51.177,81.693,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.535 | Acc: 50.000,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.487 | Acc: 46.391,64.621,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.510 | Acc: 46.361,64.348,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 46.158,64.536,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.386 | Acc: 55.469,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.528 | Acc: 52.381,81.696,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.544 | Acc: 52.096,81.136,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.549 | Acc: 51.767,81.481,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.562 | Acc: 51.514,81.665,95.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.573 | Acc: 51.284,81.683,95.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.568 | Acc: 51.259,81.754,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.572 | Acc: 51.003,81.810,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.569 | Acc: 51.102,81.891,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.568 | Acc: 51.114,81.798,95.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.565 | Acc: 51.143,81.782,95.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.564 | Acc: 51.287,81.759,95.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.567 | Acc: 51.277,81.636,95.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.573 | Acc: 51.176,81.579,95.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.575 | Acc: 51.168,81.586,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.582 | Acc: 51.043,81.619,95.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.578 | Acc: 51.127,81.676,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.576 | Acc: 51.178,81.660,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.577 | Acc: 51.162,81.594,95.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.575 | Acc: 51.198,81.648,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.467 | Acc: 50.781,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.471 | Acc: 45.685,65.290,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.500 | Acc: 45.922,64.691,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.518 | Acc: 46.055,64.780,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 2.445 | Acc: 50.781,79.688,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.565 | Acc: 51.823,81.324,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.554 | Acc: 51.524,81.784,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.554 | Acc: 51.204,81.737,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.563 | Acc: 51.119,81.520,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.561 | Acc: 51.284,81.691,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.561 | Acc: 51.343,81.592,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.562 | Acc: 51.380,81.566,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.557 | Acc: 51.393,81.653,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.566 | Acc: 51.278,81.565,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.571 | Acc: 51.150,81.491,95.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.568 | Acc: 51.308,81.533,95.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.563 | Acc: 51.349,81.506,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.562 | Acc: 51.320,81.597,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.560 | Acc: 51.265,81.656,95.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.555 | Acc: 51.321,81.717,95.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.559 | Acc: 51.258,81.649,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.554 | Acc: 51.301,81.701,95.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.552 | Acc: 51.329,81.748,95.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.552 | Acc: 51.341,81.738,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.537 | Acc: 51.562,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.490 | Acc: 46.466,64.993,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.511 | Acc: 46.418,64.425,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.535 | Acc: 46.209,64.639,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.377 | Acc: 48.438,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.484 | Acc: 50.670,82.738,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.483 | Acc: 52.134,82.870,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.521 | Acc: 51.332,82.211,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.549 | Acc: 51.321,81.848,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.569 | Acc: 50.774,81.559,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.581 | Acc: 50.665,81.373,95.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.576 | Acc: 50.925,81.411,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.570 | Acc: 51.111,81.551,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.565 | Acc: 51.260,81.595,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.561 | Acc: 51.380,81.693,95.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.559 | Acc: 51.357,81.692,95.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.558 | Acc: 51.339,81.662,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.564 | Acc: 51.233,81.537,95.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.569 | Acc: 51.157,81.559,95.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.566 | Acc: 51.186,81.637,95.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.568 | Acc: 51.202,81.637,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.566 | Acc: 51.278,81.667,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.571 | Acc: 51.186,81.590,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.569 | Acc: 51.226,81.621,95.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 50.781,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.467 | Acc: 46.205,65.253,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.494 | Acc: 46.075,64.596,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.520 | Acc: 46.017,64.805,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 2.569 | Acc: 51.562,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.681 | Acc: 47.805,81.064,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.605 | Acc: 48.514,81.898,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.594 | Acc: 49.385,81.762,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.577 | Acc: 50.029,81.916,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.564 | Acc: 50.480,81.977,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.558 | Acc: 50.613,82.096,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.561 | Acc: 50.726,82.070,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.564 | Acc: 50.893,81.983,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.567 | Acc: 50.889,81.837,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.566 | Acc: 50.867,81.876,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.565 | Acc: 51.082,81.851,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.556 | Acc: 51.336,81.966,95.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.550 | Acc: 51.368,82.127,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.551 | Acc: 51.393,82.059,95.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.555 | Acc: 51.300,82.047,95.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.554 | Acc: 51.360,81.944,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.556 | Acc: 51.306,81.885,95.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.555 | Acc: 51.320,81.828,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.554 | Acc: 51.333,81.867,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.525 | Acc: 50.000,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.474 | Acc: 46.429,65.290,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.495 | Acc: 46.399,64.768,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.520 | Acc: 46.222,64.844,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.471 | Acc: 58.594,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.511 | Acc: 50.967,82.850,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.490 | Acc: 51.810,82.508,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.499 | Acc: 51.703,82.582,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.517 | Acc: 51.514,82.350,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.537 | Acc: 51.423,82.124,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.537 | Acc: 51.498,82.141,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.539 | Acc: 51.391,82.186,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.538 | Acc: 51.441,82.153,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.534 | Acc: 51.532,82.152,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.535 | Acc: 51.504,82.082,95.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.547 | Acc: 51.347,81.890,95.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.542 | Acc: 51.562,81.960,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.541 | Acc: 51.560,81.965,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.545 | Acc: 51.415,81.934,95.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.545 | Acc: 51.331,81.927,95.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.551 | Acc: 51.183,81.863,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.550 | Acc: 51.272,81.871,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.547 | Acc: 51.394,81.875,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.549 | Acc: 51.351,81.857,95.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 52.344,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 46.280,64.955,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 46.399,64.367,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.558 | Acc: 46.311,64.690,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.970 | Acc: 43.750,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.514 | Acc: 51.488,81.808,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.548 | Acc: 51.524,81.669,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.528 | Acc: 52.139,81.685,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.528 | Acc: 51.649,81.829,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.518 | Acc: 51.562,82.085,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.525 | Acc: 51.459,82.076,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.535 | Acc: 51.463,81.727,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.531 | Acc: 51.543,81.696,95.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.529 | Acc: 51.567,81.859,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.533 | Acc: 51.547,81.810,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.538 | Acc: 51.545,81.784,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.539 | Acc: 51.559,81.775,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.545 | Acc: 51.500,81.738,95.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.545 | Acc: 51.429,81.712,95.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.546 | Acc: 51.420,81.712,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.541 | Acc: 51.502,81.766,95.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.547 | Acc: 51.363,81.791,95.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.547 | Acc: 51.394,81.819,95.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.552 | Acc: 51.355,81.791,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.502 | Acc: 51.562,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.485 | Acc: 46.540,65.327,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.509 | Acc: 46.094,64.463,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.537 | Acc: 46.017,64.793,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.550 | Acc: 53.906,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.589 | Acc: 51.042,81.324,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.535 | Acc: 51.810,81.974,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.543 | Acc: 51.550,81.826,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.541 | Acc: 51.804,81.703,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.534 | Acc: 51.733,81.699,95.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.536 | Acc: 51.692,81.612,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.548 | Acc: 51.319,81.566,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.553 | Acc: 51.281,81.531,95.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.546 | Acc: 51.325,81.587,95.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.547 | Acc: 51.236,81.545,95.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.541 | Acc: 51.283,81.688,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.539 | Acc: 51.423,81.655,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.541 | Acc: 51.341,81.681,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.540 | Acc: 51.348,81.775,95.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.541 | Acc: 51.360,81.774,95.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.543 | Acc: 51.339,81.778,95.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.546 | Acc: 51.278,81.772,95.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.549 | Acc: 51.251,81.717,95.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.552 | Acc: 51.191,81.691,95.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.501 | Acc: 51.562,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 46.094,64.769,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.513 | Acc: 45.770,64.710,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.540 | Acc: 45.748,64.908,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.595 | Acc: 50.000,89.844,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.557 | Acc: 50.856,81.920,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.562 | Acc: 50.762,81.745,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.563 | Acc: 50.973,81.737,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.555 | Acc: 51.273,81.742,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.541 | Acc: 51.377,81.931,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.531 | Acc: 51.401,82.025,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.518 | Acc: 51.430,82.175,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.528 | Acc: 51.330,81.988,95.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.538 | Acc: 51.260,81.897,95.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.537 | Acc: 51.213,81.884,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 51.248,81.939,95.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.542 | Acc: 51.219,81.940,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.536 | Acc: 51.467,81.947,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.537 | Acc: 51.329,81.970,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.541 | Acc: 51.316,81.925,95.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.541 | Acc: 51.409,81.858,95.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.539 | Acc: 51.436,81.885,95.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.542 | Acc: 51.366,81.882,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.544 | Acc: 51.329,81.839,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.548 | Acc: 50.781,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.491 | Acc: 46.466,65.067,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.512 | Acc: 46.075,64.501,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.542 | Acc: 46.196,64.575,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.933 | Acc: 50.781,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.536 | Acc: 51.339,82.403,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 51.200,81.936,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.557 | Acc: 50.935,81.788,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.555 | Acc: 50.685,81.684,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.546 | Acc: 50.859,81.877,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.539 | Acc: 51.188,81.902,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.550 | Acc: 51.130,81.738,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.551 | Acc: 51.184,81.784,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.549 | Acc: 51.187,81.824,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.554 | Acc: 51.065,81.755,95.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.553 | Acc: 51.082,81.724,95.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.554 | Acc: 51.161,81.730,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.555 | Acc: 51.221,81.624,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.560 | Acc: 51.162,81.517,95.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.561 | Acc: 51.176,81.533,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.560 | Acc: 51.241,81.566,95.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.558 | Acc: 51.292,81.621,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.557 | Acc: 51.294,81.691,95.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.553 | Acc: 51.316,81.705,95.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.573 | Acc: 50.781,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 46.354,64.993,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.520 | Acc: 46.132,64.634,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.548 | Acc: 45.927,64.728,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.511 | Acc: 53.125,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.622 | Acc: 51.116,81.027,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.602 | Acc: 51.010,81.745,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.569 | Acc: 51.255,82.121,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.555 | Acc: 51.292,82.456,95.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.550 | Acc: 51.501,82.403,95.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.544 | Acc: 51.621,82.218,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.545 | Acc: 51.524,82.048,95.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.553 | Acc: 51.262,81.978,95.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.552 | Acc: 51.291,81.962,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.554 | Acc: 51.279,81.965,95.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.548 | Acc: 51.230,82.067,95.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.551 | Acc: 51.170,81.915,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.553 | Acc: 51.116,81.837,95.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.554 | Acc: 51.059,81.781,95.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.556 | Acc: 51.030,81.720,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.554 | Acc: 51.061,81.768,95.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.551 | Acc: 51.198,81.823,95.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.554 | Acc: 51.210,81.743,95.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.554 | Acc: 51.247,81.695,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.469 | Acc: 50.781,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 46.317,64.695,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.508 | Acc: 46.513,64.463,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.532 | Acc: 46.350,64.639,68.801,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.785 | Acc: 46.094,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.533 | Acc: 50.818,82.887,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.539 | Acc: 51.448,82.146,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.539 | Acc: 51.409,81.749,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.547 | Acc: 51.042,81.694,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.544 | Acc: 51.052,81.907,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.541 | Acc: 50.968,81.934,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.535 | Acc: 51.020,82.026,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.538 | Acc: 50.995,82.002,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.538 | Acc: 51.057,82.143,95.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.541 | Acc: 51.014,82.117,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.540 | Acc: 51.032,82.035,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.542 | Acc: 51.047,82.044,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.547 | Acc: 51.048,82.004,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.555 | Acc: 50.926,81.920,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.552 | Acc: 51.067,81.930,95.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.548 | Acc: 51.156,81.980,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 51.157,82.018,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.548 | Acc: 51.149,82.057,95.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.549 | Acc: 51.144,82.023,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.546 | Acc: 52.344,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 46.168,64.732,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.532 | Acc: 46.189,64.367,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 45.914,64.472,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.657 | Acc: 44.531,86.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.543 | Acc: 51.042,82.366,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.586 | Acc: 50.305,81.688,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.565 | Acc: 50.692,82.044,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.565 | Acc: 50.579,81.761,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.546 | Acc: 50.828,82.062,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.567 | Acc: 50.542,81.857,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.559 | Acc: 50.875,82.004,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.550 | Acc: 51.077,82.143,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.548 | Acc: 51.170,82.135,95.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.546 | Acc: 51.259,82.136,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.541 | Acc: 51.312,82.194,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.540 | Acc: 51.297,82.158,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.546 | Acc: 51.395,82.094,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.546 | Acc: 51.404,81.995,95.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.551 | Acc: 51.300,81.896,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.549 | Acc: 51.322,81.890,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.549 | Acc: 51.265,81.855,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.550 | Acc: 51.298,81.869,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.549 | Acc: 51.284,81.830,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.449 | Acc: 50.781,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.490 | Acc: 46.243,64.993,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.515 | Acc: 46.151,64.520,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.533 | Acc: 45.914,64.754,68.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.451 | Acc: 53.906,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.486 | Acc: 51.711,83.333,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.534 | Acc: 51.143,82.698,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.547 | Acc: 51.204,82.095,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.558 | Acc: 50.984,81.752,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.545 | Acc: 51.137,81.830,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.543 | Acc: 51.194,81.947,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.550 | Acc: 51.136,81.948,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.548 | Acc: 51.092,81.891,95.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.551 | Acc: 51.109,81.777,95.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.550 | Acc: 51.185,81.740,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.558 | Acc: 51.117,81.667,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.550 | Acc: 51.319,81.759,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.548 | Acc: 51.338,81.807,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.551 | Acc: 51.259,81.817,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.551 | Acc: 51.256,81.855,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.551 | Acc: 51.256,81.905,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.549 | Acc: 51.299,81.866,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.547 | Acc: 51.368,81.895,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.546 | Acc: 51.388,81.865,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.583 | Acc: 50.781,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.483 | Acc: 46.615,65.141,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.506 | Acc: 46.227,64.882,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.529 | Acc: 46.196,64.972,69.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.649 | Acc: 52.344,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.554 | Acc: 50.818,82.217,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.541 | Acc: 51.429,82.279,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.537 | Acc: 51.550,82.351,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 51.206,82.147,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.543 | Acc: 51.315,82.054,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.539 | Acc: 51.453,82.051,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.543 | Acc: 51.335,82.015,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.543 | Acc: 51.509,82.002,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.548 | Acc: 51.424,81.850,95.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 51.493,81.895,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.546 | Acc: 51.347,81.837,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.546 | Acc: 51.468,81.853,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.553 | Acc: 51.365,81.804,95.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.551 | Acc: 51.373,81.784,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.551 | Acc: 51.334,81.803,95.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.551 | Acc: 51.343,81.788,95.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.547 | Acc: 51.441,81.837,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.547 | Acc: 51.368,81.871,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.548 | Acc: 51.405,81.900,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.603 | Acc: 50.781,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 46.280,64.844,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.522 | Acc: 46.151,64.425,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.541 | Acc: 45.978,64.549,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.864 | Acc: 46.875,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.486 | Acc: 51.079,82.961,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.487 | Acc: 51.258,82.851,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.511 | Acc: 51.191,82.492,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.532 | Acc: 50.907,82.166,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.521 | Acc: 51.284,82.310,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.532 | Acc: 51.194,82.096,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.541 | Acc: 51.180,81.937,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.533 | Acc: 51.286,82.031,95.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.538 | Acc: 51.355,82.040,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 51.259,81.930,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.537 | Acc: 51.202,81.908,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.538 | Acc: 51.225,81.911,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.533 | Acc: 51.281,81.980,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.529 | Acc: 51.234,81.990,95.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 51.241,82.029,95.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.529 | Acc: 51.229,82.024,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.533 | Acc: 51.155,81.937,95.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.534 | Acc: 51.156,81.956,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.536 | Acc: 51.142,81.902,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.536 | Acc: 51.562,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 46.354,64.807,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.527 | Acc: 46.227,64.577,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.545 | Acc: 46.260,64.844,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.311 | Acc: 50.781,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.562 | Acc: 51.116,82.738,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.554 | Acc: 51.467,82.508,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.529 | Acc: 51.396,82.364,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.522 | Acc: 51.611,82.176,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.531 | Acc: 51.423,82.194,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.525 | Acc: 51.537,82.218,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.518 | Acc: 51.712,82.275,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.524 | Acc: 51.572,82.259,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.526 | Acc: 51.480,82.143,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.531 | Acc: 51.372,82.152,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 51.089,82.130,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.539 | Acc: 51.063,82.083,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.539 | Acc: 51.131,82.058,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.538 | Acc: 51.218,82.034,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.546 | Acc: 51.184,81.956,95.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.544 | Acc: 51.258,81.949,95.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.545 | Acc: 51.269,81.910,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.545 | Acc: 51.266,81.886,95.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.549 | Acc: 51.286,81.863,95.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.516 | Acc: 50.781,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 45.871,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 45.922,64.577,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.548 | Acc: 45.863,64.754,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.634 | Acc: 50.000,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.492 | Acc: 51.376,82.329,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.524 | Acc: 51.353,82.450,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.521 | Acc: 51.511,82.147,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.513 | Acc: 51.630,82.388,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.511 | Acc: 51.562,82.372,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.510 | Acc: 51.685,82.386,96.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.510 | Acc: 51.468,82.408,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.523 | Acc: 51.417,82.410,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.516 | Acc: 51.489,82.433,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 51.426,82.474,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.519 | Acc: 51.396,82.410,96.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.518 | Acc: 51.443,82.394,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 51.437,82.319,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 51.296,82.301,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 51.295,82.293,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.525 | Acc: 51.232,82.270,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.527 | Acc: 51.194,82.226,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.523 | Acc: 51.199,82.233,96.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.527 | Acc: 51.271,82.146,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.535 | Acc: 50.000,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.500 | Acc: 46.243,65.141,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.520 | Acc: 46.151,64.729,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 46.094,64.946,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.219 | Acc: 61.719,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.557 | Acc: 51.042,80.990,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.548 | Acc: 51.524,81.574,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.548 | Acc: 51.460,81.455,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 51.408,82.002,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 51.013,81.969,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.524 | Acc: 51.214,82.096,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.533 | Acc: 51.092,82.142,96.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.538 | Acc: 50.820,82.143,96.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.539 | Acc: 50.850,82.131,96.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 50.836,82.128,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.541 | Acc: 50.965,82.137,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.539 | Acc: 51.034,82.158,95.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.537 | Acc: 51.096,82.124,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.533 | Acc: 51.198,82.159,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.530 | Acc: 51.272,82.208,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.529 | Acc: 51.190,82.158,95.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.534 | Acc: 51.178,82.127,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.530 | Acc: 51.257,82.161,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.531 | Acc: 51.269,82.146,95.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.585 | Acc: 52.344,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.516 | Acc: 46.243,64.546,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 46.056,64.482,68.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.543 | Acc: 45.863,64.767,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.459 | Acc: 48.438,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.472 | Acc: 52.790,84.115,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 52.954,82.870,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.513 | Acc: 52.062,82.428,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 51.900,82.311,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 51.918,82.209,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.511 | Acc: 51.976,82.167,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 52.061,82.297,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.509 | Acc: 51.970,82.415,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.508 | Acc: 51.903,82.420,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.514 | Acc: 51.854,82.354,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.518 | Acc: 51.821,82.360,96.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 51.725,82.326,96.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.525 | Acc: 51.715,82.253,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.523 | Acc: 51.727,82.293,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 51.656,82.267,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.534 | Acc: 51.580,82.189,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.532 | Acc: 51.537,82.189,96.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.530 | Acc: 51.513,82.207,96.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.529 | Acc: 51.571,82.154,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.572 | Acc: 50.781,65.625,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 46.354,64.955,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.530 | Acc: 46.113,64.748,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.548 | Acc: 45.978,64.857,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.738 | Acc: 51.562,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.573 | Acc: 51.749,82.254,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.588 | Acc: 51.315,81.307,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.557 | Acc: 51.396,81.570,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.549 | Acc: 51.601,81.723,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.553 | Acc: 51.756,81.706,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.547 | Acc: 51.931,81.663,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.546 | Acc: 51.623,81.704,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.547 | Acc: 51.519,81.653,96.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.545 | Acc: 51.485,81.794,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.540 | Acc: 51.345,81.845,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.545 | Acc: 51.280,81.791,96.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.545 | Acc: 51.323,81.730,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.541 | Acc: 51.398,81.759,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.540 | Acc: 51.329,81.770,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.543 | Acc: 51.280,81.730,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.541 | Acc: 51.314,81.766,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.537 | Acc: 51.361,81.814,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.535 | Acc: 51.394,81.919,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.534 | Acc: 51.411,82.019,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.522 | Acc: 50.000,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.479 | Acc: 46.429,64.881,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.507 | Acc: 46.361,64.520,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.536 | Acc: 46.094,64.844,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.419 | Acc: 45.312,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.513 | Acc: 51.674,82.626,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.557 | Acc: 51.105,81.650,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.543 | Acc: 51.383,81.903,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.552 | Acc: 51.495,81.617,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.549 | Acc: 51.524,81.799,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.546 | Acc: 51.440,81.863,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.533 | Acc: 51.751,82.064,95.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.541 | Acc: 51.650,81.939,95.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.536 | Acc: 51.515,82.031,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.538 | Acc: 51.349,81.884,95.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.541 | Acc: 51.312,81.890,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.532 | Acc: 51.446,82.012,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.531 | Acc: 51.494,82.013,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.531 | Acc: 51.446,82.140,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 51.435,82.177,95.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.532 | Acc: 51.341,82.158,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.532 | Acc: 51.310,82.082,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.533 | Acc: 51.383,82.137,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.530 | Acc: 51.478,82.095,95.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.542 | Acc: 49.219,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.487 | Acc: 46.168,65.141,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.513 | Acc: 46.151,64.691,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 46.158,64.908,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.660 | Acc: 50.781,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.433 | Acc: 53.795,82.887,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.476 | Acc: 52.591,82.641,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.494 | Acc: 51.819,82.736,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.500 | Acc: 51.852,82.417,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.505 | Acc: 51.756,82.387,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.503 | Acc: 51.614,82.302,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.516 | Acc: 51.485,82.292,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.523 | Acc: 51.344,82.220,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.513 | Acc: 51.364,82.385,96.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 51.391,82.358,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.519 | Acc: 51.403,82.335,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 51.387,82.271,96.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.519 | Acc: 51.560,82.238,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 51.543,82.248,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.523 | Acc: 51.402,82.221,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.522 | Acc: 51.397,82.199,96.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 51.301,82.153,96.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.524 | Acc: 51.327,82.165,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 51.321,82.197,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.569 | Acc: 50.781,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.511 | Acc: 46.391,64.955,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 46.170,64.501,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.557 | Acc: 45.991,64.703,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.934 | Acc: 39.844,78.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.560 | Acc: 49.442,81.808,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.541 | Acc: 50.419,81.898,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.553 | Acc: 50.730,81.519,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 51.080,81.858,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.524 | Acc: 51.214,81.985,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.531 | Acc: 51.201,82.005,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.537 | Acc: 51.297,81.715,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.534 | Acc: 51.179,81.779,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.536 | Acc: 51.196,81.820,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.527 | Acc: 51.345,82.023,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.525 | Acc: 51.294,82.109,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.524 | Acc: 51.336,82.154,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.529 | Acc: 51.389,82.145,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 51.404,82.234,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 51.461,82.241,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 51.477,82.214,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.525 | Acc: 51.450,82.263,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.523 | Acc: 51.467,82.293,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.526 | Acc: 51.456,82.199,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.507 | Acc: 51.562,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.540,65.104,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.514 | Acc: 46.494,64.691,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.534 | Acc: 46.299,64.946,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.061 | Acc: 57.812,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.535 | Acc: 51.860,80.804,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.483 | Acc: 51.982,82.355,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.502 | Acc: 51.537,82.287,96.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 51.399,82.407,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.513 | Acc: 51.176,82.310,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.525 | Acc: 51.207,82.335,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.526 | Acc: 50.992,82.325,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.522 | Acc: 50.888,82.453,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.519 | Acc: 50.945,82.480,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.517 | Acc: 50.917,82.400,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 51.053,82.431,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.516 | Acc: 51.180,82.417,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 51.099,82.384,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.522 | Acc: 51.143,82.354,96.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.519 | Acc: 51.165,82.410,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 51.115,82.423,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 51.166,82.414,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.524 | Acc: 51.134,82.403,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.522 | Acc: 51.222,82.396,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.542 | Acc: 51.562,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.540,64.993,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 46.380,64.539,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 46.222,64.767,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.489 | Acc: 55.469,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.595 | Acc: 50.558,82.180,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.544 | Acc: 51.315,81.726,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.551 | Acc: 51.358,81.801,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.551 | Acc: 51.273,81.944,95.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 51.539,82.132,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.547 | Acc: 51.498,81.915,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.540 | Acc: 51.629,81.954,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.543 | Acc: 51.655,81.881,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.549 | Acc: 51.545,81.884,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.543 | Acc: 51.562,81.926,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.539 | Acc: 51.562,81.918,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.541 | Acc: 51.501,81.908,95.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.543 | Acc: 51.347,81.906,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.545 | Acc: 51.271,81.909,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.542 | Acc: 51.235,82.000,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.542 | Acc: 51.280,81.985,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.540 | Acc: 51.304,81.988,96.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.540 | Acc: 51.283,81.964,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.535 | Acc: 51.359,81.996,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 52.344,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.505 | Acc: 46.280,64.993,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.531 | Acc: 46.322,64.501,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.548 | Acc: 46.196,64.754,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.337 | Acc: 54.688,88.281,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.539 | Acc: 51.749,81.882,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.527 | Acc: 51.200,81.879,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.519 | Acc: 51.037,82.082,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.536 | Acc: 50.829,81.954,95.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.536 | Acc: 50.820,82.070,95.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.539 | Acc: 50.930,82.251,95.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.540 | Acc: 50.920,82.286,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.535 | Acc: 51.102,82.206,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.537 | Acc: 51.057,82.174,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.535 | Acc: 51.170,82.202,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 51.174,82.159,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.536 | Acc: 51.151,82.099,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.533 | Acc: 51.224,82.097,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.533 | Acc: 51.293,82.126,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.534 | Acc: 51.228,82.130,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.534 | Acc: 51.266,82.104,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.532 | Acc: 51.347,82.052,95.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.530 | Acc: 51.398,82.146,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.527 | Acc: 51.370,82.224,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.642 | Acc: 51.562,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 46.354,64.955,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.536 | Acc: 46.284,64.596,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 46.119,64.818,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.715 | Acc: 46.094,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.472 | Acc: 52.679,82.812,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.490 | Acc: 52.344,82.393,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.476 | Acc: 51.972,82.505,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 52.315,82.407,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.503 | Acc: 51.887,82.395,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 51.562,82.380,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.513 | Acc: 51.535,82.375,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.510 | Acc: 51.533,82.376,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.510 | Acc: 51.550,82.329,96.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 51.481,82.311,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.523 | Acc: 51.336,82.219,96.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.516 | Acc: 51.488,82.317,96.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 51.533,82.178,96.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 51.462,82.179,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.522 | Acc: 51.425,82.122,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.523 | Acc: 51.468,82.148,96.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.525 | Acc: 51.485,82.169,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.524 | Acc: 51.461,82.183,96.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.521 | Acc: 51.485,82.230,96.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.519 | Acc: 50.000,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.479 | Acc: 46.243,65.439,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.508 | Acc: 46.170,64.787,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.530 | Acc: 46.081,64.869,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.390 | Acc: 50.000,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.507 | Acc: 51.600,81.696,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.513 | Acc: 51.696,82.012,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.523 | Acc: 51.627,81.685,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 51.678,81.636,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.528 | Acc: 51.578,81.954,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.540 | Acc: 51.414,81.863,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.538 | Acc: 51.479,81.920,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.532 | Acc: 51.543,81.983,96.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 51.593,82.061,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.526 | Acc: 51.559,81.988,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 51.520,81.929,96.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.524 | Acc: 51.569,81.979,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 51.431,82.013,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 51.360,82.067,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 51.321,82.088,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 51.392,82.080,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 51.446,82.123,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.527 | Acc: 51.424,82.088,96.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.525 | Acc: 51.489,82.115,96.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.566 | Acc: 50.000,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 46.205,65.327,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.528 | Acc: 46.132,64.710,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 46.094,64.933,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.513 | Acc: 51.562,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.494 | Acc: 51.451,81.808,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.553 | Acc: 50.743,81.383,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 51.409,81.890,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.521 | Acc: 51.649,81.819,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 51.532,82.008,95.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.534 | Acc: 51.614,81.831,95.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.546 | Acc: 51.352,81.793,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.551 | Acc: 51.199,81.929,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.556 | Acc: 51.131,81.884,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.550 | Acc: 51.325,81.934,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.551 | Acc: 51.255,81.893,95.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.541 | Acc: 51.433,82.106,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.530 | Acc: 51.515,82.217,95.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 51.593,82.204,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 51.526,82.229,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.528 | Acc: 51.468,82.194,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.529 | Acc: 51.455,82.203,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.530 | Acc: 51.426,82.139,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.530 | Acc: 51.419,82.089,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.529 | Acc: 50.781,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.489 | Acc: 46.094,64.955,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.511 | Acc: 46.151,64.691,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.536 | Acc: 46.247,64.844,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.816 | Acc: 48.438,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.568 | Acc: 50.893,81.734,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.544 | Acc: 50.953,81.898,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.530 | Acc: 51.345,82.159,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.536 | Acc: 51.100,82.089,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.525 | Acc: 51.300,82.194,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.524 | Acc: 51.446,82.070,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 51.502,82.031,96.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.517 | Acc: 51.495,82.099,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.520 | Acc: 51.511,82.113,96.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.519 | Acc: 51.473,82.257,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.518 | Acc: 51.534,82.215,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 51.472,82.190,96.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 51.374,82.223,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.522 | Acc: 51.437,82.273,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.522 | Acc: 51.420,82.265,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 51.482,82.282,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.521 | Acc: 51.469,82.249,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.522 | Acc: 51.476,82.198,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 51.503,82.240,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.570 | Acc: 50.000,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.540,65.104,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.521 | Acc: 46.322,64.520,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 46.171,64.780,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.861 | Acc: 47.656,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.559 | Acc: 50.260,82.738,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.561 | Acc: 50.705,82.241,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 51.153,82.198,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.524 | Acc: 51.244,82.330,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 51.392,82.240,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.519 | Acc: 51.614,82.535,96.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.518 | Acc: 51.740,82.513,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.523 | Acc: 51.558,82.531,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.525 | Acc: 51.554,82.519,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.527 | Acc: 51.520,82.474,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.526 | Acc: 51.439,82.480,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.521 | Acc: 51.465,82.560,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.529 | Acc: 51.341,82.420,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.527 | Acc: 51.440,82.370,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.521 | Acc: 51.521,82.428,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.522 | Acc: 51.521,82.428,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.522 | Acc: 51.549,82.400,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.520 | Acc: 51.595,82.406,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.521 | Acc: 51.558,82.359,96.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.558 | Acc: 51.562,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.500 | Acc: 46.168,65.067,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.534 | Acc: 46.341,64.806,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.549 | Acc: 46.286,65.010,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.203 | Acc: 56.250,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.560 | Acc: 50.298,81.473,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.559 | Acc: 50.400,81.860,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.559 | Acc: 50.320,81.557,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.561 | Acc: 50.559,81.433,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.543 | Acc: 50.990,81.544,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.559 | Acc: 50.885,81.495,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.559 | Acc: 50.842,81.527,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.559 | Acc: 50.810,81.633,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.554 | Acc: 50.863,81.708,95.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.546 | Acc: 50.929,81.860,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.541 | Acc: 50.940,81.989,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.541 | Acc: 50.904,81.924,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.543 | Acc: 50.868,81.977,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.541 | Acc: 50.945,82.034,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.540 | Acc: 50.997,82.039,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.542 | Acc: 51.054,81.919,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.536 | Acc: 51.157,82.008,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.535 | Acc: 51.134,82.007,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.532 | Acc: 51.156,82.078,95.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.540 | Acc: 50.781,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 46.763,64.807,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.523 | Acc: 46.380,64.520,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.546 | Acc: 46.107,64.805,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.245 | Acc: 59.375,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.594 | Acc: 50.632,81.510,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.566 | Acc: 50.686,81.803,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.556 | Acc: 51.242,81.916,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.541 | Acc: 51.283,81.993,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.542 | Acc: 51.044,81.962,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.547 | Acc: 50.897,81.857,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.551 | Acc: 50.914,81.810,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.548 | Acc: 51.126,81.842,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.542 | Acc: 51.222,81.828,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.536 | Acc: 51.325,81.922,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 51.266,81.893,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.533 | Acc: 51.251,81.804,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.531 | Acc: 51.281,81.846,96.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.528 | Acc: 51.412,81.906,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 51.466,81.987,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 51.480,81.997,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 51.459,82.040,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 51.465,82.118,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.525 | Acc: 51.417,82.089,96.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.561 | Acc: 50.781,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.131,65.030,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.522 | Acc: 46.075,64.653,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 46.055,64.908,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.500 | Acc: 52.344,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 51.302,83.222,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.512 | Acc: 51.734,82.412,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.514 | Acc: 52.011,82.223,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.530 | Acc: 51.505,82.176,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.525 | Acc: 51.516,82.085,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.521 | Acc: 51.401,82.096,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.516 | Acc: 51.313,82.242,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 51.441,82.279,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.506 | Acc: 51.476,82.260,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.502 | Acc: 51.504,82.288,96.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.507 | Acc: 51.474,82.201,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.508 | Acc: 51.562,82.223,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.508 | Acc: 51.670,82.307,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 51.629,82.332,96.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.513 | Acc: 51.609,82.273,96.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.511 | Acc: 51.555,82.311,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.512 | Acc: 51.588,82.320,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 51.573,82.347,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.514 | Acc: 51.620,82.296,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.518 | Acc: 51.562,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 46.429,64.844,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.522 | Acc: 46.361,64.634,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.539 | Acc: 46.068,64.818,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 2.427 | Acc: 53.125,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.574 | Acc: 51.302,81.920,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.505 | Acc: 51.867,82.908,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.490 | Acc: 52.267,82.531,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.498 | Acc: 51.910,82.350,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.502 | Acc: 51.702,82.418,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.502 | Acc: 51.550,82.335,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.501 | Acc: 51.568,82.308,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 51.514,82.308,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.506 | Acc: 51.407,82.299,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.511 | Acc: 51.349,82.210,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 51.230,82.130,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 51.235,82.083,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.522 | Acc: 51.215,82.067,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.523 | Acc: 51.193,82.156,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.525 | Acc: 51.134,82.169,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.525 | Acc: 51.207,82.158,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.527 | Acc: 51.162,82.146,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.529 | Acc: 51.255,82.053,96.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.529 | Acc: 51.265,82.087,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.533 | Acc: 50.000,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.491 | Acc: 46.019,64.807,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.514 | Acc: 46.018,64.463,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 45.978,64.652,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.703 | Acc: 44.531,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.518 | Acc: 50.744,80.729,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.503 | Acc: 50.877,81.726,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.515 | Acc: 50.743,81.801,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.521 | Acc: 51.032,81.867,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.527 | Acc: 51.207,81.907,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.530 | Acc: 51.169,81.863,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.520 | Acc: 51.585,81.832,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.516 | Acc: 51.611,81.983,96.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.521 | Acc: 51.558,81.867,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 51.632,81.942,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.521 | Acc: 51.524,81.879,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.518 | Acc: 51.524,81.937,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.517 | Acc: 51.676,81.968,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 51.554,81.898,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.523 | Acc: 51.570,81.901,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 51.538,81.871,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 51.537,81.866,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.524 | Acc: 51.532,81.880,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.519 | Acc: 51.667,81.927,96.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.562 | Acc: 49.219,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.540,65.290,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.521 | Acc: 46.361,64.768,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.540 | Acc: 46.119,64.895,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.583 | Acc: 50.781,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.545 | Acc: 50.000,82.478,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.545 | Acc: 50.210,82.317,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.507 | Acc: 50.961,82.620,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.505 | Acc: 51.264,82.677,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.511 | Acc: 51.222,82.704,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.511 | Acc: 51.343,82.561,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.519 | Acc: 51.369,82.375,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.527 | Acc: 51.393,82.264,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 51.472,82.282,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.517 | Acc: 51.555,82.338,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.519 | Acc: 51.428,82.374,96.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 51.394,82.329,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 51.314,82.352,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 51.318,82.390,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.516 | Acc: 51.399,82.483,96.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.517 | Acc: 51.424,82.457,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.516 | Acc: 51.441,82.485,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.515 | Acc: 51.482,82.529,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 51.407,82.427,96.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.541 | Acc: 51.562,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.487 | Acc: 46.540,65.030,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.512 | Acc: 46.284,64.825,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.537 | Acc: 46.119,64.985,69.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.403 | Acc: 53.125,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.507 | Acc: 50.781,83.147,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.492 | Acc: 50.934,83.365,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.493 | Acc: 51.460,82.774,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.498 | Acc: 51.775,82.591,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.510 | Acc: 51.756,82.348,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.510 | Acc: 51.937,82.457,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.504 | Acc: 51.978,82.402,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.510 | Acc: 51.926,82.235,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 52.089,82.282,95.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.512 | Acc: 52.111,82.198,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.511 | Acc: 52.022,82.197,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.512 | Acc: 51.828,82.239,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.517 | Acc: 51.787,82.193,95.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.520 | Acc: 51.685,82.137,95.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 51.620,82.236,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.518 | Acc: 51.606,82.180,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 51.565,82.153,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.520 | Acc: 51.584,82.157,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.524 | Acc: 51.497,82.078,95.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.578 | Acc: 51.562,67.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 46.094,64.993,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.550 | Acc: 46.056,64.482,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 45.966,64.664,68.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.328 | Acc: 57.812,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.484 | Acc: 51.749,83.668,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.479 | Acc: 52.706,82.679,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.490 | Acc: 52.638,82.390,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.500 | Acc: 51.813,82.629,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 51.740,82.372,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.523 | Acc: 51.750,82.147,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.532 | Acc: 51.457,82.148,96.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.524 | Acc: 51.495,82.293,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.534 | Acc: 51.230,82.096,96.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.534 | Acc: 51.279,82.144,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.527 | Acc: 51.294,82.254,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.533 | Acc: 51.180,82.274,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.531 | Acc: 51.332,82.274,96.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.526 | Acc: 51.315,82.368,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.530 | Acc: 51.277,82.335,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.527 | Acc: 51.302,82.328,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.523 | Acc: 51.356,82.329,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.527 | Acc: 51.318,82.237,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.524 | Acc: 51.390,82.277,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.547 | Acc: 50.781,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 46.466,65.030,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.524 | Acc: 46.227,64.615,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.546 | Acc: 46.004,64.882,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.643 | Acc: 53.906,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.531 | Acc: 52.121,82.180,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.546 | Acc: 52.001,81.745,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.533 | Acc: 52.049,82.082,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.520 | Acc: 51.871,82.359,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.513 | Acc: 51.725,82.418,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.519 | Acc: 51.730,82.315,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.522 | Acc: 51.562,82.270,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.524 | Acc: 51.320,82.148,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.522 | Acc: 51.308,82.351,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.522 | Acc: 51.154,82.299,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 51.131,82.265,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 51.190,82.219,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.527 | Acc: 51.200,82.241,96.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.524 | Acc: 51.204,82.254,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 51.344,82.234,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 51.392,82.243,96.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 51.386,82.244,96.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.519 | Acc: 51.405,82.243,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.516 | Acc: 51.429,82.247,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.595 | Acc: 50.781,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 46.466,65.141,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 46.227,64.787,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 46.094,65.010,68.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.752 | Acc: 42.188,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.571 | Acc: 49.851,82.180,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.534 | Acc: 51.353,82.184,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.546 | Acc: 51.127,82.185,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 51.080,82.243,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.537 | Acc: 51.346,82.480,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.517 | Acc: 51.659,82.735,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.513 | Acc: 51.551,82.674,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.510 | Acc: 51.587,82.570,96.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.512 | Acc: 51.562,82.545,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.514 | Acc: 51.551,82.455,96.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.519 | Acc: 51.418,82.395,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.514 | Acc: 51.501,82.505,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.517 | Acc: 51.398,82.387,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 51.326,82.401,96.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 51.352,82.369,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.523 | Acc: 51.356,82.328,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.522 | Acc: 51.448,82.402,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 51.487,82.393,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.518 | Acc: 51.542,82.419,96.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.547 | Acc: 50.000,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.508 | Acc: 46.317,64.918,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.527 | Acc: 46.208,64.882,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 46.081,64.933,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.142 | Acc: 54.688,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.424 | Acc: 53.609,83.519,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.453 | Acc: 52.763,82.679,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 52.293,82.441,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.513 | Acc: 51.775,81.935,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.514 | Acc: 51.717,81.931,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.518 | Acc: 51.395,82.051,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.525 | Acc: 51.391,81.909,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 51.417,82.089,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.519 | Acc: 51.390,82.182,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.525 | Acc: 51.325,82.171,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.527 | Acc: 51.269,82.074,95.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.527 | Acc: 51.358,82.093,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.523 | Acc: 51.368,82.115,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.523 | Acc: 51.410,82.129,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.523 | Acc: 51.412,82.127,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 51.441,82.187,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 51.489,82.217,95.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.520 | Acc: 51.478,82.196,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.521 | Acc: 51.452,82.160,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.545 | Acc: 50.000,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.500 | Acc: 46.094,65.253,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.525 | Acc: 46.132,64.710,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 45.991,64.869,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.657 | Acc: 53.125,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.537 | Acc: 50.781,81.882,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.496 | Acc: 51.181,82.889,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 51.268,82.351,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.503 | Acc: 51.447,82.263,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.510 | Acc: 51.269,82.302,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.515 | Acc: 51.220,82.257,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.506 | Acc: 51.485,82.209,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.510 | Acc: 51.499,82.303,96.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.517 | Acc: 51.416,82.230,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.519 | Acc: 51.411,82.218,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 51.527,82.229,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.515 | Acc: 51.556,82.255,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.512 | Acc: 51.601,82.304,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.508 | Acc: 51.610,82.293,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 51.539,82.343,96.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.512 | Acc: 51.521,82.306,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.507 | Acc: 51.558,82.325,96.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.509 | Acc: 51.504,82.323,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.509 | Acc: 51.528,82.314,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.592 | Acc: 50.000,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.525 | Acc: 46.689,65.104,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 46.361,64.653,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.562 | Acc: 46.235,64.831,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 3.050 | Acc: 47.656,71.875,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.537 | Acc: 50.595,81.920,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.507 | Acc: 51.239,82.355,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.499 | Acc: 51.383,82.377,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 51.370,82.436,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.492 | Acc: 51.485,82.735,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.508 | Acc: 51.311,82.548,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.515 | Acc: 51.369,82.480,96.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.513 | Acc: 51.558,82.405,96.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.526 | Acc: 51.480,82.225,96.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.523 | Acc: 51.430,82.198,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.520 | Acc: 51.460,82.130,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 51.400,82.174,96.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.519 | Acc: 51.413,82.238,96.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.516 | Acc: 51.429,82.245,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.522 | Acc: 51.272,82.197,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.523 | Acc: 51.336,82.165,96.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 51.395,82.198,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.518 | Acc: 51.437,82.226,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 51.429,82.183,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.517 | Acc: 50.781,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.490 | Acc: 46.131,65.327,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.514 | Acc: 46.056,64.596,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.536 | Acc: 45.978,64.921,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.826 | Acc: 47.656,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.562 | Acc: 50.670,82.738,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.519 | Acc: 51.429,82.851,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.508 | Acc: 51.716,82.262,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 51.514,81.944,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.522 | Acc: 51.516,82.070,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.523 | Acc: 51.440,82.096,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.519 | Acc: 51.308,82.175,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.514 | Acc: 51.543,82.254,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.522 | Acc: 51.442,82.135,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 51.621,82.156,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.519 | Acc: 51.577,82.176,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 51.608,82.265,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.523 | Acc: 51.539,82.166,96.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.524 | Acc: 51.537,82.204,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 51.386,82.221,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.525 | Acc: 51.416,82.272,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 51.386,82.205,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.526 | Acc: 51.381,82.267,96.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.522 | Acc: 51.493,82.283,96.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 52.344,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 46.168,65.104,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.523 | Acc: 46.151,64.710,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.545 | Acc: 46.068,64.805,68.904,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.355 | Acc: 53.906,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.596 | Acc: 49.702,81.510,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.584 | Acc: 49.981,81.021,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.540 | Acc: 50.423,81.775,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.537 | Acc: 50.646,81.964,96.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.553 | Acc: 50.681,81.691,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.551 | Acc: 50.749,81.721,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.544 | Acc: 50.986,81.915,96.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.534 | Acc: 51.320,81.939,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.530 | Acc: 51.329,81.975,96.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.532 | Acc: 51.322,81.934,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.531 | Acc: 51.382,81.911,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.527 | Acc: 51.355,81.992,96.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 51.419,82.046,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.520 | Acc: 51.457,82.126,96.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 51.280,82.031,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.527 | Acc: 51.305,82.039,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 51.329,82.070,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.525 | Acc: 51.333,82.081,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.522 | Acc: 51.409,82.046,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.514 | Acc: 50.781,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.391,65.290,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.525 | Acc: 46.322,65.034,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.549 | Acc: 46.145,65.126,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.551 | Acc: 56.250,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.469 | Acc: 51.562,82.552,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.519 | Acc: 51.639,82.127,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.521 | Acc: 51.524,82.147,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.529 | Acc: 51.302,82.012,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.521 | Acc: 51.369,82.078,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.528 | Acc: 51.188,82.115,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.521 | Acc: 51.330,82.286,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 51.752,82.313,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.503 | Acc: 51.727,82.316,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 51.543,82.179,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.518 | Acc: 51.456,82.159,96.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 51.456,82.226,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.517 | Acc: 51.470,82.280,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 51.415,82.320,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.521 | Acc: 51.415,82.184,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 51.475,82.204,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.516 | Acc: 51.443,82.283,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.517 | Acc: 51.565,82.289,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 51.468,82.230,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 50.000,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 46.354,65.030,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.521 | Acc: 46.380,64.577,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.543 | Acc: 46.273,64.754,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 3.126 | Acc: 49.219,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.535 | Acc: 52.046,81.399,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 51.410,81.117,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.530 | Acc: 51.819,81.442,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.549 | Acc: 51.669,81.260,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.535 | Acc: 51.764,81.536,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.530 | Acc: 51.801,81.747,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.527 | Acc: 51.950,81.915,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.523 | Acc: 52.072,82.012,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.523 | Acc: 51.938,82.096,95.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 51.897,82.194,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.520 | Acc: 51.863,82.137,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.518 | Acc: 51.828,82.167,95.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 51.676,82.148,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 51.754,82.148,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 51.651,82.148,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.519 | Acc: 51.604,82.187,95.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.517 | Acc: 51.592,82.221,95.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 51.485,82.176,95.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 51.421,82.158,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.547 | Acc: 50.781,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.514 | Acc: 46.205,64.844,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 46.399,64.405,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.565 | Acc: 46.209,64.575,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.455 | Acc: 59.375,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.564 | Acc: 50.744,81.287,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.539 | Acc: 51.562,81.898,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.559 | Acc: 51.230,82.082,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.551 | Acc: 51.032,82.089,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.551 | Acc: 51.075,82.217,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.540 | Acc: 51.085,82.290,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.542 | Acc: 51.103,82.325,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.533 | Acc: 51.116,82.444,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 51.230,82.588,95.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.520 | Acc: 51.325,82.711,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.520 | Acc: 51.315,82.622,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 51.378,82.647,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.517 | Acc: 51.431,82.684,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.520 | Acc: 51.351,82.668,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 51.357,82.639,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.519 | Acc: 51.336,82.637,96.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.518 | Acc: 51.363,82.586,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.519 | Acc: 51.316,82.525,96.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 51.312,82.478,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.541 | Acc: 50.000,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 46.503,64.807,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.517 | Acc: 46.208,64.539,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.543 | Acc: 46.043,64.664,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.586 | Acc: 54.688,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.538 | Acc: 51.004,81.659,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.570 | Acc: 50.781,81.784,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.536 | Acc: 51.268,82.095,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.529 | Acc: 51.514,82.051,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.539 | Acc: 51.269,81.977,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.529 | Acc: 51.414,81.986,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.531 | Acc: 51.435,82.009,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 51.485,82.119,96.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.526 | Acc: 51.476,82.074,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.527 | Acc: 51.469,81.973,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.526 | Acc: 51.570,81.908,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 51.725,82.012,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.522 | Acc: 51.682,82.010,96.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 51.710,82.092,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 51.684,82.135,96.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 51.645,82.104,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.518 | Acc: 51.723,82.162,96.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.520 | Acc: 51.669,82.163,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.524 | Acc: 51.528,82.156,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.522 | Acc: 50.781,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 46.205,65.067,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.520 | Acc: 46.151,64.596,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.540 | Acc: 46.081,64.908,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.426 | Acc: 57.031,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.497 | Acc: 52.753,82.403,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.506 | Acc: 52.744,82.679,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.505 | Acc: 52.382,82.518,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.506 | Acc: 52.054,82.600,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.499 | Acc: 52.181,82.511,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.501 | Acc: 52.195,82.393,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.500 | Acc: 51.917,82.513,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 51.810,82.487,96.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.495 | Acc: 51.865,82.415,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.496 | Acc: 51.889,82.447,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.498 | Acc: 51.778,82.530,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.494 | Acc: 51.845,82.534,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.497 | Acc: 51.832,82.483,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.500 | Acc: 51.849,82.490,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.504 | Acc: 51.827,82.460,96.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 51.752,82.440,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.512 | Acc: 51.725,82.384,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.514 | Acc: 51.658,82.334,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.513 | Acc: 51.677,82.345,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.533 | Acc: 52.344,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.493 | Acc: 46.354,65.141,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.527 | Acc: 46.227,64.615,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.548 | Acc: 46.094,64.741,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.276 | Acc: 53.906,88.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.503 | Acc: 51.190,83.557,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.505 | Acc: 51.296,82.927,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.522 | Acc: 50.935,82.415,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.518 | Acc: 51.254,82.620,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 51.570,82.650,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.499 | Acc: 51.763,82.793,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 51.773,82.585,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.492 | Acc: 51.888,82.691,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.500 | Acc: 51.908,82.536,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.507 | Acc: 51.640,82.517,96.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 51.559,82.498,96.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.508 | Acc: 51.657,82.449,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.510 | Acc: 51.589,82.405,96.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 51.532,82.370,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.506 | Acc: 51.661,82.408,96.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.503 | Acc: 51.691,82.457,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.507 | Acc: 51.617,82.341,96.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.508 | Acc: 51.573,82.341,96.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.511 | Acc: 51.571,82.275,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.530 | Acc: 50.781,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.482 | Acc: 46.615,65.067,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.511 | Acc: 46.361,64.672,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 46.119,64.869,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 2.925 | Acc: 41.406,72.656,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.515 | Acc: 51.042,81.622,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.524 | Acc: 51.315,81.917,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.507 | Acc: 51.486,81.942,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.512 | Acc: 51.698,82.041,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.528 | Acc: 51.199,81.892,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.532 | Acc: 51.104,81.883,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.544 | Acc: 51.058,81.699,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.535 | Acc: 51.276,81.861,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.531 | Acc: 51.446,81.941,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.529 | Acc: 51.504,81.872,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.526 | Acc: 51.506,81.968,96.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 51.381,81.889,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 51.302,81.935,96.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.529 | Acc: 51.301,81.914,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.530 | Acc: 51.287,81.943,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.522 | Acc: 51.360,82.060,96.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.521 | Acc: 51.377,82.091,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.523 | Acc: 51.298,82.044,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.522 | Acc: 51.312,81.966,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 50.781,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 46.540,64.993,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.527 | Acc: 46.341,64.653,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 46.222,64.780,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.531 | Acc: 50.000,84.375,96.875,% | Adaptive Acc: 87.500% | clf_exit: 0.344 0.484 0.172
Batch: 20 | Loss: 2.484 | Acc: 52.418,83.705,96.391,% | Adaptive Acc: 87.314% | clf_exit: 0.346 0.459 0.195
Batch: 40 | Loss: 2.496 | Acc: 52.248,82.736,96.208,% | Adaptive Acc: 87.348% | clf_exit: 0.344 0.458 0.198
Batch: 60 | Loss: 2.479 | Acc: 52.446,82.812,96.247,% | Adaptive Acc: 87.513% | clf_exit: 0.346 0.458 0.196
Batch: 80 | Loss: 2.503 | Acc: 51.784,82.658,96.238,% | Adaptive Acc: 87.548% | clf_exit: 0.342 0.461 0.197
Batch: 100 | Loss: 2.518 | Acc: 51.640,82.503,96.287,% | Adaptive Acc: 87.485% | clf_exit: 0.344 0.457 0.199
Batch: 120 | Loss: 2.524 | Acc: 51.472,82.348,96.126,% | Adaptive Acc: 87.435% | clf_exit: 0.343 0.458 0.199
Batch: 140 | Loss: 2.513 | Acc: 51.540,82.391,96.149,% | Adaptive Acc: 87.467% | clf_exit: 0.343 0.458 0.199
Batch: 160 | Loss: 2.508 | Acc: 51.791,82.478,96.171,% | Adaptive Acc: 87.718% | clf_exit: 0.344 0.458 0.198
Batch: 180 | Loss: 2.507 | Acc: 51.774,82.562,96.223,% | Adaptive Acc: 87.806% | clf_exit: 0.344 0.459 0.197
Batch: 200 | Loss: 2.511 | Acc: 51.679,82.521,96.191,% | Adaptive Acc: 87.729% | clf_exit: 0.343 0.460 0.196
Batch: 220 | Loss: 2.516 | Acc: 51.527,82.410,96.175,% | Adaptive Acc: 87.567% | clf_exit: 0.344 0.459 0.197
Batch: 240 | Loss: 2.512 | Acc: 51.566,82.449,96.207,% | Adaptive Acc: 87.565% | clf_exit: 0.344 0.460 0.196
Batch: 260 | Loss: 2.520 | Acc: 51.539,82.375,96.157,% | Adaptive Acc: 87.491% | clf_exit: 0.344 0.459 0.197
Batch: 280 | Loss: 2.523 | Acc: 51.510,82.401,96.141,% | Adaptive Acc: 87.453% | clf_exit: 0.344 0.460 0.196
Batch: 300 | Loss: 2.522 | Acc: 51.560,82.353,96.159,% | Adaptive Acc: 87.492% | clf_exit: 0.343 0.460 0.196
Batch: 320 | Loss: 2.525 | Acc: 51.431,82.311,96.176,% | Adaptive Acc: 87.451% | clf_exit: 0.341 0.462 0.197
Batch: 340 | Loss: 2.527 | Acc: 51.356,82.302,96.181,% | Adaptive Acc: 87.383% | clf_exit: 0.342 0.461 0.197
Batch: 360 | Loss: 2.524 | Acc: 51.418,82.291,96.185,% | Adaptive Acc: 87.392% | clf_exit: 0.343 0.460 0.197
Batch: 380 | Loss: 2.522 | Acc: 51.472,82.310,96.178,% | Adaptive Acc: 87.408% | clf_exit: 0.343 0.460 0.197
Batch: 0 | Loss: 4.561 | Acc: 52.344,68.750,71.094,% | Adaptive Acc: 64.062% | clf_exit: 0.438 0.328 0.234
Batch: 20 | Loss: 4.498 | Acc: 46.652,65.216,69.903,% | Adaptive Acc: 64.174% | clf_exit: 0.401 0.375 0.224
Batch: 40 | Loss: 4.525 | Acc: 46.437,64.653,69.074,% | Adaptive Acc: 64.005% | clf_exit: 0.397 0.371 0.232
Batch: 60 | Loss: 4.553 | Acc: 46.273,64.818,69.160,% | Adaptive Acc: 63.909% | clf_exit: 0.396 0.372 0.232
model is save as models/resnet56_h12_cifar100_adaptive0_circles3_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 25.668 | Acc: 4.688,4.688,10.156,% | Adaptive Acc: 7.812% | clf_exit: 0.758 0.195 0.047
Batch: 20 | Loss: 27.180 | Acc: 4.948,6.734,6.436,% | Adaptive Acc: 5.432% | clf_exit: 0.792 0.141 0.067
Batch: 40 | Loss: 27.109 | Acc: 4.935,7.050,6.021,% | Adaptive Acc: 5.507% | clf_exit: 0.791 0.141 0.068
Batch: 60 | Loss: 27.049 | Acc: 5.174,6.993,6.045,% | Adaptive Acc: 5.571% | clf_exit: 0.792 0.139 0.069
Batch: 0 | Loss: 14.793 | Acc: 14.062,25.000,17.188,% | Adaptive Acc: 15.625% | clf_exit: 0.594 0.305 0.102
Batch: 20 | Loss: 16.135 | Acc: 10.119,21.057,19.940,% | Adaptive Acc: 15.104% | clf_exit: 0.654 0.249 0.097
Batch: 40 | Loss: 16.060 | Acc: 10.328,21.513,19.855,% | Adaptive Acc: 15.377% | clf_exit: 0.646 0.247 0.107
Batch: 60 | Loss: 16.030 | Acc: 10.284,21.529,19.992,% | Adaptive Acc: 15.305% | clf_exit: 0.653 0.238 0.109
Batch: 0 | Loss: 6.101 | Acc: 32.031,59.375,66.406,% | Adaptive Acc: 48.438% | clf_exit: 0.523 0.281 0.195
Batch: 20 | Loss: 6.766 | Acc: 23.400,53.646,62.909,% | Adaptive Acc: 45.350% | clf_exit: 0.465 0.342 0.193
Batch: 40 | Loss: 6.745 | Acc: 24.009,54.192,62.462,% | Adaptive Acc: 46.284% | clf_exit: 0.452 0.348 0.200
Batch: 60 | Loss: 6.769 | Acc: 23.975,54.086,62.526,% | Adaptive Acc: 46.119% | clf_exit: 0.451 0.348 0.201
Batch: 0 | Loss: 4.561 | Acc: 52.344,68.750,71.094,% | Adaptive Acc: 64.062% | clf_exit: 0.438 0.328 0.234
Batch: 20 | Loss: 4.498 | Acc: 46.652,65.216,69.903,% | Adaptive Acc: 64.174% | clf_exit: 0.401 0.375 0.224
Batch: 40 | Loss: 4.525 | Acc: 46.437,64.653,69.074,% | Adaptive Acc: 64.005% | clf_exit: 0.397 0.371 0.232
Batch: 60 | Loss: 4.553 | Acc: 46.273,64.818,69.160,% | Adaptive Acc: 63.909% | clf_exit: 0.396 0.372 0.232







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.150 |  Acc: 2.486,4.060,6.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 12.387 |  Acc: 3.280,5.970,9.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 11.922 |  Acc: 4.738,9.162,12.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 11.796 |  Acc: 5.040,9.390,12.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 11.186 |  Acc: 7.356,13.078,17.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 11.121 |  Acc: 8.250,11.760,16.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 10.522 |  Acc: 9.714,16.534,21.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 10.651 |  Acc: 9.070,15.280,20.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 9.979 |  Acc: 12.364,19.504,24.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 10.121 |  Acc: 10.810,17.680,23.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 9.511 |  Acc: 14.444,22.068,27.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 9.460 |  Acc: 13.250,21.230,27.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 9.119 |  Acc: 16.490,24.416,30.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 9.599 |  Acc: 12.380,21.280,29.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 8.774 |  Acc: 18.224,26.304,32.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 9.009 |  Acc: 16.970,24.210,30.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 8.458 |  Acc: 19.990,28.502,35.394,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 9.817 |  Acc: 12.460,21.270,26.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 8.187 |  Acc: 21.228,30.040,37.474,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 8.888 |  Acc: 16.730,25.340,34.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 7.951 |  Acc: 22.298,31.780,39.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 9.763 |  Acc: 11.320,21.600,32.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 7.724 |  Acc: 23.440,33.578,41.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 9.000 |  Acc: 16.540,24.660,34.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 7.517 |  Acc: 24.208,35.316,42.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 9.122 |  Acc: 14.940,26.540,32.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 7.354 |  Acc: 25.200,36.294,44.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 9.697 |  Acc: 15.100,24.140,33.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 7.186 |  Acc: 25.994,37.894,45.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 8.430 |  Acc: 16.980,30.800,39.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 7.004 |  Acc: 27.070,39.336,47.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 8.737 |  Acc: 17.230,28.540,38.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 6.884 |  Acc: 27.658,40.174,48.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 8.244 |  Acc: 18.360,32.580,41.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 6.781 |  Acc: 28.454,41.402,48.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 7.371 |  Acc: 23.350,37.220,46.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 6.630 |  Acc: 29.190,42.520,50.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 7.731 |  Acc: 21.130,34.700,45.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 6.539 |  Acc: 29.372,43.392,51.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 7.679 |  Acc: 23.080,36.420,44.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 6.414 |  Acc: 30.230,44.496,52.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 7.143 |  Acc: 26.170,37.910,48.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 6.323 |  Acc: 30.766,45.424,53.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 7.614 |  Acc: 23.290,36.030,45.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 6.218 |  Acc: 31.596,46.108,53.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 8.406 |  Acc: 20.840,31.820,41.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 6.130 |  Acc: 31.970,47.118,54.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 7.840 |  Acc: 21.630,35.500,44.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 6.071 |  Acc: 32.056,47.880,55.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 7.538 |  Acc: 24.620,36.620,46.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 5.996 |  Acc: 32.782,48.306,56.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 7.119 |  Acc: 23.570,40.830,48.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 5.927 |  Acc: 33.066,49.110,56.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 7.711 |  Acc: 20.340,38.950,48.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 5.844 |  Acc: 33.592,49.742,57.536,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 8.291 |  Acc: 20.250,35.940,45.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 5.802 |  Acc: 33.576,50.146,57.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 6.995 |  Acc: 26.810,41.330,48.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 5.752 |  Acc: 33.822,50.790,58.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 7.545 |  Acc: 20.060,39.340,47.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 5.704 |  Acc: 34.232,51.260,58.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 6.966 |  Acc: 25.610,43.580,49.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 5.643 |  Acc: 34.452,51.770,59.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 6.811 |  Acc: 27.310,43.610,51.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 5.595 |  Acc: 34.570,52.304,59.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 6.728 |  Acc: 29.380,44.250,50.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 5.552 |  Acc: 34.972,52.624,59.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 7.112 |  Acc: 25.840,40.660,49.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 5.505 |  Acc: 35.212,53.120,60.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 6.608 |  Acc: 28.510,45.050,52.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.482 |  Acc: 35.436,53.220,60.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 6.373 |  Acc: 30.100,47.130,52.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.460 |  Acc: 35.448,53.534,61.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 8.519 |  Acc: 17.630,32.790,45.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.414 |  Acc: 35.572,53.626,61.154,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 8.845 |  Acc: 19.330,37.840,46.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.377 |  Acc: 36.018,54.092,61.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 7.620 |  Acc: 21.270,40.820,49.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.358 |  Acc: 35.996,54.292,61.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 9.584 |  Acc: 14.250,32.060,46.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.306 |  Acc: 36.426,54.712,62.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 6.303 |  Acc: 29.110,47.540,55.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.280 |  Acc: 36.550,55.146,62.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 7.543 |  Acc: 24.340,40.780,49.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.256 |  Acc: 36.300,55.382,63.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 7.585 |  Acc: 20.300,40.710,52.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.232 |  Acc: 36.642,55.574,63.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 6.664 |  Acc: 28.690,43.550,51.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.184 |  Acc: 37.112,55.974,63.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 7.106 |  Acc: 27.410,38.940,50.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 5.180 |  Acc: 37.282,55.952,63.642,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 7.465 |  Acc: 21.500,40.940,49.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 5.158 |  Acc: 37.516,56.254,63.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 6.748 |  Acc: 24.890,46.510,53.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 5.127 |  Acc: 37.280,56.362,64.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 6.667 |  Acc: 26.100,45.600,53.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 5.103 |  Acc: 37.360,56.822,64.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 6.782 |  Acc: 28.370,44.210,52.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 5.087 |  Acc: 37.626,56.976,64.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 7.340 |  Acc: 23.230,41.540,51.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 5.053 |  Acc: 37.794,57.118,65.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 6.248 |  Acc: 31.780,48.420,54.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 5.037 |  Acc: 37.788,57.364,65.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 6.381 |  Acc: 29.420,45.190,55.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 5.011 |  Acc: 38.104,57.528,65.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 7.638 |  Acc: 22.580,41.570,50.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 5.006 |  Acc: 37.866,57.560,65.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 7.085 |  Acc: 24.530,42.590,53.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 4.981 |  Acc: 38.450,57.926,65.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 6.823 |  Acc: 26.620,44.970,53.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 4.944 |  Acc: 38.394,58.328,66.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 6.741 |  Acc: 29.170,46.360,54.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 4.961 |  Acc: 38.284,58.094,65.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 6.700 |  Acc: 28.960,45.920,53.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 4.913 |  Acc: 38.582,58.516,66.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.537 |  Acc: 29.420,47.280,53.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 4.928 |  Acc: 38.488,58.438,66.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 7.383 |  Acc: 21.930,43.040,52.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 4.887 |  Acc: 38.702,58.598,66.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 6.653 |  Acc: 25.570,47.560,54.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 4.885 |  Acc: 38.498,58.624,66.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 7.000 |  Acc: 24.830,43.670,52.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.847 |  Acc: 38.808,59.216,67.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 6.798 |  Acc: 26.190,47.860,55.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.848 |  Acc: 38.730,59.058,66.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 7.235 |  Acc: 25.570,42.880,52.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.830 |  Acc: 38.918,59.182,67.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 6.826 |  Acc: 28.700,44.380,52.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.828 |  Acc: 39.006,59.080,67.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 5.980 |  Acc: 34.010,49.490,56.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.813 |  Acc: 39.328,59.784,67.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 6.298 |  Acc: 32.080,47.270,54.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.783 |  Acc: 39.258,59.592,67.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 6.466 |  Acc: 29.840,47.700,54.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.773 |  Acc: 39.410,59.744,67.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 6.611 |  Acc: 29.490,46.800,55.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.763 |  Acc: 39.452,59.778,68.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 6.724 |  Acc: 25.260,46.660,55.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.755 |  Acc: 39.472,59.908,67.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 6.417 |  Acc: 28.480,47.290,57.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.747 |  Acc: 39.304,59.956,68.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 7.874 |  Acc: 20.610,40.160,51.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.737 |  Acc: 39.484,60.300,68.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 6.281 |  Acc: 29.940,49.840,56.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.726 |  Acc: 39.978,59.908,68.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 7.049 |  Acc: 26.600,46.040,55.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.735 |  Acc: 39.442,60.094,68.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.539 |  Acc: 27.700,46.360,55.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.704 |  Acc: 39.822,60.474,68.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 6.186 |  Acc: 30.860,49.510,56.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.683 |  Acc: 40.130,60.438,68.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 7.415 |  Acc: 24.990,43.420,50.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.666 |  Acc: 40.006,60.656,68.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 6.263 |  Acc: 28.800,50.140,57.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.652 |  Acc: 39.910,60.740,68.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 6.463 |  Acc: 29.940,46.090,54.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.667 |  Acc: 39.998,60.588,68.662,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 6.809 |  Acc: 27.760,44.970,52.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.643 |  Acc: 40.240,61.062,68.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 6.853 |  Acc: 25.280,47.300,53.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.633 |  Acc: 40.250,60.958,69.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 6.851 |  Acc: 27.000,45.800,54.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.650 |  Acc: 39.924,60.786,69.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.731 |  Acc: 25.730,45.870,54.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.613 |  Acc: 40.406,61.292,69.394,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 7.422 |  Acc: 23.440,40.610,51.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.595 |  Acc: 40.364,61.376,69.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 6.947 |  Acc: 26.570,45.740,53.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.609 |  Acc: 40.006,61.172,69.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 6.772 |  Acc: 29.730,43.650,52.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.600 |  Acc: 40.440,61.174,69.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 6.822 |  Acc: 31.910,43.810,51.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.582 |  Acc: 40.776,61.644,69.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 7.235 |  Acc: 22.570,45.770,54.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.561 |  Acc: 40.880,61.724,69.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 6.375 |  Acc: 31.510,48.270,54.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.565 |  Acc: 40.664,61.760,69.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 6.744 |  Acc: 27.540,45.910,54.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.564 |  Acc: 40.680,62.046,69.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 6.943 |  Acc: 27.560,47.120,54.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.569 |  Acc: 40.604,61.818,69.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 7.171 |  Acc: 29.710,41.570,49.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.541 |  Acc: 40.748,61.682,70.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 6.610 |  Acc: 29.800,45.560,55.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.535 |  Acc: 40.814,61.864,70.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 6.703 |  Acc: 27.790,46.260,52.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.518 |  Acc: 41.074,62.120,70.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 7.197 |  Acc: 27.140,43.600,52.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.517 |  Acc: 40.932,61.960,70.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 7.290 |  Acc: 23.640,42.810,53.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.518 |  Acc: 40.862,62.152,70.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 7.911 |  Acc: 22.820,39.580,48.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.503 |  Acc: 40.944,62.280,70.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 6.742 |  Acc: 27.580,47.950,53.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.526 |  Acc: 40.674,61.778,70.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 6.504 |  Acc: 28.140,46.820,56.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.515 |  Acc: 40.938,62.244,70.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 6.783 |  Acc: 26.600,46.570,53.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.493 |  Acc: 41.170,62.284,70.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 5.965 |  Acc: 32.050,50.160,57.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.487 |  Acc: 40.852,62.410,70.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 6.108 |  Acc: 32.960,50.800,57.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.453 |  Acc: 41.166,62.538,71.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 5.940 |  Acc: 30.460,52.170,59.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.474 |  Acc: 40.960,62.700,70.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.459 |  Acc: 28.560,50.300,56.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.460 |  Acc: 41.348,62.670,70.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 7.092 |  Acc: 23.500,45.620,55.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.473 |  Acc: 41.092,62.600,70.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 6.515 |  Acc: 31.990,46.730,53.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.444 |  Acc: 41.402,62.992,70.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 6.063 |  Acc: 30.980,49.910,58.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.441 |  Acc: 41.434,63.006,70.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 6.385 |  Acc: 29.320,50.050,56.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.437 |  Acc: 41.550,62.804,71.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 5.834 |  Acc: 33.930,52.850,59.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.456 |  Acc: 41.626,62.446,70.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 6.010 |  Acc: 31.740,51.200,57.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.430 |  Acc: 41.500,62.814,71.036,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 7.157 |  Acc: 25.720,44.930,54.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.442 |  Acc: 41.324,62.788,70.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 6.986 |  Acc: 25.940,45.980,54.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.415 |  Acc: 41.640,63.022,71.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 6.306 |  Acc: 30.980,48.860,56.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.418 |  Acc: 41.462,63.140,71.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 6.429 |  Acc: 30.250,48.300,56.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.406 |  Acc: 41.662,63.132,71.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 6.420 |  Acc: 29.560,48.370,56.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.393 |  Acc: 41.626,63.476,71.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 6.216 |  Acc: 31.320,51.290,56.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.402 |  Acc: 41.464,63.578,71.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.116 |  Acc: 31.780,48.800,58.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.377 |  Acc: 41.562,63.486,71.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 7.626 |  Acc: 21.710,42.530,52.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.394 |  Acc: 41.430,63.326,71.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 6.110 |  Acc: 32.470,48.720,57.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.375 |  Acc: 41.944,63.704,71.662,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 6.729 |  Acc: 25.200,49.150,57.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.395 |  Acc: 41.730,63.204,71.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 6.184 |  Acc: 32.620,48.770,58.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.377 |  Acc: 41.746,63.460,71.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 6.169 |  Acc: 29.990,51.520,56.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.382 |  Acc: 41.868,63.288,71.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 6.075 |  Acc: 32.450,51.700,58.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.372 |  Acc: 41.854,63.474,71.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 5.947 |  Acc: 32.640,52.270,58.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.369 |  Acc: 41.876,63.588,71.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 6.644 |  Acc: 28.480,47.590,55.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.362 |  Acc: 41.954,63.440,71.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 6.217 |  Acc: 31.120,50.470,56.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.349 |  Acc: 41.912,63.630,71.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 6.119 |  Acc: 29.320,52.530,58.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.358 |  Acc: 41.828,63.524,71.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 7.723 |  Acc: 21.740,41.180,52.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.354 |  Acc: 41.826,63.780,71.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 6.353 |  Acc: 32.560,47.830,55.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.345 |  Acc: 42.090,63.616,72.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 6.251 |  Acc: 30.010,49.370,58.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.353 |  Acc: 42.128,63.586,71.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 6.039 |  Acc: 32.930,51.470,57.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.330 |  Acc: 41.930,63.868,72.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 5.797 |  Acc: 35.220,52.800,58.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.337 |  Acc: 41.988,63.704,72.192,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 6.036 |  Acc: 34.730,50.030,56.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.333 |  Acc: 42.128,63.828,72.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 6.661 |  Acc: 31.090,47.430,54.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.327 |  Acc: 41.910,64.134,72.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 7.253 |  Acc: 24.310,45.310,54.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.326 |  Acc: 42.346,64.026,72.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 7.473 |  Acc: 27.970,38.600,50.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.320 |  Acc: 42.154,64.042,72.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 6.937 |  Acc: 26.710,45.570,54.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.330 |  Acc: 42.112,63.816,72.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 5.769 |  Acc: 33.880,52.330,59.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.298 |  Acc: 42.252,64.036,72.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 7.918 |  Acc: 19.040,42.440,51.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.304 |  Acc: 42.212,64.098,72.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.694 |  Acc: 28.530,47.490,56.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.315 |  Acc: 42.286,63.990,72.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 7.241 |  Acc: 24.580,45.410,55.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.312 |  Acc: 42.154,64.148,72.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 6.331 |  Acc: 29.390,51.720,58.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.297 |  Acc: 42.160,64.128,72.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 6.209 |  Acc: 32.110,50.480,58.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.274 |  Acc: 42.362,64.744,72.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 7.069 |  Acc: 25.290,46.920,54.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.294 |  Acc: 42.370,64.416,72.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 7.055 |  Acc: 27.360,43.050,51.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.302 |  Acc: 42.214,64.192,72.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 6.317 |  Acc: 30.130,50.810,58.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.286 |  Acc: 42.508,64.384,72.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 9.237 |  Acc: 16.300,37.090,47.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.253 |  Acc: 42.492,64.894,72.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 6.448 |  Acc: 27.670,50.190,57.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.285 |  Acc: 42.708,64.418,72.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 6.386 |  Acc: 28.360,49.610,57.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.262 |  Acc: 42.704,64.612,72.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 6.194 |  Acc: 32.180,50.490,55.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.272 |  Acc: 42.690,64.434,72.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 7.051 |  Acc: 26.810,47.410,56.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.612 |  Acc: 46.418,71.394,80.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.408 |  Acc: 43.510,64.240,69.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.430 |  Acc: 47.648,73.178,83.138,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.359 |  Acc: 43.970,64.580,70.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.356 |  Acc: 47.902,73.922,84.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.352 |  Acc: 44.340,65.010,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.309 |  Acc: 47.924,74.632,84.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.381 |  Acc: 44.610,64.880,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.285 |  Acc: 47.994,74.598,85.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.348 |  Acc: 44.340,64.980,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.249 |  Acc: 48.194,74.944,85.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.364 |  Acc: 44.110,65.140,70.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.229 |  Acc: 48.270,75.194,86.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.366 |  Acc: 44.470,64.770,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.209 |  Acc: 48.336,75.120,86.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.387 |  Acc: 44.470,65.120,70.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.189 |  Acc: 48.426,75.362,86.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.326 |  Acc: 45.060,65.300,70.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.170 |  Acc: 48.482,75.516,87.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.382 |  Acc: 44.500,65.080,70.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.157 |  Acc: 48.548,75.526,87.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.383 |  Acc: 44.400,65.120,70.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.136 |  Acc: 48.568,75.850,87.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.391 |  Acc: 44.710,65.080,69.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.134 |  Acc: 48.620,75.690,87.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.358 |  Acc: 44.560,64.800,70.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.105 |  Acc: 48.536,75.878,88.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.363 |  Acc: 44.970,64.870,70.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.102 |  Acc: 48.546,76.182,87.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.383 |  Acc: 45.090,65.280,70.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.079 |  Acc: 48.706,76.206,88.270,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.396 |  Acc: 44.560,65.310,70.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.084 |  Acc: 48.820,76.142,88.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.405 |  Acc: 44.460,64.980,70.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 3.067 |  Acc: 48.892,76.218,88.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.430 |  Acc: 44.810,64.880,69.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 3.064 |  Acc: 48.988,76.376,88.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.458 |  Acc: 44.910,64.230,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 3.037 |  Acc: 48.794,76.420,89.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.456 |  Acc: 44.450,64.390,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 3.038 |  Acc: 48.978,76.478,89.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.449 |  Acc: 44.330,64.650,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 3.019 |  Acc: 49.018,76.664,89.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.475 |  Acc: 44.310,64.460,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 3.016 |  Acc: 49.040,76.604,89.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.488 |  Acc: 44.400,64.830,69.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 3.008 |  Acc: 49.022,76.578,89.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.504 |  Acc: 44.110,64.300,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 3.010 |  Acc: 48.918,76.574,89.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.442 |  Acc: 45.050,64.740,69.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 3.001 |  Acc: 49.166,76.742,89.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.470 |  Acc: 44.480,64.860,69.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.986 |  Acc: 49.204,76.966,89.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.448 |  Acc: 45.380,64.500,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.983 |  Acc: 49.156,77.062,89.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.483 |  Acc: 44.850,64.750,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.980 |  Acc: 49.150,77.022,89.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.508 |  Acc: 44.360,64.640,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.967 |  Acc: 49.286,77.020,90.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.492 |  Acc: 44.600,64.580,69.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.961 |  Acc: 49.272,77.140,90.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.537 |  Acc: 44.180,64.290,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.962 |  Acc: 49.146,77.146,90.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.464 |  Acc: 45.060,64.620,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.961 |  Acc: 49.012,77.092,90.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.553 |  Acc: 44.280,64.140,68.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.951 |  Acc: 49.122,77.138,90.394,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.527 |  Acc: 44.770,64.510,68.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.930 |  Acc: 49.170,77.510,90.536,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.496 |  Acc: 44.950,64.470,69.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.931 |  Acc: 49.188,77.470,90.642,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.556 |  Acc: 43.720,63.950,68.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.934 |  Acc: 49.460,77.250,90.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.508 |  Acc: 44.750,64.350,69.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.926 |  Acc: 49.188,77.528,90.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.518 |  Acc: 44.980,64.540,68.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.917 |  Acc: 49.458,77.476,90.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.539 |  Acc: 45.030,64.880,68.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.910 |  Acc: 49.544,77.520,90.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.551 |  Acc: 45.020,64.570,68.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.909 |  Acc: 49.576,77.532,91.036,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.612 |  Acc: 43.330,63.620,69.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.904 |  Acc: 49.440,77.618,90.962,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.658 |  Acc: 43.150,63.450,68.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.912 |  Acc: 49.330,77.698,90.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.578 |  Acc: 43.980,64.400,68.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.904 |  Acc: 49.204,77.766,91.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.633 |  Acc: 43.770,64.130,68.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.896 |  Acc: 49.554,77.564,91.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.626 |  Acc: 43.920,64.320,68.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.888 |  Acc: 49.598,77.712,91.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.578 |  Acc: 44.550,64.640,68.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.879 |  Acc: 49.338,77.728,91.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.623 |  Acc: 44.200,64.270,68.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.874 |  Acc: 49.688,77.816,91.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.670 |  Acc: 44.310,63.940,67.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.874 |  Acc: 49.558,78.106,91.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.648 |  Acc: 44.020,64.230,68.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.878 |  Acc: 49.642,78.036,91.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.616 |  Acc: 44.370,64.240,68.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.861 |  Acc: 49.402,78.098,91.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.666 |  Acc: 44.080,63.960,67.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.864 |  Acc: 49.634,78.092,91.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.637 |  Acc: 44.580,64.030,68.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.860 |  Acc: 49.826,78.170,91.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.687 |  Acc: 43.890,63.940,68.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.861 |  Acc: 49.670,78.104,91.440,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.612 |  Acc: 44.510,64.010,68.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.861 |  Acc: 49.568,77.970,91.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.637 |  Acc: 44.020,63.580,68.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.834 |  Acc: 49.664,78.288,91.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.635 |  Acc: 44.720,63.960,68.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.856 |  Acc: 49.440,77.906,91.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.769 |  Acc: 42.880,63.080,68.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.844 |  Acc: 49.646,78.224,91.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.706 |  Acc: 43.190,63.910,67.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.844 |  Acc: 49.678,78.302,91.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.690 |  Acc: 43.280,63.620,68.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.837 |  Acc: 49.472,78.242,91.746,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.744 |  Acc: 43.550,63.960,67.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.828 |  Acc: 49.798,78.208,92.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.673 |  Acc: 44.700,64.040,68.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.841 |  Acc: 49.422,78.260,91.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.912 |  Acc: 41.170,62.280,67.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.841 |  Acc: 49.896,78.296,91.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.730 |  Acc: 43.220,63.750,67.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.837 |  Acc: 49.688,78.258,91.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.707 |  Acc: 44.010,63.630,66.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.828 |  Acc: 49.814,78.476,91.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.691 |  Acc: 43.710,63.900,67.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.831 |  Acc: 49.774,78.356,91.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.744 |  Acc: 43.610,63.900,67.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.828 |  Acc: 49.562,78.460,91.608,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.676 |  Acc: 44.160,64.110,67.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.816 |  Acc: 49.664,78.546,92.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.710 |  Acc: 44.190,63.960,68.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.825 |  Acc: 49.994,78.452,91.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.617 |  Acc: 45.020,64.170,68.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.821 |  Acc: 49.804,78.498,91.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.884 |  Acc: 42.640,62.380,66.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.826 |  Acc: 49.770,78.444,91.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.767 |  Acc: 43.520,62.760,67.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.815 |  Acc: 49.746,78.656,91.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.654 |  Acc: 44.610,63.840,67.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.812 |  Acc: 49.782,78.584,92.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.907 |  Acc: 42.590,62.700,66.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.804 |  Acc: 49.876,78.762,92.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.712 |  Acc: 44.300,63.930,67.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.811 |  Acc: 49.990,78.684,91.736,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.771 |  Acc: 43.490,63.390,68.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.677 |  Acc: 50.636,80.210,93.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.461 |  Acc: 45.920,65.330,69.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.627 |  Acc: 51.030,80.846,94.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.464 |  Acc: 45.950,65.280,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.613 |  Acc: 50.858,81.232,94.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.480 |  Acc: 45.970,65.180,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.612 |  Acc: 50.900,81.098,95.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.468 |  Acc: 46.090,65.390,69.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.596 |  Acc: 51.250,81.180,95.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.476 |  Acc: 45.920,65.090,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.601 |  Acc: 50.866,81.286,95.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.488 |  Acc: 46.060,65.200,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.593 |  Acc: 51.180,81.390,95.154,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.481 |  Acc: 46.290,65.040,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.585 |  Acc: 51.228,81.332,95.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.487 |  Acc: 46.270,64.960,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.586 |  Acc: 51.102,81.580,95.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.486 |  Acc: 46.060,64.900,69.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.585 |  Acc: 51.358,81.310,95.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.509 |  Acc: 45.840,64.870,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.576 |  Acc: 51.226,81.426,95.376,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.480 |  Acc: 45.930,65.060,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.581 |  Acc: 51.088,81.464,95.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.478 |  Acc: 46.040,64.980,69.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.577 |  Acc: 51.318,81.378,95.394,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.481 |  Acc: 45.770,65.490,69.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.568 |  Acc: 51.230,81.678,95.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.500 |  Acc: 45.720,65.000,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.570 |  Acc: 51.052,81.522,95.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.495 |  Acc: 46.000,65.220,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.571 |  Acc: 51.250,81.646,95.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.505 |  Acc: 45.920,65.070,69.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.569 |  Acc: 51.030,81.660,95.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.513 |  Acc: 45.950,64.880,69.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.575 |  Acc: 51.146,81.364,95.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.505 |  Acc: 46.000,65.070,69.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.565 |  Acc: 51.204,81.664,95.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.503 |  Acc: 46.080,65.120,69.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.570 |  Acc: 51.276,81.430,95.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.507 |  Acc: 45.850,65.210,69.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.559 |  Acc: 51.162,81.686,95.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.515 |  Acc: 46.080,64.920,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.573 |  Acc: 51.210,81.658,95.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.501 |  Acc: 45.970,65.230,69.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.553 |  Acc: 51.310,81.718,95.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.520 |  Acc: 46.100,65.010,69.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.568 |  Acc: 51.222,81.628,95.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.505 |  Acc: 45.970,65.190,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.557 |  Acc: 51.272,81.842,95.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.505 |  Acc: 46.140,65.210,69.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.550 |  Acc: 51.358,81.864,95.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.541 |  Acc: 46.110,65.030,69.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.552 |  Acc: 51.354,81.768,95.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.522 |  Acc: 45.890,65.150,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.555 |  Acc: 51.138,81.714,95.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.527 |  Acc: 45.610,65.360,69.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.547 |  Acc: 51.308,81.814,95.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.525 |  Acc: 46.070,65.020,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.554 |  Acc: 51.328,81.676,95.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.532 |  Acc: 45.930,65.120,69.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.555 |  Acc: 51.260,81.688,95.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.516 |  Acc: 46.230,65.000,69.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.550 |  Acc: 51.094,81.986,95.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.541 |  Acc: 45.900,64.980,69.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.551 |  Acc: 51.234,81.784,95.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.519 |  Acc: 45.850,65.100,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.549 |  Acc: 51.366,81.810,95.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.513 |  Acc: 46.060,65.290,69.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.549 |  Acc: 51.396,81.846,95.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.525 |  Acc: 45.840,64.890,69.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.537 |  Acc: 51.160,81.898,95.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.531 |  Acc: 46.130,65.390,69.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.549 |  Acc: 51.312,81.850,95.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.536 |  Acc: 45.750,65.110,69.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.529 |  Acc: 51.260,82.048,96.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.530 |  Acc: 45.990,65.200,68.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.531 |  Acc: 51.280,82.120,95.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.528 |  Acc: 45.840,65.110,69.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.527 |  Acc: 51.592,82.188,96.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.534 |  Acc: 45.930,65.200,68.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.533 |  Acc: 51.390,82.012,96.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.520 |  Acc: 46.040,65.200,69.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.528 |  Acc: 51.562,82.090,95.988,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.516 |  Acc: 46.050,65.350,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.522 |  Acc: 51.382,82.170,96.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.542 |  Acc: 45.920,65.110,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.527 |  Acc: 51.444,82.194,96.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.519 |  Acc: 46.190,65.320,69.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.522 |  Acc: 51.252,82.386,96.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.531 |  Acc: 46.070,65.110,69.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.534 |  Acc: 51.390,81.958,96.080,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.533 |  Acc: 46.130,65.100,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.530 |  Acc: 51.366,82.216,95.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.539 |  Acc: 46.040,65.170,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.523 |  Acc: 51.480,82.226,96.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.516 |  Acc: 46.020,65.220,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.526 |  Acc: 51.456,82.098,96.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.529 |  Acc: 46.020,65.300,69.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.529 |  Acc: 51.404,82.140,96.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.522 |  Acc: 46.080,65.220,69.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.523 |  Acc: 51.512,82.248,96.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.523 |  Acc: 46.130,65.220,69.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.523 |  Acc: 51.564,82.316,96.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.535 |  Acc: 46.150,65.390,68.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.535 |  Acc: 51.134,82.038,95.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.531 |  Acc: 46.020,65.130,69.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.524 |  Acc: 51.458,82.110,96.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.522 |  Acc: 45.970,65.330,69.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.515 |  Acc: 51.636,82.308,96.274,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.521 |  Acc: 46.010,65.220,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.529 |  Acc: 51.354,82.078,96.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.523 |  Acc: 45.950,65.110,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.519 |  Acc: 51.682,81.962,96.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.525 |  Acc: 45.990,65.260,69.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.521 |  Acc: 51.360,82.400,96.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.520 |  Acc: 46.050,65.370,69.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.524 |  Acc: 51.532,82.124,96.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.556 |  Acc: 45.920,65.060,68.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.524 |  Acc: 51.416,82.268,96.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.530 |  Acc: 45.950,65.210,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.517 |  Acc: 51.428,82.232,96.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.542 |  Acc: 45.980,65.330,69.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.518 |  Acc: 51.552,82.382,96.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.535 |  Acc: 46.020,65.360,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.524 |  Acc: 51.412,82.138,95.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.532 |  Acc: 45.950,65.250,69.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.507 |  Acc: 51.568,82.352,96.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.546 |  Acc: 46.150,65.210,69.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.522 |  Acc: 51.424,82.202,96.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.523 |  Acc: 45.890,65.270,69.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.522 |  Acc: 51.454,82.266,96.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.529 |  Acc: 46.100,65.200,69.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.524 |  Acc: 51.438,82.044,96.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.534 |  Acc: 46.090,65.450,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.522 |  Acc: 51.410,82.218,96.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.529 |  Acc: 46.210,65.160,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.521 |  Acc: 51.484,82.208,96.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.550 |  Acc: 46.050,65.010,69.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.519 |  Acc: 51.328,82.456,96.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.531 |  Acc: 46.010,65.080,69.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.521 |  Acc: 51.510,82.214,96.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.525 |  Acc: 45.960,65.250,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.513 |  Acc: 51.704,82.344,96.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.531 |  Acc: 45.980,65.150,69.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.509 |  Acc: 51.636,82.270,96.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.517 |  Acc: 45.970,65.170,69.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.524 |  Acc: 51.330,81.950,96.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.534 |  Acc: 46.100,65.190,69.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.521 |  Acc: 51.484,82.332,96.194,% | Adaptive Acc:87.434% | clf_exit: 0.344 0.460 0.196
Testing: Epoch=299 | Loss: 4.541 |  Acc: 46.160,65.190,69.320,% | Adaptive Acc:64.180% | clf_exit: 0.395 0.378 0.227

circles: 0
Testing: Epoch=299 | Loss: 26.900 |  Acc: 5.100,7.280,6.100,% | Adaptive Acc:5.640% | clf_exit: 0.791 0.139 0.070
circles: 1
Testing: Epoch=299 | Loss: 15.930 |  Acc: 10.240,22.000,20.360,% | Adaptive Acc:15.280% | clf_exit: 0.657 0.235 0.107
circles: 2
Testing: Epoch=299 | Loss: 6.748 |  Acc: 24.040,54.470,62.720,% | Adaptive Acc:46.660% | clf_exit: 0.446 0.353 0.200
circles: 3
Testing: Epoch=299 | Loss: 4.541 |  Acc: 46.160,65.190,69.320,% | Adaptive Acc:64.180% | clf_exit: 0.395 0.378 0.227
